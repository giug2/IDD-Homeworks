<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2312.04688] Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights</title><meta property="og:description" content="Artificial Intelligence (AI) is expected to play an instrumental role in the next generation of wireless systems, such as sixth-generation (6G) mobile network. However, massive data, energy consumption, training comple…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2312.04688">

<!--Generated on Tue Feb 27 11:31:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on September 20th, 2023.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Artificial Intelligence; Federated Learning; Decentralized Machine Learning; Privacy; Physical Layer; MAC Layer; Network Layer; Transport Layer; Application Layer; Cellular Networks; 6G.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Maryam Ben Driss<sup id="id7.7.id1" class="ltx_sup"><span id="id7.7.id1.1" class="ltx_text ltx_font_italic">∙</span></sup>,  Essaid Sabir<sup id="id8.8.id2" class="ltx_sup"><span id="id8.8.id2.1" class="ltx_text ltx_font_italic">∙</span></sup>,  Halima Elbiaze<sup id="id9.9.id3" class="ltx_sup"><span id="id9.9.id3.1" class="ltx_text ltx_font_italic">∙</span></sup> ,  Walid Saad<sup id="id10.10.id4" class="ltx_sup"><span id="id10.10.id4.1" class="ltx_text ltx_font_italic">∗</span></sup>, 
<br class="ltx_break">
<br class="ltx_break">
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><sup id="id11.11.id1" class="ltx_sup"><span id="id11.11.id1.1" class="ltx_text ltx_font_italic">∘</span></sup>Department of Computer Science, University of Quebec at Montreal (UQAM), Montreal, H2L 2C4, Canada
</span>
<span class="ltx_contact ltx_role_affiliation"><sup id="id12.12.id1" class="ltx_sup"><span id="id12.12.id1.1" class="ltx_text ltx_font_italic">∗</span></sup>WirelessVT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA, USA
</span></span></span>
</div>
<div class="ltx_dates">(September 20th, 2023)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id13.id1" class="ltx_p">Artificial Intelligence (AI) is expected to play an instrumental role in the next generation of wireless systems, such as sixth-generation (6G) mobile network. However, massive data, energy consumption, training complexity, and sensitive data protection in wireless systems are all crucial challenges that must be addressed for training AI models and gathering intelligence and knowledge from distributed devices. Federated Learning (FL) is a recent framework that has emerged as a promising approach for multiple learning agents to build an accurate and robust machine learning models without sharing raw data. By allowing mobile handsets and devices to collaboratively learn a global model without explicit sharing of training data, FL exhibits high privacy and efficient spectrum utilization. While there are a lot of survey papers exploring FL paradigms and usability in 6G privacy, none of them has clearly addressed how FL can be used to improve the protocol stack and wireless operations. The main goal of this survey is to provide a comprehensive overview on FL usability to enhance mobile services and enable smart ecosystems to support novel use-cases. This paper examines the added-value of implementing FL throughout all levels of the protocol stack. Furthermore, it presents important FL applications, addresses hot topics, provides valuable insights and explicits guidance for future research and developments. Our concluding remarks aim to leverage the synergy between FL and future 6G, while highlighting FL’s potential to revolutionize wireless industry and sustain the development of cutting-edge mobile services.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Artificial Intelligence; Federated Learning; Decentralized Machine Learning; Privacy; Physical Layer; MAC Layer; Network Layer; Transport Layer; Application Layer; Cellular Networks; 6G.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS1.4.1.1" class="ltx_text">I-A</span> </span><span id="S1.SS1.5.2" class="ltx_text ltx_font_italic">Artificial Intelligence for Wireless</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Artificial Intelligence (AI) is expected to play a prominent role in current and future wireless systems, such as fifth-generation (5G) and sixth-generation (6G) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Indeed, 6G systems are envisioned to be AI-native systems in which some form of AI will be implemented for automation across the protocol stack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. For instance, AI is expected to provide new frameworks for improving wireless performance metrics, including capacity, latency, efficiency, power, spectrum frequency, flexibility, compatibility, and quality of experience <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. AI techniques will influence next-generation network systems, due to two key reasons:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><em id="S1.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">Need for more autonomy:</em> Machine Learning (ML) techniques are necessary to endow wireless systems with autonomy and self-dependence by analyzing real-time data, such as traffic patterns, user behavior, and environmental factors, to make intelligent decisions for optimizing network resources, routing, and load balancing. This level of dynamic network management allows wireless systems to adapt to changing conditions without manual intervention.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><em id="S1.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">Need for more communication:</em> AI systems, with their ability to process vast amounts of data and learn from interactions, significantly contribute to making communication more accessible, efficient, and personalized to meet the diverse and growing demands of modern users and applications.</p>
</div>
</li>
</ul>
<p id="S1.SS1.p1.2" class="ltx_p">Numerous recent research activities have been focused on surveying the core wireless networking issues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> that are addressed using various ML techniques such as spectrum management and sharing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, resource allocation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, fading channels prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, and traffic prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
However, applying traditional ML schemes in large-scale systems is still challenging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, for the following reasons (non-exhaustive list):</p>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p"><em id="S1.I2.i1.p1.1.1" class="ltx_emph ltx_font_italic">Scalability:</em> Large-scale systems often handle massive amounts of data and require complex computations. In a centralized approach, all data is collected and processed on a single server, resulting in performance bottlenecks and increased processing times.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p"><em id="S1.I2.i2.p1.1.1" class="ltx_emph ltx_font_italic">Communication overhead:</em> In a centralized scheme, data from various sources must be transmitted to the central server for processing. This leads to significant communication overhead, especially when dealing with geographically distributed data sources.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p"><em id="S1.I2.i3.p1.1.1" class="ltx_emph ltx_font_italic">Single point of failure:</em> Centralized systems have a single point of failure. Any failure of the server will impact the entire ML process. This vulnerability is critical for real-time or mission-critical applications that require continuous and reliable operation.</p>
</div>
</li>
<li id="S1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i4.p1" class="ltx_para">
<p id="S1.I2.i4.p1.1" class="ltx_p"><em id="S1.I2.i4.p1.1.1" class="ltx_emph ltx_font_italic">Privacy and security concerns:</em> Centralized ML involves collecting and storing data from multiple sources in a central location. This raises concerns about privacy and security, as sensitive data are at risk without proper security measures in place.</p>
</div>
</li>
<li id="S1.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i5.p1" class="ltx_para">
<p id="S1.I2.i5.p1.1" class="ltx_p"><em id="S1.I2.i5.p1.1.1" class="ltx_emph ltx_font_italic">Latency and real-time requirements:</em> For real-time or low-latency applications, a centralized approach is not feasible due to the long delay of processing and transmission to the central server.</p>
</div>
</li>
<li id="S1.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i6.p1" class="ltx_para">
<p id="S1.I2.i6.p1.1" class="ltx_p"><em id="S1.I2.i6.p1.1.1" class="ltx_emph ltx_font_italic">Cost and infrastructure:</em> Building and maintaining a centralized ML infrastructure for large-scale systems is costly. It requires substantial computing power, storage, and network resources to handle the volume of data and computation involved.</p>
</div>
</li>
</ul>
<p id="S1.SS1.p1.3" class="ltx_p">To address these limitations, the concept of federated learning (FL) has been recently proposed, as an effective approach to train an ML model in a distributed way <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. FL allows multiple devices or nodes to collaboratively train a global model without sharing local data. In traditional ML, data is collected from various sources, sent to a centralized server, and then used to train a global model. However, the training process of FL occurs directly on individual devices or nodes without sharing raw data. FL framework offers a promising approach for future wireless systems by combining the benefits of distributed processing, privacy preservation, scalability, and adaptability. It empowers the evolution of wireless communication and enables the development of innovative and data-driven applications more efficiently and securely.
Still, there are several limitations to implementing FL due to the distributed and dynamic nature of wireless networks. Some of the key challenges include:</p>
<ul id="S1.I3" class="ltx_itemize">
<li id="S1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i1.p1" class="ltx_para">
<p id="S1.I3.i1.p1.1" class="ltx_p"><em id="S1.I3.i1.p1.1.1" class="ltx_emph ltx_font_italic">Limited bandwidth:</em> Transmitting model updates between the central server and edge devices is resource-intensive and leads to increased communication overhead.</p>
</div>
</li>
<li id="S1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i2.p1" class="ltx_para">
<p id="S1.I3.i2.p1.1" class="ltx_p"><em id="S1.I3.i2.p1.1.1" class="ltx_emph ltx_font_italic">Unreliable connectivity:</em> Managing the participation of devices with varying connectivity and capabilities requires robust mechanisms for synchronization and communication.</p>
</div>
</li>
<li id="S1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i3.p1" class="ltx_para">
<p id="S1.I3.i3.p1.1" class="ltx_p"><em id="S1.I3.i3.p1.1.1" class="ltx_emph ltx_font_italic">Computing constraints:</em> Participating clients are usually equipped with limited computational capabilities, which may affect the convergence speed and whole model performance.</p>
</div>
</li>
<li id="S1.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i4.p1" class="ltx_para">
<p id="S1.I3.i4.p1.1" class="ltx_p"><em id="S1.I3.i4.p1.1.1" class="ltx_emph ltx_font_italic">Imbalance and non-IID data:</em> In wireless networks, the data collected by edge devices is generally imbalanced or not independent and identically distributed (non-IID), which presents challenges for model convergence and generalization.</p>
</div>
</li>
</ul>
<p id="S1.SS1.p1.4" class="ltx_p">Addressing these challenges requires a careful combination of algorithmic advancements, optimization techniques, and architectural design to make FL feasible and effective in wireless environments. As the field of FL evolves, researchers continue to work on overcoming these challenges to enable practical and secure deployments in future wireless networks.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS2.4.1.1" class="ltx_text">I-B</span> </span><span id="S1.SS2.5.2" class="ltx_text ltx_font_italic">Relevant Surveys and our Contribution</span>
</h3>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2312.04688/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="206" height="517" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The survey paper organization.</figcaption>
</figure>
<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">Although there are many surveys on FL and wireless networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> as summarized in Table <a href="#S1.T1" title="TABLE I ‣ I-B Relevant Surveys and our Contribution ‣ I Introduction ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, they do not address their applicability across the protocol stack or provide a detailed examination of FL applications in each layer of the Open Systems Interconnection (OSI) model. This survey aims to fill this gap by providing an in-depth overview of how FL is implemented throughout the entire protocol stack. We also highlight associated advantages and discuss induced challenges. State-of-the-art contributions that utilize federated ML schemes to address problems in wireless communications are collected and discussed. Our main contributions include:</p>
<ol id="S1.I4" class="ltx_enumerate">
<li id="S1.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I4.i1.p1" class="ltx_para">
<p id="S1.I4.i1.p1.1" class="ltx_p">Drawing a comprehensive background on recent FL paradigms, taxonomy and main techniques;</p>
</div>
</li>
<li id="S1.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I4.i2.p1" class="ltx_para">
<p id="S1.I4.i2.p1.1" class="ltx_p">Comparing centralized ML, distributed ML, and FL in the context of massive and sensitive environments while highlighting the characteristics and the issues associated with each approach; </p>
</div>
</li>
<li id="S1.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I4.i3.p1" class="ltx_para">
<p id="S1.I4.i3.p1.1" class="ltx_p">Exploring the latest FL schemes aiming to solve the major issues at the physical (PHY), medium access control (MAC), network (NET), transport, and application (APP) layers while achieving high accuracy, enhanced communication efficiency and low energy consumption. We also draw a detailed analysis of the benefits and drawbacks of each application/solution;</p>
</div>
</li>
<li id="S1.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I4.i4.p1" class="ltx_para">
<p id="S1.I4.i4.p1.1" class="ltx_p">Discussing relevant insights and open issues related to the application of FL in 6G and future mobile networks.</p>
</div>
</li>
</ol>
<p id="S1.SS2.p1.2" class="ltx_p">For a pleasant reading experience, our survey is organized as depicted in Fig. <a href="#S1.F1" title="Figure 1 ‣ I-B Relevant Surveys and our Contribution ‣ I Introduction ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Section II presents ML architectures and their challenges in the context of wireless systems. In Section III, we present a comprehensive overview of FL fundamentals, features, taxonomy, frameworks, benefits, and issues. Next, we explore FL for wireless operations, while focusing on PHY/MAC, NET and Transport/APP layers, in Section IV, Section V and Section VI, respectively. Next, we present recent FL verticals and applications in Section VII. Then, Section VIII summarizes the lessons learned and provide a detailed discussion of FL-wireless open problems that need to be addressed for successful integration in 6G and future systems. Finally, we highlight some promising directions for future research towards efficient AI-native networking.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<table id="S1.T1.74" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.74.75.1" class="ltx_tr">
<th id="S1.T1.74.75.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_ll ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.74.75.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.74.75.1.1.1.1" class="ltx_p" style="width:17.1pt;"><span id="S1.T1.74.75.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref</span></span>
</span>
</th>
<th id="S1.T1.74.75.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S1.T1.74.75.1.2.1" class="ltx_text ltx_font_bold">Year</span></th>
<th id="S1.T1.74.75.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S1.T1.74.75.1.3.1" class="ltx_text ltx_font_bold">Target application</span></th>
<th id="S1.T1.74.75.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S1.T1.74.75.1.4.1" class="ltx_text ltx_font_bold">Basics</span></th>
<th id="S1.T1.74.75.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S1.T1.74.75.1.5.1" class="ltx_text ltx_font_bold">PHY Layer</span></th>
<th id="S1.T1.74.75.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S1.T1.74.75.1.6.1" class="ltx_text ltx_font_bold">NET layer</span></th>
<th id="S1.T1.74.75.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S1.T1.74.75.1.7.1" class="ltx_text ltx_font_bold">Transport Layer</span></th>
<th id="S1.T1.74.75.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S1.T1.74.75.1.8.1" class="ltx_text ltx_font_bold">APP Layer</span></th>
<th id="S1.T1.74.75.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S1.T1.74.75.1.9.1" class="ltx_text ltx_font_bold">Challenges</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.4.4" class="ltx_tr">
<td id="S1.T1.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.4.5.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite></span>
</span>
</td>
<td id="S1.T1.4.4.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2020</td>
<td id="S1.T1.4.4.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">FL in mobile edge networks</td>
<td id="S1.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.1.1.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.2.2.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.4.4.8" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.3.3.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.4.4.9" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.4.4.4.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.7.7" class="ltx_tr">
<td id="S1.T1.7.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.7.7.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite></span>
</span>
</td>
<td id="S1.T1.7.7.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2020</td>
<td id="S1.T1.7.7.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FL for wireless communications</td>
<td id="S1.T1.5.5.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.5.5.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.6.6.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.6.6.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.7.7.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.7.7.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.7.7.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.7.7.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.7.7.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.11.11" class="ltx_tr">
<td id="S1.T1.11.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.11.11.5.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite></span>
</span>
</td>
<td id="S1.T1.11.11.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2020</td>
<td id="S1.T1.11.11.7" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Distributed ML for communication networks</td>
<td id="S1.T1.8.8.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.8.8.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.9.9.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.9.9.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.11.11.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.11.11.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.10.10.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.10.10.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.11.11.4" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.11.11.4.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.14.14" class="ltx_tr">
<td id="S1.T1.14.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.14.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.14.14.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite></span>
</span>
</td>
<td id="S1.T1.14.14.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2020</td>
<td id="S1.T1.14.14.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FL and wireless communications</td>
<td id="S1.T1.12.12.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.12.12.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.14.14.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.14.14.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.14.14.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.13.13.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.13.13.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.14.14.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.14.14.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.17.17" class="ltx_tr">
<td id="S1.T1.17.17.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.17.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.17.17.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite></span>
</span>
</td>
<td id="S1.T1.17.17.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2021</td>
<td id="S1.T1.17.17.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">ML and FL for handover management in 5G</td>
<td id="S1.T1.15.15.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.15.15.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.17.17.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.16.16.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.16.16.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.17.17.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.17.17.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.17.17.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.17.17.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.20.20" class="ltx_tr">
<td id="S1.T1.20.20.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.20.20.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.20.20.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span>
</span>
</td>
<td id="S1.T1.20.20.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2021</td>
<td id="S1.T1.20.20.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Federated machine learning for 6G</td>
<td id="S1.T1.18.18.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.18.18.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.19.19.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.19.19.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.20.20.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.20.20.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.20.20.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.20.20.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.20.20.9" class="ltx_td ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
</tr>
<tr id="S1.T1.22.22" class="ltx_tr">
<td id="S1.T1.22.22.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.22.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.22.22.3.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite></span>
</span>
</td>
<td id="S1.T1.22.22.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2021</td>
<td id="S1.T1.22.22.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FL for physical layer</td>
<td id="S1.T1.21.21.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.21.21.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.22.22.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.22.22.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.22.22.6" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.22.22.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.22.22.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.22.22.9" class="ltx_td ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
</tr>
<tr id="S1.T1.25.25" class="ltx_tr">
<td id="S1.T1.25.25.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.25.25.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.25.25.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite></span>
</span>
</td>
<td id="S1.T1.25.25.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2021</td>
<td id="S1.T1.25.25.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FL in networking systems</td>
<td id="S1.T1.23.23.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.23.23.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.25.25.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.24.24.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.24.24.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.25.25.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.25.25.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.25.25.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.25.25.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.29.29" class="ltx_tr">
<td id="S1.T1.29.29.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.29.29.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.29.29.5.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite></span>
</span>
</td>
<td id="S1.T1.29.29.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2021</td>
<td id="S1.T1.29.29.7" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Federated learning for IoT</td>
<td id="S1.T1.26.26.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.26.26.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.29.29.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.27.27.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.27.27.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.29.29.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.28.28.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.28.28.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.29.29.4" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.29.29.4.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.33.33" class="ltx_tr">
<td id="S1.T1.33.33.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.33.33.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.33.33.5.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite></span>
</span>
</td>
<td id="S1.T1.33.33.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2021</td>
<td id="S1.T1.33.33.7" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Recent advances of FL for IoT networks</td>
<td id="S1.T1.30.30.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.30.30.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.31.31.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.31.31.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.33.33.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.33.33.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.32.32.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.32.32.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.33.33.4" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.33.33.4.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.36.36" class="ltx_tr">
<td id="S1.T1.36.36.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.36.36.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.36.36.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite></span>
</span>
</td>
<td id="S1.T1.36.36.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2021</td>
<td id="S1.T1.36.36.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Federated ML for big data</td>
<td id="S1.T1.34.34.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.34.34.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.36.36.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.36.36.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.36.36.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.35.35.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.35.35.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.36.36.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.36.36.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.40.40" class="ltx_tr">
<td id="S1.T1.40.40.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.40.40.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.40.40.5.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite></span>
</span>
</td>
<td id="S1.T1.40.40.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2021</td>
<td id="S1.T1.40.40.7" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Intelligence for 6G using FL</td>
<td id="S1.T1.37.37.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.37.37.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.38.38.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.38.38.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.40.40.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.40.40.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.39.39.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.39.39.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.40.40.4" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.40.40.4.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.43.43" class="ltx_tr">
<td id="S1.T1.43.43.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.43.43.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.43.43.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite></span>
</span>
</td>
<td id="S1.T1.43.43.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2021</td>
<td id="S1.T1.43.43.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">The internet of federated things</td>
<td id="S1.T1.41.41.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.41.41.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.43.43.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.43.43.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.43.43.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.42.42.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.42.42.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.43.43.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.43.43.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.44.44" class="ltx_tr">
<td id="S1.T1.44.44.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.44.44.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.44.44.2.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite></span>
</span>
</td>
<td id="S1.T1.44.44.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2022</td>
<td id="S1.T1.44.44.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">From distributed ML to FL</td>
<td id="S1.T1.44.44.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.44.44.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.44.44.5" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.44.44.6" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.44.44.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.44.44.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.44.44.9" class="ltx_td ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
</tr>
<tr id="S1.T1.48.48" class="ltx_tr">
<td id="S1.T1.48.48.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.48.48.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.48.48.5.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite></span>
</span>
</td>
<td id="S1.T1.48.48.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2022</td>
<td id="S1.T1.48.48.7" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FL and next-generation communications</td>
<td id="S1.T1.45.45.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.45.45.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.46.46.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.46.46.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.47.47.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.47.47.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.48.48.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.48.48.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.48.48.4" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.48.48.4.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.50.50" class="ltx_tr">
<td id="S1.T1.50.50.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.50.50.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.50.50.3.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite></span>
</span>
</td>
<td id="S1.T1.50.50.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2022</td>
<td id="S1.T1.50.50.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FL attacks and threats</td>
<td id="S1.T1.49.49.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.49.49.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.50.50.6" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.50.50.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.50.50.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.50.50.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.50.50.2" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.50.50.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.52.52" class="ltx_tr">
<td id="S1.T1.52.52.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.52.52.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.52.52.3.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite></span>
</span>
</td>
<td id="S1.T1.52.52.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2022</td>
<td id="S1.T1.52.52.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Federated learning fundamentals</td>
<td id="S1.T1.51.51.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.51.51.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.52.52.6" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.52.52.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.52.52.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.52.52.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.52.52.2" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.52.52.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.55.55" class="ltx_tr">
<td id="S1.T1.55.55.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.55.55.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.55.55.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite></span>
</span>
</td>
<td id="S1.T1.55.55.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2022</td>
<td id="S1.T1.55.55.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FL for intrusion detection</td>
<td id="S1.T1.53.53.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.53.53.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.55.55.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.55.55.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.55.55.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.54.54.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.54.54.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.55.55.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.55.55.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.58.58" class="ltx_tr">
<td id="S1.T1.58.58.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.58.58.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.58.58.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite></span>
</span>
</td>
<td id="S1.T1.58.58.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2022</td>
<td id="S1.T1.58.58.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FL for IoT and cybersecurity</td>
<td id="S1.T1.56.56.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.56.56.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.58.58.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.58.58.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.58.58.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.57.57.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.57.57.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.58.58.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.58.58.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.60.60" class="ltx_tr">
<td id="S1.T1.60.60.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.60.60.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.60.60.3.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite></span>
</span>
</td>
<td id="S1.T1.60.60.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2022</td>
<td id="S1.T1.60.60.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">The application of FL in smart cities</td>
<td id="S1.T1.59.59.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.59.59.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.60.60.6" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.60.60.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.60.60.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.60.60.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.60.60.2" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.60.60.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.62.62" class="ltx_tr">
<td id="S1.T1.62.62.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.62.62.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.62.62.3.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite></span>
</span>
</td>
<td id="S1.T1.62.62.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2023</td>
<td id="S1.T1.62.62.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FL challenges and applications</td>
<td id="S1.T1.61.61.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.61.61.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.62.62.6" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.62.62.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.62.62.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.62.62.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.62.62.2" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.62.62.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.65.65" class="ltx_tr">
<td id="S1.T1.65.65.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.65.65.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.65.65.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite></span>
</span>
</td>
<td id="S1.T1.65.65.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2023</td>
<td id="S1.T1.65.65.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Trends and challenges of FL for 6G</td>
<td id="S1.T1.63.63.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.63.63.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.65.65.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.65.65.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.65.65.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.64.64.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.64.64.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.65.65.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.65.65.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.68.68" class="ltx_tr">
<td id="S1.T1.68.68.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.68.68.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.68.68.4.1.1" class="ltx_p" style="width:17.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite></span>
</span>
</td>
<td id="S1.T1.68.68.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2023</td>
<td id="S1.T1.68.68.6" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Communication efficiency in FL</td>
<td id="S1.T1.66.66.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.66.66.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.67.67.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.67.67.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.68.68.7" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.68.68.8" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.68.68.9" class="ltx_td ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S1.T1.68.68.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.68.68.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
<tr id="S1.T1.74.74" class="ltx_tr">
<td id="S1.T1.74.74.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S1.T1.74.74.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.74.74.7.1.1" class="ltx_p" style="width:17.1pt;">Our work</span>
</span>
</td>
<td id="S1.T1.74.74.8" class="ltx_td ltx_align_left ltx_border_b ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">2023</td>
<td id="S1.T1.74.74.9" class="ltx_td ltx_align_left ltx_border_b ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Multilayered survey on FL for B5G and 6G</td>
<td id="S1.T1.69.69.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.69.69.1.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.70.70.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.70.70.2.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.71.71.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.71.71.3.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.72.72.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.72.72.4.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.73.73.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.73.73.5.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
<td id="S1.T1.74.74.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;"><svg id="S1.T1.74.74.6.pic1" class="ltx_picture" height="11.02" overflow="visible" version="1.1" width="15.75"><g transform="translate(0,11.02) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 0 5.51 L 3.94 0 L 15.75 11.02 L 3.94 2.36 Z" style="stroke:none"></path></g></svg>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Related existing survey papers on FL for network communications.</figcaption>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Machine Learning Architectures</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Here, we provide an overview of ML architectures including traditional centralized learning, distributed learning and FL.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Centralized Machine Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">ML is the science of enabling computers to learn without being explicitly programmed. This branch of AI allows systems to identify patterns in data, make decisions, and predict future outcomes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. Standard ML techniques require data to be stored on a single machine for processing and model training (Fig. <a href="#S2.F2" title="Figure 2 ‣ II-A Centralized Machine Learning ‣ II Machine Learning Architectures ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.1). Today, Internet of Things (IoT) applications use traditional ML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> by uploading data from IoT sensors to the cloud. The cloud server trains a global model using data from multiple devices, allowing immediate interaction with other participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>. However, centralized ML suffers from numerous drawbacks, especially in wireless environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. Hereafter, we provide a non-exhaustive list of these limitations:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><em id="S2.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">Privacy issues:</em> Centralized learning involves collecting and storing sensitive data from various sources, raising significant privacy concerns as a potential target for unauthorized access <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><em id="S2.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">Latency issues:</em> In centralized learning, data from individual devices is transmitted to a central server. This data transfer introduces latency, which is highly undesirable in applications like real-time communications, autonomous vehicles, or industrial automation, where low latency is critical.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><em id="S2.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">Costs:</em> Maintaining and operating centralized servers with the computational power and storage capacity required for large-scale ML is expensive for network operators <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>.</p>
</div>
</li>
</ul>
<p id="S2.SS1.p1.2" class="ltx_p">It is worth noting that decentralized approaches, such as edge ML, have been designed to address some of the challenges of centralized ML techniques.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2312.04688/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Centralized ML has to store data in one data center. Decentralized ML distributes the model across connected devices.</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Decentralized Machine Learning</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The concept of decentralized ML was proposed (See <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>) as an effective solution to address the key challenges listed in Section II.A. As shown in Fig. <a href="#S2.F2" title="Figure 2 ‣ II-A Centralized Machine Learning ‣ II Machine Learning Architectures ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.2, the decentralized ML approach distributes the computational and data processing tasks across multiple decentralized devices rather than relying on a central server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> which offers several benefits, such as:</p>
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p">Simplifying learning since each device needs only its dataset while sharing minimal information with external participants.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p">Adapting to changes over time and learning without being limited by an internet connection or reliance on a central device.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p">Allowing sensitive data to remain on local devices or edge servers without transmitting to a central location. This enhances data privacy and security.</p>
</div>
</li>
</ul>
<p id="S2.SS2.p1.2" class="ltx_p">Overall, edge learning empowers wireless communication systems to efficiently handle data, improve response times, enhance privacy, and create more resilient and scalable applications, making it a valuable technology for the growing IoT and 5G ecosystems. Nevertheless, various challenges limit the generated local models to benefit from peer data and learn from external experiences, such as:</p>
<ul id="S2.I3" class="ltx_itemize">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.1" class="ltx_p"><em id="S2.I3.i1.p1.1.1" class="ltx_emph ltx_font_italic">Data heterogeneity:</em> In large-scale environments, data collected from different sources has diverse distributions, leading to challenges in combining and aggregating the models effectively.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.1" class="ltx_p"><em id="S2.I3.i2.p1.1.1" class="ltx_emph ltx_font_italic">Communication overhead:</em> The exchange of model updates among distributed nodes introduces communication overhead, particularly in bandwidth-constrained networks.</p>
</div>
</li>
<li id="S2.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i3.p1" class="ltx_para">
<p id="S2.I3.i3.p1.1" class="ltx_p"><em id="S2.I3.i3.p1.1.1" class="ltx_emph ltx_font_italic">Synchronization:</em> Coordinating the timing of model updates across distributed nodes is complex, leading to synchronization issues and potential inconsistencies.</p>
</div>
</li>
</ul>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2312.04688/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="326" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>FL: Collaborative ML without centralized training data.</figcaption>
</figure>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">FL offers a privacy-preserving, scalable, and efficient approach that addresses many of the challenges associated with traditional centralized and decentralized ML, making it a valuable solution in the era of data privacy and decentralization. It is particularly well-suited for applications involving sensitive data, edge computing, and distributed environments.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">Federated Machine Learning</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">FL was recently proposed by Google <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> as a promising approach for performing distributed ML tasks without relying on a centralized data center. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> defined FL as an ML setting wherein multiple entities (clients) work together to solve an ML problem under the coordination of a central server or service provider. In this approach, personal data remains stored locally and is not exchanged or transferred between clients (e.g., see Fig.<a href="#S2.F3" title="Figure 3 ‣ II-B Decentralized Machine Learning ‣ II Machine Learning Architectures ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). Instead, the model updates designed for aggregation are used to achieve the learning objective, enabling secure training while leveraging the collective knowledge of the distributed entities. FL is based on the idea of training a model locally at the data source. The devices communicate their models by combining partial training results into a new supermodel, which is then sent back to all devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>. This mechanism is strategically designed to protect privacy and enhance data security <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>.
Fig <a href="#S2.F4" title="Figure 4 ‣ II-C Federated Machine Learning ‣ II Machine Learning Architectures ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates that FL depends on the collaboration of ML, privacy, and distributed systems expertise which is fundamental to addressing the challenges posed by distributed data and privacy concerns while harnessing the collective intelligence of decentralized entities for improved model performance and scalability.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2312.04688/assets/x4.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="181" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>FL encompasses three synergistic research areas: ML, privacy, and distributed systems.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning Fundamentals</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Before discussing FL applications in wireless systems, it is necessary to provide a brief overview of FL concepts, taxonomy, and techniques. The main concepts of FL are summarized in Table <a href="#S3.T2" title="TABLE II ‣ III Federated Learning Fundamentals ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.
</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.3.4.1" class="ltx_tr">
<th id="S3.T2.3.4.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_ll ltx_border_r ltx_border_t" style="width:51.2pt;padding-top:4.5pt;padding-bottom:4.5pt;">
<span id="S3.T2.3.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.4.1.1.1.1" class="ltx_p"><span id="S3.T2.3.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Goal</span></span>
</span>
</th>
<th id="S3.T2.3.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_rr ltx_border_t" style="padding-top:4.5pt;padding-bottom:4.5pt;">
<span id="S3.T2.3.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.4.1.2.1.1" class="ltx_p" style="width:170.7pt;">Distributed model training without centralized data collection and with privacy guarantees</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.3.3" class="ltx_tr">
<td id="S3.T2.3.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_ll ltx_border_r ltx_border_t" style="width:51.2pt;padding-top:4.5pt;padding-bottom:4.5pt;">
<span id="S3.T2.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.3.4.1.1" class="ltx_p"><span id="S3.T2.3.3.4.1.1.1" class="ltx_text ltx_font_bold">Setting</span></span>
</span>
</td>
<td id="S3.T2.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:4.5pt;padding-bottom:4.5pt;">
<span id="S3.T2.3.3.3.3" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.3.3.3.3" class="ltx_p" style="width:170.7pt;"><math id="S3.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.T2.1.1.1.1.1.m1.1a"><mi id="S3.T2.1.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.1.m1.1c">K</annotation></semantics></math> devices, out of which <math id="S3.T2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.T2.2.2.2.2.2.m2.1a"><mi id="S3.T2.2.2.2.2.2.m2.1.1" xref="S3.T2.2.2.2.2.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.2.2.m2.1b"><ci id="S3.T2.2.2.2.2.2.m2.1.1.cmml" xref="S3.T2.2.2.2.2.2.m2.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.2.2.m2.1c">C</annotation></semantics></math> are selected (<math id="S3.T2.3.3.3.3.3.m3.1" class="ltx_Math" alttext="C\leq" display="inline"><semantics id="S3.T2.3.3.3.3.3.m3.1a"><mrow id="S3.T2.3.3.3.3.3.m3.1.1" xref="S3.T2.3.3.3.3.3.m3.1.1.cmml"><mi id="S3.T2.3.3.3.3.3.m3.1.1.2" xref="S3.T2.3.3.3.3.3.m3.1.1.2.cmml">C</mi><mo id="S3.T2.3.3.3.3.3.m3.1.1.1" xref="S3.T2.3.3.3.3.3.m3.1.1.1.cmml">≤</mo><mi id="S3.T2.3.3.3.3.3.m3.1.1.3" xref="S3.T2.3.3.3.3.3.m3.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.3.3.m3.1b"><apply id="S3.T2.3.3.3.3.3.m3.1.1.cmml" xref="S3.T2.3.3.3.3.3.m3.1.1"><leq id="S3.T2.3.3.3.3.3.m3.1.1.1.cmml" xref="S3.T2.3.3.3.3.3.m3.1.1.1"></leq><ci id="S3.T2.3.3.3.3.3.m3.1.1.2.cmml" xref="S3.T2.3.3.3.3.3.m3.1.1.2">𝐶</ci><csymbol cd="latexml" id="S3.T2.3.3.3.3.3.m3.1.1.3.cmml" xref="S3.T2.3.3.3.3.3.m3.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.3.3.m3.1c">C\leq</annotation></semantics></math>K)</span>
</span>
</td>
</tr>
<tr id="S3.T2.3.5.1" class="ltx_tr">
<td id="S3.T2.3.5.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_ll ltx_border_r ltx_border_t" style="width:51.2pt;padding-top:4.5pt;padding-bottom:4.5pt;">
<span id="S3.T2.3.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.5.1.1.1.1" class="ltx_p"><span id="S3.T2.3.5.1.1.1.1.1" class="ltx_text ltx_font_bold">Parameters</span></span>
</span>
</td>
<td id="S3.T2.3.5.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:4.5pt;padding-bottom:4.5pt;">
<span id="S3.T2.3.5.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.5.1.2.1.1" class="ltx_p" style="width:170.7pt;">
<span id="S3.I1" class="ltx_itemize">
<span id="S3.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I1.i1.p1" class="ltx_para">
<span id="S3.I1.i1.p1.1" class="ltx_p">Batch size</span>
</span></span>
<span id="S3.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I1.i2.p1" class="ltx_para">
<span id="S3.I1.i2.p1.1" class="ltx_p">Number of clients</span>
</span></span>
<span id="S3.I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I1.i3.p1" class="ltx_para">
<span id="S3.I1.i3.p1.1" class="ltx_p">Local iterations</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.3.6.2" class="ltx_tr">
<td id="S3.T2.3.6.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_ll ltx_border_r ltx_border_t" style="width:51.2pt;padding-top:4.5pt;padding-bottom:4.5pt;">
<span id="S3.T2.3.6.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.6.2.1.1.1" class="ltx_p"><span id="S3.T2.3.6.2.1.1.1.1" class="ltx_text ltx_font_bold">Orchestration</span></span>
</span>
</td>
<td id="S3.T2.3.6.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:4.5pt;padding-bottom:4.5pt;">
<span id="S3.T2.3.6.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.6.2.2.1.1" class="ltx_p" style="width:170.7pt;">A central orchestration server or service organizes the training but never sees raw data.</span>
</span>
</td>
</tr>
<tr id="S3.T2.3.7.3" class="ltx_tr">
<td id="S3.T2.3.7.3.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_ll ltx_border_r ltx_border_t" style="width:51.2pt;padding-top:4.5pt;padding-bottom:4.5pt;">
<span id="S3.T2.3.7.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.7.3.1.1.1" class="ltx_p"><span id="S3.T2.3.7.3.1.1.1.1" class="ltx_text ltx_font_bold">Advantages</span></span>
</span>
</td>
<td id="S3.T2.3.7.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_rr ltx_border_t" style="padding-top:4.5pt;padding-bottom:4.5pt;">
<span id="S3.T2.3.7.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.7.3.2.1.1" class="ltx_p" style="width:170.7pt;">
<span id="S3.I2" class="ltx_itemize">
<span id="S3.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i1.p1" class="ltx_para">
<span id="S3.I2.i1.p1.1" class="ltx_p">Respecting user’s privacy</span>
</span></span>
<span id="S3.I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i2.p1" class="ltx_para">
<span id="S3.I2.i2.p1.1" class="ltx_p">Minimum hardware required</span>
</span></span>
<span id="S3.I2.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i3.p1" class="ltx_para">
<span id="S3.I2.i3.p1.1" class="ltx_p">Saving user’s resources</span>
</span></span>
<span id="S3.I2.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i4.p1" class="ltx_para">
<span id="S3.I2.i4.p1.1" class="ltx_p">Working offline</span>
</span></span>
<span id="S3.I2.i5" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i5.p1" class="ltx_para">
<span id="S3.I2.i5.p1.1" class="ltx_p">Computing in real-time</span>
</span></span>
<span id="S3.I2.i6" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S3.I2.i6.p1" class="ltx_para">
<span id="S3.I2.i6.p1.1" class="ltx_p">Decreasing training complexity</span>
</span></span>
</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>FL concepts.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Federated Learning Life Cycle</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The FL process is typically driven by an engineer developing a model for a specific application <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>. In Fig. <a href="#S3.F5" title="Figure 5 ‣ III-B1 Horizontal Federated Learning ‣ III-B Different Flavors of FL ‣ III Federated Learning Fundamentals ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, the FL workflow generally comprises four steps that occur sequentially.</p>
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p"><em id="S3.I3.i1.p1.1.1" class="ltx_emph ltx_font_italic">Model selection:</em> The global model and parameters are initiated on a central server and shared with all participants.</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p"><em id="S3.I3.i2.p1.1.1" class="ltx_emph ltx_font_italic">Local model training:</em> Clients train the model locally using their data without sharing it with the central server or other clients.</p>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p id="S3.I3.i3.p1.1" class="ltx_p"><em id="S3.I3.i3.p1.1.1" class="ltx_emph ltx_font_italic">Aggregation of local models:</em> The update is sent to the central server to aggregate received parameters and create a new global model.</p>
</div>
</li>
<li id="S3.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i4.p1" class="ltx_para">
<p id="S3.I3.i4.p1.1" class="ltx_p"><em id="S3.I3.i4.p1.1.1" class="ltx_emph ltx_font_italic">Distribution of global model:</em> The distribution of the global model among participants for the next iteration.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Different Flavors of FL</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">FL frameworks are classified into three types: horizontal, vertical, and federated transfer learning, based on the distribution of data samples and features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS1.4.1.1" class="ltx_text">III-B</span>1 </span>Horizontal Federated Learning</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">Horizontal FL (HFL) or sample-based FL is applied to scenarios in which datasets share the same feature space but differ in the sample <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>. In other words, the participating client devices share the same features but target different populations. considering two banks operating in the same country, the clients of those banks are non-overlapping, their data are likely to have a similar feature space since they adopt similar businesses and operate in the same country. Partitioning by samples is usually relevant when a single company cannot centralize its data due to legal constraints or when organizations with similar aims want to improve their models collaboratively <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. Wake-word recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>, such as ”Hey Siri” and ”OK Google”, is a typical application of horizontal partition since each user says the same sentence in a different accent.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2312.04688/assets/x5.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="181" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>FL Life Cycle.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS2.4.1.1" class="ltx_text">III-B</span>2 </span>Vertical Federated Learning</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Vertical FL (VFL) is specifically applicable in scenarios where two datasets share the same sample space but differ in their feature space <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>. To illustrate this FL category, consider two companies located in the same town, one being a bank, and the other an e-commerce company. While their user base is overlapping, their data collections diverge. The bank tracks user sales, spending activity, and credit scores, while the e-commerce store captures user search and buying history. As the objective is to train a model predicting product purchases based on user features, VFL emerges as the ideal solution to gather additional features and construct a comprehensive model using data from both companies.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS3.4.1.1" class="ltx_text">III-B</span>3 </span>Federated Transfer Learning</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">Federated transfer learning (FTL) is suitable where two datasets vary in terms of samples and features space <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. Considering two companies from two countries whose users and feature spaces have a small intersection. In this scenario, FTL learns from the common instances between the spaces using the limited standard sample sets. The knowledge gained is later applied to make predictions for samples with only one-sided features. In wireless systems, FTL enables devices to remember what they have learned and what other devices have learned <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite> and this is applicable to cases in which multiple wireless devices make decisions in different environments.</p>
</div>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS4.4.1.1" class="ltx_text">III-B</span>4 </span>Other Categories</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p">There are other FL architectures, beyond HFL, VFL, and FTL. For instance, multi-participant multi-class VFL (MMVFL) was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> to manage many users. It allows privacy-preserving label distribution from its owner to other participants. FEDF is another framework introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> to train ML models on multiple geographically distributed training datasets belonging to several owners. Another FL framework, called PerFit, was developed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> to enhance the performance of devices in IoT applications by learning a shared model through aggregating local updates from distributed devices and utilizing the benefits of edge computing. This approach enables personalization and improved performance for IoT devices. In general, there are several architectures for FL depending on the distribution characteristics of the data (e.g., see Table <a href="#S3.T3" title="TABLE III ‣ III-B4 Other Categories ‣ III-B Different Flavors of FL ‣ III Federated Learning Fundamentals ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>).</p>
</div>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<th id="S3.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_ll ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref</span></th>
<th id="S3.T3.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Architecture</span></th>
<th id="S3.T3.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">Focuses</span></th>
<th id="S3.T3.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T3.1.1.1.4.1" class="ltx_text ltx_font_bold">Benefits</span></th>
<th id="S3.T3.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_rr ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T3.1.1.1.5.1" class="ltx_text ltx_font_bold">Drawbacks</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.1.2.1" class="ltx_tr">
<th id="S3.T3.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite></th>
<td id="S3.T3.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">HFL</td>
<td id="S3.T3.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Security</td>
<td id="S3.T3.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Independence</td>
<td id="S3.T3.1.2.1.5" class="ltx_td ltx_align_left ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Need to provide more security</td>
</tr>
<tr id="S3.T3.1.3.2" class="ltx_tr">
<th id="S3.T3.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite></th>
<td id="S3.T3.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">VFL</td>
<td id="S3.T3.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Privacy</td>
<td id="S3.T3.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Encryption</td>
<td id="S3.T3.1.3.2.5" class="ltx_td ltx_align_left ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;">Handling only two participants</td>
</tr>
<tr id="S3.T3.1.4.3" class="ltx_tr">
<th id="S3.T3.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite></th>
<td id="S3.T3.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FTL</td>
<td id="S3.T3.1.4.3.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Avoiding accuracy loss</td>
<td id="S3.T3.1.4.3.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">High precision</td>
<td id="S3.T3.1.4.3.5" class="ltx_td ltx_align_left ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;">Expensive computation</td>
</tr>
<tr id="S3.T3.1.5.4" class="ltx_tr">
<th id="S3.T3.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite></th>
<td id="S3.T3.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">MMVFL</td>
<td id="S3.T3.1.5.4.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Data leakage</td>
<td id="S3.T3.1.5.4.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Multiple participants</td>
<td id="S3.T3.1.5.4.5" class="ltx_td ltx_align_left ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;">Need to handle stragglers effectively</td>
</tr>
<tr id="S3.T3.1.6.5" class="ltx_tr">
<th id="S3.T3.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite></th>
<td id="S3.T3.1.6.5.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">FEDF</td>
<td id="S3.T3.1.6.5.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Parallel training</td>
<td id="S3.T3.1.6.5.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Accelerating training</td>
<td id="S3.T3.1.6.5.5" class="ltx_td ltx_align_left ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;">Enormous data exchange</td>
</tr>
<tr id="S3.T3.1.7.6" class="ltx_tr">
<th id="S3.T3.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite></th>
<td id="S3.T3.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">PerFit</td>
<td id="S3.T3.1.7.6.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">IOT applicability</td>
<td id="S3.T3.1.7.6.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Cloud based</td>
<td id="S3.T3.1.7.6.5" class="ltx_td ltx_align_left ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;">Data augmentation step is required</td>
</tr>
<tr id="S3.T3.1.8.7" class="ltx_tr">
<th id="S3.T3.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_ll ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite></th>
<td id="S3.T3.1.8.7.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">StarFL</td>
<td id="S3.T3.1.8.7.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Urban computing</td>
<td id="S3.T3.1.8.7.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r" style="padding-top:2.5pt;padding-bottom:2.5pt;">Security</td>
<td id="S3.T3.1.8.7.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_rr" style="padding-top:2.5pt;padding-bottom:2.5pt;">System efficiency</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>FL architectures: focuses, benefits and drawbacks.</figcaption>
</figure>
<div id="S3.SS2.SSS4.p2" class="ltx_para">
<p id="S3.SS2.SSS4.p2.1" class="ltx_p">Furthermore, the hybrid federated centralized learning (HFCL) approach proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> contributes to the learning process with their datasets. In cases where certain edge devices lack the computational capacity to compute gradients during model training, HFCL proves valuable because it exclusively enables active devices with sufficient computing capabilities to conduct gradient computations on their respective local datasets and engage in collaborative training of the learning model. In contrast, the remaining passive devices send their local datasets to the parameter server.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>, the authors proposed a novel concept of collaborative FL, whereby devices leverage FL techniques without relying on a centralized parameter server. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> showcases the architecture and challenges of this CFL paradigm.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Federated Learning Algorithms</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In FL, an ML model is learned iteratively by repeating the following steps: 1) The server chooses a set of users to compute an updated model; 2) Each client computes a locally trained model to update its local data; 3) Updates are transferred to the server; and 4) The server aggregates these local updates to construct a global model. The computation happens on the user’s devices and the central aggregator, while contact occurs between them <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. The goal of computation is the model preparation, and the communication usually aims to share model parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>. In this section, we present important FL algorithms (Table <a href="#S3.T4" title="TABLE IV ‣ FedML ‣ III-C Federated Learning Algorithms ‣ III Federated Learning Fundamentals ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>).</p>
</div>
<section id="S3.SS3.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">FedAvg</h4>

<div id="S3.SS3.SSSx1.p1" class="ltx_para">
<p id="S3.SS3.SSSx1.p1.1" class="ltx_p">Federated averaging (FedAvg) is a popular algorithm that uses an iterative averaging process to train the global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>. It divides the data into multiple non-overlapping subsets, and each client trains a local model on its subset. The local models are then sent to the server, and their parameters are averaged to create a new global model. This process is repeated for a fixed number of rounds until the global model converges. The steps of FedAvg are almost identical to traditional ML and deep learning (DL) techniques with a parameter-server and workers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">FedSGD</h4>

<div id="S3.SS3.SSSx2.p1" class="ltx_para">
<p id="S3.SS3.SSSx2.p1.1" class="ltx_p">The federated stochastic gradient descent is similar to FedAvg, devices use stochastic gradient descent to update models locally, and each device adjusts its learning rate, enabling better convergence for devices with different data distributions.</p>
</div>
</section>
<section id="S3.SS3.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">FedProx</h4>

<div id="S3.SS3.SSSx3.p1" class="ltx_para">
<p id="S3.SS3.SSSx3.p1.1" class="ltx_p">In heterogeneous networks, federated optimization incorporates a proximal term to link the local and global models, to minimize excessive drift during the optimization process. FedProx modifies the FedAvg algorithm by enabling partial work to be conducted across devices based on the underlying system restrictions and utilizing the proximal term to securely include the partial work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSSx4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">FedATT</h4>

<div id="S3.SS3.SSSx4.p1" class="ltx_para">
<p id="S3.SS3.SSSx4.p1.1" class="ltx_p">Attentive federated examines the relative significance of local models and aggregates them using a layer-wise soft attention mechanism between local and global models. This attentive aggregation method minimizes the weighted distance between the server and client models on non-IID datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSSx5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">SimFL</h4>

<div id="S3.SS3.SSSx5.p1" class="ltx_para">
<p id="S3.SS3.SSSx5.p1.1" class="ltx_p">Similarity-based FL (SimFL) represents an FL framework where no trusted server is needed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>. It includes four main steps:</p>
<ol id="S3.I4" class="ltx_enumerate">
<li id="S3.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I4.i1.p1" class="ltx_para">
<p id="S3.I4.i1.p1.1" class="ltx_p">The parties first update the gradients of their local data.</p>
</div>
</li>
<li id="S3.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I4.i2.p1" class="ltx_para">
<p id="S3.I4.i2.p1.1" class="ltx_p">The gradients are sent to a selected party.</p>
</div>
</li>
<li id="S3.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I4.i3.p1" class="ltx_para">
<p id="S3.I4.i3.p1.1" class="ltx_p">The selected party uses its local data and gradients to update the model.</p>
</div>
</li>
<li id="S3.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I4.i4.p1" class="ltx_para">
<p id="S3.I4.i4.p1.1" class="ltx_p">The model is sent to all the other parties.</p>
</div>
</li>
</ol>
<p id="S3.SS3.SSSx5.p1.2" class="ltx_p">To promote fairness and effectively leverage data from multiple parties, each participating party is chosen to update the model for a similar number of rounds and outputs the final model.</p>
</div>
<div id="S3.SS3.SSSx5.p2" class="ltx_para">
<p id="S3.SS3.SSSx5.p2.1" class="ltx_p">Various FL frameworks are designed to facilitate the implementation and management of the FL process. These frameworks provide tools, libraries, and APIs that enable developers to create and deploy FL algorithms:</p>
</div>
</section>
<section id="S3.SS3.SSSx6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">TFF</h4>

<div id="S3.SS3.SSSx6.p1" class="ltx_para">
<p id="S3.SS3.SSSx6.p1.1" class="ltx_p">The tensorflow federated is an open-source framework for ML and other computations on decentralized data. It has been developed to facilitate open research and experimentation with FL.</p>
</div>
</section>
<section id="S3.SS3.SSSx7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">PySyft</h4>

<div id="S3.SS3.SSSx7.p1" class="ltx_para">
<p id="S3.SS3.SSSx7.p1.1" class="ltx_p">A privacy-preserving FL framework built over PyTorch was introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>. The design relies on chains of tensors exchanged between local and remote workers.</p>
</div>
</section>
<section id="S3.SS3.SSSx8" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">LEAF</h4>

<div id="S3.SS3.SSSx8.p1" class="ltx_para">
<p id="S3.SS3.SSSx8.p1.1" class="ltx_p">LEAF was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>; it is a modular framework for learning in federated settings or ecosystems marked by massively distributed networks of devices.</p>
</div>
</section>
<section id="S3.SS3.SSSx9" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">Paddle FL</h4>

<div id="S3.SS3.SSSx9.p1" class="ltx_para">
<p id="S3.SS3.SSSx9.p1.1" class="ltx_p">An open-source framework designed mainly for industrial applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite> which effectively replicates several FL algorithms for large-scale distributed clusters.</p>
</div>
</section>
<section id="S3.SS3.SSSx10" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">FATE</h4>

<div id="S3.SS3.SSSx10.p1" class="ltx_para">
<p id="S3.SS3.SSSx10.p1.1" class="ltx_p">The federated AI technology enabler is an open-source platform that aims to create a safe computing environment for the federated AI ecosystem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSSx11" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">IBM FL</h4>

<div id="S3.SS3.SSSx11.p1" class="ltx_para">
<p id="S3.SS3.SSSx11.p1.1" class="ltx_p">A python-based FL framework proposed by IBM for enterprise environments, which provides an essential fabric for adding advanced features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSSx12" class="ltx_subsubsection">
<h4 class="ltx_title ltx_font_bold ltx_title_subsubsection">FedML</h4>

<div id="S3.SS3.SSSx12.p1" class="ltx_para">
<p id="S3.SS3.SSSx12.p1.1" class="ltx_p">An open research library proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> to support the development of FL algorithms and fair performance comparison. It offers three computing paradigms: edge device on-device training, distributed computing, and single-machine simulation.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<table id="S3.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T4.1.1.1" class="ltx_tr">
<th id="S3.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_ll ltx_border_r ltx_border_t"><span id="S3.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Algorithm</span></th>
<th id="S3.T4.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S3.T4.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.1.1.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S3.T4.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Benefits</span></span>
</span>
</th>
<th id="S3.T4.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_rr ltx_border_t">
<span id="S3.T4.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.1.1.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S3.T4.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Drawbacks</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T4.1.2.1" class="ltx_tr">
<th id="S3.T4.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t"><span id="S3.T4.1.2.1.1.1" class="ltx_text ltx_font_bold">FedAvg</span></th>
<td id="S3.T4.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.2.1.2.1.1" class="ltx_p" style="width:142.3pt;">- Simplicity</span>
<span id="S3.T4.1.2.1.2.1.2" class="ltx_p">- Communication-efficiency</span>
<span id="S3.T4.1.2.1.2.1.3" class="ltx_p">- Privacy-preserving</span>
</span>
</td>
<td id="S3.T4.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t">
<span id="S3.T4.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.2.1.3.1.1" class="ltx_p" style="width:142.3pt;">- Slow convergence speed</span>
<span id="S3.T4.1.2.1.3.1.2" class="ltx_p">- Privacy risks</span>
<span id="S3.T4.1.2.1.3.1.3" class="ltx_p">- Data heterogeneity</span>
</span>
</td>
</tr>
<tr id="S3.T4.1.3.2" class="ltx_tr">
<th id="S3.T4.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t"><span id="S3.T4.1.3.2.1.1" class="ltx_text ltx_font_bold">FedSGD</span></th>
<td id="S3.T4.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.3.2.2.1.1" class="ltx_p" style="width:142.3pt;">- High convergence speed</span>
<span id="S3.T4.1.3.2.2.1.2" class="ltx_p">- Handling data heterogeneity</span>
<span id="S3.T4.1.3.2.2.1.3" class="ltx_p">- Localized Adaptation</span>
</span>
</td>
<td id="S3.T4.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t">
<span id="S3.T4.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.3.2.3.1.1" class="ltx_p" style="width:142.3pt;">- Hyper-parameter complexity</span>
<span id="S3.T4.1.3.2.3.1.2" class="ltx_p">- Communication overhead</span>
<span id="S3.T4.1.3.2.3.1.3" class="ltx_p">- Impact of imbalanced data</span>
</span>
</td>
</tr>
<tr id="S3.T4.1.4.3" class="ltx_tr">
<th id="S3.T4.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t"><span id="S3.T4.1.4.3.1.1" class="ltx_text ltx_font_bold">FedProx</span></th>
<td id="S3.T4.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.4.3.2.1.1" class="ltx_p" style="width:142.3pt;">- High convergence speed</span>
<span id="S3.T4.1.4.3.2.1.2" class="ltx_p">- Handling non-IID data</span>
<span id="S3.T4.1.4.3.2.1.3" class="ltx_p">- Regularization</span>
</span>
</td>
<td id="S3.T4.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t">
<span id="S3.T4.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.4.3.3.1.1" class="ltx_p" style="width:142.3pt;">- Hyper-parameter tuning</span>
<span id="S3.T4.1.4.3.3.1.2" class="ltx_p">- Increased communication overhead</span>
<span id="S3.T4.1.4.3.3.1.3" class="ltx_p">- Centralized aggregator</span>
</span>
</td>
</tr>
<tr id="S3.T4.1.5.4" class="ltx_tr">
<th id="S3.T4.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t"><span id="S3.T4.1.5.4.1.1" class="ltx_text ltx_font_bold">FedATT</span></th>
<td id="S3.T4.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T4.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.5.4.2.1.1" class="ltx_p" style="width:142.3pt;">- Fast learning</span>
<span id="S3.T4.1.5.4.2.1.2" class="ltx_p">- Communication efficiency</span>
<span id="S3.T4.1.5.4.2.1.3" class="ltx_p">- Handling non-IID data</span>
</span>
</td>
<td id="S3.T4.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t">
<span id="S3.T4.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.5.4.3.1.1" class="ltx_p" style="width:142.3pt;">- Privacy risks</span>
<span id="S3.T4.1.5.4.3.1.2" class="ltx_p">- Data heterogeneity</span>
</span>
</td>
</tr>
<tr id="S3.T4.1.6.5" class="ltx_tr">
<th id="S3.T4.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_ll ltx_border_r ltx_border_t"><span id="S3.T4.1.6.5.1.1" class="ltx_text ltx_font_bold">SimFL</span></th>
<td id="S3.T4.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T4.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.6.5.2.1.1" class="ltx_p" style="width:142.3pt;">- Good accuracy</span>
<span id="S3.T4.1.6.5.2.1.2" class="ltx_p">- Fast computation</span>
<span id="S3.T4.1.6.5.2.1.3" class="ltx_p">- Security</span>
</span>
</td>
<td id="S3.T4.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_rr ltx_border_t">
<span id="S3.T4.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.1.6.5.3.1.1" class="ltx_p" style="width:142.3pt;">- Communication overhead</span>
<span id="S3.T4.1.6.5.3.1.2" class="ltx_p">- Impact of imbalanced data</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>FL algorithms: benefits and drawbacks.</figcaption>
</figure>
<div id="S3.SS3.SSSx12.p2" class="ltx_para">
<p id="S3.SS3.SSSx12.p2.1" class="ltx_p">In this section, we provided a taxonomy of the essentials of FL, including a concise definition of FL, its various categories, and the associated algorithms. Moving forward, we will delve into FL applications and explore how they are leveraged to enhance the capabilities of the 5G and 6G mobile generations.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning at PHY/MAC layers</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">With the promising performance of ML in wireless communication <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, there has been a surge in the area of ML for the wireless physical layer e.g., see <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. FL is more communication efficient and privacy-preserving than traditional ML and, thus, it has a promising potential for addressing problems at the lowest layers of the OSI model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. This section provides an overview of recent advancements in FL-based physical layer architecture, including symbol and signal detection, channel estimation, channel state information, beamforming, reconfigurable intelligent surfaces, channel access, and spectrum sharing.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Symbol/Signal Detection</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The receiver in a digital communication system must correctly identify the transmitted symbols from the observed channel output. This task is known as symbol detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>. The key benefit of using ML and DL techniques for symbol detection is to provide a data-driven mapping for modeling channel characteristics that model-based techniques do not effectively manage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>. In addition, since the model is directly fed with the obtained corrupted symbols, end-to-end learning allows the model to detect the symbols correctly without a channel estimation stage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>. Using centralized learning for this role introduces high communication overhead and privacy issues, as well as limitations related to storing and transmitting a large amount of data.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">To overcome these challenges, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> designed an FL-based receiver (FedRec) for symbol detection in downlink fading channels, designed to learn its mappings from a limited number of pilots. This approach takes advantage of this intuition by enabling users to collaborate for training through FL, which allows a single neural network to be trained over a diverse data set without additional pilots. Despite the need for numerous iterations of parameter exchanges with the base station (BS), FedRec yields an efficient symbol detector that achieves performance levels close to a MAP detector. This outperforms the model-based solution, especially when faced with inaccurate knowledge of the fading distribution. Furthermore, FedRec induces substantially less communication overhead than learning a neural network (NN) based symbol detector in a centralized scheme. FedRec facilitates utilizing compact NNs by avoiding feature extraction layers, which are trainable using relatively small datasets. While each local training data set encapsulates a relatively small number of fading channel realizations, the diversity among these data sets at different devices is exploited to obtain a unified model for all the devices by training in a federated manner.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">The advantage of FL is recognizing signal modulation while protecting private data. As such, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>, instead of transmitting the raw data between the central server and all devices, only the convolutional NN (CNN) model updates are shared. The results show that the designed approach has reached more than 70% recognition rate while satisfying privacy protection and data security.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite> presented an FL framework for automatic modulation classification named FedeAMC; under conditions of class imbalance and noise varying, data and training are in each local client, while only knowledge is shared with the server. The FL process contains six main steps: model and parameters choosing and broadcasting, local gradient calculation, key information uploading, key information aggregation, aggregated information downloading, and finally local model updating. The proposed approach achieves a low risk of data leakage without severe performance loss.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Channel Estimation</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In wireless communication, there are some undesirable effects on the signals transmitted over the wireless channel caused by the physical properties of the channel. As a result, the signals arriving at the receiver end of the communication system are always attenuated, distorted, delayed, and phase-shifted <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>. Consequently, there is a need to provide a perfect and up-to-date estimation of the channel to compensate for these effects, and accurate signal demodulation, equalization, and decoding at the receiver end of the systems. Channel estimation through ML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> requires model training on a data set in a centralized manner, which typically includes received pilot signals as input and channel data as output <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>. However, this method generates significant transmission overhead when collecting user data. To deal with this problem, FL was considered in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> to enhance the performance of channel estimation; instead of sending the entire dataset, only the model updates are transmitted between clients and server, which maintains good channel estimation and reduces the estimation error, as well as the transmission overhead that approximately 16 times lower than central learning. The authors designed a convolutional neural network at the BS and trained on the local data sets. The proposed approach has three stages:</p>
<ol id="S4.I1" class="ltx_enumerate">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><em id="S4.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">Data collection:</em> Each user creates its local training dataset, which contains the input (signals pilot) and output (channel matrix) for model training.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><em id="S4.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">Training:</em> Each user works with its local dataset, computes model changes and sends them to the BS, where they are aggregated to train a global model.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><em id="S4.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">Prediction:</em> Each user will estimate its local channel by simply feeding the obtained pilot data into the trained model.</p>
</div>
</li>
</ol>
<p id="S4.SS2.p1.2" class="ltx_p">The fact that each client has access to the qualified model for channel estimation is a significant benefit of this method.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite> used FL to create a channel prediction scheme to achieve channel pre-compensation for a low-cost free-space optical communication system. The proposed approach is effective in simplifying system structural and operational costs.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Channel State Information</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">To reap the full benefits of the reconfigurable intelligent surfaces (RIS) architecture. All efficient technologies must rely on the perfect channel state information (CSI) between the BS and the RIS and the perfect CSI between the RIS and users <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>. However, it is infeasible for RIS-enhanced systems to estimate correct CSI when radio frequency (RF) sensors or chains are not installed on the RIS. Therefore, employing FL for CSI detection in RIS-assisted wireless communications makes sense. In fact, for some small cellular BSs, a small amount of training data is not sufficient to produce a generalized model for CSI prediction. Centralized learning techniques combine all the data for processing and training, which results in communication overhead <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite> introduced a decentralized approach to overcome these challenges. They proposed an FL-based framework for CSI prediction using three-dimensional convolutional neural networks. The global model is trained at macro BSs (MBs), by gathering all local datasets from the edge BSs. To deal with the performance gap between CL and FL, they designed the federated weights and gradients (FED-WG) algorithm, which works as follows:</p>
<ol id="S4.I2" class="ltx_enumerate">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p">The MBs get the relevant local model weights and gradients from the BSs.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p">FED-WG executes two consecutive rounds of parameter updates for the global model.</p>
</div>
</li>
</ol>
<p id="S4.SS3.p2.2" class="ltx_p">The suggested FED-WG framework effectively narrows the performance gap between FL and CL, while significantly reducing the transmission overheads.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">The general process of FL approaches typically assumes perfect knowledge of the CSI during the training phase, which is challenging for fast-fading channels. In addition, the literature uses a fixed number of clients to participate in the federated model’s training. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite> tried to fill these gaps by proposing an FL approach where all clients use a constant global rate to complete training rounds. This consistently results in faster convergence, even when the CSI is imperfect.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Beamforming</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Beamforming and massive multiple input multiple outputs (MIMO) systems aim to adapt the radiation pattern of an antenna array to particular scenarios. These technologies are a crucial part of 5G and 6G new radio (e.g., see <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>). Using a centralized learning scheme for hybrid beamforming has been widely studied. Incorporating FL into beamforming and massive MIMO systems holds the potential to enhance network efficiency, robustness, and scalability. As 5G and 6G technologies continue to evolve, integrating advanced learning techniques plays a pivotal role in shaping the future of wireless communication.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite> provide an FL-based framework to map the millimeter wave (mmWave) channels into analog beamformers in a multi-user downlink network. They built a CNN architecture at the BS, where the model is trained on the edge using only the gradients provided by the different users. The approach of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite> proceeds as follows:</p>
<ol id="S4.I3" class="ltx_enumerate">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.1" class="ltx_p">The CNN model takes the channel matrix as input and the RF beamformer as output. The deep neural network is then trained by using the gradient data collected from the users.</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.1" class="ltx_p">Each user computes the gradient information with its available training data (a pair of channel matrices and corresponding beamformer index) and then sends it to the BS.</p>
</div>
</li>
<li id="S4.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S4.I3.i3.p1" class="ltx_para">
<p id="S4.I3.i3.p1.1" class="ltx_p">The BS receives all the gradient data from the users and performs the parameter updates for the CNN model which is comprised of 11 layers with two convolutional layers and a single fully connected layer. As a result, the beamformer indices are the CNN’s output.</p>
</div>
</li>
</ol>
<p id="S4.SS4.p2.2" class="ltx_p">FL strategy for hybrid beamforming provides more robust beamforming performance while exhibiting much less transmission overhead.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">This framework requires the mmWave channel matrices as inputs, which is challenging to estimate and requires more significant training overheads. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite> suggested a beamforming scheme relies only on the channel state estimation at sub-6GHz, which is considerably more accessible with current technologies compared to mmWave channel estimation. The authors aim to predict the mmWave beamforming vectors exploiting sub-6GHz channels for a network composed of multiple access point–user links, where the deep neural network accepts the sub-6GHz channels as input and outputs directly the corresponding mmWave beamforming vector. Moreover, the authors suggest a distributed FL scheme to predict the beamforming vectors locally at each user without uploading the local data to a central server. There are three main benefits of this framework:</p>
<ul id="S4.I4" class="ltx_itemize">
<li id="S4.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i1.p1" class="ltx_para">
<p id="S4.I4.i1.p1.1" class="ltx_p">The computation load is distributed to the edge of the network as opposed to a centralized cloud-based approach;</p>
</div>
</li>
<li id="S4.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i2.p1" class="ltx_para">
<p id="S4.I4.i2.p1.1" class="ltx_p">Users only share their neural network parameters and not their data, which highly reduces the signaling load, and protects the data of the individual users;</p>
</div>
</li>
<li id="S4.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i3.p1" class="ltx_para">
<p id="S4.I4.i3.p1.1" class="ltx_p">Users still share their acquired knowledge of the environment to improve the quality of their predictions.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p">mmWave-MIMO communication systems substantially improve the throughput in 5G networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>. However, these solutions reduce the multiplexing gain in the case of a small number of RF chains. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> introduced spatial path index modulation (SPIM), a technique for improving gain using other signal bits modulated by spatial path indices. The authors proposed model-based and model-free frameworks for beamformer design in multi-user SPIM-MIMO systems; they first designed the beamformers via a model-based manifold optimization algorithm. Then, the authors train a CNN model on the local dataset using FL and dropout learning to mitigate overfitting. The model updates are then gathered at the BS for aggregation and then sent back to the users for the prediction phase, where the model estimates beamformers by feeding them their channel data. The advantages of utilizing dropout learning in FL include:</p>
<ol id="S4.I5" class="ltx_enumerate">
<li id="S4.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">A</span> 
<div id="S4.I5.i1.p1" class="ltx_para">
<p id="S4.I5.i1.p1.1" class="ltx_p">Achieving approximately 10 times lower overhead than centralized learning.</p>
</div>
</li>
<li id="S4.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">B</span> 
<div id="S4.I5.i2.p1" class="ltx_para">
<p id="S4.I5.i2.p1.1" class="ltx_p">Reducing the communication cost during training.</p>
</div>
</li>
<li id="S4.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">C</span> 
<div id="S4.I5.i3.p1" class="ltx_para">
<p id="S4.I5.i3.p1.1" class="ltx_p">Achieving superior spectral efficiency compared to model-based SPIM and conventional mmWave-MIMO.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.4.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.5.2" class="ltx_text ltx_font_italic">Reconfigurable Intelligent Surfaces</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Reconfigurable Intelligent Surfaces (RIS) have emerged as a strong contender in comparison to massive MIMO. This technology has garnered notable research interest <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, particularly in harnessing recent Machine Learning techniques, especially FL, to enable reconfigurable propagation settings in wireless communication capabilities. The integration of RIS enhances the beamforming gain in uplink communications within a massive MIMO system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>. Nonetheless, this approach introduces several challenges such as ignoring user privacy and producing high communication overhead.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">To overcome these challenges, the study outlined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite> introduced an FL-driven beamformer design tailored for an IRS-assisted scenario. This entails an algorithm referred to as ”optimal beam reflection based on FL” aiming to enhance high-speed communication with sparse channel state information (CSI) by improving the data rate and protecting privacy. The standard FL algorithm is adopted to train a regression multi-layer perceptron with model transmission; the proposed framework effectively reaches a theoretical value that exceeds 90% of what is achieved by centralized Machine Learning, all while ensuring user privacy protection. Nevertheless, the RIS-user link is the only channel that is designed, while the BS-RIS link is supposed to be constant. However, in a practical case, the mm-Wave channel tends to be highly complex and characterized by a limited channel length, largely owing to environmental fluctuations. Hence, the solution of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> estimates both direct (BS-user) and cascaded (BS-IRS-user) channels in an RIS-assisted scenario, where input and output data are combined for each communication link only a single CNN architecture is designed instead of different NNs.</p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.1" class="ltx_p">A privacy-preserving paradigm combining FL with RIS in the mmWave communication systems is designed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>. First, the private data handled on each local device trains and encrypts the local models. Then, at the central server, a global model is created by aggregating them. While ensuring user data confidentiality, the suggested technique successfully approaches theoretical value and achieves greater than 95% of that created by centralized ML.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS6.4.1.1" class="ltx_text">IV-F</span> </span><span id="S4.SS6.5.2" class="ltx_text ltx_font_italic">Channel Access</span>
</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">ML and DL techniques have significantly enhanced the design of the MAC layer and have also contributed to the improvement of channel access performance by automating the tuning of protocol parameters and the evaluation of networking protocols. These advancements address critical issues related to the limited power of wireless devices and privacy concerns <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>, <a href="#bib.bib118" title="" class="ltx_ref">118</a>, <a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>. FL has garnered considerable interest due to its inherent parallelization capabilities and its potential for greater efficiency compared to centralized methods in terms of storage and privacy.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite> proposed an alternative analog communication approach in which the devices transmit their local gradient estimates directly over the wireless channel. The learning process is motivated by an FL strategy where devices have their local datasets. They communicate with the parameter server over a wireless MAC. Here, the parameter server is not interested in the individual gradient vectors but in their average, and the wireless MAC automatically provides the server with the sum of the gradients.</p>
</div>
<div id="S4.SS6.p3" class="ltx_para">
<p id="S4.SS6.p3.1" class="ltx_p">Non-orthogonal multiple access (NOMA) technology is considered a building block for 5G and beyond networks. The study discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite> investigates the organization of machine-type devices (MTD) into clusters for NOMA-based systems. Focusing on resource allocation, the authors put forth an approach involving traffic model estimation through FL. In this method, the MTD autonomously estimates its traffic model parameters and transmits them to the BS, which subsequently aggregates the traffic model, allocates the suitable resource blocks, and transmits power to each MTD.</p>
</div>
<div id="S4.SS6.p4" class="ltx_para">
<p id="S4.SS6.p4.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite> proposed a NOMA-enhanced wireless network model to offer NOMA desired channel conditions and increase consumer quality by adopting the FL concept to enable multiple agents to simultaneously explore similar environments and exchange experiences.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_ll ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S4.T5.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref</span></th>
<th id="S4.T5.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S4.T5.1.1.1.2.1" class="ltx_text ltx_font_bold">Application</span></th>
<th id="S4.T5.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.1.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T5.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Benefits</span></span>
</span>
</th>
<th id="S4.T5.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_rr ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.1.4.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T5.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Drawbacks</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.2.1" class="ltx_tr">
<th id="S4.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>, <a href="#bib.bib98" title="" class="ltx_ref">98</a>, <a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite></th>
<th id="S4.T5.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Symbol / Signal Detection</th>
<td id="S4.T5.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.2.1.3.1.1" class="ltx_p" style="width:142.3pt;">Learning collaboratively to clear the received symbols, without the need for channel estimation stage or gathering raw data</span>
</span>
</td>
<td id="S4.T5.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.2.1.4.1.1" class="ltx_p" style="width:142.3pt;">Need deep ML models for better performance</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.3.2" class="ltx_tr">
<th id="S4.T5.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>, <a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite></th>
<th id="S4.T5.1.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Channel Estimation</th>
<td id="S4.T5.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.2.3.1.1" class="ltx_p" style="width:142.3pt;">Ability of each user to estimate its channel with less transmission overhead</span>
</span>
</td>
<td id="S4.T5.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.2.4.1.1" class="ltx_p" style="width:142.3pt;">Heavy computation resources
due to the labeling phase of the channel data</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.4.3" class="ltx_tr">
<th id="S4.T5.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>, <a href="#bib.bib111" title="" class="ltx_ref">111</a>, <a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite></th>
<th id="S4.T5.1.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Beamforming</th>
<td id="S4.T5.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.3.3.1.1" class="ltx_p" style="width:142.3pt;">Dynamic beamforming and antenna configurations for optimal signal transmission, improving coverage and reducing interference</span>
</span>
</td>
<td id="S4.T5.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.3.4.1.1" class="ltx_p" style="width:142.3pt;">Sub-optimum performance and complex labeling</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.5.4" class="ltx_tr">
<th id="S4.T5.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>, <a href="#bib.bib103" title="" class="ltx_ref">103</a>, <a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite></th>
<th id="S4.T5.1.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">RIS</th>
<td id="S4.T5.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.4.3.1.1" class="ltx_p" style="width:142.3pt;">Achieving high speed convergence in high dimension and complex environment</span>
</span>
</td>
<td id="S4.T5.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.4.4.1.1" class="ltx_p" style="width:142.3pt;">Only RIS beamforming is performed</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.6.5" class="ltx_tr">
<th id="S4.T5.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>, <a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite></th>
<th id="S4.T5.1.6.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">CSI prediction</th>
<td id="S4.T5.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.5.3.1.1" class="ltx_p" style="width:142.3pt;">Estimating the accurate CSI when the RF chains or sensors are not equipped on the RIS while preserving users’ privacy</span>
</span>
</td>
<td id="S4.T5.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.5.4.1.1" class="ltx_p" style="width:142.3pt;">Need to maximize the training performance and the heterogeneous data should be taken into consideration</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.7.6" class="ltx_tr">
<th id="S4.T5.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>, <a href="#bib.bib121" title="" class="ltx_ref">121</a>, <a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite></th>
<th id="S4.T5.1.7.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Channel Access</th>
<td id="S4.T5.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.7.6.3.1.1" class="ltx_p" style="width:142.3pt;">Tuning automatically individual protocol parameters while improving the convergence speed and communication delay</span>
</span>
</td>
<td id="S4.T5.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.7.6.4.1.1" class="ltx_p" style="width:142.3pt;">The impact of CSI estimation error on the performance needs to be studied.</span>
</span>
</td>
</tr>
<tr id="S4.T5.1.8.7" class="ltx_tr">
<th id="S4.T5.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite></th>
<th id="S4.T5.1.8.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Spectrum Sharing</th>
<td id="S4.T5.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.7.3.1.1" class="ltx_p" style="width:142.3pt;">Improving spectrum sharing efficiency by learning in a distributed way from local information, without requiring the entire data</span>
</span>
</td>
<td id="S4.T5.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.8.7.4.1.1" class="ltx_p" style="width:142.3pt;">Need to collect more real data to analyze the true potential of FL in spectrum sharing</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V: </span>Summary of FL-based contributions at PHY/MAC layers.</figcaption>
</figure>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS7.4.1.1" class="ltx_text">IV-G</span> </span><span id="S4.SS7.5.2" class="ltx_text ltx_font_italic">Spectrum Sharing</span>
</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p">Spectrum efficiency is one of the key performance metrics in 5G communication networks and even beyond <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>. Advanced spectrum-sharing techniques, such as ML and DL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite>, are generally used to deal with typical challenges while enhancing efficiency. However, deploying ML techniques for spectrum applications faces the challenges of limited dataset resources, as well as privacy concerns. Thus, FL scheme handles privacy challenges while achieving interesting results compared to centralized learning.</p>
</div>
<div id="S4.SS7.p2" class="ltx_para">
<p id="S4.SS7.p2.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>, the authors proposed an ML-based non-coherent spectrum sensing system named FaIR, which leverages a communication-efficient distributed learning framework, FL, for environmental sensors to collaborate and train a data-driven ML model for incumbent detection under minimal communication bandwidth. The preliminary results show that state-of-the-art spectrum classification algorithms in an FL environment perform better than traditional techniques.</p>
</div>
<div id="S4.SS7.p3" class="ltx_para">
<p id="S4.SS7.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>, the authors investigated the spectrum sharing problem in high-mobility vehicular networks by adopting the FTL method. They start by modeling resource sharing as a multi-agent reinforcement learning problem, which is then solved using a fingerprint-based deep Q-network method that is amenable to a distributed implementation. The results show that with a well-designed reward system and training process, the vehicle-to-vehicle transmitters learn from their interactions with the communication environment. The authors developed an effective strategy to collaborate in a distributed manner, thereby optimizing system-level performance using local information.</p>
</div>
</section>
<section id="S4.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS8.4.1.1" class="ltx_text">IV-H</span> </span><span id="S4.SS8.5.2" class="ltx_text ltx_font_italic">Summary</span>
</h3>

<div id="S4.SS8.p1" class="ltx_para">
<p id="S4.SS8.p1.1" class="ltx_p">In this section, we have investigated the existing FL-based schemes that improve communication quality and key performance indicators (KPIs) for physical and MAC layers in wireless communication systems.
The following are the lessons learned from this section :</p>
<ul id="S4.I6" class="ltx_itemize">
<li id="S4.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i1.p1" class="ltx_para">
<p id="S4.I6.i1.p1.1" class="ltx_p">The integration of FL at the PHY and the MAC layers leverages the unique capabilities of FL to optimize wireless communication processes, enhancing efficiency, reliability, and performance.</p>
</div>
</li>
<li id="S4.I6.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i2.p1" class="ltx_para">
<p id="S4.I6.i2.p1.1" class="ltx_p">FL represents a novel approach that redefines how wireless networks operate at the most fundamental level such as signal detection, channel estimation, beamforming, RIS optimization, channel access, and spectrum sharing while presenting certain drawbacks such as model/data/hardware complexity, communication efficiency, and learning accuracy.</p>
</div>
</li>
</ul>
<p id="S4.SS8.p1.2" class="ltx_p">Table <a href="#S4.T5" title="TABLE V ‣ IV-F Channel Access ‣ IV Federated Learning at PHY/MAC layers ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> illustrates a summary of the main contributions and their respective benefits and drawbacks.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning at NET Layer</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The use of FL in the network layer offers a privacy-preserving, efficient, and scalable approach to ML. It addresses the challenges posed by distributed and sensitive data, while also catering to the low-latency and fault-tolerant requirements of networked systems. It is applied in several tasks, such as resource management, user behavior prediction, network slicing, routing optimization, and cloud computing, among others, as detailed next.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Traffic Classification</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Traffic classification (TC) has received increasing attention in recent years. It aims to offer the ability to automatically recognize the application that has generated a given stream of packets from the direct and passive observation of the individual packets flowing in the network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite>. Due to the achievement of FL in data privacy protection, it is applied even in internet traffic classification to improve the accuracy of packet transmission while preserving private data.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">The work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite> proposed an FL-based traffic classification framework named FLIC that classifies new applications on the fly when a client joins the learning process with a new application. The designed protocol achieves an accuracy comparable to the centralized scheme for identifying internet applications with a privacy guarantee.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite> built a cross-silo horizontal federated model for TC using flow-based time-related features. The proposed FL framework performs comparably to a centralized DL model for internet application identification without privacy leakage.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib130" title="" class="ltx_ref">130</a>]</cite>, a novel approach using federated semi-supervised learning for network traffic classification was designed. The federated servers and several clients work together to train a global classification model, where unlabeled data is used on the client, and labeled data is used on the server. Results show that this method protects users’ privacy without sharing a large amount of labeled data as well as achieving good accuracy.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">Resource Management</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Power and resource allocation remain critical wireless challenges due to the need for more resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite>. Optimizing a multi-cell network spectral efficiency and connectivity invariably results in non-convex resource allocation issues, which are frequently handled using basic methods such as successive convex approximation and matching theory. To address the high complexity and impracticality of traditional approaches, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> used ML algorithms to solve resource optimization of problems related to mobile edge computing (MEC). However, sending all local information to a central controller in MEC-enabled high-altitude balloon (HAB) networks is impracticable since the transmission of local datasets results in substantial energy usage. To this end, FL allows dispersed devices to cooperatively train an ML model by sharing trained parameters with other devices instead of sending a huge dataset.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite> solved this problem using a support vector machine (SVM) based FL to determine the user association proactively. The proposed method enables each HAB to cooperatively build an SVM model to determine all user associations without transmitting computational tasks or user historical associations to other HABs. The SVM model analyzes the relationship between the future user association and the data size of the task that each user needs to process at the current time slot to determine the user association proactively. Given the prediction of the optimal user association, each user’s service sequence and task allocation are optimized to minimize the weighted sum of the energy and time consumption. This approach reduces the weighted sum of the energy and time consumption of all users by up to 16.1% compared to a conventional centralized method.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite>, the authors investigated distributed power allocation for edge users in decentralized wireless networks. The proposed model (FL-CA) aims to minimize power consumption while satisfying the user quality of service (QoS) requirement and protecting user privacy. In the FL framework, edge devices locally make decisions on power allocation by training a local actor-critic model and then send the gradients and weight ages generated by the actor-network to the BS for information aggregation at regular intervals. Moreover, the authors adopt the federated augmentation algorithm which uses the Wasserstein generative adversarial network (WGAN) for data augmentation to overcome the over-fitting problem caused by data leakages. The algorithm empowers each device to replenish the data buffer using a generative model of WGANs until reaching an i.i.d training dataset, which reduces the communication overhead compared to direct data sample exchanges.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>]</cite>, the authors proposed a federated reinforcement learning (FRL) based channel resource allocation framework for ultra-dense 5G and B5G wireless networks and suggested collaborative learning estimates for faster learning convergence. The results demonstrate that the designed FRL model is superior to non-federated reinforcement learning.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.4.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.5.2" class="ltx_text ltx_font_italic">Radio Access Network</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">The radio access network (RAN) is a fundamental part of a mobile telecommunication system where user data is sensitive and subject to strict privacy regulations. Centralized ML approaches raise privacy concerns due to data aggregation. FL allows local model training on devices without sharing raw data, preserving user privacy while enabling collective model updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>, <a href="#bib.bib138" title="" class="ltx_ref">138</a>, <a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite>.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Deep reinforcement learning was discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite> and associated challenges in a multi-mobile virtual network operators (MVNOs) environment. The authors designed a federated deep reinforcement learning mechanism on an O-RAN architecture to improve the radio resource allocation operation of MVNOs and illustrate through extensive simulations that the proposed RAN slicing mechanism enables a better allocation of the needed radio resources to satisfy users’ QoS requirements in terms of delay and data rate.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite> proposed a novel FL-based mobility and demand-aware proactive content offloading (MDPCO) framework that exploits distributed learning strategies and capitalizes on users’ mobility and demand information for proactive content offloading. The efficacy of MDCPO improves performance against local and cloud-based models.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para">
<p id="S5.SS3.p4.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite> designed a federated deep reinforcement learning algorithm to coordinate multiple independent xAPPs in O-RAN for network slicing by developing two xAPPs, namely a power control xAPP and a slice-based resource allocation xAPP to enhance learning efficiency and improve network performance.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.4.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.5.2" class="ltx_text ltx_font_italic">User Mobility/Location Prediction</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">Due to the varied quality-of-service requirements, user behavior and wireless network performance have become crucial for developing and evaluating new applications and service opportunities. FL strategy is promising in several situations to predict users’ behavior and maximize the quality of experience (QoE). Based on the mobility predictions, we provide more information about the network, the users dynamically choose a subchannel to upload data in the uplink, the BS dynamically allocates multiple subchannels to multiple users in the downlink, and multiple users who occupy the same subchannel perform NOMA or full-duplex. Due to the privacy-sensitive nature of user activities, existing location prediction approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>, <a href="#bib.bib144" title="" class="ltx_ref">144</a>, <a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite> rely on centralized storage of user mobility data for model training, which raises privacy concerns and risks. FL has the potential to enable predictive features on smartphones without diminishing the QoE or leaking private information.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite> presented an adaptive FL model as a decentralized method for mobility prediction. They combined a personalized FL model with an attention network to predict user location in a protected way. This approach leverages the useful information in the behaviors of massive users to train accurate mobility prediction models and, meanwhile, remove the need for centralized storage.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.1" class="ltx_p">Another interesting work on human trajectory prediction using FL is presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite>. The authors proposed a privacy-preserving human mobility prediction framework to achieve promising prediction performance while preserving personal data on local devices. Based on the DL mobility model, no private data is uploaded to the centralized server. The only uploaded thing is the updated model parameters which are difficult to crack and thus more secure.</p>
</div>
<div id="S5.SS4.p4" class="ltx_para">
<p id="S5.SS4.p4.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite> demonstrated that FL for human activity recognition tasks produces models with slightly worse, but acceptable accuracy than centralized techniques. Recently, it has been used in several works and in proactive HO mm-wave vehicular networks to protect user position information, reduce communication overhead, and reduce frequency. The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib149" title="" class="ltx_ref">149</a>]</cite> proposed a hierarchical personalized FL (HPFL) approach as a novel client-server architecture framework to serve FL in user modeling with inconsistent clients. Traditional FL indiscriminately aggregates and updates the consistent whole user models, but HPFL attempts to divide and process the different components of the heterogeneous models independently.</p>
</div>
<div id="S5.SS4.p5" class="ltx_para">
<p id="S5.SS4.p5.1" class="ltx_p">Location information is a service enabler for communication network design, operations, and optimization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite>. FedLoc is a new collaborative positioning and location data processing framework proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite>. This approach properly resolves the question of privacy in target localization and location data processing in collaboration with many mobile users. The federated approach is promising thanks to its significant advantages:</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">Efficiency in handling the data privacy issue, allowing mobile users to exchange location-related information safely.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">Collaboration among mobile users facilitates the calibration effort.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">Cell phones are becoming capable platforms for performing complex calculations.</p>
</div>
</li>
</ul>
</div>
<div id="S5.SS4.p6" class="ltx_para">
<p id="S5.SS4.p6.1" class="ltx_p">The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite> presented another FL-based approach to improve the accuracy of received signal strength fingerprint-based localization while protecting the privacy of the crowdsourcing participants. The main idea of this novel method is to keep local data where it is generated and convey only local models throughout the learning process. When employed as a booster for centralized learning, the suggested approach enhanced localization accuracy by 1.8 meters and reached satisfactory localization accuracy when used alone.</p>
</div>
<div id="S5.SS4.p7" class="ltx_para">
<p id="S5.SS4.p7.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite> used FL for human activity recognition (HAR) allowing each user to handle his activity recognition task safely and collectively. They designed a perceptive extraction network as the feature extractor for each user to capture enough features from HAR data. PEN comprised of a featured network to discover local features and a relation network, a combination of long short-term memory (LSTM) and attention mechanism, which is in charge of mining global relationships hidden in the data.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS5.4.1.1" class="ltx_text">V-E</span> </span><span id="S5.SS5.5.2" class="ltx_text ltx_font_italic">Network Slicing</span>
</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">Network slicing enables the shift from a network as an infrastructure configuration to a network as a service to support a wide range of 5G and 6G smart services with several requirements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib155" title="" class="ltx_ref">155</a>]</cite>. By integrating FL into network slicing, telecommunication providers and service operators unlock the potential of personalized services while maintaining data privacy and network performance. As the demand for customizable and secure services grows <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>]</cite>, the combination of FL and network slicing is likely to play a significant role in the future of telecommunications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib157" title="" class="ltx_ref">157</a>]</cite>.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite> proposed integrating an FL framework with mobile edge systems to train double-deep Q-learning agents at the network edge for caching and computational offloading decisions while protecting user privacy. The “In-Edge AI” was assessed and shown the capacity to achieve near-optimal performance with a reasonably minimal learning overhead, while the system is cognitive and adaptive to mobile communication networks.</p>
</div>
<div id="S5.SS5.p3" class="ltx_para">
<p id="S5.SS5.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib159" title="" class="ltx_ref">159</a>]</cite>, the authors developed an FL-based approach to enhance resource allocation strategy in multi-industrial IoT. This novel proposal deep federated Q-learning, involves IoT slices’ resource allocation in terms of transmission power and spreading factor according to the slices QoS’ requirements.</p>
</div>
<div id="S5.SS5.p4" class="ltx_para">
<p id="S5.SS5.p4.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib160" title="" class="ltx_ref">160</a>]</cite> adopted FL to predict slices’ service-oriented KPIs by keeping raw data where it is generated and sending only users’ local models to the centralized entity for aggregation. The obtained results showed the efficiency of the designed approach in reaching good prediction accuracy while ensuring privacy issues.</p>
</div>
<div id="S5.SS5.p5" class="ltx_para">
<p id="S5.SS5.p5.1" class="ltx_p">Aiming to improve network throughput while reducing hand-off cost, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite> designed an efficient device association scheme for RAN slicing by exploiting a hybrid FRL framework. Two levels of aggregation were proposed for the device association problem. One involves the same type of services to aggregate the local parameter models to share similar samples. The other one pertains to the different types of services to aggregate access features to make an optimal global decision on network slicing and BS selection.</p>
</div>
<div id="S5.SS5.p6" class="ltx_para">
<p id="S5.SS5.p6.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>]</cite> investigated the distributed network slicing for 5G. They introduced a novel framework centered around a federated orchestrator in the control plane. This entity is responsible for coordinating spectrum and computational resources, all without requiring any exchange of personal data or resource information from the local BS. This framework significantly reduces service response time for both supported services, especially compared to network slicing with only a single resource.</p>
</div>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS6.4.1.1" class="ltx_text">V-F</span> </span><span id="S5.SS6.5.2" class="ltx_text ltx_font_italic">Routing Optimization</span>
</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">Predictive routing employs the power of AI to constantly evaluate real-time data to anticipate outcomes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib163" title="" class="ltx_ref">163</a>]</cite>. Most existing ML techniques to drive routing and traffic control choices are essential <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite>. However, they rarely focus on challenging networks, characterized by constantly changing network conditions and a significant volume of traffic generated by edge devices. Several FL systems are proposed to address those problems and optimize routing decisions in challenging scenarios.</p>
</div>
<div id="S5.SS6.p2" class="ltx_para">
<p id="S5.SS6.p2.1" class="ltx_p">To increase performance and facilitate the scalability of data-intensive applications, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>]</cite> designed a federated architecture for routing packets inside a distributed edge network. They proposed a novel path selection model to predict the best route using LSTM. When a peak load is anticipated, the controller leverages this information to make adjustments to routing. By employing FL, all controllers attain a global view of the infrastructure while exchanging relatively little information, which helps organizations protect the bandwidth for the application traffic.</p>
</div>
<div id="S5.SS6.p3" class="ltx_para">
<p id="S5.SS6.p3.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib166" title="" class="ltx_ref">166</a>]</cite> developed mobility-aware routing and caching strategies
for dense small-cell networks based on the FL framework to optimize the cache placement and minimize the network cost. They first started by segmenting the whole geographical region into small sections, each with one small BS (SBS) and many mobilized users (MUs). They proposed a federated routing and popularity learning strategy in which the SBSs jointly learn the routing and preferences of their respective MUs and make caching decisions.</p>
</div>
<div id="S5.SS6.p4" class="ltx_para">
<p id="S5.SS6.p4.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib167" title="" class="ltx_ref">167</a>]</cite>, the authors created a decentralized routing application on time-dependent transportation networks using FL to learn shared prediction models online. All routing occurs at the network edge within a private roadside unit fog network, where access to outside cloud services is assumed to be intermittent. This system avoids the costly transfer of raw data between processes.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<table id="S5.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T6.1.1.1" class="ltx_tr">
<th id="S5.T6.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_ll ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.1.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T6.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref</span></span>
</span>
</th>
<th id="S5.T6.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.1.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S5.T6.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Application</span></span>
</span>
</th>
<th id="S5.T6.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.1.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T6.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Benefits</span></span>
</span>
</th>
<th id="S5.T6.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_rr ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.1.4.1.1" class="ltx_p" style="width:142.3pt;"><span id="S5.T6.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Drawbacks</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T6.1.2.1" class="ltx_tr">
<td id="S5.T6.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.2.1.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>, <a href="#bib.bib129" title="" class="ltx_ref">129</a>, <a href="#bib.bib168" title="" class="ltx_ref">168</a>, <a href="#bib.bib130" title="" class="ltx_ref">130</a>]</cite></span>
</span>
</td>
<td id="S5.T6.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.2.1.2.1.1" class="ltx_p" style="width:85.4pt;">Traffic Classification</span>
</span>
</td>
<td id="S5.T6.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.2.1.3.1.1" class="ltx_p" style="width:142.3pt;">Safely classifying internet traffic as well improving the accuracy of packet transmission</span>
</span>
</td>
<td id="S5.T6.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.2.1.4.1.1" class="ltx_p" style="width:142.3pt;">More improvements are needed to deal with complex data and information security</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.3.2" class="ltx_tr">
<td id="S5.T6.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.3.2.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>, <a href="#bib.bib135" title="" class="ltx_ref">135</a>, <a href="#bib.bib136" title="" class="ltx_ref">136</a>]</cite></span>
</span>
</td>
<td id="S5.T6.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.3.2.2.1.1" class="ltx_p" style="width:85.4pt;">Resource management</span>
</span>
</td>
<td id="S5.T6.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.3.2.3.1.1" class="ltx_p" style="width:142.3pt;">FL facilitates adaptive resource allocation, distributing bandwidth, power, and other resources intelligently across network nodes</span>
</span>
</td>
<td id="S5.T6.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.3.2.4.1.1" class="ltx_p" style="width:142.3pt;">Need more evaluations by considering for practical applications</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.4.3" class="ltx_tr">
<td id="S5.T6.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.4.3.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>, <a href="#bib.bib141" title="" class="ltx_ref">141</a>, <a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite></span>
</span>
</td>
<td id="S5.T6.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.4.3.2.1.1" class="ltx_p" style="width:85.4pt;">Radio access network</span>
</span>
</td>
<td id="S5.T6.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.4.3.3.1.1" class="ltx_p" style="width:142.3pt;">Satisfy users’ QoS requirements in terms of delay and data rate</span>
</span>
</td>
<td id="S5.T6.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.4.3.4.1.1" class="ltx_p" style="width:142.3pt;">Need more enhancement privacy beyond what FL inherently promotes</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.5.4" class="ltx_tr">
<td id="S5.T6.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.5.4.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>, <a href="#bib.bib147" title="" class="ltx_ref">147</a>, <a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib149" title="" class="ltx_ref">149</a>, <a href="#bib.bib151" title="" class="ltx_ref">151</a>, <a href="#bib.bib152" title="" class="ltx_ref">152</a>, <a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite></span>
</span>
</td>
<td id="S5.T6.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.5.4.2.1.1" class="ltx_p" style="width:85.4pt;">User mobility/location prediction</span>
</span>
</td>
<td id="S5.T6.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.5.4.3.1.1" class="ltx_p" style="width:142.3pt;">Enabling predictive features on smartphones without diminishing the QoE or leaking private information</span>
</span>
</td>
<td id="S5.T6.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.5.4.4.1.1" class="ltx_p" style="width:142.3pt;">Mobile terminals should be able to process a modest amount of data and perform analysis with FL frameworks</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.6.5" class="ltx_tr">
<td id="S5.T6.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.6.5.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>, <a href="#bib.bib159" title="" class="ltx_ref">159</a>, <a href="#bib.bib160" title="" class="ltx_ref">160</a>, <a href="#bib.bib161" title="" class="ltx_ref">161</a>, <a href="#bib.bib162" title="" class="ltx_ref">162</a>]</cite></span>
</span>
</td>
<td id="S5.T6.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.6.5.2.1.1" class="ltx_p" style="width:85.4pt;">Network slicing</span>
</span>
</td>
<td id="S5.T6.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.6.5.3.1.1" class="ltx_p" style="width:142.3pt;">Offering significant improvement on service latency performance for all supported services</span>
</span>
</td>
<td id="S5.T6.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.6.5.4.1.1" class="ltx_p" style="width:142.3pt;">Updating local models with high frequency increases the network overhead and consumes network and computing resources</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.7.6" class="ltx_tr">
<td id="S5.T6.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.7.6.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>, <a href="#bib.bib166" title="" class="ltx_ref">166</a>, <a href="#bib.bib167" title="" class="ltx_ref">167</a>]</cite></span>
</span>
</td>
<td id="S5.T6.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.7.6.2.1.1" class="ltx_p" style="width:85.4pt;">Routing optimization</span>
</span>
</td>
<td id="S5.T6.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.7.6.3.1.1" class="ltx_p" style="width:142.3pt;">Optimizing routing for challenging scenarios while avoiding costly transfer of raw traffic data and reducing bandwidth stress</span>
</span>
</td>
<td id="S5.T6.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.7.6.4.1.1" class="ltx_p" style="width:142.3pt;">Need more travel time improvement and grid prediction models to mitigate the impact of errors on user trips</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.8.7" class="ltx_tr">
<td id="S5.T6.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.8.7.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib169" title="" class="ltx_ref">169</a>, <a href="#bib.bib170" title="" class="ltx_ref">170</a>, <a href="#bib.bib171" title="" class="ltx_ref">171</a>, <a href="#bib.bib172" title="" class="ltx_ref">172</a>, <a href="#bib.bib173" title="" class="ltx_ref">173</a>, <a href="#bib.bib174" title="" class="ltx_ref">174</a>, <a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite></span>
</span>
</td>
<td id="S5.T6.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.8.7.2.1.1" class="ltx_p" style="width:85.4pt;">UAV flying networks</span>
</span>
</td>
<td id="S5.T6.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.8.7.3.1.1" class="ltx_p" style="width:142.3pt;">Handling target challenges in UAV systems as well as operating at a considerably lower communication cost</span>
</span>
</td>
<td id="S5.T6.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.8.7.4.1.1" class="ltx_p" style="width:142.3pt;">Need to accelerate the strategy-making process and the resource allocation should be optimized</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.9.8" class="ltx_tr">
<td id="S5.T6.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.9.8.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib176" title="" class="ltx_ref">176</a>, <a href="#bib.bib177" title="" class="ltx_ref">177</a>]</cite></span>
</span>
</td>
<td id="S5.T6.1.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.9.8.2.1.1" class="ltx_p" style="width:85.4pt;">Underwater Networks</span>
</span>
</td>
<td id="S5.T6.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.9.8.3.1.1" class="ltx_p" style="width:142.3pt;">Enhancing underwater communication systems performance with high transmit power and secure underwater scenarios</span>
</span>
</td>
<td id="S5.T6.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.9.8.4.1.1" class="ltx_p" style="width:142.3pt;">The learning process should be more accelerated and applied in real scenarios</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.10.9" class="ltx_tr">
<td id="S5.T6.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.10.9.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>, <a href="#bib.bib179" title="" class="ltx_ref">179</a>, <a href="#bib.bib180" title="" class="ltx_ref">180</a>, <a href="#bib.bib181" title="" class="ltx_ref">181</a>, <a href="#bib.bib182" title="" class="ltx_ref">182</a>, <a href="#bib.bib183" title="" class="ltx_ref">183</a>]</cite></span>
</span>
</td>
<td id="S5.T6.1.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.10.9.2.1.1" class="ltx_p" style="width:85.4pt;">Cloud/Fog computing</span>
</span>
</td>
<td id="S5.T6.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.10.9.3.1.1" class="ltx_p" style="width:142.3pt;">Achieving less energy consumption to make full use of the big data in both cloud and fog computing</span>
</span>
</td>
<td id="S5.T6.1.10.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S5.T6.1.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.10.9.4.1.1" class="ltx_p" style="width:142.3pt;">The training efficiency has to be enhanced as well as optimizing some critical parameters</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>Summary of FL-based contributions at NET layer.</figcaption>
</figure>
</section>
<section id="S5.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS7.4.1.1" class="ltx_text">V-G</span> </span><span id="S5.SS7.5.2" class="ltx_text ltx_font_italic">Unmanned Aerial Vehicle</span>
</h3>

<div id="S5.SS7.p1" class="ltx_para">
<p id="S5.SS7.p1.1" class="ltx_p">The combination of AI and Unmanned Aerial Vehicles (UAVs), commonly known as drones, holds significant promise for various industries and applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib184" title="" class="ltx_ref">184</a>, <a href="#bib.bib185" title="" class="ltx_ref">185</a>, <a href="#bib.bib186" title="" class="ltx_ref">186</a>]</cite>. However, it presents challenges related to regulation, safety, privacy, security, and complexity. FL is an emerging and promising application that combines privacy preservation, low latency, low communication overhead, and real-time learning with the capabilities of UAVs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib187" title="" class="ltx_ref">187</a>]</cite>.</p>
</div>
<div id="S5.SS7.p2" class="ltx_para">
<p id="S5.SS7.p2.1" class="ltx_p">The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib169" title="" class="ltx_ref">169</a>]</cite> presented an FL-based drone authentication model with drones’ RF features in IoT networks. The deep NN (DNN) architecture is used, with stochastic gradient descent optimization performed locally on the drones. Results show that the federated drone authentication model gains a high true positive rate during drone authentication and better performance compared to other ML systems.</p>
</div>
<div id="S5.SS7.p3" class="ltx_para">
<p id="S5.SS7.p3.1" class="ltx_p">The study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib170" title="" class="ltx_ref">170</a>]</cite> adopted FL to facilitate privacy-preserving sensing and collaborative learning in the UAV services. This work proposed a multi-dimensional contract matching design that aims to match the most optimal UAV to each sensing sub-region while accounting for UAV heterogeneity.</p>
</div>
<div id="S5.SS7.p4" class="ltx_para">
<p id="S5.SS7.p4.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib171" title="" class="ltx_ref">171</a>]</cite> proposed a hierarchical nested personalized FL, a holistic distributed ML framework for personalized model training across the worker leader core network hierarchy. This method used data sharing across device clusters to create tailored local models.</p>
</div>
<div id="S5.SS7.p5" class="ltx_para">
<p id="S5.SS7.p5.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>]</cite>, a secured FL framework for UAV-assisted MCS was presented. Firstly, three attacks were proposed, and the related countermeasures were studied to secure cooperative learning for UAVs. Secondly, an FL approach has been developed using the blockchain network to securely store and trace UAV contributions in an immutable way while protecting local model exchange across UAVs. Finally, a privacy-preserving local model-sharing mechanism was developed to protect UAVs with high aggregation accuracy.</p>
</div>
<div id="S5.SS7.p6" class="ltx_para">
<p id="S5.SS7.p6.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib173" title="" class="ltx_ref">173</a>]</cite> proposed a novel architecture for implementing distributed learning algorithms inside a UAV swarm that consists of a leading UAV and several following UAVs. Each UAV trains a local FL model based on its gathered data and then sends it to the leading UAV, aggregating the received models, generating a global federated model, and transmitting the knowledge to followers through the intra-swarm network.</p>
</div>
<div id="S5.SS7.p7" class="ltx_para">
<p id="S5.SS7.p7.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib174" title="" class="ltx_ref">174</a>]</cite>, the authors proposed FL-aided multi-UAV systems for task classification in the broad application area of exploration scenarios. At first, local training is carried out by each UAV relying on its own locally gathered images; the model developed from the local training is then transmitted to the GFC over fading wireless channels. Finally, a global model is built at the GFC and sent back to each UAV for the next local model update. This framework operates at a considerably lower communication cost compared to traditional ML.</p>
</div>
<div id="S5.SS7.p8" class="ltx_para">
<p id="S5.SS7.p8.1" class="ltx_p">FL is a promising solution for flying ad-hoc networks (FANET). The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite> designed an FL-based on-device jamming attack detection security architecture for FANET. They added a client group prioritization technique leveraging the Dempster–Shafer theory <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib188" title="" class="ltx_ref">188</a>]</cite>, which allows the aggregator node to identify better client groups for calculating the global update.</p>
</div>
</section>
<section id="S5.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS8.4.1.1" class="ltx_text">V-H</span> </span><span id="S5.SS8.5.2" class="ltx_text ltx_font_italic">Underwater Networks</span>
</h3>

<div id="S5.SS8.p1" class="ltx_para">
<p id="S5.SS8.p1.1" class="ltx_p">Underwater wireless communication is another type of wireless communication in which acoustic signals across an underwater channel send digital information. Numerous efforts have been made to enhance the performance of underwater communication systems using ML, DL, and transfer learning techniques. However, the set-up of underwater networks is challenging because of the high propagation delay and high transmit power compared to wireless free-space air networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib189" title="" class="ltx_ref">189</a>]</cite>. FL mechanism holds promise as a secure means to collectively train underwater communication models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib190" title="" class="ltx_ref">190</a>]</cite>.</p>
</div>
<div id="S5.SS8.p2" class="ltx_para">
<p id="S5.SS8.p2.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib176" title="" class="ltx_ref">176</a>]</cite> proposed a novel multi-agent deep reinforcement learning algorithm to remove unexpected smart ocean environment changes and channel unreliability. First, each device conducts distributed DL training with personal data, aggregating the output at a centralized station. Then, the centralized machine computes global optimal solutions and then distributes the results to the associated participants. This approach effectively enhances the throughput performance in underwater scenarios.</p>
</div>
<div id="S5.SS8.p3" class="ltx_para">
<p id="S5.SS8.p3.1" class="ltx_p">For the ocean of things, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib177" title="" class="ltx_ref">177</a>]</cite> developed a federated meta-learning enhanced acoustic radio cooperative framework that takes advantage of data distributed across surface nodes to train the DL-receiver in the context of random scheduling wireless networks. This approach enables distributed transfer learning to be adapted to new datasets.</p>
</div>
</section>
<section id="S5.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS9.4.1.1" class="ltx_text">V-I</span> </span><span id="S5.SS9.5.2" class="ltx_text ltx_font_italic">Cloud/Fog Computing</span>
</h3>

<div id="S5.SS9.p1" class="ltx_para">
<p id="S5.SS9.p1.1" class="ltx_p">While the cloud proves a powerful computing platform in numerous applications, it encounters difficulties in scenarios with rigorous requirements including drones and autonomous vehicles that need low-latency and privacy-preserving <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib191" title="" class="ltx_ref">191</a>]</cite>. FL is promising for training ML models on mobile devices while ensuring limited computing, storage, energy, and bandwidth.</p>
</div>
<div id="S5.SS9.p2" class="ltx_para">
<p id="S5.SS9.p2.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>]</cite>, the authors presented a highly efficient FL framework with strong privacy preservation in cloud computing. Instead of noise injection methods, a lightweight encryption protocol is employed, giving both provable privacy and desirable model utility. This approach provides secure training to learn from all available data.</p>
</div>
<div id="S5.SS9.p3" class="ltx_para">
<p id="S5.SS9.p3.1" class="ltx_p">Existing FL approaches for cloud-based AI IoT (AIoT) applications need more accurate prediction results. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib179" title="" class="ltx_ref">179</a>]</cite> presented a collaborative architecture that deploys DNN models across both cloud and AIoT devices. They designed two-stage training and co-inference schemes to improve the prediction accuracy of individual AIoT devices using little branches, reducing their average inference time with the help of the big branch part deployed on the cloud.</p>
</div>
<div id="S5.SS9.p4" class="ltx_para">
<p id="S5.SS9.p4.1" class="ltx_p">A client-edge-cloud hierarchical FL system was presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib180" title="" class="ltx_ref">180</a>]</cite> based on the HierFAVG algorithm that allows multiple edge servers to perform partial model aggregation. This framework simultaneously reduces the model training time and the energy consumption of the end devices compared to traditional cloud-based FL.</p>
</div>
<div id="S5.SS9.p5" class="ltx_para">
<p id="S5.SS9.p5.1" class="ltx_p">To take full advantage of fog computing and AI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib192" title="" class="ltx_ref">192</a>]</cite>, a new paradigm of FL-enabled intelligent fog radio access networks was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib181" title="" class="ltx_ref">181</a>]</cite>. This framework supports intelligent signal processing and network management with low communication cost and high efficiency, providing a feasible approach to implementing network edge intelligence.</p>
</div>
<div id="S5.SS9.p6" class="ltx_para">
<p id="S5.SS9.p6.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib182" title="" class="ltx_ref">182</a>]</cite> used FL to predict content popularity in fog radio access networks and reduce computational complexity. The inputs of the prediction model are the averaged popularity scores for clustered users’ contents, the model is then learned automatically by training the algorithm with historical popularity and the pre-processed inputs.</p>
</div>
<div id="S5.SS9.p7" class="ltx_para">
<p id="S5.SS9.p7.1" class="ltx_p">To deal with the privacy gap in fog computing, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib183" title="" class="ltx_ref">183</a>]</cite> created a blockchain FL system that enables autonomous ML without any centralized authority to maintain the global model and coordinates using blockchain. The latency performance derives the optimal block generation rate by considering communication, consensus delays, and computation costs.</p>
</div>
</section>
<section id="S5.SS10" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS10.4.1.1" class="ltx_text">V-J</span> </span><span id="S5.SS10.5.2" class="ltx_text ltx_font_italic">Summary</span>
</h3>

<div id="S5.SS10.p1" class="ltx_para">
<p id="S5.SS10.p1.1" class="ltx_p">This section covers recent findings on applying FL mechanisms at the network layer. This emerging paradigm effectively approaches the results obtained by centralized ML techniques while guaranteeing 5G and 6G requirements such as user privacy, latency, limited computing, energy, and bandwidth. The lessons learned from this section are as follows:</p>
<ul id="S5.I2" class="ltx_itemize">
<li id="S5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i1.p1" class="ltx_para">
<p id="S5.I2.i1.p1.1" class="ltx_p">The application of FL at the network layer redefines how networks are managed, optimized, and evolved. By leveraging FL’s decentralized learning approach, the network layer gains the ability to enhance its performance, responsiveness, and intelligence while addressing critical challenges (e.g., privacy).</p>
</div>
</li>
<li id="S5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i2.p1" class="ltx_para">
<p id="S5.I2.i2.p1.1" class="ltx_p">While FL applications at the network layer promise numerous benefits, they also present some challenges including communication overhead, synchronization, security, and scalability.</p>
</div>
</li>
</ul>
<p id="S5.SS10.p1.2" class="ltx_p">Table <a href="#S5.T6" title="TABLE VI ‣ V-F Routing Optimization ‣ V Federated Learning at NET Layer ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> illustrates a summary of FL-based contributions that enhance the network layer architecture.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning at APP/Transport Layers</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The application and the transport layers are the last components of the OSI model that specify the shared protocols and interface methods used by hosts in a communications network. FL significantly improves handling APP layers challenges in wireless communication networks. In this section, we provide a deep dive into recent FL contributions in the context of APP and transport layers.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.4.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.5.2" class="ltx_text ltx_font_italic">Transport Performance</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">FL is applied to enhance the performance and efficiency of the data transport protocol and the transmission control protocol (TCP) used for reliable data transmission over the Internet. It brings several benefits, including improved congestion control, network management, and protocol optimization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib193" title="" class="ltx_ref">193</a>]</cite>.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">To enhance the performance of the internet of vehicles, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib194" title="" class="ltx_ref">194</a>]</cite> proposed a privacy-preserving FL framework that guarantees ubiquitous connection among the vehicles and presented a local mechanism to satisfy the reliability and latency requirements. This work introduced a mathematical framework that accurately estimates TCP-perceived packet loss probability and latency for vehicles when wireless channels suffer from different magnitude losses and transmission delays.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib195" title="" class="ltx_ref">195</a>]</cite> adopted FL to study the performance of long-lived compound TCP (C-TCP) flows over Industry 4.0 WiFi infrastructure. They developed a novel analytical model to investigate the impacts of collisions, wireless losses, and AP buffer losses on C-TCP over WiFi with bidirectional flows. The results demonstrate that cognitive radio and FL significantly enhance the performance of the industrial multiple scenarios.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.4.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.5.2" class="ltx_text ltx_font_italic">Cooperative and Distributed Computing</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">Distributed computing is a paradigm where elements of a software system are distributed across multiple computers, yet function collectively as a unified system. This strategy is employed to enhance efficiency and performance. Combining AI and distributed computing poses challenges in data management and communication between nodes. FL paradigm is used to safely manage distributed computing systems by training a shared model collaboratively while keeping all data on their devices. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib196" title="" class="ltx_ref">196</a>]</cite>, the authors designed a distributed computing defense framework for a sustainable society by combining FL and blockchain to preserve privacy and unlock the full potential of ML in distributed computing environments. Compared to traditional approaches, the result outcomes are promising in terms of accuracy and loss.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">Recently, cooperative computing has emerged as a novel paradigm within the domain of distributed strategies. This approach revolves around fostering collaboration and synergy among various computing nodes to achieve enhanced system performance and efficiency. It capitalizes on the collective intelligence and resources of individual components, paving the way for innovative solutions that address complex challenges. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib197" title="" class="ltx_ref">197</a>]</cite>, the authors introduced a novel FL framework that leverages the cooperation of devices that perform data operations inside the network by iterating local computations and mutual interactions via consensus-based methods. This method paves the way for FL integration in 5G and beyond, characterized by decentralized connectivity and computing.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS3.4.1.1" class="ltx_text">VI-C</span> </span><span id="S6.SS3.5.2" class="ltx_text ltx_font_italic">Crowdsourcing / Crowdsensing</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">Crowdsourcing has the potential to be highly advantageous to accomplish computing tasks due to its ability to rapidly collect information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib198" title="" class="ltx_ref">198</a>]</cite>. FL is used to safely implement crowd computing. It involves training ML models using decentralized data from multiple servers, without transferring the data to a central location. This helps to protect sensitive data while sharing learning and analysis.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib199" title="" class="ltx_ref">199</a>]</cite> presented a crowdsourcing framework based on FL, blockchain, and re-encryption technology. All blockchain nodes participate in crowdsourcing to retain a full data backup. By adopting FL, each worker uploads the model or gradient data to clients for aggregation. This approach allows users to implement decentralized crowdsourcing with less overhead and higher security while improving the computing audit ability.</p>
</div>
<div id="S6.SS3.p3" class="ltx_para">
<p id="S6.SS3.p3.1" class="ltx_p">The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib200" title="" class="ltx_ref">200</a>]</cite> studied FL and local differential privacy to facilitate the crowdsourcing use cases. This approach enables vehicular crowdsourcing applications to train ML models and predict traffic status while preserving privacy and reducing communication costs.</p>
</div>
<div id="S6.SS3.p4" class="ltx_para">
<p id="S6.SS3.p4.1" class="ltx_p">Recently, crowdsensing has gained significant attention and becoming an appealing paradigm for sensor-based data collection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib201" title="" class="ltx_ref">201</a>]</cite>. However, the diverse and sensitive nature of data collected through crowdsensing necessitates robust privacy protection mechanisms to secure individual user identities and personal information. Addressing this challenge is imperative to unlock the full potential of crowdsensing while upholding privacy standards. Several recent contributions employed FL paradigms to overcome those limitations. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib202" title="" class="ltx_ref">202</a>]</cite>, a federated crowdsensing framework was proposed to analyze the privacy concerns of the four crowdsensing stages: creation task, assignment task, execution task, and data aggregation task.</p>
</div>
<div id="S6.SS3.p5" class="ltx_para">
<p id="S6.SS3.p5.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib203" title="" class="ltx_ref">203</a>]</cite> integrated FL into mobile crowdsourcing to design a privacy-preserving system named PriFedAvg where the participants locally process sensing data via FL and protect training by only uploading the encrypted training models.</p>
</div>
<div id="S6.SS3.p6" class="ltx_para">
<p id="S6.SS3.p6.1" class="ltx_p">The quality-aware user recruitment problem was investigated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib204" title="" class="ltx_ref">204</a>]</cite>, using FL to predict the quality of sensed data from different users by analyzing the correlation between data and context information through FL. This method improves the quality of sensed compared with traditional algorithms.</p>
</div>
<div id="S6.SS3.p7" class="ltx_para">
<p id="S6.SS3.p7.1" class="ltx_p">A novel approach was developed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib205" title="" class="ltx_ref">205</a>]</cite> for fake task detection based on horizontal FL. Two ML algorithms and datasets were implemented to identify fake tasks containing several independent detection devices and an aggregation entity.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS4.4.1.1" class="ltx_text">VI-D</span> </span><span id="S6.SS4.5.2" class="ltx_text ltx_font_italic">Quality of Experience</span>
</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">The evolution of streaming services needs high data rates, low latency, and good QoS. Several challenges must be addressed while delivering a specific service including the large number of devices, the heterogeneous networks, and the uncontrollable environments. The quality of experience (QoE) concept is gaining tremendous research efforts to improve and deliver reliable and added-value services, at a high user experience <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib206" title="" class="ltx_ref">206</a>]</cite>. ML-based QoE models suffer from overfitting due to low data volume and limited participant profiles <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib207" title="" class="ltx_ref">207</a>]</cite>. A privacy-preserving ML scheme such as FL, enables the sharing of QoE data models between all participants only by transmitting model parameters.</p>
</div>
<div id="S6.SS4.p2" class="ltx_para">
<p id="S6.SS4.p2.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib208" title="" class="ltx_ref">208</a>]</cite> adopted FL and round-robin learning, where the model is trained sequentially amongst the collaborated partner nodes to show that high accuracy is achieved without sharing sensitive data between participants.</p>
</div>
<div id="S6.SS4.p3" class="ltx_para">
<p id="S6.SS4.p3.1" class="ltx_p">To facilitate smooth QoE model management and obtain higher accuracy, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib209" title="" class="ltx_ref">209</a>]</cite> presented a set-based Bayesian synthetic data generation method for FL that effectively reduces the training time by 30% and the network footprint in the communication channel by 60%.</p>
</div>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS5.4.1.1" class="ltx_text">VI-E</span> </span><span id="S6.SS5.5.2" class="ltx_text ltx_font_italic">Cybersecurity</span>
</h3>

<div id="S6.SS5.p1" class="ltx_para">
<p id="S6.SS5.p1.1" class="ltx_p">Cybersecurity benefits from AI techniques to enhance security performance and better protection against complex threats <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib210" title="" class="ltx_ref">210</a>]</cite>. However, traditional ML architecture does not meet the demand of cybersecurity because of the large amount of data, the data heterogeneity, the high data velocity, and the major existing challenges in gathering cyber intelligence and attack datasets from distributed resources. The FL paradigm is used to securely train models for anomaly detection tasks without collecting raw data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib211" title="" class="ltx_ref">211</a>]</cite>.</p>
</div>
<div id="S6.SS5.p2" class="ltx_para">
<p id="S6.SS5.p2.1" class="ltx_p">A privacy-preserving approach was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib212" title="" class="ltx_ref">212</a>]</cite> to support verification of the server’s calculation results to each user which allows all participants to verify the results’ correctness returned from the central server with acceptable overhead.</p>
</div>
<div id="S6.SS5.p3" class="ltx_para">
<p id="S6.SS5.p3.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib213" title="" class="ltx_ref">213</a>]</cite> designed an FL-based framework for malicious URL detection in a managed security service provider setting. They looked at various scenarios regarding data partitioning amongst agents and found that the collaborative federated ML model enhanced URL classification performance in all scenarios and improved its rates up to 27%.</p>
</div>
<div id="S6.SS5.p4" class="ltx_para">
<p id="S6.SS5.p4.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib214" title="" class="ltx_ref">214</a>]</cite>, the authors presented the FedDICE framework that integrates FL to SDN-oriented security architecture to enable collaborative learning, detection, and mitigation of ransomware attacks in collaborative environments. This approach achieves performance similar to centralized learning results.</p>
</div>
<div id="S6.SS5.p5" class="ltx_para">
<p id="S6.SS5.p5.1" class="ltx_p">The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib215" title="" class="ltx_ref">215</a>]</cite> developed an intelligent threat defense system employing blockchain FL, which seeks to fully upgrade the way passive intelligent systems operate, aiming at intelligently classifying smart cities networks traffic derived from industrial IoT by deep content inspection methods to identify anomalies that are usually due to advanced persistent threat attacks.</p>
</div>
</section>
<section id="S6.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS6.4.1.1" class="ltx_text">VI-F</span> </span><span id="S6.SS6.5.2" class="ltx_text ltx_font_italic">Summary</span>
</h3>

<div id="S6.SS6.p1" class="ltx_para">
<p id="S6.SS6.p1.1" class="ltx_p">In this section, we present a comprehensive literature review on applying FL at the application and transport layers. There are many improvements and promising solutions that have an impact on the performance of transport, distributed computing, crowdsourcing, cybersecurity, and QoE. The lessons learned from this section are :</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">Applying FL at both the transport and the application layers introduces a synergistic approach that enhances how data is transported, processed, and utilized across the network. This integration offers the potential to optimize both the technical aspects of data transmission and the functional aspects of user-facing applications.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">Ensuring secure data transmission, managing synchronization, optimizing communication overhead, and addressing scalability are considerations that require ongoing attention and innovation.</p>
</div>
</li>
</ul>
<p id="S6.SS6.p1.2" class="ltx_p">Table <a href="#S6.T7" title="TABLE VII ‣ VI-F Summary ‣ VI Federated Learning at APP/Transport Layers ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a> provides a review of the FL contributions at the APP and the transport layers, highlighting their benefits and drawbacks.</p>
</div>
<figure id="S6.T7" class="ltx_table">
<table id="S6.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T7.1.1.1" class="ltx_tr">
<th id="S6.T7.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_ll ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.1.1.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S6.T7.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref</span></span>
</span>
</th>
<th id="S6.T7.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.1.1.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S6.T7.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Application</span></span>
</span>
</th>
<th id="S6.T7.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.1.1.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S6.T7.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Benefits</span></span>
</span>
</th>
<th id="S6.T7.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_rr ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.1.1.4.1.1" class="ltx_p" style="width:142.3pt;"><span id="S6.T7.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Drawbacks</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T7.1.2.1" class="ltx_tr">
<td id="S6.T7.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.2.1.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib194" title="" class="ltx_ref">194</a>, <a href="#bib.bib195" title="" class="ltx_ref">195</a>]</cite></span>
</span>
</td>
<td id="S6.T7.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.2.1.2.1.1" class="ltx_p" style="width:85.4pt;">Transport performance</span>
</span>
</td>
<td id="S6.T7.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.2.1.3.1.1" class="ltx_p" style="width:142.3pt;">Enhancing TCP performance while preventing privacy leakage</span>
</span>
</td>
<td id="S6.T7.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.2.1.4.1.1" class="ltx_p" style="width:142.3pt;">Must implemented in complex networks to analyze the convergence and throughput fairness</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.3.2" class="ltx_tr">
<td id="S6.T7.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.3.2.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib196" title="" class="ltx_ref">196</a>, <a href="#bib.bib197" title="" class="ltx_ref">197</a>]</cite></span>
</span>
</td>
<td id="S6.T7.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.3.2.2.1.1" class="ltx_p" style="width:85.4pt;">Cooperative and Distributed Computing</span>
</span>
</td>
<td id="S6.T7.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.3.2.3.1.1" class="ltx_p" style="width:142.3pt;">Securely manage distributed and cooperative systems without requiring large computation</span>
</span>
</td>
<td id="S6.T7.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.3.2.4.1.1" class="ltx_p" style="width:142.3pt;">Requiring more efficient use of the limited bandwidth, including quantization, compression, or ad hoc channel encoding</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.4.3" class="ltx_tr">
<td id="S6.T7.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.4.3.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib199" title="" class="ltx_ref">199</a>, <a href="#bib.bib200" title="" class="ltx_ref">200</a>, <a href="#bib.bib202" title="" class="ltx_ref">202</a>, <a href="#bib.bib203" title="" class="ltx_ref">203</a>, <a href="#bib.bib204" title="" class="ltx_ref">204</a>, <a href="#bib.bib205" title="" class="ltx_ref">205</a>]</cite></span>
</span>
</td>
<td id="S6.T7.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.4.3.2.1.1" class="ltx_p" style="width:85.4pt;">Crowdsourcing and Crowdsensing</span>
</span>
</td>
<td id="S6.T7.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.4.3.3.1.1" class="ltx_p" style="width:142.3pt;">Facilitating crowdsourcing and crowdsensing applications with less overhead, less communication cost and higher security</span>
</span>
</td>
<td id="S6.T7.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.4.3.4.1.1" class="ltx_p" style="width:142.3pt;">Need to study the waiting for charging as most crowdsensing tasks have temporal deadlines</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.5.4" class="ltx_tr">
<td id="S6.T7.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.5.4.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib208" title="" class="ltx_ref">208</a>, <a href="#bib.bib209" title="" class="ltx_ref">209</a>]</cite></span>
</span>
</td>
<td id="S6.T7.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.5.4.2.1.1" class="ltx_p" style="width:85.4pt;">QoE</span>
</span>
</td>
<td id="S6.T7.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.5.4.3.1.1" class="ltx_p" style="width:142.3pt;">Enabling a seamless QoE model management without having to use sensitive data</span>
</span>
</td>
<td id="S6.T7.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.5.4.4.1.1" class="ltx_p" style="width:142.3pt;">Insufficient performance due to the difficulties in accessing QoE datasets</span>
</span>
</td>
</tr>
<tr id="S6.T7.1.6.5" class="ltx_tr">
<td id="S6.T7.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.6.5.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib212" title="" class="ltx_ref">212</a>, <a href="#bib.bib213" title="" class="ltx_ref">213</a>, <a href="#bib.bib214" title="" class="ltx_ref">214</a>, <a href="#bib.bib215" title="" class="ltx_ref">215</a>]</cite></span>
</span>
</td>
<td id="S6.T7.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.6.5.2.1.1" class="ltx_p" style="width:85.4pt;">Cybersecurity</span>
</span>
</td>
<td id="S6.T7.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.6.5.3.1.1" class="ltx_p" style="width:142.3pt;">Effectively detecting attacks while addressing issues of data sharing</span>
</span>
</td>
<td id="S6.T7.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T7.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T7.1.6.5.4.1.1" class="ltx_p" style="width:142.3pt;">Have to apply the FL strategy when the attackers influence the model training</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VII: </span>Summary of FL-based contributions at Transport/APP layers.</figcaption>
</figure>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning Applications &amp; Verticals</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this section, we discuss the benefits of adopting an FL scheme in wireless network scenarios, including autonomous driving, anomaly detection, industrial operations, smart healthcare, and other applications.</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS1.4.1.1" class="ltx_text">VII-A</span> </span><span id="S7.SS1.5.2" class="ltx_text ltx_font_italic">Autonomous Driving</span>
</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">Autonomous driving and autonomous vehicles are now among the most prominent research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib216" title="" class="ltx_ref">216</a>]</cite>. They involve the application of ML and DL techniques that actively select data, transform information, control processes, and make decisions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib217" title="" class="ltx_ref">217</a>]</cite>. However, the sequential process of centralized architectures is extremely time-consuming, and the knowledge from the fine-tuned model stays local and not leveraged. Thus, FL is considered to be a strong mechanism that enables devices to interact with their environment and acquire knowledge safely from other devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib218" title="" class="ltx_ref">218</a>]</cite>.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p">To design the autonomous controller of connected and autonomous vehicles (CAV) under the conditions of wireless link uncertainty and environmental dynamics. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib219" title="" class="ltx_ref">219</a>]</cite> presented a new DL framework, a dynamic federated proximal algorithm for the training process that introduces a regularizer at the CAVs to minimize the impact of non-IID and unbalanced data on the FL convergence.</p>
</div>
<div id="S7.SS1.p3" class="ltx_para">
<p id="S7.SS1.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib220" title="" class="ltx_ref">220</a>]</cite>, the authors integrated FL into autonomous driving to preserve vehicular privacy and improve model accuracy by keeping original data in a local vehicle and only sharing the training model parameter through the MEC server. The results show that the proposed FL-based autonomous driving system reduces 73.7 % of training loss, and improves the accuracy to around 5.55 %.</p>
</div>
<div id="S7.SS1.p4" class="ltx_para">
<p id="S7.SS1.p4.1" class="ltx_p">For privacy-aware and efficient vehicular communication networking, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib221" title="" class="ltx_ref">221</a>]</cite> built an autonomous blockchain-based FL system to ensure end-to-end trustworthiness and delay. The proposed framework enables effective autonomous vehicle communication by allowing local on-vehicle ML modules to share and validate their updates in a fully decentralized manner.</p>
</div>
<div id="S7.SS1.p5" class="ltx_para">
<p id="S7.SS1.p5.1" class="ltx_p">The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib222" title="" class="ltx_ref">222</a>]</cite> designed an online federated reinforcement transfer learning process to extract knowledge for autonomous vehicles in real time. In this model, all the participant agents make corresponding actions with the knowledge learned by others, even when they are acting in very different environments. The results show that the proposed approach effectively transfers knowledge online, with better training speed and performance.</p>
</div>
<div id="S7.SS1.p6" class="ltx_para">
<p id="S7.SS1.p6.1" class="ltx_p">To minimize the network-wide power consumption of vehicular users while ensuring high reliability in terms of probabilistic queuing delays, the work presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib223" title="" class="ltx_ref">223</a>]</cite> proposed a novel joint transmit power and resource allocation using FL, which reduces unnecessary overheads.</p>
</div>
<div id="S7.SS1.p7" class="ltx_para">
<p id="S7.SS1.p7.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib224" title="" class="ltx_ref">224</a>]</cite> proposed a new type of FL vehicular network concept namely FVN, which offers more consistent performance than a traditional vehicle network and handles data/computation-intensive applications. The obtained results demonstrate that the proposed framework provides high accuracy and less energy consumption.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS2.4.1.1" class="ltx_text">VII-B</span> </span><span id="S7.SS2.5.2" class="ltx_text ltx_font_italic">Anomaly Detection</span>
</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">FL potentially admits meaningful applications for malicious attack detection in mobile communication systems. For instance, DIoT is an autonomous self-learning distributed system for detecting compromised IoT devices. The approach designed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib225" title="" class="ltx_ref">225</a>]</cite>, FL efficiently aggregates behavior profiles while relying on device-type-specific communication profiles without human intervention or labeled data.</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib226" title="" class="ltx_ref">226</a>]</cite>, the authors adopted FL for network anomaly detection and analyzing network traffic to tackle the data scarcity problem and preserve data privacy. It’s about designing a multi-task DNN to perform network anomaly detection task, traffic recognition task, and traffic classification task.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p">An anomaly detection architecture for industrial IoT-based smart manufacturing was presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib227" title="" class="ltx_ref">227</a>]</cite>. This architecture detects anomalies for time series data typically running inside an industrial system by only sending the training model of each edge to the cloud for the global update. This approach saves 35% of the bandwidth consumed in the transmission link between the edge and the cloud.</p>
</div>
<div id="S7.SS2.p4" class="ltx_para">
<p id="S7.SS2.p4.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib228" title="" class="ltx_ref">228</a>]</cite>, the authors developed an intelligent intrusion detection framework using FL. First, the LSTM global model is deployed on the servers. Second, each user trains its local model and then uploads its parameters to the central server. Finally, the central server performs the model parameters aggregation to distribute the new knowledge to all participants. This approach achieves higher accuracy and better consistency than conventional methods.</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS3.4.1.1" class="ltx_text">VII-C</span> </span><span id="S7.SS3.5.2" class="ltx_text ltx_font_italic">Industrial Operations</span>
</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.1" class="ltx_p">Industrial operations refer to the development of many domains, including image processing, robotics, manufacturing, agriculture, and other fields. ML and DL techniques were applied to solve various industrial problems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib229" title="" class="ltx_ref">229</a>]</cite>. However, traditional centralized learning does not meet the requirements of industrial scenarios because of privacy and scalability concerns. Several works were designed and implemented using FL to address these challenges while generating potential results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib230" title="" class="ltx_ref">230</a>]</cite>.</p>
</div>
<div id="S7.SS3.p2" class="ltx_para">
<p id="S7.SS3.p2.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib231" title="" class="ltx_ref">231</a>]</cite> developed an efficient and privacy-enhanced FL (PEFL) framework to solve various industrial challenging problems in industrial AI. PEFL scheme is non-interactive which prevents privacy leakage from the local gradients and the shared parameters even when an adversary colludes with multiple entities. Results demonstrate the advantage of this approach in terms of accuracy and efficiency.</p>
</div>
<div id="S7.SS3.p3" class="ltx_para">
<p id="S7.SS3.p3.1" class="ltx_p">A verifiable FL (VFL) mechanism with privacy-preserving for big data in industrial IoT was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib232" title="" class="ltx_ref">232</a>]</cite>. This framework effectively ensures the model’s security and private gradient by allowing each participant to verify the aggregated results based on Lagrange interpolation, and the verification overhead remains constant regardless of the number of participants. The VFL is applied to many industrial scenarios because of its advantages in terms of verification and total overhead.</p>
</div>
<div id="S7.SS3.p4" class="ltx_para">
<p id="S7.SS3.p4.1" class="ltx_p">To provide a structured collection of requirements and workflows covered in an industrial FL (IFL) architecture, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib233" title="" class="ltx_ref">233</a>]</cite> designed an IFL system supporting knowledge exchange in continuously evaluated and updated FL cohorts of learning tasks with sufficient data similarity. The proposed scheme enables optimal collaboration of business partners in common ML problems, prevents negative knowledge transfer, and ensures resource optimization of involved edge devices.</p>
</div>
<div id="S7.SS3.p5" class="ltx_para">
<p id="S7.SS3.p5.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib234" title="" class="ltx_ref">234</a>]</cite> proposed a new architecture of digital twin (DT) empowered industrial IoT in which DTs sensitively capture the dynamic changes of the network. The proposed scheme adjusts the aggregation frequency according to the channel state and provides better performance in terms of learning accuracy, convergence rate, and energy saving.</p>
</div>
<div id="S7.SS3.p6" class="ltx_para">
<p id="S7.SS3.p6.1" class="ltx_p">FL offers efficient solutions to collaborative learning in decentralized multi-robot and distributed autonomous systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib235" title="" class="ltx_ref">235</a>]</cite>. The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib236" title="" class="ltx_ref">236</a>]</cite> proposed a real-time data processing architecture for multi-robots based on differential FL where a global model is trained on the cloud iteratively and distributed to multiple edge robots. This architecture is applied to multiple robotic recognition tasks and balances the trade-off between performance and privacy.</p>
</div>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS4.4.1.1" class="ltx_text">VII-D</span> </span><span id="S7.SS4.5.2" class="ltx_text ltx_font_italic">Ultra Reliable Low Latency Communications</span>
</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p id="S7.SS4.p1.1" class="ltx_p">Ultra-reliable low latency communications (URLLC) is one of the key pillars of 5G NR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib237" title="" class="ltx_ref">237</a>]</cite> for extremely low latency (e.g., 1ms) and high reliability (e.g., 99.999%). With recent advances in data-driven ML and DL, it is possible to learn a wide range of policies for wireless networks. However, those methods need:</p>
<ul id="S7.I1" class="ltx_itemize">
<li id="S7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i1.p1" class="ltx_para">
<p id="S7.I1.i1.p1.1" class="ltx_p">Long training phase.</p>
</div>
</li>
<li id="S7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i2.p1" class="ltx_para">
<p id="S7.I1.i2.p1.1" class="ltx_p">Large number of training samples.</p>
</div>
</li>
<li id="S7.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i3.p1" class="ltx_para">
<p id="S7.I1.i3.p1.1" class="ltx_p">Long time to obtain enough training samples.</p>
</div>
</li>
<li id="S7.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i4.p1" class="ltx_para">
<p id="S7.I1.i4.p1.1" class="ltx_p">Data access permission.</p>
</div>
</li>
</ul>
<p id="S7.SS4.p1.2" class="ltx_p">FL is a promising procedure that safely and collaboratively trains ML models and improves URLLC requirements, especially federated reinforcement learning which is one of the distributed setups that learns the environment across numerous decentralized devices without sharing their private data.</p>
</div>
<div id="S7.SS4.p2" class="ltx_para">
<p id="S7.SS4.p2.1" class="ltx_p">A deep reinforcement model was employed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib238" title="" class="ltx_ref">238</a>]</cite> to develop a multi-level architecture that enables device intelligence, edge intelligence, and cloud intelligence at the user level, cell level, and network level, respectively for URLLC. Considering the computing capacity of each user and each mobile edge computing server is limited, the authors applied FL to improve the learning efficiency.</p>
</div>
<div id="S7.SS4.p3" class="ltx_para">
<p id="S7.SS4.p3.1" class="ltx_p">The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib239" title="" class="ltx_ref">239</a>]</cite> presented a novel distributed, FL-based, joint transmit power and resource allocation framework to improve URLLC in vehicular communication. The extreme value theory was adopted to characterize the constraints in terms of URLLC by estimating the tail distribution locally without sharing the actual queue length samples. This approach reduces the amount of exchanged data and unnecessary overheads.</p>
</div>
<div id="S7.SS4.p4" class="ltx_para">
<p id="S7.SS4.p4.1" class="ltx_p">Addressing URLLC’s scalability and compatibility with other URLLC/non-URLLC services is a big problem. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib240" title="" class="ltx_ref">240</a>]</cite> proposed a hybrid multiple access solution for addressing such issues in a spectrum-/energy-efficient way, by leveraging a distributed hierarchical ML approach for proactive radio resource management to different URLLC traffic streams. Results show the potential of the FL-based scheme that increases 75% data rate and 99.99% reliability for both scheduled and non-scheduled traffic types.</p>
</div>
</section>
<section id="S7.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS5.4.1.1" class="ltx_text">VII-E</span> </span><span id="S7.SS5.5.2" class="ltx_text ltx_font_italic">Tactile Internet</span>
</h3>

<div id="S7.SS5.p1" class="ltx_para">
<p id="S7.SS5.p1.1" class="ltx_p">The tactile internet (TI) is the next step of the internet of things, comprising human-to-machine and machine-to-machine communication. It mainly focuses on providing real-time interactive techniques with a portfolio of engineering, social, and commercial use cases that require a high degree of reliability and latency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib241" title="" class="ltx_ref">241</a>]</cite>. AI techniques will play an important role in addressing TI challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib242" title="" class="ltx_ref">242</a>]</cite>, especially FL which has a huge potential to optimize energy, resources, and transmission delay for tactile internet applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib243" title="" class="ltx_ref">243</a>]</cite>.</p>
</div>
<div id="S7.SS5.p2" class="ltx_para">
<p id="S7.SS5.p2.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib244" title="" class="ltx_ref">244</a>]</cite> used FRL to meet the requirements of B5G mobile communication, especially at the MAC and PHY layers channel access mechanisms that enable URLLC in 5G NR for tactile internet. The FRL is an emerging solution to handle emerging wireless network scenarios since it learns from unlabeled data and avoids the expectation of a formulated Markov decision process to make optimal decisions, routing, and link selection.</p>
</div>
</section>
<section id="S7.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS6.4.1.1" class="ltx_text">VII-F</span> </span><span id="S7.SS6.5.2" class="ltx_text ltx_font_italic">Virtual/Augmented/Extended Reality &amp; Metaverse</span>
</h3>

<div id="S7.SS6.p1" class="ltx_para">
<p id="S7.SS6.p1.1" class="ltx_p">Virtual reality (VR) is a computer-generated environment with realistic-looking scenes and objects that give the user the feeling of being completely immersed in their surroundings. Deploying this new technology over wireless networks is an essential stepping stone towards flexible deployment of pervasive VR applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib245" title="" class="ltx_ref">245</a>]</cite>. Minimizing the occurrence of the break-in presence (BIP) is one of the key challenges in VR that detaches the users from their virtual world. The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib246" title="" class="ltx_ref">246</a>]</cite> designed a novel model that jointly considers the VR application type, transmission delay, VR video quality, and users’ awareness of the virtual environment to measure the BIP for wireless VR users. They adopted an FL strategy to enable multiple BSs to locally train their model using the gathered data and cooperatively build a global model to predict the entire users’ locations and orientations. Compared to centralized approaches, this method achieves significant performance by reducing the users’ BIP.</p>
</div>
<div id="S7.SS6.p2" class="ltx_para">
<p id="S7.SS6.p2.1" class="ltx_p">Augmented reality (AR) is an enhanced version of the real physical world that is achieved using digital visual elements, sound, or other sensory stimuli delivered via technology. Driven by computer vision and AI tools, AR technology has shown a strong momentum of development <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib247" title="" class="ltx_ref">247</a>]</cite>. However, the bandwidth available to transmit and process large amounts of generated data is extremely limited, making it extremely difficult for AR to detect and classify objects and achieve their goals of perfectly combining the corresponding virtual contents with the real world. To solve the classification challenge for latency-sensitive AR applications that require a high data rate, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib248" title="" class="ltx_ref">248</a>]</cite> proposed a framework that combines FL with mobile edge computing (MEC) to obtain the global optimal ML model. Evaluations show that the presented approach requires significantly fewer training iterations compared to traditional centralized frameworks. To solve the privacy issues in AR, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib249" title="" class="ltx_ref">249</a>]</cite> proposed a multi-user AR output strategy model using a hierarchical federated reinforcement learning method for generating and aggregating the AR output strategy model for multiple users. This framework effectively learns the information of multi-user AR scenarios and improves the robustness of the adaptive output strategy model.</p>
</div>
<div id="S7.SS6.p3" class="ltx_para">
<p id="S7.SS6.p3.1" class="ltx_p">Extended reality (XR) refers to all real and virtual environments and human-machine interactions generated by computer technology and wearable devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib250" title="" class="ltx_ref">250</a>]</cite>. XR technologies collect and process huge amounts of detailed and personal data about users, FL is a promising method to handle such challenges while reducing costs and preserving dispersed datasets. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib251" title="" class="ltx_ref">251</a>]</cite> investigated distributed FL methods in V2X networks for augmenting the capability of road user/object classification based on Lidar data, where the model sharing is implemented on a large number of layers, depending on the required efficiency and bandwidth requirements.</p>
</div>
<div id="S7.SS6.p4" class="ltx_para">
<p id="S7.SS6.p4.1" class="ltx_p">The metaverse refers to a virtual shared space, often encompassing AR, VR, XR, and other immersive digital environments. It’s an interconnected digital universe where users interact, socialize, work, and engage in a wide range of activities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib252" title="" class="ltx_ref">252</a>]</cite>. Applying FL to the metaverse protects the data privacy of clients and reduces the need for high computing power and
high memory on servers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib253" title="" class="ltx_ref">253</a>]</cite>.</p>
</div>
</section>
<section id="S7.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS7.4.1.1" class="ltx_text">VII-G</span> </span><span id="S7.SS7.5.2" class="ltx_text ltx_font_italic">Smart Healthcare</span>
</h3>

<div id="S7.SS7.p1" class="ltx_para">
<p id="S7.SS7.p1.1" class="ltx_p">ML and DL techniques have shown potential for accelerating the advancement of smart healthcare. However, in several healthcare situations, the limited amount of data available does not allow for building very powerful models to investigate the existing challenges. To this end, FL is employed to allow medical institutions to share their experiences, and not their data, with a guarantee of privacy to safely perform personalized healthcare and biomedical tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib254" title="" class="ltx_ref">254</a>, <a href="#bib.bib255" title="" class="ltx_ref">255</a>]</cite>.</p>
</div>
<div id="S7.SS7.p2" class="ltx_para">
<p id="S7.SS7.p2.1" class="ltx_p">The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib256" title="" class="ltx_ref">256</a>]</cite> developed the FedHealth framework using FTL that aggregates the data from the distributed organizations to train powerful ML algorithms while preserving client privacy. Following the initial training of a global model in the cloud, FedHealth leverages transfer learning to create personalized models for each organization. These personalized models are continually updated by transmitting the modified global model parameters back to the respective organizations.</p>
</div>
<div id="S7.SS7.p3" class="ltx_para">
<p id="S7.SS7.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib257" title="" class="ltx_ref">257</a>]</cite>, the authors proposed an edge computing-empowered FL-based system model to facilitate privacy-preserving collaborative model training across distributed participants for the development of healthcare applications. The result of the present approach shows that the contract design is self-revealing across two time periods and returns higher profits for the model owner as compared to the uniform strategy.</p>
</div>
<div id="S7.SS7.p4" class="ltx_para">
<p id="S7.SS7.p4.1" class="ltx_p">The clustered FL was adopted in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib258" title="" class="ltx_ref">258</a>]</cite> to develop an automatic diagnosis system for the COVID-19 pandemic. This approach allows remote healthcare institutions to benefit from collaborative learning without sharing local data and associated information.</p>
</div>
</section>
<section id="S7.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS8.4.1.1" class="ltx_text">VII-H</span> </span><span id="S7.SS8.5.2" class="ltx_text ltx_font_italic">Recommendation Systems</span>
</h3>

<div id="S7.SS8.p1" class="ltx_para">
<p id="S7.SS8.p1.1" class="ltx_p">Recommendation systems in wireless networks play a significant role in enhancing user experiences, optimizing network resource allocation, and improving overall network efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib259" title="" class="ltx_ref">259</a>]</cite>. Implementing efficient recommendation systems in wireless networks requires a combination of data analytics, ML algorithms, and real-time data processing. This encompasses the collection and analysis of user behavior, network performance metrics, and contextual data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib260" title="" class="ltx_ref">260</a>]</cite>.
FL has recently been applied to recommendation systems to protect user privacy and boost prediction accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib261" title="" class="ltx_ref">261</a>]</cite>. In FL settings, recommendation systems train recommendation models by collecting the intermediate parameters instead of the real user data, which greatly enhances user privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib262" title="" class="ltx_ref">262</a>]</cite>. A privacy-preserved recommender system framework was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib263" title="" class="ltx_ref">263</a>]</cite> by integrating FL architecture to enable the recommendation algorithm to be trained and carry out inference without centrally collecting users’ private data. This approach reduces the privacy leakage risk, satisfies legal and regulatory requirements, and allows various recommendation algorithms to be applied.</p>
</div>
<figure id="S7.T8" class="ltx_table">
<table id="S7.T8.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T8.1.1.1" class="ltx_tr">
<th id="S7.T8.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_ll ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.1.1.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S7.T8.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref</span></span>
</span>
</th>
<th id="S7.T8.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.1.1.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S7.T8.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Application</span></span>
</span>
</th>
<th id="S7.T8.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.1.1.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S7.T8.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Benefits</span></span>
</span>
</th>
<th id="S7.T8.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_rr ltx_border_t" style="padding-bottom:2.15277pt;padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.1.1.4.1.1" class="ltx_p" style="width:142.3pt;"><span id="S7.T8.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Drawbacks</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T8.1.2.1" class="ltx_tr">
<td id="S7.T8.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.2.1.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib219" title="" class="ltx_ref">219</a>, <a href="#bib.bib220" title="" class="ltx_ref">220</a>, <a href="#bib.bib221" title="" class="ltx_ref">221</a>, <a href="#bib.bib222" title="" class="ltx_ref">222</a>, <a href="#bib.bib223" title="" class="ltx_ref">223</a>, <a href="#bib.bib224" title="" class="ltx_ref">224</a>]</cite></span>
</span>
</td>
<td id="S7.T8.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.2.1.2.1.1" class="ltx_p" style="width:85.4pt;">Autonomous driving</span>
</span>
</td>
<td id="S7.T8.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.2.1.3.1.1" class="ltx_p" style="width:142.3pt;">Achieving potential learning across several decentralized vehicles by only sharing local model parameters</span>
</span>
</td>
<td id="S7.T8.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.2.1.4.1.1" class="ltx_p" style="width:142.3pt;">Need to limit the increase in the overall delay and avoid the privacy leakage risk</span>
</span>
</td>
</tr>
<tr id="S7.T8.1.3.2" class="ltx_tr">
<td id="S7.T8.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.3.2.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib225" title="" class="ltx_ref">225</a>, <a href="#bib.bib226" title="" class="ltx_ref">226</a>, <a href="#bib.bib227" title="" class="ltx_ref">227</a>, <a href="#bib.bib228" title="" class="ltx_ref">228</a>]</cite></span>
</span>
</td>
<td id="S7.T8.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.3.2.2.1.1" class="ltx_p" style="width:85.4pt;">Anomaly detection</span>
</span>
</td>
<td id="S7.T8.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.3.2.3.1.1" class="ltx_p" style="width:142.3pt;">Improving the scalability of malicious attacks detection for distributed wireless communication networks</span>
</span>
</td>
<td id="S7.T8.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.3.2.4.1.1" class="ltx_p" style="width:142.3pt;">The training phase should be optimized in terms of weights communicating and performance</span>
</span>
</td>
</tr>
<tr id="S7.T8.1.4.3" class="ltx_tr">
<td id="S7.T8.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.4.3.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib238" title="" class="ltx_ref">238</a>, <a href="#bib.bib239" title="" class="ltx_ref">239</a>, <a href="#bib.bib240" title="" class="ltx_ref">240</a>]</cite></span>
</span>
</td>
<td id="S7.T8.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.4.3.2.1.1" class="ltx_p" style="width:85.4pt;">URLLC</span>
</span>
</td>
<td id="S7.T8.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.4.3.3.1.1" class="ltx_p" style="width:142.3pt;">Decreasing service delay and providing high reliability while preserving user’s information</span>
</span>
</td>
<td id="S7.T8.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.4.3.4.1.1" class="ltx_p" style="width:142.3pt;">Cannot handle the non-IID training data and a large number of connected devices</span>
</span>
</td>
</tr>
<tr id="S7.T8.1.5.4" class="ltx_tr">
<td id="S7.T8.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.5.4.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib244" title="" class="ltx_ref">244</a>]</cite></span>
</span>
</td>
<td id="S7.T8.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.5.4.2.1.1" class="ltx_p" style="width:85.4pt;">Tactile internet</span>
</span>
</td>
<td id="S7.T8.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.5.4.3.1.1" class="ltx_p" style="width:142.3pt;">Achieving intelligent and optimized network control and resource allocation for URLLC requirements</span>
</span>
</td>
<td id="S7.T8.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.5.4.4.1.1" class="ltx_p" style="width:142.3pt;">Each device must learn the optimal decision with the help of exploration</span>
</span>
</td>
</tr>
<tr id="S7.T8.1.6.5" class="ltx_tr">
<td id="S7.T8.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.6.5.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib246" title="" class="ltx_ref">246</a>, <a href="#bib.bib248" title="" class="ltx_ref">248</a>, <a href="#bib.bib249" title="" class="ltx_ref">249</a>, <a href="#bib.bib251" title="" class="ltx_ref">251</a>]</cite></span>
</span>
</td>
<td id="S7.T8.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.6.5.2.1.1" class="ltx_p" style="width:85.4pt;">VR/AR/XR and Metaverse</span>
</span>
</td>
<td id="S7.T8.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.6.5.3.1.1" class="ltx_p" style="width:142.3pt;">Improving the generation of virtual objects by optimizing the resource management and reducing the overall latency for VR/AR users</span>
</span>
</td>
<td id="S7.T8.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.6.5.4.1.1" class="ltx_p" style="width:142.3pt;">The security problems caused by non-visual output along with the conflict between multiple output types</span>
</span>
</td>
</tr>
<tr id="S7.T8.1.7.6" class="ltx_tr">
<td id="S7.T8.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.7.6.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib256" title="" class="ltx_ref">256</a>, <a href="#bib.bib257" title="" class="ltx_ref">257</a>, <a href="#bib.bib258" title="" class="ltx_ref">258</a>]</cite></span>
</span>
</td>
<td id="S7.T8.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.7.6.2.1.1" class="ltx_p" style="width:85.4pt;">Smart healthcare</span>
</span>
</td>
<td id="S7.T8.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.7.6.3.1.1" class="ltx_p" style="width:142.3pt;">Allowing organizations to benefit securely from distributed medical experiences</span>
</span>
</td>
<td id="S7.T8.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.7.6.4.1.1" class="ltx_p" style="width:142.3pt;">Must explore the performance in varied distributed data to enhance efficiency and flexibility</span>
</span>
</td>
</tr>
<tr id="S7.T8.1.8.7" class="ltx_tr">
<td id="S7.T8.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_ll ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.8.7.1.1.1" class="ltx_p" style="width:85.4pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib260" title="" class="ltx_ref">260</a>, <a href="#bib.bib261" title="" class="ltx_ref">261</a>, <a href="#bib.bib262" title="" class="ltx_ref">262</a>, <a href="#bib.bib263" title="" class="ltx_ref">263</a>]</cite></span>
</span>
</td>
<td id="S7.T8.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.8.7.2.1.1" class="ltx_p" style="width:85.4pt;">Recommendation system</span>
</span>
</td>
<td id="S7.T8.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.8.7.3.1.1" class="ltx_p" style="width:142.3pt;">Training a distributed recommender system while protecting user privacy</span>
</span>
</td>
<td id="S7.T8.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_rr ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S7.T8.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T8.1.8.7.4.1.1" class="ltx_p" style="width:142.3pt;">The communication between the user and the server leads to increased overhead and latency</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VIII: </span>Summary of FL-based verticals and applications.</figcaption>
</figure>
</section>
<section id="S7.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS9.4.1.1" class="ltx_text">VII-I</span> </span><span id="S7.SS9.5.2" class="ltx_text ltx_font_italic">Summary</span>
</h3>

<div id="S7.SS9.p1" class="ltx_para">
<p id="S7.SS9.p1.1" class="ltx_p">In this section, we have presented a comprehensive summary of the latest research related to FL in 6G systems. We have focused on highlighting the pivotal enhancements gained through the adoption of FL in contrast to centralized ML. A summarized overview is found in Table <a href="#S7.T8" title="TABLE VIII ‣ VII-H Recommendation Systems ‣ VII Federated Learning Applications &amp; Verticals ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VIII</span></a>.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Insights and Open Problems</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">FL has gained tremendous interest in wireless communication networks, providing better and safer methods that effectively enhance mobile operations. Lately, numerous substantial FL-based advances in wireless systems have been developed promising a wide deployment in future 6G. However, FL is still a nascent research with several challenging issues such as to privacy and security risks, data scarcity/quality, system heterogeneity, complexity, and convergence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib264" title="" class="ltx_ref">264</a>]</cite>. In this section, we discuss open problems of FL and provide a summary of recent solutions, insights, and opportunities.</p>
</div>
<figure id="S8.F6" class="ltx_figure"><img src="/html/2312.04688/assets/x6.png" id="S8.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="315" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Year-wise publications of FL for mobile networks [generated from all cited papers].</figcaption>
</figure>
<figure id="S8.F7" class="ltx_figure"><img src="/html/2312.04688/assets/Figure7.png" id="S8.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="559" height="407" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Proportion of FL-based approaches per network layer [generated from all cited papers].</figcaption>
</figure>
<section id="S8.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S8.SS1.4.1.1" class="ltx_text">VIII-A</span> </span><span id="S8.SS1.5.2" class="ltx_text ltx_font_italic">Lessons Learned</span>
</h3>

<div id="S8.SS1.p1" class="ltx_para">
<p id="S8.SS1.p1.1" class="ltx_p">In this tutorial, we compiled, classified, and carefully analyzed recent results and pioneering research breakthroughs related to FL. As illustrated in Fig. <a href="#S8.F6" title="Figure 6 ‣ VIII Insights and Open Problems ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, the number of FL learning contributions in mobile networks has grown steadily over the past seven years, and widely applied to network design, as visualized in Fig. <a href="#S8.F7" title="Figure 7 ‣ VIII Insights and Open Problems ‣ Federated Learning for 6G: Paradigms, Taxonomy, Recent Advances and Insights" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. Indeed, FL leverages efficient and effective solutions compared to traditional AI techniques to handle wireless problems while preserving privacy. To sum up, the lessons learned from our study are:</p>
<ul id="S8.I1" class="ltx_itemize">
<li id="S8.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I1.i1.p1" class="ltx_para">
<p id="S8.I1.i1.p1.1" class="ltx_p">6G and beyond call for high network flexibility, reliability, privacy, and intelligence. Those desired features are efficiently and effectively provided by FL approaches.</p>
</div>
</li>
<li id="S8.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I1.i2.p1" class="ltx_para">
<p id="S8.I1.i2.p1.1" class="ltx_p">FL has the potential to shape next-generation wireless systems by enhancing the protocol stack and meeting future demands of data-intensive applications. By incorporating FL across multiple network layers, wireless systems will benefit from fundamental values such as sustainability, trustworthiness, fairness, reduced communication overhead, high resilience and neverseen degree of versatility.</p>
</div>
</li>
<li id="S8.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I1.i3.p1" class="ltx_para">
<p id="S8.I1.i3.p1.1" class="ltx_p">FL support by wireless networks has the potential to revolutionize several industries, from healthcare and manufacturing to smart cities and smart farming, as it enables novel personalized services, efficient resource management, and data-driven decision-making.</p>
</div>
</li>
<li id="S8.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I1.i4.p1" class="ltx_para">
<p id="S8.I1.i4.p1.1" class="ltx_p">FL is speculated to be a transformative approach for the evolution of future wireless communication systems. However, challenges like communication efficiency, model aggregation, and security still need to be addressed to fully harness FL potential in 6G and future wireless networks. Integrating FL into the design loop of future networks will redefine their capabilities in terms of performance, privacy, resilience, and intelligence.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S8.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S8.SS2.4.1.1" class="ltx_text">VIII-B</span> </span><span id="S8.SS2.5.2" class="ltx_text ltx_font_italic">Federated Learning Challenges</span>
</h3>

<div id="S8.SS2.p1" class="ltx_para">
<p id="S8.SS2.p1.1" class="ltx_p">Through our systematic review of existing literature, we have identified some primary bottlenecks that dominate current FL research:</p>
</div>
<section id="S8.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS2.SSS1.4.1.1" class="ltx_text">VIII-B</span>1 </span>Privacy and Security</h4>

<div id="S8.SS2.SSS1.p1" class="ltx_para">
<p id="S8.SS2.SSS1.p1.1" class="ltx_p">Contrary to decentralized schemes, federated learning was designed to provide a secure machine learning among distributed learning agents. However, data privacy is still challenging due to the presence of attackers such as on-device malicious clients to malicious users with only a black-box access to the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib265" title="" class="ltx_ref">265</a>]</cite>. Although local data might not escape the device, an intruder still can learn the presence of a data point used for training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. Many efforts have been spent to deal with this issue using transfer ML, secure aggregation, and attack recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib266" title="" class="ltx_ref">266</a>, <a href="#bib.bib267" title="" class="ltx_ref">267</a>]</cite>.</p>
</div>
</section>
<section id="S8.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS2.SSS2.4.1.1" class="ltx_text">VIII-B</span>2 </span>Complexity and Convergence</h4>

<div id="S8.SS2.SSS2.p1" class="ltx_para">
<p id="S8.SS2.SSS2.p1.1" class="ltx_p">Federated learning suffers from high computational complexity during training due to running consensus algorithms over heterogeneous massive environments over perturbed/faulty communication systems. It includes a large number of handsets with data generated ruled by diverse distributions, which results in high communication overhead. The goal of FL is to train high-quality models with lower communication complexity and faster convergence, hence it is crucial to design efficient schemes to overcome such a limitation. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib268" title="" class="ltx_ref">268</a>]</cite>, two solutions were designed to reduce uplink communication costs: learning an update directly from a reduced set of variables, and learning a complete model update and compressing it before sending it to the server. Based on gradient descent, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib269" title="" class="ltx_ref">269</a>]</cite> analyzed the convergence bound for FL with non-IID datasets. Other researches were proposed for uplink and downlink transmission to improve the convergence time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib270" title="" class="ltx_ref">270</a>, <a href="#bib.bib271" title="" class="ltx_ref">271</a>, <a href="#bib.bib272" title="" class="ltx_ref">272</a>, <a href="#bib.bib273" title="" class="ltx_ref">273</a>]</cite>.</p>
</div>
</section>
<section id="S8.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS2.SSS3.4.1.1" class="ltx_text">VIII-B</span>3 </span>Client Selection</h4>

<div id="S8.SS2.SSS3.p1" class="ltx_para">
<p id="S8.SS2.SSS3.p1.1" class="ltx_p">FL clients execute limited number of training iterations using local update parameters and only exchange model updates with the aggregating server. The number of agents is sufficiently large and the bandwidth available for model update distribution is limited. Thus, it is practical to select the best subset of clients in the training stage, as client selection policy is critical to FL in terms of training efficiency and global model quality. Manifestly, the client nodes generate highly heterogeneous local datasets and handle different computation capabilities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib274" title="" class="ltx_ref">274</a>]</cite>, which affects the global model convergence. The FL framework has to be robust to devise dropout and anticipate the scenarios where only a small number of participants are left connected to participate in a training iteration. Several research activities were devoted to bridge this gap. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib275" title="" class="ltx_ref">275</a>]</cite>, the authors design a client selection framework that flexibly spans the trade-off between convergence speed and solution bias. They demonstrate that biasing client selection towards clients with higher local loss achieves faster error convergence. Tang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib276" title="" class="ltx_ref">276</a>]</cite> use the correlations between clients to achieve a faster and more stable convergence in heterogeneous scenarios. Furthermore, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib277" title="" class="ltx_ref">277</a>]</cite>, the authors propose a client selection mechanism that allows the server to pick the clients that can participate based on their available resources. The server decides on the amount of data, energy, and CPU resources required to take part in each round. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib278" title="" class="ltx_ref">278</a>]</cite>, a delay-constrained client selection framework is proposed for heterogeneous FL in intelligent transportation systems, aiming to improve the model accuracy, training speed, and transmission time. Further, reinforcement learning is deployed to improve client selection performance by involving a reinforcement learning agent that learns a client selection policy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib279" title="" class="ltx_ref">279</a>]</cite>. Also, a multi-armed bandit model is used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib280" title="" class="ltx_ref">280</a>]</cite> for client selection to boost volatile FL by speeding up model convergence, promoting model accuracy, and reducing energy consumption. Alternatively, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib281" title="" class="ltx_ref">281</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib282" title="" class="ltx_ref">282</a>]</cite> propose a client selection method using a genetic algorithm based on the client’s cost and the model accuracy. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib283" title="" class="ltx_ref">283</a>]</cite>, the authors present the client selection as a game where the clients express their interest in participating in the FL process.</p>
</div>
</section>
<section id="S8.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS2.SSS4.4.1.1" class="ltx_text">VIII-B</span>4 </span>Fairness &amp; Role Distribution</h4>

<div id="S8.SS2.SSS4.p1" class="ltx_para">
<p id="S8.SS2.SSS4.p1.1" class="ltx_p">FL systems are designed to train distributed models using decentralized and private local training data, which requires to assess the mid/long-term training robustness and resilience. Most of current techniques combine models and prioritize them proportionately to the frequency of local samples. However, the question of role distribution between FL participants remains unsolved and calls for implementing high fairness, this was examined from the perspective of ensuring accuracy across clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib284" title="" class="ltx_ref">284</a>]</cite>. Numerous works employ robust approaches to address fairness, including <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib285" title="" class="ltx_ref">285</a>, <a href="#bib.bib286" title="" class="ltx_ref">286</a>, <a href="#bib.bib287" title="" class="ltx_ref">287</a>]</cite>, the authors tried to improve the overall fairness without compromising the predictive performance using zero-shot data augmentation, Lyapunov optimization, and participants reputation, respectively. The research preented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib288" title="" class="ltx_ref">288</a>]</cite> introduces federated fair averaging to mitigate potential conflicts among clients before averaging their gradients. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib282" title="" class="ltx_ref">282</a>]</cite>, the authors propose an FL framework that uses a genetic algorithm to ensure fairness and improve the volume and heterogeneity of data in the FL process. Another approach for fair client selection is presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib289" title="" class="ltx_ref">289</a>]</cite>, which uses a dynamic multi-criteria scheme to promote fairness among clients in each round of the FL process.</p>
</div>
</section>
<section id="S8.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS2.SSS5.4.1.1" class="ltx_text">VIII-B</span>5 </span>Data quality</h4>

<div id="S8.SS2.SSS5.p1" class="ltx_para">
<p id="S8.SS2.SSS5.p1.1" class="ltx_p">The data quality in FL is a critical factor that directly impacts the accuracy, reliability, and performance of the trained models. Maintaining high data quality for FL is a multifaceted challenge that requires careful considerations:</p>
<ul id="S8.I2" class="ltx_itemize">
<li id="S8.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I2.i1.p1" class="ltx_para">
<p id="S8.I2.i1.p1.1" class="ltx_p"><em id="S8.I2.i1.p1.1.1" class="ltx_emph ltx_font_italic">Data heterogeneity:</em> In real-world, i.i.d. assumption does not hold as data sources may experience spatial or temporal correlations, which may lead to convergence or accuracy inefficiencies and serious fairness issues. Data heterogeneity is mainly due to variations in data distribution, format, and quality. Addressing these differences and ensuring representative data from all devices is crucial reliable training.</p>
</div>
</li>
<li id="S8.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I2.i2.p1" class="ltx_para">
<p id="S8.I2.i2.p1.1" class="ltx_p"><em id="S8.I2.i2.p1.1.1" class="ltx_emph ltx_font_italic">Data labeling:</em> For supervised learning tasks, inconsistent labeling across devices may lead to biased models and erroneous predictions.</p>
</div>
</li>
<li id="S8.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I2.i3.p1" class="ltx_para">
<p id="S8.I2.i3.p1.1" class="ltx_p"><em id="S8.I2.i3.p1.1.1" class="ltx_emph ltx_font_italic">Imbalanced data:</em> Handling data imbalance in FL is essential to ensure generalization and fair representation across all classes.</p>
</div>
</li>
<li id="S8.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I2.i4.p1" class="ltx_para">
<p id="S8.I2.i4.p1.1" class="ltx_p"><em id="S8.I2.i4.p1.1.1" class="ltx_emph ltx_font_italic">Data freshness:</em> Ensuring data freshness is crucial to capture recent trends, patterns, real-time changes, and user behaviors. Meanwhile, network latency, communication overhead, and battery consumption are to be addressed for efficient data freshness and communication trade-offs.</p>
</div>
</li>
<li id="S8.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I2.i5.p1" class="ltx_para">
<p id="S8.I2.i5.p1.1" class="ltx_p"><em id="S8.I2.i5.p1.1.1" class="ltx_emph ltx_font_italic">Data Regulation:</em> To comply with data storage/processing location, protection regulations, and other constraints, FL systems have to consider legal and ethical aspects in the whole data value chain.</p>
</div>
</li>
</ul>
<p id="S8.SS2.SSS5.p1.2" class="ltx_p">The framework introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib290" title="" class="ltx_ref">290</a>]</cite> combines FL and blockchain to ensure high data quality for complex ML tasks while increasing the accuracy of the trained models. Moreover, employing pre-processing techniques, local validation, and rigorous aggregation strategies contribute to maintaining data quality and fostering more robust and dependable FL models.</p>
</div>
</section>
</section>
<section id="S8.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S8.SS3.4.1.1" class="ltx_text">VIII-C</span> </span><span id="S8.SS3.5.2" class="ltx_text ltx_font_italic">Wireless Challenges for Federated Learning</span>
</h3>

<div id="S8.SS3.p1" class="ltx_para">
<p id="S8.SS3.p1.1" class="ltx_p">To train FL algorithms, all participants must transmit their training parameters over a shared network which require to face several important communication issues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib291" title="" class="ltx_ref">291</a>]</cite>. In this section, we present the main problems related to the implementation of FL over wireless environments.</p>
</div>
<section id="S8.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS3.SSS1.4.1.1" class="ltx_text">VIII-C</span>1 </span>Resource Constraints</h4>

<div id="S8.SS3.SSS1.p1" class="ltx_para">
<p id="S8.SS3.SSS1.p1.1" class="ltx_p">Wireless devices are usually equipped with limited hardware and software capabilities, which may drastically affect the local model training efficiency and the whole FL feasibility. Namely, the FL may experience a loss of efficiency due to the following specific aspects:</p>
<ul id="S8.I3" class="ltx_itemize">
<li id="S8.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I3.i1.p1" class="ltx_para">
<p id="S8.I3.i1.p1.1" class="ltx_p"><span id="S8.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Computational power:</span> Most of mobile handsets and IoT devices have limited computational capabilities, which affects their ability to perform complex model updates and heavy local training. This way, the so called stragglers with low processing capabilities may lower the training quality and slow the overall federated learning process. Therefore, it is fo paramount importance to elaborate policies to handle stragglers, such as strategic redundancy or per-client weighting.</p>
</div>
</li>
<li id="S8.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I3.i2.p1" class="ltx_para">
<p id="S8.I3.i2.p1.1" class="ltx_p"><span id="S8.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Memory limitations:</span> The low amount of memory installed on devices restricts the size of the models they can handle and increase the processing time. Therefore, only lightweight model training and/or low-moderate accuracy may be supported.</p>
</div>
</li>
<li id="S8.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I3.i3.p1" class="ltx_para">
<p id="S8.I3.i3.p1.1" class="ltx_p"><span id="S8.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Wireless context:</span> Transmitting model updates and gradients over wireless requires efficient bandwidth allocation to deal with the channel variability. Devices suffering from uncontrolled/unpredictable wireless context may experience poor communication experience, leading to unbounded delays and communication overhead in particular under large models or frequent updates.</p>
</div>
</li>
<li id="S8.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I3.i4.p1" class="ltx_para">
<p id="S8.I3.i4.p1.1" class="ltx_p"><span id="S8.I3.i4.p1.1.1" class="ltx_text ltx_font_bold">Energy Considerations:</span> Running mobile handsets and IoT sensors faces a serious energy constraints due to limited battery life. Indeed, intensive model training tasks may lead to rapid battery depletion, affecting the FL robustness and user experience afterwards. Then, it is of utmost importance to design energy-efficient model update mechanisms and green communication strategies to sustain a satisfactory learning experience.</p>
</div>
</li>
</ul>
<p id="S8.SS3.SSS1.p1.2" class="ltx_p">Abovementioned limitations impact the effectiveness, efficiency, and feasibility of implementing FL over wireless network systems. Numerous works (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib292" title="" class="ltx_ref">292</a>, <a href="#bib.bib293" title="" class="ltx_ref">293</a>]</cite>) explored techniques such as model compression, federated optimization strategies, and adaptive learning algorithms tailored to resource-constrained devices to balance the model accuracy and resource efficiency while enabling effective participation of a diverse range of devices in the FL ecosystem.</p>
</div>
</section>
<section id="S8.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS3.SSS2.4.1.1" class="ltx_text">VIII-C</span>2 </span>Federated Learning Over Wireless</h4>

<div id="S8.SS3.SSS2.p1" class="ltx_para">
<p id="S8.SS3.SSS2.p1.1" class="ltx_p">Wireless links introduce additional challenges when transmitting model updates and data from/to participating devices to/from the central server in an FL framework. Symbol errors introduced by the unreliable nature of the wireless channel impact the quality and correctness of the FL updates among users and affect the performance of FL algorithms, as well as their convergence speed. To address the inherently unreliable connectivity in FL, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib294" title="" class="ltx_ref">294</a>, <a href="#bib.bib295" title="" class="ltx_ref">295</a>]</cite> consider error correction coding, adaptive modulation and coding schemes, robust aggregation algorithms, and the use of redundant data transmission. These approaches aim to ensure that the FL process continues running effectively even under faulty wireless communications.</p>
</div>
</section>
<section id="S8.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS3.SSS3.4.1.1" class="ltx_text">VIII-C</span>3 </span>Over-the-Air Data Aggregation</h4>

<div id="S8.SS3.SSS3.p1" class="ltx_para">
<p id="S8.SS3.SSS3.p1.1" class="ltx_p">Over-the-air computation offers the advantage of low resource consumption since the BS only needs to handle functions uploaded by users rather than dealing with individual data. FL implementing over-the-air aggregation enables users to share the same spectral resources, resulting in communication efficiency enhancement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib296" title="" class="ltx_ref">296</a>]</cite>. However, several works such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib297" title="" class="ltx_ref">297</a>, <a href="#bib.bib298" title="" class="ltx_ref">298</a>]</cite> have examined the impact of the channel time variations on the convergence of the FL with over-the-air aggregation, and show that the resulting undesired interference has only limited destructive effects, which do not prevent the convergence of the learning algorithm. Furthermore, other issues should be addressed such as model distortion caused by channel fading, inefficient over-the-air aggregation of locally trained models with significant data imbalances, and the constrained availability and verification of individual local models.</p>
</div>
</section>
</section>
<section id="S8.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S8.SS4.4.1.1" class="ltx_text">VIII-D</span> </span><span id="S8.SS4.5.2" class="ltx_text ltx_font_italic">Hot Topics and Insights</span>
</h3>

<div id="S8.SS4.p1" class="ltx_para">
<p id="S8.SS4.p1.1" class="ltx_p">In this section, we provide a broad overview of the hot topics that still need addressed for meaningful FL. We also outline several directions of future work with continuingly high interest for a wide range of research communities.</p>
</div>
<section id="S8.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS4.SSS1.4.1.1" class="ltx_text">VIII-D</span>1 </span>FL and Edge Computing/Networking</h4>

<div id="S8.SS4.SSS1.p1" class="ltx_para">
<p id="S8.SS4.SSS1.p1.1" class="ltx_p">Combining FL and edge computing promises to handle the massive amount of data securely gathered from ubiquitous mobile devices. Edge computing refers to situations in which user nodes have computational and/or storage capability but need edge help for coordination or to offload the most computationally intensive activities. FL has long been recognized as an excellent match for edge-hosted applications, and numerous research efforts have aimed to make it as efficient as possible <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib299" title="" class="ltx_ref">299</a>]</cite>. Nevertheless, the interaction between FL and edge computing/networking is becoming an open battlefield with several issues to solve. First, the nodes connect to the edge-based server using different radio access technologies, which influences the delay experienced while delivering model updates. Second, heterogeneous mobile clients with different capability also affects the FL performance. Therefore, the set of participating clients in the FL process needs to be strategically chosen to communicate effectively. Third, during the exchange of model updates, several clients participate by contributing their on-device training data, and it is difficult to prevent malicious clients from sending fake data to poison the training process which in turn poisons the model or the received model gradient parameters.</p>
</div>
</section>
<section id="S8.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS4.SSS2.4.1.1" class="ltx_text">VIII-D</span>2 </span>FL for 6G applications</h4>

<div id="S8.SS4.SSS2.p1" class="ltx_para">
<p id="S8.SS4.SSS2.p1.1" class="ltx_p">Future 6G applications are expected to generate and handle large amounts of data, such as extended reality (XR), mixed reality (MR), wireless brain-computer interactions, hologram communications, tactile internet, mURLLC, XURLLC, and other use cases that require high QoE, astonishing reliability and extremely low latency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib300" title="" class="ltx_ref">300</a>]</cite>. Federated ML schemes are highly recommended to obtain greater learning and secure communication between distributed devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib301" title="" class="ltx_ref">301</a>]</cite>. However, new concerns arise when applying FL for emerging technologies, essentially the convergence analysis that is affected by the large propagation attenuation in THz and the optimization of the parameters for quantum key distribution to name a few.</p>
</div>
</section>
<section id="S8.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS4.SSS3.4.1.1" class="ltx_text">VIII-D</span>3 </span>FL meets Blockchain</h4>

<div id="S8.SS4.SSS3.p1" class="ltx_para">
<p id="S8.SS4.SSS3.p1.1" class="ltx_p">Blockchain technology combines encryption with distributed computing to improve the privacy of decentralized networks while cutting down the need for a central authority. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib302" title="" class="ltx_ref">302</a>, <a href="#bib.bib303" title="" class="ltx_ref">303</a>]</cite>, it has beeb shown that implementing FL and blockchain helps automating energy transfers and allows autonomous energy providers to safely trade value <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib304" title="" class="ltx_ref">304</a>]</cite>. Additionally, game theoretic tools may help FL to substantially reduce communications among distributed wireless networks and address the fundamental problems of large-scale distributed and privacy-preserving learning algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib305" title="" class="ltx_ref">305</a>, <a href="#bib.bib306" title="" class="ltx_ref">306</a>]</cite>. Local federated learners are the players and the aggregation of the received gradients in a central server is the mean-field game effect. Adopting incentive mechanisms via blockchain and game theory helps distributed systems exploring the user’s habits and preferences, assessing and improving the relevance of online search engines.</p>
</div>
</section>
<section id="S8.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS4.SSS4.4.1.1" class="ltx_text">VIII-D</span>4 </span>Federated Distillation</h4>

<div id="S8.SS4.SSS4.p1" class="ltx_para">
<p id="S8.SS4.SSS4.p1.1" class="ltx_p">Despite being communication-efficient, FL still requires the transmission of extensive models from large number of clients through the air. FL
has well-known limits, such as:</p>
<ul id="S8.I4" class="ltx_itemize">
<li id="S8.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I4.i1.p1" class="ltx_para">
<p id="S8.I4.i1.p1.1" class="ltx_p">Clients must implement the same model architecture;</p>
</div>
</li>
<li id="S8.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I4.i2.p1" class="ltx_para">
<p id="S8.I4.i2.p1.1" class="ltx_p">Transmitting the huge model weights and updates implies high communication costs;</p>
</div>
</li>
<li id="S8.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S8.I4.i3.p1" class="ltx_para">
<p id="S8.I4.i3.p1.1" class="ltx_p">Parameter-averaging aggregation schemes perform poorly due to client model drifts.</p>
</div>
</li>
</ul>
<p id="S8.SS4.SSS4.p1.2" class="ltx_p">Knowledge distillation helps overcoming limitations of the parameter-averaging technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib307" title="" class="ltx_ref">307</a>]</cite>. Federated distillation is a process of distilling knowledge from a larger central model to a smaller model on edge devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib308" title="" class="ltx_ref">308</a>]</cite>. Within this process, knowledge is transferred between models by having each model acting as a teacher to the other models. Each model shares its knowledge with the other models, allowing the models to learn from each other and improve their performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib309" title="" class="ltx_ref">309</a>]</cite>. Such a mechanism leads to improved accuracy as more data is implicitly used for training. It also offers improved privacy and security as data is not shared. Moreover, federated distillation exhibits a reduced bandwidth usage due to the distributed training. Likewise, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib310" title="" class="ltx_ref">310</a>]</cite> propose to distill knowledge in the FL process, with key idea relying on exchanging soft targets instead of transferring the model parameters between server and clients. The authors showed that their solution can reduce both communication overhead and computation costs.</p>
</div>
</section>
<section id="S8.SS4.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS4.SSS5.4.1.1" class="ltx_text">VIII-D</span>5 </span>FL for Semantic Communications</h4>

<div id="S8.SS4.SSS5.p1" class="ltx_para">
<p id="S8.SS4.SSS5.p1.1" class="ltx_p">Semantic Communication (SC) is a new paradigm, expected to be a major part of 6G and beyond. It allows to achieve more efficient data processing and transmission considering user expectation and application requirements as well as the semantic/meaning of the data being sent. SC combines natural language processing, AI, and ML to create a powerful and dynamic communication system able to understand the context of the data being processed. Indeed, it allows to build more secure, reliable, and energy-efficient communication networks. In addition, semantic communication is expected to reduce the latency and complexity of data processing, allowing for more efficient data transmission and improved user experience <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib311" title="" class="ltx_ref">311</a>]</cite>. This way, SC is anticipated to support novel applications and services, such as intelligent virtual assistants, smart robots, and autonomous vehicles. However, some SC processes such as semantic detection, knowledge modelling, and coordination, are resource-hungry and may show inefficient behaviors, especially for communication between a source and a destination.</p>
</div>
<div id="S8.SS4.SSS5.p2" class="ltx_para">
<p id="S8.SS4.SSS5.p2.1" class="ltx_p">FL framework addresses this challenge by training a shared model to process the common semantic knowledge without exposing local semantic data from each edge server. Instead, the edge servers collaborate by exchanging intermediate model training results. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib312" title="" class="ltx_ref">312</a>]</cite>, a federated ML is used to support resource-efficient semantic-aware networking. The proposed solution allows each user to offload computationally intensive semantic encoding and decoding tasks to edge servers, while it protects its own model-related information by coordinating via intermediate results.</p>
</div>
</section>
<section id="S8.SS4.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS4.SSS6.4.1.1" class="ltx_text">VIII-D</span>6 </span>FL and Energy Efficiency</h4>

<div id="S8.SS4.SSS6.p1" class="ltx_para">
<p id="S8.SS4.SSS6.p1.1" class="ltx_p">Energy efficiency is critical to build sustainable 6G and next generations of mobile networks. Inline with this goal, the energy consumption of FL during the training process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib313" title="" class="ltx_ref">313</a>]</cite> must be carefully optimized and underlying schemes must be energy-aware designed. It is understood, FL is more energy-efficient than traditional centralized learning approaches, but there are still several energy wasting operations to be rethought for green learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib314" title="" class="ltx_ref">314</a>]</cite>. First, the distributed nature of FL requires more computing resources, which may results in increased energy consumption. Second, FL might require data to be transferred across devices/edge/cloud, leading to increased energy consumption. Finally, the FL process typically requires multiple rounds of data transmission and computation, which further increases the overall energy consumption. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib315" title="" class="ltx_ref">315</a>]</cite> a distributed FL framework is designed to overcome the connectivity and energy depletion for distant devices. The framework is suitable for mobile edge computing that connects the devices in a distributed manner using clustering protocols. This approach resolves centralized systems issues and exhibits scalable, faster, and energy-efficient communication when exchanging the trained models.</p>
</div>
<div id="S8.SS4.SSS6.p2" class="ltx_para">
<p id="S8.SS4.SSS6.p2.1" class="ltx_p">In the near future, FL is trusted to run large neural networks or similar algorithms at mobile devices and client handsets level. This is not feasible for resource-constrained devices. In this regard, one major challenge is how to design FL algorithms to minimize the use of computing and communication resources. One potential perspective is to efficiently use quantization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib316" title="" class="ltx_ref">316</a>, <a href="#bib.bib317" title="" class="ltx_ref">317</a>]</cite>, which was shown to significantly reduce energy consumption. Indeed, there is a need for new frameworks to build green FL algorithms that achieve both high computational and communication efficiency, while requiring low resource and energy budget.</p>
</div>
</section>
</section>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IX </span><span id="S9.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">Federated learning shows great potential in addressing privacy concerns and communication costs in various sectors, especially in current and upcoming mobile network generations. This paper thoroughly examines FL’s role in wireless communication networks, comparing different ML architectures and exploring the FL fundamentals, techniques, and frameworks. We also review the latest contributions that use FL to improve communication and KPIs within the protocol stack. Finally, we discuss important insights and challenges that come with deploying FL strategies in 5G, 6G, and beyond. Overall, FL is a vital research domain with far-reaching implications for the future, and this paper provides a detailed analysis of its potential and impact.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Table of Abbreviations &amp; Acronyms</h2>

<div id="Sx1.p1" class="ltx_para ltx_noindent">
<p id="Sx1.p1.1" class="ltx_p">The main abbreviations used in this survey are listed bellow:
<br class="ltx_break"></p>
</div>
<div id="Sx1.p2" class="ltx_para">
<table id="Sx1.p2.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx1.p2.1.1.1" class="ltx_tr">
<td id="Sx1.p2.1.1.1.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Abbreviation</span></td>
<td id="Sx1.p2.1.1.1.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Description</span></td>
</tr>
<tr id="Sx1.p2.1.2.2" class="ltx_tr">
<td id="Sx1.p2.1.2.2.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.2.2.1.1" class="ltx_text" style="font-size:90%;">5G</span></td>
<td id="Sx1.p2.1.2.2.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.2.2.2.1" class="ltx_text" style="font-size:90%;">Fifth Generation Mobile Network</span></td>
</tr>
<tr id="Sx1.p2.1.3.3" class="ltx_tr">
<td id="Sx1.p2.1.3.3.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.3.3.1.1" class="ltx_text" style="font-size:90%;">6G</span></td>
<td id="Sx1.p2.1.3.3.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.3.3.2.1" class="ltx_text" style="font-size:90%;">Sixth Generation Mobile Network</span></td>
</tr>
<tr id="Sx1.p2.1.4.4" class="ltx_tr">
<td id="Sx1.p2.1.4.4.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.4.4.1.1" class="ltx_text" style="font-size:90%;">NR</span></td>
<td id="Sx1.p2.1.4.4.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.4.4.2.1" class="ltx_text" style="font-size:90%;">(5G) New Radio</span></td>
</tr>
<tr id="Sx1.p2.1.5.5" class="ltx_tr">
<td id="Sx1.p2.1.5.5.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.5.5.1.1" class="ltx_text" style="font-size:90%;">RF</span></td>
<td id="Sx1.p2.1.5.5.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.5.5.2.1" class="ltx_text" style="font-size:90%;">Radio Frequency</span></td>
</tr>
<tr id="Sx1.p2.1.6.6" class="ltx_tr">
<td id="Sx1.p2.1.6.6.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.6.6.1.1" class="ltx_text" style="font-size:90%;">AI</span></td>
<td id="Sx1.p2.1.6.6.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.6.6.2.1" class="ltx_text" style="font-size:90%;">Artificial Intelligence</span></td>
</tr>
<tr id="Sx1.p2.1.7.7" class="ltx_tr">
<td id="Sx1.p2.1.7.7.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.7.7.1.1" class="ltx_text" style="font-size:90%;">FL</span></td>
<td id="Sx1.p2.1.7.7.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.7.7.2.1" class="ltx_text" style="font-size:90%;">Federated Learning</span></td>
</tr>
<tr id="Sx1.p2.1.8.8" class="ltx_tr">
<td id="Sx1.p2.1.8.8.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.8.8.1.1" class="ltx_text" style="font-size:90%;">ML</span></td>
<td id="Sx1.p2.1.8.8.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.8.8.2.1" class="ltx_text" style="font-size:90%;">Machine Learning</span></td>
</tr>
<tr id="Sx1.p2.1.9.9" class="ltx_tr">
<td id="Sx1.p2.1.9.9.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.9.9.1.1" class="ltx_text" style="font-size:90%;">DL</span></td>
<td id="Sx1.p2.1.9.9.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.9.9.2.1" class="ltx_text" style="font-size:90%;">Deep Learning</span></td>
</tr>
<tr id="Sx1.p2.1.10.10" class="ltx_tr">
<td id="Sx1.p2.1.10.10.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.10.10.1.1" class="ltx_text" style="font-size:90%;">FRL</span></td>
<td id="Sx1.p2.1.10.10.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.10.10.2.1" class="ltx_text" style="font-size:90%;">Federated Reinforcement Learning</span></td>
</tr>
<tr id="Sx1.p2.1.11.11" class="ltx_tr">
<td id="Sx1.p2.1.11.11.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.11.11.1.1" class="ltx_text" style="font-size:90%;">OSI</span></td>
<td id="Sx1.p2.1.11.11.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.11.11.2.1" class="ltx_text" style="font-size:90%;">Open Systems Interconnection</span></td>
</tr>
<tr id="Sx1.p2.1.12.12" class="ltx_tr">
<td id="Sx1.p2.1.12.12.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.12.12.1.1" class="ltx_text" style="font-size:90%;">PHY</span></td>
<td id="Sx1.p2.1.12.12.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.12.12.2.1" class="ltx_text" style="font-size:90%;">Physical Layer</span></td>
</tr>
<tr id="Sx1.p2.1.13.13" class="ltx_tr">
<td id="Sx1.p2.1.13.13.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.13.13.1.1" class="ltx_text" style="font-size:90%;">NET</span></td>
<td id="Sx1.p2.1.13.13.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.13.13.2.1" class="ltx_text" style="font-size:90%;">Network Layer</span></td>
</tr>
<tr id="Sx1.p2.1.14.14" class="ltx_tr">
<td id="Sx1.p2.1.14.14.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.14.14.1.1" class="ltx_text" style="font-size:90%;">MAC</span></td>
<td id="Sx1.p2.1.14.14.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.14.14.2.1" class="ltx_text" style="font-size:90%;">Medium Access Control Layer</span></td>
</tr>
<tr id="Sx1.p2.1.15.15" class="ltx_tr">
<td id="Sx1.p2.1.15.15.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.15.15.1.1" class="ltx_text" style="font-size:90%;">APP</span></td>
<td id="Sx1.p2.1.15.15.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.15.15.2.1" class="ltx_text" style="font-size:90%;">Application</span></td>
</tr>
<tr id="Sx1.p2.1.16.16" class="ltx_tr">
<td id="Sx1.p2.1.16.16.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.16.16.1.1" class="ltx_text" style="font-size:90%;">IoT</span></td>
<td id="Sx1.p2.1.16.16.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.16.16.2.1" class="ltx_text" style="font-size:90%;">Internet of Things</span></td>
</tr>
<tr id="Sx1.p2.1.17.17" class="ltx_tr">
<td id="Sx1.p2.1.17.17.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.17.17.1.1" class="ltx_text" style="font-size:90%;">CNN</span></td>
<td id="Sx1.p2.1.17.17.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.17.17.2.1" class="ltx_text" style="font-size:90%;">Convolutional Neural Network</span></td>
</tr>
<tr id="Sx1.p2.1.18.18" class="ltx_tr">
<td id="Sx1.p2.1.18.18.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.18.18.1.1" class="ltx_text" style="font-size:90%;">NN</span></td>
<td id="Sx1.p2.1.18.18.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.18.18.2.1" class="ltx_text" style="font-size:90%;">Neural Network</span></td>
</tr>
<tr id="Sx1.p2.1.19.19" class="ltx_tr">
<td id="Sx1.p2.1.19.19.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.19.19.1.1" class="ltx_text" style="font-size:90%;">HFL</span></td>
<td id="Sx1.p2.1.19.19.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.19.19.2.1" class="ltx_text" style="font-size:90%;">Horizontal Federated Learning</span></td>
</tr>
<tr id="Sx1.p2.1.20.20" class="ltx_tr">
<td id="Sx1.p2.1.20.20.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.20.20.1.1" class="ltx_text" style="font-size:90%;">VFL</span></td>
<td id="Sx1.p2.1.20.20.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.20.20.2.1" class="ltx_text" style="font-size:90%;">Vertical Federated Learning</span></td>
</tr>
<tr id="Sx1.p2.1.21.21" class="ltx_tr">
<td id="Sx1.p2.1.21.21.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.21.21.1.1" class="ltx_text" style="font-size:90%;">FTL</span></td>
<td id="Sx1.p2.1.21.21.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.21.21.2.1" class="ltx_text" style="font-size:90%;">Federated Transfer Learning</span></td>
</tr>
<tr id="Sx1.p2.1.22.22" class="ltx_tr">
<td id="Sx1.p2.1.22.22.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.22.22.1.1" class="ltx_text" style="font-size:90%;">MMVFL</span></td>
<td id="Sx1.p2.1.22.22.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.22.22.2.1" class="ltx_text" style="font-size:90%;">Multi-class Vertical Federated Learning</span></td>
</tr>
<tr id="Sx1.p2.1.23.23" class="ltx_tr">
<td id="Sx1.p2.1.23.23.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.23.23.1.1" class="ltx_text" style="font-size:90%;">HFCL</span></td>
<td id="Sx1.p2.1.23.23.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.23.23.2.1" class="ltx_text" style="font-size:90%;">Hybrid Federated Centralized Learning</span></td>
</tr>
<tr id="Sx1.p2.1.24.24" class="ltx_tr">
<td id="Sx1.p2.1.24.24.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.24.24.1.1" class="ltx_text" style="font-size:90%;">FedAvg</span></td>
<td id="Sx1.p2.1.24.24.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.24.24.2.1" class="ltx_text" style="font-size:90%;">Federated Averaging</span></td>
</tr>
<tr id="Sx1.p2.1.25.25" class="ltx_tr">
<td id="Sx1.p2.1.25.25.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.25.25.1.1" class="ltx_text" style="font-size:90%;">SimFL</span></td>
<td id="Sx1.p2.1.25.25.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.25.25.2.1" class="ltx_text" style="font-size:90%;">Similarity Federated Learning</span></td>
</tr>
<tr id="Sx1.p2.1.26.26" class="ltx_tr">
<td id="Sx1.p2.1.26.26.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.26.26.1.1" class="ltx_text" style="font-size:90%;">TFF</span></td>
<td id="Sx1.p2.1.26.26.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.26.26.2.1" class="ltx_text" style="font-size:90%;">TensorFlow Federated</span></td>
</tr>
<tr id="Sx1.p2.1.27.27" class="ltx_tr">
<td id="Sx1.p2.1.27.27.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.27.27.1.1" class="ltx_text" style="font-size:90%;">FATE</span></td>
<td id="Sx1.p2.1.27.27.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.27.27.2.1" class="ltx_text" style="font-size:90%;">Federated AI Technology Enabler</span></td>
</tr>
<tr id="Sx1.p2.1.28.28" class="ltx_tr">
<td id="Sx1.p2.1.28.28.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.28.28.1.1" class="ltx_text" style="font-size:90%;">FedML</span></td>
<td id="Sx1.p2.1.28.28.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.28.28.2.1" class="ltx_text" style="font-size:90%;">Federated Machine Learning</span></td>
</tr>
<tr id="Sx1.p2.1.29.29" class="ltx_tr">
<td id="Sx1.p2.1.29.29.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.29.29.1.1" class="ltx_text" style="font-size:90%;">FedRec</span></td>
<td id="Sx1.p2.1.29.29.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.29.29.2.1" class="ltx_text" style="font-size:90%;">FL-based receiver</span></td>
</tr>
<tr id="Sx1.p2.1.30.30" class="ltx_tr">
<td id="Sx1.p2.1.30.30.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.30.30.1.1" class="ltx_text" style="font-size:90%;">AMC</span></td>
<td id="Sx1.p2.1.30.30.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.30.30.2.1" class="ltx_text" style="font-size:90%;">Automatic Modulation Classification</span></td>
</tr>
<tr id="Sx1.p2.1.31.31" class="ltx_tr">
<td id="Sx1.p2.1.31.31.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.31.31.1.1" class="ltx_text" style="font-size:90%;">TCP</span></td>
<td id="Sx1.p2.1.31.31.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.31.31.2.1" class="ltx_text" style="font-size:90%;">Transmission Control Protocol</span></td>
</tr>
<tr id="Sx1.p2.1.32.32" class="ltx_tr">
<td id="Sx1.p2.1.32.32.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.32.32.1.1" class="ltx_text" style="font-size:90%;">CSI</span></td>
<td id="Sx1.p2.1.32.32.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.32.32.2.1" class="ltx_text" style="font-size:90%;">Channel State Information</span></td>
</tr>
<tr id="Sx1.p2.1.33.33" class="ltx_tr">
<td id="Sx1.p2.1.33.33.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.33.33.1.1" class="ltx_text" style="font-size:90%;">RF</span></td>
<td id="Sx1.p2.1.33.33.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.33.33.2.1" class="ltx_text" style="font-size:90%;">Radio Frequency</span></td>
</tr>
<tr id="Sx1.p2.1.34.34" class="ltx_tr">
<td id="Sx1.p2.1.34.34.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.34.34.1.1" class="ltx_text" style="font-size:90%;">RIS</span></td>
<td id="Sx1.p2.1.34.34.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.34.34.2.1" class="ltx_text" style="font-size:90%;">Reconfigurable Intelligent Surfaces</span></td>
</tr>
<tr id="Sx1.p2.1.35.35" class="ltx_tr">
<td id="Sx1.p2.1.35.35.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.35.35.1.1" class="ltx_text" style="font-size:90%;">FED-WG</span></td>
<td id="Sx1.p2.1.35.35.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.35.35.2.1" class="ltx_text" style="font-size:90%;">Federated Weights and Gradients</span></td>
</tr>
<tr id="Sx1.p2.1.36.36" class="ltx_tr">
<td id="Sx1.p2.1.36.36.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.36.36.1.1" class="ltx_text" style="font-size:90%;">MIMO</span></td>
<td id="Sx1.p2.1.36.36.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.36.36.2.1" class="ltx_text" style="font-size:90%;">Multiple Input Multiple Outputs</span></td>
</tr>
<tr id="Sx1.p2.1.37.37" class="ltx_tr">
<td id="Sx1.p2.1.37.37.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.37.37.1.1" class="ltx_text" style="font-size:90%;">mm-Wave</span></td>
<td id="Sx1.p2.1.37.37.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.37.37.2.1" class="ltx_text" style="font-size:90%;">millimeter Wave</span></td>
</tr>
<tr id="Sx1.p2.1.38.38" class="ltx_tr">
<td id="Sx1.p2.1.38.38.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.38.38.1.1" class="ltx_text" style="font-size:90%;">SPIM</span></td>
<td id="Sx1.p2.1.38.38.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.38.38.2.1" class="ltx_text" style="font-size:90%;">Spatial Path Index Modulation</span></td>
</tr>
<tr id="Sx1.p2.1.39.39" class="ltx_tr">
<td id="Sx1.p2.1.39.39.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.39.39.1.1" class="ltx_text" style="font-size:90%;">NOMA</span></td>
<td id="Sx1.p2.1.39.39.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.39.39.2.1" class="ltx_text" style="font-size:90%;">Non-orthogonal Multiple Access</span></td>
</tr>
<tr id="Sx1.p2.1.40.40" class="ltx_tr">
<td id="Sx1.p2.1.40.40.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.40.40.1.1" class="ltx_text" style="font-size:90%;">MTD</span></td>
<td id="Sx1.p2.1.40.40.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.40.40.2.1" class="ltx_text" style="font-size:90%;">Machine Type Devices</span></td>
</tr>
<tr id="Sx1.p2.1.41.41" class="ltx_tr">
<td id="Sx1.p2.1.41.41.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.41.41.1.1" class="ltx_text" style="font-size:90%;">MEC</span></td>
<td id="Sx1.p2.1.41.41.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.41.41.2.1" class="ltx_text" style="font-size:90%;">Multi-access edge computing</span></td>
</tr>
<tr id="Sx1.p2.1.42.42" class="ltx_tr">
<td id="Sx1.p2.1.42.42.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.42.42.1.1" class="ltx_text" style="font-size:90%;">LSTM</span></td>
<td id="Sx1.p2.1.42.42.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.42.42.2.1" class="ltx_text" style="font-size:90%;">Long Short Term Memory</span></td>
</tr>
<tr id="Sx1.p2.1.43.43" class="ltx_tr">
<td id="Sx1.p2.1.43.43.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.43.43.1.1" class="ltx_text" style="font-size:90%;">SVM</span></td>
<td id="Sx1.p2.1.43.43.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.43.43.2.1" class="ltx_text" style="font-size:90%;">Support Vector Machine</span></td>
</tr>
<tr id="Sx1.p2.1.44.44" class="ltx_tr">
<td id="Sx1.p2.1.44.44.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.44.44.1.1" class="ltx_text" style="font-size:90%;">UAV</span></td>
<td id="Sx1.p2.1.44.44.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.44.44.2.1" class="ltx_text" style="font-size:90%;">Unmanned Aerial Vehicle</span></td>
</tr>
<tr id="Sx1.p2.1.45.45" class="ltx_tr">
<td id="Sx1.p2.1.45.45.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.45.45.1.1" class="ltx_text" style="font-size:90%;">QoE</span></td>
<td id="Sx1.p2.1.45.45.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.45.45.2.1" class="ltx_text" style="font-size:90%;">Quality of Experience</span></td>
</tr>
<tr id="Sx1.p2.1.46.46" class="ltx_tr">
<td id="Sx1.p2.1.46.46.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.46.46.1.1" class="ltx_text" style="font-size:90%;">HDRL</span></td>
<td id="Sx1.p2.1.46.46.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.46.46.2.1" class="ltx_text" style="font-size:90%;">Hybrid FL Reinforcement Learning</span></td>
</tr>
<tr id="Sx1.p2.1.47.47" class="ltx_tr">
<td id="Sx1.p2.1.47.47.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.47.47.1.1" class="ltx_text" style="font-size:90%;">VR</span></td>
<td id="Sx1.p2.1.47.47.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.47.47.2.1" class="ltx_text" style="font-size:90%;">Virtual Reality</span></td>
</tr>
<tr id="Sx1.p2.1.48.48" class="ltx_tr">
<td id="Sx1.p2.1.48.48.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.48.48.1.1" class="ltx_text" style="font-size:90%;">AR</span></td>
<td id="Sx1.p2.1.48.48.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.48.48.2.1" class="ltx_text" style="font-size:90%;">Augmented Reality</span></td>
</tr>
<tr id="Sx1.p2.1.49.49" class="ltx_tr">
<td id="Sx1.p2.1.49.49.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.49.49.1.1" class="ltx_text" style="font-size:90%;">XR</span></td>
<td id="Sx1.p2.1.49.49.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.49.49.2.1" class="ltx_text" style="font-size:90%;">Extended Reality</span></td>
</tr>
<tr id="Sx1.p2.1.50.50" class="ltx_tr">
<td id="Sx1.p2.1.50.50.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.50.50.1.1" class="ltx_text" style="font-size:90%;">TI</span></td>
<td id="Sx1.p2.1.50.50.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.50.50.2.1" class="ltx_text" style="font-size:90%;">Tactile Internet</span></td>
</tr>
<tr id="Sx1.p2.1.51.51" class="ltx_tr">
<td id="Sx1.p2.1.51.51.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.51.51.1.1" class="ltx_text" style="font-size:90%;">URLLC</span></td>
<td id="Sx1.p2.1.51.51.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.51.51.2.1" class="ltx_text" style="font-size:90%;">Ultra-Reliable Low-Latency Communication</span></td>
</tr>
<tr id="Sx1.p2.1.52.52" class="ltx_tr">
<td id="Sx1.p2.1.52.52.1" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.52.52.1.1" class="ltx_text" style="font-size:90%;">TC</span></td>
<td id="Sx1.p2.1.52.52.2" class="ltx_td ltx_align_left"><span id="Sx1.p2.1.52.52.2.1" class="ltx_text" style="font-size:90%;">Traffic Classification</span></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
W. Saad, M. Bennis, and M. Chen, “A vision of 6g wireless systems:
Applications, trends, technologies, and open research problems,” </span><em id="bib.bib1.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
network</em><span id="bib.bib1.3.3" class="ltx_text" style="font-size:90%;">, vol. 34, no. 3, pp. 134–142, 2019.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
W. Jiang, B. Han, M. A. Habibi, and H. D. Schotten, “The road towards 6g: A
comprehensive survey,” </span><em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Open Journal of the Communications
Society</em><span id="bib.bib2.3.3" class="ltx_text" style="font-size:90%;">, vol. 2, pp. 334–366, 2021.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
C. Chaccour, W. Saad, M. Debbah, Z. Han, and H. V. Poor, “Less data, more
knowledge: Building next generation semantic communication networks,”
</span><em id="bib.bib3.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2211.14343</em><span id="bib.bib3.3.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
E. Dahlman, S. Parkvall, J. Peisa, H. Tullberg, H. Murai, and M. Fujioka,
“Artificial intelligence in future evolution of mobile communication,” in
</span><em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2019 International Conference on Artificial Intelligence in Information
and Communication (ICAIIC)</em><span id="bib.bib4.3.3" class="ltx_text" style="font-size:90%;">.   IEEE,
2019, pp. 102–106.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
K. B. Letaief, W. Chen, Y. Shi, J. Zhang, and Y.-J. A. Zhang, “The roadmap to
6g: Ai empowered wireless networks,” </span><em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Magazine</em><span id="bib.bib5.3.3" class="ltx_text" style="font-size:90%;">,
vol. 57, no. 8, pp. 84–90, 2019.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
M. Chen, U. Challita, W. Saad, C. Yin, and M. Debbah, “Artificial neural
networks-based machine learning for wireless networks: A tutorial,”
</span><em id="bib.bib6.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Surveys &amp; Tutorials</em><span id="bib.bib6.3.3" class="ltx_text" style="font-size:90%;">, vol. 21, no. 4, pp.
3039–3071, 2019.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
M. Chen, U. Challita, W. Saad, C. Yin, and M. Debbah, “Artificial
neural networks-based machine learning for wireless networks: A tutorial,”
</span><em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Surveys Tutorials</em><span id="bib.bib7.3.3" class="ltx_text" style="font-size:90%;">, vol. 21, no. 4, pp. 3039–3071,
2019.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
N. Rastegardoost and B. Jabbari, “A machine learning algorithm for unlicensed
lte and wifi spectrum sharing,” in </span><em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2018 IEEE International Symposium
on Dynamic Spectrum Access Networks (DySPAN)</em><span id="bib.bib8.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2018, pp. 1–6.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Y.-Y. Liu and S.-J. Yoo, “Dynamic resource allocation using reinforcement
learning for lte-u and wifi in the unlicensed spectrum,” in </span><em id="bib.bib9.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2017 Ninth
International Conference on Ubiquitous and Future Networks (ICUFN)</em><span id="bib.bib9.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2017, pp. 471–475.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
T. Jiang, D. Grace, and P. D. Mitchell, “Efficient exploration in
reinforcement learning-based cognitive radio spectrum sharing,” </span><em id="bib.bib10.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IET
communications</em><span id="bib.bib10.3.3" class="ltx_text" style="font-size:90%;">, vol. 5, no. 10, pp. 1309–1317, 2011.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Z. Zhang, K. Zhang, F. Gao, and S. Zhang, “Spectrum prediction and
channel selection for sensing-based spectrum sharing scheme using online
learning techniques,” in </span><em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2015 IEEE 26th Annual International Symposium
on Personal, Indoor, and Mobile Radio Communications (PIMRC)</em><span id="bib.bib11.3.3" class="ltx_text" style="font-size:90%;">, 2015, pp.
355–359.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
C. Yang, J. Li, M. Guizani, A. Anpalagan, and M. Elkashlan,
“Advanced spectrum sharing in 5g cognitive heterogeneous networks,”
</span><em id="bib.bib12.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Wireless Communications</em><span id="bib.bib12.3.3" class="ltx_text" style="font-size:90%;">, vol. 23, no. 2, pp. 94–101, 2016.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Y. Zhang, Y. Gu, M. Pan, and Z. Han, “Distributed matching based
spectrum allocation in cognitive radio networks,” in </span><em id="bib.bib13.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2014 IEEE Global
Communications Conference</em><span id="bib.bib13.3.3" class="ltx_text" style="font-size:90%;">, 2014, pp. 864–869.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
K. Gai and M. Qiu, “Optimal resource allocation using reinforcement learning
for iot content-centric services,” </span><em id="bib.bib14.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Applied Soft Computing</em><span id="bib.bib14.3.3" class="ltx_text" style="font-size:90%;">, vol. 70,
pp. 12–21, 2018.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
J. Wang, J. Wang, Y. Wu, J. Wang, H. Zhu, M. Lin, and J. Wang,
“A machine learning framework for resource allocation assisted by cloud
computing,” </span><em id="bib.bib15.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Network</em><span id="bib.bib15.3.3" class="ltx_text" style="font-size:90%;">, vol. 32, no. 2, pp. 144–151, 2018.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
H. Li, H. Gao, T. Lv, and Y. Lu, “Deep q-learning based dynamic
resource allocation for self-powered ultra-dense networks,” in </span><em id="bib.bib16.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2018
IEEE International Conference on Communications Workshops (ICC Workshops)</em><span id="bib.bib16.3.3" class="ltx_text" style="font-size:90%;">,
2018, pp. 1–6.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
B. R. Ray and S. Chowdhury, “Reverse engineering technique (ret) to predict
resource allocation in a google cloud system,” in </span><em id="bib.bib17.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2018 8th
International Conference on Cloud Computing, Data Science &amp; Engineering
(Confluence)</em><span id="bib.bib17.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2018, pp.
688–693.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
S. K. Singh and A. Jukan, “Machine-learning-based prediction for resource
(re)allocation in optical data center networks,” </span><em id="bib.bib18.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE/OSA Journal of
Optical Communications and Networking</em><span id="bib.bib18.3.3" class="ltx_text" style="font-size:90%;">, vol. 10, no. 10, pp. D12–D28, 2018.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
U. Challita, L. Dong, and W. Saad, “Deep learning for proactive resource
allocation in lte-u networks,” in </span><em id="bib.bib19.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European wireless technology
conference</em><span id="bib.bib19.3.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
W. Jiang and H. D. Schotten, “Multi-antenna fading channel prediction
empowered by artificial intelligence,” in </span><em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2018 IEEE 88th Vehicular
Technology Conference (VTC-Fall)</em><span id="bib.bib20.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2018, pp. 1–6.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
W. Jiang and H. Schotten, “A deep learning method to predict fading channel in
multi-antenna systems,” in </span><em id="bib.bib21.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE 91st Vehicular Technology
Conference (VTC2020-Spring)</em><span id="bib.bib21.3.3" class="ltx_text" style="font-size:90%;">.   IEEE,
2020, pp. 1–5.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
W. Jiang and H. D. Schotten, “Deep learning for fading channel prediction,”
</span><em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Open Journal of the Communications Society</em><span id="bib.bib22.3.3" class="ltx_text" style="font-size:90%;">, vol. 1, pp. 320–332,
2020.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
W. Jiang and H. Schotten, “Recurrent neural networks with long short-term
memory for fading channel prediction,” in </span><em id="bib.bib23.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE 91st Vehicular
Technology Conference (VTC2020-Spring)</em><span id="bib.bib23.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 1–5.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
A. Konstantinov and A. Pestryakov, “Fading channel prediction for 5g,” in
</span><em id="bib.bib24.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2019 Systems of Signal Synchronization, Generating and Processing in
Telecommunications (SYNCHROINFO)</em><span id="bib.bib24.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2019, pp. 1–7.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
R. Alvizu, S. Troia, G. Maier, and A. Pattavina, “Matheuristic with
machine-learning-based prediction for software-defined mobile metro-core
networks,” </span><em id="bib.bib25.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of Optical Communications and Networking</em><span id="bib.bib25.3.3" class="ltx_text" style="font-size:90%;">, vol. 9,
p. D19, 09 2017.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
I. Railean, C. Stolojescu, S. Moga, and P. Lenca, “Wimax traffic
forecasting based on neural networks in wavelet domain,” in </span><em id="bib.bib26.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2010
Fourth International Conference on Research Challenges in Information Science
(RCIS)</em><span id="bib.bib26.3.3" class="ltx_text" style="font-size:90%;">, 2010, pp. 443–452.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
S. Suthaharan, “Big data classification: Problems and challenges in network
intrusion prediction with machine learning,” </span><em id="bib.bib27.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM SIGMETRICS
Performance Evaluation Review</em><span id="bib.bib27.3.3" class="ltx_text" style="font-size:90%;">, vol. 41, no. 4, pp. 70–73, 2014.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
F. Kong, J. Li, B. Jiang, T. Zhang, and H. Song, “Big data-driven machine
learning-enabled traffic flow prediction,” </span><em id="bib.bib28.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Transactions on Emerging
Telecommunications Technologies</em><span id="bib.bib28.3.3" class="ltx_text" style="font-size:90%;">, vol. 30, no. 9, p. e3482, 2019.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
J. Verbraeken, M. Wolting, J. Katzy, J. Kloppenburg, T. Verbelen, and J. S.
Rellermeyer, “A survey on distributed machine learning,” </span><em id="bib.bib29.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM
Computing Surveys (CSUR)</em><span id="bib.bib29.3.3" class="ltx_text" style="font-size:90%;">, vol. 53, no. 2, pp. 1–33, 2020.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
N. Kato, B. Mao, F. Tang, Y. Kawamoto, and J. Liu, “Ten challenges in
advancing machine learning technologies toward 6g,” </span><em id="bib.bib30.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Wireless
Communications</em><span id="bib.bib30.3.3" class="ltx_text" style="font-size:90%;">, vol. 27, no. 3, pp. 96–103, 2020.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
D. Shome, O. Waqar, and W. U. Khan, “Federated learning and next generation
wireless communications: A survey on bidirectional relationship,”
</span><em id="bib.bib31.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Transactions on Emerging Telecommunications Technologies</em><span id="bib.bib31.3.3" class="ltx_text" style="font-size:90%;">, vol. 33,
no. 7, p. e4458, 2022.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang,
D. Niyato, and C. Miao, “Federated learning in mobile edge networks: A
comprehensive survey,” </span><em id="bib.bib32.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Surveys &amp; Tutorials</em><span id="bib.bib32.3.3" class="ltx_text" style="font-size:90%;">,
vol. 22, no. 3, pp. 2031–2063, 2020.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
S. Niknam, H. S. Dhillon, and J. H. Reed, “Federated learning for wireless
communications: Motivation, opportunities, and challenges,” </span><em id="bib.bib33.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Communications Magazine</em><span id="bib.bib33.3.3" class="ltx_text" style="font-size:90%;">, vol. 58, no. 6, pp. 46–51, 2020.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
S. Hu, X. Chen, W. Ni, E. Hossain, and X. Wang, “Distributed machine learning
for wireless communication networks: Techniques, architectures, and
applications,” </span><em id="bib.bib34.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2012.01489</em><span id="bib.bib34.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Z. Qin, G. Y. Li, and H. Ye, “Federated learning and wireless
communications,” </span><em id="bib.bib35.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2005.05265</em><span id="bib.bib35.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
M. S. Mollel, A. I. Abubakar, M. Ozturk, S. F. Kaijage, M. Kisangiri,
S. Hussain, M. A. Imran, and Q. H. Abbasi, “A survey of machine learning
applications to handover management in 5g and beyond,” </span><em id="bib.bib36.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Access</em><span id="bib.bib36.3.3" class="ltx_text" style="font-size:90%;">,
vol. 9, pp. 45 770–45 802, 2021.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Z. Yang, M. Chen, K.-K. Wong, H. V. Poor, and S. Cui, “Federated learning for
6g : Applications, challenges, and opportunities,” </span><em id="bib.bib37.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2101.01338</em><span id="bib.bib37.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
A. M. Elbir, A. K. Papazafeiropoulos, and S. Chatzinotas, “Federated learning
for physical layer design,” </span><em id="bib.bib38.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2102.11777</em><span id="bib.bib38.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
O. A. Wahab, A. Mourad, H. Otrok, and T. Taleb, “Federated machine learning:
Survey, multi-level classification, desirable criteria and future directions
in communication and networking systems,” </span><em id="bib.bib39.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Surveys
&amp; Tutorials</em><span id="bib.bib39.3.3" class="ltx_text" style="font-size:90%;">, vol. 23, no. 2, pp. 1342–1397, 2021.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, J. Li, and H. V. Poor,
“Federated learning for internet of things: A comprehensive survey,”
</span><em id="bib.bib40.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.07914</em><span id="bib.bib40.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
L. U. Khan, W. Saad, Z. Han, E. Hossain, and C. S. Hong, “Federated learning
for internet of things: Recent advances, taxonomy, and open challenges,”
</span><em id="bib.bib41.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Surveys &amp; Tutorials</em><span id="bib.bib41.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
T. R. Gadekallu, Q.-V. Pham, T. Huynh-The, S. Bhattacharya, P. K. R.
Maddikunta, and M. Liyanage, “Federated learning for big data: A survey on
opportunities, applications, and future directions,” </span><em id="bib.bib42.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2110.04160</em><span id="bib.bib42.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
M. Al-Quraan, L. Mohjazi, L. Bariah, A. Centeno, A. Zoha, S. Muhaidat,
M. Debbah, and M. A. Imran, “Edge-native intelligence for 6g communications
driven by federated learning: A survey of trends and challenges,”
</span><em id="bib.bib43.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2111.07392</em><span id="bib.bib43.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
R. Kontar, N. Shi, X. Yue, S. Chung, E. Byon, M. Chowdhury, J. Jin, W. Kontar,
N. Masoud, M. Noueihed </span><em id="bib.bib44.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib44.3.3" class="ltx_text" style="font-size:90%;">, “The internet of federated things
(ioft): A vision for the future and in-depth survey of data-driven approaches
for federated learning,” </span><em id="bib.bib44.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2111.05326</em><span id="bib.bib44.5.5" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
J. Liu, J. Huang, Y. Zhou, X. Li, S. Ji, H. Xiong, and D. Dou, “From
distributed machine learning to federated learning: A survey,” </span><em id="bib.bib45.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv
preprint arXiv:2104.14362</em><span id="bib.bib45.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
D. Shome, O. Waqar, and W. U. Khan, “Federated learning and next generation
wireless communications: A survey on bidirectional relationship,”
</span><em id="bib.bib46.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2110.07649</em><span id="bib.bib46.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
N. Rodríguez-Barroso, D. J. López, M. Luzón, F. Herrera, and
E. Martínez-Cámara, “Survey on federated learning threats:
concepts, taxonomy on attacks and defences, experimental study and
challenges,” </span><em id="bib.bib47.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2201.08135</em><span id="bib.bib47.3.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
S. Banabilah, M. Aloqaily, E. Alsayed, N. Malik, and Y. Jararweh, “Federated
learning review: Fundamentals, enabling technologies, and future
applications,” </span><em id="bib.bib48.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Information Processing &amp; Management</em><span id="bib.bib48.3.3" class="ltx_text" style="font-size:90%;">, vol. 59, no. 6,
p. 103061, 2022.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
S. Agrawal, S. Sarkar, O. Aouedi, G. Yenduri, K. Piamrat, M. Alazab,
S. Bhattacharya, P. K. R. Maddikunta, and T. R. Gadekallu, “Federated
learning for intrusion detection system: Concepts, challenges and future
directions,” </span><em id="bib.bib49.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Communications</em><span id="bib.bib49.3.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
B. Ghimire and D. B. Rawat, “Recent advances on federated learning for
cybersecurity and cybersecurity for federated learning for internet of
things,” </span><em id="bib.bib50.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</em><span id="bib.bib50.3.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
S. Pandya, G. Srivastava, R. Jhaveri, M. R. Babu, S. Bhattacharya, P. K. R.
Maddikunta, S. Mastorakis, M. J. Piran, and T. R. Gadekallu, “Federated
learning for smart cities: A comprehensive survey,” </span><em id="bib.bib51.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Sustainable Energy
Technologies and Assessments</em><span id="bib.bib51.3.3" class="ltx_text" style="font-size:90%;">, vol. 55, p. 102987, 2023.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
J. Wen, Z. Zhang, Y. Lan, Z. Cui, J. Cai, and W. Zhang, “A survey on federated
learning: challenges and applications,” </span><em id="bib.bib52.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Journal of
Machine Learning and Cybernetics</em><span id="bib.bib52.3.3" class="ltx_text" style="font-size:90%;">, vol. 14, no. 2, pp. 513–535, 2023.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
M. Al-Quraan, L. Mohjazi, L. Bariah, A. Centeno, A. Zoha, K. Arshad,
K. Assaleh, S. Muhaidat, M. Debbah, and M. A. Imran, “Edge-native
intelligence for 6g communications driven by federated learning: A survey of
trends and challenges,” </span><em id="bib.bib53.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Emerging Topics in
Computational Intelligence</em><span id="bib.bib53.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
Z. Zhao, Y. Mao, Y. Liu, L. Song, Y. Ouyang, X. Chen, and W. Ding, “Towards
efficient communications in federated learning: A contemporary survey,”
</span><em id="bib.bib54.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of the Franklin Institute</em><span id="bib.bib54.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text" style="font-size:90%;">
R. Boutaba, M. A. Salahuddin, N. Limam, S. Ayoubi, N. Shahriar,
F. Estrada-Solano, and O. M. Caicedo, “A comprehensive survey on machine
learning for networking: evolution, applications and research
opportunities,” </span><em id="bib.bib55.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of Internet Services and Applications</em><span id="bib.bib55.3.3" class="ltx_text" style="font-size:90%;">,
vol. 9, no. 1, pp. 1–99, 2018.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text" style="font-size:90%;">
X.-D. Zhang, “Machine learning,” in </span><em id="bib.bib56.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">A Matrix Algebra Approach to
Artificial Intelligence</em><span id="bib.bib56.3.3" class="ltx_text" style="font-size:90%;">.   Springer,
2020, pp. 223–440.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text" style="font-size:90%;">
J. Jagannath, N. Polosky, A. Jagannath, F. Restuccia, and T. Melodia, “Machine
learning for wireless communications in the internet of things: A
comprehensive survey,” </span><em id="bib.bib57.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Ad Hoc Networks</em><span id="bib.bib57.3.3" class="ltx_text" style="font-size:90%;">, vol. 93, p. 101913, 2019.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text" style="font-size:90%;">
D. Gündüz, P. de Kerret, N. D. Sidiropoulos, D. Gesbert, C. R. Murthy,
and M. van der Schaar, “Machine learning in the air,” </span><em id="bib.bib58.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Journal on
Selected Areas in Communications</em><span id="bib.bib58.3.3" class="ltx_text" style="font-size:90%;">, vol. 37, no. 10, pp. 2184–2199, 2019.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text" style="font-size:90%;">
X. Ma, Y. Zhou, L. Wang, and M. Miao, “Privacy-preserving byzantine-robust
federated learning,” </span><em id="bib.bib59.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Standards &amp; Interfaces</em><span id="bib.bib59.3.3" class="ltx_text" style="font-size:90%;">, vol. 80, p.
103561, 2022.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text" style="font-size:90%;">
Q. Yang, Y. Liu, Y. Cheng, Y. Kang, T. Chen, and H. Yu, </span><em id="bib.bib60.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Federated
Learning</em><span id="bib.bib60.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text" style="font-size:90%;">
V. Sze, Y.-H. Chen, J. Emer, A. Suleiman, and Z. Zhang, “Hardware for machine
learning: Challenges and opportunities,” in </span><em id="bib.bib61.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2017 IEEE Custom
Integrated Circuits Conference (CICC)</em><span id="bib.bib61.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2017, pp. 1–8.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text" style="font-size:90%;">
B. A. y Arcas, “Decentralized machine learning,” in </span><em id="bib.bib62.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2018 IEEE
International Conference on Big Data (Big Data)</em><span id="bib.bib62.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2018, pp. 1–1.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text" style="font-size:90%;">
M. Murshed, C. Murphy, D. Hou, N. Khan, G. Ananthanarayanan, and F. Hussain,
“Machine learning at the network edge: A survey,” </span><em id="bib.bib63.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:1908.00080</em><span id="bib.bib63.3.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text" style="font-size:90%;">
S. Abdulrahman, H. Tout, H. Ould-Slimane, A. Mourad, C. Talhi, and
M. Guizani, “A survey on federated learning: The journey from centralized
to distributed on-site learning and beyond,” </span><em id="bib.bib64.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Internet of Things
Journal</em><span id="bib.bib64.3.3" class="ltx_text" style="font-size:90%;">, vol. 8, no. 7, pp. 5476–5497, 2021.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text" style="font-size:90%;">
J. Konečnỳ, H. B. McMahan, D. Ramage, and P. Richtárik,
“Federated optimization: Distributed machine learning for on-device
intelligence,” </span><em id="bib.bib65.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1610.02527</em><span id="bib.bib65.3.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text" style="font-size:90%;">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, R. G. L. D’Oliveira, S. E.
Rouayheb, D. Evans, J. Gardner, Z. Garrett, A. Gascón, B. Ghazi, P. B.
Gibbons, M. Gruteser, Z. Harchaoui, C. He, L. He, Z. Huo, B. Hutchinson,
J. Hsu, M. Jaggi, T. Javidi, G. Joshi, M. Khodak, J. Konečný,
A. Korolova, F. Koushanfar, S. Koyejo, T. Lepoint, Y. Liu, P. Mittal,
M. Mohri, R. Nock, A. Özgür, R. Pagh, M. Raykova, H. Qi,
D. Ramage, R. Raskar, D. Song, W. Song, S. U. Stich, Z. Sun, A. T. Suresh,
F. Tramèr, P. Vepakomma, J. Wang, L. Xiong, Z. Xu, Q. Yang, F. X. Yu,
H. Yu, and S. Zhao, “Advances and open problems in federated learning,”
</span><em id="bib.bib66.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib66.3.3" class="ltx_text" style="font-size:90%;">, vol. abs/1912.04977, 2019. [Online]. Available:
http://arxiv.org/abs/1912.04977
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text" style="font-size:90%;">
C. Zhang, Y. Xie, H. Bai, B. Yu, W. Li, and Y. Gao, “A survey on federated
learning,” </span><em id="bib.bib67.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Knowledge-Based Systems</em><span id="bib.bib67.3.3" class="ltx_text" style="font-size:90%;">, vol. 216, p. 106775, 2021.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text" style="font-size:90%;">
V. Mothukuri, R. M. Parizi, S. Pouriyeh, Y. Huang, A. Dehghantanha, and
G. Srivastava, “A survey on security and privacy of federated learning,”
</span><em id="bib.bib68.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Future Generation Computer Systems</em><span id="bib.bib68.3.3" class="ltx_text" style="font-size:90%;">, vol. 115, pp. 619–640, 2021.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock"><span id="bib.bib69.1.1" class="ltx_text" style="font-size:90%;">
Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine learning: Concept
and applications,” </span><em id="bib.bib69.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Transactions on Intelligent Systems and
Technology (TIST)</em><span id="bib.bib69.3.3" class="ltx_text" style="font-size:90%;">, vol. 10, no. 2, pp. 1–19, 2019.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock"><span id="bib.bib70.1.1" class="ltx_text" style="font-size:90%;">
L. Li, Y. Fan, M. Tse, and K.-Y. Lin, “A review of applications in federated
learning,” </span><em id="bib.bib70.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computers &amp; Industrial Engineering</em><span id="bib.bib70.3.3" class="ltx_text" style="font-size:90%;">, p. 106854, 2020.
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock"><span id="bib.bib71.1.1" class="ltx_text" style="font-size:90%;">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings </span><em id="bib.bib71.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib71.3.3" class="ltx_text" style="font-size:90%;">, “Advances
and open problems in federated learning,” </span><em id="bib.bib71.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:1912.04977</em><span id="bib.bib71.5.5" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock"><span id="bib.bib72.1.1" class="ltx_text" style="font-size:90%;">
D. Leroy, A. Coucke, T. Lavril, T. Gisselbrecht, and J. Dureau, “Federated
learning for keyword spotting,” in </span><em id="bib.bib72.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICASSP 2019-2019 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP)</em><span id="bib.bib72.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2019, pp. 6341–6345.
</span>
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock"><span id="bib.bib73.1.1" class="ltx_text" style="font-size:90%;">
Y. Liu, Y. Kang, C. Xing, T. Chen, and Q. Yang, “A secure federated transfer
learning framework,” </span><em id="bib.bib73.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Intelligent Systems</em><span id="bib.bib73.3.3" class="ltx_text" style="font-size:90%;">, vol. 35, no. 4, pp.
70–82, 2020.
</span>
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock"><span id="bib.bib74.1.1" class="ltx_text" style="font-size:90%;">
B. Liu, L. Wang, and M. Liu, “Lifelong federated reinforcement learning: a
learning architecture for navigation in cloud robotic systems,” </span><em id="bib.bib74.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Robotics and Automation Letters</em><span id="bib.bib74.3.3" class="ltx_text" style="font-size:90%;">, vol. 4, no. 4, pp. 4555–4562, 2019.
</span>
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock"><span id="bib.bib75.1.1" class="ltx_text" style="font-size:90%;">
S. Feng and H. Yu, “Multi-participant multi-class vertical federated
learning,” </span><em id="bib.bib75.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2001.11154</em><span id="bib.bib75.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock"><span id="bib.bib76.1.1" class="ltx_text" style="font-size:90%;">
T.-D. Cao, T. Truong-Huu, H. Tran, and K. Tran, “A federated learning
framework for privacy-preserving and parallel training,” </span><em id="bib.bib76.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv
preprint arXiv:2001.09782</em><span id="bib.bib76.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock"><span id="bib.bib77.1.1" class="ltx_text" style="font-size:90%;">
Q. Wu, K. He, and X. Chen, “Personalized federated learning for intelligent
iot applications: A cloud-edge based framework,” </span><em id="bib.bib77.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Open Journal of
the Computer Society</em><span id="bib.bib77.3.3" class="ltx_text" style="font-size:90%;">, vol. 1, pp. 35–44, 2020.
</span>
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock"><span id="bib.bib78.1.1" class="ltx_text" style="font-size:90%;">
A. Huang, Y. Liu, T. Chen, Y. Zhou, Q. Sun, H. Chai, and Q. Yang, “Starfl:
Hybrid federated learning architecture for smart urban computing,” </span><em id="bib.bib78.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM
Transactions on Intelligent Systems and Technology (TIST)</em><span id="bib.bib78.3.3" class="ltx_text" style="font-size:90%;">, vol. 12, no. 4,
pp. 1–23, 2021.
</span>
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock"><span id="bib.bib79.1.1" class="ltx_text" style="font-size:90%;">
A. M. Elbir, S. Coleri, and K. V. Mishra, “Hybrid federated and centralized
learning,” </span><em id="bib.bib79.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2011.06892</em><span id="bib.bib79.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock"><span id="bib.bib80.1.1" class="ltx_text" style="font-size:90%;">
M. Chen, H. V. Poor, W. Saad, and S. Cui, “Wireless communications for
collaborative federated learning,” </span><em id="bib.bib80.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Magazine</em><span id="bib.bib80.3.3" class="ltx_text" style="font-size:90%;">,
vol. 58, no. 12, pp. 48–54, 2020.
</span>
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock"><span id="bib.bib81.1.1" class="ltx_text" style="font-size:90%;">
M. Aledhari, R. Razzak, R. M. Parizi, and F. Saeed, “Federated learning: A
survey on enabling technologies, protocols, and applications,” </span><em id="bib.bib81.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Access</em><span id="bib.bib81.3.3" class="ltx_text" style="font-size:90%;">, vol. 8, pp. 140 699–140 725, 2020.
</span>
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock"><span id="bib.bib82.1.1" class="ltx_text" style="font-size:90%;">
Q. Li, Z. Wen, Z. Wu, S. Hu, N. Wang, and B. He, “A survey on federated
learning systems: vision, hype and reality for data privacy and protection,”
</span><em id="bib.bib82.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1907.09693</em><span id="bib.bib82.3.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock"><span id="bib.bib83.1.1" class="ltx_text" style="font-size:90%;">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in </span><em id="bib.bib83.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Artificial Intelligence and Statistics</em><span id="bib.bib83.3.3" class="ltx_text" style="font-size:90%;">.   PMLR, 2017, pp. 1273–1282.
</span>
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock"><span id="bib.bib84.1.1" class="ltx_text" style="font-size:90%;">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith,
“Federated optimization in heterogeneous networks,” </span><em id="bib.bib84.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:1812.06127</em><span id="bib.bib84.3.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock"><span id="bib.bib85.1.1" class="ltx_text" style="font-size:90%;">
S. Ji, S. Pan, G. Long, X. Li, J. Jiang, and Z. Huang, “Learning private
neural language modeling with attentive aggregation,” in </span><em id="bib.bib85.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2019
International Joint Conference on Neural Networks (IJCNN)</em><span id="bib.bib85.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2019, pp. 1–8.
</span>
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock"><span id="bib.bib86.1.1" class="ltx_text" style="font-size:90%;">
Q. Li, Z. Wen, and B. He, “Practical federated gradient boosting decision
trees,” in </span><em id="bib.bib86.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial
Intelligence</em><span id="bib.bib86.3.3" class="ltx_text" style="font-size:90%;">, vol. 34, no. 04, 2020, pp. 4642–4649.
</span>
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock"><span id="bib.bib87.1.1" class="ltx_text" style="font-size:90%;">
T. Ryffel, A. Trask, M. Dahl, B. Wagner, J. Mancuso, D. Rueckert, and
J. Passerat-Palmbach, “A generic framework for privacy preserving deep
learning,” </span><em id="bib.bib87.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1811.04017</em><span id="bib.bib87.3.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock"><span id="bib.bib88.1.1" class="ltx_text" style="font-size:90%;">
S. Caldas, P. Wu, T. Li, J. Konečný, H. B. McMahan, V. Smith, and
A. Talwalkar, “LEAF: A benchmark for federated settings,” </span><em id="bib.bib88.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib88.3.3" class="ltx_text" style="font-size:90%;">,
vol. abs/1812.01097, 2018. [Online]. Available:
http://arxiv.org/abs/1812.01097
</span>
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock"><span id="bib.bib89.1.1" class="ltx_text" style="font-size:90%;">
Y. Ma, D. Yu, T. Wu, and H. Wang, “Paddlepaddle: An open-source deep learning
platform from industrial practice,” </span><em id="bib.bib89.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Frontiers of Data and Domputing</em><span id="bib.bib89.3.3" class="ltx_text" style="font-size:90%;">,
vol. 1, no. 1, pp. 105–115, 2019.
</span>
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock"><span id="bib.bib90.1.1" class="ltx_text" style="font-size:90%;">
WeBank, “Fate: An industrial grade federated learning framework,”
</span><em id="bib.bib90.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">https://www.fedai.org</em><span id="bib.bib90.3.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock"><span id="bib.bib91.1.1" class="ltx_text" style="font-size:90%;">
H. Ludwig, N. Baracaldo, G. Thomas, Y. Zhou, A. Anwar, S. Rajamoni, Y. Ong,
J. Radhakrishnan, A. Verma, M. Sinn </span><em id="bib.bib91.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib91.3.3" class="ltx_text" style="font-size:90%;">, “Ibm federated learning:
an enterprise framework white paper v0. 1,” </span><em id="bib.bib91.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2007.10987</em><span id="bib.bib91.5.5" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock"><span id="bib.bib92.1.1" class="ltx_text" style="font-size:90%;">
C. He, S. Li, J. So, X. Zeng, M. Zhang, H. Wang, X. Wang, P. Vepakomma,
A. Singh, H. Qiu </span><em id="bib.bib92.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib92.3.3" class="ltx_text" style="font-size:90%;">, “Fedml: A research library and benchmark for
federated machine learning,” </span><em id="bib.bib92.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2007.13518</em><span id="bib.bib92.5.5" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock"><span id="bib.bib93.1.1" class="ltx_text" style="font-size:90%;">
Z. Qin, H. Ye, G. Y. Li, and B.-H. F. Juang, “Deep learning in physical layer
communications,” </span><em id="bib.bib93.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Wireless Communications</em><span id="bib.bib93.3.3" class="ltx_text" style="font-size:90%;">, vol. 26, no. 2, pp.
93–99, 2019.
</span>
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock"><span id="bib.bib94.1.1" class="ltx_text" style="font-size:90%;">
T. O’shea and J. Hoydis, “An introduction to deep learning for the physical
layer,” </span><em id="bib.bib94.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Cognitive Communications and Networking</em><span id="bib.bib94.3.3" class="ltx_text" style="font-size:90%;">,
vol. 3, no. 4, pp. 563–575, 2017.
</span>
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock"><span id="bib.bib95.1.1" class="ltx_text" style="font-size:90%;">
N. Farsad, N. Shlezinger, A. J. Goldsmith, and Y. C. Eldar, “Data-driven
symbol detection via model-based machine learning,” </span><em id="bib.bib95.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2002.07806</em><span id="bib.bib95.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock"><span id="bib.bib96.1.1" class="ltx_text" style="font-size:90%;">
——, “Data-driven symbol detection via model-based machine learning,”
2020.
</span>
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock"><span id="bib.bib97.1.1" class="ltx_text" style="font-size:90%;">
M. B. Mashhadi, N. Shlezinger, Y. C. Eldar, and D. Gunduz, “Fedrec: Federated
learning of universal receivers over fading channels,” </span><em id="bib.bib97.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2011.07271</em><span id="bib.bib97.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock"><span id="bib.bib98.1.1" class="ltx_text" style="font-size:90%;">
J. Shi, H. Zhao, M. Wang, and Q. Tian, “Signal recognition based on federated
learning,” in </span><em id="bib.bib98.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE INFOCOM 2020-IEEE Conference on Computer
Communications Workshops (INFOCOM WKSHPS)</em><span id="bib.bib98.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 1105–1110.
</span>
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock"><span id="bib.bib99.1.1" class="ltx_text" style="font-size:90%;">
Y. Wang, G. Gui, H. Gacanin, B. Adebisi, H. Sari, and F. Adachi, “Federated
learning for automatic modulation classification under class imbalance and
varying noise condition,” </span><em id="bib.bib99.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Cognitive
Communications and Networking</em><span id="bib.bib99.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock"><span id="bib.bib100.1.1" class="ltx_text" style="font-size:90%;">
O. O. Oyerinde and S. H. Mneney, “Review of channel estimation for wireless
communication systems,” </span><em id="bib.bib100.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IETE Technical review</em><span id="bib.bib100.3.3" class="ltx_text" style="font-size:90%;">, vol. 29, no. 4, pp.
282–298, 2012.
</span>
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock"><span id="bib.bib101.1.1" class="ltx_text" style="font-size:90%;">
P. Dong, H. Zhang, G. Y. Li, I. S. Gaspar, and N. NaderiAlizadeh, “Deep
cnn-based channel estimation for mmwave massive mimo systems,” </span><em id="bib.bib101.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Journal of Selected Topics in Signal Processing</em><span id="bib.bib101.3.3" class="ltx_text" style="font-size:90%;">, vol. 13, no. 5, pp.
989–1000, 2019.
</span>
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock"><span id="bib.bib102.1.1" class="ltx_text" style="font-size:90%;">
A. M. Elbir, A. Papazafeiropoulos, P. Kourtessis, and S. Chatzinotas, “Deep
channel learning for large intelligent surfaces aided mm-wave massive mimo
systems,” </span><em id="bib.bib102.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Wireless Communications Letters</em><span id="bib.bib102.3.3" class="ltx_text" style="font-size:90%;">, vol. 9, no. 9, pp.
1447–1451, 2020.
</span>
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock"><span id="bib.bib103.1.1" class="ltx_text" style="font-size:90%;">
A. M. Elbir and S. Coleri, “Federated learning for channel estimation in
conventional and irs-assisted massive mimo,” </span><em id="bib.bib103.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2008.10846</em><span id="bib.bib103.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock"><span id="bib.bib104.1.1" class="ltx_text" style="font-size:90%;">
D. Xue, P. Han, Y. Liu, Z. Sha, Y. Liu, and L. Guo, “Low-cost
free-space-optical communication system with federated learning-based channel
prediction,” in </span><em id="bib.bib104.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 Asia Communications and Photonics Conference
(ACP) and International Conference on Information Photonics and Optical
Communications (IPOC)</em><span id="bib.bib104.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020,
pp. 1–3.
</span>
</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock"><span id="bib.bib105.1.1" class="ltx_text" style="font-size:90%;">
E. Onggosanusi, M. S. Rahman, L. Guo, Y. Kwak, H. Noh, Y. Kim, S. Faxer,
M. Harrison, M. Frenne, S. Grant </span><em id="bib.bib105.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib105.3.3" class="ltx_text" style="font-size:90%;">, “Modular and high-resolution
channel state information and beam management for 5g new radio,” </span><em id="bib.bib105.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Communications Magazine</em><span id="bib.bib105.5.5" class="ltx_text" style="font-size:90%;">, vol. 56, no. 3, pp. 48–55, 2018.
</span>
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock"><span id="bib.bib106.1.1" class="ltx_text" style="font-size:90%;">
C. Luo, J. Ji, Q. Wang, X. Chen, and P. Li, “Channel state information
prediction for 5g wireless communications: A deep learning approach,”
</span><em id="bib.bib106.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Network Science and Engineering</em><span id="bib.bib106.3.3" class="ltx_text" style="font-size:90%;">, vol. 7, no. 1,
pp. 227–236, 2018.
</span>
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock"><span id="bib.bib107.1.1" class="ltx_text" style="font-size:90%;">
W. Hou, J. Sun, G. Gui, T. Ohtsuki, A. M. Elbir, H. Gacanin, and H. Sari,
“Federated learning for dl-csi prediction in fdd massive mimo systems,”
</span><em id="bib.bib107.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Wireless Communications Letters</em><span id="bib.bib107.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock"><span id="bib.bib108.1.1" class="ltx_text" style="font-size:90%;">
F. Pase, M. Giordani, and M. Zorzi, “On the convergence time of federated
learning over wireless networks under imperfect csi,” </span><em id="bib.bib108.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2104.00331</em><span id="bib.bib108.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock"><span id="bib.bib109.1.1" class="ltx_text" style="font-size:90%;">
L. Dai, R. Jiao, F. Adachi, H. V. Poor, and L. Hanzo, “Deep learning for
wireless communications: An emerging interdisciplinary paradigm,” </span><em id="bib.bib109.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Wireless Communications</em><span id="bib.bib109.3.3" class="ltx_text" style="font-size:90%;">, vol. 27, no. 4, pp. 133–139, 2020.
</span>
</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock"><span id="bib.bib110.1.1" class="ltx_text" style="font-size:90%;">
A. M. Elbir and S. Coleri, “Federated learning for hybrid beamforming in
mm-wave massive mimo,” </span><em id="bib.bib110.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Letters</em><span id="bib.bib110.3.3" class="ltx_text" style="font-size:90%;">, vol. 24, no. 12,
pp. 2795–2799, 2020.
</span>
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock"><span id="bib.bib111.1.1" class="ltx_text" style="font-size:90%;">
I. Chafaa, R. Negrel, E. V. Belmega, and M. Debbah, “Federated channel-beam
mapping: from sub-6ghz to mmwave,” in </span><em id="bib.bib111.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE WCNC 2021 workshop:
distributed machine learning</em><span id="bib.bib111.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock"><span id="bib.bib112.1.1" class="ltx_text" style="font-size:90%;">
R. W. Heath, N. Gonzalez-Prelcic, S. Rangan, W. Roh, and A. M. Sayeed, “An
overview of signal processing techniques for millimeter wave mimo systems,”
</span><em id="bib.bib112.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE journal of selected topics in signal processing</em><span id="bib.bib112.3.3" class="ltx_text" style="font-size:90%;">, vol. 10, no. 3,
pp. 436–453, 2016.
</span>
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock"><span id="bib.bib113.1.1" class="ltx_text" style="font-size:90%;">
A. M. Elbir, S. Coleri, and K. V. Mishra, “Federated dropout learning for
hybrid beamforming with spatial path index modulation in multi-user
mmwave-mimo systems,” </span><em id="bib.bib113.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2102.07450</em><span id="bib.bib113.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock"><span id="bib.bib114.1.1" class="ltx_text" style="font-size:90%;">
Z. Wang, L. Liu, and S. Cui, “Intelligent reflecting surface assisted massive
mimo communications,” in </span><em id="bib.bib114.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE 21st International Workshop on
Signal Processing Advances in Wireless Communications (SPAWC)</em><span id="bib.bib114.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 1–5.
</span>
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock"><span id="bib.bib115.1.1" class="ltx_text" style="font-size:90%;">
D. Ma, L. Li, H. Ren, D. Wang, X. Li, and Z. Han, “Distributed rate
optimization for intelligent reflecting surface with federated learning,” in
</span><em id="bib.bib115.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE International Conference on Communications Workshops (ICC
Workshops)</em><span id="bib.bib115.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 1–6.
</span>
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock"><span id="bib.bib116.1.1" class="ltx_text" style="font-size:90%;">
L. Li, D. Ma, H. Ren, D. Wang, X. Tang, W. Liang, and T. Bai, “Enhanced
reconfigurable intelligent surface assisted mmwave communication: A federated
learning approach,” </span><em id="bib.bib116.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">China Communications</em><span id="bib.bib116.3.3" class="ltx_text" style="font-size:90%;">, vol. 17, no. 10, pp.
115–128, 2020.
</span>
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock"><span id="bib.bib117.1.1" class="ltx_text" style="font-size:90%;">
Z. Liu and I. Elhanany, “Rl-mac: a reinforcement learning based mac protocol
for wireless sensor networks,” </span><em id="bib.bib117.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Journal of Sensor
Networks</em><span id="bib.bib117.3.3" class="ltx_text" style="font-size:90%;">, vol. 1, no. 3-4, pp. 117–124, 2006.
</span>
</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock"><span id="bib.bib118.1.1" class="ltx_text" style="font-size:90%;">
M. Qiao, H. Zhao, S. Huang, L. Zhou, and S. Wang, “An intelligent mac protocol
selection method based on machine learning in wireless sensor networks,”
</span><em id="bib.bib118.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">KSII Transactions on Internet and Information Systems (TIIS)</em><span id="bib.bib118.3.3" class="ltx_text" style="font-size:90%;">, vol. 12,
no. 11, pp. 5425–5448, 2018.
</span>
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock"><span id="bib.bib119.1.1" class="ltx_text" style="font-size:90%;">
H. B. Pasandi and T. Nadeem, “Mac protocol design optimization using deep
learning,” in </span><em id="bib.bib119.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 International Conference on Artificial Intelligence
in Information and Communication (ICAIIC)</em><span id="bib.bib119.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 709–715.
</span>
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock"><span id="bib.bib120.1.1" class="ltx_text" style="font-size:90%;">
M. M. Amiri and D. Gündüz, “Machine learning at the wireless edge:
Distributed stochastic gradient descent over-the-air,” </span><em id="bib.bib120.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Transactions on Signal Processing</em><span id="bib.bib120.3.3" class="ltx_text" style="font-size:90%;">, vol. 68, pp. 2155–2169, 2020.
</span>
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock"><span id="bib.bib121.1.1" class="ltx_text" style="font-size:90%;">
O. Habachi, M.-A. Adjif, and J.-P. Cances, “Fast uplink grant for noma: A
federated learning based approach,” in </span><em id="bib.bib121.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Symposium on
Ubiquitous Networking</em><span id="bib.bib121.3.3" class="ltx_text" style="font-size:90%;">.   Springer,
2019, pp. 96–109.
</span>
</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock"><span id="bib.bib122.1.1" class="ltx_text" style="font-size:90%;">
R. Zhong, X. Liu, Y. Liu, Y. Chen, and Z. Han, “Mobile reconfigurable
intelligent surfaces for noma networks: Federated learning approaches,”
</span><em id="bib.bib122.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2105.09462</em><span id="bib.bib122.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock"><span id="bib.bib123.1.1" class="ltx_text" style="font-size:90%;">
M. Troglia, J. Melcher, Y. Zheng, D. Anthony, A. Yang, and T. Yang, “Fair:
Federated incumbent detection in cbrs band,” in </span><em id="bib.bib123.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2019 IEEE
International Symposium on Dynamic Spectrum Access Networks (DySPAN)</em><span id="bib.bib123.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2019, pp. 1–6.
</span>
</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock"><span id="bib.bib124.1.1" class="ltx_text" style="font-size:90%;">
N. Wang, J. Le, W. Li, L. Jiao, Z. Li, and K. Zeng, “Privacy protection and
efficient incumbent detection in spectrum sharing based on federated
learning,” in </span><em id="bib.bib124.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE Conference on Communications and Network
Security (CNS)</em><span id="bib.bib124.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 1–9.
</span>
</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock"><span id="bib.bib125.1.1" class="ltx_text" style="font-size:90%;">
L. Zhang, M. Xiao, G. Wu, M. Alam, Y.-C. Liang, and S. Li, “A survey of
advanced techniques for spectrum sharing in 5g networks,” </span><em id="bib.bib125.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Wireless Communications</em><span id="bib.bib125.3.3" class="ltx_text" style="font-size:90%;">, vol. 24, no. 5, pp. 44–51, 2017.
</span>
</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock"><span id="bib.bib126.1.1" class="ltx_text" style="font-size:90%;">
L. Liang, H. Ye, and G. Y. Li, “Spectrum sharing in vehicular networks based
on multi-agent reinforcement learning,” </span><em id="bib.bib126.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Journal on Selected Areas
in Communications</em><span id="bib.bib126.3.3" class="ltx_text" style="font-size:90%;">, vol. 37, no. 10, pp. 2282–2292, 2019.
</span>
</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock"><span id="bib.bib127.1.1" class="ltx_text" style="font-size:90%;">
S. Valenti, D. Rossi, A. Dainotti, A. Pescapè, A. Finamore, and M. Mellia,
“Reviewing traffic classification,” in </span><em id="bib.bib127.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Data Traffic Monitoring and
Analysis</em><span id="bib.bib127.3.3" class="ltx_text" style="font-size:90%;">.   Springer, 2013, pp.
123–147.
</span>
</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock"><span id="bib.bib128.1.1" class="ltx_text" style="font-size:90%;">
H. Mun and Y. Lee, “Internet traffic classification with federated learning,”
</span><em id="bib.bib128.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Electronics</em><span id="bib.bib128.3.3" class="ltx_text" style="font-size:90%;">, vol. 10, no. 1, p. 27, 2021.
</span>
</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock"><span id="bib.bib129.1.1" class="ltx_text" style="font-size:90%;">
U. Majeed, L. U. Khan, and C. S. Hong, “Cross-silo horizontal federated
learning for flow-based time-related-features oriented traffic
classification,” in </span><em id="bib.bib129.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 21st Asia-Pacific Network Operations and
Management Symposium (APNOMS)</em><span id="bib.bib129.3.3" class="ltx_text" style="font-size:90%;">.   IEEE,
2020, pp. 389–392.
</span>
</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock"><span id="bib.bib130.1.1" class="ltx_text" style="font-size:90%;">
Y. Peng, M. He, and Y. Wang, “A federated semi-supervised learning approach
for network traffic classification,” </span><em id="bib.bib130.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2107.03933</em><span id="bib.bib130.3.3" class="ltx_text" style="font-size:90%;">,
2021.
</span>
</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock"><span id="bib.bib131.1.1" class="ltx_text" style="font-size:90%;">
M. Nazir, A. Sabah, S. Sarwar, A. Yaseen, and A. Jurcut, “Power and resource
allocation in wireless communication network,” </span><em id="bib.bib131.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Wireless Personal
Communications</em><span id="bib.bib131.3.3" class="ltx_text" style="font-size:90%;">, pp. 1–24, 2021.
</span>
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock"><span id="bib.bib132.1.1" class="ltx_text" style="font-size:90%;">
L. Ale, N. Zhang, H. Wu, D. Chen, and T. Han, “Online proactive caching in
mobile edge computing using bidirectional deep recurrent neural network,”
</span><em id="bib.bib132.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</em><span id="bib.bib132.3.3" class="ltx_text" style="font-size:90%;">, vol. 6, no. 3, pp. 5520–5530, 2019.
</span>
</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock"><span id="bib.bib133.1.1" class="ltx_text" style="font-size:90%;">
R. Dong, C. She, W. Hardjawana, Y. Li, and B. Vucetic, “Deep learning for
hybrid 5g services in mobile edge computing systems: Learn from a digital
twin,” </span><em id="bib.bib133.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Wireless Communications</em><span id="bib.bib133.3.3" class="ltx_text" style="font-size:90%;">, vol. 18, no. 10,
pp. 4692–4707, 2019.
</span>
</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock"><span id="bib.bib134.1.1" class="ltx_text" style="font-size:90%;">
S. Wang, M. Chen, C. Yin, W. Saad, C. S. Hong, S. Cui, and H. V. Poor,
“Federated learning for task and resource allocation in wireless high
altitude balloon networks,” </span><em id="bib.bib134.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</em><span id="bib.bib134.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock"><span id="bib.bib135.1.1" class="ltx_text" style="font-size:90%;">
M. Yan, B. Chen, G. Feng, and S. Qin, “Federated cooperation and augmentation
for power allocation in decentralized wireless networks,” </span><em id="bib.bib135.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Access</em><span id="bib.bib135.3.3" class="ltx_text" style="font-size:90%;">, vol. 8, pp. 48 088–48 100, 2020.
</span>
</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock"><span id="bib.bib136.1.1" class="ltx_text" style="font-size:90%;">
R. Ali, Y. B. Zikria, S. Garg, A. K. Bashir, M. S. Obaidat, and H. S. Kim, “A
federated reinforcement learning framework for incumbent technologies in
beyond 5g networks,” </span><em id="bib.bib136.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Network</em><span id="bib.bib136.3.3" class="ltx_text" style="font-size:90%;">, vol. 35, no. 4, pp. 152–159,
2021.
</span>
</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock"><span id="bib.bib137.1.1" class="ltx_text" style="font-size:90%;">
F. Foukalas, “Federated-learning-driven radio access networks,” </span><em id="bib.bib137.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Wireless Communications</em><span id="bib.bib137.3.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock"><span id="bib.bib138.1.1" class="ltx_text" style="font-size:90%;">
D. López-Pérez, A. De Domenico, N. Piovesan, G. Xinli, H. Bao,
S. Qitao, and M. Debbah, “A survey on 5g radio access network energy
efficiency: Massive mimo, lean carrier design, sleep modes, and machine
learning,” </span><em id="bib.bib138.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Surveys &amp; Tutorials</em><span id="bib.bib138.3.3" class="ltx_text" style="font-size:90%;">, vol. 24, no. 1,
pp. 653–697, 2022.
</span>
</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock"><span id="bib.bib139.1.1" class="ltx_text" style="font-size:90%;">
Z. Mahrez, M. B. Driss, E. Sabir, W. Saad, and E. Driouch, “Benchmarking of
anomaly detection techniques in o-ran for handover optimization,” in
</span><em id="bib.bib139.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2023 International Wireless Communications and Mobile Computing
(IWCMC)</em><span id="bib.bib139.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2023, pp. 119–125.
</span>
</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock"><span id="bib.bib140.1.1" class="ltx_text" style="font-size:90%;">
A. Abouaomar, A. Taik, A. Filali, and S. Cherkaoui, “Federated learning for
ran slicing in beyond 5g networks,” </span><em id="bib.bib140.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2206.11328</em><span id="bib.bib140.3.3" class="ltx_text" style="font-size:90%;">,
2022.
</span>
</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock"><span id="bib.bib141.1.1" class="ltx_text" style="font-size:90%;">
S. Manzoor, A. N. Mian, A. Zoha, and M. A. Imran, “Federated learning
empowered mobility-aware proactive content offloading framework for fog radio
access networks,” </span><em id="bib.bib141.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Future Generation Computer Systems</em><span id="bib.bib141.3.3" class="ltx_text" style="font-size:90%;">, vol. 133, pp.
307–319, 2022.
</span>
</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock"><span id="bib.bib142.1.1" class="ltx_text" style="font-size:90%;">
H. Zhang, H. Zhou, and M. Erol-Kantarci, “Federated deep reinforcement
learning for resource allocation in o-ran slicing,” in </span><em id="bib.bib142.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">GLOBECOM
2022-2022 IEEE Global Communications Conference</em><span id="bib.bib142.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2022, pp. 958–963.
</span>
</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock"><span id="bib.bib143.1.1" class="ltx_text" style="font-size:90%;">
M. Luca, G. Barlacchi, B. Lepri, and L. Pappalardo, “Deep learning for human
mobility: a survey on data and models,” </span><em id="bib.bib143.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2012.02825</em><span id="bib.bib143.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock"><span id="bib.bib144.1.1" class="ltx_text" style="font-size:90%;">
J. Feng, Y. Li, C. Zhang, F. Sun, F. Meng, A. Guo, and D. Jin, “Deepmove:
Predicting human mobility with attentional recurrent networks,” in
</span><em id="bib.bib144.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 2018 world wide web conference</em><span id="bib.bib144.3.3" class="ltx_text" style="font-size:90%;">, 2018, pp.
1459–1468.
</span>
</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock"><span id="bib.bib145.1.1" class="ltx_text" style="font-size:90%;">
T. Anagnostopoulos, C. Anagnostopoulos, and S. Hadjiefthymiades, “Mobility
prediction based on machine learning,” in </span><em id="bib.bib145.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2011 IEEE 12th International
Conference on Mobile Data Management</em><span id="bib.bib145.3.3" class="ltx_text" style="font-size:90%;">, vol. 2.   IEEE, 2011, pp. 27–30.
</span>
</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock"><span id="bib.bib146.1.1" class="ltx_text" style="font-size:90%;">
A. Li, S. Wang, W. Li, S. Liu, and S. Zhang, “Predicting human mobility with
federated learning,” in </span><em id="bib.bib146.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 28th International
Conference on Advances in Geographic Information Systems</em><span id="bib.bib146.3.3" class="ltx_text" style="font-size:90%;">, 2020, pp.
441–444.
</span>
</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock"><span id="bib.bib147.1.1" class="ltx_text" style="font-size:90%;">
J. Feng, C. Rong, F. Sun, D. Guo, and Y. Li, “Pmf: A privacy-preserving human
mobility prediction framework via federated learning,” </span><em id="bib.bib147.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of
the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</em><span id="bib.bib147.3.3" class="ltx_text" style="font-size:90%;">,
vol. 4, no. 1, pp. 1–21, 2020.
</span>
</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock"><span id="bib.bib148.1.1" class="ltx_text" style="font-size:90%;">
K. Sozinov, V. Vlassov, and S. Girdzijauskas, “Human activity recognition
using federated learning,” in </span><em id="bib.bib148.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2018 IEEE Intl Conf on Parallel &amp;
Distributed Processing with Applications, Ubiquitous Computing &amp;
Communications, Big Data &amp; Cloud Computing, Social Computing &amp; Networking,
Sustainable Computing &amp; Communications
(ISPA/IUCC/BDCloud/SocialCom/SustainCom)</em><span id="bib.bib148.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2018, pp. 1103–1111.
</span>
</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock"><span id="bib.bib149.1.1" class="ltx_text" style="font-size:90%;">
J. Wu, Q. Liu, Z. Huang, Y. Ning, H. Wang, E. Chen, J. Yi, and B. Zhou,
“Hierarchical personalized federated learning for user modeling,” in
</span><em id="bib.bib149.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the Web Conference 2021</em><span id="bib.bib149.3.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 957–968.
</span>
</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock"><span id="bib.bib150.1.1" class="ltx_text" style="font-size:90%;">
A. Bourdoux, A. N. Barreto, B. van Liempd, C. de Lima, D. Dardari, D. Belot,
E.-S. Lohan, G. Seco-Granados, H. Sarieddeen, H. Wymeersch </span><em id="bib.bib150.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib150.3.3" class="ltx_text" style="font-size:90%;">,
“6g white paper on localization and sensing,” </span><em id="bib.bib150.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2006.01779</em><span id="bib.bib150.5.5" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock"><span id="bib.bib151.1.1" class="ltx_text" style="font-size:90%;">
F. Yin, Z. Lin, Q. Kong, Y. Xu, D. Li, S. Theodoridis, and S. R. Cui, “Fedloc:
Federated learning framework for data-driven cooperative localization and
location data processing,” </span><em id="bib.bib151.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Open Journal of Signal Processing</em><span id="bib.bib151.3.3" class="ltx_text" style="font-size:90%;">,
vol. 1, pp. 187–215, 2020.
</span>
</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock"><span id="bib.bib152.1.1" class="ltx_text" style="font-size:90%;">
B. S. Ciftler, A. Albaseer, N. Lasla, and M. Abdallah, “Federated learning for
localization: A privacy-preserving crowdsourcing method,” </span><em id="bib.bib152.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv
preprint arXiv:2001.01911</em><span id="bib.bib152.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock"><span id="bib.bib153.1.1" class="ltx_text" style="font-size:90%;">
Z. Xiao, X. Xu, H. Xing, F. Song, X. Wang, and B. Zhao, “A federated learning
system with enhanced feature extraction for human activity recognition,”
</span><em id="bib.bib153.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Knowledge-Based Systems</em><span id="bib.bib153.3.3" class="ltx_text" style="font-size:90%;">, p. 107338, 2021.
</span>
</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock"><span id="bib.bib154.1.1" class="ltx_text" style="font-size:90%;">
L. U. Khan, I. Yaqoob, N. H. Tran, Z. Han, and C. S. Hong, “Network slicing:
Recent advances, taxonomy, requirements, and open research challenges,”
</span><em id="bib.bib154.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Access</em><span id="bib.bib154.3.3" class="ltx_text" style="font-size:90%;">, vol. 8, pp. 36 009–36 028, 2020.
</span>
</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock"><span id="bib.bib155.1.1" class="ltx_text" style="font-size:90%;">
S. A. Kazmi, L. U. Khan, N. H. Tran, and C. S. Hong, </span><em id="bib.bib155.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Network slicing for
5G and beyond networks</em><span id="bib.bib155.3.3" class="ltx_text" style="font-size:90%;">.   Springer,
2019, vol. 1.
</span>
</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock"><span id="bib.bib156.1.1" class="ltx_text" style="font-size:90%;">
W. Wu, C. Zhou, M. Li, H. Wu, H. Zhou, N. Zhang, W. Zhuang </span><em id="bib.bib156.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib156.3.3" class="ltx_text" style="font-size:90%;">,
“Ai-native network slicing for 6g networks,” </span><em id="bib.bib156.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2105.08576</em><span id="bib.bib156.5.5" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock"><span id="bib.bib157.1.1" class="ltx_text" style="font-size:90%;">
L. U. Khan, S. R. Pandey, N. H. Tran, W. Saad, Z. Han, M. N. Nguyen, and C. S.
Hong, “Federated learning for edge networks: Resource optimization and
incentive mechanism,” </span><em id="bib.bib157.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Magazine</em><span id="bib.bib157.3.3" class="ltx_text" style="font-size:90%;">, vol. 58, no. 10,
pp. 88–93, 2020.
</span>
</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock"><span id="bib.bib158.1.1" class="ltx_text" style="font-size:90%;">
X. Wang, Y. Han, C. Wang, Q. Zhao, X. Chen, and M. Chen, “In-edge ai:
Intelligentizing mobile edge computing, caching and communication by
federated learning,” </span><em id="bib.bib158.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Network</em><span id="bib.bib158.3.3" class="ltx_text" style="font-size:90%;">, vol. 33, no. 5, pp. 156–165,
2019.
</span>
</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock"><span id="bib.bib159.1.1" class="ltx_text" style="font-size:90%;">
S. Messaoud, A. Bradai, O. B. Ahmed, P. T. A. Quang, M. Atri, and M. S.
Hossain, “Deep federated q-learning-based network slicing for industrial
iot,” </span><em id="bib.bib159.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Industrial Informatics</em><span id="bib.bib159.3.3" class="ltx_text" style="font-size:90%;">, vol. 17, no. 8,
pp. 5572–5582, 2020.
</span>
</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock"><span id="bib.bib160.1.1" class="ltx_text" style="font-size:90%;">
B. Brik and A. Ksentini, “On predicting service-oriented network slices
performances in 5g: A federated learning approach,” in </span><em id="bib.bib160.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE 45th
Conference on Local Computer Networks (LCN)</em><span id="bib.bib160.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 164–171.
</span>
</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock"><span id="bib.bib161.1.1" class="ltx_text" style="font-size:90%;">
Y.-J. Liu, G. Feng, Y. Sun, S. Qin, and Y.-C. Liang, “Device association for
ran slicing based on hybrid federated deep reinforcement learning,”
</span><em id="bib.bib161.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Vehicular Technology</em><span id="bib.bib161.3.3" class="ltx_text" style="font-size:90%;">, vol. 69, no. 12, pp.
15 731–15 745, 2020.
</span>
</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock"><span id="bib.bib162.1.1" class="ltx_text" style="font-size:90%;">
Y. Li, A. Huang, Y. Xiao, X. Ge, S. Sun, and H.-C. Chao, “Federated
orchestration for network slicing of bandwidth and computational resource,”
</span><em id="bib.bib162.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2002.02451</em><span id="bib.bib162.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock"><span id="bib.bib163.1.1" class="ltx_text" style="font-size:90%;">
S. Sendra, A. Rego, J. Lloret, J. M. Jimenez, and O. Romero, “Including
artificial intelligence in a routing protocol using software defined
networks,” in </span><em id="bib.bib163.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2017 IEEE International Conference on Communications
Workshops (ICC Workshops)</em><span id="bib.bib163.3.3" class="ltx_text" style="font-size:90%;">.   IEEE,
2017, pp. 670–674.
</span>
</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock"><span id="bib.bib164.1.1" class="ltx_text" style="font-size:90%;">
H. Yao, T. Mai, C. Jiang, L. Kuang, and S. Guo, “Ai routers &amp; network mind: A
hybrid machine learning paradigm for packet routing,” </span><em id="bib.bib164.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Computational Intelligence Magazine</em><span id="bib.bib164.3.3" class="ltx_text" style="font-size:90%;">, vol. 14, no. 4, pp. 21–30, 2019.
</span>
</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock"><span id="bib.bib165.1.1" class="ltx_text" style="font-size:90%;">
A. Sacco, F. Esposito, and G. Marchetto, “A federated learning approach to
routing in challenged sdn-enabled edge networks,” in </span><em id="bib.bib165.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 6th IEEE
Conference on Network Softwarization (NetSoft)</em><span id="bib.bib165.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 150–154.
</span>
</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock"><span id="bib.bib166.1.1" class="ltx_text" style="font-size:90%;">
Y. Cao, S. Maghsudi, and T. Ohtsuki, “Mobility-aware routing and caching: A
federated learning assisted approach,” </span><em id="bib.bib166.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2102.10743</em><span id="bib.bib166.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock"><span id="bib.bib167.1.1" class="ltx_text" style="font-size:90%;">
M. Wilbur, C. Samal, J. P. Talusan, K. Yasumoto, and A. Dubey, “Time-dependent
decentralized routing using federated learning,” in </span><em id="bib.bib167.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE 23rd
International Symposium on Real-Time Distributed Computing (ISORC)</em><span id="bib.bib167.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 56–64.
</span>
</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock"><span id="bib.bib168.1.1" class="ltx_text" style="font-size:90%;">
U. Majeed, S. S. Hassan, and C. S. Hong, “Cross-silo model-based secure
federated transfer learning for flow-based traffic classification,” in
</span><em id="bib.bib168.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 International Conference on Information Networking (ICOIN)</em><span id="bib.bib168.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2021, pp. 588–593.
</span>
</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock"><span id="bib.bib169.1.1" class="ltx_text" style="font-size:90%;">
A. Yazdinejad, R. M. Parizi, A. Dehghantanha, and H. Karimipour, “Federated
learning for drone authentication,” </span><em id="bib.bib169.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Ad Hoc Networks</em><span id="bib.bib169.3.3" class="ltx_text" style="font-size:90%;">, vol. 120, p.
102574, 2021. [Online]. Available:
https://www.sciencedirect.com/science/article/pii/S1570870521001165
</span>
</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[170]</span>
<span class="ltx_bibblock"><span id="bib.bib170.1.1" class="ltx_text" style="font-size:90%;">
W. Y. B. Lim, J. Huang, Z. Xiong, J. Kang, D. Niyato, X.-S. Hua, C. Leung, and
C. Miao, “Towards federated learning in uav-enabled internet of vehicles: A
multi-dimensional contract-matching approach,” </span><em id="bib.bib170.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on
Intelligent Transportation Systems</em><span id="bib.bib170.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[171]</span>
<span class="ltx_bibblock"><span id="bib.bib171.1.1" class="ltx_text" style="font-size:90%;">
S. Wang, S. Hosseinalipour, M. Gorlatova, C. G. Brinton, and M. Chiang,
“Uav-assisted online machine learning over multi-tiered networks: A
hierarchical nested personalized federated learning approach,” </span><em id="bib.bib171.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv
preprint arXiv:2106.15734</em><span id="bib.bib171.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[172]</span>
<span class="ltx_bibblock"><span id="bib.bib172.1.1" class="ltx_text" style="font-size:90%;">
Y. Wang, Z. Su, N. Zhang, and A. Benslimane, “Learning in the air: Secure
federated learning for uav-assisted crowdsensing,” </span><em id="bib.bib172.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions
on network science and engineering</em><span id="bib.bib172.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[173]</span>
<span class="ltx_bibblock"><span id="bib.bib173.1.1" class="ltx_text" style="font-size:90%;">
T. Zeng, O. Semiari, M. Mozaffari, M. Chen, W. Saad, and M. Bennis, “Federated
learning in the sky: Joint power allocation and scheduling with uav swarms,”
in </span><em id="bib.bib173.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICC 2020-2020 IEEE International Conference on Communications
(ICC)</em><span id="bib.bib173.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 1–6.
</span>
</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[174]</span>
<span class="ltx_bibblock"><span id="bib.bib174.1.1" class="ltx_text" style="font-size:90%;">
H. Zhang and L. Hanzo, “Federated learning assisted multi-uav networks,”
</span><em id="bib.bib174.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Vehicular Technology</em><span id="bib.bib174.3.3" class="ltx_text" style="font-size:90%;">, vol. 69, no. 11, pp.
14 104–14 109, 2020.
</span>
</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[175]</span>
<span class="ltx_bibblock"><span id="bib.bib175.1.1" class="ltx_text" style="font-size:90%;">
N. I. Mowla, N. H. Tran, I. Doh, and K. Chae, “Federated learning-based
cognitive detection of jamming attack in flying ad-hoc network,” </span><em id="bib.bib175.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Access</em><span id="bib.bib175.3.3" class="ltx_text" style="font-size:90%;">, vol. 8, pp. 4338–4350, 2019.
</span>
</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[176]</span>
<span class="ltx_bibblock"><span id="bib.bib176.1.1" class="ltx_text" style="font-size:90%;">
D. Kwon, J. Jeon, S. Park, J. Kim, and S. Cho, “Multiagent ddpg-based deep
learning for smart ocean federated learning iot networks,” </span><em id="bib.bib176.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Internet of Things Journal</em><span id="bib.bib176.3.3" class="ltx_text" style="font-size:90%;">, vol. 7, no. 10, pp. 9895–9903, 2020.
</span>
</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[177]</span>
<span class="ltx_bibblock"><span id="bib.bib177.1.1" class="ltx_text" style="font-size:90%;">
H. Zhao, F. Ji, Q. Guan, Q. Li, S. Wang, H. Dong, and M. Wen, “Federated meta
learning enhanced acoustic radio cooperative framework for ocean of things
underwater acoustic communications,” </span><em id="bib.bib177.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2105.13296</em><span id="bib.bib177.3.3" class="ltx_text" style="font-size:90%;">,
2021.
</span>
</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[178]</span>
<span class="ltx_bibblock"><span id="bib.bib178.1.1" class="ltx_text" style="font-size:90%;">
C. Fang, Y. Guo, N. Wang, and A. Ju, “Highly efficient federated learning with
strong privacy preservation in cloud computing,” </span><em id="bib.bib178.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computers &amp;
Security</em><span id="bib.bib178.3.3" class="ltx_text" style="font-size:90%;">, vol. 96, p. 101889, 2020.
</span>
</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[179]</span>
<span class="ltx_bibblock"><span id="bib.bib179.1.1" class="ltx_text" style="font-size:90%;">
X. Zhang, M. Hu, J. Xia, T. Wei, M. Chen, and S. Hu, “Efficient federated
learning for cloud-based aiot applications,” </span><em id="bib.bib179.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on
Computer-Aided Design of Integrated Circuits and Systems</em><span id="bib.bib179.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[180]</span>
<span class="ltx_bibblock"><span id="bib.bib180.1.1" class="ltx_text" style="font-size:90%;">
L. Liu, J. Zhang, S. Song, and K. B. Letaief, “Client-edge-cloud hierarchical
federated learning,” in </span><em id="bib.bib180.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICC 2020-2020 IEEE International Conference on
Communications (ICC)</em><span id="bib.bib180.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp.
1–6.
</span>
</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[181]</span>
<span class="ltx_bibblock"><span id="bib.bib181.1.1" class="ltx_text" style="font-size:90%;">
Z. Zhao, C. Feng, H. H. Yang, and X. Luo, “Federated-learning-enabled
intelligent fog radio access networks: Fundamental theory, key techniques,
and future trends,” </span><em id="bib.bib181.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE wireless communications</em><span id="bib.bib181.3.3" class="ltx_text" style="font-size:90%;">, vol. 27, no. 2, pp.
22–28, 2020.
</span>
</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[182]</span>
<span class="ltx_bibblock"><span id="bib.bib182.1.1" class="ltx_text" style="font-size:90%;">
Y. Wu, Y. Jiang, M. Bennis, F. Zheng, X. Gao, and X. You, “Content popularity
prediction in fog radio access networks: A federated learning based
approach,” in </span><em id="bib.bib182.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICC 2020-2020 IEEE International Conference on
Communications (ICC)</em><span id="bib.bib182.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp.
1–6.
</span>
</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[183]</span>
<span class="ltx_bibblock"><span id="bib.bib183.1.1" class="ltx_text" style="font-size:90%;">
Y. Qu, L. Gao, T. H. Luan, Y. Xiang, S. Yu, B. Li, and G. Zheng,
“Decentralized privacy using blockchain-enabled federated learning in fog
computing,” </span><em id="bib.bib183.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</em><span id="bib.bib183.3.3" class="ltx_text" style="font-size:90%;">, vol. 7, no. 6, pp.
5171–5183, 2020.
</span>
</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[184]</span>
<span class="ltx_bibblock"><span id="bib.bib184.1.1" class="ltx_text" style="font-size:90%;">
A. A. Khuwaja, Y. Chen, N. Zhao, M.-S. Alouini, and P. Dobbins, “A survey of
channel modeling for uav communications,” </span><em id="bib.bib184.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Surveys
&amp; Tutorials</em><span id="bib.bib184.3.3" class="ltx_text" style="font-size:90%;">, vol. 20, no. 4, pp. 2804–2821, 2018.
</span>
</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[185]</span>
<span class="ltx_bibblock"><span id="bib.bib185.1.1" class="ltx_text" style="font-size:90%;">
V. Hassija, V. Chamola, A. Agrawal, A. Goyal, N. C. Luong, D. Niyato, F. R. Yu,
and M. Guizani, “Fast, reliable, and secure drone communication: A
comprehensive survey,” </span><em id="bib.bib185.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2105.01347</em><span id="bib.bib185.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[186]</span>
<span class="ltx_bibblock"><span id="bib.bib186.1.1" class="ltx_text" style="font-size:90%;">
P. S. Bithas, E. T. Michailidis, N. Nomikos, D. Vouyioukas, and A. G. Kanatas,
“A survey on machine-learning techniques for uav-based communications,”
</span><em id="bib.bib186.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Sensors</em><span id="bib.bib186.3.3" class="ltx_text" style="font-size:90%;">, vol. 19, no. 23, p. 5170, 2019.
</span>
</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[187]</span>
<span class="ltx_bibblock"><span id="bib.bib187.1.1" class="ltx_text" style="font-size:90%;">
B. Brik, A. Ksentini, and M. Bouaziz, “Federated learning for uavs-enabled
wireless networks: Use cases, challenges, and open problems,” </span><em id="bib.bib187.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Access</em><span id="bib.bib187.3.3" class="ltx_text" style="font-size:90%;">, vol. 8, pp. 53 841–53 849, 2020.
</span>
</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[188]</span>
<span class="ltx_bibblock"><span id="bib.bib188.1.1" class="ltx_text" style="font-size:90%;">
K. Sentz and S. Ferson, “Combination of evidence in dempster-shafer theory,”
</span><em id="bib.bib188.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">,</em><span id="bib.bib188.3.3" class="ltx_text" style="font-size:90%;">, 2002.
</span>
</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[189]</span>
<span class="ltx_bibblock"><span id="bib.bib189.1.1" class="ltx_text" style="font-size:90%;">
M. C. Domingo, “Securing underwater wireless communication networks,”
</span><em id="bib.bib189.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Wireless Communications</em><span id="bib.bib189.3.3" class="ltx_text" style="font-size:90%;">, vol. 18, no. 1, pp. 22–28, 2011.
</span>
</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[190]</span>
<span class="ltx_bibblock"><span id="bib.bib190.1.1" class="ltx_text" style="font-size:90%;">
N. Victor, M. Alazab, S. Bhattacharya, S. Magnusson, P. K. R. Maddikunta,
K. Ramana, T. R. Gadekallu </span><em id="bib.bib190.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib190.3.3" class="ltx_text" style="font-size:90%;">, “Federated learning for iout:
Concepts, applications, challenges and opportunities,” </span><em id="bib.bib190.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2207.13976</em><span id="bib.bib190.5.5" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[191]</span>
<span class="ltx_bibblock"><span id="bib.bib191.1.1" class="ltx_text" style="font-size:90%;">
G. Zhu, D. Liu, Y. Du, C. You, J. Zhang, and K. Huang, “Toward an intelligent
edge: Wireless communication meets machine learning,” </span><em id="bib.bib191.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
communications magazine</em><span id="bib.bib191.3.3" class="ltx_text" style="font-size:90%;">, vol. 58, no. 1, pp. 19–25, 2020.
</span>
</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[192]</span>
<span class="ltx_bibblock"><span id="bib.bib192.1.1" class="ltx_text" style="font-size:90%;">
P. Habibi, M. Farhoudi, S. Kazemian, S. Khorsandi, and A. Leon-Garcia, “Fog
computing: a comprehensive architectural survey,” </span><em id="bib.bib192.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Access</em><span id="bib.bib192.3.3" class="ltx_text" style="font-size:90%;">,
vol. 8, pp. 69 105–69 133, 2020.
</span>
</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[193]</span>
<span class="ltx_bibblock"><span id="bib.bib193.1.1" class="ltx_text" style="font-size:90%;">
A. Renda, P. Ducange, F. Marcelloni, D. Sabella, M. C. Filippou, G. Nardini,
G. Stea, A. Virdis, D. Micheli, D. Rapone </span><em id="bib.bib193.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib193.3.3" class="ltx_text" style="font-size:90%;">, “Federated learning
of explainable ai models in 6g systems: Towards secure and automated vehicle
networking,” </span><em id="bib.bib193.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">Information</em><span id="bib.bib193.5.5" class="ltx_text" style="font-size:90%;">, vol. 13, no. 8, p. 395, 2022.
</span>
</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[194]</span>
<span class="ltx_bibblock"><span id="bib.bib194.1.1" class="ltx_text" style="font-size:90%;">
S. R. Pokhrel and J. Choi, “Improving tcp performance over wifi for internet
of vehicles: A federated learning approach,” </span><em id="bib.bib194.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on
Vehicular Technology</em><span id="bib.bib194.3.3" class="ltx_text" style="font-size:90%;">, vol. 69, no. 6, pp. 6798–6802, 2020.
</span>
</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[195]</span>
<span class="ltx_bibblock"><span id="bib.bib195.1.1" class="ltx_text" style="font-size:90%;">
S. R. Pokhrel and S. Singh, “Compound tcp performance for industry 4.0 wifi: A
cognitive federated learning approach,” </span><em id="bib.bib195.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on
Industrial Informatics</em><span id="bib.bib195.3.3" class="ltx_text" style="font-size:90%;">, vol. 17, no. 3, pp. 2143–2151, 2020.
</span>
</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[196]</span>
<span class="ltx_bibblock"><span id="bib.bib196.1.1" class="ltx_text" style="font-size:90%;">
P. K. Sharma, J. H. Park, and K. Cho, “Blockchain and federated learning-based
distributed computing defence framework for sustainable society,”
</span><em id="bib.bib196.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Sustainable Cities and Society</em><span id="bib.bib196.3.3" class="ltx_text" style="font-size:90%;">, vol. 59, p. 102220, 2020.
</span>
</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[197]</span>
<span class="ltx_bibblock"><span id="bib.bib197.1.1" class="ltx_text" style="font-size:90%;">
S. Savazzi, M. Nicoli, and V. Rampa, “Federated learning with cooperating
devices: A consensus approach for massive iot networks,” </span><em id="bib.bib197.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Internet
of Things Journal</em><span id="bib.bib197.3.3" class="ltx_text" style="font-size:90%;">, vol. 7, no. 5, pp. 4641–4654, 2020.
</span>
</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[198]</span>
<span class="ltx_bibblock"><span id="bib.bib198.1.1" class="ltx_text" style="font-size:90%;">
K. Wazny, ““crowdsourcing” ten years in: A review,” </span><em id="bib.bib198.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of
global health</em><span id="bib.bib198.3.3" class="ltx_text" style="font-size:90%;">, vol. 7, no. 2, 2017.
</span>
</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[199]</span>
<span class="ltx_bibblock"><span id="bib.bib199.1.1" class="ltx_text" style="font-size:90%;">
Z. Li, J. Liu, J. Hao, H. Wang, and M. Xian, “Crowdsfl: A secure crowd
computing framework based on blockchain and federated learning,”
</span><em id="bib.bib199.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Electronics</em><span id="bib.bib199.3.3" class="ltx_text" style="font-size:90%;">, vol. 9, no. 5, p. 773, 2020.
</span>
</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[200]</span>
<span class="ltx_bibblock"><span id="bib.bib200.1.1" class="ltx_text" style="font-size:90%;">
Y. Zhao, J. Zhao, M. Yang, T. Wang, N. Wang, L. Lyu, D. Niyato, and K.-Y. Lam,
“Local differential privacy-based federated learning for internet of
things,” </span><em id="bib.bib200.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</em><span id="bib.bib200.3.3" class="ltx_text" style="font-size:90%;">, vol. 8, no. 11, pp.
8836–8853, 2020.
</span>
</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[201]</span>
<span class="ltx_bibblock"><span id="bib.bib201.1.1" class="ltx_text" style="font-size:90%;">
A. Capponi, C. Fiandrino, B. Kantarci, L. Foschini, D. Kliazovich, and
P. Bouvry, “A survey on mobile crowdsensing systems: Challenges, solutions,
and opportunities,” </span><em id="bib.bib201.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE communications surveys &amp; tutorials</em><span id="bib.bib201.3.3" class="ltx_text" style="font-size:90%;">,
vol. 21, no. 3, pp. 2419–2465, 2019.
</span>
</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[202]</span>
<span class="ltx_bibblock"><span id="bib.bib202.1.1" class="ltx_text" style="font-size:90%;">
L. Wang, H. Yu, and X. Han, “Federated crowdsensing: Framework and
challenges,” </span><em id="bib.bib202.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2011.03208</em><span id="bib.bib202.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[203]</span>
<span class="ltx_bibblock"><span id="bib.bib203.1.1" class="ltx_text" style="font-size:90%;">
B. Zhao, X. Liu, and W.-n. Chen, “When crowdsensing meets federated learning:
Privacy-preserving mobile crowdsensing system,” </span><em id="bib.bib203.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2102.10109</em><span id="bib.bib203.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[204]</span>
<span class="ltx_bibblock"><span id="bib.bib204.1.1" class="ltx_text" style="font-size:90%;">
W. Zhang, Z. Li, and X. Chen, “Quality-aware user recruitment based on
federated learning in mobile crowd sensing,” </span><em id="bib.bib204.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Tsinghua Science and
Technology</em><span id="bib.bib204.3.3" class="ltx_text" style="font-size:90%;">, vol. 26, no. 6, pp. 869–877, 2021.
</span>
</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[205]</span>
<span class="ltx_bibblock"><span id="bib.bib205.1.1" class="ltx_text" style="font-size:90%;">
Z. Chen, M. Simsek, and B. Kantarci, “Federated learning-based risk-aware
decision to mitigate fake task impacts on crowdsensing platforms,”
</span><em id="bib.bib205.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2101.01266</em><span id="bib.bib205.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[206]</span>
<span class="ltx_bibblock"><span id="bib.bib206.1.1" class="ltx_text" style="font-size:90%;">
K. Bouraqia, E. Sabir, M. Sadik, and L. Ladid, “Quality of experience for
streaming services: measurements, challenges and insights,” </span><em id="bib.bib206.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Access</em><span id="bib.bib206.3.3" class="ltx_text" style="font-size:90%;">, vol. 8, pp. 13 341–13 361, 2020.
</span>
</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[207]</span>
<span class="ltx_bibblock"><span id="bib.bib207.1.1" class="ltx_text" style="font-size:90%;">
S. Aroussi and A. Mellouk, “Survey on machine learning-based qoe-qos
correlation models,” in </span><em id="bib.bib207.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2014 International Conference on Computing,
Management and Telecommunications (ComManTel)</em><span id="bib.bib207.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2014, pp. 200–204.
</span>
</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[208]</span>
<span class="ltx_bibblock"><span id="bib.bib208.1.1" class="ltx_text" style="font-size:90%;">
S. Ickin, K. Vandikas, and M. Fiedler, “Privacy preserving qoe modeling using
collaborative learning,” in </span><em id="bib.bib208.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 4th Internet-QoE
Workshop on QoE-Based Analysis and Management of Data Communication
Networks</em><span id="bib.bib208.3.3" class="ltx_text" style="font-size:90%;">, 2019, pp. 13–18.
</span>
</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[209]</span>
<span class="ltx_bibblock"><span id="bib.bib209.1.1" class="ltx_text" style="font-size:90%;">
S. Ickin, K. Vandikas, F. Moradi, J. Taghia, and W. Hu, “Ensemble-based
synthetic data synthesis for federated qoe modeling,” in </span><em id="bib.bib209.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 6th IEEE
Conference on Network Softwarization (NetSoft)</em><span id="bib.bib209.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 72–76.
</span>
</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[210]</span>
<span class="ltx_bibblock"><span id="bib.bib210.1.1" class="ltx_text" style="font-size:90%;">
N. Wirkuttis and H. Klein, “Artificial intelligence in cybersecurity,”
</span><em id="bib.bib210.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Cyber, Intelligence, and Security</em><span id="bib.bib210.3.3" class="ltx_text" style="font-size:90%;">, vol. 1, no. 1, pp. 103–119, 2017.
</span>
</span>
</li>
<li id="bib.bib211" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[211]</span>
<span class="ltx_bibblock"><span id="bib.bib211.1.1" class="ltx_text" style="font-size:90%;">
V. Rey, P. M. S. Sánchez, A. H. Celdrán, and G. Bovet, “Federated
learning for malware detection in iot devices,” </span><em id="bib.bib211.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Networks</em><span id="bib.bib211.3.3" class="ltx_text" style="font-size:90%;">,
vol. 204, p. 108693, 2022.
</span>
</span>
</li>
<li id="bib.bib212" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[212]</span>
<span class="ltx_bibblock"><span id="bib.bib212.1.1" class="ltx_text" style="font-size:90%;">
G. Xu, H. Li, S. Liu, K. Yang, and X. Lin, “Verifynet: Secure and verifiable
federated learning,” </span><em id="bib.bib212.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Information Forensics and
Security</em><span id="bib.bib212.3.3" class="ltx_text" style="font-size:90%;">, vol. 15, pp. 911–926, 2019.
</span>
</span>
</li>
<li id="bib.bib213" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[213]</span>
<span class="ltx_bibblock"><span id="bib.bib213.1.1" class="ltx_text" style="font-size:90%;">
E. Khramtsova, C. Hammerschmidt, S. Lagraa, and R. State, “Federated learning
for cyber security: Soc collaboration for malicious url detection,” in
</span><em id="bib.bib213.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE 40th International Conference on Distributed Computing
Systems (ICDCS)</em><span id="bib.bib213.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp.
1316–1321.
</span>
</span>
</li>
<li id="bib.bib214" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[214]</span>
<span class="ltx_bibblock"><span id="bib.bib214.1.1" class="ltx_text" style="font-size:90%;">
C. Thapa, K. K. Karmakar, A. H. Celdran, S. Camtepe, V. Varadharajan, and
S. Nepal, “Feddice: A ransomware spread detection in a distributed
integrated clinical environment using federated learning and sdn based
mitigation,” </span><em id="bib.bib214.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2106.05434</em><span id="bib.bib214.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib215" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[215]</span>
<span class="ltx_bibblock"><span id="bib.bib215.1.1" class="ltx_text" style="font-size:90%;">
K. Demertzis, “Blockchained federated learning for threat defense,”
</span><em id="bib.bib215.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2102.12746</em><span id="bib.bib215.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib216" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[216]</span>
<span class="ltx_bibblock"><span id="bib.bib216.1.1" class="ltx_text" style="font-size:90%;">
M. Hengstler, E. Enkel, and S. Duelli, “Applied artificial intelligence and
trust—the case of autonomous vehicles and medical assistance devices,”
</span><em id="bib.bib216.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Technological Forecasting and Social Change</em><span id="bib.bib216.3.3" class="ltx_text" style="font-size:90%;">, vol. 105, pp. 105–120,
2016.
</span>
</span>
</li>
<li id="bib.bib217" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[217]</span>
<span class="ltx_bibblock"><span id="bib.bib217.1.1" class="ltx_text" style="font-size:90%;">
A. E. Sallab, M. Abdou, E. Perot, and S. Yogamani, “Deep reinforcement
learning framework for autonomous driving,” </span><em id="bib.bib217.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Electronic Imaging</em><span id="bib.bib217.3.3" class="ltx_text" style="font-size:90%;">, vol.
2017, no. 19, pp. 70–76, 2017.
</span>
</span>
</li>
<li id="bib.bib218" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[218]</span>
<span class="ltx_bibblock"><span id="bib.bib218.1.1" class="ltx_text" style="font-size:90%;">
A. M. Elbir, B. Soner, and S. Coleri, “Federated learning in vehicular
networks,” </span><em id="bib.bib218.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2006.01412</em><span id="bib.bib218.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib219" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[219]</span>
<span class="ltx_bibblock"><span id="bib.bib219.1.1" class="ltx_text" style="font-size:90%;">
T. Zeng, O. Semiari, M. Chen, W. Saad, and M. Bennis, “Federated learning on
the road: Autonomous controller design for connected and autonomous
vehicles,” </span><em id="bib.bib219.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2102.03401</em><span id="bib.bib219.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib220" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[220]</span>
<span class="ltx_bibblock"><span id="bib.bib220.1.1" class="ltx_text" style="font-size:90%;">
Y. Li, X. Tao, X. Zhang, J. Liu, and J. Xu, “Privacy-preserved federated
learning for autonomous driving,” </span><em id="bib.bib220.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Intelligent
Transportation Systems</em><span id="bib.bib220.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib221" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[221]</span>
<span class="ltx_bibblock"><span id="bib.bib221.1.1" class="ltx_text" style="font-size:90%;">
S. R. Pokhrel and J. Choi, “Federated learning with blockchain for autonomous
vehicles: Analysis and design challenges,” </span><em id="bib.bib221.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on
Communications</em><span id="bib.bib221.3.3" class="ltx_text" style="font-size:90%;">, vol. 68, no. 8, pp. 4734–4746, 2020.
</span>
</span>
</li>
<li id="bib.bib222" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[222]</span>
<span class="ltx_bibblock"><span id="bib.bib222.1.1" class="ltx_text" style="font-size:90%;">
X. Liang, Y. Liu, T. Chen, M. Liu, and Q. Yang, “Federated transfer
reinforcement learning for autonomous driving,” </span><em id="bib.bib222.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:1910.06001</em><span id="bib.bib222.3.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib223" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[223]</span>
<span class="ltx_bibblock"><span id="bib.bib223.1.1" class="ltx_text" style="font-size:90%;">
S. Samarakoon, M. Bennis, W. Saad, and M. Debbah, “Federated learning for
ultra-reliable low-latency v2v communications,” in </span><em id="bib.bib223.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2018 IEEE Global
Communications Conference (GLOBECOM)</em><span id="bib.bib223.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2018, pp. 1–7.
</span>
</span>
</li>
<li id="bib.bib224" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[224]</span>
<span class="ltx_bibblock"><span id="bib.bib224.1.1" class="ltx_text" style="font-size:90%;">
J. Posner, L. Tseng, M. Aloqaily, and Y. Jararweh, “Federated learning in
vehicular networks: opportunities and solutions,” </span><em id="bib.bib224.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Network</em><span id="bib.bib224.3.3" class="ltx_text" style="font-size:90%;">,
vol. 35, no. 2, pp. 152–159, 2021.
</span>
</span>
</li>
<li id="bib.bib225" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[225]</span>
<span class="ltx_bibblock"><span id="bib.bib225.1.1" class="ltx_text" style="font-size:90%;">
T. D. Nguyen, S. Marchal, M. Miettinen, H. Fereidooni, N. Asokan, and A.-R.
Sadeghi, “Dïot: A federated self-learning anomaly detection system for
iot,” in </span><em id="bib.bib225.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2019 IEEE 39th International Conference on Distributed
Computing Systems (ICDCS)</em><span id="bib.bib225.3.3" class="ltx_text" style="font-size:90%;">.   IEEE,
2019, pp. 756–767.
</span>
</span>
</li>
<li id="bib.bib226" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[226]</span>
<span class="ltx_bibblock"><span id="bib.bib226.1.1" class="ltx_text" style="font-size:90%;">
Y. Zhao, J. Chen, D. Wu, J. Teng, and S. Yu, “Multi-task network anomaly
detection using federated learning,” in </span><em id="bib.bib226.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the tenth
international symposium on information and communication technology</em><span id="bib.bib226.3.3" class="ltx_text" style="font-size:90%;">, 2019,
pp. 273–279.
</span>
</span>
</li>
<li id="bib.bib227" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[227]</span>
<span class="ltx_bibblock"><span id="bib.bib227.1.1" class="ltx_text" style="font-size:90%;">
T. T. Huong, T. P. Bac, D. M. Long, T. D. Luong, N. M. Dan, B. D. Thang, K. P.
Tran </span><em id="bib.bib227.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib227.3.3" class="ltx_text" style="font-size:90%;">, “Detecting cyberattacks using anomaly detection in
industrial control systems: A federated learning approach,” </span><em id="bib.bib227.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computers
in Industry</em><span id="bib.bib227.5.5" class="ltx_text" style="font-size:90%;">, vol. 132, p. 103509, 2021.
</span>
</span>
</li>
<li id="bib.bib228" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[228]</span>
<span class="ltx_bibblock"><span id="bib.bib228.1.1" class="ltx_text" style="font-size:90%;">
R. Zhao, Y. Yin, Y. Shi, and Z. Xue, “Intelligent intrusion detection based on
federated learning aided long short-term memory,” </span><em id="bib.bib228.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Physical
Communication</em><span id="bib.bib228.3.3" class="ltx_text" style="font-size:90%;">, vol. 42, p. 101157, 2020.
</span>
</span>
</li>
<li id="bib.bib229" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[229]</span>
<span class="ltx_bibblock"><span id="bib.bib229.1.1" class="ltx_text" style="font-size:90%;">
W. Zellinger, V. Wieser, M. Kumar, D. Brunner, N. Shepeleva, R. Gálvez,
J. Langer, L. Fischer, and B. Moser, “Beyond federated learning: On
confidentiality-critical machine learning applications in industry,”
</span><em id="bib.bib229.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Procedia Computer Science</em><span id="bib.bib229.3.3" class="ltx_text" style="font-size:90%;">, vol. 180, pp. 734–743, 2021.
</span>
</span>
</li>
<li id="bib.bib230" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[230]</span>
<span class="ltx_bibblock"><span id="bib.bib230.1.1" class="ltx_text" style="font-size:90%;">
S. Savazzi, M. Nicoli, M. Bennis, S. Kianoush, and L. Barbieri, “Opportunities
of federated learning in connected, cooperative, and automated industrial
systems,” </span><em id="bib.bib230.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Magazine</em><span id="bib.bib230.3.3" class="ltx_text" style="font-size:90%;">, vol. 59, no. 2, pp. 16–21,
2021.
</span>
</span>
</li>
<li id="bib.bib231" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[231]</span>
<span class="ltx_bibblock"><span id="bib.bib231.1.1" class="ltx_text" style="font-size:90%;">
M. Hao, H. Li, X. Luo, G. Xu, H. Yang, and S. Liu, “Efficient and
privacy-enhanced federated learning for industrial artificial intelligence,”
</span><em id="bib.bib231.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Industrial Informatics</em><span id="bib.bib231.3.3" class="ltx_text" style="font-size:90%;">, vol. 16, no. 10, pp.
6532–6542, 2019.
</span>
</span>
</li>
<li id="bib.bib232" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[232]</span>
<span class="ltx_bibblock"><span id="bib.bib232.1.1" class="ltx_text" style="font-size:90%;">
A. Fu, X. Zhang, N. Xiong, Y. Gao, H. Wang, and J. Zhang, “Vfl: A verifiable
federated learning with privacy-preserving for big data in industrial iot,”
</span><em id="bib.bib232.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Industrial Informatics</em><span id="bib.bib232.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib233" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[233]</span>
<span class="ltx_bibblock"><span id="bib.bib233.1.1" class="ltx_text" style="font-size:90%;">
T. Hiessl, D. Schall, J. Kemnitz, and S. Schulte, “Industrial federated
learning–requirements and system design,” in </span><em id="bib.bib233.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference
on Practical Applications of Agents and Multi-Agent Systems</em><span id="bib.bib233.3.3" class="ltx_text" style="font-size:90%;">.   Springer, 2020, pp. 42–53.
</span>
</span>
</li>
<li id="bib.bib234" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[234]</span>
<span class="ltx_bibblock"><span id="bib.bib234.1.1" class="ltx_text" style="font-size:90%;">
W. Sun, S. Lei, L. Wang, Z. Liu, and Y. Zhang, “Adaptive federated learning
and digital twin for industrial internet of things,” </span><em id="bib.bib234.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions
on Industrial Informatics</em><span id="bib.bib234.3.3" class="ltx_text" style="font-size:90%;">, vol. 17, no. 8, pp. 5605–5614, 2020.
</span>
</span>
</li>
<li id="bib.bib235" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[235]</span>
<span class="ltx_bibblock"><span id="bib.bib235.1.1" class="ltx_text" style="font-size:90%;">
Y. Xianjia, J. P. Queralta, J. Heikkonen, and T. Westerlund, “Federated
learning in robotic and autonomous systems,” </span><em id="bib.bib235.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2104.10141</em><span id="bib.bib235.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib236" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[236]</span>
<span class="ltx_bibblock"><span id="bib.bib236.1.1" class="ltx_text" style="font-size:90%;">
W. Zhou, Y. Li, S. Chen, and B. Ding, “Real-time data processing architecture
for multi-robots based on differential federated learning,” in </span><em id="bib.bib236.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2018
IEEE SmartWorld, Ubiquitous Intelligence &amp; Computing, Advanced &amp; Trusted
Computing, Scalable Computing &amp; Communications, Cloud &amp; Big Data Computing,
Internet of People and Smart City Innovation
(SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)</em><span id="bib.bib236.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2018, pp. 462–471.
</span>
</span>
</li>
<li id="bib.bib237" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[237]</span>
<span class="ltx_bibblock"><span id="bib.bib237.1.1" class="ltx_text" style="font-size:90%;">
J. Park, S. Samarakoon, H. Shiri, M. K. Abdel-Aziz, T. Nishio, A. Elgabli, and
M. Bennis, “Extreme urllc: Vision, challenges, and key enablers,”
</span><em id="bib.bib237.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2001.09683</em><span id="bib.bib237.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib238" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[238]</span>
<span class="ltx_bibblock"><span id="bib.bib238.1.1" class="ltx_text" style="font-size:90%;">
C. She, R. Dong, Z. Gu, Z. Hou, Y. Li, W. Hardjawana, C. Yang, L. Song, and
B. Vucetic, “Deep learning for ultra-reliable and low-latency communications
in 6g networks,” </span><em id="bib.bib238.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Network</em><span id="bib.bib238.3.3" class="ltx_text" style="font-size:90%;">, vol. 34, no. 5, pp. 219–225, 2020.
</span>
</span>
</li>
<li id="bib.bib239" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[239]</span>
<span class="ltx_bibblock"><span id="bib.bib239.1.1" class="ltx_text" style="font-size:90%;">
S. Samarakoon, M. Bennis, W. Saad, and M. Debbah, “Distributed federated
learning for ultra-reliable low-latency vehicular communications,”
</span><em id="bib.bib239.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Communications</em><span id="bib.bib239.3.3" class="ltx_text" style="font-size:90%;">, vol. 68, no. 2, pp. 1146–1159,
2019.
</span>
</span>
</li>
<li id="bib.bib240" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[240]</span>
<span class="ltx_bibblock"><span id="bib.bib240.1.1" class="ltx_text" style="font-size:90%;">
A. Azari, M. Ozger, and C. Cavdar, “Risk-aware resource allocation for urllc:
Challenges and strategies with machine learning,” </span><em id="bib.bib240.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications
Magazine</em><span id="bib.bib240.3.3" class="ltx_text" style="font-size:90%;">, vol. 57, no. 3, pp. 42–48, 2019.
</span>
</span>
</li>
<li id="bib.bib241" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[241]</span>
<span class="ltx_bibblock"><span id="bib.bib241.1.1" class="ltx_text" style="font-size:90%;">
M. Simsek, A. Aijaz, M. Dohler, J. Sachs, and G. Fettweis, “5g-enabled tactile
internet,” </span><em id="bib.bib241.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Journal on Selected Areas in Communications</em><span id="bib.bib241.3.3" class="ltx_text" style="font-size:90%;">, vol. 34,
no. 3, pp. 460–473, 2016.
</span>
</span>
</li>
<li id="bib.bib242" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[242]</span>
<span class="ltx_bibblock"><span id="bib.bib242.1.1" class="ltx_text" style="font-size:90%;">
N. Promwongsa, A. Ebrahimzadeh, D. Naboulsi, S. Kianpisheh, F. Belqasmi,
R. Glitho, N. Crespi, and O. Alfandi, “A comprehensive survey of the tactile
internet: State-of-the-art and research directions,” </span><em id="bib.bib242.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Communications Surveys &amp; Tutorials</em><span id="bib.bib242.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib243" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[243]</span>
<span class="ltx_bibblock"><span id="bib.bib243.1.1" class="ltx_text" style="font-size:90%;">
M. Mukherjee, M. Guo, J. Lloret, and Q. Zhang, “Leveraging intelligent
computation offloading with fog/edge computing for tactile internet:
Advantages and limitations,” </span><em id="bib.bib243.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Network</em><span id="bib.bib243.3.3" class="ltx_text" style="font-size:90%;">, vol. 34, no. 5, pp.
322–329, 2020.
</span>
</span>
</li>
<li id="bib.bib244" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[244]</span>
<span class="ltx_bibblock"><span id="bib.bib244.1.1" class="ltx_text" style="font-size:90%;">
R. Ali, Y. B. Zikria, A. K. Bashir, S. Garg, and H. S. Kim, “Urllc for 5g and
beyond: Requirements, enabling incumbent technologies and network
intelligence,” </span><em id="bib.bib244.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Access</em><span id="bib.bib244.3.3" class="ltx_text" style="font-size:90%;">, vol. 9, pp. 67 064–67 095, 2021.
</span>
</span>
</li>
<li id="bib.bib245" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[245]</span>
<span class="ltx_bibblock"><span id="bib.bib245.1.1" class="ltx_text" style="font-size:90%;">
E. Bastug, M. Bennis, M. Médard, and M. Debbah, “Toward interconnected
virtual reality: Opportunities, challenges, and enablers,” </span><em id="bib.bib245.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Communications Magazine</em><span id="bib.bib245.3.3" class="ltx_text" style="font-size:90%;">, vol. 55, no. 6, pp. 110–117, 2017.
</span>
</span>
</li>
<li id="bib.bib246" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[246]</span>
<span class="ltx_bibblock"><span id="bib.bib246.1.1" class="ltx_text" style="font-size:90%;">
M. Chen, O. Semiari, W. Saad, X. Liu, and C. Yin, “Federated echo state
learning for minimizing breaks in presence in wireless virtual reality
networks,” </span><em id="bib.bib246.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Wireless Communications</em><span id="bib.bib246.3.3" class="ltx_text" style="font-size:90%;">, vol. 19,
no. 1, pp. 177–191, 2019.
</span>
</span>
</li>
<li id="bib.bib247" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[247]</span>
<span class="ltx_bibblock"><span id="bib.bib247.1.1" class="ltx_text" style="font-size:90%;">
Y. Chen, Q. Wang, H. Chen, X. Song, H. Tang, and M. Tian, “An overview of
augmented reality technology,” in </span><em id="bib.bib247.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of Physics: Conference
Series</em><span id="bib.bib247.3.3" class="ltx_text" style="font-size:90%;">, vol. 1237, no. 2.   IOP
Publishing, 2019, p. 022082.
</span>
</span>
</li>
<li id="bib.bib248" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[248]</span>
<span class="ltx_bibblock"><span id="bib.bib248.1.1" class="ltx_text" style="font-size:90%;">
D. Chen, L. J. Xie, B. Kim, L. Wang, C. S. Hong, L.-C. Wang, and Z. Han,
“Federated learning based mobile edge computing for augmented reality
applications,” in </span><em id="bib.bib248.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 international conference on computing,
networking and communications (ICNC)</em><span id="bib.bib248.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2020, pp. 767–773.
</span>
</span>
</li>
<li id="bib.bib249" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[249]</span>
<span class="ltx_bibblock"><span id="bib.bib249.1.1" class="ltx_text" style="font-size:90%;">
F. Wang, Y. Liu, J. Liu, A. Argyriou, L. Wang, and Z. Xu, “Output security for
multi-user augmented reality using federated reinforcement learning,”
</span><em id="bib.bib249.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">.</em><span id="bib.bib249.3.3" class="ltx_text" style="font-size:90%;">, .
</span>
</span>
</li>
<li id="bib.bib250" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[250]</span>
<span class="ltx_bibblock"><span id="bib.bib250.1.1" class="ltx_text" style="font-size:90%;">
J. Ratcliffe, F. Soave, N. Bryan-Kinns, L. Tokarchuk, and I. Farkhatdinov,
“Extended reality (xr) remote research: a survey of drawbacks and
opportunities,” in </span><em id="bib.bib250.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 2021 CHI Conference on Human
Factors in Computing Systems</em><span id="bib.bib250.3.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 1–13.
</span>
</span>
</li>
<li id="bib.bib251" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[251]</span>
<span class="ltx_bibblock"><span id="bib.bib251.1.1" class="ltx_text" style="font-size:90%;">
L. Barbieri, S. Savazzi, M. Brambilla, and M. Nicoli, “Decentralized federated
learning for extended sensing in 6g connected vehicles,” </span><em id="bib.bib251.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Vehicular
Communications</em><span id="bib.bib251.3.3" class="ltx_text" style="font-size:90%;">, p. 100396, 2021.
</span>
</span>
</li>
<li id="bib.bib252" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[252]</span>
<span class="ltx_bibblock"><span id="bib.bib252.1.1" class="ltx_text" style="font-size:90%;">
M. Chehimi, O. Hashash, and W. Saad, “The roadmap to a quantum-enabled
wireless metaverse: Beyond the classical limits,” in </span><em id="bib.bib252.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2023 Fifth
International Conference on Advances in Computational Tools for Engineering
Applications (ACTEA)</em><span id="bib.bib252.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2023, pp.
7–12.
</span>
</span>
</li>
<li id="bib.bib253" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[253]</span>
<span class="ltx_bibblock"><span id="bib.bib253.1.1" class="ltx_text" style="font-size:90%;">
Y. Chen, S. Huang, W. Gan, G. Huang, and Y. Wu, “Federated learning for
metaverse: A survey,” </span><em id="bib.bib253.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2303.17987</em><span id="bib.bib253.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib254" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[254]</span>
<span class="ltx_bibblock"><span id="bib.bib254.1.1" class="ltx_text" style="font-size:90%;">
D. C. Nguyen, Q.-V. Pham, P. N. Pathirana, M. Ding, A. Seneviratne, Z. Lin,
O. Dobre, and W.-J. Hwang, “Federated learning for smart healthcare: A
survey,” </span><em id="bib.bib254.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Computing Surveys (CSUR)</em><span id="bib.bib254.3.3" class="ltx_text" style="font-size:90%;">, vol. 55, no. 3, pp. 1–37,
2022.
</span>
</span>
</li>
<li id="bib.bib255" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[255]</span>
<span class="ltx_bibblock"><span id="bib.bib255.1.1" class="ltx_text" style="font-size:90%;">
J. Xu, B. S. Glicksberg, C. Su, P. Walker, J. Bian, and F. Wang, “Federated
learning for healthcare informatics,” </span><em id="bib.bib255.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of Healthcare
Informatics Research</em><span id="bib.bib255.3.3" class="ltx_text" style="font-size:90%;">, vol. 5, no. 1, pp. 1–19, 2021.
</span>
</span>
</li>
<li id="bib.bib256" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[256]</span>
<span class="ltx_bibblock"><span id="bib.bib256.1.1" class="ltx_text" style="font-size:90%;">
Y. Chen, X. Qin, J. Wang, C. Yu, and W. Gao, “Fedhealth: A federated transfer
learning framework for wearable healthcare,” </span><em id="bib.bib256.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Intelligent
Systems</em><span id="bib.bib256.3.3" class="ltx_text" style="font-size:90%;">, vol. 35, no. 4, pp. 83–93, 2020.
</span>
</span>
</li>
<li id="bib.bib257" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[257]</span>
<span class="ltx_bibblock"><span id="bib.bib257.1.1" class="ltx_text" style="font-size:90%;">
W. Y. B. Lim, S. Garg, Z. Xiong, D. Niyato, C. Leung, C. Miao, and M. Guizani,
“Dynamic contract design for federated learning in smart healthcare
applications,” </span><em id="bib.bib257.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</em><span id="bib.bib257.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib258" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[258]</span>
<span class="ltx_bibblock"><span id="bib.bib258.1.1" class="ltx_text" style="font-size:90%;">
A. Qayyum, K. Ahmad, M. A. Ahsan, A. Al-Fuqaha, and J. Qadir, “Collaborative
federated learning for healthcare: Multi-modal covid-19 diagnosis at the
edge,” </span><em id="bib.bib258.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2101.07511</em><span id="bib.bib258.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib259" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[259]</span>
<span class="ltx_bibblock"><span id="bib.bib259.1.1" class="ltx_text" style="font-size:90%;">
Y. Fu, Y. Zhang, Q. Zhu, H.-n. Dai, M. Li, and T. Q. Quek, “A new vision of
wireless edge caching networks (wecns): Issues, technologies, and open
research trends,” </span><em id="bib.bib259.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Network</em><span id="bib.bib259.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib260" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[260]</span>
<span class="ltx_bibblock"><span id="bib.bib260.1.1" class="ltx_text" style="font-size:90%;">
L. Gashi, A. Luma, H. Snopçe, and Y. Januzaj, “A secure recommender
system model for service placement in wireless networks.”
</span><em id="bib.bib260.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Journal of Interactive Mobile Technologies</em><span id="bib.bib260.3.3" class="ltx_text" style="font-size:90%;">, vol. 17,
no. 11, 2023.
</span>
</span>
</li>
<li id="bib.bib261" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[261]</span>
<span class="ltx_bibblock"><span id="bib.bib261.1.1" class="ltx_text" style="font-size:90%;">
M. Vaishnavi and S. Vemuru, “The three-tier architecture of federated learning
for recommendation systems,” in </span><em id="bib.bib261.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2023 7th International Conference on
Computing Methodologies and Communication (ICCMC)</em><span id="bib.bib261.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2023, pp. 1529–1533.
</span>
</span>
</li>
<li id="bib.bib262" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[262]</span>
<span class="ltx_bibblock"><span id="bib.bib262.1.1" class="ltx_text" style="font-size:90%;">
L. Yang, B. Tan, V. W. Zheng, K. Chen, and Q. Yang, “Federated recommendation
systems,” </span><em id="bib.bib262.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Federated Learning: Privacy and Incentive</em><span id="bib.bib262.3.3" class="ltx_text" style="font-size:90%;">, pp. 225–239,
2020.
</span>
</span>
</li>
<li id="bib.bib263" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[263]</span>
<span class="ltx_bibblock"><span id="bib.bib263.1.1" class="ltx_text" style="font-size:90%;">
J. Qin, B. Liu, and J. Qian, “A novel privacy-preserved recommender system
framework based on federated learning,” in </span><em id="bib.bib263.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 The 4th International
Conference on Software Engineering and Information Management</em><span id="bib.bib263.3.3" class="ltx_text" style="font-size:90%;">, 2021, pp.
82–88.
</span>
</span>
</li>
<li id="bib.bib264" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[264]</span>
<span class="ltx_bibblock"><span id="bib.bib264.1.1" class="ltx_text" style="font-size:90%;">
W. Huang, M. Ye, and B. Du, “Learn from others and be yourself in
heterogeneous federated learning,” in </span><em id="bib.bib264.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib264.3.3" class="ltx_text" style="font-size:90%;">, 2022, pp.
10 143–10 153.
</span>
</span>
</li>
<li id="bib.bib265" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[265]</span>
<span class="ltx_bibblock"><span id="bib.bib265.1.1" class="ltx_text" style="font-size:90%;">
L. Lyu, H. Yu, and Q. Yang, “Threats to federated learning: A survey,”
</span><em id="bib.bib265.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2003.02133</em><span id="bib.bib265.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib266" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[266]</span>
<span class="ltx_bibblock"><span id="bib.bib266.1.1" class="ltx_text" style="font-size:90%;">
H. Fereidooni, S. Marchal, M. Miettinen, A. Mirhoseini, H. Möllering, T. D.
Nguyen, P. Rieger, A.-R. Sadeghi, T. Schneider, H. Yalame </span><em id="bib.bib266.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">et al.</em><span id="bib.bib266.3.3" class="ltx_text" style="font-size:90%;">,
“Safelearn: secure aggregation for private federated learning,” in
</span><em id="bib.bib266.4.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 IEEE Security and Privacy Workshops (SPW)</em><span id="bib.bib266.5.5" class="ltx_text" style="font-size:90%;">.   IEEE, 2021, pp. 56–62.
</span>
</span>
</li>
<li id="bib.bib267" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[267]</span>
<span class="ltx_bibblock"><span id="bib.bib267.1.1" class="ltx_text" style="font-size:90%;">
Q. Zhang, B. Gu, C. Deng, and H. Huang, “Secure bilevel asynchronous vertical
federated learning with backward updating,” </span><em id="bib.bib267.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2103.00958</em><span id="bib.bib267.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib268" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[268]</span>
<span class="ltx_bibblock"><span id="bib.bib268.1.1" class="ltx_text" style="font-size:90%;">
J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh,
and D. Bacon, “Federated learning: Strategies for improving communication
efficiency,” </span><em id="bib.bib268.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1610.05492</em><span id="bib.bib268.3.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib269" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[269]</span>
<span class="ltx_bibblock"><span id="bib.bib269.1.1" class="ltx_text" style="font-size:90%;">
S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and K. Chan,
“Adaptive federated learning in resource constrained edge computing
systems,” </span><em id="bib.bib269.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Journal on Selected Areas in Communications</em><span id="bib.bib269.3.3" class="ltx_text" style="font-size:90%;">, vol. 37,
no. 6, pp. 1205–1221, 2019.
</span>
</span>
</li>
<li id="bib.bib270" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[270]</span>
<span class="ltx_bibblock"><span id="bib.bib270.1.1" class="ltx_text" style="font-size:90%;">
F. Haddadpour and M. Mahdavi, “On the convergence of local descent methods in
federated learning,” </span><em id="bib.bib270.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1910.14425</em><span id="bib.bib270.3.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib271" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[271]</span>
<span class="ltx_bibblock"><span id="bib.bib271.1.1" class="ltx_text" style="font-size:90%;">
C. T. Dinh, N. H. Tran, M. N. Nguyen, C. S. Hong, W. Bao, A. Y. Zomaya, and
V. Gramoli, “Federated learning over wireless networks: Convergence analysis
and resource allocation,” </span><em id="bib.bib271.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE/ACM Transactions on Networking</em><span id="bib.bib271.3.3" class="ltx_text" style="font-size:90%;">,
vol. 29, no. 1, pp. 398–409, 2020.
</span>
</span>
</li>
<li id="bib.bib272" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[272]</span>
<span class="ltx_bibblock"><span id="bib.bib272.1.1" class="ltx_text" style="font-size:90%;">
X. Wei and C. Shen, “Federated learning over noisy channels: Convergence
analysis and design examples,” </span><em id="bib.bib272.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2101.02198</em><span id="bib.bib272.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib273" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[273]</span>
<span class="ltx_bibblock"><span id="bib.bib273.1.1" class="ltx_text" style="font-size:90%;">
M. Chen, N. Shlezinger, H. V. Poor, Y. C. Eldar, and S. Cui,
“Communication-efficient federated learning,” </span><em id="bib.bib273.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the
National Academy of Sciences</em><span id="bib.bib273.3.3" class="ltx_text" style="font-size:90%;">, vol. 118, no. 17, 2021.
</span>
</span>
</li>
<li id="bib.bib274" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[274]</span>
<span class="ltx_bibblock"><span id="bib.bib274.1.1" class="ltx_text" style="font-size:90%;">
M. Ahmadi, A. Taghavirashidizadeh, D. Javaheri, A. Masoumian, S. J. Ghoushchi,
and Y. Pourasad, “Dqre-scnet: a novel hybrid approach for selecting users in
federated learning with deep-q-reinforcement learning based on spectral
clustering,” </span><em id="bib.bib274.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of King Saud University-Computer and Information
Sciences</em><span id="bib.bib274.3.3" class="ltx_text" style="font-size:90%;">, vol. 34, no. 9, pp. 7445–7458, 2022.
</span>
</span>
</li>
<li id="bib.bib275" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[275]</span>
<span class="ltx_bibblock"><span id="bib.bib275.1.1" class="ltx_text" style="font-size:90%;">
Y. J. Cho, J. Wang, and G. Joshi, “Client selection in federated learning:
Convergence analysis and power-of-choice selection strategies,” </span><em id="bib.bib275.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv
preprint arXiv:2010.01243</em><span id="bib.bib275.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib276" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[276]</span>
<span class="ltx_bibblock"><span id="bib.bib276.1.1" class="ltx_text" style="font-size:90%;">
M. Tang, X. Ning, Y. Wang, Y. Wang, and Y. Chen, “Fedgp: Correlation-based
active client selection for heterogeneous federated learning,” </span><em id="bib.bib276.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv
preprint arXiv:2103.13822</em><span id="bib.bib276.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib277" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[277]</span>
<span class="ltx_bibblock"><span id="bib.bib277.1.1" class="ltx_text" style="font-size:90%;">
T. Nishio and R. Yonetani, “Client selection for federated learning with
heterogeneous resources in mobile edge,” in </span><em id="bib.bib277.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICC 2019-2019 IEEE
International Conference on Communications (ICC)</em><span id="bib.bib277.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2019, pp. 1–7.
</span>
</span>
</li>
<li id="bib.bib278" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[278]</span>
<span class="ltx_bibblock"><span id="bib.bib278.1.1" class="ltx_text" style="font-size:90%;">
W. Zhang, Y. Chen, Y. Jiang, and J. Liu, “Delay-constrained client selection
for heterogeneous federated learning in intelligent transportation systems,”
</span><em id="bib.bib278.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Network Science and Engineering</em><span id="bib.bib278.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib279" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[279]</span>
<span class="ltx_bibblock"><span id="bib.bib279.1.1" class="ltx_text" style="font-size:90%;">
Z. Cheng, X. Fan, N. Chen, M. Liwang, L. Huang, and X. Wang, “Learning-based
client selection for multiple federated learning services with constrained
monetary budgets,” </span><em id="bib.bib279.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICT Express</em><span id="bib.bib279.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib280" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[280]</span>
<span class="ltx_bibblock"><span id="bib.bib280.1.1" class="ltx_text" style="font-size:90%;">
F. Shi, W. Lin, L. Fan, X. Lai, and X. Wang, “Efficient client selection based
on contextual combinatorial multi-arm bandits,” </span><em id="bib.bib280.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on
Wireless Communications</em><span id="bib.bib280.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib281" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[281]</span>
<span class="ltx_bibblock"><span id="bib.bib281.1.1" class="ltx_text" style="font-size:90%;">
D. Kang and C. W. Ahn, “Ga approach to optimize training client set in
federated learning,” </span><em id="bib.bib281.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Access</em><span id="bib.bib281.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib282" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[282]</span>
<span class="ltx_bibblock"><span id="bib.bib282.1.1" class="ltx_text" style="font-size:90%;">
M. Chahoud, H. Sami, A. Mourad, S. Otoum, H. Otrok, J. Bentahar, and
M. Guizani, “On-demand-fl: A dynamic and efficient multi-criteria federated
learning client deployment scheme,” </span><em id="bib.bib282.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</em><span id="bib.bib282.3.3" class="ltx_text" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li id="bib.bib283" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[283]</span>
<span class="ltx_bibblock"><span id="bib.bib283.1.1" class="ltx_text" style="font-size:90%;">
X. Tang, Y. Wang, R. Huang, G. Chen, and L. Wang, “Stackelberg game based
resource allocation algorithm for federated learning in mec systems,” in
</span><em id="bib.bib283.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2023 6th World Conference on Computing and Communication Technologies
(WCCCT)</em><span id="bib.bib283.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2023, pp. 7–12.
</span>
</span>
</li>
<li id="bib.bib284" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[284]</span>
<span class="ltx_bibblock"><span id="bib.bib284.1.1" class="ltx_text" style="font-size:90%;">
U. Michieli and M. Ozay, “Are all users treated fairly in federated learning
systems?” in </span><em id="bib.bib284.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em><span id="bib.bib284.3.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 2318–2322.
</span>
</span>
</li>
<li id="bib.bib285" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[285]</span>
<span class="ltx_bibblock"><span id="bib.bib285.1.1" class="ltx_text" style="font-size:90%;">
W. Hao, M. El-Khamy, J. Lee, J. Zhang, K. J. Liang, C. Chen, and L. C. Duke,
“Towards fair federated learning with zero-shot data augmentation,” in
</span><em id="bib.bib285.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition</em><span id="bib.bib285.3.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 3310–3319.
</span>
</span>
</li>
<li id="bib.bib286" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[286]</span>
<span class="ltx_bibblock"><span id="bib.bib286.1.1" class="ltx_text" style="font-size:90%;">
T. Huang, W. Lin, W. Wu, L. He, K. Li, and A. Y. Zomaya, “An
efficiency-boosting client selection scheme for federated learning with
fairness guarantee,” </span><em id="bib.bib286.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Parallel and Distributed
Systems</em><span id="bib.bib286.3.3" class="ltx_text" style="font-size:90%;">, vol. 32, no. 7, pp. 1552–1564, 2020.
</span>
</span>
</li>
<li id="bib.bib287" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[287]</span>
<span class="ltx_bibblock"><span id="bib.bib287.1.1" class="ltx_text" style="font-size:90%;">
L. Lyu, X. Xu, Q. Wang, and H. Yu, “Collaborative fairness in federated
learning,” in </span><em id="bib.bib287.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Federated Learning</em><span id="bib.bib287.3.3" class="ltx_text" style="font-size:90%;">.   Springer, 2020, pp. 189–204.
</span>
</span>
</li>
<li id="bib.bib288" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[288]</span>
<span class="ltx_bibblock"><span id="bib.bib288.1.1" class="ltx_text" style="font-size:90%;">
Z. Wang, X. Fan, J. Qi, C. Wen, C. Wang, and R. Yu, “Federated learning with
fair averaging,” </span><em id="bib.bib288.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.14937</em><span id="bib.bib288.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib289" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[289]</span>
<span class="ltx_bibblock"><span id="bib.bib289.1.1" class="ltx_text" style="font-size:90%;">
W. He, H. Yao, T. Mai, F. Wang, and M. Guizani, “Three-stage stackelberg game
enabled clustered federated learning in heterogeneous uav swarms,”
</span><em id="bib.bib289.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Vehicular Technology</em><span id="bib.bib289.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib290" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[290]</span>
<span class="ltx_bibblock"><span id="bib.bib290.1.1" class="ltx_text" style="font-size:90%;">
A. Peyvandi, B. Majidi, S. Peyvandi, and J. C. Patra, “Privacy-preserving
federated learning for scalable and high data quality
computational-intelligence-as-a-service in society 5.0,” </span><em id="bib.bib290.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Multimedia
tools and applications</em><span id="bib.bib290.3.3" class="ltx_text" style="font-size:90%;">, vol. 81, no. 18, pp. 25 029–25 050, 2022.
</span>
</span>
</li>
<li id="bib.bib291" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[291]</span>
<span class="ltx_bibblock"><span id="bib.bib291.1.1" class="ltx_text" style="font-size:90%;">
P. Singh, M. K. Singh, R. Singh, and N. Singh, “Federated learning:
Challenges, methods, and future directions,” in </span><em id="bib.bib291.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Federated Learning for
IoT Applications</em><span id="bib.bib291.3.3" class="ltx_text" style="font-size:90%;">.   Springer, 2022, pp.
199–214.
</span>
</span>
</li>
<li id="bib.bib292" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[292]</span>
<span class="ltx_bibblock"><span id="bib.bib292.1.1" class="ltx_text" style="font-size:90%;">
J. Konečnỳ, B. McMahan, and D. Ramage, “Federated optimization:
Distributed optimization beyond the datacenter,” </span><em id="bib.bib292.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:1511.03575</em><span id="bib.bib292.3.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib293" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[293]</span>
<span class="ltx_bibblock"><span id="bib.bib293.1.1" class="ltx_text" style="font-size:90%;">
M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A joint learning
and communications framework for federated learning over wireless networks,”
</span><em id="bib.bib293.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Wireless Communications</em><span id="bib.bib293.3.3" class="ltx_text" style="font-size:90%;">, vol. 20, no. 1, pp.
269–283, 2020.
</span>
</span>
</li>
<li id="bib.bib294" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[294]</span>
<span class="ltx_bibblock"><span id="bib.bib294.1.1" class="ltx_text" style="font-size:90%;">
H. H. Yang, Z. Liu, T. Q. Quek, and H. V. Poor, “Scheduling policies for
federated learning in wireless networks,” </span><em id="bib.bib294.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE transactions on
communications</em><span id="bib.bib294.3.3" class="ltx_text" style="font-size:90%;">, vol. 68, no. 1, pp. 317–333, 2019.
</span>
</span>
</li>
<li id="bib.bib295" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[295]</span>
<span class="ltx_bibblock"><span id="bib.bib295.1.1" class="ltx_text" style="font-size:90%;">
M. Chen, H. V. Poor, W. Saad, and S. Cui, “Convergence time optimization for
federated learning over wireless networks,” </span><em id="bib.bib295.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on
Wireless Communications</em><span id="bib.bib295.3.3" class="ltx_text" style="font-size:90%;">, vol. 20, no. 4, pp. 2457–2471, 2020.
</span>
</span>
</li>
<li id="bib.bib296" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[296]</span>
<span class="ltx_bibblock"><span id="bib.bib296.1.1" class="ltx_text" style="font-size:90%;">
B. Xiao, X. Yu, W. Ni, X. Wang, and H. V. Poor, “Over-the-air federated
learning: Status quo, open challenges, and future directions,” </span><em id="bib.bib296.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv
preprint arXiv:2307.00974</em><span id="bib.bib296.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib297" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[297]</span>
<span class="ltx_bibblock"><span id="bib.bib297.1.1" class="ltx_text" style="font-size:90%;">
H. Y. Oksuz, F. Molinari, H. Sprekeler, and J. Raisch, “Federated learning in
wireless networks via over-the-air computations,” </span><em id="bib.bib297.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2305.04630</em><span id="bib.bib297.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib298" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[298]</span>
<span class="ltx_bibblock"><span id="bib.bib298.1.1" class="ltx_text" style="font-size:90%;">
B. Tegin and T. M. Duman, “Federated learning with over-the-air aggregation
over time-varying channels,” </span><em id="bib.bib298.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Wireless
Communications</em><span id="bib.bib298.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib299" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[299]</span>
<span class="ltx_bibblock"><span id="bib.bib299.1.1" class="ltx_text" style="font-size:90%;">
F. Malandrino and C. F. Chiasserini, “Federated learning at the network edge:
When not all nodes are created equal,” </span><em id="bib.bib299.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2101.01995</em><span id="bib.bib299.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib300" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[300]</span>
<span class="ltx_bibblock"><span id="bib.bib300.1.1" class="ltx_text" style="font-size:90%;">
A. Z. Tan, H. Yu, L. Cui, and Q. Yang, “Towards personalized federated
learning,” </span><em id="bib.bib300.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Neural Networks and Learning Systems</em><span id="bib.bib300.3.3" class="ltx_text" style="font-size:90%;">,
2022.
</span>
</span>
</li>
<li id="bib.bib301" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[301]</span>
<span class="ltx_bibblock"><span id="bib.bib301.1.1" class="ltx_text" style="font-size:90%;">
L. Barbieri, S. Savazzi, M. Brambilla, and M. Nicoli, “Decentralized federated
learning for extended sensing in 6g connected vehicles,” </span><em id="bib.bib301.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Vehicular
Communications</em><span id="bib.bib301.3.3" class="ltx_text" style="font-size:90%;">, vol. 33, p. 100396, 2022.
</span>
</span>
</li>
<li id="bib.bib302" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[302]</span>
<span class="ltx_bibblock"><span id="bib.bib302.1.1" class="ltx_text" style="font-size:90%;">
S. K. Singh, L. T. Yang, and J. H. Park, “Fusionfedblock: Fusion of blockchain
and federated learning to preserve privacy in industry 5.0,”
</span><em id="bib.bib302.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Information Fusion</em><span id="bib.bib302.3.3" class="ltx_text" style="font-size:90%;">, vol. 90, pp. 233–240, 2023.
</span>
</span>
</li>
<li id="bib.bib303" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[303]</span>
<span class="ltx_bibblock"><span id="bib.bib303.1.1" class="ltx_text" style="font-size:90%;">
Y. Qu, M. P. Uddin, C. Gan, Y. Xiang, L. Gao, and J. Yearwood,
“Blockchain-enabled federated learning: A survey,” </span><em id="bib.bib303.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Computing
Surveys</em><span id="bib.bib303.3.3" class="ltx_text" style="font-size:90%;">, vol. 55, no. 4, pp. 1–35, 2022.
</span>
</span>
</li>
<li id="bib.bib304" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[304]</span>
<span class="ltx_bibblock"><span id="bib.bib304.1.1" class="ltx_text" style="font-size:90%;">
H. Kim, J. Park, M. Bennis, and S.-L. Kim, “Blockchained on-device federated
learning,” </span><em id="bib.bib304.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Letters</em><span id="bib.bib304.3.3" class="ltx_text" style="font-size:90%;">, vol. 24, no. 6, pp.
1279–1283, 2019.
</span>
</span>
</li>
<li id="bib.bib305" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[305]</span>
<span class="ltx_bibblock"><span id="bib.bib305.1.1" class="ltx_text" style="font-size:90%;">
C. Ma, J. Li, M. Ding, L. Shi, T. Wang, Z. Han, and H. V. Poor, “When
federated learning meets blockchain: A new distributed learning paradigm,”
</span><em id="bib.bib305.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2009.09338</em><span id="bib.bib305.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib306" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[306]</span>
<span class="ltx_bibblock"><span id="bib.bib306.1.1" class="ltx_text" style="font-size:90%;">
A. Mehrjou, “Federated learning as a mean-field game,” </span><em id="bib.bib306.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2107.03770</em><span id="bib.bib306.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib307" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[307]</span>
<span class="ltx_bibblock"><span id="bib.bib307.1.1" class="ltx_text" style="font-size:90%;">
E. Jeong, S. Oh, H. Kim, J. Park, M. Bennis, and S.-L. Kim,
“Communication-efficient on-device machine learning: Federated distillation
and augmentation under non-iid private data,” </span><em id="bib.bib307.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:1811.11479</em><span id="bib.bib307.3.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib308" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[308]</span>
<span class="ltx_bibblock"><span id="bib.bib308.1.1" class="ltx_text" style="font-size:90%;">
A. Mora, I. Tenison, P. Bellavista, and I. Rish, “Knowledge distillation for
federated learning: a practical guide,” </span><em id="bib.bib308.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint
arXiv:2211.04742</em><span id="bib.bib308.3.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib309" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[309]</span>
<span class="ltx_bibblock"><span id="bib.bib309.1.1" class="ltx_text" style="font-size:90%;">
M. Chen, D. Gündüz, K. Huang, W. Saad, M. Bennis, A. V. Feljan, and
H. V. Poor, “Distributed learning in wireless networks: Recent progress and
future challenges,” </span><em id="bib.bib309.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Journal on Selected Areas in Communications</em><span id="bib.bib309.3.3" class="ltx_text" style="font-size:90%;">,
vol. 39, no. 12, pp. 3579–3605, 2021.
</span>
</span>
</li>
<li id="bib.bib310" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[310]</span>
<span class="ltx_bibblock"><span id="bib.bib310.1.1" class="ltx_text" style="font-size:90%;">
H. Q. Le, J. H. Shin, M. N. Nguyen, and C. S. Hong, “Distilling knowledge in
federated learning,” in </span><em id="bib.bib310.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 22nd Asia-Pacific Network Operations and
Management Symposium (APNOMS)</em><span id="bib.bib310.3.3" class="ltx_text" style="font-size:90%;">.   IEEE,
2021, pp. 196–201.
</span>
</span>
</li>
<li id="bib.bib311" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[311]</span>
<span class="ltx_bibblock"><span id="bib.bib311.1.1" class="ltx_text" style="font-size:90%;">
W. Yang, H. Du, Z. Q. Liew, W. Y. B. Lim, Z. Xiong, D. Niyato, X. Chi, X. S.
Shen, and C. Miao, “Semantic communications for future internet:
Fundamentals, applications, and challenges,” </span><em id="bib.bib311.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications
Surveys &amp; Tutorials</em><span id="bib.bib311.3.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib312" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[312]</span>
<span class="ltx_bibblock"><span id="bib.bib312.1.1" class="ltx_text" style="font-size:90%;">
G. Shi, Y. Xiao, Y. Li, and X. Xie, “From semantic communication to
semantic-aware networking: Model, architecture, and open problems,”
</span><em id="bib.bib312.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Communications Magazine</em><span id="bib.bib312.3.3" class="ltx_text" style="font-size:90%;">, vol. 59, no. 8, pp. 44–50, 2021.
</span>
</span>
</li>
<li id="bib.bib313" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[313]</span>
<span class="ltx_bibblock"><span id="bib.bib313.1.1" class="ltx_text" style="font-size:90%;">
D. Shi, L. Li, R. Chen, P. Prakash, M. Pan, and Y. Fang, “Toward
energy-efficient federated learning over 5g+ mobile devices,” </span><em id="bib.bib313.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Wireless Communications</em><span id="bib.bib313.3.3" class="ltx_text" style="font-size:90%;">, vol. 29, no. 5, pp. 44–51, 2022.
</span>
</span>
</li>
<li id="bib.bib314" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[314]</span>
<span class="ltx_bibblock"><span id="bib.bib314.1.1" class="ltx_text" style="font-size:90%;">
Z. Yang, M. Chen, W. Saad, C. S. Hong, and M. Shikh-Bahaei, “Energy efficient
federated learning over wireless communication networks,” </span><em id="bib.bib314.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Transactions on Wireless Communications</em><span id="bib.bib314.3.3" class="ltx_text" style="font-size:90%;">, vol. 20, no. 3, pp. 1935–1949,
2020.
</span>
</span>
</li>
<li id="bib.bib315" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[315]</span>
<span class="ltx_bibblock"><span id="bib.bib315.1.1" class="ltx_text" style="font-size:90%;">
S. A. Khowaja, K. Dev, P. Khowaja, and P. Bellavista, “Toward energy-efficient
distributed federated learning for 6g networks,” </span><em id="bib.bib315.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Wireless
Communications</em><span id="bib.bib315.3.3" class="ltx_text" style="font-size:90%;">, vol. 28, no. 6, pp. 34–40, 2022.
</span>
</span>
</li>
<li id="bib.bib316" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[316]</span>
<span class="ltx_bibblock"><span id="bib.bib316.1.1" class="ltx_text" style="font-size:90%;">
M. Kim, W. Saad, M. Mozaffari, and M. Debbah, “Green, quantized federated
learning over wireless networks: An energy-efficient design,” </span><em id="bib.bib316.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE
Transactions on Wireless Communications</em><span id="bib.bib316.3.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib317" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[317]</span>
<span class="ltx_bibblock"><span id="bib.bib317.1.1" class="ltx_text" style="font-size:90%;">
——, “On the tradeoff between energy, precision, and accuracy in federated
quantized neural networks,” in </span><em id="bib.bib317.2.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICC 2022-IEEE International Conference
on Communications</em><span id="bib.bib317.3.3" class="ltx_text" style="font-size:90%;">.   IEEE, 2022, pp.
2194–2199.
</span>
</span>
</li>
</ul>
</section>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Maryam Ben Driss<span id="p1.1.1.1" class="ltx_text ltx_font_medium"> (Student Member, IEEE) received the B.Sc. degree in Computer Science in 2018 and the M.Sc. degree in Big Data and Data Science in 2020 from the University of Hassan II, Faculty of Sciences Ben M’Sik, Casablanca, Morocco. She is currently pursuing her Ph.D. degree at the National Higher School of Electricity and Mechanics (ENSEM) in Casablanca. Her research interests include Artificial Intelligence, Federated Learning, Machine Learning, Deep Learning, Cellular Networks, 5G, 6G and beyond.
<br class="ltx_break"></span></span></p>
</div>
<div id="p2" class="ltx_para ltx_noindent">
<p id="p2.1" class="ltx_p"><span id="p2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Essaid Sabir</span><span id="p2.1.2" class="ltx_text" style="font-size:90%;"> (Senior Member, IEEE) received the Ph.D. degree (Hons.) in networking and computer engineering from Avignon University, France, in 2010. He has been a non-tenure-track Assistant Professor at Avignon University, from 2009 to 2012. He has been a Professor at Hassan II university of Casablanca until late 2022, where he was leading the NEST research Group. He is a professor with the department of computer science, Université du Québec à Montréal. His research interests include 5G/6G, wireless networks, IoT, AI/ML, and game theory. His work has been awarded in four international conferences. To bridge the gap between academia and industry, he founded the International Conference on Ubiquitous Networking (UNet) and co-founded the WINCOM conference series. He serves as a guest editor for many journals. He organized numerous events and played executive roles for other major events.</span>
<br class="ltx_break"></p>
</div>
<div id="p3" class="ltx_para ltx_noindent">
<p id="p3.1" class="ltx_p"><span id="p3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Halima Elbiaze</span><span id="p3.1.2" class="ltx_text" style="font-size:90%;"> (Senior Member, IEEE) received the B.S. degree in applied mathematics from the University of MV, Morocco, in 1996, the M.Sc. degree in telecommunication systems from the University of Versailles, in 1998, and the Ph.D. degree in computer science from Institut National des Télécommunications, Paris, France, in 2002. Since 2003, she has been with the Department of Computer Science, Université du Québec à Montréal, QC, Canada, where she is currently an Associate Professor. She has authored or co-authored many journal and conference papers. Her research interests include network performance evaluation, traffic engineering, and quality of service management in optical and wireless networks.</span>
<br class="ltx_break"></p>
</div>
<div id="p4" class="ltx_para ltx_noindent">
<p id="p4.1" class="ltx_p"><span id="p4.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Walid Saad</span><span id="p4.1.2" class="ltx_text" style="font-size:90%;"> (Fellow Member, IEEE) received his Ph.D. degree from the University of Oslo in 2010. He is a Professor at the Department of Electrical and Computer Engineering at Virginia Tech where he leads the Network Science, Wireless, and Security (NEWS) laboratory. His research interests include wireless networks, machine learning, game theory, cybersecurity, unmanned aerial vehicles, semantic communications, and cyber-physical systems. He was the author/co-author of eleven conferences’ best paper awards and the 2015 and 2022 IEEE ComSoc Fred W. Ellersick Prize.</span></p>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2312.04687" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2312.04688" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2312.04688">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2312.04688" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2312.04689" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 11:31:22 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
