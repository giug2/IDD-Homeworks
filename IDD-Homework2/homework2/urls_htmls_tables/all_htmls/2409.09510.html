<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models</title>
<!--Generated on Sat Sep 14 19:17:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.09510v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S1" title="In Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S2" title="In Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Problem Formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S3" title="In Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>LLM Personalization Approaches</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S3.SS1" title="In 3 LLM Personalization Approaches â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>RAG for Personalizing LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S3.SS2" title="In 3 LLM Personalization Approaches â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>PEFT for Personalizing LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S3.SS3" title="In 3 LLM Personalization Approaches â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>PEFT-RAG for Personalizing LLMs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4" title="In Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.SS0.SSS0.Px1" title="In 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">Setup.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.SS0.SSS0.Px2" title="In 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">How do PEFT- and RAG-based approaches perform for LLM personalization?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.SS0.SSS0.Px3" title="In 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">How does the combination of PEFT and RAG impact the personalization performance?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.SS0.SSS0.Px4" title="In 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">How does profile size and data presence in training corpus affect performance?</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S5" title="In Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S5.SS0.SSS0.Px1" title="In 5 Related Work â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">Retrieval-Augmented Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S5.SS0.SSS0.Px2" title="In 5 Related Work â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">Parameter Efficient Fine-Tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S5.SS0.SSS0.Px3" title="In 5 Related Work â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">Personalizing LLMs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S6" title="In Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#Sx1.SS0.SSS0.Px1" title="In Limitations â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">Resource Intensivity.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#Sx1.SS0.SSS0.Px2" title="In Limitations â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">Adaptor Loading and Retrieval Latency.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1" title="In Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Experiments Setup</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1.SS0.SSS0.Px1" title="In Appendix A Experiments Setup â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">Tasks &amp; Datasets.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1.SS0.SSS0.Px2" title="In Appendix A Experiments Setup â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">RAG Configuration.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1.SS0.SSS0.Px3" title="In Appendix A Experiments Setup â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title">PEFT Configuration.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A2" title="In Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Implementation of <math alttext="\phi_{q}" class="ltx_Math" display="inline"><semantics><msub><mi>Ï•</mi><mi>q</mi></msub><annotation-xml encoding="MathML-Content"><apply><csymbol cd="ambiguous">subscript</csymbol><ci>italic-Ï•</ci><ci>ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex">\phi_{q}</annotation><annotation encoding="application/x-llamapun">italic_Ï• start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\phi_{p}" class="ltx_Math" display="inline"><semantics><msub><mi>Ï•</mi><mi>p</mi></msub><annotation-xml encoding="MathML-Content"><apply><csymbol cd="ambiguous">subscript</csymbol><ci>italic-Ï•</ci><ci>ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex">\phi_{p}</annotation><annotation encoding="application/x-llamapun">italic_Ï• start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> for RAG Personalization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A3" title="In Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Implementation of CONVERT function for PEFT Personalization</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Alireza Salemi
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hamed Zamani 
<br class="ltx_break"/>University of Massachusetts Amherst 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{asalemi,zamani}@cs.umass.edu</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Privacy-preserving methods for personalizing large language models (LLMs) are relatively under-explored. There are two schools of thought on this topic: (1) generating personalized outputs by personalizing the input prompt through retrieval augmentation from the userâ€™s personal information (RAG-based methods), and (2) parameter-efficient fine-tuning of LLMs per user that considers efficiency and space limitations (PEFT-based methods). This paper presents the first systematic comparison between two approaches on a wide range of personalization tasks using seven diverse datasets. Our results indicate that RAG-based and PEFT-based personalization methods on average yield 14.92% and 1.07% improvements over the non-personalized LLM, respectively. We find that combining RAG with PEFT elevates these improvements to 15.98%. Additionally, we identify a positive correlation between the amount of user data and PEFTâ€™s effectiveness, indicating that RAG is a better choice for cold-start users (i.e., userâ€™s with limited personal data).</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_guessed_headers ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_thead">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">Alireza Salemi â€‚</span>and<span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.2">â€‚Hamed Zamani</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.2.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.1.1">University of Massachusetts Amherst</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.3.2.1.1">{asalemi,zamani}@cs.umass.edu</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Personalizing large language models (LLMs) has recently emerged as a critical topic in natural language processing <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib37" title="">a</a>); Kumar etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib21" title="">2024</a>)</cite> due to its applications in various real-world systems, such as personalized recommender system <cite class="ltx_cite ltx_citemacro_cite">Hua etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib12" title="">2023</a>); Chen (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib4" title="">2023</a>)</cite>, virtual assistants <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib25" title="">2024b</a>); Kocaballi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib20" title="">2019</a>)</cite>, and targeted content generation <cite class="ltx_cite ltx_citemacro_cite">Alhafni etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib2" title="">2024</a>)</cite>. These systems benefit from tailoring responses and actions based on individual user preferences.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">While various approaches exist for personalizing LLMs, they can be categorized into two schools of thought: those that only modify the input provided to the LLMs and those that alter the parameters of the LLMs. Retrieval-augmented generation (RAG) can be considered part of the first group, where personalized information is retrieved from the userâ€™s profile and used to generate a personalized prompt for the LLMs <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>. In the second group, parameter-efficient fine-tuning (PEFT), such as low-rank adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_cite">Hu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib11" title="">2022</a>)</cite>, can be used to tune the parameters of LLMs for each user data separately for personalization, as keeping a whole set of model parameters for each user is impractical in real-world applications. Both of these approaches preserve the privacy of users as they do not update LLM parameters and do not create input prompts using data from other users.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">We conduct an extensive set of experiments to compare these two schools of thought on seven diverse datasets obtained from the Language Model Personalization (LaMP) benchmark <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>. In more detail, LaMP consists of three text classification tasks and four text generation tasks. Each input in this benchmark is treated as a separate user, with its own specific input, expected output, and user profile, making it an ideal test case for evaluating the personalization methods explored in this paper. Our experiments show that personalizing LLMs using RAG results in an average improvement of 14.92% over the non-personalized baseline, while PEFT-based personalization leads to only a 1.07% improvement. Additionally, we demonstrate that combining both approaches achieves the best results, with a 15.98% improvement over the non-personalized baseline. Furthermore, our analysis provides insight into why PEFT does not perform as well for personalizing LLMs. In most cases, we found a positive correlation between the size of the user profile and the performance improvement, suggesting that the lack of sufficient data per user is a key reason for PEFTâ€™s underperformance. To encourage future research in this area, we have open-sourced our codebase.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The code and data are available at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/LaMP-Benchmark/LaMP" title="">https://github.com/LaMP-Benchmark/LaMP</a></span></span></span></p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Problem Formulation</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.9">This paper focuses on personalized text generation, aiming to produce outputs that are tailored to the preferences of a user. We assume access to a dataset <math alttext="T=\{(x_{i},y_{i},P_{i})\}_{i=1}^{|T|}" class="ltx_Math" display="inline" id="S2.p1.1.m1.2"><semantics id="S2.p1.1.m1.2a"><mrow id="S2.p1.1.m1.2.2" xref="S2.p1.1.m1.2.2.cmml"><mi id="S2.p1.1.m1.2.2.3" xref="S2.p1.1.m1.2.2.3.cmml">T</mi><mo id="S2.p1.1.m1.2.2.2" xref="S2.p1.1.m1.2.2.2.cmml">=</mo><msubsup id="S2.p1.1.m1.2.2.1" xref="S2.p1.1.m1.2.2.1.cmml"><mrow id="S2.p1.1.m1.2.2.1.1.1.1" xref="S2.p1.1.m1.2.2.1.1.1.2.cmml"><mo id="S2.p1.1.m1.2.2.1.1.1.1.2" stretchy="false" xref="S2.p1.1.m1.2.2.1.1.1.2.cmml">{</mo><mrow id="S2.p1.1.m1.2.2.1.1.1.1.1.3" xref="S2.p1.1.m1.2.2.1.1.1.1.1.4.cmml"><mo id="S2.p1.1.m1.2.2.1.1.1.1.1.3.4" stretchy="false" xref="S2.p1.1.m1.2.2.1.1.1.1.1.4.cmml">(</mo><msub id="S2.p1.1.m1.2.2.1.1.1.1.1.1.1" xref="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.2" xref="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.3" xref="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.p1.1.m1.2.2.1.1.1.1.1.3.5" xref="S2.p1.1.m1.2.2.1.1.1.1.1.4.cmml">,</mo><msub id="S2.p1.1.m1.2.2.1.1.1.1.1.2.2" xref="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.cmml"><mi id="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.2" xref="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.3" xref="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo id="S2.p1.1.m1.2.2.1.1.1.1.1.3.6" xref="S2.p1.1.m1.2.2.1.1.1.1.1.4.cmml">,</mo><msub id="S2.p1.1.m1.2.2.1.1.1.1.1.3.3" xref="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.cmml"><mi id="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.2" xref="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.2.cmml">P</mi><mi id="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.3" xref="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.3.cmml">i</mi></msub><mo id="S2.p1.1.m1.2.2.1.1.1.1.1.3.7" stretchy="false" xref="S2.p1.1.m1.2.2.1.1.1.1.1.4.cmml">)</mo></mrow><mo id="S2.p1.1.m1.2.2.1.1.1.1.3" stretchy="false" xref="S2.p1.1.m1.2.2.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p1.1.m1.2.2.1.1.3" xref="S2.p1.1.m1.2.2.1.1.3.cmml"><mi id="S2.p1.1.m1.2.2.1.1.3.2" xref="S2.p1.1.m1.2.2.1.1.3.2.cmml">i</mi><mo id="S2.p1.1.m1.2.2.1.1.3.1" xref="S2.p1.1.m1.2.2.1.1.3.1.cmml">=</mo><mn id="S2.p1.1.m1.2.2.1.1.3.3" xref="S2.p1.1.m1.2.2.1.1.3.3.cmml">1</mn></mrow><mrow id="S2.p1.1.m1.1.1.1.3" xref="S2.p1.1.m1.1.1.1.2.cmml"><mo id="S2.p1.1.m1.1.1.1.3.1" stretchy="false" xref="S2.p1.1.m1.1.1.1.2.1.cmml">|</mo><mi id="S2.p1.1.m1.1.1.1.1" xref="S2.p1.1.m1.1.1.1.1.cmml">T</mi><mo id="S2.p1.1.m1.1.1.1.3.2" stretchy="false" xref="S2.p1.1.m1.1.1.1.2.1.cmml">|</mo></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.2b"><apply id="S2.p1.1.m1.2.2.cmml" xref="S2.p1.1.m1.2.2"><eq id="S2.p1.1.m1.2.2.2.cmml" xref="S2.p1.1.m1.2.2.2"></eq><ci id="S2.p1.1.m1.2.2.3.cmml" xref="S2.p1.1.m1.2.2.3">ğ‘‡</ci><apply id="S2.p1.1.m1.2.2.1.cmml" xref="S2.p1.1.m1.2.2.1"><csymbol cd="ambiguous" id="S2.p1.1.m1.2.2.1.2.cmml" xref="S2.p1.1.m1.2.2.1">superscript</csymbol><apply id="S2.p1.1.m1.2.2.1.1.cmml" xref="S2.p1.1.m1.2.2.1"><csymbol cd="ambiguous" id="S2.p1.1.m1.2.2.1.1.2.cmml" xref="S2.p1.1.m1.2.2.1">subscript</csymbol><set id="S2.p1.1.m1.2.2.1.1.1.2.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1"><vector id="S2.p1.1.m1.2.2.1.1.1.1.1.4.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.3"><apply id="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.1.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.2.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.2">ğ‘¦</ci><ci id="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.3.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.2.2.3">ğ‘–</ci></apply><apply id="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.1.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.3.3">subscript</csymbol><ci id="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.2.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.2">ğ‘ƒ</ci><ci id="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.3.cmml" xref="S2.p1.1.m1.2.2.1.1.1.1.1.3.3.3">ğ‘–</ci></apply></vector></set><apply id="S2.p1.1.m1.2.2.1.1.3.cmml" xref="S2.p1.1.m1.2.2.1.1.3"><eq id="S2.p1.1.m1.2.2.1.1.3.1.cmml" xref="S2.p1.1.m1.2.2.1.1.3.1"></eq><ci id="S2.p1.1.m1.2.2.1.1.3.2.cmml" xref="S2.p1.1.m1.2.2.1.1.3.2">ğ‘–</ci><cn id="S2.p1.1.m1.2.2.1.1.3.3.cmml" type="integer" xref="S2.p1.1.m1.2.2.1.1.3.3">1</cn></apply></apply><apply id="S2.p1.1.m1.1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.1.3"><abs id="S2.p1.1.m1.1.1.1.2.1.cmml" xref="S2.p1.1.m1.1.1.1.3.1"></abs><ci id="S2.p1.1.m1.1.1.1.1.cmml" xref="S2.p1.1.m1.1.1.1.1">ğ‘‡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.2c">T=\{(x_{i},y_{i},P_{i})\}_{i=1}^{|T|}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.2d">italic_T = { ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | italic_T | end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="x_{i}" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><msub id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">x</mi><mi id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">ğ‘¥</ci><ci id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the input prompt from user <math alttext="u_{i}" class="ltx_Math" display="inline" id="S2.p1.3.m3.1"><semantics id="S2.p1.3.m3.1a"><msub id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml"><mi id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml">u</mi><mi id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p1.3.m3.1.1.1.cmml" xref="S2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">ğ‘¢</ci><ci id="S2.p1.3.m3.1.1.3.cmml" xref="S2.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">u_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.3.m3.1d">italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="y_{i}" class="ltx_Math" display="inline" id="S2.p1.4.m4.1"><semantics id="S2.p1.4.m4.1a"><msub id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><mi id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml">y</mi><mi id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2">ğ‘¦</ci><ci id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.4.m4.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the expected output for user <math alttext="u_{i}" class="ltx_Math" display="inline" id="S2.p1.5.m5.1"><semantics id="S2.p1.5.m5.1a"><msub id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml"><mi id="S2.p1.5.m5.1.1.2" xref="S2.p1.5.m5.1.1.2.cmml">u</mi><mi id="S2.p1.5.m5.1.1.3" xref="S2.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><apply id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.1.cmml" xref="S2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.p1.5.m5.1.1.2.cmml" xref="S2.p1.5.m5.1.1.2">ğ‘¢</ci><ci id="S2.p1.5.m5.1.1.3.cmml" xref="S2.p1.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">u_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.5.m5.1d">italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="P_{i}" class="ltx_Math" display="inline" id="S2.p1.6.m6.1"><semantics id="S2.p1.6.m6.1a"><msub id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml"><mi id="S2.p1.6.m6.1.1.2" xref="S2.p1.6.m6.1.1.2.cmml">P</mi><mi id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.2">ğ‘ƒ</ci><ci id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.6.m6.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the user profile. Here, a user profile <math alttext="P_{i}" class="ltx_Math" display="inline" id="S2.p1.7.m7.1"><semantics id="S2.p1.7.m7.1a"><msub id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml"><mi id="S2.p1.7.m7.1.1.2" xref="S2.p1.7.m7.1.1.2.cmml">P</mi><mi id="S2.p1.7.m7.1.1.3" xref="S2.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b"><apply id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.p1.7.m7.1.1.1.cmml" xref="S2.p1.7.m7.1.1">subscript</csymbol><ci id="S2.p1.7.m7.1.1.2.cmml" xref="S2.p1.7.m7.1.1.2">ğ‘ƒ</ci><ci id="S2.p1.7.m7.1.1.3.cmml" xref="S2.p1.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.7.m7.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> consists of a set of unstructured text documents for the user <math alttext="u_{i}" class="ltx_Math" display="inline" id="S2.p1.8.m8.1"><semantics id="S2.p1.8.m8.1a"><msub id="S2.p1.8.m8.1.1" xref="S2.p1.8.m8.1.1.cmml"><mi id="S2.p1.8.m8.1.1.2" xref="S2.p1.8.m8.1.1.2.cmml">u</mi><mi id="S2.p1.8.m8.1.1.3" xref="S2.p1.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.8.m8.1b"><apply id="S2.p1.8.m8.1.1.cmml" xref="S2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p1.8.m8.1.1.1.cmml" xref="S2.p1.8.m8.1.1">subscript</csymbol><ci id="S2.p1.8.m8.1.1.2.cmml" xref="S2.p1.8.m8.1.1.2">ğ‘¢</ci><ci id="S2.p1.8.m8.1.1.3.cmml" xref="S2.p1.8.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.8.m8.1c">u_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.8.m8.1d">italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, denoted as <math alttext="P_{i}=\{d_{(i,j)}\}_{j=1}^{|P_{i}|}" class="ltx_Math" display="inline" id="S2.p1.9.m9.4"><semantics id="S2.p1.9.m9.4a"><mrow id="S2.p1.9.m9.4.4" xref="S2.p1.9.m9.4.4.cmml"><msub id="S2.p1.9.m9.4.4.3" xref="S2.p1.9.m9.4.4.3.cmml"><mi id="S2.p1.9.m9.4.4.3.2" xref="S2.p1.9.m9.4.4.3.2.cmml">P</mi><mi id="S2.p1.9.m9.4.4.3.3" xref="S2.p1.9.m9.4.4.3.3.cmml">i</mi></msub><mo id="S2.p1.9.m9.4.4.2" xref="S2.p1.9.m9.4.4.2.cmml">=</mo><msubsup id="S2.p1.9.m9.4.4.1" xref="S2.p1.9.m9.4.4.1.cmml"><mrow id="S2.p1.9.m9.4.4.1.1.1.1" xref="S2.p1.9.m9.4.4.1.1.1.2.cmml"><mo id="S2.p1.9.m9.4.4.1.1.1.1.2" stretchy="false" xref="S2.p1.9.m9.4.4.1.1.1.2.cmml">{</mo><msub id="S2.p1.9.m9.4.4.1.1.1.1.1" xref="S2.p1.9.m9.4.4.1.1.1.1.1.cmml"><mi id="S2.p1.9.m9.4.4.1.1.1.1.1.2" xref="S2.p1.9.m9.4.4.1.1.1.1.1.2.cmml">d</mi><mrow id="S2.p1.9.m9.2.2.2.4" xref="S2.p1.9.m9.2.2.2.3.cmml"><mo id="S2.p1.9.m9.2.2.2.4.1" stretchy="false" xref="S2.p1.9.m9.2.2.2.3.cmml">(</mo><mi id="S2.p1.9.m9.1.1.1.1" xref="S2.p1.9.m9.1.1.1.1.cmml">i</mi><mo id="S2.p1.9.m9.2.2.2.4.2" xref="S2.p1.9.m9.2.2.2.3.cmml">,</mo><mi id="S2.p1.9.m9.2.2.2.2" xref="S2.p1.9.m9.2.2.2.2.cmml">j</mi><mo id="S2.p1.9.m9.2.2.2.4.3" stretchy="false" xref="S2.p1.9.m9.2.2.2.3.cmml">)</mo></mrow></msub><mo id="S2.p1.9.m9.4.4.1.1.1.1.3" stretchy="false" xref="S2.p1.9.m9.4.4.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p1.9.m9.4.4.1.1.3" xref="S2.p1.9.m9.4.4.1.1.3.cmml"><mi id="S2.p1.9.m9.4.4.1.1.3.2" xref="S2.p1.9.m9.4.4.1.1.3.2.cmml">j</mi><mo id="S2.p1.9.m9.4.4.1.1.3.1" xref="S2.p1.9.m9.4.4.1.1.3.1.cmml">=</mo><mn id="S2.p1.9.m9.4.4.1.1.3.3" xref="S2.p1.9.m9.4.4.1.1.3.3.cmml">1</mn></mrow><mrow id="S2.p1.9.m9.3.3.1.1" xref="S2.p1.9.m9.3.3.1.2.cmml"><mo id="S2.p1.9.m9.3.3.1.1.2" stretchy="false" xref="S2.p1.9.m9.3.3.1.2.1.cmml">|</mo><msub id="S2.p1.9.m9.3.3.1.1.1" xref="S2.p1.9.m9.3.3.1.1.1.cmml"><mi id="S2.p1.9.m9.3.3.1.1.1.2" xref="S2.p1.9.m9.3.3.1.1.1.2.cmml">P</mi><mi id="S2.p1.9.m9.3.3.1.1.1.3" xref="S2.p1.9.m9.3.3.1.1.1.3.cmml">i</mi></msub><mo id="S2.p1.9.m9.3.3.1.1.3" stretchy="false" xref="S2.p1.9.m9.3.3.1.2.1.cmml">|</mo></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.9.m9.4b"><apply id="S2.p1.9.m9.4.4.cmml" xref="S2.p1.9.m9.4.4"><eq id="S2.p1.9.m9.4.4.2.cmml" xref="S2.p1.9.m9.4.4.2"></eq><apply id="S2.p1.9.m9.4.4.3.cmml" xref="S2.p1.9.m9.4.4.3"><csymbol cd="ambiguous" id="S2.p1.9.m9.4.4.3.1.cmml" xref="S2.p1.9.m9.4.4.3">subscript</csymbol><ci id="S2.p1.9.m9.4.4.3.2.cmml" xref="S2.p1.9.m9.4.4.3.2">ğ‘ƒ</ci><ci id="S2.p1.9.m9.4.4.3.3.cmml" xref="S2.p1.9.m9.4.4.3.3">ğ‘–</ci></apply><apply id="S2.p1.9.m9.4.4.1.cmml" xref="S2.p1.9.m9.4.4.1"><csymbol cd="ambiguous" id="S2.p1.9.m9.4.4.1.2.cmml" xref="S2.p1.9.m9.4.4.1">superscript</csymbol><apply id="S2.p1.9.m9.4.4.1.1.cmml" xref="S2.p1.9.m9.4.4.1"><csymbol cd="ambiguous" id="S2.p1.9.m9.4.4.1.1.2.cmml" xref="S2.p1.9.m9.4.4.1">subscript</csymbol><set id="S2.p1.9.m9.4.4.1.1.1.2.cmml" xref="S2.p1.9.m9.4.4.1.1.1.1"><apply id="S2.p1.9.m9.4.4.1.1.1.1.1.cmml" xref="S2.p1.9.m9.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p1.9.m9.4.4.1.1.1.1.1.1.cmml" xref="S2.p1.9.m9.4.4.1.1.1.1.1">subscript</csymbol><ci id="S2.p1.9.m9.4.4.1.1.1.1.1.2.cmml" xref="S2.p1.9.m9.4.4.1.1.1.1.1.2">ğ‘‘</ci><interval closure="open" id="S2.p1.9.m9.2.2.2.3.cmml" xref="S2.p1.9.m9.2.2.2.4"><ci id="S2.p1.9.m9.1.1.1.1.cmml" xref="S2.p1.9.m9.1.1.1.1">ğ‘–</ci><ci id="S2.p1.9.m9.2.2.2.2.cmml" xref="S2.p1.9.m9.2.2.2.2">ğ‘—</ci></interval></apply></set><apply id="S2.p1.9.m9.4.4.1.1.3.cmml" xref="S2.p1.9.m9.4.4.1.1.3"><eq id="S2.p1.9.m9.4.4.1.1.3.1.cmml" xref="S2.p1.9.m9.4.4.1.1.3.1"></eq><ci id="S2.p1.9.m9.4.4.1.1.3.2.cmml" xref="S2.p1.9.m9.4.4.1.1.3.2">ğ‘—</ci><cn id="S2.p1.9.m9.4.4.1.1.3.3.cmml" type="integer" xref="S2.p1.9.m9.4.4.1.1.3.3">1</cn></apply></apply><apply id="S2.p1.9.m9.3.3.1.2.cmml" xref="S2.p1.9.m9.3.3.1.1"><abs id="S2.p1.9.m9.3.3.1.2.1.cmml" xref="S2.p1.9.m9.3.3.1.1.2"></abs><apply id="S2.p1.9.m9.3.3.1.1.1.cmml" xref="S2.p1.9.m9.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.p1.9.m9.3.3.1.1.1.1.cmml" xref="S2.p1.9.m9.3.3.1.1.1">subscript</csymbol><ci id="S2.p1.9.m9.3.3.1.1.1.2.cmml" xref="S2.p1.9.m9.3.3.1.1.1.2">ğ‘ƒ</ci><ci id="S2.p1.9.m9.3.3.1.1.1.3.cmml" xref="S2.p1.9.m9.3.3.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.9.m9.4c">P_{i}=\{d_{(i,j)}\}_{j=1}^{|P_{i}|}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.9.m9.4d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = { italic_d start_POSTSUBSCRIPT ( italic_i , italic_j ) end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.9">This paper aims to utilize the information about user <math alttext="u_{i}" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><msub id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml"><mi id="S2.p2.1.m1.1.1.2" xref="S2.p2.1.m1.1.1.2.cmml">u</mi><mi id="S2.p2.1.m1.1.1.3" xref="S2.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><apply id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p2.1.m1.1.1.1.cmml" xref="S2.p2.1.m1.1.1">subscript</csymbol><ci id="S2.p2.1.m1.1.1.2.cmml" xref="S2.p2.1.m1.1.1.2">ğ‘¢</ci><ci id="S2.p2.1.m1.1.1.3.cmml" xref="S2.p2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">u_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p2.1.m1.1d">italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> available in profile <math alttext="P_{i}" class="ltx_Math" display="inline" id="S2.p2.2.m2.1"><semantics id="S2.p2.2.m2.1a"><msub id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml"><mi id="S2.p2.2.m2.1.1.2" xref="S2.p2.2.m2.1.1.2.cmml">P</mi><mi id="S2.p2.2.m2.1.1.3" xref="S2.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><apply id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p2.2.m2.1.1.1.cmml" xref="S2.p2.2.m2.1.1">subscript</csymbol><ci id="S2.p2.2.m2.1.1.2.cmml" xref="S2.p2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="S2.p2.2.m2.1.1.3.cmml" xref="S2.p2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to construct a personalized LLM <math alttext="M_{i}=\textsc{personalize}(M,P_{i})" class="ltx_Math" display="inline" id="S2.p2.3.m3.2"><semantics id="S2.p2.3.m3.2a"><mrow id="S2.p2.3.m3.2.2" xref="S2.p2.3.m3.2.2.cmml"><msub id="S2.p2.3.m3.2.2.3" xref="S2.p2.3.m3.2.2.3.cmml"><mi id="S2.p2.3.m3.2.2.3.2" xref="S2.p2.3.m3.2.2.3.2.cmml">M</mi><mi id="S2.p2.3.m3.2.2.3.3" xref="S2.p2.3.m3.2.2.3.3.cmml">i</mi></msub><mo id="S2.p2.3.m3.2.2.2" xref="S2.p2.3.m3.2.2.2.cmml">=</mo><mrow id="S2.p2.3.m3.2.2.1" xref="S2.p2.3.m3.2.2.1.cmml"><mtext class="ltx_font_smallcaps" id="S2.p2.3.m3.2.2.1.3" xref="S2.p2.3.m3.2.2.1.3a.cmml">personalize</mtext><mo id="S2.p2.3.m3.2.2.1.2" xref="S2.p2.3.m3.2.2.1.2.cmml">â¢</mo><mrow id="S2.p2.3.m3.2.2.1.1.1" xref="S2.p2.3.m3.2.2.1.1.2.cmml"><mo id="S2.p2.3.m3.2.2.1.1.1.2" stretchy="false" xref="S2.p2.3.m3.2.2.1.1.2.cmml">(</mo><mi id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">M</mi><mo id="S2.p2.3.m3.2.2.1.1.1.3" xref="S2.p2.3.m3.2.2.1.1.2.cmml">,</mo><msub id="S2.p2.3.m3.2.2.1.1.1.1" xref="S2.p2.3.m3.2.2.1.1.1.1.cmml"><mi id="S2.p2.3.m3.2.2.1.1.1.1.2" xref="S2.p2.3.m3.2.2.1.1.1.1.2.cmml">P</mi><mi id="S2.p2.3.m3.2.2.1.1.1.1.3" xref="S2.p2.3.m3.2.2.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.p2.3.m3.2.2.1.1.1.4" stretchy="false" xref="S2.p2.3.m3.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.2b"><apply id="S2.p2.3.m3.2.2.cmml" xref="S2.p2.3.m3.2.2"><eq id="S2.p2.3.m3.2.2.2.cmml" xref="S2.p2.3.m3.2.2.2"></eq><apply id="S2.p2.3.m3.2.2.3.cmml" xref="S2.p2.3.m3.2.2.3"><csymbol cd="ambiguous" id="S2.p2.3.m3.2.2.3.1.cmml" xref="S2.p2.3.m3.2.2.3">subscript</csymbol><ci id="S2.p2.3.m3.2.2.3.2.cmml" xref="S2.p2.3.m3.2.2.3.2">ğ‘€</ci><ci id="S2.p2.3.m3.2.2.3.3.cmml" xref="S2.p2.3.m3.2.2.3.3">ğ‘–</ci></apply><apply id="S2.p2.3.m3.2.2.1.cmml" xref="S2.p2.3.m3.2.2.1"><times id="S2.p2.3.m3.2.2.1.2.cmml" xref="S2.p2.3.m3.2.2.1.2"></times><ci id="S2.p2.3.m3.2.2.1.3a.cmml" xref="S2.p2.3.m3.2.2.1.3"><mtext class="ltx_font_smallcaps" id="S2.p2.3.m3.2.2.1.3.cmml" xref="S2.p2.3.m3.2.2.1.3">personalize</mtext></ci><interval closure="open" id="S2.p2.3.m3.2.2.1.1.2.cmml" xref="S2.p2.3.m3.2.2.1.1.1"><ci id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1">ğ‘€</ci><apply id="S2.p2.3.m3.2.2.1.1.1.1.cmml" xref="S2.p2.3.m3.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.3.m3.2.2.1.1.1.1.1.cmml" xref="S2.p2.3.m3.2.2.1.1.1.1">subscript</csymbol><ci id="S2.p2.3.m3.2.2.1.1.1.1.2.cmml" xref="S2.p2.3.m3.2.2.1.1.1.1.2">ğ‘ƒ</ci><ci id="S2.p2.3.m3.2.2.1.1.1.1.3.cmml" xref="S2.p2.3.m3.2.2.1.1.1.1.3">ğ‘–</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.2c">M_{i}=\textsc{personalize}(M,P_{i})</annotation><annotation encoding="application/x-llamapun" id="S2.p2.3.m3.2d">italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = personalize ( italic_M , italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> by applying a transformation <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S2.p2.9.1">personalize</span> to the LLM <math alttext="M" class="ltx_Math" display="inline" id="S2.p2.5.m5.1"><semantics id="S2.p2.5.m5.1a"><mi id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b"><ci id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">M</annotation><annotation encoding="application/x-llamapun" id="S2.p2.5.m5.1d">italic_M</annotation></semantics></math>. This function can either modify the parameters of the LLM <math alttext="M" class="ltx_Math" display="inline" id="S2.p2.6.m6.1"><semantics id="S2.p2.6.m6.1a"><mi id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b"><ci id="S2.p2.6.m6.1.1.cmml" xref="S2.p2.6.m6.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">M</annotation><annotation encoding="application/x-llamapun" id="S2.p2.6.m6.1d">italic_M</annotation></semantics></math> to construct <math alttext="M_{i}" class="ltx_Math" display="inline" id="S2.p2.7.m7.1"><semantics id="S2.p2.7.m7.1a"><msub id="S2.p2.7.m7.1.1" xref="S2.p2.7.m7.1.1.cmml"><mi id="S2.p2.7.m7.1.1.2" xref="S2.p2.7.m7.1.1.2.cmml">M</mi><mi id="S2.p2.7.m7.1.1.3" xref="S2.p2.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.7.m7.1b"><apply id="S2.p2.7.m7.1.1.cmml" xref="S2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.1.cmml" xref="S2.p2.7.m7.1.1">subscript</csymbol><ci id="S2.p2.7.m7.1.1.2.cmml" xref="S2.p2.7.m7.1.1.2">ğ‘€</ci><ci id="S2.p2.7.m7.1.1.3.cmml" xref="S2.p2.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.7.m7.1c">M_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p2.7.m7.1d">italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> or simply alter the input to the LLM based on the profile <math alttext="P_{i}" class="ltx_Math" display="inline" id="S2.p2.8.m8.1"><semantics id="S2.p2.8.m8.1a"><msub id="S2.p2.8.m8.1.1" xref="S2.p2.8.m8.1.1.cmml"><mi id="S2.p2.8.m8.1.1.2" xref="S2.p2.8.m8.1.1.2.cmml">P</mi><mi id="S2.p2.8.m8.1.1.3" xref="S2.p2.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.8.m8.1b"><apply id="S2.p2.8.m8.1.1.cmml" xref="S2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p2.8.m8.1.1.1.cmml" xref="S2.p2.8.m8.1.1">subscript</csymbol><ci id="S2.p2.8.m8.1.1.2.cmml" xref="S2.p2.8.m8.1.1.2">ğ‘ƒ</ci><ci id="S2.p2.8.m8.1.1.3.cmml" xref="S2.p2.8.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.8.m8.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.p2.8.m8.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. We focus on comparing different methods for designing the transformation <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S2.p2.9.2">personalize</span> while keeping privacy, which means we cannot use information from other users to personalize the LLM for a user.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>LLM Personalization Approaches</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>RAG for Personalizing LLMs</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.7">Given an input prompt <math alttext="x" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_x</annotation></semantics></math> from the user, we use the query generation function <math alttext="\phi_{q}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">Ï•</mi><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">italic-Ï•</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\phi_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_Ï• start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> to create a query. This query is then passed through the retriever <math alttext="R" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">R</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_R</annotation></semantics></math>, which retrieves <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_k</annotation></semantics></math> documents from the userâ€™s profile <math alttext="P_{u}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">P</mi><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">ğ‘ƒ</ci><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">P_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">italic_P start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math>. Finally, the prompt generation function <math alttext="\phi_{p}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">Ï•</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">italic-Ï•</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\phi_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">italic_Ï• start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> combines the retrieved documents and the input prompt to generate a personalized prompt, which is used as the input to the LLM <math alttext="M" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">italic_M</annotation></semantics></math> to generate a more tailored response, formally, defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bar{y}=M(\phi_{p}(x,R(\phi_{q}(x),k))" class="ltx_math_unparsed" display="block" id="S3.E1.m1.3"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3b"><mover accent="true" id="S3.E1.m1.3.4"><mi id="S3.E1.m1.3.4.2">y</mi><mo id="S3.E1.m1.3.4.1">Â¯</mo></mover><mo id="S3.E1.m1.3.5">=</mo><mi id="S3.E1.m1.3.6">M</mi><mrow id="S3.E1.m1.3.7"><mo id="S3.E1.m1.3.7.1" stretchy="false">(</mo><msub id="S3.E1.m1.3.7.2"><mi id="S3.E1.m1.3.7.2.2">Ï•</mi><mi id="S3.E1.m1.3.7.2.3">p</mi></msub><mrow id="S3.E1.m1.3.7.3"><mo id="S3.E1.m1.3.7.3.1" stretchy="false">(</mo><mi id="S3.E1.m1.3.3">x</mi><mo id="S3.E1.m1.3.7.3.2">,</mo><mi id="S3.E1.m1.3.7.3.3">R</mi><mrow id="S3.E1.m1.3.7.3.4"><mo id="S3.E1.m1.3.7.3.4.1" stretchy="false">(</mo><msub id="S3.E1.m1.3.7.3.4.2"><mi id="S3.E1.m1.3.7.3.4.2.2">Ï•</mi><mi id="S3.E1.m1.3.7.3.4.2.3">q</mi></msub><mrow id="S3.E1.m1.3.7.3.4.3"><mo id="S3.E1.m1.3.7.3.4.3.1" stretchy="false">(</mo><mi id="S3.E1.m1.1.1">x</mi><mo id="S3.E1.m1.3.7.3.4.3.2" stretchy="false">)</mo></mrow><mo id="S3.E1.m1.3.7.3.4.4">,</mo><mi id="S3.E1.m1.2.2">k</mi><mo id="S3.E1.m1.3.7.3.4.5" stretchy="false">)</mo></mrow><mo id="S3.E1.m1.3.7.3.5" stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\bar{y}=M(\phi_{p}(x,R(\phi_{q}(x),k))</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.3d">overÂ¯ start_ARG italic_y end_ARG = italic_M ( italic_Ï• start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_x , italic_R ( italic_Ï• start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_x ) , italic_k ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.2">Note that this approach does not modify the LLM itself. Instead, it adjusts its input, using a tailored prompt to the user based on the retrieved documents from the user profile. This allows us to personalize the LLMâ€™s response without altering its underlying structure and parameters, which works on any black-box LLM. The implementation details for <math alttext="\phi_{q}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">Ï•</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">italic-Ï•</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\phi_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_Ï• start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\phi_{p}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">Ï•</mi><mi id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">italic-Ï•</ci><ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\phi_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_Ï• start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> are provided in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1.T3" title="Table 3 â€£ Tasks &amp; Datasets. â€£ Appendix A Experiments Setup â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A2" title="Appendix B Implementation of Ï•_ğ‘ and Ï•_ğ‘ for RAG Personalization â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">B</span></a>. In our experiments, we used a wide range of retrieval models: BM25 <cite class="ltx_cite ltx_citemacro_cite">Robertson etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib35" title="">1994</a>)</cite> as a lexical-matching retrieval model, Contriever <cite class="ltx_cite ltx_citemacro_cite">Izacard etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib13" title="">2022</a>)</cite> as a semantic matching retrieval model, Recency <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite> as a time-aware retrieval model, and RSPG <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib37" title="">2024a</a>)</cite> as an ensemble model that chooses an appropriate retrieval model per input. More information is provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1" title="Appendix A Experiments Setup â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>PEFT for Personalizing LLMs</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Keeping a separate LLM for each user is infeasible for systems with many users. For example, storing FlanT5-XXL <cite class="ltx_cite ltx_citemacro_cite">Chung etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib5" title="">2024</a>)</cite> requires 45 GB per user. Conversely, a LoRA adapter with <math alttext="r=8" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">r</mi><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><eq id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></eq><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ‘Ÿ</ci><cn id="S3.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">r=8</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_r = 8</annotation></semantics></math> for the same model only needs 55 MB. For 1 million users, this totals 55 TB, making it more practical for real-world applications. Thus, using PEFT is a more cost-efficient solution.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.12">This approach uses a user profile <math alttext="P_{u}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">P</mi><mi id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">ğ‘ƒ</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">P_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_P start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> for learning user-specific parameters, resulting in a personalized LLM <math alttext="M_{u}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">M</mi><mi id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">ğ‘€</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">M_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math>. There are different ways to do this; we apply LoRA to the LLM <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_M</annotation></semantics></math> and train the model using the documents in <math alttext="P_{u}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><msub id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">P</mi><mi id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">ğ‘ƒ</ci><ci id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">P_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.1d">italic_P start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math>. LoRA fine-tunes LLMs by injecting trainable low-rank matrices into the modelâ€™s weight matrices. Instead of updating the full weights during training, LoRA decomposes the weight update into two smaller, low-rank matrices <math alttext="A\in\mathbb{R}^{d\times r}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><mrow id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">A</mi><mo id="S3.SS2.p2.5.m5.1.1.1" xref="S3.SS2.p2.5.m5.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml"><mi id="S3.SS2.p2.5.m5.1.1.3.2" xref="S3.SS2.p2.5.m5.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.5.m5.1.1.3.3" xref="S3.SS2.p2.5.m5.1.1.3.3.cmml"><mi id="S3.SS2.p2.5.m5.1.1.3.3.2" xref="S3.SS2.p2.5.m5.1.1.3.3.2.cmml">d</mi><mo id="S3.SS2.p2.5.m5.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p2.5.m5.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p2.5.m5.1.1.3.3.3" xref="S3.SS2.p2.5.m5.1.1.3.3.3.cmml">r</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><in id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1"></in><ci id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2">ğ´</ci><apply id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.3.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2">â„</ci><apply id="S3.SS2.p2.5.m5.1.1.3.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.3"><times id="S3.SS2.p2.5.m5.1.1.3.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3.3.1"></times><ci id="S3.SS2.p2.5.m5.1.1.3.3.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS2.p2.5.m5.1.1.3.3.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.3.3">ğ‘Ÿ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">A\in\mathbb{R}^{d\times r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">italic_A âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_d Ã— italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="B\in\mathbb{R}^{r\times k}" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m6.1"><semantics id="S3.SS2.p2.6.m6.1a"><mrow id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.p2.6.m6.1.1.2" xref="S3.SS2.p2.6.m6.1.1.2.cmml">B</mi><mo id="S3.SS2.p2.6.m6.1.1.1" xref="S3.SS2.p2.6.m6.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.6.m6.1.1.3" xref="S3.SS2.p2.6.m6.1.1.3.cmml"><mi id="S3.SS2.p2.6.m6.1.1.3.2" xref="S3.SS2.p2.6.m6.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.6.m6.1.1.3.3" xref="S3.SS2.p2.6.m6.1.1.3.3.cmml"><mi id="S3.SS2.p2.6.m6.1.1.3.3.2" xref="S3.SS2.p2.6.m6.1.1.3.3.2.cmml">r</mi><mo id="S3.SS2.p2.6.m6.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p2.6.m6.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p2.6.m6.1.1.3.3.3" xref="S3.SS2.p2.6.m6.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><apply id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1"><in id="S3.SS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1.1"></in><ci id="S3.SS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2">ğµ</ci><apply id="S3.SS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.3.1.cmml" xref="S3.SS2.p2.6.m6.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.3.2.cmml" xref="S3.SS2.p2.6.m6.1.1.3.2">â„</ci><apply id="S3.SS2.p2.6.m6.1.1.3.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3"><times id="S3.SS2.p2.6.m6.1.1.3.3.1.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3.1"></times><ci id="S3.SS2.p2.6.m6.1.1.3.3.2.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3.2">ğ‘Ÿ</ci><ci id="S3.SS2.p2.6.m6.1.1.3.3.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3.3">ğ‘˜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">B\in\mathbb{R}^{r\times k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m6.1d">italic_B âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_r Ã— italic_k end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="r" class="ltx_Math" display="inline" id="S3.SS2.p2.7.m7.1"><semantics id="S3.SS2.p2.7.m7.1a"><mi id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><ci id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.7.m7.1d">italic_r</annotation></semantics></math> is the rank parameter. The original weights <math alttext="W_{0}\in\mathbb{R}^{d\times k}" class="ltx_Math" display="inline" id="S3.SS2.p2.8.m8.1"><semantics id="S3.SS2.p2.8.m8.1a"><mrow id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml"><msub id="S3.SS2.p2.8.m8.1.1.2" xref="S3.SS2.p2.8.m8.1.1.2.cmml"><mi id="S3.SS2.p2.8.m8.1.1.2.2" xref="S3.SS2.p2.8.m8.1.1.2.2.cmml">W</mi><mn id="S3.SS2.p2.8.m8.1.1.2.3" xref="S3.SS2.p2.8.m8.1.1.2.3.cmml">0</mn></msub><mo id="S3.SS2.p2.8.m8.1.1.1" xref="S3.SS2.p2.8.m8.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.8.m8.1.1.3" xref="S3.SS2.p2.8.m8.1.1.3.cmml"><mi id="S3.SS2.p2.8.m8.1.1.3.2" xref="S3.SS2.p2.8.m8.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.8.m8.1.1.3.3" xref="S3.SS2.p2.8.m8.1.1.3.3.cmml"><mi id="S3.SS2.p2.8.m8.1.1.3.3.2" xref="S3.SS2.p2.8.m8.1.1.3.3.2.cmml">d</mi><mo id="S3.SS2.p2.8.m8.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p2.8.m8.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p2.8.m8.1.1.3.3.3" xref="S3.SS2.p2.8.m8.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><apply id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1"><in id="S3.SS2.p2.8.m8.1.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1.1"></in><apply id="S3.SS2.p2.8.m8.1.1.2.cmml" xref="S3.SS2.p2.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.1.1.2.1.cmml" xref="S3.SS2.p2.8.m8.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.8.m8.1.1.2.2.cmml" xref="S3.SS2.p2.8.m8.1.1.2.2">ğ‘Š</ci><cn id="S3.SS2.p2.8.m8.1.1.2.3.cmml" type="integer" xref="S3.SS2.p2.8.m8.1.1.2.3">0</cn></apply><apply id="S3.SS2.p2.8.m8.1.1.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.1.1.3.1.cmml" xref="S3.SS2.p2.8.m8.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.8.m8.1.1.3.2.cmml" xref="S3.SS2.p2.8.m8.1.1.3.2">â„</ci><apply id="S3.SS2.p2.8.m8.1.1.3.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3.3"><times id="S3.SS2.p2.8.m8.1.1.3.3.1.cmml" xref="S3.SS2.p2.8.m8.1.1.3.3.1"></times><ci id="S3.SS2.p2.8.m8.1.1.3.3.2.cmml" xref="S3.SS2.p2.8.m8.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS2.p2.8.m8.1.1.3.3.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3.3.3">ğ‘˜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">W_{0}\in\mathbb{R}^{d\times k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.8.m8.1d">italic_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_d Ã— italic_k end_POSTSUPERSCRIPT</annotation></semantics></math> remain frozen, and only <math alttext="A" class="ltx_Math" display="inline" id="S3.SS2.p2.9.m9.1"><semantics id="S3.SS2.p2.9.m9.1a"><mi id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.1b"><ci id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.1c">A</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.9.m9.1d">italic_A</annotation></semantics></math> and <math alttext="B" class="ltx_Math" display="inline" id="S3.SS2.p2.10.m10.1"><semantics id="S3.SS2.p2.10.m10.1a"><mi id="S3.SS2.p2.10.m10.1.1" xref="S3.SS2.p2.10.m10.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m10.1b"><ci id="S3.SS2.p2.10.m10.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m10.1c">B</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.10.m10.1d">italic_B</annotation></semantics></math> are trained to approximate the updates (<math alttext="W=W_{0}+AB" class="ltx_Math" display="inline" id="S3.SS2.p2.11.m11.1"><semantics id="S3.SS2.p2.11.m11.1a"><mrow id="S3.SS2.p2.11.m11.1.1" xref="S3.SS2.p2.11.m11.1.1.cmml"><mi id="S3.SS2.p2.11.m11.1.1.2" xref="S3.SS2.p2.11.m11.1.1.2.cmml">W</mi><mo id="S3.SS2.p2.11.m11.1.1.1" xref="S3.SS2.p2.11.m11.1.1.1.cmml">=</mo><mrow id="S3.SS2.p2.11.m11.1.1.3" xref="S3.SS2.p2.11.m11.1.1.3.cmml"><msub id="S3.SS2.p2.11.m11.1.1.3.2" xref="S3.SS2.p2.11.m11.1.1.3.2.cmml"><mi id="S3.SS2.p2.11.m11.1.1.3.2.2" xref="S3.SS2.p2.11.m11.1.1.3.2.2.cmml">W</mi><mn id="S3.SS2.p2.11.m11.1.1.3.2.3" xref="S3.SS2.p2.11.m11.1.1.3.2.3.cmml">0</mn></msub><mo id="S3.SS2.p2.11.m11.1.1.3.1" xref="S3.SS2.p2.11.m11.1.1.3.1.cmml">+</mo><mrow id="S3.SS2.p2.11.m11.1.1.3.3" xref="S3.SS2.p2.11.m11.1.1.3.3.cmml"><mi id="S3.SS2.p2.11.m11.1.1.3.3.2" xref="S3.SS2.p2.11.m11.1.1.3.3.2.cmml">A</mi><mo id="S3.SS2.p2.11.m11.1.1.3.3.1" xref="S3.SS2.p2.11.m11.1.1.3.3.1.cmml">â¢</mo><mi id="S3.SS2.p2.11.m11.1.1.3.3.3" xref="S3.SS2.p2.11.m11.1.1.3.3.3.cmml">B</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.11.m11.1b"><apply id="S3.SS2.p2.11.m11.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1"><eq id="S3.SS2.p2.11.m11.1.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1.1"></eq><ci id="S3.SS2.p2.11.m11.1.1.2.cmml" xref="S3.SS2.p2.11.m11.1.1.2">ğ‘Š</ci><apply id="S3.SS2.p2.11.m11.1.1.3.cmml" xref="S3.SS2.p2.11.m11.1.1.3"><plus id="S3.SS2.p2.11.m11.1.1.3.1.cmml" xref="S3.SS2.p2.11.m11.1.1.3.1"></plus><apply id="S3.SS2.p2.11.m11.1.1.3.2.cmml" xref="S3.SS2.p2.11.m11.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m11.1.1.3.2.1.cmml" xref="S3.SS2.p2.11.m11.1.1.3.2">subscript</csymbol><ci id="S3.SS2.p2.11.m11.1.1.3.2.2.cmml" xref="S3.SS2.p2.11.m11.1.1.3.2.2">ğ‘Š</ci><cn id="S3.SS2.p2.11.m11.1.1.3.2.3.cmml" type="integer" xref="S3.SS2.p2.11.m11.1.1.3.2.3">0</cn></apply><apply id="S3.SS2.p2.11.m11.1.1.3.3.cmml" xref="S3.SS2.p2.11.m11.1.1.3.3"><times id="S3.SS2.p2.11.m11.1.1.3.3.1.cmml" xref="S3.SS2.p2.11.m11.1.1.3.3.1"></times><ci id="S3.SS2.p2.11.m11.1.1.3.3.2.cmml" xref="S3.SS2.p2.11.m11.1.1.3.3.2">ğ´</ci><ci id="S3.SS2.p2.11.m11.1.1.3.3.3.cmml" xref="S3.SS2.p2.11.m11.1.1.3.3.3">ğµ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.11.m11.1c">W=W_{0}+AB</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.11.m11.1d">italic_W = italic_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_A italic_B</annotation></semantics></math>). The parameter <math alttext="r" class="ltx_Math" display="inline" id="S3.SS2.p2.12.m12.1"><semantics id="S3.SS2.p2.12.m12.1a"><mi id="S3.SS2.p2.12.m12.1.1" xref="S3.SS2.p2.12.m12.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.12.m12.1b"><ci id="S3.SS2.p2.12.m12.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.12.m12.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.12.m12.1d">italic_r</annotation></semantics></math> controls the capacity of low-rank approximation.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.7">To train the LLM on a user profile <math alttext="P_{u}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><msub id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">P</mi><mi id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ğ‘ƒ</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">P_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_P start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math>, for each document <math alttext="d_{i}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">d</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">ğ‘‘</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> in <math alttext="P_{u}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><msub id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">P</mi><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">ğ‘ƒ</ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">P_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_P start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math>, we convert it into an input-output pair <math alttext="(x_{i},y_{i})=\textsc{convert}(d_{i})" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.3"><semantics id="S3.SS2.p3.4.m4.3a"><mrow id="S3.SS2.p3.4.m4.3.3" xref="S3.SS2.p3.4.m4.3.3.cmml"><mrow id="S3.SS2.p3.4.m4.2.2.2.2" xref="S3.SS2.p3.4.m4.2.2.2.3.cmml"><mo id="S3.SS2.p3.4.m4.2.2.2.2.3" stretchy="false" xref="S3.SS2.p3.4.m4.2.2.2.3.cmml">(</mo><msub id="S3.SS2.p3.4.m4.1.1.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.1.1.1.2" xref="S3.SS2.p3.4.m4.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS2.p3.4.m4.1.1.1.1.1.3" xref="S3.SS2.p3.4.m4.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p3.4.m4.2.2.2.2.4" xref="S3.SS2.p3.4.m4.2.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.4.m4.2.2.2.2.2" xref="S3.SS2.p3.4.m4.2.2.2.2.2.cmml"><mi id="S3.SS2.p3.4.m4.2.2.2.2.2.2" xref="S3.SS2.p3.4.m4.2.2.2.2.2.2.cmml">y</mi><mi id="S3.SS2.p3.4.m4.2.2.2.2.2.3" xref="S3.SS2.p3.4.m4.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS2.p3.4.m4.2.2.2.2.5" stretchy="false" xref="S3.SS2.p3.4.m4.2.2.2.3.cmml">)</mo></mrow><mo id="S3.SS2.p3.4.m4.3.3.4" xref="S3.SS2.p3.4.m4.3.3.4.cmml">=</mo><mrow id="S3.SS2.p3.4.m4.3.3.3" xref="S3.SS2.p3.4.m4.3.3.3.cmml"><mtext class="ltx_font_smallcaps" id="S3.SS2.p3.4.m4.3.3.3.3" xref="S3.SS2.p3.4.m4.3.3.3.3a.cmml">convert</mtext><mo id="S3.SS2.p3.4.m4.3.3.3.2" xref="S3.SS2.p3.4.m4.3.3.3.2.cmml">â¢</mo><mrow id="S3.SS2.p3.4.m4.3.3.3.1.1" xref="S3.SS2.p3.4.m4.3.3.3.1.1.1.cmml"><mo id="S3.SS2.p3.4.m4.3.3.3.1.1.2" stretchy="false" xref="S3.SS2.p3.4.m4.3.3.3.1.1.1.cmml">(</mo><msub id="S3.SS2.p3.4.m4.3.3.3.1.1.1" xref="S3.SS2.p3.4.m4.3.3.3.1.1.1.cmml"><mi id="S3.SS2.p3.4.m4.3.3.3.1.1.1.2" xref="S3.SS2.p3.4.m4.3.3.3.1.1.1.2.cmml">d</mi><mi id="S3.SS2.p3.4.m4.3.3.3.1.1.1.3" xref="S3.SS2.p3.4.m4.3.3.3.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p3.4.m4.3.3.3.1.1.3" stretchy="false" xref="S3.SS2.p3.4.m4.3.3.3.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.3b"><apply id="S3.SS2.p3.4.m4.3.3.cmml" xref="S3.SS2.p3.4.m4.3.3"><eq id="S3.SS2.p3.4.m4.3.3.4.cmml" xref="S3.SS2.p3.4.m4.3.3.4"></eq><interval closure="open" id="S3.SS2.p3.4.m4.2.2.2.3.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2"><apply id="S3.SS2.p3.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS2.p3.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.p3.4.m4.2.2.2.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.4.m4.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2.2.2">ğ‘¦</ci><ci id="S3.SS2.p3.4.m4.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.4.m4.2.2.2.2.2.3">ğ‘–</ci></apply></interval><apply id="S3.SS2.p3.4.m4.3.3.3.cmml" xref="S3.SS2.p3.4.m4.3.3.3"><times id="S3.SS2.p3.4.m4.3.3.3.2.cmml" xref="S3.SS2.p3.4.m4.3.3.3.2"></times><ci id="S3.SS2.p3.4.m4.3.3.3.3a.cmml" xref="S3.SS2.p3.4.m4.3.3.3.3"><mtext class="ltx_font_smallcaps" id="S3.SS2.p3.4.m4.3.3.3.3.cmml" xref="S3.SS2.p3.4.m4.3.3.3.3">convert</mtext></ci><apply id="S3.SS2.p3.4.m4.3.3.3.1.1.1.cmml" xref="S3.SS2.p3.4.m4.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.3.3.3.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.3.3.3.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.3.3.3.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.3.3.3.1.1.1.2">ğ‘‘</ci><ci id="S3.SS2.p3.4.m4.3.3.3.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.3.3.3.1.1.1.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.3c">(x_{i},y_{i})=\textsc{convert}(d_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.3d">( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = convert ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, and then train the model with the seq2seq cross-entropy loss <cite class="ltx_cite ltx_citemacro_cite">Sutskever etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib43" title="">2014</a>)</cite> to generate <math alttext="y_{i}" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><msub id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml">y</mi><mi id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2">ğ‘¦</ci><ci id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> in its output given <math alttext="x_{i}" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><msub id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">x</mi><mi id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">ğ‘¥</ci><ci id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> as the input. There are different ways to implement <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S3.SS2.p3.7.1">convert</span> function. If the user profile consists of input-output pairs, they can be directly used for training. Alternatively, when the profile does not consist of explicit input-output pairs, these pairs can be automatically generated from each document from the profile. Whenever the profile contains input-output pairs for a user, we use those directly. Otherwise, we define text completion as the training task. The function used for different tasks is summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1.T4" title="Table 4 â€£ PEFT Configuration. â€£ Appendix A Experiments Setup â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a> in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A3" title="Appendix C Implementation of CONVERT function for PEFT Personalization â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>PEFT-RAG for Personalizing LLMs</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.3">This approach integrates both PEFT and RAG to personalize an LLM. First, we train the LLM <math alttext="M" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_M</annotation></semantics></math> on a user profile <math alttext="P_{u}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">P</mi><mi id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">ğ‘ƒ</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">P_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> using the method described in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S3.SS2" title="3.2 PEFT for Personalizing LLMs â€£ 3 LLM Personalization Approaches â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">3.2</span></a>, resulting in the personalized model <math alttext="M_{u}" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1"><semantics id="S3.SS3.p1.3.m3.1a"><msub id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">M</mi><mi id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">ğ‘€</ci><ci id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">M_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.1d">italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math>. Next, we apply the RAG personalization approach outlined in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S3.SS1" title="3.1 RAG for Personalizing LLMs â€£ 3 LLM Personalization Approaches â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">3.1</span></a>, denoted as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bar{y}=M_{u}(\phi_{p}(x,R(\phi_{q}(x),k))" class="ltx_math_unparsed" display="block" id="S3.E2.m1.3"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3b"><mover accent="true" id="S3.E2.m1.3.4"><mi id="S3.E2.m1.3.4.2">y</mi><mo id="S3.E2.m1.3.4.1">Â¯</mo></mover><mo id="S3.E2.m1.3.5">=</mo><msub id="S3.E2.m1.3.6"><mi id="S3.E2.m1.3.6.2">M</mi><mi id="S3.E2.m1.3.6.3">u</mi></msub><mrow id="S3.E2.m1.3.7"><mo id="S3.E2.m1.3.7.1" stretchy="false">(</mo><msub id="S3.E2.m1.3.7.2"><mi id="S3.E2.m1.3.7.2.2">Ï•</mi><mi id="S3.E2.m1.3.7.2.3">p</mi></msub><mrow id="S3.E2.m1.3.7.3"><mo id="S3.E2.m1.3.7.3.1" stretchy="false">(</mo><mi id="S3.E2.m1.3.3">x</mi><mo id="S3.E2.m1.3.7.3.2">,</mo><mi id="S3.E2.m1.3.7.3.3">R</mi><mrow id="S3.E2.m1.3.7.3.4"><mo id="S3.E2.m1.3.7.3.4.1" stretchy="false">(</mo><msub id="S3.E2.m1.3.7.3.4.2"><mi id="S3.E2.m1.3.7.3.4.2.2">Ï•</mi><mi id="S3.E2.m1.3.7.3.4.2.3">q</mi></msub><mrow id="S3.E2.m1.3.7.3.4.3"><mo id="S3.E2.m1.3.7.3.4.3.1" stretchy="false">(</mo><mi id="S3.E2.m1.1.1">x</mi><mo id="S3.E2.m1.3.7.3.4.3.2" stretchy="false">)</mo></mrow><mo id="S3.E2.m1.3.7.3.4.4">,</mo><mi id="S3.E2.m1.2.2">k</mi><mo id="S3.E2.m1.3.7.3.4.5" stretchy="false">)</mo></mrow><mo id="S3.E2.m1.3.7.3.5" stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex" id="S3.E2.m1.3c">\bar{y}=M_{u}(\phi_{p}(x,R(\phi_{q}(x),k))</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.3d">overÂ¯ start_ARG italic_y end_ARG = italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( italic_Ï• start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_x , italic_R ( italic_Ï• start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_x ) , italic_k ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.8">where <math alttext="M_{u}" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m1.1"><semantics id="S3.SS3.p1.4.m1.1a"><msub id="S3.SS3.p1.4.m1.1.1" xref="S3.SS3.p1.4.m1.1.1.cmml"><mi id="S3.SS3.p1.4.m1.1.1.2" xref="S3.SS3.p1.4.m1.1.1.2.cmml">M</mi><mi id="S3.SS3.p1.4.m1.1.1.3" xref="S3.SS3.p1.4.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m1.1b"><apply id="S3.SS3.p1.4.m1.1.1.cmml" xref="S3.SS3.p1.4.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m1.1.1.1.cmml" xref="S3.SS3.p1.4.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.4.m1.1.1.2.cmml" xref="S3.SS3.p1.4.m1.1.1.2">ğ‘€</ci><ci id="S3.SS3.p1.4.m1.1.1.3.cmml" xref="S3.SS3.p1.4.m1.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m1.1c">M_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m1.1d">italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> is a personalized model with PEFT, <math alttext="R" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m2.1"><semantics id="S3.SS3.p1.5.m2.1a"><mi id="S3.SS3.p1.5.m2.1.1" xref="S3.SS3.p1.5.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m2.1b"><ci id="S3.SS3.p1.5.m2.1.1.cmml" xref="S3.SS3.p1.5.m2.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m2.1c">R</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.5.m2.1d">italic_R</annotation></semantics></math> is a retriever, <math alttext="\phi_{q}" class="ltx_Math" display="inline" id="S3.SS3.p1.6.m3.1"><semantics id="S3.SS3.p1.6.m3.1a"><msub id="S3.SS3.p1.6.m3.1.1" xref="S3.SS3.p1.6.m3.1.1.cmml"><mi id="S3.SS3.p1.6.m3.1.1.2" xref="S3.SS3.p1.6.m3.1.1.2.cmml">Ï•</mi><mi id="S3.SS3.p1.6.m3.1.1.3" xref="S3.SS3.p1.6.m3.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m3.1b"><apply id="S3.SS3.p1.6.m3.1.1.cmml" xref="S3.SS3.p1.6.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m3.1.1.1.cmml" xref="S3.SS3.p1.6.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.6.m3.1.1.2.cmml" xref="S3.SS3.p1.6.m3.1.1.2">italic-Ï•</ci><ci id="S3.SS3.p1.6.m3.1.1.3.cmml" xref="S3.SS3.p1.6.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m3.1c">\phi_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.6.m3.1d">italic_Ï• start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\phi_{p}" class="ltx_Math" display="inline" id="S3.SS3.p1.7.m4.1"><semantics id="S3.SS3.p1.7.m4.1a"><msub id="S3.SS3.p1.7.m4.1.1" xref="S3.SS3.p1.7.m4.1.1.cmml"><mi id="S3.SS3.p1.7.m4.1.1.2" xref="S3.SS3.p1.7.m4.1.1.2.cmml">Ï•</mi><mi id="S3.SS3.p1.7.m4.1.1.3" xref="S3.SS3.p1.7.m4.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m4.1b"><apply id="S3.SS3.p1.7.m4.1.1.cmml" xref="S3.SS3.p1.7.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m4.1.1.1.cmml" xref="S3.SS3.p1.7.m4.1.1">subscript</csymbol><ci id="S3.SS3.p1.7.m4.1.1.2.cmml" xref="S3.SS3.p1.7.m4.1.1.2">italic-Ï•</ci><ci id="S3.SS3.p1.7.m4.1.1.3.cmml" xref="S3.SS3.p1.7.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m4.1c">\phi_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.7.m4.1d">italic_Ï• start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> are the query and prompt generation functions, and <math alttext="k" class="ltx_Math" display="inline" id="S3.SS3.p1.8.m5.1"><semantics id="S3.SS3.p1.8.m5.1a"><mi id="S3.SS3.p1.8.m5.1.1" xref="S3.SS3.p1.8.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m5.1b"><ci id="S3.SS3.p1.8.m5.1.1.cmml" xref="S3.SS3.p1.8.m5.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.8.m5.1d">italic_k</annotation></semantics></math> is the number of retrieved documents. The key difference from Equation <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S3.E1" title="In 3.1 RAG for Personalizing LLMs â€£ 3 LLM Personalization Approaches â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a> is that this first trains the LLM on the user-specific profile to learn preferences before applying RAG.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setup.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">Following <cite class="ltx_cite ltx_citemacro_citet">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>, FlanT5-XXL <cite class="ltx_cite ltx_citemacro_cite">Chung etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib5" title="">2024</a>)</cite>, with 11 billion parameters, is used. The experiments are conducted on the LaMP benchmark <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>, consisting of seven personalized tasks: three text classificationâ€”binary, categorical, and ordinalâ€”and four text generation tasks. For binary classification, we use accuracy; for categorical, both accuracy and F1 scores; and for ordinal, MAE and RMSE. For text generation, ROUGE-1 and ROUGE-L <cite class="ltx_cite ltx_citemacro_cite">Lin (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib29" title="">2004</a>)</cite> are used. The detailed setup is in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1" title="Appendix A Experiments Setup â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">How do PEFT- and RAG-based approaches perform for LLM personalization?</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.2">The results of PEFT- and RAG-personalization and the non-personalized baseline are reported in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.T1" title="Table 1 â€£ How do PEFT- and RAG-based approaches perform for LLM personalization? â€£ 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>. The results suggest that using PEFT improves performance compared to non-personalized LLMs in 5 out of 7 datasets. Similarly, the RAG approach leads to performance improvements across all datasets. Comparing PEFT with RAG, the results indicate that using RAG is more effective than using PEFT, as shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.T1" title="Table 1 â€£ How do PEFT- and RAG-based approaches perform for LLM personalization? â€£ 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>. Specifically, PEFT achieves a 1.07% improvement over non-personalized LLMs, whereas the RAG approach achieves an average improvement of 14.92%. This clearly indicates that retrieval-augmented generation is a superior approach for personalizing LLMs. Note that the different retrieval models in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.T1" title="Table 1 â€£ How do PEFT- and RAG-based approaches perform for LLM personalization? â€£ 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a> achieve varying levels of improvement. However, RSPG <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib37" title="">2024a</a>)</cite>, which dynamically selects the best retrieval model for each instance, outperforms all other retrieval models in terms of overall performance. Additionally, the rank parameter <math alttext="r" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px2.p1.1.m1.1a"><mi id="S4.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.1.m1.1b"><ci id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.1.m1.1c">r</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.1.m1.1d">italic_r</annotation></semantics></math> also influences performance. Specifically, on LaMP-1, LaMP-3, and LaMP-6, increasing <math alttext="r" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="S4.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.2.m2.1c">r</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.2.m2.1d">italic_r</annotation></semantics></math> leads to noticeable improvements in performance, while it does not significantly affect other tasks.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.21" style="width:433.6pt;height:154.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-169.1pt,60.1pt) scale(0.56188,0.56188) ;">
<p class="ltx_p" id="S4.T1.21.21"><span class="ltx_text" id="S4.T1.21.21.21">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T1.21.21.21.21" style="width:771.7pt;height:274.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S4.T1.21.21.21.21.21"><span class="ltx_text" id="S4.T1.21.21.21.21.21.21">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.21.21.21.21.21.21.21">
<span class="ltx_tbody">
<span class="ltx_tr" id="S4.T1.21.21.21.21.21.21.21.22.1">
<span class="ltx_td ltx_align_left ltx_border_r ltx_rowspan ltx_rowspan_2" id="S4.T1.21.21.21.21.21.21.21.22.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.21.21.21.21.21.21.21.22.1.1.1">Dataset</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_rowspan ltx_rowspan_2" id="S4.T1.21.21.21.21.21.21.21.22.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.21.21.21.21.21.21.21.22.1.2.1">Metric</span></span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.21.21.21.21.21.21.21.22.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.21.21.21.21.21.21.21.22.1.3.1">No</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_colspan ltx_colspan_4" id="S4.T1.21.21.21.21.21.21.21.22.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.21.21.21.21.21.21.21.22.1.4.1">PEFT Personalization</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_colspan ltx_colspan_4" id="S4.T1.21.21.21.21.21.21.21.22.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.21.21.21.21.21.21.21.22.1.5.1">RAG Personalization</span></span>
<span class="ltx_td ltx_align_center ltx_colspan ltx_colspan_4" id="S4.T1.21.21.21.21.21.21.21.22.1.6"><span class="ltx_text ltx_font_bold" id="S4.T1.21.21.21.21.21.21.21.22.1.6.1">PEFT-RAG Personalization</span></span></span>
<span class="ltx_tr" id="S4.T1.8.8.8.8.8.8.8.8">
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.8.8.8.8.8.8.8.8.9"><span class="ltx_text ltx_font_bold" id="S4.T1.8.8.8.8.8.8.8.8.9.1">Personalization</span></span>
<span class="ltx_td ltx_align_center" id="S4.T1.1.1.1.1.1.1.1.1.1"><math alttext="r=8" class="ltx_Math" display="inline" id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1a"><mrow id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">r</mi><mo id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.1" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1"><eq id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.1"></eq><ci id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.2">ğ‘Ÿ</ci><cn id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1c">r=8</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1d">italic_r = 8</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center" id="S4.T1.2.2.2.2.2.2.2.2.2"><math alttext="r=16" class="ltx_Math" display="inline" id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1"><semantics id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1a"><mrow id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1" xref="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.cmml"><mi id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.2" xref="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.2.cmml">r</mi><mo id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.1" xref="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.1.cmml">=</mo><mn id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.3" xref="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1b"><apply id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1"><eq id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.1.cmml" xref="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.1"></eq><ci id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.2.cmml" xref="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.2">ğ‘Ÿ</ci><cn id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.3.cmml" type="integer" xref="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1c">r=16</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1d">italic_r = 16</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center" id="S4.T1.3.3.3.3.3.3.3.3.3"><math alttext="r=32" class="ltx_Math" display="inline" id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1"><semantics id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1a"><mrow id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1" xref="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.cmml"><mi id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.2" xref="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.2.cmml">r</mi><mo id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.1" xref="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.1.cmml">=</mo><mn id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.3" xref="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1b"><apply id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1"><eq id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.1.cmml" xref="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.1"></eq><ci id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.2.cmml" xref="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.2">ğ‘Ÿ</ci><cn id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.3.cmml" type="integer" xref="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1c">r=32</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1d">italic_r = 32</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.4.4.4.4.4.4.4.4.4"><math alttext="r=64" class="ltx_Math" display="inline" id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1"><semantics id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1a"><mrow id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1" xref="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.cmml"><mi id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.2" xref="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.2.cmml">r</mi><mo id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.1" xref="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.1.cmml">=</mo><mn id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.3" xref="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1b"><apply id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1"><eq id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.1.cmml" xref="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.1"></eq><ci id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.2.cmml" xref="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.2">ğ‘Ÿ</ci><cn id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.3.cmml" type="integer" xref="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1c">r=64</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1d">italic_r = 64</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center" id="S4.T1.8.8.8.8.8.8.8.8.10">BM25</span>
<span class="ltx_td ltx_align_center" id="S4.T1.8.8.8.8.8.8.8.8.11">Recency</span>
<span class="ltx_td ltx_align_center" id="S4.T1.8.8.8.8.8.8.8.8.12">Contriever</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.8.8.8.8.8.8.8.8.13">RSPG</span>
<span class="ltx_td ltx_align_center" id="S4.T1.5.5.5.5.5.5.5.5.5"><math alttext="r=8" class="ltx_Math" display="inline" id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1"><semantics id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1a"><mrow id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1" xref="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.cmml"><mi id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.2" xref="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.2.cmml">r</mi><mo id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.1" xref="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.1.cmml">=</mo><mn id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.3" xref="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1b"><apply id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1"><eq id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.1.cmml" xref="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.1"></eq><ci id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.2.cmml" xref="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.2">ğ‘Ÿ</ci><cn id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.3.cmml" type="integer" xref="S4.T1.5.5.5.5.5.5.5.5.5.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1c">r=8</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.5.5.5.5.5.5.5.5.m1.1d">italic_r = 8</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center" id="S4.T1.6.6.6.6.6.6.6.6.6"><math alttext="r=16" class="ltx_Math" display="inline" id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1"><semantics id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1a"><mrow id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1" xref="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.cmml"><mi id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.2" xref="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.2.cmml">r</mi><mo id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.1" xref="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.1.cmml">=</mo><mn id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.3" xref="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1b"><apply id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.cmml" xref="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1"><eq id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.1.cmml" xref="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.1"></eq><ci id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.2.cmml" xref="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.2">ğ‘Ÿ</ci><cn id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.3.cmml" type="integer" xref="S4.T1.6.6.6.6.6.6.6.6.6.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1c">r=16</annotation><annotation encoding="application/x-llamapun" id="S4.T1.6.6.6.6.6.6.6.6.6.m1.1d">italic_r = 16</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center" id="S4.T1.7.7.7.7.7.7.7.7.7"><math alttext="r=32" class="ltx_Math" display="inline" id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1"><semantics id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1a"><mrow id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1" xref="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.cmml"><mi id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.2" xref="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.2.cmml">r</mi><mo id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.1" xref="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.1.cmml">=</mo><mn id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.3" xref="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1b"><apply id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.cmml" xref="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1"><eq id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.1.cmml" xref="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.1"></eq><ci id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.2.cmml" xref="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.2">ğ‘Ÿ</ci><cn id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.3.cmml" type="integer" xref="S4.T1.7.7.7.7.7.7.7.7.7.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1c">r=32</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.7.7.7.7.7.7.7.7.m1.1d">italic_r = 32</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center" id="S4.T1.8.8.8.8.8.8.8.8.8"><math alttext="r=64" class="ltx_Math" display="inline" id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1"><semantics id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1a"><mrow id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1" xref="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.cmml"><mi id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.2" xref="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.2.cmml">r</mi><mo id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.1" xref="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.1.cmml">=</mo><mn id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.3" xref="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1b"><apply id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.cmml" xref="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1"><eq id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.1.cmml" xref="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.1"></eq><ci id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.2.cmml" xref="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.2">ğ‘Ÿ</ci><cn id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.3.cmml" type="integer" xref="S4.T1.8.8.8.8.8.8.8.8.8.m1.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1c">r=64</annotation><annotation encoding="application/x-llamapun" id="S4.T1.8.8.8.8.8.8.8.8.8.m1.1d">italic_r = 64</annotation></semantics></math></span></span>
<span class="ltx_tr" id="S4.T1.9.9.9.9.9.9.9.9">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.2"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.2.1">
<span class="ltx_inline-block ltx_align_left" id="S4.T1.9.9.9.9.9.9.9.9.2.1.1">
<span class="ltx_p" id="S4.T1.9.9.9.9.9.9.9.9.2.1.1.1">LaMP-1: Personalized</span>
<span class="ltx_p" id="S4.T1.9.9.9.9.9.9.9.9.2.1.1.2">Citation Identification</span>
</span></span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.1"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.1.1">Accuracy <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.9.9.9.9.9.9.9.9.1.1.m1.1"><semantics id="S4.T1.9.9.9.9.9.9.9.9.1.1.m1.1a"><mo id="S4.T1.9.9.9.9.9.9.9.9.1.1.m1.1.1" stretchy="false" xref="S4.T1.9.9.9.9.9.9.9.9.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.9.9.9.9.9.9.1.1.m1.1b"><ci id="S4.T1.9.9.9.9.9.9.9.9.1.1.m1.1.1.cmml" xref="S4.T1.9.9.9.9.9.9.9.9.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.9.9.9.9.9.9.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.9.9.9.9.9.9.9.9.1.1.m1.1d">â†‘</annotation></semantics></math></span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.3"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.3.1">0.502</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.4"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.4.1">0.502</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.5"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.5.1">0.502</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.6"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.6.1">0.504</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.7"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.7.1">0.506</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.8"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.8.1">0.626</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.9"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.9.1">0.622</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.10"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.10.1">0.636</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.11"><span class="ltx_text ltx_font_bold" id="S4.T1.9.9.9.9.9.9.9.9.11.1">0.672</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.12"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.12.1">0.670</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.13"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.13.1">0.668</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.14"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.14.1">0.671</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.9.9.9.9.9.9.9.9.15"><span class="ltx_text" id="S4.T1.9.9.9.9.9.9.9.9.15.1">0.671</span></span></span>
<span class="ltx_tr" id="S4.T1.10.10.10.10.10.10.10.10">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="S4.T1.10.10.10.10.10.10.10.10.2"><span class="ltx_text" id="S4.T1.10.10.10.10.10.10.10.10.2.1">
<span class="ltx_inline-block ltx_align_left" id="S4.T1.10.10.10.10.10.10.10.10.2.1.1">
<span class="ltx_p" id="S4.T1.10.10.10.10.10.10.10.10.2.1.1.1">LaMP-2: Personalized</span>
<span class="ltx_p" id="S4.T1.10.10.10.10.10.10.10.10.2.1.1.2">Movie Tagging</span>
</span></span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.1">Accuracy <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1"><semantics id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1a"><mo id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1.1" stretchy="false" xref="S4.T1.10.10.10.10.10.10.10.10.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1b"><ci id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1.1.cmml" xref="S4.T1.10.10.10.10.10.10.10.10.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.10.10.10.10.10.10.10.10.1.m1.1d">â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.3">0.359</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.4">0.360</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.5">0.360</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.6">0.360</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.7">0.359</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.8">0.387</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.9">0.377</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.10">0.396</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.11">0.430</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.12">0.430</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.13"><span class="ltx_text ltx_font_bold" id="S4.T1.10.10.10.10.10.10.10.10.13.1">0.431</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.14">0.430</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.10.10.10.10.10.10.10.10.15">0.430</span></span>
<span class="ltx_tr" id="S4.T1.11.11.11.11.11.11.11.11">
<span class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.11.11.11.11.11.11.11.11.1">F1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1"><semantics id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1a"><mo id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1.1" stretchy="false" xref="S4.T1.11.11.11.11.11.11.11.11.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1b"><ci id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1.1.cmml" xref="S4.T1.11.11.11.11.11.11.11.11.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.11.11.11.11.11.11.11.11.1.m1.1d">â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.11.11.11.11.11.11.11.11.2">0.276</span>
<span class="ltx_td ltx_align_center" id="S4.T1.11.11.11.11.11.11.11.11.3">0.278</span>
<span class="ltx_td ltx_align_center" id="S4.T1.11.11.11.11.11.11.11.11.4">0.278</span>
<span class="ltx_td ltx_align_center" id="S4.T1.11.11.11.11.11.11.11.11.5">0.278</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.11.11.11.11.11.11.11.11.6">0.277</span>
<span class="ltx_td ltx_align_center" id="S4.T1.11.11.11.11.11.11.11.11.7">0.306</span>
<span class="ltx_td ltx_align_center" id="S4.T1.11.11.11.11.11.11.11.11.8">0.295</span>
<span class="ltx_td ltx_align_center" id="S4.T1.11.11.11.11.11.11.11.11.9">0.304</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.11.11.11.11.11.11.11.11.10">0.339</span>
<span class="ltx_td ltx_align_center" id="S4.T1.11.11.11.11.11.11.11.11.11">0.341</span>
<span class="ltx_td ltx_align_center" id="S4.T1.11.11.11.11.11.11.11.11.12"><span class="ltx_text ltx_font_bold" id="S4.T1.11.11.11.11.11.11.11.11.12.1">0.342</span></span>
<span class="ltx_td ltx_align_center" id="S4.T1.11.11.11.11.11.11.11.11.13">0.341</span>
<span class="ltx_td ltx_align_center" id="S4.T1.11.11.11.11.11.11.11.11.14">0.341</span></span>
<span class="ltx_tr" id="S4.T1.12.12.12.12.12.12.12.12">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="S4.T1.12.12.12.12.12.12.12.12.2"><span class="ltx_text" id="S4.T1.12.12.12.12.12.12.12.12.2.1">
<span class="ltx_inline-block ltx_align_left" id="S4.T1.12.12.12.12.12.12.12.12.2.1.1">
<span class="ltx_p" id="S4.T1.12.12.12.12.12.12.12.12.2.1.1.1">LaMP-3: Personalized</span>
<span class="ltx_p" id="S4.T1.12.12.12.12.12.12.12.12.2.1.1.2">Product Rating</span>
</span></span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.1">MAE <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1"><semantics id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1a"><mo id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1.1" stretchy="false" xref="S4.T1.12.12.12.12.12.12.12.12.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1b"><ci id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1.1.cmml" xref="S4.T1.12.12.12.12.12.12.12.12.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.12.12.12.12.12.12.12.12.1.m1.1d">â†“</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.3">0.308</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.4">0.308</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.5">0.307</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.6">0.306</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.7">0.301</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.8">0.298</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.9">0.296</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.10">0.299</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.11">0.264</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.12">0.264</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.13">0.265</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.14">0.264</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.12.12.12.12.12.12.12.12.15"><span class="ltx_text ltx_font_bold" id="S4.T1.12.12.12.12.12.12.12.12.15.1">0.259</span></span></span>
<span class="ltx_tr" id="S4.T1.13.13.13.13.13.13.13.13">
<span class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.13.13.13.13.13.13.13.13.1">RMSE <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1"><semantics id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1a"><mo id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1.1" stretchy="false" xref="S4.T1.13.13.13.13.13.13.13.13.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1b"><ci id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1.1.cmml" xref="S4.T1.13.13.13.13.13.13.13.13.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.13.13.13.13.13.13.13.13.1.m1.1d">â†“</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.13.13.13.13.13.13.13.13.2">0.611</span>
<span class="ltx_td ltx_align_center" id="S4.T1.13.13.13.13.13.13.13.13.3">0.607</span>
<span class="ltx_td ltx_align_center" id="S4.T1.13.13.13.13.13.13.13.13.4">0.607</span>
<span class="ltx_td ltx_align_center" id="S4.T1.13.13.13.13.13.13.13.13.5">0.602</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.13.13.13.13.13.13.13.13.6">0.600</span>
<span class="ltx_td ltx_align_center" id="S4.T1.13.13.13.13.13.13.13.13.7">0.611</span>
<span class="ltx_td ltx_align_center" id="S4.T1.13.13.13.13.13.13.13.13.8">0.605</span>
<span class="ltx_td ltx_align_center" id="S4.T1.13.13.13.13.13.13.13.13.9">0.616</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.13.13.13.13.13.13.13.13.10">0.568</span>
<span class="ltx_td ltx_align_center" id="S4.T1.13.13.13.13.13.13.13.13.11">0.568</span>
<span class="ltx_td ltx_align_center" id="S4.T1.13.13.13.13.13.13.13.13.12">0.570</span>
<span class="ltx_td ltx_align_center" id="S4.T1.13.13.13.13.13.13.13.13.13">0.564</span>
<span class="ltx_td ltx_align_center" id="S4.T1.13.13.13.13.13.13.13.13.14"><span class="ltx_text ltx_font_bold" id="S4.T1.13.13.13.13.13.13.13.13.14.1">0.562</span></span></span>
<span class="ltx_tr" id="S4.T1.14.14.14.14.14.14.14.14">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="S4.T1.14.14.14.14.14.14.14.14.2"><span class="ltx_text" id="S4.T1.14.14.14.14.14.14.14.14.2.1">
<span class="ltx_inline-block ltx_align_left" id="S4.T1.14.14.14.14.14.14.14.14.2.1.1">
<span class="ltx_p" id="S4.T1.14.14.14.14.14.14.14.14.2.1.1.1">LaMP-4: Personalized</span>
<span class="ltx_p" id="S4.T1.14.14.14.14.14.14.14.14.2.1.1.2">News Headline Generation</span>
</span></span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.1">ROUGE-1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1"><semantics id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1a"><mo id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1.1" stretchy="false" xref="S4.T1.14.14.14.14.14.14.14.14.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1b"><ci id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1.1.cmml" xref="S4.T1.14.14.14.14.14.14.14.14.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.14.14.14.14.14.14.14.14.1.m1.1d">â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.3">0.176</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.4">0.178</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.5">0.177</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.6">0.178</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.7">0.178</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.8">0.186</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.9">0.189</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.10">0.183</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.11">0.203</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.12">0.203</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.13"><span class="ltx_text ltx_font_bold" id="S4.T1.14.14.14.14.14.14.14.14.13.1">0.204</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.14"><span class="ltx_text ltx_font_bold" id="S4.T1.14.14.14.14.14.14.14.14.14.1">0.204</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.14.14.14.14.14.14.14.14.15">0.203</span></span>
<span class="ltx_tr" id="S4.T1.15.15.15.15.15.15.15.15">
<span class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.15.15.15.15.15.15.15.15.1">ROUGE-L <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1"><semantics id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1a"><mo id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1.1" stretchy="false" xref="S4.T1.15.15.15.15.15.15.15.15.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1b"><ci id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1.1.cmml" xref="S4.T1.15.15.15.15.15.15.15.15.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.15.15.15.15.15.15.15.15.1.m1.1d">â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.15.15.15.15.15.15.15.15.2">0.160</span>
<span class="ltx_td ltx_align_center" id="S4.T1.15.15.15.15.15.15.15.15.3">0.162</span>
<span class="ltx_td ltx_align_center" id="S4.T1.15.15.15.15.15.15.15.15.4">0.162</span>
<span class="ltx_td ltx_align_center" id="S4.T1.15.15.15.15.15.15.15.15.5">0.163</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.15.15.15.15.15.15.15.15.6">0.163</span>
<span class="ltx_td ltx_align_center" id="S4.T1.15.15.15.15.15.15.15.15.7">0.171</span>
<span class="ltx_td ltx_align_center" id="S4.T1.15.15.15.15.15.15.15.15.8">0.173</span>
<span class="ltx_td ltx_align_center" id="S4.T1.15.15.15.15.15.15.15.15.9">0.169</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.15.15.15.15.15.15.15.15.10">0.186</span>
<span class="ltx_td ltx_align_center" id="S4.T1.15.15.15.15.15.15.15.15.11">0.186</span>
<span class="ltx_td ltx_align_center" id="S4.T1.15.15.15.15.15.15.15.15.12">0.186</span>
<span class="ltx_td ltx_align_center" id="S4.T1.15.15.15.15.15.15.15.15.13"><span class="ltx_text ltx_font_bold" id="S4.T1.15.15.15.15.15.15.15.15.13.1">0.187</span></span>
<span class="ltx_td ltx_align_center" id="S4.T1.15.15.15.15.15.15.15.15.14">0.186</span></span>
<span class="ltx_tr" id="S4.T1.16.16.16.16.16.16.16.16">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="S4.T1.16.16.16.16.16.16.16.16.2"><span class="ltx_text" id="S4.T1.16.16.16.16.16.16.16.16.2.1">
<span class="ltx_inline-block ltx_align_left" id="S4.T1.16.16.16.16.16.16.16.16.2.1.1">
<span class="ltx_p" id="S4.T1.16.16.16.16.16.16.16.16.2.1.1.1">LaMP-5: Personalized</span>
<span class="ltx_p" id="S4.T1.16.16.16.16.16.16.16.16.2.1.1.2">Scholarly Title Generation</span>
</span></span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.1">ROUGE-1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.16.16.16.16.16.16.16.16.1.m1.1"><semantics id="S4.T1.16.16.16.16.16.16.16.16.1.m1.1a"><mo id="S4.T1.16.16.16.16.16.16.16.16.1.m1.1.1" stretchy="false" xref="S4.T1.16.16.16.16.16.16.16.16.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.16.16.16.16.16.16.16.16.1.m1.1b"><ci id="S4.T1.16.16.16.16.16.16.16.16.1.m1.1.1.cmml" xref="S4.T1.16.16.16.16.16.16.16.16.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.16.16.16.16.16.16.16.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.16.16.16.16.16.16.16.16.1.m1.1d">â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.3">0.478</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.4">0.478</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.5">0.478</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.6">0.477</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.7">0.478</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.8">0.477</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.9">0.475</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.10"><span class="ltx_text ltx_font_bold" id="S4.T1.16.16.16.16.16.16.16.16.10.1">0.483</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.11">0.480</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.12">0.481</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.13">0.480</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.14">0.480</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.16.16.16.16.16.16.16.15">0.479</span></span>
<span class="ltx_tr" id="S4.T1.17.17.17.17.17.17.17.17">
<span class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.17.17.17.17.17.17.17.17.1">ROUGE-L <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.17.17.17.17.17.17.17.17.1.m1.1"><semantics id="S4.T1.17.17.17.17.17.17.17.17.1.m1.1a"><mo id="S4.T1.17.17.17.17.17.17.17.17.1.m1.1.1" stretchy="false" xref="S4.T1.17.17.17.17.17.17.17.17.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.17.17.17.17.17.17.17.17.1.m1.1b"><ci id="S4.T1.17.17.17.17.17.17.17.17.1.m1.1.1.cmml" xref="S4.T1.17.17.17.17.17.17.17.17.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.17.17.17.17.17.17.17.17.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.17.17.17.17.17.17.17.17.1.m1.1d">â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.17.17.17.17.17.17.17.17.2">0.428</span>
<span class="ltx_td ltx_align_center" id="S4.T1.17.17.17.17.17.17.17.17.3">0.429</span>
<span class="ltx_td ltx_align_center" id="S4.T1.17.17.17.17.17.17.17.17.4">0.429</span>
<span class="ltx_td ltx_align_center" id="S4.T1.17.17.17.17.17.17.17.17.5">0.428</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.17.17.17.17.17.17.17.17.6">0.428</span>
<span class="ltx_td ltx_align_center" id="S4.T1.17.17.17.17.17.17.17.17.7">0.427</span>
<span class="ltx_td ltx_align_center" id="S4.T1.17.17.17.17.17.17.17.17.8">0.426</span>
<span class="ltx_td ltx_align_center" id="S4.T1.17.17.17.17.17.17.17.17.9"><span class="ltx_text ltx_font_bold" id="S4.T1.17.17.17.17.17.17.17.17.9.1">0.433</span></span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.17.17.17.17.17.17.17.17.10">0.429</span>
<span class="ltx_td ltx_align_center" id="S4.T1.17.17.17.17.17.17.17.17.11">0.431</span>
<span class="ltx_td ltx_align_center" id="S4.T1.17.17.17.17.17.17.17.17.12">0.431</span>
<span class="ltx_td ltx_align_center" id="S4.T1.17.17.17.17.17.17.17.17.13">0.431</span>
<span class="ltx_td ltx_align_center" id="S4.T1.17.17.17.17.17.17.17.17.14">0.431</span></span>
<span class="ltx_tr" id="S4.T1.18.18.18.18.18.18.18.18">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="S4.T1.18.18.18.18.18.18.18.18.2"><span class="ltx_text" id="S4.T1.18.18.18.18.18.18.18.18.2.1">
<span class="ltx_inline-block ltx_align_left" id="S4.T1.18.18.18.18.18.18.18.18.2.1.1">
<span class="ltx_p" id="S4.T1.18.18.18.18.18.18.18.18.2.1.1.1">LaMP-6: Personalized</span>
<span class="ltx_p" id="S4.T1.18.18.18.18.18.18.18.18.2.1.1.2">Email Subject Generation</span>
</span></span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.1">ROUGE-1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.18.18.18.18.18.18.18.18.1.m1.1"><semantics id="S4.T1.18.18.18.18.18.18.18.18.1.m1.1a"><mo id="S4.T1.18.18.18.18.18.18.18.18.1.m1.1.1" stretchy="false" xref="S4.T1.18.18.18.18.18.18.18.18.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.18.18.18.18.18.18.18.18.1.m1.1b"><ci id="S4.T1.18.18.18.18.18.18.18.18.1.m1.1.1.cmml" xref="S4.T1.18.18.18.18.18.18.18.18.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.18.18.18.18.18.18.18.18.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.18.18.18.18.18.18.18.18.1.m1.1d">â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.3">0.335</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.4">0.342</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.5">0.342</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.6">0.341</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.7">0.343</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.8">0.412</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.9">0.403</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.10">0.401</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.11">0.433</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.12">0.436</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.13">0.436</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.14">0.436</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.18.18.18.18.18.18.18.18.15"><span class="ltx_text ltx_font_bold" id="S4.T1.18.18.18.18.18.18.18.18.15.1">0.437</span></span></span>
<span class="ltx_tr" id="S4.T1.19.19.19.19.19.19.19.19">
<span class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.19.19.19.19.19.19.19.19.1">ROUGE-L <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.19.19.19.19.19.19.19.19.1.m1.1"><semantics id="S4.T1.19.19.19.19.19.19.19.19.1.m1.1a"><mo id="S4.T1.19.19.19.19.19.19.19.19.1.m1.1.1" stretchy="false" xref="S4.T1.19.19.19.19.19.19.19.19.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.19.19.19.19.19.19.19.19.1.m1.1b"><ci id="S4.T1.19.19.19.19.19.19.19.19.1.m1.1.1.cmml" xref="S4.T1.19.19.19.19.19.19.19.19.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.19.19.19.19.19.19.19.19.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.19.19.19.19.19.19.19.19.1.m1.1d">â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.19.19.19.19.19.19.19.19.2">0.319</span>
<span class="ltx_td ltx_align_center" id="S4.T1.19.19.19.19.19.19.19.19.3">0.325</span>
<span class="ltx_td ltx_align_center" id="S4.T1.19.19.19.19.19.19.19.19.4">0.326</span>
<span class="ltx_td ltx_align_center" id="S4.T1.19.19.19.19.19.19.19.19.5">0.325</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.19.19.19.19.19.19.19.19.6">0.326</span>
<span class="ltx_td ltx_align_center" id="S4.T1.19.19.19.19.19.19.19.19.7">0.398</span>
<span class="ltx_td ltx_align_center" id="S4.T1.19.19.19.19.19.19.19.19.8">0.389</span>
<span class="ltx_td ltx_align_center" id="S4.T1.19.19.19.19.19.19.19.19.9">0.386</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.19.19.19.19.19.19.19.19.10">0.418</span>
<span class="ltx_td ltx_align_center" id="S4.T1.19.19.19.19.19.19.19.19.11"><span class="ltx_text ltx_font_bold" id="S4.T1.19.19.19.19.19.19.19.19.11.1">0.422</span></span>
<span class="ltx_td ltx_align_center" id="S4.T1.19.19.19.19.19.19.19.19.12"><span class="ltx_text ltx_font_bold" id="S4.T1.19.19.19.19.19.19.19.19.12.1">0.422</span></span>
<span class="ltx_td ltx_align_center" id="S4.T1.19.19.19.19.19.19.19.19.13"><span class="ltx_text ltx_font_bold" id="S4.T1.19.19.19.19.19.19.19.19.13.1">0.422</span></span>
<span class="ltx_td ltx_align_center" id="S4.T1.19.19.19.19.19.19.19.19.14">0.421</span></span>
<span class="ltx_tr" id="S4.T1.20.20.20.20.20.20.20.20">
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="S4.T1.20.20.20.20.20.20.20.20.2"><span class="ltx_text" id="S4.T1.20.20.20.20.20.20.20.20.2.1">
<span class="ltx_inline-block ltx_align_left" id="S4.T1.20.20.20.20.20.20.20.20.2.1.1">
<span class="ltx_p" id="S4.T1.20.20.20.20.20.20.20.20.2.1.1.1">LaMP-7: Personalized</span>
<span class="ltx_p" id="S4.T1.20.20.20.20.20.20.20.20.2.1.1.2">Tweet Paraphrasing</span>
</span></span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.1">ROUGE-1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.20.20.20.20.20.20.20.20.1.m1.1"><semantics id="S4.T1.20.20.20.20.20.20.20.20.1.m1.1a"><mo id="S4.T1.20.20.20.20.20.20.20.20.1.m1.1.1" stretchy="false" xref="S4.T1.20.20.20.20.20.20.20.20.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.20.20.20.20.20.20.20.20.1.m1.1b"><ci id="S4.T1.20.20.20.20.20.20.20.20.1.m1.1.1.cmml" xref="S4.T1.20.20.20.20.20.20.20.20.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.20.20.20.20.20.20.20.20.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.20.20.20.20.20.20.20.20.1.m1.1d">â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.3">0.449</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.4">0.449</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.5">0.449</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.6">0.449</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.7">0.449</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.8">0.446</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.9">0.444</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.10">0.440</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.11"><span class="ltx_text ltx_font_bold" id="S4.T1.20.20.20.20.20.20.20.20.11.1">0.461</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.12">0.460</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.13">0.460</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.14">0.460</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.20.20.20.20.20.20.20.20.15">0.460</span></span>
<span class="ltx_tr" id="S4.T1.21.21.21.21.21.21.21.21">
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T1.21.21.21.21.21.21.21.21.1">ROUGE-L <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.21.21.21.21.21.21.21.21.1.m1.1"><semantics id="S4.T1.21.21.21.21.21.21.21.21.1.m1.1a"><mo id="S4.T1.21.21.21.21.21.21.21.21.1.m1.1.1" stretchy="false" xref="S4.T1.21.21.21.21.21.21.21.21.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.21.21.21.21.21.21.21.21.1.m1.1b"><ci id="S4.T1.21.21.21.21.21.21.21.21.1.m1.1.1.cmml" xref="S4.T1.21.21.21.21.21.21.21.21.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.21.21.21.21.21.21.21.21.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.21.21.21.21.21.21.21.21.1.m1.1d">â†‘</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.21.21.21.21.21.21.21.21.2">0.396</span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.21.21.21.21.21.21.21.21.3">0.397</span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.21.21.21.21.21.21.21.21.4">0.397</span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.21.21.21.21.21.21.21.21.5">0.396</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.21.21.21.21.21.21.21.21.6">0.396</span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.21.21.21.21.21.21.21.21.7">0.394</span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.21.21.21.21.21.21.21.21.8">0.393</span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.21.21.21.21.21.21.21.21.9">0.390</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.21.21.21.21.21.21.21.21.10"><span class="ltx_text ltx_font_bold" id="S4.T1.21.21.21.21.21.21.21.21.10.1">0.409</span></span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.21.21.21.21.21.21.21.21.11"><span class="ltx_text ltx_font_bold" id="S4.T1.21.21.21.21.21.21.21.21.11.1">0.409</span></span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.21.21.21.21.21.21.21.21.12"><span class="ltx_text ltx_font_bold" id="S4.T1.21.21.21.21.21.21.21.21.12.1">0.409</span></span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.21.21.21.21.21.21.21.21.13">0.408</span>
<span class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.21.21.21.21.21.21.21.21.14"><span class="ltx_text ltx_font_bold" id="S4.T1.21.21.21.21.21.21.21.21.14.1">0.409</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>The performance of utilized LLM personalization approaches on the LaMP benchmark.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="100" id="S4.F1.g1" src="extracted/5855333/figs/user_doc_count_improvement_average_with_rag.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Correlation (with confidence interval) between profile item count and performance improvement of <span class="ltx_text" id="S4.F1.3.1" style="color:#0000FF;">PEFT</span>- and <span class="ltx_text" id="S4.F1.4.2" style="color:#FF0000;">RAG</span>-based personalization in comparison with no personalization on the tasks in the LaMP benchmark.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">How does the combination of PEFT and RAG impact the personalization performance?</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">To address this, we use the best retrieval model from TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.T1" title="Table 1 â€£ How do PEFT- and RAG-based approaches perform for LLM personalization? â€£ 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a> and combine it with each userâ€™s personalized LLM, trained using PEFT, to perform RAG personalization with PEFT. The results of this experiment are reported in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.T1" title="Table 1 â€£ How do PEFT- and RAG-based approaches perform for LLM personalization? â€£ 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>. The findings suggest that combining RAG with PEFT leads to improvements over RAG in 4 out of 7 tasks. Additionally, this approach results in a 15.98% improvement over the non-personalized LLM, which is 0.44% more relative improvement over RAG personalization. Thus, this combination appears to be an effective for enhancing personalization.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">How does profile size and data presence in training corpus affect performance?</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p1.1">We create a regression plot<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://seaborn.pydata.org/generated/seaborn.regplot.html" title="">https://seaborn.pydata.org/generated/seaborn.regplot.html</a></span></span></span> between the profile size and relative improvement obtained by the best personalized LLM using PEFT- and RAG-based personalization versus the non-personalized LLM. We define improvement as 1 if there is a gain over no-personalization and -1 if there is no gain. Since many users do not experience any change in their performance, we excluded them from the analysis. This plot is depicted in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.F1" title="Figure 1 â€£ How do PEFT- and RAG-based approaches perform for LLM personalization? â€£ 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>. This figure indicates that, for 5 out of 7 datasets, there is a positive correlation between the number of items in the user profile and performance improvement for PEFT. For the LaMP-5 task, where we observe a negative or zero correlation, one explanation is that the profiles consist of abstracts from papers authored by the user, which are often collaborative works. Here, users with larger profiles tend to be senior researchers who may not have been directly involved in the writing process. We found that in 94% (17 out of 18) of performance drop cases, the user was not the primary author on most papers in their profile. Thus, training on such data is less effective for personalizing the LLM for their preferences. Finally, when considering all users across all tasks, we observe a positive correlation between performance improvement and the number of items in a userâ€™s profile. Conversely, we observe a negative correlation between the improvement in RAG-based personalization and the non-personalized baseline. This indicates that as the profile grows, retrieval models face difficulty in identifying and retrieving the relevant documents to personalize the LLM. These observations suggest that one reason PEFT does not perform as well as RAG for personalizing LLMs may be the insufficient amount of training data per user, which limits the modelâ€™s ability to learn from the user.</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p2.1">Another observation in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#S4.T1" title="Table 1 â€£ How do PEFT- and RAG-based approaches perform for LLM personalization? â€£ 4 Experiments â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a> is that PEFT performs better on the LaMP-6 task compared to other tasks. Since FlanT5 <cite class="ltx_cite ltx_citemacro_cite">Chung etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib5" title="">2024</a>)</cite> is trained on public datasets, and the LaMP-6 dataset contains PII information, the Avocado <cite class="ltx_cite ltx_citemacro_cite">Oard, Douglas etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib32" title="">2015</a>)</cite> corpus was not included in its training corpus. Consequently, it has not been exposed to this corpus. We believe that the improvement on this task is due to the LLM encountering this corpus for the first time and thus learning more from it. In contrast, other datasets are based on public data that FlanT5 is already trained on them. This suggests that training the LLM using PEFT on private user data can yield considerable improvements.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Retrieval-Augmented Generation</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">has proven effective for text generation in knowledge grounding for textual <cite class="ltx_cite ltx_citemacro_cite">Izacard and Grave (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib15" title="">2021b</a>); Asai etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib3" title="">2024</a>); Petroni etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib33" title="">2021</a>)</cite> and multi-modal <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib36" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib39" title="">b</a>); Gui etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib8" title="">2022</a>)</cite>, and reducing hallucinations <cite class="ltx_cite ltx_citemacro_cite">Agrawal etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib1" title="">2024</a>); Shuster etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib42" title="">2021</a>)</cite>. In RAG, a retrieverâ€” general <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib46" title="">2024</a>); Salemi and Zamani (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib41" title="">2024b</a>)</cite> or task-specific <cite class="ltx_cite ltx_citemacro_cite">Izacard and Grave (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib14" title="">2021a</a>); Izacard etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib16" title="">2024</a>)</cite>â€”retrieves relevant documents based on the input, which are used to generate a response. The quality of retrieval and the LLMâ€™s ability to use the retrieved information <cite class="ltx_cite ltx_citemacro_cite">Kim etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib18" title="">2024</a>); Salemi and Zamani (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib40" title="">2024a</a>); Lewis etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib22" title="">2020</a>); Zamani etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib47" title="">2022</a>)</cite> are crucial to performance.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Parameter Efficient Fine-Tuning</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">optimizes LLMs to specific tasks without full model training <cite class="ltx_cite ltx_citemacro_cite">Houlsby etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib10" title="">2019</a>)</cite>, updating only a small parameter set to reduce computational cost while maintaining performance<cite class="ltx_cite ltx_citemacro_cite">Liao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib28" title="">2023</a>); Han etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib9" title="">2024</a>)</cite>. Low-Rank Adaptation (LoRA), a well-known PEFT method, adapts LLMs with minimal parameter updates by introducing low-rank decomposition into weight matrices and injecting trainable low-rank matrices into frozen weights <cite class="ltx_cite ltx_citemacro_cite">Hu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib11" title="">2022</a>); Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib26" title="">2024c</a>); Lialin etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib27" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Personalizing LLMs</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px3.p1.1">is an important topic, where <cite class="ltx_cite ltx_citemacro_citet">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite> introduced a RAG-based method for personalizing LLMs and the LaMP benchmark for evaluating personalized tasks. <cite class="ltx_cite ltx_citemacro_citet">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib24" title="">2023</a>)</cite> explored this in long-form text generation, while others have focused on personalized assistants <cite class="ltx_cite ltx_citemacro_cite">Mysore etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib31" title="">2023</a>); Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib48" title="">2024</a>); Lu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib30" title="">2024</a>)</cite>. Various techniques have been studied, such as training retriever with LLM feedback on personalized outputs <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib37" title="">2024a</a>)</cite>, summarizing user profiles <cite class="ltx_cite ltx_citemacro_cite">Richardson etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib34" title="">2023</a>)</cite>, alignment with personalized feedback <cite class="ltx_cite ltx_citemacro_cite">Jang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib17" title="">2023</a>)</cite>, and automatic personalized prompt generation <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib23" title="">2024a</a>)</cite>. PEFT was used to personalize LLMs by a shared pool of adapters for users <cite class="ltx_cite ltx_citemacro_cite">Tan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib44" title="">2024</a>)</cite>, which raises privacy concerns as the model is trained on data from multiple users.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This paper investigates personalizing LLMs using RAG and PEFT. The results indicate that RAG significantly outperforms PEFT. Furthermore, combining RAG with PEFT leads to improvements in personalized tasks compared to personalization using RAG or PEFT alone. Finally, we provide evidence suggesting that the insufficient number of documents per user contributes to the poor performance of PEFT in personalizing LLMs.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This work has limitations related to resource intensivity and adaptor loading and retrieval latency.</p>
</div>
<section class="ltx_paragraph" id="Sx1.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Resource Intensivity.</h4>
<div class="ltx_para" id="Sx1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="Sx1.SS0.SSS0.Px1.p1.1">Personalizing LLMs, particularly using PEFT with LoRA can be resource-intensive. Training models with LoRA requires significant computational resources. This can lead to increased costs and extended training times, which may limit the scalability of these methods in resource-constrained environments. For this reason, in this paper, we were only able to conduct our experiments on a single LLM, FlanT5-XXL <cite class="ltx_cite ltx_citemacro_cite">Chung etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib5" title="">2024</a>)</cite>, which has 11 billion parameters, following <cite class="ltx_cite ltx_citemacro_citet">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>. While running similar experiments on other LLMs could provide valuable insights, it is prohibitively expensive. In this work, we utilized over 10,000 hours of A100 GPU computation for training and experimentation. Based on the average figures reported by <cite class="ltx_cite ltx_citemacro_citet">Dodge etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib6" title="">2022</a>)</cite>, the total computational effort for these experiments would result in the generation of at least 400 kilograms of CO2 if conducted on cloud-based GPU providers. Since we ran the experiments locally, which may be less efficient in terms of energy usage and CO2 emissions, the actual carbon footprint could be even higher. This highlights the environmental cost associated with large-scale LLM experiments, further complicating scalability. Scaling this study to include multiple LLMs would significantly increase the computational costs, making it infeasible for us to pursue at this time.</p>
</div>
<div class="ltx_para" id="Sx1.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="Sx1.SS0.SSS0.Px1.p2.1">In addition to the high cost of training these models, storing them can also be challenging. For example, if each adapter requires 200 MB of disk space, a website with 100,000,000 users would need 20 PB of disk space just to store the adapters. Addressing these challenges is crucial for the practical deployment of such systems. Studying solutions to overcome issues will be an important step towards the real-world application of personalized LLMs.</p>
</div>
</section>
<section class="ltx_paragraph" id="Sx1.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Adaptor Loading and Retrieval Latency.</h4>
<div class="ltx_para" id="Sx1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="Sx1.SS0.SSS0.Px2.p1.1">In the context of our comparison between RAG and PEFT methods, adaptor loading and retrieval latency emerge as critical factors influencing overall system performance. For RAG models, retrieval latency is a prominent concern. The process of querying external databases and loading relevant information incurs time costs that can impact the responsiveness of the system. High retrieval latency may hinder the efficiency of real-time applications where prompt responses are crucial. Additionally, complications such as the need for efficient indexing and managing a large corpus of data can further exacerbate latency issues. On the other hand, PEFT approaches involve adapting pre-trained models through the use of adaptors or additional parameters. The process of loading these adaptors can introduce overhead, particularly when dealing with large-scale models or numerous adaptors. While PEFT is designed to be more resource-efficient compared to full fine-tuning, the integration and initialization of adaptors still require computational resources and time. This overhead can affect the deployment and operational efficiency of PEFT-based systems, especially in scenarios requiring frequent updates or real-time interactions.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">This work was supported in part by the Center for Intelligent Information Retrieval, in part by Google, in part by Loweâ€™s, and in part by Microsoft. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal etÂ al. (2024)</span>
<span class="ltx_bibblock">
Garima Agrawal, Tharindu Kumarage, Zeyad Alghamdi, and Huan Liu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.naacl-long.219" title="">Can knowledge graphs reduce hallucinations in LLMs? : A survey</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</em>, pages 3947â€“3960, Mexico City, Mexico. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alhafni etÂ al. (2024)</span>
<span class="ltx_bibblock">
Bashar Alhafni, Vivek Kulkarni, Dhruv Kumar, and Vipul Raheja. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.personalize-1.8" title="">Personalized text generation with fine-grained linguistic control</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 1st Workshop on Personalization of Generative AI Systems (PERSONALIZE 2024)</em>, pages 88â€“101, St. Julians, Malta. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai etÂ al. (2024)</span>
<span class="ltx_bibblock">
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=hSyW5go0v8" title="">Self-RAG: Learning to retrieve, generate, and critique through self-reflection</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen (2023)</span>
<span class="ltx_bibblock">
Junyi Chen. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2311.12338" title="">A survey on large language models for personalized and explainable recommendations</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Preprint</em>, arXiv:2311.12338.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung etÂ al. (2024)</span>
<span class="ltx_bibblock">
HyungÂ Won Chung, LeÂ Hou, Shayne Longpre, Barret Zoph, YiÂ Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, ShixiangÂ Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, EdÂ H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, QuocÂ V. Le, and Jason Wei. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://jmlr.org/papers/v25/23-0870.html" title="">Scaling instruction-finetuned language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Journal of Machine Learning Research</em>, 25(70):1â€“53.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dodge etÂ al. (2022)</span>
<span class="ltx_bibblock">
Jesse Dodge, Taylor Prewitt, Remi TachetÂ des Combes, Erika Odmark, Roy Schwartz, Emma Strubell, AlexandraÂ Sasha Luccioni, NoahÂ A. Smith, Nicole DeCario, and Will Buchanan. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3531146.3533234" title="">Measuring the carbon intensity of ai in cloud instances</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</em>, FAccT â€™22, page 1877â€“1894, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag and Al-Onaizan (2017)</span>
<span class="ltx_bibblock">
Markus Freitag and Yaser Al-Onaizan. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W17-3207" title="">Beam search strategies for neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the First Workshop on Neural Machine Translation</em>, pages 56â€“60, Vancouver. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gui etÂ al. (2022)</span>
<span class="ltx_bibblock">
Liangke Gui, Borui Wang, Qiuyuan Huang, Alexander Hauptmann, Yonatan Bisk, and Jianfeng Gao. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.naacl-main.70" title="">KAT: A knowledge augmented transformer for vision-and-language</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 956â€“968, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han etÂ al. (2024)</span>
<span class="ltx_bibblock">
Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, and SaiÂ Qian Zhang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.14608" title="">Parameter-efficient fine-tuning for large models: A comprehensive survey</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Preprint</em>, arXiv:2403.14608.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Houlsby etÂ al. (2019)</span>
<span class="ltx_bibblock">
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin DeÂ Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v97/houlsby19a.html" title="">Parameter-efficient transfer learning for NLP</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 36th International Conference on Machine Learning</em>, volumeÂ 97 of <em class="ltx_emph ltx_font_italic" id="bib.bib10.2.2">Proceedings of Machine Learning Research</em>, pages 2790â€“2799. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al. (2022)</span>
<span class="ltx_bibblock">
EdwardÂ J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, LuÂ Wang, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="">LoRA: Low-rank adaptation of large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hua etÂ al. (2023)</span>
<span class="ltx_bibblock">
Wenyue Hua, Lei Li, Shuyuan Xu, LiÂ Chen, and Yongfeng Zhang. 2023.

</span>
<span class="ltx_bibblock">Tutorial on large language models for recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 17th ACM Conference on Recommender Systems</em>, pages 1281â€“1283.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard etÂ al. (2022)</span>
<span class="ltx_bibblock">
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2112.09118" title="">Unsupervised dense information retrieval with contrastive learning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Preprint</em>, arXiv:2112.09118.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard and Grave (2021a)</span>
<span class="ltx_bibblock">
Gautier Izacard and Edouard Grave. 2021a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=NTEz-6wysdb" title="">Distilling knowledge from reader to retriever for question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard and Grave (2021b)</span>
<span class="ltx_bibblock">
Gautier Izacard and Edouard Grave. 2021b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.eacl-main.74" title="">Leveraging passage retrieval with generative models for open domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</em>, pages 874â€“880, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard etÂ al. (2024)</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. 2024.

</span>
<span class="ltx_bibblock">Atlas: few-shot learning with retrieval augmented language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">J. Mach. Learn. Res.</em>, 24(1).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Joel Jang, Seungone Kim, BillÂ Yuchen Lin, Yizhong Wang, Jack Hessel, Luke Zettlemoyer, Hannaneh Hajishirzi, Yejin Choi, and Prithviraj Ammanabrolu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2310.11564" title="">Personalized soups: Personalized large language model alignment via post-hoc parameter merging</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Preprint</em>, arXiv:2310.11564.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2024)</span>
<span class="ltx_bibblock">
ToÂ Eun Kim, Alireza Salemi, Andrew Drozdov, Fernando Diaz, and Hamed Zamani. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2407.12982" title="">Retrieval-enhanced machine learning: Synthesis and opportunities</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Preprint</em>, arXiv:2407.12982.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2015)</span>
<span class="ltx_bibblock">
Diederik Kingma and Jimmy Ba. 2015.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">International Conference on Learning Representations (ICLR)</em>, San Diega, CA, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocaballi etÂ al. (2019)</span>
<span class="ltx_bibblock">
AhmetÂ Baki Kocaballi, Shlomo Berkovsky, JuanÂ C Quiroz, Liliana Laranjo, HuongÂ Ly Tong, Dana Rezazadegan, Agustina Briatore, and Enrico Coiera. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.2196/15360" title="">The personalization of conversational agents in health care: Systematic review</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">J Med Internet Res</em>, 21(11):e15360.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar etÂ al. (2024)</span>
<span class="ltx_bibblock">
Ishita Kumar, Snigdha Viswanathan, Sushrita Yerra, Alireza Salemi, RyanÂ A. Rossi, Franck Dernoncourt, Hanieh Deilamsalehy, Xiang Chen, Ruiyi Zhang, Shubham Agarwal, Nedim Lipka, and Hamed Zamani. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2407.11016" title="">Longlamp: A benchmark for personalized long-form text generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Preprint</em>, arXiv:2407.11016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2020)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, Sebastian Riedel, and Douwe Kiela. 2020.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 34th International Conference on Neural Information Processing Systems</em>, NIPS â€™20, Red Hook, NY, USA. Curran Associates Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2024a)</span>
<span class="ltx_bibblock">
Cheng Li, Mingyang Zhang, Qiaozhu Mei, Weize Kong, and Michael Bendersky. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3589334.3645408" title="">Learning to rewrite prompts for personalized text generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the ACM on Web Conference 2024</em>, WWW â€™24. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023)</span>
<span class="ltx_bibblock">
Cheng Li, Mingyang Zhang, Qiaozhu Mei, Yaqing Wang, SpurthiÂ Amba Hombaiah, YiÂ Liang, and Michael Bendersky. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2308.07968" title="">Teach llms to personalize â€“ an approach inspired by writing education</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Preprint</em>, arXiv:2308.07968.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2024b)</span>
<span class="ltx_bibblock">
Hao Li, Chenghao Yang, AnÂ Zhang, Yang Deng, Xiang Wang, and Tat-Seng Chua. 2024b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2406.05925" title="">Hello again! llm-powered personalized agent for long-term dialogue</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Preprint</em>, arXiv:2406.05925.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2024c)</span>
<span class="ltx_bibblock">
Yixiao Li, Yifan Yu, Chen Liang, Nikos Karampatziakis, Pengcheng He, Weizhu Chen, and Tuo Zhao. 2024c.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=LzPWWPAdY4" title="">Loftq: LoRA-fine-tuning-aware quantization for large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lialin etÂ al. (2024)</span>
<span class="ltx_bibblock">
Vladislav Lialin, Sherin Muckatira, Namrata Shivagunde, and Anna Rumshisky. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=DLJznSp6X3" title="">ReloRA: High-rank training through low-rank updates</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liao etÂ al. (2023)</span>
<span class="ltx_bibblock">
Baohao Liao, Yan Meng, and Christof Monz. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.233" title="">Parameter-efficient fine-tuning without introducing new latency</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 4242â€“4260, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)</span>
<span class="ltx_bibblock">
Chin-Yew Lin. 2004.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W04-1013" title="">ROUGE: A package for automatic evaluation of summaries</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Text Summarization Branches Out</em>, pages 74â€“81, Barcelona, Spain. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2024)</span>
<span class="ltx_bibblock">
Zhuoran Lu, Sheshera Mysore, Tara Safavi, Jennifer Neville, Longqi Yang, and Mengting Wan. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2405.04656" title="">Corporate communication companion (ccc): An llm-empowered writing assistant for workplace social media</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Preprint</em>, arXiv:2405.04656.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mysore etÂ al. (2023)</span>
<span class="ltx_bibblock">
Sheshera Mysore, Zhuoran Lu, Mengting Wan, Longqi Yang, Steve Menezes, Tina Baghaee, EmmanuelÂ Barajas Gonzalez, Jennifer Neville, and Tara Safavi. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2311.09180" title="">Pearl: Personalizing large language model writing assistants with generation-calibrated retrievers</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Preprint</em>, arXiv:2311.09180.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oard, Douglas etÂ al. (2015)</span>
<span class="ltx_bibblock">
Oard, Douglas, Webber, William, Kirsch, David A., and Golitsynskiy, Sergey. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.35111/WQT6-JG60" title="">Avocado research email collection</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni etÂ al. (2021)</span>
<span class="ltx_bibblock">
Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola DeÂ Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean Maillard, Vassilis Plachouras, Tim RocktÃ¤schel, and Sebastian Riedel. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.naacl-main.200" title="">KILT: a benchmark for knowledge intensive language tasks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 2523â€“2544, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Richardson etÂ al. (2023)</span>
<span class="ltx_bibblock">
Chris Richardson, Yao Zhang, Kellen Gillespie, Sudipta Kar, Arshdeep Singh, Zeynab Raeesy, OmarÂ Zia Khan, and Abhinav Sethy. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2310.20081" title="">Integrating summarization and retrieval for enhanced personalization via large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Preprint</em>, arXiv:2310.20081.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson etÂ al. (1994)</span>
<span class="ltx_bibblock">
StephenÂ E. Robertson, Steve Walker, Susan Jones, Micheline Hancock-Beaulieu, and Mike Gatford. 1994.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:3946054" title="">Okapi at trec-3</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Text Retrieval Conference</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salemi etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Alireza Salemi, Juan AltmayerÂ Pizzorno, and Hamed Zamani. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3539618.3591629" title="">A symmetric dual encoding dense retrieval framework for knowledge-intensive visual question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, SIGIR â€™23, page 110â€“120, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salemi etÂ al. (2024a)</span>
<span class="ltx_bibblock">
Alireza Salemi, Surya Kallumadi, and Hamed Zamani. 2024a.

</span>
<span class="ltx_bibblock">Optimization methods for personalizing large language models through retrieval augmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the 47th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, SIGIR â€™24.

</span>
<span class="ltx_bibblock">(to appear).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salemi etÂ al. (2024b)</span>
<span class="ltx_bibblock">
Alireza Salemi, Sheshera Mysore, Michael Bendersky, and Hamed Zamani. 2024b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.acl-long.399" title="">LaMP: When large language models meet personalization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 7370â€“7392, Bangkok, Thailand. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salemi etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Alireza Salemi, Mahta Rafiee, and Hamed Zamani. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3578337.3605137" title="">Pre-training multi-modal dense retrievers for outside-knowledge visual question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 2023 ACM SIGIR International Conference on Theory of Information Retrieval</em>, ICTIR â€™23, page 169â€“176, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salemi and Zamani (2024a)</span>
<span class="ltx_bibblock">
Alireza Salemi and Hamed Zamani. 2024a.

</span>
<span class="ltx_bibblock">Evaluating retrieval quality in retrieval-augmented generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Proceedings of the 47th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, SIGIR â€™24.

</span>
<span class="ltx_bibblock">(to appear).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salemi and Zamani (2024b)</span>
<span class="ltx_bibblock">
Alireza Salemi and Hamed Zamani. 2024b.

</span>
<span class="ltx_bibblock">Towards a search engine for machines: Unified ranking for multiple retrieval-augmented large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the 47th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, SIGIR â€™24.

</span>
<span class="ltx_bibblock">(to appear).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shuster etÂ al. (2021)</span>
<span class="ltx_bibblock">
Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.findings-emnlp.320" title="">Retrieval augmentation reduces hallucination in conversation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Findings of the Association for Computational Linguistics: EMNLP 2021</em>, pages 3784â€“3803, Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutskever etÂ al. (2014)</span>
<span class="ltx_bibblock">
Ilya Sutskever, Oriol Vinyals, and QuocÂ V Le. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf" title="">Sequence to sequence learning with neural networks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Advances in Neural Information Processing Systems</em>, volumeÂ 27. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan etÂ al. (2024)</span>
<span class="ltx_bibblock">
Zhaoxuan Tan, Zheyuan Liu, and Meng Jiang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2406.10471" title="">Personalized pieces: Efficient personalized large language models through collaborative efforts</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Preprint</em>, arXiv:2406.10471.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani etÂ al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, AidanÂ N Gomez, ÅÂ ukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="">Attention is all you need</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Advances in Neural Information Processing Systems</em>, volumeÂ 30. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2024)</span>
<span class="ltx_bibblock">
Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2212.03533" title="">Text embeddings by weakly-supervised contrastive pre-training</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Preprint</em>, arXiv:2212.03533.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zamani etÂ al. (2022)</span>
<span class="ltx_bibblock">
Hamed Zamani, Fernando Diaz, Mostafa Dehghani, Donald Metzler, and Michael Bendersky. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3477495.3531722" title="">Retrieval-enhanced machine learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, SIGIR â€™22, page 2875â€“2886, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2024)</span>
<span class="ltx_bibblock">
Kai Zhang, Yangyang Kang, Fubang Zhao, and Xiaozhong Liu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.naacl-long.132" title="">LLM-based medical assistant personalization with short- and long-term memory coordination</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</em>, pages 2386â€“2398, Mexico City, Mexico. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Experiments Setup</h2>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Tasks &amp; Datasets.</h4>
<div class="ltx_para" id="A1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p1.1">In this paper, we conduct our experiments using the LaMP benchmark <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>, which is designed to evaluate the personalization of LLMs. Each sample in the benchmark represents a user, including an input prompt, an expected output, and a set of items forming the user profile, provided in either structured or unstructured format. The benchmark features 7 personalized tasks: three text classification tasks and four text generation tasks. The dataset statistics for this benchmark are detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1.T2" title="Table 2 â€£ Tasks &amp; Datasets. â€£ Appendix A Experiments Setup â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>. We focus on the time-based configuration of this benchmark, as it provides shared users between the training and test sets. This allows us to train the models on user profiles for the PEFT approach.</p>
</div>
<figure class="ltx_table" id="A1.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T2.18" style="width:433.6pt;height:99.4pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-99.4pt,22.6pt) scale(0.68576,0.68576) ;">
<p class="ltx_p" id="A1.T2.18.18"><span class="ltx_text" id="A1.T2.18.18.18">
<span class="ltx_inline-block ltx_transformed_outer" id="A1.T2.18.18.18.18" style="width:632.3pt;height:145pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="A1.T2.18.18.18.18.18"><span class="ltx_text" id="A1.T2.18.18.18.18.18.18">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T2.18.18.18.18.18.18.18">
<span class="ltx_thead">
<span class="ltx_tr" id="A1.T2.18.18.18.18.18.18.18.19.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="A1.T2.18.18.18.18.18.18.18.19.1.1"><span class="ltx_text ltx_font_bold" id="A1.T2.18.18.18.18.18.18.18.19.1.1.1">Task</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T2.18.18.18.18.18.18.18.19.1.2"><span class="ltx_text ltx_font_bold" id="A1.T2.18.18.18.18.18.18.18.19.1.2.1">#train</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T2.18.18.18.18.18.18.18.19.1.3"><span class="ltx_text ltx_font_bold" id="A1.T2.18.18.18.18.18.18.18.19.1.3.1">#dev</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="A1.T2.18.18.18.18.18.18.18.19.1.4"><span class="ltx_text ltx_font_bold" id="A1.T2.18.18.18.18.18.18.18.19.1.4.1">#test</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T2.18.18.18.18.18.18.18.19.1.5"><span class="ltx_text ltx_font_bold" id="A1.T2.18.18.18.18.18.18.18.19.1.5.1">Input Length</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="A1.T2.18.18.18.18.18.18.18.19.1.6"><span class="ltx_text ltx_font_bold" id="A1.T2.18.18.18.18.18.18.18.19.1.6.1">Output Length</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="A1.T2.18.18.18.18.18.18.18.19.1.7"><span class="ltx_text ltx_font_bold" id="A1.T2.18.18.18.18.18.18.18.19.1.7.1">#Profile Size</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T2.18.18.18.18.18.18.18.19.1.8"><span class="ltx_text ltx_font_bold" id="A1.T2.18.18.18.18.18.18.18.19.1.8.1">#classes</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="A1.T2.2.2.2.2.2.2.2.2">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T2.2.2.2.2.2.2.2.2.3">LaMP-1: Personalized Citation Identification</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.2.2.2.2.2.2.2.2.4">6542</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.2.2.2.2.2.2.2.2.5">1500</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.2.2.2.2.2.2.2.2.6">1500</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.1.1.1.1.1.1.1.1.1">51.43 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A1.T2.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="A1.T2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A1.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.1.1.1.1.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="A1.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.T2.1.1.1.1.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.1.1.1.1.1.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.1.1.1.1.1.1.1.1.1.m1.1d">Â±</annotation></semantics></math> 5.70</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.2.2.2.2.2.2.2.2.7">-</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.2.2.2.2.2.2.2.2.2">84.15 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.2.2.2.2.2.2.2.2.2.m1.1"><semantics id="A1.T2.2.2.2.2.2.2.2.2.2.m1.1a"><mo id="A1.T2.2.2.2.2.2.2.2.2.2.m1.1.1" xref="A1.T2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.2.2.2.2.2.2.2.2.2.m1.1b"><csymbol cd="latexml" id="A1.T2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="A1.T2.2.2.2.2.2.2.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.2.2.2.2.2.2.2.2.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.2.2.2.2.2.2.2.2.2.m1.1d">Â±</annotation></semantics></math> 47.54</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.2.2.2.2.2.2.2.2.8">2</span></span>
<span class="ltx_tr" id="A1.T2.4.4.4.4.4.4.4.4">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T2.4.4.4.4.4.4.4.4.3">LaMP-2: Personalized Movie Tagging</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.4.4.4.4.4.4.4.4.4">5073</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.4.4.4.4.4.4.4.4.5">1410</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.4.4.4.4.4.4.4.4.6">1557</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.3.3.3.3.3.3.3.3.1">92.39 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.3.3.3.3.3.3.3.3.1.m1.1"><semantics id="A1.T2.3.3.3.3.3.3.3.3.1.m1.1a"><mo id="A1.T2.3.3.3.3.3.3.3.3.1.m1.1.1" xref="A1.T2.3.3.3.3.3.3.3.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.3.3.3.3.3.3.3.3.1.m1.1b"><csymbol cd="latexml" id="A1.T2.3.3.3.3.3.3.3.3.1.m1.1.1.cmml" xref="A1.T2.3.3.3.3.3.3.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.3.3.3.3.3.3.3.3.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.3.3.3.3.3.3.3.3.1.m1.1d">Â±</annotation></semantics></math> 21.95</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.4.4.4.4.4.4.4.4.7">-</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.4.4.4.4.4.4.4.4.2">86.76 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.4.4.4.4.4.4.4.4.2.m1.1"><semantics id="A1.T2.4.4.4.4.4.4.4.4.2.m1.1a"><mo id="A1.T2.4.4.4.4.4.4.4.4.2.m1.1.1" xref="A1.T2.4.4.4.4.4.4.4.4.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.4.4.4.4.4.4.4.4.2.m1.1b"><csymbol cd="latexml" id="A1.T2.4.4.4.4.4.4.4.4.2.m1.1.1.cmml" xref="A1.T2.4.4.4.4.4.4.4.4.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.4.4.4.4.4.4.4.4.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.4.4.4.4.4.4.4.4.2.m1.1d">Â±</annotation></semantics></math> 189.52</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.4.4.4.4.4.4.4.4.8">15</span></span>
<span class="ltx_tr" id="A1.T2.6.6.6.6.6.6.6.6">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T2.6.6.6.6.6.6.6.6.3">LaMP-3: Personalized Product Rating</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.6.6.6.6.6.6.6.6.4">20000</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.6.6.6.6.6.6.6.6.5">2500</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.6.6.6.6.6.6.6.6.6">2500</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.5.5.5.5.5.5.5.5.1">128.18 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.5.5.5.5.5.5.5.5.1.m1.1"><semantics id="A1.T2.5.5.5.5.5.5.5.5.1.m1.1a"><mo id="A1.T2.5.5.5.5.5.5.5.5.1.m1.1.1" xref="A1.T2.5.5.5.5.5.5.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.5.5.5.5.5.5.5.5.1.m1.1b"><csymbol cd="latexml" id="A1.T2.5.5.5.5.5.5.5.5.1.m1.1.1.cmml" xref="A1.T2.5.5.5.5.5.5.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.5.5.5.5.5.5.5.5.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.5.5.5.5.5.5.5.5.1.m1.1d">Â±</annotation></semantics></math> 146.25</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.6.6.6.6.6.6.6.6.7">-</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.6.6.6.6.6.6.6.6.2">185.40 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.6.6.6.6.6.6.6.6.2.m1.1"><semantics id="A1.T2.6.6.6.6.6.6.6.6.2.m1.1a"><mo id="A1.T2.6.6.6.6.6.6.6.6.2.m1.1.1" xref="A1.T2.6.6.6.6.6.6.6.6.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.6.6.6.6.6.6.6.6.2.m1.1b"><csymbol cd="latexml" id="A1.T2.6.6.6.6.6.6.6.6.2.m1.1.1.cmml" xref="A1.T2.6.6.6.6.6.6.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.6.6.6.6.6.6.6.6.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.6.6.6.6.6.6.6.6.2.m1.1d">Â±</annotation></semantics></math> 129.30</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.6.6.6.6.6.6.6.6.8">5</span></span>
<span class="ltx_tr" id="A1.T2.9.9.9.9.9.9.9.9">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T2.9.9.9.9.9.9.9.9.4">LaMP-4: Personalized News Headline Generation</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.9.9.9.9.9.9.9.9.5">12500</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.9.9.9.9.9.9.9.9.6">1500</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.9.9.9.9.9.9.9.9.7">1800</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.7.7.7.7.7.7.7.7.1">29.97 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.7.7.7.7.7.7.7.7.1.m1.1"><semantics id="A1.T2.7.7.7.7.7.7.7.7.1.m1.1a"><mo id="A1.T2.7.7.7.7.7.7.7.7.1.m1.1.1" xref="A1.T2.7.7.7.7.7.7.7.7.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.7.7.7.7.7.7.7.7.1.m1.1b"><csymbol cd="latexml" id="A1.T2.7.7.7.7.7.7.7.7.1.m1.1.1.cmml" xref="A1.T2.7.7.7.7.7.7.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.7.7.7.7.7.7.7.7.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.7.7.7.7.7.7.7.7.1.m1.1d">Â±</annotation></semantics></math> 12.09</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.8.8.8.8.8.8.8.8.2">10.07 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.8.8.8.8.8.8.8.8.2.m1.1"><semantics id="A1.T2.8.8.8.8.8.8.8.8.2.m1.1a"><mo id="A1.T2.8.8.8.8.8.8.8.8.2.m1.1.1" xref="A1.T2.8.8.8.8.8.8.8.8.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.8.8.8.8.8.8.8.8.2.m1.1b"><csymbol cd="latexml" id="A1.T2.8.8.8.8.8.8.8.8.2.m1.1.1.cmml" xref="A1.T2.8.8.8.8.8.8.8.8.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.8.8.8.8.8.8.8.8.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.8.8.8.8.8.8.8.8.2.m1.1d">Â±</annotation></semantics></math> 3.10</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.9.9.9.9.9.9.9.9.3">204.59 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.9.9.9.9.9.9.9.9.3.m1.1"><semantics id="A1.T2.9.9.9.9.9.9.9.9.3.m1.1a"><mo id="A1.T2.9.9.9.9.9.9.9.9.3.m1.1.1" xref="A1.T2.9.9.9.9.9.9.9.9.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.9.9.9.9.9.9.9.9.3.m1.1b"><csymbol cd="latexml" id="A1.T2.9.9.9.9.9.9.9.9.3.m1.1.1.cmml" xref="A1.T2.9.9.9.9.9.9.9.9.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.9.9.9.9.9.9.9.9.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.9.9.9.9.9.9.9.9.3.m1.1d">Â±</annotation></semantics></math> 250.75</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.9.9.9.9.9.9.9.9.8">-</span></span>
<span class="ltx_tr" id="A1.T2.12.12.12.12.12.12.12.12">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T2.12.12.12.12.12.12.12.12.4">LaMP-5: Personalized Scholarly Title Generation</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.12.12.12.12.12.12.12.12.5">14682</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.12.12.12.12.12.12.12.12.6">1500</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.12.12.12.12.12.12.12.12.7">1500</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.10.10.10.10.10.10.10.10.1">162.34 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.10.10.10.10.10.10.10.10.1.m1.1"><semantics id="A1.T2.10.10.10.10.10.10.10.10.1.m1.1a"><mo id="A1.T2.10.10.10.10.10.10.10.10.1.m1.1.1" xref="A1.T2.10.10.10.10.10.10.10.10.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.10.10.10.10.10.10.10.10.1.m1.1b"><csymbol cd="latexml" id="A1.T2.10.10.10.10.10.10.10.10.1.m1.1.1.cmml" xref="A1.T2.10.10.10.10.10.10.10.10.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.10.10.10.10.10.10.10.10.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.10.10.10.10.10.10.10.10.1.m1.1d">Â±</annotation></semantics></math> 65.63</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.11.11.11.11.11.11.11.11.2">9.71 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.11.11.11.11.11.11.11.11.2.m1.1"><semantics id="A1.T2.11.11.11.11.11.11.11.11.2.m1.1a"><mo id="A1.T2.11.11.11.11.11.11.11.11.2.m1.1.1" xref="A1.T2.11.11.11.11.11.11.11.11.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.11.11.11.11.11.11.11.11.2.m1.1b"><csymbol cd="latexml" id="A1.T2.11.11.11.11.11.11.11.11.2.m1.1.1.cmml" xref="A1.T2.11.11.11.11.11.11.11.11.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.11.11.11.11.11.11.11.11.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.11.11.11.11.11.11.11.11.2.m1.1d">Â±</annotation></semantics></math> 3.21</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.12.12.12.12.12.12.12.12.3">87.88 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.12.12.12.12.12.12.12.12.3.m1.1"><semantics id="A1.T2.12.12.12.12.12.12.12.12.3.m1.1a"><mo id="A1.T2.12.12.12.12.12.12.12.12.3.m1.1.1" xref="A1.T2.12.12.12.12.12.12.12.12.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.12.12.12.12.12.12.12.12.3.m1.1b"><csymbol cd="latexml" id="A1.T2.12.12.12.12.12.12.12.12.3.m1.1.1.cmml" xref="A1.T2.12.12.12.12.12.12.12.12.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.12.12.12.12.12.12.12.12.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.12.12.12.12.12.12.12.12.3.m1.1d">Â±</annotation></semantics></math> 53.63</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.12.12.12.12.12.12.12.12.8">-</span></span>
<span class="ltx_tr" id="A1.T2.15.15.15.15.15.15.15.15">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T2.15.15.15.15.15.15.15.15.4">LaMP-6: Personalized Email Subject Generation</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.15.15.15.15.15.15.15.15.5">4821</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.15.15.15.15.15.15.15.15.6">1250</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.15.15.15.15.15.15.15.15.7">1250</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.13.13.13.13.13.13.13.13.1">454.87 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.13.13.13.13.13.13.13.13.1.m1.1"><semantics id="A1.T2.13.13.13.13.13.13.13.13.1.m1.1a"><mo id="A1.T2.13.13.13.13.13.13.13.13.1.m1.1.1" xref="A1.T2.13.13.13.13.13.13.13.13.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.13.13.13.13.13.13.13.13.1.m1.1b"><csymbol cd="latexml" id="A1.T2.13.13.13.13.13.13.13.13.1.m1.1.1.cmml" xref="A1.T2.13.13.13.13.13.13.13.13.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.13.13.13.13.13.13.13.13.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.13.13.13.13.13.13.13.13.1.m1.1d">Â±</annotation></semantics></math> 889.41</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.14.14.14.14.14.14.14.14.2">7.37 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.14.14.14.14.14.14.14.14.2.m1.1"><semantics id="A1.T2.14.14.14.14.14.14.14.14.2.m1.1a"><mo id="A1.T2.14.14.14.14.14.14.14.14.2.m1.1.1" xref="A1.T2.14.14.14.14.14.14.14.14.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.14.14.14.14.14.14.14.14.2.m1.1b"><csymbol cd="latexml" id="A1.T2.14.14.14.14.14.14.14.14.2.m1.1.1.cmml" xref="A1.T2.14.14.14.14.14.14.14.14.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.14.14.14.14.14.14.14.14.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.14.14.14.14.14.14.14.14.2.m1.1d">Â±</annotation></semantics></math> 2.78</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T2.15.15.15.15.15.15.15.15.3">55.67 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.15.15.15.15.15.15.15.15.3.m1.1"><semantics id="A1.T2.15.15.15.15.15.15.15.15.3.m1.1a"><mo id="A1.T2.15.15.15.15.15.15.15.15.3.m1.1.1" xref="A1.T2.15.15.15.15.15.15.15.15.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.15.15.15.15.15.15.15.15.3.m1.1b"><csymbol cd="latexml" id="A1.T2.15.15.15.15.15.15.15.15.3.m1.1.1.cmml" xref="A1.T2.15.15.15.15.15.15.15.15.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.15.15.15.15.15.15.15.15.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.15.15.15.15.15.15.15.15.3.m1.1d">Â±</annotation></semantics></math> 36.32</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.15.15.15.15.15.15.15.15.8">-</span></span>
<span class="ltx_tr" id="A1.T2.18.18.18.18.18.18.18.18">
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A1.T2.18.18.18.18.18.18.18.18.4">LaMP-7: Personalized Tweet Paraphrasing</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T2.18.18.18.18.18.18.18.18.5">13437</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T2.18.18.18.18.18.18.18.18.6">1498</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T2.18.18.18.18.18.18.18.18.7">1500</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T2.16.16.16.16.16.16.16.16.1">29.72 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.16.16.16.16.16.16.16.16.1.m1.1"><semantics id="A1.T2.16.16.16.16.16.16.16.16.1.m1.1a"><mo id="A1.T2.16.16.16.16.16.16.16.16.1.m1.1.1" xref="A1.T2.16.16.16.16.16.16.16.16.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.16.16.16.16.16.16.16.16.1.m1.1b"><csymbol cd="latexml" id="A1.T2.16.16.16.16.16.16.16.16.1.m1.1.1.cmml" xref="A1.T2.16.16.16.16.16.16.16.16.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.16.16.16.16.16.16.16.16.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.16.16.16.16.16.16.16.16.1.m1.1d">Â±</annotation></semantics></math> 7.01</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T2.17.17.17.17.17.17.17.17.2">16.96 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.17.17.17.17.17.17.17.17.2.m1.1"><semantics id="A1.T2.17.17.17.17.17.17.17.17.2.m1.1a"><mo id="A1.T2.17.17.17.17.17.17.17.17.2.m1.1.1" xref="A1.T2.17.17.17.17.17.17.17.17.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.17.17.17.17.17.17.17.17.2.m1.1b"><csymbol cd="latexml" id="A1.T2.17.17.17.17.17.17.17.17.2.m1.1.1.cmml" xref="A1.T2.17.17.17.17.17.17.17.17.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.17.17.17.17.17.17.17.17.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.17.17.17.17.17.17.17.17.2.m1.1d">Â±</annotation></semantics></math> 5.67</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T2.18.18.18.18.18.18.18.18.3">15.71 <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T2.18.18.18.18.18.18.18.18.3.m1.1"><semantics id="A1.T2.18.18.18.18.18.18.18.18.3.m1.1a"><mo id="A1.T2.18.18.18.18.18.18.18.18.3.m1.1.1" xref="A1.T2.18.18.18.18.18.18.18.18.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A1.T2.18.18.18.18.18.18.18.18.3.m1.1b"><csymbol cd="latexml" id="A1.T2.18.18.18.18.18.18.18.18.3.m1.1.1.cmml" xref="A1.T2.18.18.18.18.18.18.18.18.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.18.18.18.18.18.18.18.18.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T2.18.18.18.18.18.18.18.18.3.m1.1d">Â±</annotation></semantics></math> 14.86</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T2.18.18.18.18.18.18.18.18.8">-</span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Statistics of the datasets within the LaMP benchmark <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite> with time-based data separation.</figcaption>
</figure>
<figure class="ltx_table" id="A1.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T3.26" style="width:433.6pt;height:137.3pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-85.7pt,27.0pt) scale(0.71666,0.71666) ;">
<p class="ltx_p" id="A1.T3.26.26"><span class="ltx_text" id="A1.T3.26.26.26">
<span class="ltx_inline-block ltx_transformed_outer" id="A1.T3.26.26.26.26" style="width:605.1pt;height:191.6pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="A1.T3.26.26.26.26.26"><span class="ltx_text" id="A1.T3.26.26.26.26.26.26">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T3.26.26.26.26.26.26.26">
<span class="ltx_thead">
<span class="ltx_tr" id="A1.T3.26.26.26.26.26.26.26.27.1">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="A1.T3.26.26.26.26.26.26.26.27.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.26.26.26.26.26.26.26.27.1.1.1">
<span class="ltx_p" id="A1.T3.26.26.26.26.26.26.26.27.1.1.1.1" style="width:113.8pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.26.26.26.26.26.26.26.27.1.1.1.1.1">Task</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="A1.T3.26.26.26.26.26.26.26.27.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.26.26.26.26.26.26.26.27.1.2.1">
<span class="ltx_p" id="A1.T3.26.26.26.26.26.26.26.27.1.2.1.1" style="width:199.2pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.26.26.26.26.26.26.26.27.1.2.1.1.1">Per Profile Entry Prompt (<span class="ltx_text ltx_font_typewriter" id="A1.T3.26.26.26.26.26.26.26.27.1.2.1.1.1.1">PPEP</span>)</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="A1.T3.26.26.26.26.26.26.26.27.1.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.26.26.26.26.26.26.26.27.1.3.1">
<span class="ltx_p" id="A1.T3.26.26.26.26.26.26.26.27.1.3.1.1" style="width:256.1pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.26.26.26.26.26.26.26.27.1.3.1.1.1">Aggregated Input Prompt(AIP)</span></span>
</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="A1.T3.3.3.3.3.3.3.3.3">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A1.T3.3.3.3.3.3.3.3.3.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.3.3.3.3.3.3.3.3.4.1">
<span class="ltx_p" id="A1.T3.3.3.3.3.3.3.3.3.4.1.1" style="width:113.8pt;">1: Citation Identification</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A1.T3.1.1.1.1.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.1.1.1.1.1.1.1.1.1.1">
<span class="ltx_p" id="A1.T3.1.1.1.1.1.1.1.1.1.1.1" style="width:199.2pt;">â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><msub id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">P</mi><mi id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.m1.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.T3.1.1.1.1.1.1.1.1.1.1.1.1">[title]</span>â€</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A1.T3.3.3.3.3.3.3.3.3.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.3.3.3.3.3.3.3.3.3.2">
<span class="ltx_p" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2" style="width:256.1pt;"><span class="ltx_text ltx_font_typewriter" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.1" style="color:#0000FF;">add_to_paper_title</span>(<span class="ltx_text ltx_font_typewriter" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.2" style="color:#0000FF;">concat</span>([<span class="ltx_text ltx_font_typewriter" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.3" style="color:#0000FF;">PPEP</span>(<math alttext="P_{1}" class="ltx_Math" display="inline" id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1"><semantics id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1a"><msub id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1" xref="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.cmml"><mi id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.2" xref="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.2.cmml">P</mi><mn id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.3" xref="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1b"><apply id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.cmml" xref="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.1.cmml" xref="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.2.cmml" xref="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.2">ğ‘ƒ</ci><cn id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.3.cmml" type="integer" xref="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1c">P_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.2.2.2.2.2.2.2.2.2.1.1.m1.1d">italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>), â€¦, <span class="ltx_text ltx_font_typewriter" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.4" style="color:#0000FF;">PPEP</span>(<math alttext="P_{n}" class="ltx_Math" display="inline" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1"><semantics id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1a"><msub id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1" xref="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.cmml"><mi id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.2" xref="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.3" xref="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1b"><apply id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.cmml" xref="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.1.cmml" xref="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.2.cmml" xref="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.3.cmml" xref="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1c">P_{n}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>)], <span class="ltx_text" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.5" style="color:#808080;">", and "</span>), <span class="ltx_text ltx_font_typewriter" id="A1.T3.3.3.3.3.3.3.3.3.3.2.2.6" style="color:#FF0000;">[INPUT]</span>)</span>
</span></span></span>
<span class="ltx_tr" id="A1.T3.7.7.7.7.7.7.7.7">
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.7.7.7.7.7.7.7.7.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.7.7.7.7.7.7.7.7.5.1">
<span class="ltx_p" id="A1.T3.7.7.7.7.7.7.7.7.5.1.1" style="width:113.8pt;">2: Movie Tagging</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.5.5.5.5.5.5.5.5.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.5.5.5.5.5.5.5.5.2.2">
<span class="ltx_p" id="A1.T3.5.5.5.5.5.5.5.5.2.2.2" style="width:199.2pt;">the tag for the movie: â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1"><semantics id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1a"><msub id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1" xref="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.cmml"><mi id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.2" xref="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.2.cmml">P</mi><mi id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.3" xref="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1b"><apply id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.cmml" xref="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.1.cmml" xref="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.2.cmml" xref="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.3.cmml" xref="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.4.4.4.4.4.4.4.4.1.1.1.m1.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.1">[description]</span>â€ is â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1"><semantics id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1a"><msub id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1" xref="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.cmml"><mi id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.2" xref="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.3" xref="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1b"><apply id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.cmml" xref="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.1.cmml" xref="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.2.cmml" xref="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.3.cmml" xref="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.T3.5.5.5.5.5.5.5.5.2.2.2.2">[tag]</span>â€</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.7.7.7.7.7.7.7.7.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.7.7.7.7.7.7.7.7.4.2">
<span class="ltx_p" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2" style="width:256.1pt;"><span class="ltx_text ltx_font_typewriter" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.1" style="color:#0000FF;">concat</span>([<span class="ltx_text ltx_font_typewriter" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.2" style="color:#0000FF;">PPEP</span>(<math alttext="P_{1}" class="ltx_Math" display="inline" id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1"><semantics id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1a"><msub id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1" xref="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.cmml"><mi id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.2" xref="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.2.cmml">P</mi><mn id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.3" xref="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1b"><apply id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.cmml" xref="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.1.cmml" xref="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.2.cmml" xref="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.2">ğ‘ƒ</ci><cn id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.3.cmml" type="integer" xref="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1c">P_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.6.6.6.6.6.6.6.6.3.1.1.m1.1d">italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>), â€¦, <span class="ltx_text ltx_font_typewriter" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.3" style="color:#0000FF;">PPEP</span>(<math alttext="P_{n}" class="ltx_Math" display="inline" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1"><semantics id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1a"><msub id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1" xref="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.cmml"><mi id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.2" xref="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.3" xref="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1b"><apply id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.cmml" xref="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.1.cmml" xref="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.2.cmml" xref="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.3.cmml" xref="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1c">P_{n}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>)], <span class="ltx_text" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.4" style="color:#808080;">â€œ, and â€</span>). <span class="ltx_text ltx_font_typewriter" id="A1.T3.7.7.7.7.7.7.7.7.4.2.2.5" style="color:#FF0000;">[INPUT]</span></span>
</span></span></span>
<span class="ltx_tr" id="A1.T3.11.11.11.11.11.11.11.11">
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.11.11.11.11.11.11.11.11.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.11.11.11.11.11.11.11.11.5.1">
<span class="ltx_p" id="A1.T3.11.11.11.11.11.11.11.11.5.1.1" style="width:113.8pt;">3: Product Rating</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.9.9.9.9.9.9.9.9.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.9.9.9.9.9.9.9.9.2.2">
<span class="ltx_p" id="A1.T3.9.9.9.9.9.9.9.9.2.2.2" style="width:199.2pt;"><math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1"><semantics id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1a"><msub id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1" xref="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.cmml"><mi id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.2" xref="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.2.cmml">P</mi><mi id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.3" xref="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1b"><apply id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.cmml" xref="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.1.cmml" xref="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.2.cmml" xref="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.3.cmml" xref="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.8.8.8.8.8.8.8.8.1.1.1.m1.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>[score] is the score for â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1"><semantics id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1a"><msub id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1" xref="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.cmml"><mi id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.2" xref="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.3" xref="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1b"><apply id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.cmml" xref="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.1.cmml" xref="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.2.cmml" xref="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.3.cmml" xref="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.T3.9.9.9.9.9.9.9.9.2.2.2.1">[text]</span>â€</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.11.11.11.11.11.11.11.11.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.11.11.11.11.11.11.11.11.4.2">
<span class="ltx_p" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2" style="width:256.1pt;"><span class="ltx_text ltx_font_typewriter" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.1" style="color:#0000FF;">concat</span>([<span class="ltx_text ltx_font_typewriter" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.2" style="color:#0000FF;">PPEP</span>(<math alttext="P_{1}" class="ltx_Math" display="inline" id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1"><semantics id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1a"><msub id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1" xref="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.cmml"><mi id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.2" xref="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.2.cmml">P</mi><mn id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.3" xref="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1b"><apply id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.cmml" xref="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.1.cmml" xref="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.2.cmml" xref="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.2">ğ‘ƒ</ci><cn id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.3.cmml" type="integer" xref="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1c">P_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.10.10.10.10.10.10.10.10.3.1.1.m1.1d">italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>), â€¦, <span class="ltx_text ltx_font_typewriter" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.3" style="color:#0000FF;">PPEP</span>(<math alttext="P_{n}" class="ltx_Math" display="inline" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1"><semantics id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1a"><msub id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1" xref="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.cmml"><mi id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.2" xref="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.3" xref="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1b"><apply id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.cmml" xref="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.1.cmml" xref="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.2.cmml" xref="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.3.cmml" xref="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1c">P_{n}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>)], <span class="ltx_text" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.4" style="color:#808080;">â€œ, and â€</span>). <span class="ltx_text ltx_font_typewriter" id="A1.T3.11.11.11.11.11.11.11.11.4.2.2.5" style="color:#FF0000;">[INPUT]</span></span>
</span></span></span>
<span class="ltx_tr" id="A1.T3.15.15.15.15.15.15.15.15">
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.15.15.15.15.15.15.15.15.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.15.15.15.15.15.15.15.15.5.1">
<span class="ltx_p" id="A1.T3.15.15.15.15.15.15.15.15.5.1.1" style="width:113.8pt;">4: News Headline Generation</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.13.13.13.13.13.13.13.13.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.13.13.13.13.13.13.13.13.2.2">
<span class="ltx_p" id="A1.T3.13.13.13.13.13.13.13.13.2.2.2" style="width:199.2pt;">â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1"><semantics id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1a"><msub id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1" xref="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.cmml"><mi id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.2" xref="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.2.cmml">P</mi><mi id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.3" xref="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1b"><apply id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.cmml" xref="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.1.cmml" xref="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.2.cmml" xref="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.3.cmml" xref="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.12.12.12.12.12.12.12.12.1.1.1.m1.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.1">[title]</span>â€ is the title for â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1"><semantics id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1a"><msub id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1" xref="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.cmml"><mi id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.2" xref="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.3" xref="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1b"><apply id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.cmml" xref="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.1.cmml" xref="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.2.cmml" xref="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.3.cmml" xref="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.T3.13.13.13.13.13.13.13.13.2.2.2.2">[text]</span>â€</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.15.15.15.15.15.15.15.15.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.15.15.15.15.15.15.15.15.4.2">
<span class="ltx_p" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2" style="width:256.1pt;"><span class="ltx_text ltx_font_typewriter" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.1" style="color:#0000FF;">concat</span>([<span class="ltx_text ltx_font_typewriter" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.2" style="color:#0000FF;">PPEP</span>(<math alttext="P_{1}" class="ltx_Math" display="inline" id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1"><semantics id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1a"><msub id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1" xref="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.cmml"><mi id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.2" xref="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.2.cmml">P</mi><mn id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.3" xref="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1b"><apply id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.cmml" xref="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.1.cmml" xref="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.2.cmml" xref="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.2">ğ‘ƒ</ci><cn id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.3.cmml" type="integer" xref="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1c">P_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.14.14.14.14.14.14.14.14.3.1.1.m1.1d">italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>), â€¦, <span class="ltx_text ltx_font_typewriter" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.3" style="color:#0000FF;">PPEP</span>(<math alttext="P_{n}" class="ltx_Math" display="inline" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1"><semantics id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1a"><msub id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1" xref="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.cmml"><mi id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.2" xref="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.3" xref="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1b"><apply id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.cmml" xref="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.1.cmml" xref="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.2.cmml" xref="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.3.cmml" xref="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1c">P_{n}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>)], <span class="ltx_text" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.4" style="color:#808080;">â€œ, and â€</span>). <span class="ltx_text ltx_font_typewriter" id="A1.T3.15.15.15.15.15.15.15.15.4.2.2.5" style="color:#FF0000;">[INPUT]</span></span>
</span></span></span>
<span class="ltx_tr" id="A1.T3.19.19.19.19.19.19.19.19">
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.19.19.19.19.19.19.19.19.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.19.19.19.19.19.19.19.19.5.1">
<span class="ltx_p" id="A1.T3.19.19.19.19.19.19.19.19.5.1.1" style="width:113.8pt;">5: Scholarly Title Generation</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.17.17.17.17.17.17.17.17.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.17.17.17.17.17.17.17.17.2.2">
<span class="ltx_p" id="A1.T3.17.17.17.17.17.17.17.17.2.2.2" style="width:199.2pt;">â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1"><semantics id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1a"><msub id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1" xref="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.cmml"><mi id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.2" xref="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.2.cmml">P</mi><mi id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.3" xref="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1b"><apply id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.cmml" xref="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.1.cmml" xref="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.2.cmml" xref="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.3.cmml" xref="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.16.16.16.16.16.16.16.16.1.1.1.m1.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.1">[title]</span>â€ is the title for â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1"><semantics id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1a"><msub id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1" xref="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.cmml"><mi id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.2" xref="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.3" xref="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1b"><apply id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.cmml" xref="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.1.cmml" xref="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.2.cmml" xref="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.3.cmml" xref="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.17.17.17.17.17.17.17.17.2.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>[abstract]â€</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.19.19.19.19.19.19.19.19.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.19.19.19.19.19.19.19.19.4.2">
<span class="ltx_p" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2" style="width:256.1pt;"><span class="ltx_text ltx_font_typewriter" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.1" style="color:#0000FF;">concat</span>([<span class="ltx_text ltx_font_typewriter" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.2" style="color:#0000FF;">PPEP</span>(<math alttext="P_{1}" class="ltx_Math" display="inline" id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1"><semantics id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1a"><msub id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1" xref="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.cmml"><mi id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.2" xref="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.2.cmml">P</mi><mn id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.3" xref="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1b"><apply id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.cmml" xref="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.1.cmml" xref="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.2.cmml" xref="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.2">ğ‘ƒ</ci><cn id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.3.cmml" type="integer" xref="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1c">P_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.18.18.18.18.18.18.18.18.3.1.1.m1.1d">italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>), â€¦, <span class="ltx_text ltx_font_typewriter" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.3" style="color:#0000FF;">PPEP</span>(<math alttext="P_{n}" class="ltx_Math" display="inline" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1"><semantics id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1a"><msub id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1" xref="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.cmml"><mi id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.2" xref="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.3" xref="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1b"><apply id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.cmml" xref="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.1.cmml" xref="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.2.cmml" xref="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.3.cmml" xref="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1c">P_{n}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>)], <span class="ltx_text" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.4" style="color:#808080;">â€œ, and ""</span>)<span class="ltx_text" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.5" style="color:#808080;">. Following the given patterns</span> <span class="ltx_text ltx_font_typewriter" id="A1.T3.19.19.19.19.19.19.19.19.4.2.2.6" style="color:#FF0000;">[INPUT]</span></span>
</span></span></span>
<span class="ltx_tr" id="A1.T3.23.23.23.23.23.23.23.23">
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.23.23.23.23.23.23.23.23.5">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.23.23.23.23.23.23.23.23.5.1">
<span class="ltx_p" id="A1.T3.23.23.23.23.23.23.23.23.5.1.1" style="width:113.8pt;">6: Email Subject Generation</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.21.21.21.21.21.21.21.21.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.21.21.21.21.21.21.21.21.2.2">
<span class="ltx_p" id="A1.T3.21.21.21.21.21.21.21.21.2.2.2" style="width:199.2pt;">â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1"><semantics id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1a"><msub id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1" xref="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.cmml"><mi id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.2" xref="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.2.cmml">P</mi><mi id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.3" xref="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1b"><apply id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.cmml" xref="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.1.cmml" xref="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.2.cmml" xref="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.3.cmml" xref="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.20.20.20.20.20.20.20.20.1.1.1.m1.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.1">[title]</span>â€ is the title for â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1"><semantics id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1a"><msub id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1" xref="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.cmml"><mi id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.2" xref="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.3" xref="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1b"><apply id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.cmml" xref="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.1.cmml" xref="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.2.cmml" xref="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.3.cmml" xref="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.T3.21.21.21.21.21.21.21.21.2.2.2.2">[text]</span>â€</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.T3.23.23.23.23.23.23.23.23.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.23.23.23.23.23.23.23.23.4.2">
<span class="ltx_p" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2" style="width:256.1pt;"><span class="ltx_text ltx_font_typewriter" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.1" style="color:#0000FF;">concat</span>([<span class="ltx_text ltx_font_typewriter" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.2" style="color:#0000FF;">PPEP</span>(<math alttext="P_{1}" class="ltx_Math" display="inline" id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1"><semantics id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1a"><msub id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1" xref="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.cmml"><mi id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.2" xref="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.2.cmml">P</mi><mn id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.3" xref="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1b"><apply id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.cmml" xref="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.1.cmml" xref="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.2.cmml" xref="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.2">ğ‘ƒ</ci><cn id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.3.cmml" type="integer" xref="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1c">P_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.22.22.22.22.22.22.22.22.3.1.1.m1.1d">italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>), â€¦, <span class="ltx_text ltx_font_typewriter" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.3" style="color:#0000FF;">PPEP</span>(<math alttext="P_{n}" class="ltx_Math" display="inline" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1"><semantics id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1a"><msub id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1" xref="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.cmml"><mi id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.2" xref="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.3" xref="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1b"><apply id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.cmml" xref="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.1.cmml" xref="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.2.cmml" xref="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.3.cmml" xref="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1c">P_{n}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>)], <span class="ltx_text" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.4" style="color:#808080;">â€œ, and â€</span>). <span class="ltx_text ltx_font_typewriter" id="A1.T3.23.23.23.23.23.23.23.23.4.2.2.5" style="color:#FF0000;">[INPUT]</span></span>
</span></span></span>
<span class="ltx_tr" id="A1.T3.26.26.26.26.26.26.26.26">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T3.26.26.26.26.26.26.26.26.4">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.26.26.26.26.26.26.26.26.4.1">
<span class="ltx_p" id="A1.T3.26.26.26.26.26.26.26.26.4.1.1" style="width:113.8pt;">7: Tweet Paraphrasing</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T3.24.24.24.24.24.24.24.24.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.24.24.24.24.24.24.24.24.1.1">
<span class="ltx_p" id="A1.T3.24.24.24.24.24.24.24.24.1.1.1" style="width:199.2pt;">â€œ<math alttext="P_{i}" class="ltx_Math" display="inline" id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1"><semantics id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1a"><msub id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1" xref="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.cmml"><mi id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.2" xref="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.2.cmml">P</mi><mi id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.3" xref="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1b"><apply id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.cmml" xref="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.1.cmml" xref="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.2.cmml" xref="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.3.cmml" xref="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.m1.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_typewriter" id="A1.T3.24.24.24.24.24.24.24.24.1.1.1.1">[text]</span>â€</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T3.26.26.26.26.26.26.26.26.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T3.26.26.26.26.26.26.26.26.3.2">
<span class="ltx_p" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2" style="width:256.1pt;"><span class="ltx_text ltx_font_typewriter" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.1" style="color:#0000FF;">concat</span>([<span class="ltx_text ltx_font_typewriter" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.2" style="color:#0000FF;">PPEP</span>(<math alttext="P_{1}" class="ltx_Math" display="inline" id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1"><semantics id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1a"><msub id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1" xref="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.cmml"><mi id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.2" xref="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.2.cmml">P</mi><mn id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.3" xref="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1b"><apply id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.cmml" xref="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.1.cmml" xref="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1">subscript</csymbol><ci id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.2.cmml" xref="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.2">ğ‘ƒ</ci><cn id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.3.cmml" type="integer" xref="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1c">P_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.25.25.25.25.25.25.25.25.2.1.1.m1.1d">italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>), â€¦, <span class="ltx_text ltx_font_typewriter" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.3" style="color:#0000FF;">PPEP</span>(<math alttext="P_{n}" class="ltx_Math" display="inline" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1"><semantics id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1a"><msub id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1" xref="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.cmml"><mi id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.2" xref="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.2.cmml">P</mi><mi id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.3" xref="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1b"><apply id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.cmml" xref="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.1.cmml" xref="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1">subscript</csymbol><ci id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.2.cmml" xref="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.2">ğ‘ƒ</ci><ci id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.3.cmml" xref="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1c">P_{n}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>)], <span class="ltx_text" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.4" style="color:#808080;">â€œ, and â€</span>) <span class="ltx_text" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.5" style="color:#808080;">are written by a person. Following the given patterns</span> <span class="ltx_text ltx_font_typewriter" id="A1.T3.26.26.26.26.26.26.26.26.3.2.2.6" style="color:#FF0000;">[INPUT]</span></span>
</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Prompts template used to augment the input of the LM with the user profile, following <cite class="ltx_cite ltx_citemacro_citet">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>. <span class="ltx_text ltx_font_typewriter" id="A1.T3.32.1" style="color:#0000FF;">concat</span> is a function that <span class="ltx_text ltx_font_typewriter" id="A1.T3.33.2">concat</span>enates the strings in its first argument by placing the string in the second argument between them. <span class="ltx_text ltx_font_typewriter" id="A1.T3.34.3" style="color:#0000FF;">add_to_paper_title</span> is a function designed to add the string in its first argument to the paperâ€™s title in the Personalized Citation Identification task. <span class="ltx_text ltx_font_typewriter" id="A1.T3.35.4" style="color:#0000FF;">PPEP</span> is a function that create the prompt for each entry in the retrieved profile entries. <span class="ltx_text ltx_font_typewriter" id="A1.T3.36.5" style="color:#FF0000;">[INPUT]</span> is the taskâ€™s input.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">RAG Configuration.</h4>
<div class="ltx_para" id="A1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p1.1">For personalization LLMs using retreival-augmentation , we adopt the experimental setup used by <cite class="ltx_cite ltx_citemacro_citet">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib37" title="">2024a</a>)</cite>. Specifically, we employ the BM25 <cite class="ltx_cite ltx_citemacro_cite">Robertson etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib35" title="">1994</a>)</cite> retrieval model implemented in the <span class="ltx_text ltx_font_italic" id="A1.SS0.SSS0.Px2.p1.1.1">rank_bm25</span> library<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>This library can be find at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/dorianbrown/rank_bm25" title="">https://github.com/dorianbrown/rank_bm25</a></span></span></span>, as well as Contriever <cite class="ltx_cite ltx_citemacro_cite">Izacard etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib13" title="">2022</a>)</cite>, Recency, and RSPG <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib37" title="">2024a</a>)</cite>. In all experiments, we retrieve <math alttext="k=4" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="A1.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="A1.SS0.SSS0.Px2.p1.1.m1.1.1" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">k</mi><mo id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">=</mo><mn id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1"><eq id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.1"></eq><ci id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.2">ğ‘˜</ci><cn id="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="A1.SS0.SSS0.Px2.p1.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px2.p1.1.m1.1c">k=4</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px2.p1.1.m1.1d">italic_k = 4</annotation></semantics></math> documents to personalize the LLM. Following <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>, we utilize FlanT5-XXL <cite class="ltx_cite ltx_citemacro_cite">Chung etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib5" title="">2024</a>)</cite> with 11 billion parameters as the LLM in our experiments. We configure the model with an input length of 512 tokens and an output length of 128 tokens. For generating outputs, we use beam search <cite class="ltx_cite ltx_citemacro_cite">Freitag and Al-Onaizan (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib7" title="">2017</a>)</cite> with a beam size of 4.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">PEFT Configuration.</h4>
<div class="ltx_para" id="A1.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px3.p1.4">To train the LLMs for each user, we use the PEFT library<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Available at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/docs/peft/en/index" title="">https://huggingface.co/docs/peft/en/index</a></span></span></span>. We train the models for 50 epochs on each user profile with a learning rate of <math alttext="5\times 10^{-4}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px3.p1.1.m1.1"><semantics id="A1.SS0.SSS0.Px3.p1.1.m1.1a"><mrow id="A1.SS0.SSS0.Px3.p1.1.m1.1.1" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.cmml"><mn id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.2" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.2.cmml">5</mn><mo id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.1.cmml">Ã—</mo><msup id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.cmml"><mn id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.2" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.2.cmml">10</mn><mrow id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3.cmml"><mo id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3a" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3.2" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px3.p1.1.m1.1b"><apply id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1"><times id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.1"></times><cn id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.2.cmml" type="integer" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.2">5</cn><apply id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.1.cmml" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3">superscript</csymbol><cn id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.2.cmml" type="integer" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.2">10</cn><apply id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3.cmml" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3"><minus id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3.1.cmml" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3"></minus><cn id="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3.2.cmml" type="integer" xref="A1.SS0.SSS0.Px3.p1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px3.p1.1.m1.1c">5\times 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px3.p1.1.m1.1d">5 Ã— 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>, applying 5% of the steps as warmup with linear scheduler. The Adam optimizer <cite class="ltx_cite ltx_citemacro_cite">Kingma and Ba (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib19" title="">2015</a>)</cite> is used with a weight decay of <math alttext="10^{-4}" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px3.p1.2.m2.1"><semantics id="A1.SS0.SSS0.Px3.p1.2.m2.1a"><msup id="A1.SS0.SSS0.Px3.p1.2.m2.1.1" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1.cmml"><mn id="A1.SS0.SSS0.Px3.p1.2.m2.1.1.2" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml">10</mn><mrow id="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml"><mo id="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3a" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml">âˆ’</mo><mn id="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3.2" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px3.p1.2.m2.1b"><apply id="A1.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1">superscript</csymbol><cn id="A1.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml" type="integer" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1.2">10</cn><apply id="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3"><minus id="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3.1.cmml" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3"></minus><cn id="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3.2.cmml" type="integer" xref="A1.SS0.SSS0.Px3.p1.2.m2.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px3.p1.2.m2.1c">10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px3.p1.2.m2.1d">10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>, and a batch size of 16 is achieved through gradient accumulation. We use LoRA with dropout rate of <math alttext="0.1" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px3.p1.3.m3.1"><semantics id="A1.SS0.SSS0.Px3.p1.3.m3.1a"><mn id="A1.SS0.SSS0.Px3.p1.3.m3.1.1" xref="A1.SS0.SSS0.Px3.p1.3.m3.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px3.p1.3.m3.1b"><cn id="A1.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" type="float" xref="A1.SS0.SSS0.Px3.p1.3.m3.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px3.p1.3.m3.1c">0.1</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px3.p1.3.m3.1d">0.1</annotation></semantics></math> and <math alttext="\alpha=32" class="ltx_Math" display="inline" id="A1.SS0.SSS0.Px3.p1.4.m4.1"><semantics id="A1.SS0.SSS0.Px3.p1.4.m4.1a"><mrow id="A1.SS0.SSS0.Px3.p1.4.m4.1.1" xref="A1.SS0.SSS0.Px3.p1.4.m4.1.1.cmml"><mi id="A1.SS0.SSS0.Px3.p1.4.m4.1.1.2" xref="A1.SS0.SSS0.Px3.p1.4.m4.1.1.2.cmml">Î±</mi><mo id="A1.SS0.SSS0.Px3.p1.4.m4.1.1.1" xref="A1.SS0.SSS0.Px3.p1.4.m4.1.1.1.cmml">=</mo><mn id="A1.SS0.SSS0.Px3.p1.4.m4.1.1.3" xref="A1.SS0.SSS0.Px3.p1.4.m4.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px3.p1.4.m4.1b"><apply id="A1.SS0.SSS0.Px3.p1.4.m4.1.1.cmml" xref="A1.SS0.SSS0.Px3.p1.4.m4.1.1"><eq id="A1.SS0.SSS0.Px3.p1.4.m4.1.1.1.cmml" xref="A1.SS0.SSS0.Px3.p1.4.m4.1.1.1"></eq><ci id="A1.SS0.SSS0.Px3.p1.4.m4.1.1.2.cmml" xref="A1.SS0.SSS0.Px3.p1.4.m4.1.1.2">ğ›¼</ci><cn id="A1.SS0.SSS0.Px3.p1.4.m4.1.1.3.cmml" type="integer" xref="A1.SS0.SSS0.Px3.p1.4.m4.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px3.p1.4.m4.1c">\alpha=32</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px3.p1.4.m4.1d">italic_Î± = 32</annotation></semantics></math> in all experiments. LoRA is applied to all keys, queries, and values in the transformer <cite class="ltx_cite ltx_citemacro_cite">Vaswani etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib45" title="">2017</a>)</cite>. Following <cite class="ltx_cite ltx_citemacro_cite">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>, we use FlanT5-XXL <cite class="ltx_cite ltx_citemacro_cite">Chung etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib5" title="">2024</a>)</cite> with 11 billion parameters as the LLM in our experiments. The model is configured with an input length of 512 tokens and an output length of 128 tokens. For generating outputs, we use beam search <cite class="ltx_cite ltx_citemacro_cite">Freitag and Al-Onaizan (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib7" title="">2017</a>)</cite> with a beam size of 4. We train the model on up to 32 Nvidia A100 GPUs with 80GB VRAM and 128GB RAM for up to 7 days. In total, over 10,000 GPU hours have been used for the experiments reported in this paper. To reduce the cost of training LLMs per user, we train an LLM only for each user present in the test sets, rather than for all users in the benchmark. In total, 37,560 adapters were trained, which occupy approximately 18 TB of disk space.</p>
</div>
<figure class="ltx_table" id="A1.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T4.2" style="width:433.6pt;height:195.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-118.7pt,53.5pt) scale(0.64624,0.64624) ;">
<p class="ltx_p" id="A1.T4.2.2"><span class="ltx_text" id="A1.T4.2.2.2">
<span class="ltx_inline-block ltx_transformed_outer" id="A1.T4.2.2.2.2" style="width:671.0pt;height:302.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="A1.T4.2.2.2.2.2"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T4.2.2.2.2.2.2.2">
<span class="ltx_thead">
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r" id="A1.T4.2.2.2.2.2.2.2.2.3"><span class="ltx_text ltx_font_bold" id="A1.T4.2.2.2.2.2.2.2.2.3.1">Dataset</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="A1.T4.2.2.2.2.2.2.2.2.4"><span class="ltx_text ltx_font_bold" id="A1.T4.2.2.2.2.2.2.2.2.4.1">Profile Format</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r" id="A1.T4.1.1.1.1.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.1.1.1.1.1.1.1.1.1">
<span class="ltx_p" id="A1.T4.1.1.1.1.1.1.1.1.1.1.1" style="width:284.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1">Generated Input (<math alttext="x_{i}" class="ltx_Math" display="inline" id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><msub id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">x</mi><mi id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2">ğ‘¥</ci><ci id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T4.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>)</span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T4.2.2.2.2.2.2.2.2.2"><span class="ltx_text ltx_font_bold" id="A1.T4.2.2.2.2.2.2.2.2.2.1">Generated Output (<math alttext="y_{i}" class="ltx_Math" display="inline" id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1"><semantics id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1a"><msub id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1" xref="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.cmml"><mi id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.2" xref="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.2.cmml">y</mi><mi id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.3" xref="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1b"><apply id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.cmml" xref="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.1.cmml" xref="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1">subscript</csymbol><ci id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.2.cmml" xref="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.2">ğ‘¦</ci><ci id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.3.cmml" xref="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.T4.2.2.2.2.2.2.2.2.2.1.m1.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>)</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.3.1">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.3.1.1"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.3.1.1.1">
<span class="ltx_inline-block ltx_align_left" id="A1.T4.2.2.2.2.2.2.2.3.1.1.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.3.1.1.1.1.1">LaMP-1: Personalized</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.3.1.1.1.1.2">Citation Identification</span>
</span></span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.3.1.2">title: [title]</span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.3.1.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.2.2.2.2.2.2.2.3.1.3.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.3.1.3.1.1" style="width:284.5pt;"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.3.1.3.1.1.1">Write an abstract for this title: [title]</span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.3.1.4"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.3.1.4.1">[abstract]</span></span></span>
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.4.2">
<span class="ltx_td ltx_align_center ltx_border_r" id="A1.T4.2.2.2.2.2.2.2.4.2.1">abstract: [abstract]</span></span>
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.5.3">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.5.3.1"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.5.3.1.1">
<span class="ltx_inline-block ltx_align_left" id="A1.T4.2.2.2.2.2.2.2.5.3.1.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.1.1.1.1">LaMP-2: Personalized</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.1.1.1.2">Movie Tagging</span>
</span></span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.5.3.2"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.5.3.2.1">
<span class="ltx_inline-block ltx_align_center" id="A1.T4.2.2.2.2.2.2.2.5.3.2.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.2.1.1.1">description: [description]</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.2.1.1.2">tag: [tag]</span>
</span></span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.5.3.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.2.2.2.2.2.2.2.5.3.3.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.3.1.1" style="width:284.5pt;"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.5.3.3.1.1.1">
<span class="ltx_inline-block ltx_align_left" id="A1.T4.2.2.2.2.2.2.2.5.3.3.1.1.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.3.1.1.1.1.1">Which tag does this movie relate to among the following tags?</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.3.1.1.1.1.2">Just answer with the tag name without further explanation.</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.3.1.1.1.1.3">tags: [sci-fi, based on a book, comedy, action, twist ending,</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.3.1.1.1.1.4">dystopia, dark comedy, classic, psychology, fantasy, romance,</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.3.1.1.1.1.5">thought-provoking, social commentary, violence, true story]</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.5.3.3.1.1.1.1.6">description: [description]</span>
</span></span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.5.3.4"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.5.3.4.1">[tag]</span></span></span>
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.6.4">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.6.4.1"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.6.4.1.1">
<span class="ltx_inline-block ltx_align_left" id="A1.T4.2.2.2.2.2.2.2.6.4.1.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.6.4.1.1.1.1">LaMP-3: Personalized</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.6.4.1.1.1.2">Product Rating</span>
</span></span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.6.4.2"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.6.4.2.1">
<span class="ltx_inline-block ltx_align_left" id="A1.T4.2.2.2.2.2.2.2.6.4.2.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.6.4.2.1.1.1">review: [review]</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.6.4.2.1.1.2">score: [score]</span>
</span></span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.6.4.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.2.2.2.2.2.2.2.6.4.3.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.6.4.3.1.1" style="width:284.5pt;"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.6.4.3.1.1.1">
<span class="ltx_inline-block ltx_align_left" id="A1.T4.2.2.2.2.2.2.2.6.4.3.1.1.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.6.4.3.1.1.1.1.1">What is the score of the following review on a scale of 1 to 5?</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.6.4.3.1.1.1.1.2">just answer with 1, 2, 3, 4, or 5 without further explanation.</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.6.4.3.1.1.1.1.3">review: [review]</span>
</span></span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.6.4.4"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.6.4.4.1">[score]</span></span></span>
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.7.5">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.7.5.1"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.7.5.1.1">
<span class="ltx_inline-block ltx_align_left" id="A1.T4.2.2.2.2.2.2.2.7.5.1.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.7.5.1.1.1.1">LaMP-4: Personalized</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.7.5.1.1.1.2">News Headline Generation</span>
</span></span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.7.5.2">article: [article]</span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.7.5.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.2.2.2.2.2.2.2.7.5.3.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.7.5.3.1.1" style="width:284.5pt;"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.7.5.3.1.1.1">Generate a headline for the following article: [article]</span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.7.5.4"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.7.5.4.1">[title]</span></span></span>
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.8.6">
<span class="ltx_td ltx_align_center ltx_border_r" id="A1.T4.2.2.2.2.2.2.2.8.6.1">title: [title]</span></span>
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.9.7">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.9.7.1"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.9.7.1.1">
<span class="ltx_inline-block ltx_align_left" id="A1.T4.2.2.2.2.2.2.2.9.7.1.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.9.7.1.1.1.1">LaMP-5: Personalized</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.9.7.1.1.1.2">Scholarly Title Generation</span>
</span></span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.9.7.2">abstract: [abstract]</span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.9.7.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.2.2.2.2.2.2.2.9.7.3.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.9.7.3.1.1" style="width:284.5pt;"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.9.7.3.1.1.1">Generate a title for the following abstract of a paper: [abstract]</span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.9.7.4"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.9.7.4.1">[title]</span></span></span>
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.10.8">
<span class="ltx_td ltx_align_center ltx_border_r" id="A1.T4.2.2.2.2.2.2.2.10.8.1">title: [title]</span></span>
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.11.9">
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.11.9.1"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.11.9.1.1">
<span class="ltx_inline-block ltx_align_left" id="A1.T4.2.2.2.2.2.2.2.11.9.1.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.11.9.1.1.1.1">LaMP-6: Personalized</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.11.9.1.1.1.2">Email Subject Generation</span>
</span></span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.11.9.2">email: [email]</span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.11.9.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.2.2.2.2.2.2.2.11.9.3.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.11.9.3.1.1" style="width:284.5pt;"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.11.9.3.1.1.1">Generate a subject for the following email: [email]</span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_border_t ltx_rowspan ltx_rowspan_2" id="A1.T4.2.2.2.2.2.2.2.11.9.4"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.11.9.4.1">[title]</span></span></span>
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.12.10">
<span class="ltx_td ltx_align_center ltx_border_r" id="A1.T4.2.2.2.2.2.2.2.12.10.1">title: [title]</span></span>
<span class="ltx_tr" id="A1.T4.2.2.2.2.2.2.2.13.11">
<span class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.13.11.1"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.13.11.1.1">
<span class="ltx_inline-block ltx_align_left" id="A1.T4.2.2.2.2.2.2.2.13.11.1.1.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.13.11.1.1.1.1">LaMP-7: Personalized</span>
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.13.11.1.1.1.2">Tweet Paraphrasing</span>
</span></span></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.13.11.2"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.13.11.2.1">tweet: [tweet]</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.13.11.3">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.2.2.2.2.2.2.2.13.11.3.1">
<span class="ltx_p" id="A1.T4.2.2.2.2.2.2.2.13.11.3.1.1" style="width:284.5pt;"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.13.11.3.1.1.1">Complete the following tweet: [first part of the tweet]</span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T4.2.2.2.2.2.2.2.13.11.4"><span class="ltx_text" id="A1.T4.2.2.2.2.2.2.2.13.11.4.1">[second part of the tweet]</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>The implementation of the input-output generation function for PEFT personalization. The profiles in LaMP-2, LaMP-3, LaMP-4, LaMP-5, and LaMP-7 consist of input-output pairs for the user, which are directly used as training pairs. However, for the LaMP-1 and LaMP-7 tasks, such pairs do not exist. For LaMP-1, we provide the model with a title and ask it to generate the abstract. For LaMP-7, we randomly divide a tweet into two parts and ask the model to generate the second part based on the first part.</figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Implementation of <math alttext="\phi_{q}" class="ltx_Math" display="inline" id="A2.1.m1.1"><semantics id="A2.1.m1.1b"><msub id="A2.1.m1.1.1" xref="A2.1.m1.1.1.cmml"><mi id="A2.1.m1.1.1.2" xref="A2.1.m1.1.1.2.cmml">Ï•</mi><mi id="A2.1.m1.1.1.3" xref="A2.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="A2.1.m1.1c"><apply id="A2.1.m1.1.1.cmml" xref="A2.1.m1.1.1"><csymbol cd="ambiguous" id="A2.1.m1.1.1.1.cmml" xref="A2.1.m1.1.1">subscript</csymbol><ci id="A2.1.m1.1.1.2.cmml" xref="A2.1.m1.1.1.2">italic-Ï•</ci><ci id="A2.1.m1.1.1.3.cmml" xref="A2.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.1.m1.1d">\phi_{q}</annotation><annotation encoding="application/x-llamapun" id="A2.1.m1.1e">italic_Ï• start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\phi_{p}" class="ltx_Math" display="inline" id="A2.2.m2.1"><semantics id="A2.2.m2.1b"><msub id="A2.2.m2.1.1" xref="A2.2.m2.1.1.cmml"><mi id="A2.2.m2.1.1.2" xref="A2.2.m2.1.1.2.cmml">Ï•</mi><mi id="A2.2.m2.1.1.3" xref="A2.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="A2.2.m2.1c"><apply id="A2.2.m2.1.1.cmml" xref="A2.2.m2.1.1"><csymbol cd="ambiguous" id="A2.2.m2.1.1.1.cmml" xref="A2.2.m2.1.1">subscript</csymbol><ci id="A2.2.m2.1.1.2.cmml" xref="A2.2.m2.1.1.2">italic-Ï•</ci><ci id="A2.2.m2.1.1.3.cmml" xref="A2.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.2.m2.1d">\phi_{p}</annotation><annotation encoding="application/x-llamapun" id="A2.2.m2.1e">italic_Ï• start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> for RAG Personalization</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">To implement the query generation function <math alttext="\phi_{q}" class="ltx_Math" display="inline" id="A2.p1.1.m1.1"><semantics id="A2.p1.1.m1.1a"><msub id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml"><mi id="A2.p1.1.m1.1.1.2" xref="A2.p1.1.m1.1.1.2.cmml">Ï•</mi><mi id="A2.p1.1.m1.1.1.3" xref="A2.p1.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><apply id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.p1.1.m1.1.1.1.cmml" xref="A2.p1.1.m1.1.1">subscript</csymbol><ci id="A2.p1.1.m1.1.1.2.cmml" xref="A2.p1.1.m1.1.1.2">italic-Ï•</ci><ci id="A2.p1.1.m1.1.1.3.cmml" xref="A2.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">\phi_{q}</annotation><annotation encoding="application/x-llamapun" id="A2.p1.1.m1.1d">italic_Ï• start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math>, following <cite class="ltx_cite ltx_citemacro_citet">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>, we extract and use the non-template portions of the userâ€™s input prompt as the query. For further details on the template used for generating inputs in the LaMP benchmark, we refer the reader to <cite class="ltx_cite ltx_citemacro_citet">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite>. Additionally, we use the same function as <cite class="ltx_cite ltx_citemacro_citet">Salemi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#bib.bib38" title="">2024b</a>)</cite> to generate personalized prompts for the LLM, as detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1.T3" title="Table 3 â€£ Tasks &amp; Datasets. â€£ Appendix A Experiments Setup â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Implementation of CONVERT function for PEFT Personalization</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">The implementation of the input-output generation function for PEFT personalization involves different approaches depending on the task, as shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09510v1#A1.T4" title="Table 4 â€£ PEFT Configuration. â€£ Appendix A Experiments Setup â€£ Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>. For LaMP-2, LaMP-3, LaMP-4, LaMP-5, and LaMP-7, user profiles contain input-output pairs that are directly used for training. However, tasks LaMP-1 and LaMP-7 require different strategies since such pairs are unavailable. In LaMP-1, the model is given a title and tasked with generating the corresponding abstract. For LaMP-7, a tweet is randomly split into two sections, and the model is asked to generate the second part based on the first.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Sep 14 19:17:14 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
