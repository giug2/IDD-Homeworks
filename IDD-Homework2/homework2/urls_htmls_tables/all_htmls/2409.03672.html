<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.03672] Wind turbine condition monitoring based on intra- and inter-farm federated learning</title><meta property="og:description" content="As wind energy adoption is growing, ensuring the efficient operation and maintenance of wind turbines becomes essential for maximizing energy production and minimizing costs and downtime. Many AI applications in wind e…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Wind turbine condition monitoring based on intra- and inter-farm federated learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Wind turbine condition monitoring based on intra- and inter-farm federated learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.03672">

<!--Generated on Sun Oct  6 00:32:37 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_fleqn">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\MakePerPage</span>
<p id="p1.2" class="ltx_p">footnote









</p>
</div>
<h1 class="ltx_title ltx_title_document">Wind turbine condition monitoring based on intra- and inter-farm federated learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Albin Grataloup
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:albin.grataloup@bfh.ch">albin.grataloup@bfh.ch</a>
</span>
<span class="ltx_contact ltx_role_address">Bern University of Applied Sciences, School of Engineering and Computer Science, Quellgasse 21, 2501 Biel, Switzerland 
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Stefan Jonas
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:stefan.jonas@bfh.ch">stefan.jonas@bfh.ch</a>
</span>
<span class="ltx_contact ltx_role_address">Università della Svizzera italiana, Faculty of Informatics, Via la Santa 1, 6962 Lugano-Viganello, Switzerland
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Angela Meyer
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:angela.meyer@bfh.ch">angela.meyer@bfh.ch</a>
</span>
<span class="ltx_contact ltx_role_address">Delft University of Technology, Department of Geoscience and Remote Sensing, Stevinweg 1, 2628 Delft, The Netherlands
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">As wind energy adoption is growing, ensuring the efficient operation and maintenance of wind turbines becomes essential for maximizing energy production and minimizing costs and downtime. Many AI applications in wind energy, such as in condition monitoring and power forecasting, may benefit from using operational data not only from individual wind turbines but from multiple turbines and multiple wind farms. Collaborative distributed AI which preserves data privacy holds a strong potential for these applications. Federated learning has emerged as a privacy-preserving distributed machine learning approach in this context. We explore federated learning in wind turbine condition monitoring, specifically for fault detection using normal behaviour models. We investigate various federated learning strategies, including collaboration across different wind farms and turbine models, as well as collaboration restricted to the same wind farm and turbine model. Our case study results indicate that federated learning across multiple wind turbines consistently outperforms models trained on a single turbine, especially when training data is scarce. Moreover, the amount of historical data necessary to train an effective model can be significantly reduced by employing a collaborative federated learning strategy. Finally, our findings show that extending the collaboration to multiple wind farms may result in inferior performance compared to restricting learning within a farm, specifically when faced with statistical heterogeneity and imbalanced datasets.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
wind turbines, wind farms, federated learning, condition monitoring, normal behaviour model , fault detection , distributed , collaborative , privacy-preserving, wind energy , wind farm clusters, industrial fleets

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The deployment of wind turbines for renewable energy generation is witnessing exponential growth globally <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, driven by the transition towards sustainable energy sources. Ensuring the efficient and reliable operation of wind turbines is critical to maximizing energy production and minimizing downtime and maintenance costs. Condition monitoring and anomaly detection play a pivotal role, offering insights into the health and performance of critical components. Deep learning methods, in particular, have risen as an efficient approach to anomaly detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. However, the demanding data prerequisites of deep learning models present a major challenge as they necessitate either an abundance of labeled data from faulty operation or, in our scenario, a large amount of fault-free data for training a <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">normal behaviour model</em> (NBM). A NBM operates by predicting target variables like component temperatures or power output that are crucial for assessing system health or performance. Anomalies are identified when the predicted target variable diverges significantly from the measured value of the target variable, such as detecting an abnormal spike in component temperatures compared to the system’s normal operational values. Condition monitoring and anomaly detection are extensively studied fields within the area of wind turbine operations. In recent years, deep learning has emerged as a particularly promising approach for condition-monitoring tasks. Among the methodologies employed, NBMs have gained prominence. These models rely on the comparison between critical features measured in wind turbines and their corresponding predicted values, serving as indicator for assessing wind turbine health <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Training an effective NBM requires a substantial amount of data, which can be time-consuming or even impractical to obtain. For wind turbines, the fastest way to amass sufficient data is by collecting training data from multiple turbines. However, this approach raises significant data privacy concerns as manufacturers and operators are hesitant to share operational data due to strategic business interests <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. A single wind turbine would require a significant amount of time to gather enough data to train a representative and accurate NBM. To address this issue, we propose privacy-preserving collaborative learning methods to leverage training data collected from multiple wind turbines simultaneously. Federated Learning (FL) emerged as a promising paradigm to address these challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. FL enables collaborative decentralised model training across multiple wind turbines while preserving their data privacy. By exchanging only FL model parameters and not operational data, the sensitive operation data of each wind turbine remains local and inaccessible to others. This approach allows wind turbines to collaboratively train an effective NBM with less data, without compromising their privacy.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Federated learning has gained traction across various domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. It was also adopted in renewable energy sectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, notably in wind energy applications, for tasks such as wind power forecasting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, to obtain significantly more accurate forecasts compared to local models. It also has shown promising results in fault detection applications, exhibiting improved performance over local training methodologies for tasks such as blade icing detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, fault detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and condition monitoring with an NBM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Despite these advancements, the application of FL for training NBMs for wind turbines remains largely unexplored. By investigating collaborative NBM training across multiple wind turbines and wind farms, our study builds upon previous work on the potential of FL for training NBMs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. We assess the benefits and limits of collaboration particularly by addressing the effect of statistical heterogeneity between different wind turbines and wind farms. We also analyse how FL affects the time required to collect training data for a NBM through collaborative learning of multiple wind turbines.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The objectives of our study are twofold: First, we assess the effectiveness of collaborative federated learning strategies among wind turbines of multiple wind farms, comparing intra- and inter-farm collaborative federated learning (Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). Second, we quantify the time savings in collecting training data for a NBM through collaborative FL across multiple wind turbines compared to collecting training data from a single WT (referred to as ”local” data).</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2409.03672/assets/img/Figure1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="5064" height="2436" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Left: Intra-farm learning, only the turbines from the same wind farms collaborate. Right: Collaborative inter-farm learning on the turbines of all wind farms.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Federated learning for condition monitoring of wind turbines</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">FL is a collaborative deep-learning framework that involves distributed participants referred to as clients. In our scenario, each wind turbine acts as an individual client and aims to collaboratively train a machine learning model for condition monitoring. In FL, it is crucial that the clients never share their locally stored data in order to preserve data privacy. The iterative FL training process involves that clients train local models, such as a NBM, using only their private local dataset, and then transmit the model parameters to a central server where they are aggregated. This approach ensures the privacy of locally stored client data and can provide a viable solution to overcome data scarcity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. FL with a central server involves the following iterative steps:</p>
</div>
<figure id="S2.fig1" class="ltx_figure">
<figure id="alg1" class="ltx_float ltx_minipage ltx_align_middle" style="width:260.2pt;">
<div id="alg1.6" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="alg1.6.7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span>
R: number of training rounds.

<br class="ltx_break">Initialization of the server model;
</div>
<div id="alg1.6.8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span>

</div>
<div id="alg1.1.1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="alg1.1.1.2" class="ltx_text ltx_font_bold">for</span> <em id="alg1.1.1.1" class="ltx_emph ltx_font_italic"><math id="alg1.1.1.1.m1.1" class="ltx_Math" alttext="t=1\cdots R" display="inline"><semantics id="alg1.1.1.1.m1.1a"><mrow id="alg1.1.1.1.m1.1.1" xref="alg1.1.1.1.m1.1.1.cmml"><mi id="alg1.1.1.1.m1.1.1.2" xref="alg1.1.1.1.m1.1.1.2.cmml">t</mi><mo id="alg1.1.1.1.m1.1.1.1" xref="alg1.1.1.1.m1.1.1.1.cmml">=</mo><mrow id="alg1.1.1.1.m1.1.1.3" xref="alg1.1.1.1.m1.1.1.3.cmml"><mn id="alg1.1.1.1.m1.1.1.3.2" xref="alg1.1.1.1.m1.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="alg1.1.1.1.m1.1.1.3.1" xref="alg1.1.1.1.m1.1.1.3.1.cmml">​</mo><mi mathvariant="normal" id="alg1.1.1.1.m1.1.1.3.3" xref="alg1.1.1.1.m1.1.1.3.3.cmml">⋯</mi><mo lspace="0em" rspace="0em" id="alg1.1.1.1.m1.1.1.3.1a" xref="alg1.1.1.1.m1.1.1.3.1.cmml">​</mo><mi id="alg1.1.1.1.m1.1.1.3.4" xref="alg1.1.1.1.m1.1.1.3.4.cmml">R</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.1.1.1.m1.1b"><apply id="alg1.1.1.1.m1.1.1.cmml" xref="alg1.1.1.1.m1.1.1"><eq id="alg1.1.1.1.m1.1.1.1.cmml" xref="alg1.1.1.1.m1.1.1.1"></eq><ci id="alg1.1.1.1.m1.1.1.2.cmml" xref="alg1.1.1.1.m1.1.1.2">𝑡</ci><apply id="alg1.1.1.1.m1.1.1.3.cmml" xref="alg1.1.1.1.m1.1.1.3"><times id="alg1.1.1.1.m1.1.1.3.1.cmml" xref="alg1.1.1.1.m1.1.1.3.1"></times><cn type="integer" id="alg1.1.1.1.m1.1.1.3.2.cmml" xref="alg1.1.1.1.m1.1.1.3.2">1</cn><ci id="alg1.1.1.1.m1.1.1.3.3.cmml" xref="alg1.1.1.1.m1.1.1.3.3">⋯</ci><ci id="alg1.1.1.1.m1.1.1.3.4.cmml" xref="alg1.1.1.1.m1.1.1.3.4">𝑅</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.1.1.m1.1c">t=1\cdots R</annotation></semantics></math></em> <span id="alg1.1.1.3" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="alg1.6.9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
- N clients receive a global FL model from the server;
</div>
<div id="alg1.6.10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="alg1.3.3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   - All clients independently perform training updates on this model using only their local datasets <math id="alg1.2.2.m1.1" class="ltx_Math" alttext="\mathscr{D}_{i}" display="inline"><semantics id="alg1.2.2.m1.1a"><msub id="alg1.2.2.m1.1.1" xref="alg1.2.2.m1.1.1.cmml"><mi class="ltx_font_mathscript" id="alg1.2.2.m1.1.1.2" xref="alg1.2.2.m1.1.1.2.cmml">𝒟</mi><mi id="alg1.2.2.m1.1.1.3" xref="alg1.2.2.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.2.2.m1.1b"><apply id="alg1.2.2.m1.1.1.cmml" xref="alg1.2.2.m1.1.1"><csymbol cd="ambiguous" id="alg1.2.2.m1.1.1.1.cmml" xref="alg1.2.2.m1.1.1">subscript</csymbol><ci id="alg1.2.2.m1.1.1.2.cmml" xref="alg1.2.2.m1.1.1.2">𝒟</ci><ci id="alg1.2.2.m1.1.1.3.cmml" xref="alg1.2.2.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.2.m1.1c">\mathscr{D}_{i}</annotation></semantics></math>,  <math id="alg1.3.3.m2.1" class="ltx_Math" alttext="i=1\dots N" display="inline"><semantics id="alg1.3.3.m2.1a"><mrow id="alg1.3.3.m2.1.1" xref="alg1.3.3.m2.1.1.cmml"><mi id="alg1.3.3.m2.1.1.2" xref="alg1.3.3.m2.1.1.2.cmml">i</mi><mo id="alg1.3.3.m2.1.1.1" xref="alg1.3.3.m2.1.1.1.cmml">=</mo><mrow id="alg1.3.3.m2.1.1.3" xref="alg1.3.3.m2.1.1.3.cmml"><mn id="alg1.3.3.m2.1.1.3.2" xref="alg1.3.3.m2.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="alg1.3.3.m2.1.1.3.1" xref="alg1.3.3.m2.1.1.3.1.cmml">​</mo><mi mathvariant="normal" id="alg1.3.3.m2.1.1.3.3" xref="alg1.3.3.m2.1.1.3.3.cmml">…</mi><mo lspace="0em" rspace="0em" id="alg1.3.3.m2.1.1.3.1a" xref="alg1.3.3.m2.1.1.3.1.cmml">​</mo><mi id="alg1.3.3.m2.1.1.3.4" xref="alg1.3.3.m2.1.1.3.4.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.3.3.m2.1b"><apply id="alg1.3.3.m2.1.1.cmml" xref="alg1.3.3.m2.1.1"><eq id="alg1.3.3.m2.1.1.1.cmml" xref="alg1.3.3.m2.1.1.1"></eq><ci id="alg1.3.3.m2.1.1.2.cmml" xref="alg1.3.3.m2.1.1.2">𝑖</ci><apply id="alg1.3.3.m2.1.1.3.cmml" xref="alg1.3.3.m2.1.1.3"><times id="alg1.3.3.m2.1.1.3.1.cmml" xref="alg1.3.3.m2.1.1.3.1"></times><cn type="integer" id="alg1.3.3.m2.1.1.3.2.cmml" xref="alg1.3.3.m2.1.1.3.2">1</cn><ci id="alg1.3.3.m2.1.1.3.3.cmml" xref="alg1.3.3.m2.1.1.3.3">…</ci><ci id="alg1.3.3.m2.1.1.3.4.cmml" xref="alg1.3.3.m2.1.1.3.4">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.3.m2.1c">i=1\dots N</annotation></semantics></math>;

</div>
<div id="alg1.5.5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   - The clients send the parameters of their updated local models <math id="alg1.4.4.m1.1" class="ltx_Math" alttext="\mathscr{M}_{i}" display="inline"><semantics id="alg1.4.4.m1.1a"><msub id="alg1.4.4.m1.1.1" xref="alg1.4.4.m1.1.1.cmml"><mi class="ltx_font_mathscript" id="alg1.4.4.m1.1.1.2" xref="alg1.4.4.m1.1.1.2.cmml">ℳ</mi><mi id="alg1.4.4.m1.1.1.3" xref="alg1.4.4.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.4.4.m1.1b"><apply id="alg1.4.4.m1.1.1.cmml" xref="alg1.4.4.m1.1.1"><csymbol cd="ambiguous" id="alg1.4.4.m1.1.1.1.cmml" xref="alg1.4.4.m1.1.1">subscript</csymbol><ci id="alg1.4.4.m1.1.1.2.cmml" xref="alg1.4.4.m1.1.1.2">ℳ</ci><ci id="alg1.4.4.m1.1.1.3.cmml" xref="alg1.4.4.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.4.m1.1c">\mathscr{M}_{i}</annotation></semantics></math>, <math id="alg1.5.5.m2.1" class="ltx_Math" alttext="i=1\dots N" display="inline"><semantics id="alg1.5.5.m2.1a"><mrow id="alg1.5.5.m2.1.1" xref="alg1.5.5.m2.1.1.cmml"><mi id="alg1.5.5.m2.1.1.2" xref="alg1.5.5.m2.1.1.2.cmml">i</mi><mo id="alg1.5.5.m2.1.1.1" xref="alg1.5.5.m2.1.1.1.cmml">=</mo><mrow id="alg1.5.5.m2.1.1.3" xref="alg1.5.5.m2.1.1.3.cmml"><mn id="alg1.5.5.m2.1.1.3.2" xref="alg1.5.5.m2.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="alg1.5.5.m2.1.1.3.1" xref="alg1.5.5.m2.1.1.3.1.cmml">​</mo><mi mathvariant="normal" id="alg1.5.5.m2.1.1.3.3" xref="alg1.5.5.m2.1.1.3.3.cmml">…</mi><mo lspace="0em" rspace="0em" id="alg1.5.5.m2.1.1.3.1a" xref="alg1.5.5.m2.1.1.3.1.cmml">​</mo><mi id="alg1.5.5.m2.1.1.3.4" xref="alg1.5.5.m2.1.1.3.4.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.5.5.m2.1b"><apply id="alg1.5.5.m2.1.1.cmml" xref="alg1.5.5.m2.1.1"><eq id="alg1.5.5.m2.1.1.1.cmml" xref="alg1.5.5.m2.1.1.1"></eq><ci id="alg1.5.5.m2.1.1.2.cmml" xref="alg1.5.5.m2.1.1.2">𝑖</ci><apply id="alg1.5.5.m2.1.1.3.cmml" xref="alg1.5.5.m2.1.1.3"><times id="alg1.5.5.m2.1.1.3.1.cmml" xref="alg1.5.5.m2.1.1.3.1"></times><cn type="integer" id="alg1.5.5.m2.1.1.3.2.cmml" xref="alg1.5.5.m2.1.1.3.2">1</cn><ci id="alg1.5.5.m2.1.1.3.3.cmml" xref="alg1.5.5.m2.1.1.3.3">…</ci><ci id="alg1.5.5.m2.1.1.3.4.cmml" xref="alg1.5.5.m2.1.1.3.4">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.5.m2.1c">i=1\dots N</annotation></semantics></math>, to the server;
</div>
<div id="alg1.6.11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="alg1.6.6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   - The server aggregates the parameters of all models <math id="alg1.6.6.m1.1" class="ltx_Math" alttext="\mathscr{M}_{i}" display="inline"><semantics id="alg1.6.6.m1.1a"><msub id="alg1.6.6.m1.1.1" xref="alg1.6.6.m1.1.1.cmml"><mi class="ltx_font_mathscript" id="alg1.6.6.m1.1.1.2" xref="alg1.6.6.m1.1.1.2.cmml">ℳ</mi><mi id="alg1.6.6.m1.1.1.3" xref="alg1.6.6.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.6.6.m1.1b"><apply id="alg1.6.6.m1.1.1.cmml" xref="alg1.6.6.m1.1.1"><csymbol cd="ambiguous" id="alg1.6.6.m1.1.1.1.cmml" xref="alg1.6.6.m1.1.1">subscript</csymbol><ci id="alg1.6.6.m1.1.1.2.cmml" xref="alg1.6.6.m1.1.1.2">ℳ</ci><ci id="alg1.6.6.m1.1.1.3.cmml" xref="alg1.6.6.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.6.m1.1c">\mathscr{M}_{i}</annotation></semantics></math>, to obtain the updated global FL model;
</div>
<div id="alg1.6.12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="alg1.6.13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span> end for
</div>
<div id="alg1.6.14" class="ltx_listingline">
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.8.1.1" class="ltx_text ltx_font_bold">missing</span>fnum@algorithm1Algorithm 1 </span>Centralised federated learning</figcaption>
</figure>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The most widely applied FL framework is the Federated Averaging (<span id="S2.p2.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span>) algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> in which the aggregation step consists of averaging the received model parameters</p>
</div>
<div id="S2.p3" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\omega^{t+1}=\sum\limits_{i=1}^{N}\frac{n_{i}}{n}\omega_{i}^{t+1}" display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><msup id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.2.2" xref="S2.E1.m1.1.1.2.2.cmml">ω</mi><mrow id="S2.E1.m1.1.1.2.3" xref="S2.E1.m1.1.1.2.3.cmml"><mi id="S2.E1.m1.1.1.2.3.2" xref="S2.E1.m1.1.1.2.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.2.3.1" xref="S2.E1.m1.1.1.2.3.1.cmml">+</mo><mn id="S2.E1.m1.1.1.2.3.3" xref="S2.E1.m1.1.1.2.3.3.cmml">1</mn></mrow></msup><mo rspace="0.111em" id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><munderover id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.3.1.cmml"><mo movablelimits="false" id="S2.E1.m1.1.1.3.1.2.2" xref="S2.E1.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.E1.m1.1.1.3.1.2.3" xref="S2.E1.m1.1.1.3.1.2.3.cmml"><mi id="S2.E1.m1.1.1.3.1.2.3.2" xref="S2.E1.m1.1.1.3.1.2.3.2.cmml">i</mi><mo id="S2.E1.m1.1.1.3.1.2.3.1" xref="S2.E1.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.E1.m1.1.1.3.1.2.3.3" xref="S2.E1.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.1.1.3.1.3" xref="S2.E1.m1.1.1.3.1.3.cmml">N</mi></munderover><mrow id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml"><mfrac id="S2.E1.m1.1.1.3.2.2" xref="S2.E1.m1.1.1.3.2.2.cmml"><msub id="S2.E1.m1.1.1.3.2.2.2" xref="S2.E1.m1.1.1.3.2.2.2.cmml"><mi id="S2.E1.m1.1.1.3.2.2.2.2" xref="S2.E1.m1.1.1.3.2.2.2.2.cmml">n</mi><mi id="S2.E1.m1.1.1.3.2.2.2.3" xref="S2.E1.m1.1.1.3.2.2.2.3.cmml">i</mi></msub><mi id="S2.E1.m1.1.1.3.2.2.3" xref="S2.E1.m1.1.1.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.2.1" xref="S2.E1.m1.1.1.3.2.1.cmml">​</mo><msubsup id="S2.E1.m1.1.1.3.2.3" xref="S2.E1.m1.1.1.3.2.3.cmml"><mi id="S2.E1.m1.1.1.3.2.3.2.2" xref="S2.E1.m1.1.1.3.2.3.2.2.cmml">ω</mi><mi id="S2.E1.m1.1.1.3.2.3.2.3" xref="S2.E1.m1.1.1.3.2.3.2.3.cmml">i</mi><mrow id="S2.E1.m1.1.1.3.2.3.3" xref="S2.E1.m1.1.1.3.2.3.3.cmml"><mi id="S2.E1.m1.1.1.3.2.3.3.2" xref="S2.E1.m1.1.1.3.2.3.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.3.2.3.3.1" xref="S2.E1.m1.1.1.3.2.3.3.1.cmml">+</mo><mn id="S2.E1.m1.1.1.3.2.3.3.3" xref="S2.E1.m1.1.1.3.2.3.3.3.cmml">1</mn></mrow></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><eq id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"></eq><apply id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.2">superscript</csymbol><ci id="S2.E1.m1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.2.2">𝜔</ci><apply id="S2.E1.m1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.2.3"><plus id="S2.E1.m1.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.2.3.1"></plus><ci id="S2.E1.m1.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="S2.E1.m1.1.1.2.3.3.cmml" xref="S2.E1.m1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><apply id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.1.1.cmml" xref="S2.E1.m1.1.1.3.1">superscript</csymbol><apply id="S2.E1.m1.1.1.3.1.2.cmml" xref="S2.E1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.1.2.1.cmml" xref="S2.E1.m1.1.1.3.1">subscript</csymbol><sum id="S2.E1.m1.1.1.3.1.2.2.cmml" xref="S2.E1.m1.1.1.3.1.2.2"></sum><apply id="S2.E1.m1.1.1.3.1.2.3.cmml" xref="S2.E1.m1.1.1.3.1.2.3"><eq id="S2.E1.m1.1.1.3.1.2.3.1.cmml" xref="S2.E1.m1.1.1.3.1.2.3.1"></eq><ci id="S2.E1.m1.1.1.3.1.2.3.2.cmml" xref="S2.E1.m1.1.1.3.1.2.3.2">𝑖</ci><cn type="integer" id="S2.E1.m1.1.1.3.1.2.3.3.cmml" xref="S2.E1.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.1.1.3.1.3.cmml" xref="S2.E1.m1.1.1.3.1.3">𝑁</ci></apply><apply id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2"><times id="S2.E1.m1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2.1"></times><apply id="S2.E1.m1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2"><divide id="S2.E1.m1.1.1.3.2.2.1.cmml" xref="S2.E1.m1.1.1.3.2.2"></divide><apply id="S2.E1.m1.1.1.3.2.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.2.2.1.cmml" xref="S2.E1.m1.1.1.3.2.2.2">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.2.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2.2.2">𝑛</ci><ci id="S2.E1.m1.1.1.3.2.2.2.3.cmml" xref="S2.E1.m1.1.1.3.2.2.2.3">𝑖</ci></apply><ci id="S2.E1.m1.1.1.3.2.2.3.cmml" xref="S2.E1.m1.1.1.3.2.2.3">𝑛</ci></apply><apply id="S2.E1.m1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.3.1.cmml" xref="S2.E1.m1.1.1.3.2.3">superscript</csymbol><apply id="S2.E1.m1.1.1.3.2.3.2.cmml" xref="S2.E1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2.3">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2.3.2.2">𝜔</ci><ci id="S2.E1.m1.1.1.3.2.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3.2.3">𝑖</ci></apply><apply id="S2.E1.m1.1.1.3.2.3.3.cmml" xref="S2.E1.m1.1.1.3.2.3.3"><plus id="S2.E1.m1.1.1.3.2.3.3.1.cmml" xref="S2.E1.m1.1.1.3.2.3.3.1"></plus><ci id="S2.E1.m1.1.1.3.2.3.3.2.cmml" xref="S2.E1.m1.1.1.3.2.3.3.2">𝑡</ci><cn type="integer" id="S2.E1.m1.1.1.3.2.3.3.3.cmml" xref="S2.E1.m1.1.1.3.2.3.3.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\omega^{t+1}=\sum\limits_{i=1}^{N}\frac{n_{i}}{n}\omega_{i}^{t+1}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.7" class="ltx_p">where <math id="S2.p4.1.m1.1" class="ltx_Math" alttext="\omega^{t}" display="inline"><semantics id="S2.p4.1.m1.1a"><msup id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml"><mi id="S2.p4.1.m1.1.1.2" xref="S2.p4.1.m1.1.1.2.cmml">ω</mi><mi id="S2.p4.1.m1.1.1.3" xref="S2.p4.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><apply id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p4.1.m1.1.1.1.cmml" xref="S2.p4.1.m1.1.1">superscript</csymbol><ci id="S2.p4.1.m1.1.1.2.cmml" xref="S2.p4.1.m1.1.1.2">𝜔</ci><ci id="S2.p4.1.m1.1.1.3.cmml" xref="S2.p4.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">\omega^{t}</annotation></semantics></math> and <math id="S2.p4.2.m2.1" class="ltx_Math" alttext="\omega_{i}^{t}" display="inline"><semantics id="S2.p4.2.m2.1a"><msubsup id="S2.p4.2.m2.1.1" xref="S2.p4.2.m2.1.1.cmml"><mi id="S2.p4.2.m2.1.1.2.2" xref="S2.p4.2.m2.1.1.2.2.cmml">ω</mi><mi id="S2.p4.2.m2.1.1.2.3" xref="S2.p4.2.m2.1.1.2.3.cmml">i</mi><mi id="S2.p4.2.m2.1.1.3" xref="S2.p4.2.m2.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.1b"><apply id="S2.p4.2.m2.1.1.cmml" xref="S2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.1.1.1.cmml" xref="S2.p4.2.m2.1.1">superscript</csymbol><apply id="S2.p4.2.m2.1.1.2.cmml" xref="S2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.1.1.2.1.cmml" xref="S2.p4.2.m2.1.1">subscript</csymbol><ci id="S2.p4.2.m2.1.1.2.2.cmml" xref="S2.p4.2.m2.1.1.2.2">𝜔</ci><ci id="S2.p4.2.m2.1.1.2.3.cmml" xref="S2.p4.2.m2.1.1.2.3">𝑖</ci></apply><ci id="S2.p4.2.m2.1.1.3.cmml" xref="S2.p4.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.1c">\omega_{i}^{t}</annotation></semantics></math> denote the global model parameters and the model parameters of client <math id="S2.p4.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.p4.3.m3.1a"><mi id="S2.p4.3.m3.1.1" xref="S2.p4.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.p4.3.m3.1b"><ci id="S2.p4.3.m3.1.1.cmml" xref="S2.p4.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.3.m3.1c">i</annotation></semantics></math>, respectively, in training round <math id="S2.p4.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.p4.4.m4.1a"><mi id="S2.p4.4.m4.1.1" xref="S2.p4.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.p4.4.m4.1b"><ci id="S2.p4.4.m4.1.1.cmml" xref="S2.p4.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.4.m4.1c">t</annotation></semantics></math>. <math id="S2.p4.5.m5.1" class="ltx_Math" alttext="n_{i}" display="inline"><semantics id="S2.p4.5.m5.1a"><msub id="S2.p4.5.m5.1.1" xref="S2.p4.5.m5.1.1.cmml"><mi id="S2.p4.5.m5.1.1.2" xref="S2.p4.5.m5.1.1.2.cmml">n</mi><mi id="S2.p4.5.m5.1.1.3" xref="S2.p4.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p4.5.m5.1b"><apply id="S2.p4.5.m5.1.1.cmml" xref="S2.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S2.p4.5.m5.1.1.1.cmml" xref="S2.p4.5.m5.1.1">subscript</csymbol><ci id="S2.p4.5.m5.1.1.2.cmml" xref="S2.p4.5.m5.1.1.2">𝑛</ci><ci id="S2.p4.5.m5.1.1.3.cmml" xref="S2.p4.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.5.m5.1c">n_{i}</annotation></semantics></math> denotes the amount of data available to client <math id="S2.p4.6.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.p4.6.m6.1a"><mi id="S2.p4.6.m6.1.1" xref="S2.p4.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.p4.6.m6.1b"><ci id="S2.p4.6.m6.1.1.cmml" xref="S2.p4.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.6.m6.1c">i</annotation></semantics></math> while <math id="S2.p4.7.m7.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.p4.7.m7.1a"><mi id="S2.p4.7.m7.1.1" xref="S2.p4.7.m7.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.p4.7.m7.1b"><ci id="S2.p4.7.m7.1.1.cmml" xref="S2.p4.7.m7.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.7.m7.1c">n</annotation></semantics></math> is the total amount of available data across all clients involved in the aggregation.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Although <span id="S2.p5.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> has demonstrated empirical success and serves as a cornerstone in many FL algorithms, its effectiveness in real-world applications can be hindered by <em id="S2.p5.1.2" class="ltx_emph ltx_font_italic">statistical heterogeneity</em>, where the data distributions differ across the clients participating in the learning process. The clients’ data may differ in their statistical properties and in size, for example, because of differences in feature distributions or in label distributions. In wind turbines, individual turbines may display differing mechanical characteristics and possibly even differing turbine models and supervisory control and data acquisition (SCADA) systems may be involved. Statistical heterogeneity poses a challenge for FL model training and convergence because the aggregated model must learn to generalize across the diverse datasets. The variations among clients result in differences in the statistical distributions of their local datasets, leading to non-identically distributed (non-iid) data distributions.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">Fleets of industrial assets, such as wind turbines, can display significant statistical heterogeneity across clients. In such settings, global FL models tend to exhibit suboptimal performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> compared to locally trained models. The latter may even achieve higher accuracy than their globally trained counterparts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.
As a result, some clients may lack incentives to participate in training the global FL model (<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>). To address this challenge, Personalised FL (PFL) has been proposed to customize global FL models to individual clients. PFL retains the advantages of collaborative learning while tailoring the resulting global FL models to each client’s specific local data. Various PFL approaches exist, including client clustering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, personalised model layers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, meta-learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, and fine-tuning methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. We refer to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> for a comprehensive overview of customisation approaches, and to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> for PFL applications in renewable energy contexts.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">Training a NBM on data from a single WT requires a significant amount of data representative of the WT’s normal operational behaviour, which may not always be available. For example, this is typically the case in newly installed wind farms or after component updates and replacements. The resulting lack of data to train a representative and accurate model is known as the <em id="S2.p7.1.1" class="ltx_emph ltx_font_italic">cold start problem</em> in computer science, e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. We propose to exploit data gathered from multiple wind turbines to reduce the amount of time required for collecting data for training NBMs. We refer to the time savings as the <em id="S2.p7.1.2" class="ltx_emph ltx_font_italic">cold start speed up</em> because it is the speed up achieved by training a NBM from scratch through collaborative training rather than training on only local data. Due to privacy considerations, the data from individual turbines are kept confidential, so no data sharing with other wind turbines or servers is allowed. We employ FL for collaborative learning across different wind turbines and different wind farms. We assess the impact of having multiple turbines with different specifications in different wind farms on the efficacy of collaborative learning.
Condition monitoring often relies on NBMs which simulate the normal operation behaviour of the monitored WT components under the current environmental and operation conditions. NBMs are trained on WT data from fault-free operation periods, and allow quantifying the deviations between the measured target variables and their expected values as simulated by the NBM.
We consider identical feature and label spaces of all client wind turbines in this study, so the same SCADA variables are used as features and target variables of the NBMs of all WTs and wind farms considered in this study. Other types of FL, such as vertical FL and federated transfer learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> are not considered in this study.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Intra- and inter-farm federated learning of normal behaviour models</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Wind farm data</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We investigate FL for wind turbine condition monitoring using SCADA data of WTs from three different wind farms (Table <a href="#S3.T1" title="Table 1 ‣ 3.1 Wind farm data ‣ 3 Intra- and inter-farm federated learning of normal behaviour models ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). The wind farms provide different WT models and site conditions, which can give rise to statistical heterogeneity of the WTs’ SCADA variables.
The wind farms Penmanshiel and Kelmarsh exhibit similar configurations, sharing identical SCADA variables, whereas the EDP wind farm features a different SCADA system. We chose 10-minute averages of wind speed, ambient temperature, and wind direction as input features for the NBM, with gear-bearing temperature as the target variable to be predicted. The SCADA data were cleaned by removing curtailment periods and outliers. Wind speed and ambient temperature were normalised, while wind direction was cyclically encoded by a sine-cosine transformation.
The SCADA datasets of the EDP, Kelmarsh and Penmanshiel wind farms contain significant fractions of missing values of 1%, 5%, and 30%, respectively. The FL algorithm <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> applied in our study weighs the WTs’ contribution to the training in accordance with the fraction of training data available from them (eq. <a href="#S2.E1" title="In 2 Federated learning for condition monitoring of wind turbines ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), so data imbalance can affect the learning process in intra- and inter-farm FL.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.1.1.1" class="ltx_text ltx_font_bold">Wind farm</span></td>
<td id="S3.T1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.1.1.2.1" class="ltx_text ltx_font_bold">Penmanshiel</span></td>
<td id="S3.T1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.1.1.3.1" class="ltx_text ltx_font_bold">Kelmarsh</span></td>
<td id="S3.T1.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.1.1.4.1" class="ltx_text ltx_font_bold">EDP</span></td>
</tr>
<tr id="S3.T1.1.2" class="ltx_tr">
<td id="S3.T1.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.2.1.1" class="ltx_text ltx_font_bold">Location</span></td>
<td id="S3.T1.1.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">55.906°N, 2.262°W</td>
<td id="S3.T1.1.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">52.402°N, 0.945°W</td>
<td id="S3.T1.1.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">unknown</td>
</tr>
<tr id="S3.T1.1.3" class="ltx_tr">
<td id="S3.T1.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.3.1.1" class="ltx_text ltx_font_bold">Turbine model</span></td>
<td id="S3.T1.1.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Senvion MM82</td>
<td id="S3.T1.1.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Senvion MM92</td>
<td id="S3.T1.1.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">unknown</td>
</tr>
<tr id="S3.T1.1.4" class="ltx_tr">
<td id="S3.T1.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.4.1.1" class="ltx_text ltx_font_bold">Time period</span></td>
<td id="S3.T1.1.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2016–2021</td>
<td id="S3.T1.1.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2016–2021</td>
<td id="S3.T1.1.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2016–2017</td>
</tr>
<tr id="S3.T1.1.5" class="ltx_tr">
<td id="S3.T1.1.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.5.1.1" class="ltx_text ltx_font_bold">Number of turbines</span></td>
<td id="S3.T1.1.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">14</td>
<td id="S3.T1.1.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">6</td>
<td id="S3.T1.1.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4</td>
</tr>
<tr id="S3.T1.1.6" class="ltx_tr">
<td id="S3.T1.1.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.6.1.1" class="ltx_text ltx_font_bold">Rated power</span></td>
<td id="S3.T1.1.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2.05 MW</td>
<td id="S3.T1.1.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2.05 MW</td>
<td id="S3.T1.1.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.34 MW</td>
</tr>
<tr id="S3.T1.1.7" class="ltx_tr">
<td id="S3.T1.1.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.7.1.1" class="ltx_text ltx_font_bold">Rotor diameter</span></td>
<td id="S3.T1.1.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">82 m</td>
<td id="S3.T1.1.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">92 m</td>
<td id="S3.T1.1.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">unknown</td>
</tr>
<tr id="S3.T1.1.8" class="ltx_tr">
<td id="S3.T1.1.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.8.1.1" class="ltx_text ltx_font_bold">Cut-out wind speed</span></td>
<td id="S3.T1.1.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25 m/s</td>
<td id="S3.T1.1.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">24 m/s</td>
<td id="S3.T1.1.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25 m/s</td>
</tr>
<tr id="S3.T1.1.9" class="ltx_tr">
<td id="S3.T1.1.9.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.9.1.1" class="ltx_text ltx_font_bold">SCADA data source</span></td>
<td id="S3.T1.1.9.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite></td>
<td id="S3.T1.1.9.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite></td>
<td id="S3.T1.1.9.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> &amp; <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Wind farms that provided SCADA data to our study</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Model architecture and training</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The NBM trained in this study is an LSTM (Long Short-Term Memory) network consisting of layers of LSTM units followed by fully connected layers. The LSTM layers capture temporal dependencies in the data. We utilized a 24-hour trailing window to make sure the model can capture the operational conditions of the past 24 hours. The NBM predicts the expected gear-bearing temperature at the end of this time window.
Hyperparameters of the LSTM network were optimised for a single randomly selected turbine from the Penmanshiel wind farm whose data presented greater complexity than the turbines of other wind farms. The resulting LSTM model comprises two LSTM layers of sizes 16 and 64, respectively, and ReLU activation, followed by two fully connected layers of sizes 64 and 32 with ReLU activation. For this case study, we randomly selected four turbines from each of the three wind farms to reduce data imbalance and computational cost for FL model training. SCADA data from the resulting 12 WTs was used to train a NBM with FL.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">To assess the reduction of the training data accumulation time (cold start speed up), we train our NBM using increasing time intervals of training data. We will start by selecting a specific date as the start date. Then, for each start date, we will train multiple NBMs, each incorporating progressively more historical data by using different time ranges of training data. The time ranges commence from the selected start date and incrementally increase by one week, reaching a maximum of 12 weeks. This approach allows us to evaluate the impact of FL on reducing the time required to accumulate adequate data for model training.
To account for seasonal variations and avoid bias towards any particular season, we select four different start dates spread evenly throughout the year: December 2016, March 2017, June 2017, and September 2017. For each of these start dates, we train models using all 12 different time ranges, enabling a comprehensive evaluation of the cold start speed up achieved by FL across different seasons. For each start date, a test set is given by the 4-week time window that follows the 12<sup id="S3.SS2.p2.1.1" class="ltx_sup">th</sup> week of training data. Each local dataset is split into 80% for training and 20% for validation. We note that in the case of only one or up to two weeks of data, this may result in a validation dataset that is not fully independent from the training dataset due to autocorrelation of environmental condition time series.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">For each training set described above (defined by a selected start date and time range), we trained normal behaviour models of gear bearing temperature according to three different learning strategies representing different types of collaboration:
</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><em id="S3.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">Local learning</em>: Each wind turbine independently trains its own model using only its local data without any collaboration with other turbines.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><em id="S3.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">Intra-farm learning</em>: Each wind farm utilizes <span id="S3.I1.i2.p1.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> to train its own FL model, with no exchange of data or knowledge between different wind farms. In intra-farm learning, FL models are trained on similar WT clients, as turbines within a given wind farm typically exhibit similar and correlated SCADA data patterns.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><em id="S3.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">Inter-farm learning</em>: Turbines of multiple wind farms participate in a single <span id="S3.I1.i3.p1.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> learning process. The participating wind turbines involve different WT models, SCADA systems, and geographic locations, which results in significant data heterogeneity among the participating WT clients.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">The intra- and inter-farm learning strategies are illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. For each FL strategy, we assessed the performance of the trained normal behaviour models with and without fine-tuning. Fine-tuning involves retraining the global model on each wind turbine’s local training data after the FL training process. We provide our implementation on GitHub <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code available at <a target="_blank" href="https://github.com/EnergyWeatherAI/FL-Wind-NBM" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/EnergyWeatherAI/FL-Wind-NBM</a></span></span></span>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results and discussion</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>FL outperforms local training if training data are limited</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We compare the FL strategies by analysing the quality of the NBMs trained for the gear-bearing temperatures of the twelve WTs from the three wind farms. We assess the average of the NBMs for the individual WTs when trained with the respective learning strategy and training data time range.
The accuracies of gear-bearing temperature NBMs trained with different learning strategies were averaged across all time
ranges, start dates, and all twelve wind turbines. As shown in Table <a href="#S4.T2" title="Table 2 ‣ 4.1 FL outperforms local training if training data are limited ‣ 4 Results and discussion ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, intra-farm <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> with fine-tuning resulted in NBMs with the lowest mean absolute errors (MAEs), followed by inter-farm learning with fine-tuning. Thus, NBMs trained collaboratively by multiple wind turbines can outperform those trained with only local data, especially when little training data (less than a few months, as in this study) is available. Furthermore, our results show that fine-tuning retains some of the collaborative knowledge, even though non-fine-tuned models exhibit moderate to poor performances, highlighting the importance of fine-tuning in consolidating collaborative learning gains and improving model performance.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T2.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1" class="ltx_td ltx_border_r" style="padding-top:1.25pt;padding-bottom:1.25pt;"></td>
<td id="S4.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" colspan="2">FedAvg</td>
<td id="S4.T2.1.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T2.1.1.3.1" class="ltx_text">Local</span></td>
</tr>
<tr id="S4.T2.1.2" class="ltx_tr">
<td id="S4.T2.1.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Fine-tuned</td>
<td id="S4.T2.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Intra-farm</td>
<td id="S4.T2.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">Inter-farm</td>
</tr>
<tr id="S4.T2.1.3" class="ltx_tr">
<td id="S4.T2.1.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">no</td>
<td id="S4.T2.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">1.31</td>
<td id="S4.T2.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;">6.92</td>
<td id="S4.T2.1.3.4" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:1.25pt;padding-bottom:1.25pt;"></td>
</tr>
<tr id="S4.T2.1.4" class="ltx_tr">
<td id="S4.T2.1.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" style="padding-top:1.25pt;padding-bottom:1.25pt;">yes</td>
<td id="S4.T2.1.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span id="S4.T2.1.4.2.1" class="ltx_text ltx_font_bold">0.87</span></td>
<td id="S4.T2.1.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:1.25pt;padding-bottom:1.25pt;">0.97</td>
<td id="S4.T2.1.4.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_b ltx_border_r" style="padding-top:1.25pt;padding-bottom:1.25pt;" rowspan="2"><span id="S4.T2.1.4.4.1" class="ltx_text">1.44</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Mean absolute errors (in °C) of the gear-bearing temperature NBMs trained with different learning strategies, averaged across all time ranges, start dates, and wind turbines.</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Overall, intra-farm <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> with fine-tuning demonstrates a significant improvement over local training, reducing the MAE by approximately 40%. While inter-farm <span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> with fine-tuning also demonstrates improvement over local training, it falls slightly behind fine-tuned intra-farm learning. This discrepancy may be caused by the significant statistical heterogeneity between the wind farm SCADA variables involved in the NBM training. Intra-farm FL without fine-tuning outperforms local training by approximately 9%. For inter-farm learning in presence of significant statistical heterogeneity across wind farms, the loss increases by almost fivefold without fine-tuning (Table <a href="#S4.T2" title="Table 2 ‣ 4.1 FL outperforms local training if training data are limited ‣ 4 Results and discussion ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
The relative performance between local training and fine-tuned intra- and inter-farm <span id="S4.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">FedAvg</span> remains consistent across all time ranges considered, as shown in Figure <a href="#S4.F2" title="Figure 2 ‣ 4.1 FL outperforms local training if training data are limited ‣ 4 Results and discussion ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. FL consistently exhibits a strong improvement compared to local training, even with 12 weeks of training data. Our above results were averaged over different start dates. We investigated whether the results depend on the time of year and found they remain largely consistent across different seasons, as shown in Figure <a href="#A1.F1" title="Figure 1 ‣ Appendix A ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> in the appendix. In all seasons, intra- and interfarm FL enable more accurate NBMs than local training.
We also found our conclusions do not depend on the start date, with the exception of June 2017 (Figures <a href="#A1.F1" title="Figure 1 ‣ Appendix A ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#A2.F2" title="Figure 2 ‣ Appendix B ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> in the appendix), which could possibly be due to a seasonality shift between the training and test set for the Kelmarsh wind farm.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2409.03672/assets/img/Figure2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="206" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Mean absolute errors for fine-tuned <span id="S4.F2.2.1" class="ltx_text ltx_font_typewriter">FedAvg</span> and local training. The losses are averaged across all start dates and wind turbines.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>FL strongly reduces the training data collection time</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The <em id="S4.SS2.p1.1.1" class="ltx_emph ltx_font_italic">cold start speed up</em> refers to the reduction of time needed to accumulate the amount of historical training data required to achieve performances comparable to local training when employing FL. As shown in Figure <a href="#S4.F3" title="Figure 3 ‣ 4.2 FL strongly reduces the training data collection time ‣ 4 Results and discussion ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> with fine-tuning reduces the training data collection time by approximately eight to nine weeks out of the twelve weeks under consideration in intra-farm and inter-farm FL. For example in Figure <a href="#S4.F3" title="Figure 3 ‣ 4.2 FL strongly reduces the training data collection time ‣ 4 Results and discussion ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, to achieve the equivalent accuracy of the best performing gear bearing temperature NBM trained with local data, intra-farm <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_typewriter">FedAvg</span> with fine-tuning requires only 18 days of training data compared to the 84 days of training data required using local data only. This speed up allows for the earlier deployment of accurate NBMs, enabling an earlier fault detection and thereby reducing the risk of undetected incipient faults.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2409.03672/assets/img/Figure3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="214" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S4.F3.2.1" class="ltx_text ltx_font_typewriter">FedAvg</span> with fine-tuning reduces the time needed to accumulate the amount of historical training data required to achieve performances comparable to local training by 66 days in intra-farm learning and by 58 days in inter-farm learning, when averaged across all WTs and start dates.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results by wind farm</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The statistical heterogeneity of the datasets of different clients can present a significant challenge to collaborative learning. Our results suggest that increasing the number of WTs involved in the training does not necessarily lead to improved collaborative learning outcomes, even after fine tuning. In particular, if the data distributions vary among the different wind turbines, the performance of collaborative learning across WTs of different wind farms (inter-farm learning) can be worse than that of collaborative learning within a given wind farm (intra-farm learning).</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">We also assessed the performance of FL for NBM training in the context of the individual wind farms. We averaged the accuracies of the NBMs across the four turbines involved in the FL training from each wind farm, as shown in Table <a href="#S4.T3" title="Table 3 ‣ 4.3 Results by wind farm ‣ 4 Results and discussion ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> with fine-tuning consistently outperformed the other learning methods at each wind farm. Intra-farm FL with fine-tuning significantly surpasses the accuracy of inter-farm learning with fine-tuning at the Penmanshiel wind farm, as shown in Table <a href="#S4.T3" title="Table 3 ‣ 4.3 Results by wind farm ‣ 4 Results and discussion ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Figure <a href="#S4.F4" title="Figure 4 ‣ 4.3 Results by wind farm ‣ 4 Results and discussion ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
The comparatively poor performance of inter-farm FL is likely related to the low fraction of SCADA data from the Penmanshiel wind farm (see Figure <a href="#A3.F1" title="Figure 1 ‣ Appendix C ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> in the appendix), as its small data contribution to the inter-farm FL training results in a small contribution to the inter-farm FL model.
The non-fine-tuned inter-farm MAE is substantially higher (16.65°C, see also Figure <a href="#A2.F1" title="Figure 1 ‣ Appendix B ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> in the appendix), indicating that the NBM primarily learns from the other two wind farms in the case of inter-farm learning.
Conversely, the EDP wind farm exhibits minimal disparity between intra- and inter-farm learning. This is likely because a significant portion of the global model’s influence stems from EDP’s data, which accounts for roughly <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mn id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">50</mn><mo id="S4.SS3.p2.1.m1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">50\%</annotation></semantics></math> of the total data across the various wind farms (as depicted in Figure <a href="#A3.F1" title="Figure 1 ‣ Appendix C ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). Thus, the global model’s performances on EDP’s wind turbines are less affected by the heterogeneity introduced by other wind farms’ data.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:173.4pt;height:90.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-51.1pt,26.7pt) scale(0.629374231063538,0.629374231063538) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_tt"></td>
<td id="S4.T3.1.1.1.2" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">FedAvg</td>
<td id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T3.1.1.1.4.1" class="ltx_text">Local</span></td>
</tr>
<tr id="S4.T3.1.1.2" class="ltx_tr">
<td id="S4.T3.1.1.2.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S4.T3.1.1.2.2" class="ltx_td ltx_align_center ltx_border_r">Fine-tuned</td>
<td id="S4.T3.1.1.2.3" class="ltx_td ltx_align_center ltx_border_r">Intra-farm</td>
<td id="S4.T3.1.1.2.4" class="ltx_td ltx_align_center ltx_border_r">inter-farm</td>
</tr>
<tr id="S4.T3.1.1.3" class="ltx_tr">
<td id="S4.T3.1.1.3.1" class="ltx_td ltx_align_left ltx_align_top ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.1.1.3.1.1" class="ltx_text">EDP</span></td>
<td id="S4.T3.1.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">no</td>
<td id="S4.T3.1.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.74</td>
<td id="S4.T3.1.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.33</td>
<td id="S4.T3.1.1.3.5" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S4.T3.1.1.4" class="ltx_tr">
<td id="S4.T3.1.1.4.1" class="ltx_td ltx_align_center ltx_border_r">yes</td>
<td id="S4.T3.1.1.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.1.1.4.2.1" class="ltx_text ltx_font_bold">1.35</span></td>
<td id="S4.T3.1.1.4.3" class="ltx_td ltx_align_center ltx_border_r">1.44</td>
<td id="S4.T3.1.1.4.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_r"><span id="S4.T3.1.1.4.4.1" class="ltx_text">2.10</span></td>
</tr>
<tr id="S4.T3.1.1.5" class="ltx_tr">
<td id="S4.T3.1.1.5.1" class="ltx_td ltx_align_left ltx_align_top ltx_border_l ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T3.1.1.5.1.1" class="ltx_text">Kelmarsh</span></td>
<td id="S4.T3.1.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">no</td>
<td id="S4.T3.1.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.18</td>
<td id="S4.T3.1.1.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.81</td>
<td id="S4.T3.1.1.5.5" class="ltx_td ltx_border_r ltx_border_tt"></td>
</tr>
<tr id="S4.T3.1.1.6" class="ltx_tr">
<td id="S4.T3.1.1.6.1" class="ltx_td ltx_align_center ltx_border_r">yes</td>
<td id="S4.T3.1.1.6.2" class="ltx_td ltx_align_center ltx_border_r">0.87</td>
<td id="S4.T3.1.1.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.1.1.6.3.1" class="ltx_text ltx_font_bold">0.65</span></td>
<td id="S4.T3.1.1.6.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_r"><span id="S4.T3.1.1.6.4.1" class="ltx_text">1.23</span></td>
</tr>
<tr id="S4.T3.1.1.7" class="ltx_tr">
<td id="S4.T3.1.1.7.1" class="ltx_td ltx_align_left ltx_align_top ltx_border_bb ltx_border_b ltx_border_l ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T3.1.1.7.1.1" class="ltx_text">Penmanshiel</span></td>
<td id="S4.T3.1.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">no</td>
<td id="S4.T3.1.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.02</td>
<td id="S4.T3.1.1.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">16.65</td>
<td id="S4.T3.1.1.7.5" class="ltx_td ltx_border_r ltx_border_tt"></td>
</tr>
<tr id="S4.T3.1.1.8" class="ltx_tr">
<td id="S4.T3.1.1.8.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">yes</td>
<td id="S4.T3.1.1.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r"><span id="S4.T3.1.1.8.2.1" class="ltx_text ltx_font_bold">0.40</span></td>
<td id="S4.T3.1.1.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">0.82</td>
<td id="S4.T3.1.1.8.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_bb ltx_border_b ltx_border_r" rowspan="2"><span id="S4.T3.1.1.8.4.1" class="ltx_text">1.00</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Mean absolute errors (in °C) of the gear-bearing temperature NBMs trained with different learning strategies from each wind farm, averaged across all time ranges, start dates, and wind turbines of the respective wind farm.</figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2409.03672/assets/img/Figure4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="185" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Evolution of the mean absolute errors (in °C) for fine-tuned <span id="S4.F4.2.1" class="ltx_text ltx_font_typewriter">FedAvg</span>  and local training. These losses are the averaged results across all start dates and turbines within each wind farm.</figcaption>
</figure>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">For each wind farm, the implementation of FL strategies results in a significant cold start speed up, with saved time ranging from four to more than ten weeks. This phenomenon is illustrated in Figure <a href="#S4.F5" title="Figure 5 ‣ 4.3 Results by wind farm ‣ 4 Results and discussion ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, where the cold start speed up for fine-tuned <span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> is depicted. The most substantial reduction in the time required to collect training data occurs with intra-farm learning with fine-tuning in the Penmanshiel wind farm.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2409.03672/assets/img/Figure5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="351" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Cold start speed up for fine-tuned <span id="S4.F5.2.1" class="ltx_text ltx_font_typewriter">FedAvg</span>. These MAEs are averaged across the different start dates and turbines within each wind farm.</figcaption>
</figure>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">We considered four different start dates, one in each season, to investigate how seasonality impacts the accuracy of NBMs trained with different FL strategies at each wind farm. This resulted in twelve combinations of start date and wind farm, as shown in Figure <a href="#S4.F6" title="Figure 6 ‣ 4.3 Results by wind farm ‣ 4 Results and discussion ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> and Table <a href="#A3.T1" title="Table 1 ‣ Appendix C ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> in the appendix.
Intra-farm learning with fine-tuning emerged as the best-performing strategy in most cases (10 out of 12), and inter-farm learning with fine-tuning in the remaining two cases which pertain to the Kelmarsh wind farm.
We also investigated how the different learning strategies perform for individual wind turbines and found that our above results are confirmed also at WT level. Federated learning enables more accurate normal behaviour models than local training with limited data, and a reduction in the amount of time needed to collect the required model training data. Fine-tuning provided more accurate NBMs in all cases. Moreover, intra-farm FL tended to provide more accurate NBMs than inter-farm FL.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p">In addition to <span id="S4.SS3.p5.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span>, all experiments were repeated with an alternative federated learning algorithm called <span id="S4.SS3.p5.1.2" class="ltx_text ltx_font_typewriter">FedProx</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. <span id="S4.SS3.p5.1.3" class="ltx_text ltx_font_typewriter">FedProx</span> follows a similar learning process as <span id="S4.SS3.p5.1.4" class="ltx_text ltx_font_typewriter">FedAvg</span> but incorporates a regularization term in the loss function during local training, which measures the discrepancy between the current global model and the updated local model of the clients. Our experiment indicates that <span id="S4.SS3.p5.1.5" class="ltx_text ltx_font_typewriter">FedProx</span> performs comparably, albeit slightly worse, than <span id="S4.SS3.p5.1.6" class="ltx_text ltx_font_typewriter">FedAvg</span> for both inter-farm and intra-farm learning. This may be attributed to the fact that <span id="S4.SS3.p5.1.7" class="ltx_text ltx_font_typewriter">FedProx</span> slows down local training to retain more knowledge from the global FL model but does not address the models competing against each other due to statistical heterogeneity.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2409.03672/assets/img/Figure6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="500" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Mean absolute error for each start date and wind farm. These results are averaged across the turbines within a given wind farm.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our study demonstrated the effectiveness of privacy-preserving collaborative learning of wind turbine normal behaviour models for condition monitoring applications. We demonstrated that federated learning enables a reduction of the training data accumulation time, allowing for an earlier detection of developing faults, compared to local training. We also found that having more collaborators is not necessarily better in collaborative learning. In the presence of high statistical heterogeneity, i.e., significant differences between the data distributions of the involved wind turbines, the performance of federated learning across wind turbines of different wind farms (<em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">inter-farm</em> learning) is worse than that of federated learning within a given wind farm (<em id="S5.p1.1.2" class="ltx_emph ltx_font_italic">intra-farm</em> learning).</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">We assessed two distinct collaborative learning approaches: inter-farm learning, which involves collaboration across turbines from different wind farms, and intra-farm learning, which restricts collaboration to turbines in the same wind farm. Our analysis shows that high levels of statistical heterogeneity present significant challenges to collaborative learning. The accuracy of NBMs trained in intra-farm learning surpassed that of inter-farm learning in most situations, underscoring the adverse impacts of heterogeneity on collaborative learning. We demonstrated fine-tuning as an approach to address FL model training in view of significant statistical heterogeneity.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">We propose several directions of future research. Firstly, our model selection and hyperparameter tuning processes were conducted on a full dataset from a single turbine, potentially diverging from real-world conditions where historical data accumulation occurs incrementally and disregarding the contributions of the other turbines. Addressing this challenge entails the development of automated and adaptive model selection methods capable of accommodating evolving data volumes and complexities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. Moreover, integrating FL techniques for hyperparameter tuning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> could enhance efficiency and scalability in FL settings. Furthermore, we propose to investigate continuous learning strategies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> for their potential to reduce communication costs and training time in FL by enabling incremental model updates instead of periodic full re-training. Incorporating such strategies would not only contribute to the ongoing evolution and refinement of collaborative learning methodologies in renewable energy applications but may also render them more applicable to real industrial settings. Finally, we considered identical feature and label spaces of all client wind turbines but did not consider other types of FL in this study, such as federated transfer learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. They may form subject of future research in wind energy applications.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">In conclusion, our study demonstrated the potential and challenges of collaborative learning in wind turbine condition monitoring through FL. By advancing our understanding of effective collaboration strategies and addressing challenges such as statistical heterogeneity and model adaptation, we move closer to realizing the full potential of FL for enhancing the reliability and efficiency of wind farms and other renewable energy systems.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">CRediT author statement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p"><span id="Sx1.p1.1.1" class="ltx_text ltx_font_bold">Grataloup, A.</span>: Conceptualization, Formal analysis, Investigation, Methodology, Software, Validation, Visualization, Writing – original draft, Writing – review &amp; editing.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p"><span id="Sx1.p2.1.1" class="ltx_text ltx_font_bold">Jonas, S.</span>: Conceptualization, Methodology, Writing – review &amp; editing.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<p id="Sx1.p3.1" class="ltx_p"><span id="Sx1.p3.1.1" class="ltx_text ltx_font_bold">Meyer, A.</span>: Conceptualization, Writing – review &amp; editing, Funding acquisition, Project administration, Supervision, Resources.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">This research was supported by the Swiss National Science Foundation (Grant No. 206342).</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Appendix</h2>

</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix"><span class="ltx_tag ltx_tag_appendix">Appendix A </span></h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Figure <a href="#A1.F1" title="Figure 1 ‣ Appendix A ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows that the evolution of the mean absolute errors for fine-tuned <span id="A1.p1.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> and local training by starting date is also consistent across all seasons with the exception of the starting date in June 2017. A possible explanation for this behavior is a seasonality-based data distribution shift between the training and test set for the Kelmarsh wind farm, which is discussed further in Appendix B.</p>
</div>
<figure id="A1.F1" class="ltx_figure"><img src="/html/2409.03672/assets/img/Figure_A1.png" id="A1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="6159" height="4182" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Mean absolute errors for each start date, with fine-tuned <span id="A1.F1.2.1" class="ltx_text ltx_font_typewriter">FedAvg</span> and local training. These results are averaged across all turbines.</figcaption>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix"><span class="ltx_tag ltx_tag_appendix">Appendix B </span></h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">We examine the model prediction compared to the ground truth of the gear-bearing temperature for one selected turbine from each wind farm. We restrict ourselves here to models trained on three weeks of training data in December for Figure <a href="#A2.F1" title="Figure 1 ‣ Appendix B ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and June for Figure <a href="#A2.F2" title="Figure 2 ‣ Appendix B ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, using the corresponding four-week test dataset for evaluation. This analysis provides insights into the performance of various learning methods, enabling a qualitative assessment of FL. Notably, predictions from local training (no collaboration) and fine-tuned <span id="A2.p1.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> closely align with the ground truth. However, non-fine-tuned <span id="A2.p1.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> exhibits inferior performance, especially in scenarios characterized by significant data heterogeneity among clients, such as inter-farm learning.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.1" class="ltx_p">The models were trained on three weeks of data in December 2016. Figure <a href="#A2.F1" title="Figure 1 ‣ Appendix B ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the performance of the local, intra- and interfarm learning strategies on the respective test sets. A single WT has been picked randomly from each wind farm to this end.</p>
</div>
<figure id="A2.F1" class="ltx_figure"><img src="/html/2409.03672/assets/img/Figure_A2.png" id="A2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="473" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Actual versus predicted gear bearing temperatures using local learning (1<sup id="A2.F1.5.1" class="ltx_sup">st</sup> row), intra and inter-farm <span id="A2.F1.6.2" class="ltx_text ltx_font_typewriter">FedAvg</span> with and without finetuning (3<sup id="A2.F1.7.3" class="ltx_sup">rd</sup> and 2<sup id="A2.F1.8.4" class="ltx_sup">nd</sup> row, respectively).</figcaption>
</figure>
<div id="A2.p3" class="ltx_para">
<p id="A2.p3.1" class="ltx_p">One important observation from Figure <a href="#A2.F1" title="Figure 1 ‣ Appendix B ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> is the widening error of non-fine-tuned inter-farm <span id="A2.p3.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> as the data proportion decreases. Specifically, the red curve representing non-fine-tuned inter-farm <span id="A2.p3.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> for Penmanshiel (the wind farm with the smallest data proportion) shows a pronounced deviation from ground truth and is closer to the temperature ranges observed in the Kelmarsh and EDP wind farms. This disparity arises from the observable heterogeneity, with Penmanshiel exhibiting a temperature range of 25°C to 35°C, contrasting with the 40°C to 60°C range observed in Kelmarsh and EDP wind farms. <span id="A2.p3.1.3" class="ltx_text ltx_font_typewriter">FedAvg</span> attributes a larger weight to clients with more data, resulting in Penmanshiel’s turbine contributing significantly less than those of Kelmarsh and EDP wind farms (see Figure <a href="#A3.F1" title="Figure 1 ‣ Appendix C ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div id="A2.p4" class="ltx_para">
<p id="A2.p4.1" class="ltx_p">Non-fine-tuned intra-farm learning outperforms non-fine-tuned inter-farm learning in this case study. This indicates that the different wind farms involved in the collaborative FL process end up competing to achieve different learning objectives rather than collaborate. However, this disparity is no longer visible after fine-tuning and opens the question of whether there is a retention of collaborative knowledge.</p>
</div>
<div id="A2.p5" class="ltx_para">
<p id="A2.p5.1" class="ltx_p">While these observations hold across most start dates and time ranges, a different behaviour emerges in situations where the local training fails to fit the test set, as shown in Figure <a href="#A2.F2" title="Figure 2 ‣ Appendix B ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>:</p>
</div>
<figure id="A2.F2" class="ltx_figure"><img src="/html/2409.03672/assets/img/Figure_A3.png" id="A2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="473" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>For each wind farm, we compare ground truth (in black) to the predicted gear bearing temperature (in °C) using local learning (1<sup id="A2.F2.5.1" class="ltx_sup">st</sup> row), non-fine-tuned intra and inter-farm <span id="A2.F2.6.2" class="ltx_text ltx_font_typewriter">FedAvg</span> (2<sup id="A2.F2.7.3" class="ltx_sup">nd</sup> row), and their fine-tuned version (3<sup id="A2.F2.8.4" class="ltx_sup">rd</sup> row). A single turbine has been picked for each wind farm. This visual evaluation is done on the test dataset and the models are trained on three weeks of data in June 2017.</figcaption>
</figure>
<div id="A2.p6" class="ltx_para">
<p id="A2.p6.1" class="ltx_p">In Figure <a href="#A2.F2" title="Figure 2 ‣ Appendix B ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the overall observations remain consistent, except for the Kelmarsh wind farm during the testing period between September 11 and September 17. During this period, local training fails to effectively fit the ground truth, likely indicating either potential anomalies in the data, or data points lying outside the range of the model’s training data, leading to poor generalization. Upon examining the data distribution of various features, we find no indications of anomalous behavior during that
period. Furthermore, we observe wind speed and ambient temperature value ranges slightly higher and lower, respectively, in the affected test set compared to the training set. Such variations are expected when comparing weather conditions between June and September. A distribution shift being a possible cause is further supported by the observation that during this period, inter-farm learning, both with and without fine-tuning, outperforms intra-farm learning (see also Figure <a href="#A1.F1" title="Figure 1 ‣ Appendix A ‣ Wind turbine condition monitoring based on intra- and inter-farm federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). This suggests that inter-farm learning may benefit from insights gained from other farms, enabling it to better adapt to locally unseen data. However, in practical scenarios, our primary concern is not whether a model trained on data from June will perform well on test data in September. Instead, our focus would lie on ensuring that the model performs effectively in the weeks that follow the training set. We could continuously retrain the model with new data as it becomes available, thereby mitigating any seasonality shift and increasing the likelihood of the model performing well on near-future data in a continuous learning setting.</p>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix"><span class="ltx_tag ltx_tag_appendix">Appendix C </span></h2>

<figure id="A3.F1" class="ltx_figure"><img src="/html/2409.03672/assets/img/Figure_A4.png" id="A3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="2076" height="1418" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Proportion of data available per wind farm when taking different time windows of data (1 to 12 weeks by 1-week intervals).</figcaption>
</figure>
<figure id="A3.T1" class="ltx_table">
<div id="A3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:128.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-99.7pt,34.7pt) scale(0.649033677386352,0.649033677386352) ;">
<table id="A3.T1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="A3.T1.1.1.1" class="ltx_tr">
<td id="A3.T1.1.1.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_tt"></td>
<td id="A3.T1.1.1.1.2" class="ltx_td ltx_border_rr ltx_border_tt"></td>
<td id="A3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="3">EDP</td>
<td id="A3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="3">Kelmarsh</td>
<td id="A3.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">Penmanshiel</td>
</tr>
<tr id="A3.T1.1.1.2" class="ltx_tr">
<td id="A3.T1.1.1.2.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="A3.T1.1.1.2.2" class="ltx_td ltx_border_rr"></td>
<td id="A3.T1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">FedAvg</td>
<td id="A3.T1.1.1.2.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_rr ltx_border_t" rowspan="2"><span id="A3.T1.1.1.2.4.1" class="ltx_text">Local</span></td>
<td id="A3.T1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">FedAvg</td>
<td id="A3.T1.1.1.2.6" class="ltx_td ltx_align_center ltx_align_top ltx_border_rr ltx_border_t" rowspan="2"><span id="A3.T1.1.1.2.6.1" class="ltx_text">Local</span></td>
<td id="A3.T1.1.1.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">FedAvg</td>
<td id="A3.T1.1.1.2.8" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_t" rowspan="2"><span id="A3.T1.1.1.2.8.1" class="ltx_text">Local</span></td>
</tr>
<tr id="A3.T1.1.1.3" class="ltx_tr">
<td id="A3.T1.1.1.3.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="A3.T1.1.1.3.2" class="ltx_td ltx_align_center ltx_border_rr">Fine-tuned</td>
<td id="A3.T1.1.1.3.3" class="ltx_td ltx_align_center ltx_border_r">Intra-farm</td>
<td id="A3.T1.1.1.3.4" class="ltx_td ltx_align_center ltx_border_r">Inter-farm</td>
<td id="A3.T1.1.1.3.5" class="ltx_td ltx_align_center ltx_border_r">Intra-farm</td>
<td id="A3.T1.1.1.3.6" class="ltx_td ltx_align_center ltx_border_r">Inter-farm</td>
<td id="A3.T1.1.1.3.7" class="ltx_td ltx_align_center ltx_border_r">Intra-farm</td>
<td id="A3.T1.1.1.3.8" class="ltx_td ltx_align_center ltx_border_r">Inter-farm</td>
</tr>
<tr id="A3.T1.1.1.4" class="ltx_tr">
<td id="A3.T1.1.1.4.1" class="ltx_td ltx_align_left ltx_align_top ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="A3.T1.1.1.4.1.1" class="ltx_text">2016-12-01</span></td>
<td id="A3.T1.1.1.4.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">no</td>
<td id="A3.T1.1.1.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.79</td>
<td id="A3.T1.1.1.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.49</td>
<td id="A3.T1.1.1.4.5" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="A3.T1.1.1.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.81</td>
<td id="A3.T1.1.1.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.82</td>
<td id="A3.T1.1.1.4.8" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="A3.T1.1.1.4.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.95</td>
<td id="A3.T1.1.1.4.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">17.80</td>
<td id="A3.T1.1.1.4.11" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="A3.T1.1.1.5" class="ltx_tr">
<td id="A3.T1.1.1.5.1" class="ltx_td ltx_align_center ltx_border_rr">yes</td>
<td id="A3.T1.1.1.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T1.1.1.5.2.1" class="ltx_text ltx_font_bold">1.48</span></td>
<td id="A3.T1.1.1.5.3" class="ltx_td ltx_align_center ltx_border_r">1.53</td>
<td id="A3.T1.1.1.5.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_rr"><span id="A3.T1.1.1.5.4.1" class="ltx_text">2.24</span></td>
<td id="A3.T1.1.1.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T1.1.1.5.5.1" class="ltx_text ltx_font_bold">0.42</span></td>
<td id="A3.T1.1.1.5.6" class="ltx_td ltx_align_center ltx_border_r">0.44</td>
<td id="A3.T1.1.1.5.7" class="ltx_td ltx_align_center ltx_align_top ltx_border_rr"><span id="A3.T1.1.1.5.7.1" class="ltx_text">0.72</span></td>
<td id="A3.T1.1.1.5.8" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T1.1.1.5.8.1" class="ltx_text ltx_font_bold">0.34</span></td>
<td id="A3.T1.1.1.5.9" class="ltx_td ltx_align_center ltx_border_r">0.77</td>
<td id="A3.T1.1.1.5.10" class="ltx_td ltx_align_center ltx_align_top ltx_border_r"><span id="A3.T1.1.1.5.10.1" class="ltx_text">0.93</span></td>
</tr>
<tr id="A3.T1.1.1.6" class="ltx_tr">
<td id="A3.T1.1.1.6.1" class="ltx_td ltx_align_left ltx_align_top ltx_border_l ltx_border_r ltx_border_tt" rowspan="2"><span id="A3.T1.1.1.6.1.1" class="ltx_text">2017-03-01</span></td>
<td id="A3.T1.1.1.6.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">no</td>
<td id="A3.T1.1.1.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.67</td>
<td id="A3.T1.1.1.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">2.47</td>
<td id="A3.T1.1.1.6.5" class="ltx_td ltx_border_rr ltx_border_tt"></td>
<td id="A3.T1.1.1.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.78</td>
<td id="A3.T1.1.1.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.93</td>
<td id="A3.T1.1.1.6.8" class="ltx_td ltx_border_rr ltx_border_tt"></td>
<td id="A3.T1.1.1.6.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.94</td>
<td id="A3.T1.1.1.6.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">16.32</td>
<td id="A3.T1.1.1.6.11" class="ltx_td ltx_border_r ltx_border_tt"></td>
</tr>
<tr id="A3.T1.1.1.7" class="ltx_tr">
<td id="A3.T1.1.1.7.1" class="ltx_td ltx_align_center ltx_border_rr">yes</td>
<td id="A3.T1.1.1.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T1.1.1.7.2.1" class="ltx_text ltx_font_bold">1.39</span></td>
<td id="A3.T1.1.1.7.3" class="ltx_td ltx_align_center ltx_border_r">1.51</td>
<td id="A3.T1.1.1.7.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_rr"><span id="A3.T1.1.1.7.4.1" class="ltx_text">2.23</span></td>
<td id="A3.T1.1.1.7.5" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T1.1.1.7.5.1" class="ltx_text ltx_font_bold">0.35</span></td>
<td id="A3.T1.1.1.7.6" class="ltx_td ltx_align_center ltx_border_r">0.40</td>
<td id="A3.T1.1.1.7.7" class="ltx_td ltx_align_center ltx_align_top ltx_border_rr"><span id="A3.T1.1.1.7.7.1" class="ltx_text">0.59</span></td>
<td id="A3.T1.1.1.7.8" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T1.1.1.7.8.1" class="ltx_text ltx_font_bold">0.25</span></td>
<td id="A3.T1.1.1.7.9" class="ltx_td ltx_align_center ltx_border_r">0.68</td>
<td id="A3.T1.1.1.7.10" class="ltx_td ltx_align_center ltx_align_top ltx_border_r"><span id="A3.T1.1.1.7.10.1" class="ltx_text">0.83</span></td>
</tr>
<tr id="A3.T1.1.1.8" class="ltx_tr">
<td id="A3.T1.1.1.8.1" class="ltx_td ltx_align_left ltx_align_top ltx_border_l ltx_border_r ltx_border_tt" rowspan="2"><span id="A3.T1.1.1.8.1.1" class="ltx_text">2017-06-01</span></td>
<td id="A3.T1.1.1.8.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">no</td>
<td id="A3.T1.1.1.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.77</td>
<td id="A3.T1.1.1.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">2.02</td>
<td id="A3.T1.1.1.8.5" class="ltx_td ltx_border_rr ltx_border_tt"></td>
<td id="A3.T1.1.1.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">2.08</td>
<td id="A3.T1.1.1.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.85</td>
<td id="A3.T1.1.1.8.8" class="ltx_td ltx_border_rr ltx_border_tt"></td>
<td id="A3.T1.1.1.8.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.06</td>
<td id="A3.T1.1.1.8.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">13.76</td>
<td id="A3.T1.1.1.8.11" class="ltx_td ltx_border_r ltx_border_tt"></td>
</tr>
<tr id="A3.T1.1.1.9" class="ltx_tr">
<td id="A3.T1.1.1.9.1" class="ltx_td ltx_align_center ltx_border_rr">yes</td>
<td id="A3.T1.1.1.9.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T1.1.1.9.2.1" class="ltx_text ltx_font_bold">1.30</span></td>
<td id="A3.T1.1.1.9.3" class="ltx_td ltx_align_center ltx_border_r">1.32</td>
<td id="A3.T1.1.1.9.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_rr"><span id="A3.T1.1.1.9.4.1" class="ltx_text">1.88</span></td>
<td id="A3.T1.1.1.9.5" class="ltx_td ltx_align_center ltx_border_r">1.89</td>
<td id="A3.T1.1.1.9.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T1.1.1.9.6.1" class="ltx_text ltx_font_bold">0.96</span></td>
<td id="A3.T1.1.1.9.7" class="ltx_td ltx_align_center ltx_align_top ltx_border_rr"><span id="A3.T1.1.1.9.7.1" class="ltx_text">2.08</span></td>
<td id="A3.T1.1.1.9.8" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T1.1.1.9.8.1" class="ltx_text ltx_font_bold">0.48</span></td>
<td id="A3.T1.1.1.9.9" class="ltx_td ltx_align_center ltx_border_r">0.85</td>
<td id="A3.T1.1.1.9.10" class="ltx_td ltx_align_center ltx_align_top ltx_border_r"><span id="A3.T1.1.1.9.10.1" class="ltx_text">1.09</span></td>
</tr>
<tr id="A3.T1.1.1.10" class="ltx_tr">
<td id="A3.T1.1.1.10.1" class="ltx_td ltx_align_left ltx_align_top ltx_border_bb ltx_border_b ltx_border_l ltx_border_r ltx_border_tt" rowspan="2"><span id="A3.T1.1.1.10.1.1" class="ltx_text">2017-09-01</span></td>
<td id="A3.T1.1.1.10.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">no</td>
<td id="A3.T1.1.1.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.74</td>
<td id="A3.T1.1.1.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">2.34</td>
<td id="A3.T1.1.1.10.5" class="ltx_td ltx_border_rr ltx_border_tt"></td>
<td id="A3.T1.1.1.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.06</td>
<td id="A3.T1.1.1.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.63</td>
<td id="A3.T1.1.1.10.8" class="ltx_td ltx_border_rr ltx_border_tt"></td>
<td id="A3.T1.1.1.10.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.12</td>
<td id="A3.T1.1.1.10.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">18.76</td>
<td id="A3.T1.1.1.10.11" class="ltx_td ltx_border_r ltx_border_tt"></td>
</tr>
<tr id="A3.T1.1.1.11" class="ltx_tr">
<td id="A3.T1.1.1.11.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_rr">yes</td>
<td id="A3.T1.1.1.11.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r"><span id="A3.T1.1.1.11.2.1" class="ltx_text ltx_font_bold">1.24</span></td>
<td id="A3.T1.1.1.11.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">1.38</td>
<td id="A3.T1.1.1.11.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_bb ltx_border_b ltx_border_rr" rowspan="2"><span id="A3.T1.1.1.11.4.1" class="ltx_text">2.05</span></td>
<td id="A3.T1.1.1.11.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">0.83</td>
<td id="A3.T1.1.1.11.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r"><span id="A3.T1.1.1.11.6.1" class="ltx_text ltx_font_bold">0.80</span></td>
<td id="A3.T1.1.1.11.7" class="ltx_td ltx_align_center ltx_align_top ltx_border_bb ltx_border_b ltx_border_rr" rowspan="2"><span id="A3.T1.1.1.11.7.1" class="ltx_text">1.53</span></td>
<td id="A3.T1.1.1.11.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r"><span id="A3.T1.1.1.11.8.1" class="ltx_text ltx_font_bold">0.52</span></td>
<td id="A3.T1.1.1.11.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">0.97</td>
<td id="A3.T1.1.1.11.10" class="ltx_td ltx_align_center ltx_align_top ltx_border_bb ltx_border_b ltx_border_r" rowspan="2"><span id="A3.T1.1.1.11.10.1" class="ltx_text">1.16</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Mean absolute error (in °C) for each wind farm, start date and learning strategy, averaged across all time ranges, and wind turbines within each wind farm.</figcaption>
</figure>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
T. E, T. J, S. A, G. A, D. M, L. S, K. A, M. A, I. E, S. D, J. O. G, E. OD, G. M, Clean energy technology observatory: Wind energy in the european union - 2023 status report on technology development, trends, value chains and markets (KJ-NA-31-678-EN-N (online)).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.2760/618644%20(online)" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.2760/618644(online)</span></a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
GWEC, Global wind report 2023, <a target="_blank" href="https://gwec.net/wp-content/uploads/2023/03/GWR-2023_interactive.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://gwec.net/wp-content/uploads/2023/03/GWR-2023_interactive.pdf</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
G. Pang, C. Shen, L. Cao, A. V. D. Hengel, <a target="_blank" href="https://doi.org/10.1145/3439950" title="" class="ltx_ref ltx_href">Deep learning for anomaly detection: A review</a>, ACM Comput. Surv. 54 (2).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1145/3439950" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1145/3439950</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://doi.org/10.1145/3439950" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3439950</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
J. L. C. Hoffmann, L. P. Horstmann, M. M. Lucena, G. M. de Araujo, A. A. Fröhlich, M. H. N. Nishioka, <a target="_blank" href="https://doi.org/10.1080/08839514.2021.1966879" title="" class="ltx_ref ltx_href">Anomaly detection on wind turbines based on a deep learning analysis of vibration signals</a>, Applied Artificial Intelligence 35 (12) (2021) 893–913.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/https://doi.org/10.1080/08839514.2021.1966879" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">arXiv:https://doi.org/10.1080/08839514.2021.1966879</span></a>, <a target="_blank" href="http://dx.doi.org/10.1080/08839514.2021.1966879" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1080/08839514.2021.1966879</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://doi.org/10.1080/08839514.2021.1966879" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1080/08839514.2021.1966879</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
C. Zhang, T. Yang, <a target="_blank" href="https://www.mdpi.com/1996-1073/16/19/7008" title="" class="ltx_ref ltx_href">Anomaly detection for wind turbines using long short-term memory-based variational autoencoder wasserstein generation adversarial network under semi-supervised training</a>, Energies 16 (19).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.3390/en16197008" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.3390/en16197008</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://www.mdpi.com/1996-1073/16/19/7008" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/1996-1073/16/19/7008</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
B. Altice, E. Nazario, M. Davis, M. Shekaramiz, T. K. Moon, M. A. S. Masoum, <a target="_blank" href="https://www.mdpi.com/1996-1073/17/5/982" title="" class="ltx_ref ltx_href">Anomaly detection on small wind turbine blades using deep learning algorithms</a>, Energies 17 (5).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.3390/en17050982" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.3390/en17050982</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://www.mdpi.com/1996-1073/17/5/982" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/1996-1073/17/5/982</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Maron, D. Anagnostos, B. Brodbeck, A. Meyer, Artificial intelligence-based condition monitoring and predictive maintenance framework for wind turbines, Journal of Physics: Conference Series (2022) 2151<a target="_blank" href="http://dx.doi.org/10.1088/1742-6596/2151/1/012007" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1088/1742-6596/2151/1/012007</span></a>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
S. Jonas, D. Anagnostos, B. Brodbeck, A. Meyer, Vibration fault detection in wind turbines based on normal behaviour models without feature engineering, Energies (2023) 1760<a target="_blank" href="http://dx.doi.org/10.3390/en16041760" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.3390/en16041760</span></a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
P. Bangalore, S. Letzgus, D. Karlsson, M. Patriksson, <a target="_blank" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/we.2102" title="" class="ltx_ref ltx_href">An artificial neural network-based condition monitoring method for wind turbines, with application to the monitoring of the gearbox</a>, Wind Energy 20 (8) (2017) 1421–1438.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/https://onlinelibrary.wiley.com/doi/pdf/10.1002/we.2102" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1002/we.2102</span></a>, <a target="_blank" href="http://dx.doi.org/https://doi.org/10.1002/we.2102" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:https://doi.org/10.1002/we.2102</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/we.2102" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://onlinelibrary.wiley.com/doi/abs/10.1002/we.2102</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A. Kusiak, <a target="_blank" href="https://doi.org/10.1038/529019a" title="" class="ltx_ref ltx_href">Renewables: Share data on wind energy</a>, Nature 529 (7584) (2016) 19–21.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1038/529019a" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1038/529019a</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://doi.org/10.1038/529019a" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/529019a</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
A. Grataloup, S. Jonas, A. Meyer, <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S2666546824000417" title="" class="ltx_ref ltx_href">A review of federated learning in renewable energy applications: Potential, challenges, and future directions</a>, Energy and AI 17 (2024) 100375.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/https://doi.org/10.1016/j.egyai.2024.100375" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:https://doi.org/10.1016/j.egyai.2024.100375</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S2666546824000417" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S2666546824000417</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
L. Li, Y. Fan, M. Tse, K.-Y. Lin, A review of applications in federated learning, Computers &amp; Industrial Engineering 149 (2020) 106854.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1016/j.cie.2020.106854" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1016/j.cie.2020.106854</span></a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Y. Li, R. Wang, Y. Li, M. Zhang, C. Long, Wind power forecasting considering data privacy protection: A federated deep reinforcement learning approach, Applied Energy 329 (C).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1016/j.apenergy.2022.1" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1016/j.apenergy.2022.1</span></a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A. Ahmadi, M. Talaei, M. Sadipour, A. M. Amani, M. Jalili, Deep federated learning-based privacy-preserving wind power forecasting, IEEE access : practical innovations, open solutions 11 (2023) 39521–39530.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/ACCESS.2022.3232475" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ACCESS.2022.3232475</span></a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
H. Moayyed, A. Moradzadeh, B. Mohammadi-Ivatloo, A. P. Aguiar, R. Ghorbani, A Cyber-Secure generalized supermodel for wind power forecasting based on deep federated learning and image processing, Energy Conversion and Management 267 (2022) 115852.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1016/j.enconman.2022.115852" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1016/j.enconman.2022.115852</span></a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y. Wang, W. Zhang, Q. Guo, Y. Wu, A privacy-preserving wind speed prediction method based on federated deep learning, in: 2022 4th International Conference on Power and Energy Technology (ICPET), 2022, pp. 638–643.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/ICPET55165.2022.9918344" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ICPET55165.2022.9918344</span></a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
L. Wang, W. Fan, G. Jiang, P. Xie, <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0360544223019126" title="" class="ltx_ref ltx_href">An efficient federated transfer learning framework for collaborative monitoring of wind turbines in IoE-enabled wind farms</a>, Energy 284 (2023) 128518.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/https://doi.org/10.1016/j.energy.2023.128518" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:https://doi.org/10.1016/j.energy.2023.128518</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0360544223019126" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S0360544223019126</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
X. Cheng, F. Shi, Y. Liu, X. Liu, L. Huang, Wind turbine blade icing detection: A federated learning approach, Energy 254 (2022) 124441.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1016/j.energy.2022.124441" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1016/j.energy.2022.124441</span></a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
X. Cheng, F. Shi, Y. Liu, J. Zhou, X. Liu, L. Huang, A class-imbalanced heterogeneous federated learning model for detecting icing on wind turbine blades, IEEE Transactions on Industrial Informatics 18 (12) (2022) 8487–8497.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/TII.2022.3167467" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TII.2022.3167467</span></a>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
D. Zhang, W. Tian, Y. Yin, X. Liu, X. Cheng, F. Shi, Human knowledge-based compressed federated learning model for wind turbine blade icing detection, in: 2022 International Conference on High Performance Big Data and Intelligent Systems (HDIS), 2022, pp. 277–281.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/HDIS56859.2022.9991642" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/HDIS56859.2022.9991642</span></a>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
X. Cheng, W. Tian, F. Shi, M. Zhao, S. Chen, H. Wang, A blockchain-empowered cluster-based federated learning model for blade icing estimation on IoT-Enabled wind turbine, IEEE Transactions on Industrial Informatics 18 (12) (2022) 9184–9195.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/TII.2022.3159684" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TII.2022.3159684</span></a>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
G. Jiang, W. Fan, W. Li, L. Wang, Q. He, P. Xie, X. Li, DeepFedWT: A federated deep learning framework for fault detection of wind turbines, Measurement 199 (2022) 111529.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1016/j.measurement.2022.111529" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1016/j.measurement.2022.111529</span></a>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
W. Yang, G. Yu, Federated multi-model transfer learning-based fault diagnosis with peer-to-peer network for wind turbine cluster, Machines 10 (972).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.3390/machines10110972" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.3390/machines10110972</span></a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
L. Jenkel, S. Jonas, A. Meyer, Privacy-Preserving Fleet-Wide Learning of Wind Turbine Conditions with Federated Learning, Energies 16 (17) (2023) 6377.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.3390/en16176377" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.3390/en16176377</span></a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, B. A. y. Arcas, <a target="_blank" href="https://proceedings.mlr.press/v54/mcmahan17a.html" title="" class="ltx_ref ltx_href">Communication-Efficient Learning of Deep Networks from Decentralized Data</a>, in: A. Singh, J. Zhu (Eds.), Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, Vol. 54 of Proceedings of Machine Learning Research, PMLR, Fort Lauderdale, FL, USA, 2017, pp. 1273–1282.

<br class="ltx_break">URL <a target="_blank" href="https://proceedings.mlr.press/v54/mcmahan17a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v54/mcmahan17a.html</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
T.-M. H. Hsu, H. Qi, M. Brown, Measuring the Effects of Non-Identical Data Distribution for Federated Visual Classification<a target="_blank" href="http://dx.doi.org/10.48550/ARXIV.1909.06335" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.48550/ARXIV.1909.06335</span></a>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Q. Li, Y. Diao, Q. Chen, B. He, Federated Learning on Non-IID Data Silos: An Experimental Study<a target="_blank" href="http://dx.doi.org/10.48550/ARXIV.2102.02079" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.48550/ARXIV.2102.02079</span></a>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Y. Deng, M. M. Kamani, M. Mahdavi, Adaptive Personalized Federated Learning<a target="_blank" href="http://dx.doi.org/10.48550/ARXIV.2003.13461" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.48550/ARXIV.2003.13461</span></a>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
T. Yu, E. Bagdasaryan, V. Shmatikov, Salvaging Federated Learning by Local Adaptation<a target="_blank" href="http://dx.doi.org/10.48550/ARXIV.2002.04758" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.48550/ARXIV.2002.04758</span></a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
C. Briggs, Z. Fan, P. Andras, Federated learning with hierarchical clustering of local updates to improve training on non-IID data, in: 2020 International Joint Conference on Neural Networks (IJCNN), IEEE, Glasgow, United Kingdom, 2020, pp. 1–9.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/IJCNN48605.2020.9207469" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/IJCNN48605.2020.9207469</span></a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
G. Long, M. Xie, T. Shen, T. Zhou, X. Wang, J. Jiang, Multi-center federated learning: Clients clustering for better personalization, World Wide Web-internet and Web Information Systems 26 (1) (2022) 481–500.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1007/s11280-022-01046-x" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1007/s11280-022-01046-x</span></a>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
L. Tang, H. Xie, X. Wang, Z. Bie, Privacy-preserving knowledge sharing for few-shot building energy prediction: A federated learning approach, Applied Energy 337 (2023) 120860.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1016/j.apenergy.2023.120860" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1016/j.apenergy.2023.120860</span></a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
J. C. Bezdek, Objective function clustering, in: Pattern Recognition with Fuzzy Objective Function Algorithms, Springer US, Boston, MA, 1981, pp. 43–93.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1007/978-1-4757-0450-1-3" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1007/978-1-4757-0450-1-3</span></a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
M. G. Arivazhagan, V. Aggarwal, A. K. Singh, S. Choudhary, Federated Learning with Personalization Layers<a target="_blank" href="http://dx.doi.org/10.48550/ARXIV.1912.00818" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.48550/ARXIV.1912.00818</span></a>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
A. Fallah, A. Mokhtari, A. Ozdaglar, <a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/24389bfe4fe2eba8bf9aa9203a44cdad-Paper.pdf" title="" class="ltx_ref ltx_href">Personalized federated learning with theoretical guarantees: A model-agnostic meta-learning approach</a>, in: H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, H. Lin (Eds.), Advances in Neural Information Processing Systems, Vol. 33, Curran Associates, Inc., Virtual, 2020, pp. 3557–3568.

<br class="ltx_break">URL <a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/24389bfe4fe2eba8bf9aa9203a44cdad-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper_files/paper/2020/file/24389bfe4fe2eba8bf9aa9203a44cdad-Paper.pdf</a>

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
L. Collins, H. Hassani, A. Mokhtari, S. Shakkottai, FedAvg with Fine Tuning: Local Updates Lead to Representation Learning<a target="_blank" href="http://dx.doi.org/10.48550/ARXIV.2205.13692" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.48550/ARXIV.2205.13692</span></a>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
A. Z. Tan, H. Yu, L. Cui, Q. Yang, Towards Personalized Federated Learning, IEEE Transactions on Neural Networks and Learning Systems (2022) 1–17<a target="_blank" href="http://dx.doi.org/10.1109/TNNLS.2022.3160699" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TNNLS.2022.3160699</span></a>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
V. Kulkarni, M. Kulkarni, A. Pant, Survey of Personalization Techniques for Federated Learning, in: 2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4), IEEE, London, United Kingdom, 2020, pp. 794–797.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/WorldS450073.2020.9210355" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/WorldS450073.2020.9210355</span></a>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
E. Serral, P. Valderas, V. Pelechano, Improving the cold-start problem in user task automation by using models at runtime, Information Systems Development<a target="_blank" href="http://dx.doi.org/10.1007/978-1-4419-9790-6_54" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1007/978-1-4419-9790-6_54</span></a>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, Y. Cheng, Y. Kang, T. Chen, H. Yu, Federated Transfer Learning, Springer International Publishing, Cham, 2020, pp. 83–93.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1007/978-3-031-01585-4_6" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1007/978-3-031-01585-4_6</span></a>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
C. Plumley, <a target="_blank" href="https://doi.org/10.5281/zenodo.5946808" title="" class="ltx_ref ltx_href">Penmanshiel wind farm data</a> (Feb. 2022).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.5281/zenodo.5946808" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.5281/zenodo.5946808</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://doi.org/10.5281/zenodo.5946808" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.5946808</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
C. Plumley, <a target="_blank" href="https://doi.org/10.5281/zenodo.5841834" title="" class="ltx_ref ltx_href">Kelmarsh wind farm data</a> (Feb. 2022).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.5281/zenodo.5841834" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.5281/zenodo.5841834</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://doi.org/10.5281/zenodo.5841834" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.5841834</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.edp.com/en/innovation/open-data/wind-turbine-scada-signals-2016" title="" class="ltx_ref ltx_href">Creative commons attribution-sharealike</a>.

<br class="ltx_break">URL <a target="_blank" href="https://www.edp.com/en/innovation/open-data/wind-turbine-scada-signals-2016" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.edp.com/en/innovation/open-data/wind-turbine-scada-signals-2016</a>

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.edp.com/en/innovation/open-data/wind-turbine-scada-signals-2017" title="" class="ltx_ref ltx_href">Creative commons attribution-sharealike</a>.

<br class="ltx_break">URL <a target="_blank" href="https://www.edp.com/en/innovation/open-data/wind-turbine-scada-signals-2017" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.edp.com/en/innovation/open-data/wind-turbine-scada-signals-2017</a>

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, V. Smith, Federated Optimization in Heterogeneous Networks<a target="_blank" href="http://dx.doi.org/10.48550/ARXIV.1812.06127" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.48550/ARXIV.1812.06127</span></a>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
B. Celik, J. Vanschoren, <a target="_blank" href="https://api.semanticscholar.org/CorpusID:219573246" title="" class="ltx_ref ltx_href">Adaptation strategies for automated machine learning on evolving data</a>, IEEE Transactions on Pattern Analysis and Machine Intelligence 43 (2020) 3067–3078.

<br class="ltx_break">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:219573246" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:219573246</a>

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
M. Khodak, R. Tu, T. Li, L. Li, M.-F. F. Balcan, V. Smith, A. Talwalkar, Federated hyperparameter tuning: Challenges, baselines, and connections to weight-sharing, Advances in Neural Information Processing Systems 34 (2021) 19184–19197, <a target="_blank" href="https://proceedings.neurips.cc/paper/2021/hash/a0205b87490c847182672e8d371e9948-Abstract.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2021/hash/a0205b87490c847182672e8d371e9948-Abstract.html</a>.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
L. Wang, X. Zhang, H. Su, J. Zhu, A comprehensive survey of continual learning: Theory, method and application, IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence (01) (5555) 1–20.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/TPAMI.2024.3367329" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TPAMI.2024.3367329</span></a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.03671" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.03672" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.03672">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.03672" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.03673" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Oct  6 00:32:37 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
