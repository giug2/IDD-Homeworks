<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2308.08786] APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service</title><meta property="og:description" content="Cross-silo privacy-preserving federated learning (PPFL) is a powerful tool to collaboratively train robust and generalized machine learning (ML) models
without sharing sensitive (e.g., healthcare of financial) local da…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2308.08786">

<!--Generated on Wed Feb 28 12:34:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated learning,  privacy preserving,  federation as a service,  AI for science,  science as a service,  HPC,  IAM
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zilinghan Li123,
Shilan He134,
Pranshu Chaturvedi123,
Trung-Hieu Hoang4,
Minseok Ryu5,
E. A. Huerta167,
<br class="ltx_break">Volodymyr Kindratenko234,
Jordan Fuhrman 19,
Maryellen Giger 19,
Ryan Chard18,
Kibaek Kim9,
Ravi Madduri18
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">1Data Science and Learning Division, Argonne National Laboratory, Lemont, IL 60439 USA
</span>
<span class="ltx_contact ltx_role_affiliation">2Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801 USA
</span>
<span class="ltx_contact ltx_role_affiliation">3National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign, Urbana, IL 61801 USA
</span>
<span class="ltx_contact ltx_role_affiliation">4Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL 61801 USA
</span>
<span class="ltx_contact ltx_role_affiliation">5School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ 85281 USA
</span>
<span class="ltx_contact ltx_role_affiliation">6Department of Physics, University of Illinois at Urbana-Champaign, Urbana, IL 61801 USA
</span>
<span class="ltx_contact ltx_role_affiliation">7Department of Computer Science, The University of Chicago, Chicago, IL 60637 USA
</span>
<span class="ltx_contact ltx_role_affiliation">8University of Chicago Consortium for Advanced Science and Engineering, Chicago, IL 60637 USA
</span>
<span class="ltx_contact ltx_role_affiliation">9Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL 60439 USA
</span>
<span class="ltx_contact ltx_role_affiliation">10Department of Radiology, University of Chicago, Hyde Park, IL 60616 USA
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Cross-silo privacy-preserving federated learning (PPFL) is a powerful tool to collaboratively train robust and generalized machine learning (ML) models
without sharing sensitive (e.g., healthcare of financial) local data. To ease and accelerate the adoption of
PPFL, we introduce <span id="id1.id1.1" class="ltx_text ltx_font_italic">APPFLx</span>, a ready-to-use
platform that provides privacy-preserving cross-silo federated learning as a service. <span id="id1.id1.2" class="ltx_text ltx_font_italic">APPFLx</span> employs Globus authentication to allow users to easily and securely invite trustworthy collaborators for PPFL, implements several synchronous and asynchronous FL algorithms, streamlines the FL experiment launch process, and enables tracking and visualizing the life cycle of FL experiments, allowing domain experts and ML practitioners to easily orchestrate and evaluate cross-silo FL under one platform. <span id="id1.id1.3" class="ltx_text ltx_font_italic">APPFLx</span> is available online at https://appflx.link</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated learning, privacy preserving, federation as a service, AI for science, science as a service, HPC, IAM

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Building robust machine learning (ML) models that are resilient to domain shift <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> requires training across diverse, oftentimes private, datasets; as well as access to large computing
resources. Federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> is a collaborative learning approach, capable of addressing domain shift challenges, where multiple data owners, referred to as clients, train a model together under the orchestration of a central server by sharing the ML model trained on their local datasets instead of sharing the data directly.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">FL enables the creation of more robust models without the exposure of local datasets. However, FL by itself, does not guarantee the privacy of data, because the information extracted from the communication of FL algorithms can be accumulated and utilized to infer the private local data used for training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. To address these challenges, we developed an open-source software framework, called Argonne Privacy Preserving Federated Learning (APPFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, whose algorithmic advances in differential privacy
enable privacy-preserving federated learning (PPFL).
APPFL enables the training of ML models in a distributed setting across multiple institutions, where sensitive data are located, with the ability to scale on supercomputing resources. With APPFL,
researchers can develop robust, trustworthy ML models
for applications in biomedicine and smart grid applications, where data privacy is essential.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Setting up a secure FL experiment that needs high-performance computing resources across distributed sites requires technical capabilities that may not be available for all. To lower the technical and cybersecurity barriers to entry for leveraging PPFL, and to enable domain experts in large institutions to utilize FL, we created the Argonne Privacy-Preserving Federated Learning as a service (<span id="S1.p3.1.1" class="ltx_text ltx_font_italic">APPFLx</span>), which enables cross-silo PPFL with user-friendly web interfaces for managing, deploying, analyzing, and visualizing PPFL experiments.
<span id="S1.p3.1.2" class="ltx_text ltx_font_italic">APPFLx</span> also enables the creation of secure federations with end-to-end strong Identity and Access Management (IAM), where collaborators across organizational boundaries can create a new federation or join an existing federation using their institutional identities, perform training on datasets at their respective institutions and securely share the privacy-preserving model weights with the service to enable secure aggregation.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Existing PPFL frameworks typically involve downloading and configuring complex software, manually creating trust boundaries and identities to enable gradient aggregation, and understanding of technical details of the underlying deep learning software stack to enable distributed training which is cumbersome <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
In stark contrast, <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">APPFLx</span> features include:
1) secure distributed training on heterogeneous computing resources, along with over half a dozen federation strategies; 2) both synchronous and asynchronous aggregation; 3) integration with TensorBoard capabilities; 4) interfaces to examine data distributions and resource utilization across different sites; 5) detailed reports of different experiments, ability to use model architectures from GitHub or pre-trained models from HuggingFace model repository; and 6) the ability to set different hyper-parameters of the experiments (like privacy budget to be used in training) from the convenient web interface. Additionally, we developed comprehensive approaches to measure privacy protection by attacking models generated by <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">APPFLx</span> and implemented FAIR standards <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> for capturing and storing the metadata for all the PPFL experiments to
ensure reproducibility.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">System Overview</span>
</h2>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2308.08786/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="167" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>System overview of <span id="S2.F1.2.1" class="ltx_text ltx_font_italic">APPFLx</span>.</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section we describe the main components of <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">APPFLx</span>; see Figure <a href="#S2.F1" title="Figure 1 ‣ II System Overview ‣ APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for the system overview.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Identity and Access Management (IAM).</span> In cross-silo PPFL, ensuring the verification of collaborating clients’ identities is of utmost importance to prevent potential attacks from Byzantine clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. <span id="S2.p2.1.2" class="ltx_text ltx_font_italic">APPFLx</span> utilizes the Globus authentication service <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> for user identification. Authenticated users can create a “federation” using the Globus group authorization service and extend invitations to trusted collaborators, allowing them to conduct FL experiments securely and efficiently.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Client Computing Resources &amp; Data.</span> In an FL group, each client has access to private local datasets. The composition of FL clients is generally heterogeneous in computing capabilities, and each FL client may also have a heterogeneous computing resource. Examples of typical FL clients include high performance computing clusters with job schedulers such as SLURM and cloud computing machines. <span id="S2.p3.1.2" class="ltx_text ltx_font_italic">APPFLx</span> allows users to easily register their heterogeneous computing resources for FL by following a simple one-time setup. This setup process includes creating a Globus Compute (previously known as funcX) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> endpoint and installing the APPFLx client package on the computing resource. FuncX is a distributed Function as a Service (FaaS) platform used by <span id="S2.p3.1.3" class="ltx_text ltx_font_italic">APPFLx</span> to dispatch the training task codebase from the server to clients for local training. Clients are required to open ports 443 (HTTPS) and 5671 (AMQPS) for outbound traffic to transmit tasks and results between the funcX service and the endpoints, where HTTPS is used for retrieving credentials and AMQPS is used for encrypted task/result transmission. The APPFLx client package contains the codebase that provides seamless support for remote training tasks. The process of setting up a funcX endpoint also incorporates Globus authentication, ensuring that only members belonging to the same FL group are authorized to send codebase for execution on the funcX endpoints. This stringent security measure fosters a protected environment for the FL collaborators.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Client Configuration Page.</span> Once the clients have created funcX endpoints, they can register their computing resources by providing the funcX endpoint ID and the device type on the client configuration page of <span id="S2.p4.1.2" class="ltx_text ltx_font_italic">APPFLx</span>. Furthermore, clients are required to upload a data loader file on this page that enables the dispatched training codebase to access their local data on their computing resources during the training.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Server Configuration Page.</span> The FL group administrator is responsible for configuring the FL settings on the <span id="S2.p5.1.2" class="ltx_text ltx_font_italic">APPFLx</span> server configuration page. These settings include the FL algorithm, training model architecture, training loss function, hyper-parameters (e.g., learning rate, number of local and global epochs), and privacy budgets. In particular, <span id="S2.p5.1.3" class="ltx_text ltx_font_italic">APPFLx</span> provides five synchronous FL algorithms (<span id="S2.p5.1.4" class="ltx_text ltx_font_typewriter">FedAvg</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, <span id="S2.p5.1.5" class="ltx_text ltx_font_typewriter">FedAvgM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, <span id="S2.p5.1.6" class="ltx_text ltx_font_typewriter">FedAdam</span>, <span id="S2.p5.1.7" class="ltx_text ltx_font_typewriter">FedAdagrad</span>, and <span id="S2.p5.1.8" class="ltx_text ltx_font_typewriter">FedYogi</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>) and two asynchronous FL algorithms (<span id="S2.p5.1.9" class="ltx_text ltx_font_typewriter">FedAsync</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and <span id="S2.p5.1.10" class="ltx_text ltx_font_typewriter">FedBuf</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>). For the training model, <span id="S2.p5.1.11" class="ltx_text ltx_font_italic">APPFLx</span> offers flexible choices — users can choose pre-defined template models or upload their own model definition files from their local computers. Moreover, the platform seamlessly integrates with GitHub, promoting enhanced collaboration opportunities among the FL group members, and it also integrates with HuggingFace to allow users to leverage pre-trained models, further enhancing the efficiency of the FL. Understanding training data distribution across the different sites in a federation is an important aspect to reason with FL model performance. On the server configuration page, the FL administrator can visualize the distribution of the training data across available sites before starting the FL process. Additionally, the FL administrator can check the status of client endpoints and launch an FL experiment on this page.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p"><span id="S2.p6.1.1" class="ltx_text ltx_font_bold">FL Server Container.</span> Upon initiation by the FL group administrator, <span id="S2.p6.1.2" class="ltx_text ltx_font_italic">APPFLx</span> launches an FL orchestration server in a container using AWS Elastic Container Service (ECS) and AWS Fargate, facilitating both scalability and robustness. The server retrieves the experiment configurations from AWS S3 and acts as a funcX client to dispatch training functions to the client funcX endpoints to train models using their local data. <span id="S2.p6.1.3" class="ltx_text ltx_font_italic">APPFLx</span> employs the AWS S3 bucket for model transfers between the server container and client endpoints. The server aggregates the locally trained models based on the choice of the FL algorithms available in APPFL.
As the FL experiment unfolds, the server stores all the experiment logs and results in the AWS cloud storage, ensuring comprehensive and reliable record-keeping.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p"><span id="S2.p7.1.1" class="ltx_text ltx_font_bold">AWS Cloud Storage.</span> <span id="S2.p7.1.2" class="ltx_text ltx_font_italic">APPFLx</span> utilizes AWS cloud storage services to securely and reliably store all FL experiment information. Specifically, real-time training logs are seamlessly managed by AWS CloudWatch. DynamoDB is used to store experiment metadata, and AWS S3 plays a pivotal role in storing a diverse array of experiment-related files, including configuration files, various result files, and training log backups. Incorporating these AWS cloud storage services, <span id="S2.p7.1.3" class="ltx_text ltx_font_italic">APPFLx</span> guarantees a resilient infrastructure, allowing users to confidently engage in FL experiments while maintaining the utmost data integrity and privacy.</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.1" class="ltx_p"><span id="S2.p8.1.1" class="ltx_text ltx_font_bold">Federation Information Page.</span> Powered by the AWS cloud storage, <span id="S2.p8.1.2" class="ltx_text ltx_font_italic">APPFLx</span> provides an information page accessible to all FL group members. This page provides a wealth of valuable information regarding the FL experiments conducted within the group. Users can access real-time training logs for immediate monitoring and insightful analysis of ongoing training processes. Experiment configurations are also available for review on this page. In addition, users can access essential training metrics, such as the time taken for each client to complete specific training tasks, for in-depth performance evaluation. Furthermore, the page provides reports containing the local validation accuracy results for each client. <span id="S2.p8.1.3" class="ltx_text ltx_font_italic">APPFLx</span> can also generate a comparison report, which empowers users to conduct thorough comparisons across multiple experiment runs, facilitating data-driven decision-making and fostering continuous improvements in the FL process. Finally, the group administrator is provided with an endpoint information section to monitor the CPU, GPU, memory, and network usage of the client endpoints in real-time. The federation information page serves as an invaluable resource, promoting collaboration, transparency, and efficiency within the FL group.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Experiment</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Experiment Settings and Launch</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In this section, we present a use case that employs <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">APPFLx</span> to conduct federated learning with a group of five clients to train a convolutional neural network (CNN) with two convolutional layers using the artificially partitioned MNIST datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. The MNIST dataset is partitioned equally into five chunks as the local datasets of the five FL clients. Two synchronous FL algorithms, <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_typewriter">FedAvgM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, are employed to train the model. The FL training takes 10 global communication rounds, and each client performs 2 local epochs in each round with batch size 64 and local learning rate 0.01. Local learning rate is decayed by a factor of 0.975 for each round, and the server momentum for <span id="S3.SS1.p1.1.4" class="ltx_text ltx_markedasmath ltx_font_typewriter">FedAvgM</span> is equal to 0.9.
Table <a href="#S3.T1" title="TABLE I ‣ III-A Experiment Settings and Launch ‣ III Experiment ‣ APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> shows the information of five heterogeneous client endpoints. Notably, all the endpoints only use the CPU for training. The group members use the client configuration page to register their endpoints and upload data loaders for their local datasets. The group administrator launches the FL experiment by specifying the training hyper-parameters in the server configuration page.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Client endpoints information.</figcaption>
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Endpoint name</th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Machine</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.2.1" class="ltx_tr">
<td id="S3.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T1.1.2.1.1.1" class="ltx_text ltx_font_typewriter">delta-cpu-01</span></td>
<td id="S3.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">NCSA Delta supercomputer</td>
</tr>
<tr id="S3.T1.1.3.2" class="ltx_tr">
<td id="S3.T1.1.3.2.1" class="ltx_td ltx_align_left"><span id="S3.T1.1.3.2.1.1" class="ltx_text ltx_font_typewriter">delta-gpu-01</span></td>
<td id="S3.T1.1.3.2.2" class="ltx_td ltx_align_left">NCSA Delta supercomputer</td>
</tr>
<tr id="S3.T1.1.4.3" class="ltx_tr">
<td id="S3.T1.1.4.3.1" class="ltx_td ltx_align_left"><span id="S3.T1.1.4.3.1.1" class="ltx_text ltx_font_typewriter">mydefconf</span></td>
<td id="S3.T1.1.4.3.2" class="ltx_td ltx_align_left">ALCF Polaris supercomputer</td>
</tr>
<tr id="S3.T1.1.5.4" class="ltx_tr">
<td id="S3.T1.1.5.4.1" class="ltx_td ltx_align_left"><span id="S3.T1.1.5.4.1.1" class="ltx_text ltx_font_typewriter">crn-azure</span></td>
<td id="S3.T1.1.5.4.2" class="ltx_td ltx_align_left">Microsoft Azure virtual machine</td>
</tr>
<tr id="S3.T1.1.6.5" class="ltx_tr">
<td id="S3.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T1.1.6.5.1.1" class="ltx_text ltx_font_typewriter">appfl-test</span></td>
<td id="S3.T1.1.6.5.2" class="ltx_td ltx_align_left ltx_border_bb">MacBook Pro, 2021, M1 Chip</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Experiment Information and Results</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">As previously mentioned, <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">APPFLx</span> offers a federation information page for all group members to access the information and results of the FL experiments, and the group administrator is also provided with an endpoint information section to monitor the status of all the client endpoints, as shown in Figure <a href="#S3.F2" title="Figure 2 ‣ III-B Experiment Information and Results ‣ III Experiment ‣ APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Figure <a href="#S3.F3" title="Figure 3 ‣ III-B Experiment Information and Results ‣ III Experiment ‣ APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> showcases the client endpoint monitor page, presenting real-time resource utilization for each client endpoint. For launched FL experiments, group members have access to various components, including real-time logs, experiment configurations, experiment reports, and tensorboard visualizations (Figure <a href="#S3.F4" title="Figure 4 ‣ III-B Experiment Information and Results ‣ III Experiment ‣ APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). Figure <a href="#S3.F5" title="Figure 5 ‣ III-B Experiment Information and Results ‣ III Experiment ‣ APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the change in the validation accuracy of <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> and <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_typewriter">FedAvgM</span> algorithms during the training process.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2308.08786/assets/endpoint-info1.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="256" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Federation information page.</figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2308.08786/assets/clean_board.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="586" height="568" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Client endpoints monitor page.</figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2308.08786/assets/5_sites.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="586" height="380" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Tensorboard visualization page showing ML model performance at five different sites.</figcaption>
</figure>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2308.08786/assets/x2.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="203" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Validation accuracy of <span id="S3.F5.3.1" class="ltx_text ltx_font_typewriter">FedAvg</span> and <span id="S3.F5.4.2" class="ltx_text ltx_font_typewriter">FedAvgM</span> during the federated learning process.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p"><span id="S4.p1.1.1" class="ltx_text ltx_font_italic">APPFLx</span> is a user-friendly platform that provides privacy-preserving cross-silo federated learning as a service. With streamlined FL experiment launching process and comprehensive experiment results, <span id="S4.p1.1.2" class="ltx_text ltx_font_italic">APPFLx</span> enhances the accessibility and ease of use of privacy-preserving federated learning for professionals across diverse industries. This efficient and collaborative environment empowers users to develop robust and generalized ML models securely, promoting advancements in various fields while safeguarding data privacy.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The material is based upon work and resources of the Argonne Leadership Computing Facility at Argonne National Laboratory, which is supported by the U.S. Department of Energy, Office of Science, under contract number DE-AC02-06CH11357 and in part by MIDRC (The Medical Imaging and Data Resource Center) funded by the the National Institutes of Health under contract 75N92020C00021.
This research is also part of the Delta research computing project, which is supported by the National Science Foundation (award OCI 2005572), and the State of Illinois. Delta is a joint effort of the University of Illinois at Urbana-Champaign and its National Center for SuperComputing Applications.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
“The clinician and dataset shift in artificial intelligence,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">The New
England Journal of Medicine</em>, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. Hatamizadeh, H. Yin, H. R. Roth, W. Li, J. Kautz, D. Xu, and P. Molchanov,
“Gradvit: Gradient inversion of vision transformers,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
(CVPR)</em>, June 2022, pp. 10 021–10 030.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M. Ryu, Y. Kim, K. Kim, and R. K. Madduri, “APPFL: Open-source software
framework for privacy-preserving federated learning,” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">2022 IEEE
International Parallel and Distributed Processing Symposium Workshops
(IPDPSW)</em>.   IEEE, 2022, pp. 1074–1083.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
D. J. Beutel, T. Topal, A. Mathur, X. Qiu, J. Fernandez-Marques, Y. Gao,
L. Sani, K. H. Li, T. Parcollet, P. P. B. de Gusmão <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
“Flower: A friendly federated learning research framework,” <em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2007.14390</em>, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
H. R. Roth, Y. Cheng, Y. Wen, I. Yang, Z. Xu, Y.-T. Hsieh, K. Kersten,
A. Harouni, C. Zhao, K. Lu <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Nvidia flare: Federated learning
from simulation to real-world,” <em id="bib.bib6.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.13291</em>,
2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
N. Ravi, P. Chaturvedi, E. A. Huerta, Z. Liu, R. Chard,
A. Scourtas, K. J. Schmidt, K. Chard, B. Blaiszik, and I. Foster,
“FAIR principles for AI models with a practical application for accelerated
high energy diffraction microscopy,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Scientific Data</em>, vol. 9, no. 1,
p. 657, Nov. 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
E. A. Huerta, B. Blaiszik, L. C. Brinson, K. E. Bouchard, D. Diaz, C. Doglioni,
J. M. Duarte, M. Emani, I. Foster, G. Fox, P. Harris, L. Heinrich, S. Jha,
D. S. Katz, V. Kindratenko, C. R. Kirkpatrick, K. Lassila-Perini, R. K.
Madduri, M. S. Neubauer, F. E. Psomopoulos, A. Roy, O. Rübel, Z. Zhao, and
R. Zhu, “FAIR for AI: An interdisciplinary and international community
building perspective,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Scientific Data</em>, vol. 10, no. 1, jul 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
L. Lamport, R. Shostak, and M. Pease, “The byzantine generals problem,” in
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Concurrency: the works of leslie lamport</em>, 2019, pp. 203–226.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
I. Foster, “Globus online: Accelerating and democratizing science through
cloud-based services,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE Internet Computing</em>, vol. 15, no. 3, pp.
70–73, 2011.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
B. Allen, J. Bresnahan, L. Childers, I. Foster, G. Kandaswamy, R. Kettimuthu,
J. Kordas, M. Link, S. Martin, K. Pickett <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Software as a
service for data scientists,” <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, vol. 55,
no. 2, pp. 81–88, 2012.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
S. Tuecke, R. Ananthakrishnan, K. Chard, M. Lidman, B. McCollam, S. Rosen, and
I. Foster, “Globus auth: A research identity and access management
platform,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">2016 IEEE 12th International Conference on e-Science
(e-Science)</em>.   IEEE, 2016, pp.
203–212.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
R. Chard, Y. Babuji, Z. Li, T. Skluzacek, A. Woodard, B. Blaiszik, I. Foster,
and K. Chard, “FuncX: A federated function serving fabric for science,”
in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th International symposium on high-performance
parallel and distributed computing</em>, 2020, pp. 65–76.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
T.-M. H. Hsu, H. Qi, and M. Brown, “Measuring the effects of non-identical
data distribution for federated visual classification,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1909.06335</em>, 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
S. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Konečnỳ,
S. Kumar, and H. B. McMahan, “Adaptive federated optimization,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2003.00295</em>, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
C. Xie, S. Koyejo, and I. Gupta, “Asynchronous federated optimization,”
<em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1903.03934</em>, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Nguyen, K. Malik, H. Zhan, A. Yousefpour, M. Rabbat, M. Malek, and D. Huba,
“Federated learning with buffered asynchronous aggregation,” in
<em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence and
Statistics</em>.   PMLR, 2022, pp.
3581–3607.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
L. Deng, “The mnist database of handwritten digit images for machine learning
research [best of the web],” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">IEEE signal processing magazine</em>,
vol. 29, no. 6, pp. 141–142, 2012.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2308.08785" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2308.08786" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2308.08786">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2308.08786" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2308.08787" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 12:34:04 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
