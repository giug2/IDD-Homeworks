<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems</title>
<!--Generated on Mon May 27 12:20:02 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Speaker recognition,  voice-controlled systems,  adversarial examples,  replay attack,  jamming attack,  liveness detection,  voice-synthesis attack." lang="en" name="keywords"/>
<base href="/html/2405.17100v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S1" title="In Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2" title="In Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS1" title="In 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>System Overview of VCS</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS1.SSS1" title="In 2.1. System Overview of VCS ‣ 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.1 </span>Physical Layer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS1.SSS2" title="In 2.1. System Overview of VCS ‣ 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.2 </span>Preprocessing Layer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS1.SSS3" title="In 2.1. System Overview of VCS ‣ 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.3 </span>Kernel Layer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS1.SSS4" title="In 2.1. System Overview of VCS ‣ 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.4 </span>Service Layer</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS2" title="In 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Attacks against VCS</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS2.SSS1" title="In 2.2. Attacks against VCS ‣ 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>Threat Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS2.SSS2" title="In 2.2. Attacks against VCS ‣ 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.2 </span>Attack Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS2.SSS3" title="In 2.2. Attacks against VCS ‣ 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.3 </span>Attacker Goal</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS3" title="In 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Defense Schemes in VCS</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.SS4" title="In 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Layer-Based Systematization of Attacks and Defenses in VCS</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S3" title="In Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Physical Layer</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S3.SS1" title="In 3. Physical Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Transduction Attacks in Physical Layer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S3.SS2" title="In 3. Physical Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Voice-synthesis Attacks in Physical Layer</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S4" title="In Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Preprocessing Layer</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S4.SS1" title="In 4. Preprocessing Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Voice-synthesis Attacks in Preprocessing Layer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S4.SS2" title="In 4. Preprocessing Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Adversarial Attacks in Preprocessing Layer</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S4.SS2.SSS1" title="In 4.2. Adversarial Attacks in Preprocessing Layer ‣ 4. Preprocessing Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Taxonomy of Adversarial Attacks in VCS</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S4.SS2.SSS2" title="In 4.2. Adversarial Attacks in Preprocessing Layer ‣ 4. Preprocessing Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Basic Idea of Designing Adversarial Samples</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S4.SS2.SSS3" title="In 4.2. Adversarial Attacks in Preprocessing Layer ‣ 4. Preprocessing Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>The Characteristics of Adversarial Attacks in Preprocessing Layer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S4.SS2.SSS4" title="In 4.2. Adversarial Attacks in Preprocessing Layer ‣ 4. Preprocessing Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.4 </span>Defense Schemes against Adversarial Attacks.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5" title="In Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Kernel Layer</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.SS1" title="In 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Spoofing Attacks in Kernel Layer</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.SS1.SSS1" title="In 5.1. Spoofing Attacks in Kernel Layer ‣ 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Replay</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.SS1.SSS2" title="In 5.1. Spoofing Attacks in Kernel Layer ‣ 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Impersonation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.SS1.SSS3" title="In 5.1. Spoofing Attacks in Kernel Layer ‣ 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.3 </span>Speech Synthesis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.SS1.SSS4" title="In 5.1. Spoofing Attacks in Kernel Layer ‣ 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.4 </span>Voice Conversion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.SS1.SSS5" title="In 5.1. Spoofing Attacks in Kernel Layer ‣ 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.5 </span>Twins</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.SS1.SSS6" title="In 5.1. Spoofing Attacks in Kernel Layer ‣ 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.6 </span>Defense Schemes against Spoofing Attacks.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.SS2" title="In 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Adversarial Attacks in Kernel Layer</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.SS2.SSS1" title="In 5.2. Adversarial Attacks in Kernel Layer ‣ 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.1 </span>Adversarial Examples Crafting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.SS2.SSS2" title="In 5.2. Adversarial Attacks in Kernel Layer ‣ 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.2 </span>Defense Schemes against Adversarial Attacks.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S6" title="In Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Service Layer</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S6.SS1" title="In 6. Service Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Squatting Attacks in Service Layer</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S6.SS1.SSS1" title="In 6.1. Squatting Attacks in Service Layer ‣ 6. Service Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1.1 </span>Defense Schemes against Squatting Attacks.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S6.SS2" title="In 6. Service Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Faking Termination in Service Layer</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S6.SS2.SSS1" title="In 6.2. Faking Termination in Service Layer ‣ 6. Service Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.1 </span>Defense Schemes against Faking Termination.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S7" title="In Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>General Attack Mitigation Strategy</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S7.SS1" title="In 7. General Attack Mitigation Strategy ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Liveness Detection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S7.SS2" title="In 7. General Attack Mitigation Strategy ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Audio Conversion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S8" title="In Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Challenges and Future Directions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S8.SS1" title="In 8. Challenges and Future Directions ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>Challenges</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S8.SS2" title="In 8. Challenges and Future Directions ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>Future Directions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S9" title="In Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\UseRawInputEncoding</span>
</div>
<h1 class="ltx_title ltx_title_document">Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems </h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Haozhe Xu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:haozhexu@whu.edu.cn">haozhexu@whu.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0008-8264-725X" title="ORCID identifier">0009-0008-8264-725X</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Wuhan University</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Wuhan</span><span class="ltx_text ltx_affiliation_state" id="id3.3.id3">Hubei</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">CN</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Cong Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-0930-0283" title="ORCID identifier">0000-0002-0930-0283</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Wuhan University</span><span class="ltx_text ltx_affiliation_city" id="id6.2.id2">Wuhan</span><span class="ltx_text ltx_affiliation_state" id="id7.3.id3">Hubei</span><span class="ltx_text ltx_affiliation_country" id="id8.4.id4">CN</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:cnacwu@whu.edu.cn">cnacwu@whu.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yangyang Gu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:guyangyang@whu.edu.cn">guyangyang@whu.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">Wuhan University</span><span class="ltx_text ltx_affiliation_city" id="id10.2.id2">Wuhan</span><span class="ltx_text ltx_affiliation_state" id="id11.3.id3">Hubei</span><span class="ltx_text ltx_affiliation_country" id="id12.4.id4">CN</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xingcan Shang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:xc%CB%99shang@whu.edu.cn">xc˙shang@whu.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id13.1.id1">Wuhan University</span><span class="ltx_text ltx_affiliation_city" id="id14.2.id2">Wuhan</span><span class="ltx_text ltx_affiliation_state" id="id15.3.id3">Hubei</span><span class="ltx_text ltx_affiliation_country" id="id16.4.id4">CN</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jing Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:chenjing@whu.edu.cn">chenjing@whu.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-7212-5297" title="ORCID identifier">0000-0002-7212-5297</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id17.1.id1">Wuhan University</span><span class="ltx_text ltx_affiliation_city" id="id18.2.id2">Wuhan</span><span class="ltx_text ltx_affiliation_state" id="id19.3.id3">Hubei</span><span class="ltx_text ltx_affiliation_country" id="id20.4.id4">CN</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kun He
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:hekun@whu.edu.cn">hekun@whu.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0003-3472-419X" title="ORCID identifier">0000-0003-3472-419X</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id21.1.id1">Wuhan University</span><span class="ltx_text ltx_affiliation_city" id="id22.2.id2">Wuhan</span><span class="ltx_text ltx_affiliation_state" id="id23.3.id3">Hubei</span><span class="ltx_text ltx_affiliation_country" id="id24.4.id4">CN</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ruiying Du
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:duraying@whu.edu.cn">duraying@whu.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id25.1.id1">Wuhan University</span><span class="ltx_text ltx_affiliation_city" id="id26.2.id2">Wuhan</span><span class="ltx_text ltx_affiliation_state" id="id27.3.id3">Hubei</span><span class="ltx_text ltx_affiliation_country" id="id28.4.id4">CN</span>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id29.id1">The integration of Voice Control Systems (VCS) into smart devices and their growing presence in daily life accentuate the importance of their security.
Current research has uncovered numerous vulnerabilities in VCS, presenting significant risks to user privacy and security.
However, a cohesive and systematic examination of these vulnerabilities and the corresponding solutions is still absent.
This lack of comprehensive analysis presents a challenge for VCS designers in fully understanding and mitigating the security issues within these systems.</p>
<p class="ltx_p" id="id30.id2">Addressing this gap, our study introduces a hierarchical model structure for VCS,
providing a novel lens for categorizing and analyzing existing literature in a systematic manner.
We classify attacks based on their technical principles and thoroughly evaluate various attributes,
such as their methods, targets, vectors, and behaviors.
Furthermore, we consolidate and assess the defense mechanisms proposed in current research,
offering actionable recommendations for enhancing VCS security.
Our work makes a significant contribution by simplifying the complexity inherent in VCS security,
aiding designers in effectively identifying and countering potential threats, and setting a foundation for future advancements in VCS security research.</p>
</div>
<div class="ltx_keywords">Speaker recognition, voice-controlled systems, adversarial examples, replay attack, jamming attack, liveness detection, voice-synthesis attack.
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_journal" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journal: </span>POMACS</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalvolume" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalvolume: </span>37</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalnumber" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalnumber: </span>4</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_article" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">article: </span>111</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_publicationmonth" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">publicationmonth: </span>8</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">VCS, offering convenient user interfaces, have become integral to modern smart devices, including mobile technologies and smart home systems. The evolution of VCS has led to their widespread adoption, with the market projected to reach $7.07 billion by 2023 <cite class="ltx_cite ltx_citemacro_citep">(Sma, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib2" title="">2023</a>)</cite>. This surge in popularity is attributed to their diverse applications, ranging from managing smart homes to facilitating online shopping. However, this expansion brings significant security challenges, such as data privacy and vulnerability to cyber attacks, which have become increasingly critical concerns in the VCS domain.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">VCS, as a complex amalgamation of software and hardware components, inherently possesses diverse security vulnerabilities. These vulnerabilities open avenues for attackers to devise a range of attack methods, challenging VCS designers to anticipate and understand these multifaceted threats. For example, some attackers exploit hardware vulnerabilities in microphones, using non-acoustic means like lasers to inject malicious commands into VCS <cite class="ltx_cite ltx_citemacro_citep">(Sugawara et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib138" title="">2020</a>)</cite>. Furthermore, through adversarial training, attackers can create audio commands that, while seemingly benign to humans, are interpreted as malicious instructions by VCS. In the realm of third-party VCS services, attackers may embed carefully crafted malicious services, which could be inadvertently triggered by the VCS <cite class="ltx_cite ltx_citemacro_citep">(Kumar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib77" title="">2018</a>; Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib194" title="">2019a</a>)</cite>. However, most existing defense strategies focus narrowly on specific attack types, overlooking the broader implications of various attacks on the entire VCS ecosystem. This narrow focus leaves a gap in understanding the comprehensive risks and attack vectors facing VCS, beyond individual defense measures. Therefore, given these complexities, there is an urgent need for researchers in the VCS field to conduct a comprehensive and systematic survey, analyzing both the current attacks on VCS and the existing defense mechanisms.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><em class="ltx_emph ltx_font_italic" id="S1.p3.1.1">Comparison with related surveys.</em> Our survey distinguishes itself from prior research by categorizing VCS into distinct layers: hardware, preprocessing, kernel, and service. This approach enables a comprehensive examination of security risks and defense mechanisms, considering each layer’s specific integration perspective. Table <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S1.T1" title="Table 1 ‣ 1. Introduction ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_tag">1</span></a> provides a comparative summary of our work in relation to similar studies. For instance, Zhang et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib194" title="">2019a</a>)</cite> focused specifically on security threats from malicious services within VCS. Bai et al. <cite class="ltx_cite ltx_citemacro_citep">(Bai
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib13" title="">2020</a>)</cite> explored acoustic technologies and their applications in domestic and industrial settings. Abdullah et al. <cite class="ltx_cite ltx_citemacro_citep">(Abdullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib6" title="">2021b</a>)</cite> and Chen et al. <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib27" title="">2022</a>)</cite> conducted in-depth analyses of risks associated with Automatic Speech Recognition (ASR) and Speaker Verification (SV) systems, integral components of VCS. Zhang et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib196" title="">2022</a>)</cite> provided a detailed survey on adversarial attacks targeting ASR. These studies, while insightful, often focus on specific layers or subsets of layers within VCS, possibly overlooking the full view of security threats. For example, <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib194" title="">2019a</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Bai
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib13" title="">2020</a>)</cite> did not comprehensively address vulnerabilities in the service layer. Similarly, <cite class="ltx_cite ltx_citemacro_citep">(Abdullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib6" title="">2021b</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib27" title="">2022</a>)</cite>, and <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib196" title="">2022</a>)</cite> primarily analyzed the kernel layer, neglecting other critical layers. In contrast, our survey aims to bridge these gaps by providing an all-encompassing analysis of VCS security across all layers. Although the work in <cite class="ltx_cite ltx_citemacro_citep">(Edu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib40" title="">2020</a>)</cite> presents a comprehensive overview of VCS attacks, it predominantly focuses on smart home applications, omitting extensive discussion on mobile device integration.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">Motivation.</em>
In addition to the current surveys lacking a comprehensive perspective on examining VCS security issues, researchers also urgently need to address the following questions:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">VCS systems are vulnerable to a variety of attacks, such as transduction attacks, speech synthesis attacks, and adversarial attacks. This susceptibility stems from two main factors: the advancement of technology providing attackers with more sophisticated tools and algorithms, and the inherent complexity of VCS as a system comprising multiple hardware and software components, each with unique security vulnerabilities. Understanding the mechanics behind these attacks and the specific vulnerabilities of VCS components is crucial for designers.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Beyond understanding attack mechanisms, it is vital for VCS designers to be aware of effective defense solutions. Current defense strategies, such as adversarial training, are often tailored to specific attack types <cite class="ltx_cite ltx_citemacro_citep">(Wang, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib154" title="">2021</a>; Gong and
Poellabauer, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib49" title="">2018a</a>; Iter
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib65" title="">2017</a>; Yakura and Sakuma, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib172" title="">2018</a>; Abdel-Hamid et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib3" title="">2014</a>; Hai and Joo, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib58" title="">2003</a>; Zeng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib187" title="">2019</a>)</cite>, posing a challenge in selecting appropriate defense combinations to robustly enhance VCS against a wide array of attacks.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">The diverse nature of VCS, encompassing both automatic speech recognition (ASR) and speaker verification (SV), often leads to these components being studied in isolation <cite class="ltx_cite ltx_citemacro_citep">(Abdullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib6" title="">2021b</a>; Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib27" title="">2022</a>)</cite>. However, many VCS systems incorporate both ASR and SV functionalities, and attacks against these systems often exhibit overlapping characteristics. Designers must, therefore, consider the potential vulnerabilities of both ASR and SV in tandem when designing VCS.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In our paper, we conduct a comprehensive and systematic study of VCS security.
To thoroughly discuss the various attacks VCS faces, we categorize these attacks based on the hierarchical model of VCS, which includes hardware, software, and service layers. We then analyze and assess the corresponding defense schemes, tailored to each type of attack within these layers. For each attack, we conduct a multi-dimensional evaluation, considering aspects such as attack methods, targets, vectors, and performance impact, and discuss potential directions for future research. Additionally, we offer practical combinations of defense schemes, providing valuable insights for VCS researchers to effectively counter diverse attacks. An illustrative organizational structure for our survey article is presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Our work distinguishes itself from existing surveys in several comprehensive aspects: i) We provide extensive coverage of a broad range of attack methods applicable to each layer within the hierarchical model of VCS. This approach offers a nuanced understanding of the potential vulnerabilities at different levels of the system. ii) Our overview is expanded to include various devices that incorporate VCS, where we detail the unique security risks associated with each device type. This broadens the scope of our survey to encompass a wider array of real-world applications. iii) We present a detailed introduction to defense schemes corresponding to these attack methods, thereby enabling readers to not only understand these strategies but also to implement them in practical scenarios. This comprehensive approach to both attack and defense aspects provides a well-rounded perspective on VCS security.</p>
</div>
<figure class="ltx_table" id="S1.T1">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 1. </span>A comparison of existing survey work in the smart voice-controlled systems</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S1.T1.3">
<tr class="ltx_tr" id="S1.T1.3.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.3.1.1" rowspan="3" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.1.1.1" style="font-size:70%;">Ref No.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.3.1.2" rowspan="3" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.1.2.1" style="font-size:70%;">Year</span></td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" id="S1.T1.3.1.3" rowspan="3" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.1.3.1" style="font-size:70%;">Major Contribution of Surveys</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="10" id="S1.T1.3.1.4" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.1.4.1" style="font-size:70%;">Scope</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="5" id="S1.T1.3.2.1" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.2.1.1" style="font-size:70%;">Attack</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="5" id="S1.T1.3.2.2" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.2.2.1" style="font-size:70%;">Defense</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.3.1" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_text" id="S1.T1.3.3.1.1" style="font-size:70%;">SVS</span><sup class="ltx_sup" id="S1.T1.3.3.1.2"><span class="ltx_text" id="S1.T1.3.3.1.2.1" style="font-size:70%;">1</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.3.2" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_text" id="S1.T1.3.3.2.1" style="font-size:70%;">NLPS</span><sup class="ltx_sup" id="S1.T1.3.3.2.2"><span class="ltx_text" id="S1.T1.3.3.2.2.1" style="font-size:70%;">2</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.3.3" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_text" id="S1.T1.3.3.3.1" style="font-size:70%;">HS</span><sup class="ltx_sup" id="S1.T1.3.3.3.2"><span class="ltx_text" id="S1.T1.3.3.3.2.1" style="font-size:70%;">3</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.3.4" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_text" id="S1.T1.3.3.4.1" style="font-size:70%;">SWSS</span><sup class="ltx_sup" id="S1.T1.3.3.4.2"><span class="ltx_text" id="S1.T1.3.3.4.2.1" style="font-size:70%;">4</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.3.3.5" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_text" id="S1.T1.3.3.5.1" style="font-size:70%;">MDS</span><sup class="ltx_sup" id="S1.T1.3.3.5.2"><span class="ltx_text" id="S1.T1.3.3.5.2.1" style="font-size:70%;">5</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.3.6" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.3.6.1" style="font-size:70%;">SVS</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.3.7" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.3.7.1" style="font-size:70%;">NLPS</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.3.8" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.3.8.1" style="font-size:70%;">HS</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.3.9" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.3.9.1" style="font-size:70%;">SWSS</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.3.10" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.3.10.1" style="font-size:70%;">MDS</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.4">
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.1" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_rule" style="width:0.0pt;height:16.0pt;background:black;display:inline-block;"></span><span class="ltx_text" id="S1.T1.3.4.1.1" style="font-size:70%;">
</span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.T1.3.4.1.2.1" style="font-size:70%;">(</span>Zhang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S1.T1.3.4.1.3.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib194" title="">2019a</a><span class="ltx_text" id="S1.T1.3.4.1.4.3" style="font-size:70%;">)</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.2" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.2.1" style="font-size:70%;">2019</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S1.T1.3.4.3" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.4.3.1">
<span class="ltx_p" id="S1.T1.3.4.3.1.1" style="width:140.0pt;"><span class="ltx_text" id="S1.T1.3.4.3.1.1.1" style="font-size:70%;">A comprehensive study about third party skills with threats in VA and how to avoid them.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.4" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.4.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.5" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.5.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.6" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.6.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.7" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.7.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.8" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.8.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.9" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.9.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.10" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.10.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.11" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.11.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.12" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.12.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.3.4.13" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.4.13.1" style="font-size:70%;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.5">
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.1" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_rule" style="width:0.0pt;height:16.0pt;background:black;display:inline-block;"></span><span class="ltx_text" id="S1.T1.3.5.1.1" style="font-size:70%;">
</span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.T1.3.5.1.2.1" style="font-size:70%;">(</span>Edu
et al<span class="ltx_text">.</span><span class="ltx_text" id="S1.T1.3.5.1.3.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib40" title="">2020</a><span class="ltx_text" id="S1.T1.3.5.1.4.3" style="font-size:70%;">)</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.2" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.2.1" style="font-size:70%;">2020</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S1.T1.3.5.3" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.5.3.1">
<span class="ltx_p" id="S1.T1.3.5.3.1.1" style="width:140.0pt;"><span class="ltx_text" id="S1.T1.3.5.3.1.1.1" style="font-size:70%;">A thorough survey over the security and privacy of Personal Assistant of smart home personal assistants</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.4" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.4.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.5" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.5.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.6" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.6.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.7" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.7.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.8" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.8.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.9" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.9.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.10" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.10.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.11" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.11.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.12" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.12.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.5.13" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.5.13.1" style="font-size:70%;">✗</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.6">
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.1" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_rule" style="width:0.0pt;height:16.0pt;background:black;display:inline-block;"></span><span class="ltx_text" id="S1.T1.3.6.1.1" style="font-size:70%;">
</span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.T1.3.6.1.2.1" style="font-size:70%;">(</span>Bai
et al<span class="ltx_text">.</span><span class="ltx_text" id="S1.T1.3.6.1.3.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib13" title="">2020</a><span class="ltx_text" id="S1.T1.3.6.1.4.3" style="font-size:70%;">)</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.2" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.2.1" style="font-size:70%;">2020</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S1.T1.3.6.3" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.6.3.1">
<span class="ltx_p" id="S1.T1.3.6.3.1.1" style="width:140.0pt;"><span class="ltx_text" id="S1.T1.3.6.3.1.1.1" style="font-size:70%;">A comprehensive survey on acoustic-based technologies and applications in life and industry.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.4" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.4.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.5" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.5.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.6" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.6.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.7" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.7.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.8" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.8.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.9" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.9.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.10" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.10.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.11" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.11.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.12" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.12.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.6.13" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.6.13.1" style="font-size:70%;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.7">
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.1" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_rule" style="width:0.0pt;height:16.0pt;background:black;display:inline-block;"></span><span class="ltx_text" id="S1.T1.3.7.1.1" style="font-size:70%;">
</span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.T1.3.7.1.2.1" style="font-size:70%;">(</span>Abdullah et al<span class="ltx_text">.</span><span class="ltx_text" id="S1.T1.3.7.1.3.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib6" title="">2021b</a><span class="ltx_text" id="S1.T1.3.7.1.4.3" style="font-size:70%;">)</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.2" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.2.1" style="font-size:70%;">2021</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S1.T1.3.7.3" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.7.3.1">
<span class="ltx_p" id="S1.T1.3.7.3.1.1" style="width:140.0pt;"><span class="ltx_text" id="S1.T1.3.7.3.1.1.1" style="font-size:70%;">A detailed study about security threats and defense schemes in ASR and SV.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.4" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.4.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.5" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.5.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.6" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.6.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.7" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.7.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.8" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.8.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.9" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.9.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.10" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.10.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.11" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.11.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.12" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.12.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.7.13" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.7.13.1" style="font-size:70%;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.8">
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.1" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_rule" style="width:0.0pt;height:16.0pt;background:black;display:inline-block;"></span><span class="ltx_text" id="S1.T1.3.8.1.1" style="font-size:70%;">
</span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.T1.3.8.1.2.1" style="font-size:70%;">(</span>Chen et al<span class="ltx_text">.</span><span class="ltx_text" id="S1.T1.3.8.1.3.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib27" title="">2022</a><span class="ltx_text" id="S1.T1.3.8.1.4.3" style="font-size:70%;">)</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.2" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.2.1" style="font-size:70%;">2022</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S1.T1.3.8.3" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.8.3.1">
<span class="ltx_p" id="S1.T1.3.8.3.1.1" style="width:140.0pt;"><span class="ltx_text" id="S1.T1.3.8.3.1.1.1" style="font-size:70%;">A modularized and comprehensive survey about ASR security and comparison between ASR and IRS security.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.4" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.4.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.5" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.5.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.6" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.6.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.7" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.7.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.8" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.8.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.9" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.9.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.10" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.10.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.11" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.11.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.12" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.12.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.8.13" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.8.13.1" style="font-size:70%;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.9">
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.1" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_rule" style="width:0.0pt;height:16.0pt;background:black;display:inline-block;"></span><span class="ltx_text" id="S1.T1.3.9.1.1" style="font-size:70%;">
</span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.T1.3.9.1.2.1" style="font-size:70%;">(</span>Zhang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S1.T1.3.9.1.3.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib196" title="">2022</a><span class="ltx_text" id="S1.T1.3.9.1.4.3" style="font-size:70%;">)</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.2" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.2.1" style="font-size:70%;">2022</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S1.T1.3.9.3" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.9.3.1">
<span class="ltx_p" id="S1.T1.3.9.3.1.1" style="width:140.0pt;"><span class="ltx_text" id="S1.T1.3.9.3.1.1.1" style="font-size:70%;">A detailed investigation of adversarial attacks against ASR.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.4" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.4.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.5" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.5.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.6" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.6.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.7" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.7.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.8" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.8.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.9" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.9.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.10" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.10.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.11" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.11.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.12" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.12.1" style="font-size:70%;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.3.9.13" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.9.13.1" style="font-size:70%;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.10">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.1" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_rule" style="width:0.0pt;height:16.0pt;background:black;display:inline-block;"></span><span class="ltx_text" id="S1.T1.3.10.1.1" style="font-size:70%;">
</span><span class="ltx_text" id="S1.T1.3.10.1.2"></span><span class="ltx_text" id="S1.T1.3.10.1.3" style="font-size:70%;"> </span><span class="ltx_text" id="S1.T1.3.10.1.4" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S1.T1.3.10.1.4.1">
<span class="ltx_tr" id="S1.T1.3.10.1.4.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S1.T1.3.10.1.4.1.1.1" style="padding-top:1.05pt;padding-bottom:1.05pt;">Ours</span></span>
</span></span><span class="ltx_text" id="S1.T1.3.10.1.5"></span><span class="ltx_text" id="S1.T1.3.10.1.6" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.2" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.2.1" style="font-size:70%;">2023</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S1.T1.3.10.3" style="padding-top:1.05pt;padding-bottom:1.05pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.10.3.1">
<span class="ltx_p" id="S1.T1.3.10.3.1.1" style="width:140.0pt;"><span class="ltx_text" id="S1.T1.3.10.3.1.1.1" style="font-size:70%;">A comprehensive overview of the challenges faced by VCS and its future direction.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.4" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.4.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.5" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.5.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.6" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.6.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.7" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.7.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.8" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.8.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.9" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.9.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.10" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.10.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.11" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.11.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.12" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.12.1" style="font-size:70%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.3.10.13" style="padding-top:1.05pt;padding-bottom:1.05pt;"><span class="ltx_text" id="S1.T1.3.10.13.1" style="font-size:70%;">✓</span></td>
</tr>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S1.I2">
<li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I2.i1.p1">
<p class="ltx_p" id="S1.I2.i1.p1.5"><sup class="ltx_sup" id="S1.I2.i1.p1.5.1"><span class="ltx_text ltx_font_italic" id="S1.I2.i1.p1.5.1.1" style="font-size:80%;">1</span></sup><span class="ltx_text" id="S1.I2.i1.p1.5.2" style="font-size:80%;">SVS: Speaker Verification Security.
</span><sup class="ltx_sup" id="S1.I2.i1.p1.5.3"><span class="ltx_text ltx_font_italic" id="S1.I2.i1.p1.5.3.1" style="font-size:80%;">2</span></sup><span class="ltx_text" id="S1.I2.i1.p1.5.4" style="font-size:80%;">NLPS: Natural Language Processing Security.
</span><sup class="ltx_sup" id="S1.I2.i1.p1.5.5"><span class="ltx_text ltx_font_italic" id="S1.I2.i1.p1.5.5.1" style="font-size:80%;">3</span></sup><span class="ltx_text" id="S1.I2.i1.p1.5.6" style="font-size:80%;">HS: Hardware Security.
</span><sup class="ltx_sup" id="S1.I2.i1.p1.5.7"><span class="ltx_text ltx_font_italic" id="S1.I2.i1.p1.5.7.1" style="font-size:80%;">4</span></sup><span class="ltx_text" id="S1.I2.i1.p1.5.8" style="font-size:80%;">SWSS: Skill Web Service Security.
</span><sup class="ltx_sup" id="S1.I2.i1.p1.5.9"><span class="ltx_text ltx_font_italic" id="S1.I2.i1.p1.5.9.1" style="font-size:80%;">5</span></sup><span class="ltx_text" id="S1.I2.i1.p1.5.10" style="font-size:80%;">MDS: Mobile Device Security.</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1"><em class="ltx_emph ltx_font_italic" id="S1.p7.1.1">Contributions.</em>
We summarize our contribution as follows:</p>
<ul class="ltx_itemize" id="S1.I3">
<li class="ltx_item" id="S1.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I3.i1.p1">
<p class="ltx_p" id="S1.I3.i1.p1.1">Our unique approach to examining VCS security involves dividing VCS into four distinct layers: the physical layer, preprocessing layer, kernel layer, and service layer. This hierarchical model allows for a systematic and detailed analysis of both attacks and defense schemes at each layer, providing VCS researchers with a comprehensive framework to understand and evaluate associated risks accurately.</p>
</div>
</li>
<li class="ltx_item" id="S1.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I3.i2.p1">
<p class="ltx_p" id="S1.I3.i2.p1.1">Utilizing our proposed hierarchical model, we have systematically integrated and assessed potential attacks on each VCS layer. By employing various metrics, such as attack complexity and potential impact, we offer a feasibility analysis that enables users to gauge the security threats these attacks pose to VCS accurately.</p>
</div>
</li>
<li class="ltx_item" id="S1.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I3.i3.p1">
<p class="ltx_p" id="S1.I3.i3.p1.1">We have developed and evaluated defense strategies tailored to each layer of VCS, considering practical effectiveness and usability from multiple dimensions. Additionally, we introduce a generalized attack mitigation strategy, aiding designers in constructing a more robust and comprehensive defense system for VCS.</p>
</div>
</li>
<li class="ltx_item" id="S1.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I3.i4.p1">
<p class="ltx_p" id="S1.I3.i4.p1.1">Through an extensive analysis of existing literature, we provide targeted recommendations for enhancing current security research and directions for future development in the field, addressing gaps and emerging trends in VCS security research.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S1.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="774" id="S1.F1.g1" src="x1.png" width="631"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>An Illustrative Overview of Structure of Our Survey Article.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S1.F1.1">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S1.F1.2">[paper structure]Divide the paper into 8 sections.</p>
</div>
</div>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this section, we brief the common system overview of VCS, then illustrate attacks and defenses of VCS.
It then systematize attacks and defensive schemes based on Layer</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>System Overview of VCS</h3>
<figure class="ltx_figure" id="S2.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="95" id="S2.F2.g1" src="x2.png" width="747"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>A hierarchical Workflow Diagram of VCS. After a user issues a voice command to the VCS, the user will receive a response from the VCS. Based on the response, the user can choose to issue another relevant command to the VCS.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S2.F2.1">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S2.F2.2">[workflow]Use five block diagrams to represent the structure of VCS.</p>
</div>
</div>
</figure>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">As Siri achieved significant success on iPhones, VCS have seen widespread integration into daily life. Nowadays, most smart devices, including smartphones, smart homes, and smart vehicles, come equipped with voice assistants. VCS enable users to perform various tasks such as unlocking devices, setting alarms, and opening doors, thereby enhancing interaction with smart technology. Popular VCS like Google Home, Amazon Echo, and Apple HomePod have expanded their capabilities through third-party services, providing features like voice translation and audio transcription.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">With the rapid development and increasing prevalence of VCS, security concerns have similarly grown. To thoroughly analyze and effectively organize the potential risks and defensive strategies for voice assistants, we categorize VCS into four functional layers: the physical layer, preprocessing layer, kernel layer, and service layer. This layered approach allows for a detailed examination of how VCS process voice commands and provide services to users, as illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.F2" title="Figure 2 ‣ 2.1. System Overview of VCS ‣ 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1. </span>Physical Layer</h4>
<div class="ltx_para" id="S2.SS1.SSS1.p1">
<p class="ltx_p" id="S2.SS1.SSS1.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS1.p1.1.1">Transmission channels.</em>
Acoustic signals, when transmitted over-the-air in VCS, are subject to various environmental influences that can degrade their quality. Ideally, signal transmission should occur without loss, but realistically, signal intensity diminishes with distance, reducing the information carried. This limitation poses a challenge in capturing sufficient signal data, thus constraining the effective operational range between the source and the target device. Environmental factors such as noise types can also hinder a VCS’s ability to accurately interpret acoustic signals. Furthermore, signal reflection off surrounding objects can result in the reception of mixed signals, complicating the interpretation of the original acoustic input.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS1.p2">
<p class="ltx_p" id="S2.SS1.SSS1.p2.1">This vulnerability is particularly concerning in security contexts, where attackers could exploit these transmission challenges by deploying malicious audio. Such attacks might aim to compromise the VCS by leveraging signal interference, necessitating countermeasures. Attackers, aware of these transmission challenges, might enhance the robustness of their malicious audio or resort to generating electronic signals that mimic acoustic ones, to increase the likelihood of successful system penetration.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS1.p3">
<p class="ltx_p" id="S2.SS1.SSS1.p3.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS1.p3.1.1">Acoustic signal conversion.</em>
For a VCS to process acoustic signals, they must first be converted into digital signals, a process involving two critical steps. Initially, the system employs sensors, typically microphones, to transform acoustic signals into electrical signals. Among microphones, electrodynamics and capacitive types are common, with the latter being more prevalent in modern devices due to their sensitivity and reliability. Capacitive microphones operate by detecting changes in capacitance caused by the vibration of movable plates in response to sound waves, thereby converting acoustic signals into electrical ones <cite class="ltx_cite ltx_citemacro_citep">(Zawawi
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib185" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS1.p4">
<p class="ltx_p" id="S2.SS1.SSS1.p4.1">The next stage involves an analog-to-digital converter (ADC), which digitizes the electrical signals. The ADC employs a sample and hold circuit to capture and stabilize the signal value, followed by a quantizer that processes these samples, converting them into binary numbers representing the digital signal. This conversion is pivotal for effective VCS processing, but each stage also presents potential security vulnerabilities, such as susceptibility to signal manipulation or interference, that must be carefully managed to ensure system integrity.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2. </span>Preprocessing Layer</h4>
<div class="ltx_para" id="S2.SS1.SSS2.p1">
<p class="ltx_p" id="S2.SS1.SSS2.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS2.p1.1.1">Signal preprocessing.</em>
Signal preprocessing is vital in VCS, as it involves processing raw speech signals to extract clean speech for analysis. VCS utilize band filters to isolate speech signals within the 300-3400kHz frequency band, essential for clear speech recognition. The use of multiple microphones for multichannel speech capture necessitates techniques such as multichannel acoustic echo cancellation, reverberation control, and source separation. These processes ensure high-quality signal capture, crucial for accurate speech recognition. Recent advancements include the application of deep learning methods for signal preprocessing, offering improved noise mitigation and signal clarity <cite class="ltx_cite ltx_citemacro_citep">(Ryant
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib117" title="">2013</a>)</cite>. This enhanced preprocessing is critical for robust VCS functioning, particularly in complex acoustic environments.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS2.p2">
<p class="ltx_p" id="S2.SS1.SSS2.p2.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS2.p2.1.1">Acoustic feature extraction.</em>
This step aims to extract distinctive features from speech signals, accounting for variations in speaker characteristics, environmental noise, and transmission channels. The process begins with segmenting the processed audio into frames using a sliding window technique, followed by feature extraction. Common algorithms for feature extraction include Short-time Fourier Transform (STFT), Linear Predictive Coding (LPC) <cite class="ltx_cite ltx_citemacro_citep">(Rabiner and Juang, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib111" title="">1993</a>)</cite>, Mel Frequency Cepstral Coefficients (MFCC) <cite class="ltx_cite ltx_citemacro_citep">(Sigurdsson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib132" title="">2006</a>)</cite>, and Perceptual Linear Prediction (PLP) <cite class="ltx_cite ltx_citemacro_citep">(Rabiner, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib112" title="">1978</a>)</cite>. Each algorithm plays a unique role in enhancing the robustness of VCS by efficiently capturing and representing different acoustic properties of speech.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.3. </span>Kernel Layer</h4>
<div class="ltx_para" id="S2.SS1.SSS3.p1">
<p class="ltx_p" id="S2.SS1.SSS3.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS3.p1.1.1">Acoustic model.</em>
Post feature extraction in the preprocessing layer, the acoustic model establishes a statistical relationship between these features and acoustic units like phonemes using machine learning algorithms. Traditional models commonly use Gaussian Mixture Models (GMM) and Hidden Markov Models (HMM), while contemporary models increasingly employ neural networks such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) <cite class="ltx_cite ltx_citemacro_citep">(Sainath
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib119" title="">2015</a>)</cite>, enhancing the accuracy and efficiency of phoneme conversion.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p2">
<p class="ltx_p" id="S2.SS1.SSS3.p2.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS3.p2.1.1">Language model.</em>
The language model predicts the likelihood of word sequences forming coherent sentences, differentiating between homophones based on context. This model is pivotal in controlling VCS output using common words and grammatical rules. Models are generally divided into statistical (e.g., N-gram, HMM) and neural network-based, with the latter becoming increasingly prevalent in modern VCS.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p3">
<p class="ltx_p" id="S2.SS1.SSS3.p3.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS3.p3.1.1">Phonetic dictionary.</em>
This component links the acoustic and language models by mapping words to phonemes, essential for decoding the user’s intent in VCS. The phonetic dictionary facilitates the establishment of relationships between the models’ units, thereby aiding in effective system decoding.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p4">
<p class="ltx_p" id="S2.SS1.SSS3.p4.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS3.p4.1.1">End-to-end model.</em>
To streamline VCS, end-to-end models have been developed. These models directly convert acoustic features into word sequences, integrating the functions of both acoustic and language models. This simplification reduces potential attack vectors, enhancing system security. Examples include CTC <cite class="ltx_cite ltx_citemacro_citep">(Graves et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib54" title="">2006</a>)</cite>, Transducer <cite class="ltx_cite ltx_citemacro_citep">(Graves, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib53" title="">2012</a>)</cite>, and Attention models <cite class="ltx_cite ltx_citemacro_citep">(Chorowski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib29" title="">2015</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p5">
<p class="ltx_p" id="S2.SS1.SSS3.p5.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS3.p5.1.1">Natural language processing (NLP).</em>
NLP enables machines to understand and act upon natural language inputs. Its development has evolved from rule-based to statistical models, and now to neural network-based models like Word2vec <cite class="ltx_cite ltx_citemacro_citep">(Mikolov
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib98" title="">2013</a>)</cite> and BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib38" title="">2018</a>)</cite>, reflecting the industry’s shift towards more sophisticated, context-aware processing.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p6">
<p class="ltx_p" id="S2.SS1.SSS3.p6.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS3.p6.1.1">Speaker verification.</em>
Distinct from traditional VCS, speaker verification focuses on identifying the speaker rather than interpreting speech content. It consists of speaker identification (SI) and speaker verification (SV), with the latter confirming a speaker’s identity. In the kernel layer, speaker verification differs from standard VCS by determining the probability of potential speakers, thus requiring specialized discussion regarding its security implications.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.4. </span>Service Layer</h4>
<div class="ltx_para" id="S2.SS1.SSS4.p1">
<p class="ltx_p" id="S2.SS1.SSS4.p1.1">After interpreting the user’s intent in the kernel layer, the VCS responds in the service layer. Utilizing Natural Language Generation (NLG), the system conveys the required information in text or audibly through Text-to-Speech (TTS) technology. Technological advancements have expanded VCS capabilities to include third-party services, enabling more complex functionalities. However, this expansion introduces new security challenges, such as increased exposure to data breaches and exploitation of service vulnerabilities, necessitating robust security measures.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Attacks against VCS</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Current researches highlight the vulnerability of VCS to a range of attacks, stemming from its complex architecture which presents potential vulnerabilities at each layer. To equip system designers with a comprehensive understanding of these threats, this section delves into the nature of attacks against VCS, examining them from the perspectives of threat models, attack metrics, and attack objectives. We will explore how threat models help identify potential security weaknesses, discuss metrics for assessing the impact and severity of attacks, and analyze the typical goals of attackers targeting VCS systems.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1. </span>Threat Model</h4>
<div class="ltx_para" id="S2.SS2.SSS1.p1">
<p class="ltx_p" id="S2.SS2.SSS1.p1.1">We consider attack scenarios under these assumptions:</p>
<ol class="ltx_enumerate" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1">Attackers may have prior knowledge of the target VCS, including its brand and model. For common VCS, attackers might possess the same device model.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1">The VCS operates on a trusted platform with encrypted communication, preventing attacks via the operating system, hardware, or communication interception.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1">Attackers’ knowledge varies:
1) White/Grey-box: Full or partial model knowledge, applicable to open-source VCS.
2) Black-box: No model knowledge, typical in commercial VCS.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2. </span>Attack Metrics</h4>
<div class="ltx_para" id="S2.SS2.SSS2.p1">
<p class="ltx_p" id="S2.SS2.SSS2.p1.1">Based on the threat model, we assess VCS attacks as follows:</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS2.p2">
<p class="ltx_p" id="S2.SS2.SSS2.p2.1"><em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS2.p2.1.1">Attack method.</em> The method determines the targeted VCS layer. Some exploit non-audio signals to attack the physical layer, while others use audio-based methods to deceive the kernel layer.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS2.p3">
<p class="ltx_p" id="S2.SS2.SSS2.p3.1"><em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS2.p3.1.1">Attack target.</em> Targets may vary from specific models (requiring detailed knowledge) to general hardware vulnerabilities affecting multiple VCS models.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS2.p4">
<p class="ltx_p" id="S2.SS2.SSS2.p4.1"><em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS2.p4.1.1">Attack vector.</em> Over-the-air attacks, more feasible in real-world settings, must be robust against environmental factors and signal degradation.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS2.p5">
<p class="ltx_p" id="S2.SS2.SSS2.p5.1"><em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS2.p5.1.1">Performance.</em> The effectiveness of an attack is measured by its success rate and maximum effective distance, indicating its practicality in real scenarios.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.3. </span>Attacker Goal</h4>
<div class="ltx_para" id="S2.SS2.SSS3.p1">
<p class="ltx_p" id="S2.SS2.SSS3.p1.1">Attackers primarily aim to disrupt VCS operations, leading to unauthorized command execution. Untargeted attacks may cause incorrect audio decoding, while targeted attacks seek to execute specific malicious commands. Security impacts include unauthorized control of smart devices (e.g., unlocking doors), while privacy concerns involve eavesdropping or accessing personal information via malicious services.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Defense Schemes in VCS</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">The range of defense strategies for VCS is relatively narrow compared to the diversity of attack methods. Current defenses primarily fall into two categories: 1) Layer-specific solutions, such as adversarial training, which fortify particular layers like the kernel layer against specific types of attacks, yet they might not be effective against threats targeting other layers. This category also includes specialized encryption for communication security and hardware-focused safeguards. 2) Holistic strategies, like liveness detection, are designed to protect the entire VCS by verifying the authenticity of voice inputs, thereby securing all layers from a range of potential attacks. While liveness detection is adept at confirming genuine user interaction, challenges such as differentiating between live and recorded voices persist. The effectiveness of VCS security often hinges on integrating both layer-specific and holistic defenses to comprehensively address the multifaceted nature of potential threats.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Layer-Based Systematization of Attacks and Defenses in VCS</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">The prevailing approach in academic circles for classifying attacks on VCS typically revolves around either human perception or specific VCS components. However, this method can inadvertently group distinct attack methodologies under the same category, despite their differing technical principles. For instance, both DolphinAttack <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib189" title="">2017b</a>)</cite> and Hidden Voice Command <cite class="ltx_cite ltx_citemacro_citep">(Carlini et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib19" title="">2016</a>)</cite> are categorized as voice-synthesis attacks. Nonetheless, they fundamentally differ in their mechanisms: DolphinAttack exploits microphone hardware vulnerabilities, whereas Hidden Voice Command targets the preprocessing algorithms.</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">While the component-based classification method provides a systematic approach to categorizing attacks, it often leads to an isolated analysis of SV and ASR components, as seen in existing literature <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib27" title="">2022</a>; Abdullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib6" title="">2021b</a>)</cite>. Our research suggests that despite the distinct outputs of these two components, they share similar technical principles and vulnerabilities that can be exploited by attackers. Thus, analyzing them separately may obscure the full understanding of potential attack vectors.</p>
</div>
<div class="ltx_para" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.1">To address these classification challenges, our article proposes a restructuring of attack categorization based on the VCS architecture, dividing them into attacks on the physical layer, preprocessing layer, core layer, and service layer, as outlined in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S2.F2" title="Figure 2 ‣ 2.1. System Overview of VCS ‣ 2. Background ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_tag">2</span></a>. This approach allows for a more precise identification of the vulnerabilities specific to each layer and the attacks that exploit them. We will also categorize defense solutions accordingly: those designed to protect specific layers will be discussed in their respective sections, while generalized defense strategies applicable across all VCS layers will be comprehensively covered in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S7" title="7. General Attack Mitigation Strategy ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_tag">7</span></a>. The ensuing chapters will detail the array of attack threats and corresponding defensive measures for each layer within VCS.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Physical Layer</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The physical layer of VCS plays a pivotal role in converting sound signals into digital formats. This conversion process involves the transmission of sound signals through channels, typically air, to microphone devices, which are then digitized. However, this layer is vulnerable to a range of attacks due to the lack of signal verification in the transmission channel and the susceptibility of microphone devices to manipulation. Attackers can exploit these vulnerabilities by transmitting malicious audios or using specific signals to coerce microphones into generating attacker-desired digital signals. This section explores various attack types targeting the physical layer, including transduction attacks that manipulate physical components to create false inputs, voice-synthesis attacks that craft misleading audio inputs, and denial of service attacks aimed at overwhelming the system. A comprehensive summary and comparison of these attacks are detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S3.T2" title="Table 2 ‣ 3.2. Voice-synthesis Attacks in Physical Layer ‣ 3. Physical Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_tag">2</span></a>, elucidating their methods, targets, and potential impacts on the VCS.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Transduction Attacks in Physical Layer</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Transduction attacks exploit microphone vulnerabilities in VCS by using non-standard signals that microphones should typically not recognize. These attacks manipulate the physical properties of microphone equipment to induce unintended digital signal generation, leading to VCS compromise.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.1.1">Light Signal.</em> Microphones, designed to be sensitive only to sound signals, can unexpectedly respond to modulated light signals. Sugawara et al. <cite class="ltx_cite ltx_citemacro_citep">(Sugawara et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib138" title="">2020</a>)</cite> demonstrated that by modulating laser amplitude, attackers can transmit malicious commands to VCS from distances exceeding 100 meters, exploiting this unintended sensitivity.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.1">Electromagnetic Wave (EW).</em> Microphone circuits can inadvertently act as antennas, receiving electromagnetic waves which are then demodulated into malicious commands. This vulnerability allows attackers to use electromagnetic coupling, as shown by Kasmi and Esteves <cite class="ltx_cite ltx_citemacro_citep">(Kasmi and Esteves, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib70" title="">2015</a>)</cite>, to control voice assistants through headphone cables. Further research indicates that specific electromagnetic waves generated by wired <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib161" title="">2022</a>)</cite> or wireless chargers <cite class="ltx_cite ltx_citemacro_citep">(Dai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib31" title="">2022</a>)</cite> can also inject commands into VCS.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><em class="ltx_emph ltx_font_italic" id="S3.SS1.p4.1.1">Defense Schemes against Transduction Attacks.</em> For light-based attacks, sensor fusion technology <cite class="ltx_cite ltx_citemacro_citep">(Davidson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib33" title="">2016</a>)</cite> offers a software-level defense by exploiting the omnidirectional nature of sound versus the directional nature of light, which typically affects only one microphone. This approach detects discrepancies between multiple microphone inputs. Hardware solutions include shielding microphones with opaque covers to block light, though this may attenuate sound signals <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib163" title="">2015</a>)</cite>. Against EW attacks, sensors detecting electromagnetic changes can alert to potential intrusions. A comprehensive defense strategy involves adding authentication mechanisms to VCS, effectively mitigating various transduction attacks.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Voice-synthesis Attacks in Physical Layer</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Voice-synthesis attacks in the physical layer of VCS differ from transduction attacks as they primarily utilize ultrasonic signals, which are inaudible to humans but can be received by most microphones. These attacks exploit the fact that ultrasound, with frequencies above 20 Hz, can be demodulated in the system through nonlinear amplifiers after being received by the microphone. Attackers modulate malicious commands into these ultrasonic signals, leading to interference with the normal functioning of VCS. Researchers have demonstrated such attacks using solid surface transmission<cite class="ltx_cite ltx_citemacro_citep">(Yan
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib176" title="">2020</a>)</cite> and air transmission methods<cite class="ltx_cite ltx_citemacro_citep">(Qi
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib108" title="">2023</a>; Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib189" title="">2017b</a>; Iijima et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib64" title="">2018</a>; Ji
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib68" title="">2021</a>; Roy
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib116" title="">2018</a>; Song and Mittal, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib134" title="">2017</a>; Yan
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib175" title="">2019</a>)</cite>. Additionally, a novel approach exploiting specific current fluctuations to remotely attack VCS through sounds generated by the switching mode power supply (SMPS) in the same power grid was proposed in <cite class="ltx_cite ltx_citemacro_citep">(Yang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib177" title="">2023a</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><em class="ltx_emph ltx_font_italic" id="S3.SS2.p2.1.1">Defense Schemes against Voice-synthesis Attacks.</em>
To counteract these attacks, hardware-based defenses include using microphones that are incapable of receiving ultrasonic signals, similar to the iPhone 6 Plus microphone<cite class="ltx_cite ltx_citemacro_citep">(Qi
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib108" title="">2023</a>)</cite>, or implementing a ”guarding” mechanism with an external signal generator to neutralize malicious audio<cite class="ltx_cite ltx_citemacro_citep">(He
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib62" title="">2019</a>)</cite>. However, replacing microphones or adding signal generators in existing VCS products is impractical, making software-level defenses more viable. For air-transmitted voice-synthesis attacks, the demodulated attack signal in the 500 to 1000 Hz range differs significantly from the original signal, detectable via a variational auto-encoder<cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib85" title="">2023</a>)</cite>. Additionally, a microphone array can calculate the attenuation rate of sound waves at different microphones, identifying ultrasonic-origin voice commands<cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib188" title="">2021</a>)</cite>. Solid surface attacks lack this attenuation distinction, but their recovered attack signal introduces new frequency components from 10 kHz to 20 kHz, providing another basis for detection and differentiation from baseband signals.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 2. </span>Comparison of transduction attack and voice-synthesis attack in physical layer</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.3">
<tr class="ltx_tr" id="S3.T2.3.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.1.1" rowspan="2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.1.1.1" style="font-size:70%;">Attack Type</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.1.2" rowspan="2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.1.2.1" style="font-size:70%;">Paper</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.1.3" rowspan="2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.1.3.1" style="font-size:70%;">Attack Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.1.4" rowspan="2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.1.4.1" style="font-size:70%;">Attack Target</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.1.5" rowspan="2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.1.5.1" style="font-size:70%;">Attacker Vector</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.T2.3.1.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.1.6.1" style="font-size:70%;">Performance</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.2.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.2.1.1" style="font-size:70%;">Success</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.2.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.2.2.1" style="font-size:70%;">Distance</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.3.1" rowspan="4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.3.1.1" style="font-size:70%;">
<span class="ltx_inline-block ltx_transformed_outer" id="S3.T2.3.3.1.1.1" style="width:36.0pt;height:53.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:53.3pt;transform:translate(-8.65pt,-8.65pt) rotate(-90deg) ;">
<span class="ltx_p" id="S3.T2.3.3.1.1.1.1"><span class="ltx_text" id="S3.T2.3.3.1.1.1.1.1"></span> <span class="ltx_text" id="S3.T2.3.3.1.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T2.3.3.1.1.1.1.2.1">
<span class="ltx_tr" id="S3.T2.3.3.1.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.3.3.1.1.1.1.2.1.1.1" style="padding-top:2.45pt;padding-bottom:2.45pt;">Transduction</span></span>
<span class="ltx_tr" id="S3.T2.3.3.1.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.3.3.1.1.1.1.2.1.2.1" style="padding-top:2.45pt;padding-bottom:2.45pt;">Attacks</span></span>
</span></span> <span class="ltx_text" id="S3.T2.3.3.1.1.1.1.3"></span></span>
</span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.3.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.3.2.1.1" style="font-size:70%;">(</span>Sugawara et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.3.2.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib138" title="">2020</a><span class="ltx_text" id="S3.T2.3.3.2.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.3.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.3.3.1" style="font-size:70%;">Light</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.3.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.3.4.1" style="font-size:70%;">Microphone</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.3.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.3.5.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.3.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.3.6.1" style="font-size:70%;">90%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.7" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.3.7.1" style="font-size:70%;">25m</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.4">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.4.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.4.1.1.1" style="font-size:70%;">(</span>Kasmi and Esteves<span class="ltx_text" id="S3.T2.3.4.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib70" title="">2015</a><span class="ltx_text" id="S3.T2.3.4.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.4.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.4.2.1" style="font-size:70%;">EW</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.4.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.4.3.1" style="font-size:70%;">Headphone Cable</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.4.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.4.4.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.4.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.4.5.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.4.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.4.6.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.5">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.5.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.5.1.1.1" style="font-size:70%;">(</span>Wang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.5.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib161" title="">2022</a><span class="ltx_text" id="S3.T2.3.5.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.5.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.5.2.1" style="font-size:70%;">EW</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.5.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.5.3.1" style="font-size:70%;">Charging Port</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.5.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.5.4.1" style="font-size:70%;">Power Line</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.5.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.5.5.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.5.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.5.6.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.6">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.6.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.6.1.1.1" style="font-size:70%;">(</span>Dai et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.6.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib31" title="">2022</a><span class="ltx_text" id="S3.T2.3.6.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.6.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.6.2.1" style="font-size:70%;">EW</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.6.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.6.3.1" style="font-size:70%;">Microphone</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.6.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.6.4.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.6.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.6.5.1" style="font-size:70%;">91%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.6.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.6.6.1" style="font-size:70%;">5 cm</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.7">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.3.7.1" rowspan="9" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.7.1.1" style="font-size:70%;">
<span class="ltx_inline-block ltx_transformed_outer" id="S3.T2.3.7.1.1.1" style="width:6.2pt;height:71.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:71.7pt;transform:translate(-32.74pt,-32.06pt) rotate(-90deg) ;">
<span class="ltx_p" id="S3.T2.3.7.1.1.1.1">Voice-synthesis Attacks</span>
</span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.7.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.7.2.1.1" style="font-size:70%;">(</span>Yan
et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.7.2.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib176" title="">2020</a><span class="ltx_text" id="S3.T2.3.7.2.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.7.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.7.3.1" style="font-size:70%;">Ultrasonic</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.7.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.7.4.1" style="font-size:70%;">Microphone</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.7.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.7.5.1" style="font-size:70%;">Solid Surface</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.7.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.7.6.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.7.7" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.7.7.1" style="font-size:70%;">2.5m+</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.8">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.8.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.8.1.1.1" style="font-size:70%;">(</span>Zhang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.8.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib189" title="">2017b</a><span class="ltx_text" id="S3.T2.3.8.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.8.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.8.2.1" style="font-size:70%;">Ultrasonic</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.8.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.8.3.1" style="font-size:70%;">Microphone</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.8.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.8.4.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.8.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.8.5.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.8.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.8.6.1" style="font-size:70%;">165 cm</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.9">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.9.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.9.1.1.1" style="font-size:70%;">(</span>Iijima et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.9.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib64" title="">2018</a><span class="ltx_text" id="S3.T2.3.9.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.9.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.9.2.1" style="font-size:70%;">Ultrasonic</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.9.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.9.3.1" style="font-size:70%;">Microphone</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.9.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.9.4.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.9.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.9.5.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.9.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.9.6.1" style="font-size:70%;">10 m</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.10">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.10.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.10.1.1.1" style="font-size:70%;">(</span>Ji
et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.10.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib68" title="">2021</a><span class="ltx_text" id="S3.T2.3.10.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.10.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.10.2.1" style="font-size:70%;">Ultrasonic</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.10.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.10.3.1" style="font-size:70%;">Capacitor</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.10.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.10.4.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.10.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.10.5.1" style="font-size:70%;">80%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.10.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.10.6.1" style="font-size:70%;">10.5 cm</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.11">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.11.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.11.1.1.1" style="font-size:70%;">(</span>Roy
et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.11.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib116" title="">2018</a><span class="ltx_text" id="S3.T2.3.11.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.11.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.11.2.1" style="font-size:70%;">Ultrasonic</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.11.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.11.3.1" style="font-size:70%;">Microphone</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.11.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.11.4.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.11.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.11.5.1" style="font-size:70%;">50%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.11.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.11.6.1" style="font-size:70%;">760 cm</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.12">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.12.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.12.1.1.1" style="font-size:70%;">(</span>Song and Mittal<span class="ltx_text" id="S3.T2.3.12.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib134" title="">2017</a><span class="ltx_text" id="S3.T2.3.12.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.12.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.12.2.1" style="font-size:70%;">Ultrasonic</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.12.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.12.3.1" style="font-size:70%;">Microphone</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.12.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.12.4.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.12.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.12.5.1" style="font-size:70%;">80%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.12.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.12.6.1" style="font-size:70%;">3 m</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.13">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.13.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.13.1.1.1" style="font-size:70%;">(</span>Yan
et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.13.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib175" title="">2019</a><span class="ltx_text" id="S3.T2.3.13.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.13.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.13.2.1" style="font-size:70%;">Ultrasonic</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.13.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.13.3.1" style="font-size:70%;">Microphone</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.13.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.13.4.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.13.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.13.5.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.13.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.13.6.1" style="font-size:70%;">165 cm</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.14">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.14.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.14.1.1.1" style="font-size:70%;">(</span>Qi
et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.14.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib108" title="">2023</a><span class="ltx_text" id="S3.T2.3.14.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.14.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.14.2.1" style="font-size:70%;">Ultrasonic</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.14.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.14.3.1" style="font-size:70%;">Microphone</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.14.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.14.4.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.3.14.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.14.5.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.14.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.14.6.1" style="font-size:70%;">360 cm</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.15">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.3.15.1" style="padding-top:2.45pt;padding-bottom:2.45pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T2.3.15.1.1.1" style="font-size:70%;">(</span>Yang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S3.T2.3.15.1.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib177" title="">2023a</a><span class="ltx_text" id="S3.T2.3.15.1.3.3" style="font-size:70%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.3.15.2" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.15.2.1" style="font-size:70%;">Audible Sound</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.3.15.3" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.15.3.1" style="font-size:70%;">SMPS</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.3.15.4" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.15.4.1" style="font-size:70%;">Over-the-air</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.3.15.5" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.15.5.1" style="font-size:70%;">90%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T2.3.15.6" style="padding-top:2.45pt;padding-bottom:2.45pt;"><span class="ltx_text" id="S3.T2.3.15.6.1" style="font-size:70%;">23 m</span></td>
</tr>
</table>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Preprocessing Layer</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In VCS, the preprocessing layer is essential for refining the digital signals obtained from the physical layer. This layer’s primary function is to filter and enhance audio signals, which often contain a mix of human voices and background noise. Voice activity detection algorithms, like G.729 <cite class="ltx_cite ltx_citemacro_citep">(Sohn
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib133" title="">1999</a>)</cite>, are used to isolate segments containing human speech, followed by the application of low-pass filters to reduce noise and improve VCS’s recognition capabilities. Advances in Deep Neural Networks (DNN) have further enhanced these preprocessing tasks <cite class="ltx_cite ltx_citemacro_citep">(Ryant
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib117" title="">2013</a>)</cite>. Besides noise reduction, this layer is responsible for extracting relevant features from audio signals using techniques such as DFC, MFCC, LPC, MFCS, and PLP, preparing them for subsequent phoneme, character, or word sequence recognition. However, vulnerabilities within these feature extraction processes have been identified, allowing attackers to execute voice-synthesis and adversarial attacks that deceive the VCS. This section discusses these attack methods, exploring how they exploit the preprocessing layer’s weaknesses. Table <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S4.T3" title="Table 3 ‣ 4.2.4. Defense Schemes against Adversarial Attacks. ‣ 4.2. Adversarial Attacks in Preprocessing Layer ‣ 4. Preprocessing Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_tag">3</span></a> provides a comparative summary of these attacks, outlining their strategies and impact on VCS.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Voice-synthesis Attacks in Preprocessing Layer</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Voice-synthesis attacks in the preprocessing layer of VCS utilize technology to create specific speech patterns that can be misinterpreted as legitimate instructions. Due to the lossy nature of signal processing and feature extraction in this layer, attackers can craft voice segments that mimic target voice features. These segments are then mistakenly recognized as intended voice signals by the VCS after undergoing preprocessing. A key characteristic of these attacks is the significant difference between the synthesized and target audio signals, making detection challenging for users.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">For instance, Bispham et al. <cite class="ltx_cite ltx_citemacro_citep">(Bispham
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib16" title="">2019</a>)</cite> produced nonsensical voice commands by altering consonant phonemes in the target voice. Despite the apparent errors, the VCS’s voice model could correct these anomalies, leading to system recognition of these commands. Abdullah et al. <cite class="ltx_cite ltx_citemacro_citep">(Abdullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib4" title="">2019</a>)</cite> employed various signal processing techniques like Time Domain Inversion and High Frequency Addition to morph the target voice into an unintelligible audio signal. They leveraged the VCS’s sensitivity to specific keywords to construct more effective malicious samples. In another approach, Carlini and Vaidya et al. <cite class="ltx_cite ltx_citemacro_citep">(Carlini et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib19" title="">2016</a>; Vaidya
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib147" title="">2015</a>)</cite> targeted the Mel Frequency Cepstral Coefficients (MFCC) feature extraction, common in VCS. By calculating the MFCC features of the target voice and then reversing this process, they generated synthetic audio that successfully deceived the VCS. While these attacks effectively disguise their intent, the unusual noises they produce may still raise user suspicion.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><em class="ltx_emph ltx_font_italic" id="S4.SS1.p3.1.1">Defense Schemes against Voice-synthesis Attacks.</em>
Defending against voice-synthesis attacks in the preprocessing layer of VCS involves two main strategies: detection and prevention. Detection refers to the system’s ability to recognize an attack and alert the user. One common approach is the use of verification mechanisms like CAPTCHAs <cite class="ltx_cite ltx_citemacro_citep">(May, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib95" title="">2005</a>)</cite>, where the system requests a verification response from the user before executing a voice command. This allows users to confirm if the command aligns with their intentions. Additionally, prompt warnings can notify users when the VCS receives voice commands, providing an opportunity to recognize and counteract potential attacks, even if the user may overlook the unusual noise generated by the attack <cite class="ltx_cite ltx_citemacro_citep">(Carlini et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib19" title="">2016</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">Prevention strategies focus on averting the damage from an attack. Voice Activity Detection (VAD) is proposed as a preventive measure <cite class="ltx_cite ltx_citemacro_citep">(Abdullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib4" title="">2019</a>)</cite>. As a speech processing algorithm, VAD can distinguish between noise and actual speech <cite class="ltx_cite ltx_citemacro_citep">(Hartpence, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib60" title="">2013</a>; Ramirez
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib115" title="">2007</a>)</cite>, effectively identifying and disregarding synthesized audio attacks. Moreover, adjusting VCS filters to slightly degrade audio quality can disrupt synthetic audio, which typically lacks robustness, while still preserving the recognition of genuine human speech <cite class="ltx_cite ltx_citemacro_citep">(Carlini et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib19" title="">2016</a>)</cite>. These preventive measures work by exploiting the inherent weaknesses in synthesized audio, thereby reducing the likelihood of successful attacks.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Adversarial Attacks in Preprocessing Layer</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Originally emerging in the field of image recognition <cite class="ltx_cite ltx_citemacro_citep">(Goodfellow
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib52" title="">2014</a>)</cite>, the concept of adversarial attacks has since gained significant attention in speech recognition. Contrary to voice-synthesis attacks, adversarial attacks craft voice commands that sound normal to human users but lead to incorrect predictions by the machine learning models in VCS. These attacks typically involve introducing subtle perturbations into benign audio samples, creating what are known as adversarial samples. These samples exploit the sensitivity of deep learning models to small input changes, posing serious security and privacy risks to audio-based systems.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">In audio applications, these perturbations can be added directly to the audio waveform or to its features. When perturbations are applied to audio features, attackers must reverse-engineer the audio waveform from these features to ensure the altered audio is still recognizable by the VCS. This subsection focuses on adversarial attacks that perturb audio features, as this method intricately involves the operational principles of the preprocessing layer in VCS. Such attacks highlight the inherent vulnerabilities in the feature extraction and processing mechanisms, underscoring the need for robust defense strategies in this layer of VCS.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Taxonomy of Adversarial Attacks in VCS</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">Adversarial attacks in VCS can be classified based on different criteria, including the attack scenario, target, and vector.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p2.1.1">Attack Scenario:</span>
Adversarial attacks are divided into white-box, black-box, and gray-box attacks based on the attacker’s knowledge of the target VCS model. White-box attacks assume complete access to the VCS model, including its internal parameters. Black-box attacks, in contrast, limit the attacker to accessing only the inputs and outputs of the VCS, without knowledge of the internal model details. Gray-box attacks represent an intermediate scenario, where the attacker has partial knowledge of the model’s parameters.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p3">
<p class="ltx_p" id="S4.SS2.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p3.1.1">Attack Target:</span>
In terms of objectives, adversarial attacks can be either targeted or untargeted. Targeted attacks manipulate the VCS to produce a specific, incorrect output defined by the attacker. In contrast, untargeted attacks aim to induce any error in the system’s output without a predetermined result. For example, in Speaker Verification (SV), untargeted attacks might result in the identification of any incorrect speaker, while targeted attacks would misidentify a speaker as a specific individual chosen by the attacker. Similarly, in Automatic Speech Recognition (ASR), untargeted attacks cause any incorrect transcription, whereas targeted attacks aim for a specific false transcription.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p4">
<p class="ltx_p" id="S4.SS2.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p4.1.1">Attack Vector:</span>
Based on the method of delivery, adversarial attacks in VCS can be categorized into Wav-to-API (WTA) attacks and Wav-air-API (WAA) attacks <cite class="ltx_cite ltx_citemacro_citep">(Yuan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib184" title="">2018b</a>)</cite>. WTA attacks involve directly inputting an adversarial audio file into the VCS API, whereas WAA attacks transmit the adversarial sample through the air, capturing it with the system’s microphone before processing. Additionally, there is the Wav-Wave-API (WWA) vector, where adversarial audio deceives VCS after transmission through a transmitter and radio play <cite class="ltx_cite ltx_citemacro_citep">(Yakura and Sakuma, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib172" title="">2018</a>)</cite>. This classification helps in understanding the pathways through which adversarial audio can impact VCS, indicating the need for varied defensive strategies.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Basic Idea of Designing Adversarial Samples</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">Adversarial audio samples are essentially a fusion of benign audio with carefully crafted adversarial perturbations. The primary challenge in the industry is to ensure that these perturbations, when added to benign audio, remain imperceptible to human users while effectively leading the VCS to produce erroneous outputs <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib82" title="">2019</a>)</cite>. This task can be conceptualized as an optimization problem where the attacker’s goal is to minimally alter the audio to cause misclassification by the VCS.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1">The process of designing such attacks in the audio domain, similar to other domains, often involves training neural networks <cite class="ltx_cite ltx_citemacro_citep">(Yan
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib174" title="">2023</a>)</cite>. However, the methods used in the image recognition domain, the most prevalent area of adversarial attacks application, are not directly transferable to audio due to fundamental differences. In audio, perturbations are added in the temporal domain requiring higher precision compared to the spatial domain in images <cite class="ltx_cite ltx_citemacro_citep">(Alzantot
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib11" title="">2018</a>; Carlini and
Wagner, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib20" title="">2018</a>; Vadillo and
Santana, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib145" title="">2019</a>; Abdullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib5" title="">2021a</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.p3.11">The optimization problem in this context is expressed as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="F(x,\delta,y)=\min_{\|\delta\|}l_{m}(f(x+\delta),y)+c\cdot\|\delta\|" class="ltx_Math" display="block" id="S4.E1.m1.7"><semantics id="S4.E1.m1.7a"><mrow id="S4.E1.m1.7.7" xref="S4.E1.m1.7.7.cmml"><mrow id="S4.E1.m1.7.7.3" xref="S4.E1.m1.7.7.3.cmml"><mi id="S4.E1.m1.7.7.3.2" xref="S4.E1.m1.7.7.3.2.cmml">F</mi><mo id="S4.E1.m1.7.7.3.1" xref="S4.E1.m1.7.7.3.1.cmml">⁢</mo><mrow id="S4.E1.m1.7.7.3.3.2" xref="S4.E1.m1.7.7.3.3.1.cmml"><mo id="S4.E1.m1.7.7.3.3.2.1" stretchy="false" xref="S4.E1.m1.7.7.3.3.1.cmml">(</mo><mi id="S4.E1.m1.2.2" xref="S4.E1.m1.2.2.cmml">x</mi><mo id="S4.E1.m1.7.7.3.3.2.2" xref="S4.E1.m1.7.7.3.3.1.cmml">,</mo><mi id="S4.E1.m1.3.3" xref="S4.E1.m1.3.3.cmml">δ</mi><mo id="S4.E1.m1.7.7.3.3.2.3" xref="S4.E1.m1.7.7.3.3.1.cmml">,</mo><mi id="S4.E1.m1.4.4" xref="S4.E1.m1.4.4.cmml">y</mi><mo id="S4.E1.m1.7.7.3.3.2.4" stretchy="false" xref="S4.E1.m1.7.7.3.3.1.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.7.7.2" xref="S4.E1.m1.7.7.2.cmml">=</mo><mrow id="S4.E1.m1.7.7.1" xref="S4.E1.m1.7.7.1.cmml"><mrow id="S4.E1.m1.7.7.1.1" xref="S4.E1.m1.7.7.1.1.cmml"><mrow id="S4.E1.m1.7.7.1.1.3" xref="S4.E1.m1.7.7.1.1.3.cmml"><munder id="S4.E1.m1.7.7.1.1.3.1" xref="S4.E1.m1.7.7.1.1.3.1.cmml"><mi id="S4.E1.m1.7.7.1.1.3.1.2" xref="S4.E1.m1.7.7.1.1.3.1.2.cmml">min</mi><mrow id="S4.E1.m1.1.1.1.3" xref="S4.E1.m1.1.1.1.2.cmml"><mo id="S4.E1.m1.1.1.1.3.1" stretchy="false" xref="S4.E1.m1.1.1.1.2.1.cmml">‖</mo><mi id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml">δ</mi><mo id="S4.E1.m1.1.1.1.3.2" stretchy="false" xref="S4.E1.m1.1.1.1.2.1.cmml">‖</mo></mrow></munder><mo id="S4.E1.m1.7.7.1.1.3a" lspace="0.167em" xref="S4.E1.m1.7.7.1.1.3.cmml">⁡</mo><msub id="S4.E1.m1.7.7.1.1.3.2" xref="S4.E1.m1.7.7.1.1.3.2.cmml"><mi id="S4.E1.m1.7.7.1.1.3.2.2" xref="S4.E1.m1.7.7.1.1.3.2.2.cmml">l</mi><mi id="S4.E1.m1.7.7.1.1.3.2.3" xref="S4.E1.m1.7.7.1.1.3.2.3.cmml">m</mi></msub></mrow><mo id="S4.E1.m1.7.7.1.1.2" xref="S4.E1.m1.7.7.1.1.2.cmml">⁢</mo><mrow id="S4.E1.m1.7.7.1.1.1.1" xref="S4.E1.m1.7.7.1.1.1.2.cmml"><mo id="S4.E1.m1.7.7.1.1.1.1.2" stretchy="false" xref="S4.E1.m1.7.7.1.1.1.2.cmml">(</mo><mrow id="S4.E1.m1.7.7.1.1.1.1.1" xref="S4.E1.m1.7.7.1.1.1.1.1.cmml"><mi id="S4.E1.m1.7.7.1.1.1.1.1.3" xref="S4.E1.m1.7.7.1.1.1.1.1.3.cmml">f</mi><mo id="S4.E1.m1.7.7.1.1.1.1.1.2" xref="S4.E1.m1.7.7.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E1.m1.7.7.1.1.1.1.1.1.1" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E1.m1.7.7.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.7.7.1.1.1.1.1.1.1.1" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.3.cmml">δ</mi></mrow><mo id="S4.E1.m1.7.7.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.7.7.1.1.1.1.3" xref="S4.E1.m1.7.7.1.1.1.2.cmml">,</mo><mi id="S4.E1.m1.5.5" xref="S4.E1.m1.5.5.cmml">y</mi><mo id="S4.E1.m1.7.7.1.1.1.1.4" stretchy="false" xref="S4.E1.m1.7.7.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.7.7.1.2" xref="S4.E1.m1.7.7.1.2.cmml">+</mo><mrow id="S4.E1.m1.7.7.1.3" xref="S4.E1.m1.7.7.1.3.cmml"><mi id="S4.E1.m1.7.7.1.3.2" xref="S4.E1.m1.7.7.1.3.2.cmml">c</mi><mo id="S4.E1.m1.7.7.1.3.1" lspace="0.222em" rspace="0.222em" xref="S4.E1.m1.7.7.1.3.1.cmml">⋅</mo><mrow id="S4.E1.m1.7.7.1.3.3.2" xref="S4.E1.m1.7.7.1.3.3.1.cmml"><mo id="S4.E1.m1.7.7.1.3.3.2.1" stretchy="false" xref="S4.E1.m1.7.7.1.3.3.1.1.cmml">‖</mo><mi id="S4.E1.m1.6.6" xref="S4.E1.m1.6.6.cmml">δ</mi><mo id="S4.E1.m1.7.7.1.3.3.2.2" stretchy="false" xref="S4.E1.m1.7.7.1.3.3.1.1.cmml">‖</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.7b"><apply id="S4.E1.m1.7.7.cmml" xref="S4.E1.m1.7.7"><eq id="S4.E1.m1.7.7.2.cmml" xref="S4.E1.m1.7.7.2"></eq><apply id="S4.E1.m1.7.7.3.cmml" xref="S4.E1.m1.7.7.3"><times id="S4.E1.m1.7.7.3.1.cmml" xref="S4.E1.m1.7.7.3.1"></times><ci id="S4.E1.m1.7.7.3.2.cmml" xref="S4.E1.m1.7.7.3.2">𝐹</ci><vector id="S4.E1.m1.7.7.3.3.1.cmml" xref="S4.E1.m1.7.7.3.3.2"><ci id="S4.E1.m1.2.2.cmml" xref="S4.E1.m1.2.2">𝑥</ci><ci id="S4.E1.m1.3.3.cmml" xref="S4.E1.m1.3.3">𝛿</ci><ci id="S4.E1.m1.4.4.cmml" xref="S4.E1.m1.4.4">𝑦</ci></vector></apply><apply id="S4.E1.m1.7.7.1.cmml" xref="S4.E1.m1.7.7.1"><plus id="S4.E1.m1.7.7.1.2.cmml" xref="S4.E1.m1.7.7.1.2"></plus><apply id="S4.E1.m1.7.7.1.1.cmml" xref="S4.E1.m1.7.7.1.1"><times id="S4.E1.m1.7.7.1.1.2.cmml" xref="S4.E1.m1.7.7.1.1.2"></times><apply id="S4.E1.m1.7.7.1.1.3.cmml" xref="S4.E1.m1.7.7.1.1.3"><apply id="S4.E1.m1.7.7.1.1.3.1.cmml" xref="S4.E1.m1.7.7.1.1.3.1"><csymbol cd="ambiguous" id="S4.E1.m1.7.7.1.1.3.1.1.cmml" xref="S4.E1.m1.7.7.1.1.3.1">subscript</csymbol><min id="S4.E1.m1.7.7.1.1.3.1.2.cmml" xref="S4.E1.m1.7.7.1.1.3.1.2"></min><apply id="S4.E1.m1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.3"><csymbol cd="latexml" id="S4.E1.m1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.3.1">norm</csymbol><ci id="S4.E1.m1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1">𝛿</ci></apply></apply><apply id="S4.E1.m1.7.7.1.1.3.2.cmml" xref="S4.E1.m1.7.7.1.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.7.7.1.1.3.2.1.cmml" xref="S4.E1.m1.7.7.1.1.3.2">subscript</csymbol><ci id="S4.E1.m1.7.7.1.1.3.2.2.cmml" xref="S4.E1.m1.7.7.1.1.3.2.2">𝑙</ci><ci id="S4.E1.m1.7.7.1.1.3.2.3.cmml" xref="S4.E1.m1.7.7.1.1.3.2.3">𝑚</ci></apply></apply><interval closure="open" id="S4.E1.m1.7.7.1.1.1.2.cmml" xref="S4.E1.m1.7.7.1.1.1.1"><apply id="S4.E1.m1.7.7.1.1.1.1.1.cmml" xref="S4.E1.m1.7.7.1.1.1.1.1"><times id="S4.E1.m1.7.7.1.1.1.1.1.2.cmml" xref="S4.E1.m1.7.7.1.1.1.1.1.2"></times><ci id="S4.E1.m1.7.7.1.1.1.1.1.3.cmml" xref="S4.E1.m1.7.7.1.1.1.1.1.3">𝑓</ci><apply id="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1"><plus id="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.1"></plus><ci id="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.7.7.1.1.1.1.1.1.1.1.3">𝛿</ci></apply></apply><ci id="S4.E1.m1.5.5.cmml" xref="S4.E1.m1.5.5">𝑦</ci></interval></apply><apply id="S4.E1.m1.7.7.1.3.cmml" xref="S4.E1.m1.7.7.1.3"><ci id="S4.E1.m1.7.7.1.3.1.cmml" xref="S4.E1.m1.7.7.1.3.1">⋅</ci><ci id="S4.E1.m1.7.7.1.3.2.cmml" xref="S4.E1.m1.7.7.1.3.2">𝑐</ci><apply id="S4.E1.m1.7.7.1.3.3.1.cmml" xref="S4.E1.m1.7.7.1.3.3.2"><csymbol cd="latexml" id="S4.E1.m1.7.7.1.3.3.1.1.cmml" xref="S4.E1.m1.7.7.1.3.3.2.1">norm</csymbol><ci id="S4.E1.m1.6.6.cmml" xref="S4.E1.m1.6.6">𝛿</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.7c">F(x,\delta,y)=\min_{\|\delta\|}l_{m}(f(x+\delta),y)+c\cdot\|\delta\|</annotation><annotation encoding="application/x-llamapun" id="S4.E1.m1.7d">italic_F ( italic_x , italic_δ , italic_y ) = roman_min start_POSTSUBSCRIPT ∥ italic_δ ∥ end_POSTSUBSCRIPT italic_l start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ( italic_f ( italic_x + italic_δ ) , italic_y ) + italic_c ⋅ ∥ italic_δ ∥</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.SSS2.p3.10">Here, <math alttext="x" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.1.m1.1"><semantics id="S4.SS2.SSS2.p3.1.m1.1a"><mi id="S4.SS2.SSS2.p3.1.m1.1.1" xref="S4.SS2.SSS2.p3.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.1.m1.1b"><ci id="S4.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p3.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.1.m1.1d">italic_x</annotation></semantics></math> represents the benign audio sample, <math alttext="\delta" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.2.m2.1"><semantics id="S4.SS2.SSS2.p3.2.m2.1a"><mi id="S4.SS2.SSS2.p3.2.m2.1.1" xref="S4.SS2.SSS2.p3.2.m2.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.2.m2.1b"><ci id="S4.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p3.2.m2.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.2.m2.1c">\delta</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.2.m2.1d">italic_δ</annotation></semantics></math> the added perturbation, and <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.3.m3.1"><semantics id="S4.SS2.SSS2.p3.3.m3.1a"><mi id="S4.SS2.SSS2.p3.3.m3.1.1" xref="S4.SS2.SSS2.p3.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.3.m3.1b"><ci id="S4.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S4.SS2.SSS2.p3.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.3.m3.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.3.m3.1d">italic_y</annotation></semantics></math> the label output by the model <math alttext="f(\cdot)" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.4.m4.1"><semantics id="S4.SS2.SSS2.p3.4.m4.1a"><mrow id="S4.SS2.SSS2.p3.4.m4.1.2" xref="S4.SS2.SSS2.p3.4.m4.1.2.cmml"><mi id="S4.SS2.SSS2.p3.4.m4.1.2.2" xref="S4.SS2.SSS2.p3.4.m4.1.2.2.cmml">f</mi><mo id="S4.SS2.SSS2.p3.4.m4.1.2.1" xref="S4.SS2.SSS2.p3.4.m4.1.2.1.cmml">⁢</mo><mrow id="S4.SS2.SSS2.p3.4.m4.1.2.3.2" xref="S4.SS2.SSS2.p3.4.m4.1.2.cmml"><mo id="S4.SS2.SSS2.p3.4.m4.1.2.3.2.1" stretchy="false" xref="S4.SS2.SSS2.p3.4.m4.1.2.cmml">(</mo><mo id="S4.SS2.SSS2.p3.4.m4.1.1" lspace="0em" rspace="0em" xref="S4.SS2.SSS2.p3.4.m4.1.1.cmml">⋅</mo><mo id="S4.SS2.SSS2.p3.4.m4.1.2.3.2.2" stretchy="false" xref="S4.SS2.SSS2.p3.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.4.m4.1b"><apply id="S4.SS2.SSS2.p3.4.m4.1.2.cmml" xref="S4.SS2.SSS2.p3.4.m4.1.2"><times id="S4.SS2.SSS2.p3.4.m4.1.2.1.cmml" xref="S4.SS2.SSS2.p3.4.m4.1.2.1"></times><ci id="S4.SS2.SSS2.p3.4.m4.1.2.2.cmml" xref="S4.SS2.SSS2.p3.4.m4.1.2.2">𝑓</ci><ci id="S4.SS2.SSS2.p3.4.m4.1.1.cmml" xref="S4.SS2.SSS2.p3.4.m4.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.4.m4.1c">f(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.4.m4.1d">italic_f ( ⋅ )</annotation></semantics></math>. The loss function <math alttext="l_{m}(\cdot)" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.5.m5.1"><semantics id="S4.SS2.SSS2.p3.5.m5.1a"><mrow id="S4.SS2.SSS2.p3.5.m5.1.2" xref="S4.SS2.SSS2.p3.5.m5.1.2.cmml"><msub id="S4.SS2.SSS2.p3.5.m5.1.2.2" xref="S4.SS2.SSS2.p3.5.m5.1.2.2.cmml"><mi id="S4.SS2.SSS2.p3.5.m5.1.2.2.2" xref="S4.SS2.SSS2.p3.5.m5.1.2.2.2.cmml">l</mi><mi id="S4.SS2.SSS2.p3.5.m5.1.2.2.3" xref="S4.SS2.SSS2.p3.5.m5.1.2.2.3.cmml">m</mi></msub><mo id="S4.SS2.SSS2.p3.5.m5.1.2.1" xref="S4.SS2.SSS2.p3.5.m5.1.2.1.cmml">⁢</mo><mrow id="S4.SS2.SSS2.p3.5.m5.1.2.3.2" xref="S4.SS2.SSS2.p3.5.m5.1.2.cmml"><mo id="S4.SS2.SSS2.p3.5.m5.1.2.3.2.1" stretchy="false" xref="S4.SS2.SSS2.p3.5.m5.1.2.cmml">(</mo><mo id="S4.SS2.SSS2.p3.5.m5.1.1" lspace="0em" rspace="0em" xref="S4.SS2.SSS2.p3.5.m5.1.1.cmml">⋅</mo><mo id="S4.SS2.SSS2.p3.5.m5.1.2.3.2.2" stretchy="false" xref="S4.SS2.SSS2.p3.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.5.m5.1b"><apply id="S4.SS2.SSS2.p3.5.m5.1.2.cmml" xref="S4.SS2.SSS2.p3.5.m5.1.2"><times id="S4.SS2.SSS2.p3.5.m5.1.2.1.cmml" xref="S4.SS2.SSS2.p3.5.m5.1.2.1"></times><apply id="S4.SS2.SSS2.p3.5.m5.1.2.2.cmml" xref="S4.SS2.SSS2.p3.5.m5.1.2.2"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p3.5.m5.1.2.2.1.cmml" xref="S4.SS2.SSS2.p3.5.m5.1.2.2">subscript</csymbol><ci id="S4.SS2.SSS2.p3.5.m5.1.2.2.2.cmml" xref="S4.SS2.SSS2.p3.5.m5.1.2.2.2">𝑙</ci><ci id="S4.SS2.SSS2.p3.5.m5.1.2.2.3.cmml" xref="S4.SS2.SSS2.p3.5.m5.1.2.2.3">𝑚</ci></apply><ci id="S4.SS2.SSS2.p3.5.m5.1.1.cmml" xref="S4.SS2.SSS2.p3.5.m5.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.5.m5.1c">l_{m}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.5.m5.1d">italic_l start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ( ⋅ )</annotation></semantics></math> measures the discrepancy between the model’s actual output <math alttext="f(x+\delta)" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.6.m6.1"><semantics id="S4.SS2.SSS2.p3.6.m6.1a"><mrow id="S4.SS2.SSS2.p3.6.m6.1.1" xref="S4.SS2.SSS2.p3.6.m6.1.1.cmml"><mi id="S4.SS2.SSS2.p3.6.m6.1.1.3" xref="S4.SS2.SSS2.p3.6.m6.1.1.3.cmml">f</mi><mo id="S4.SS2.SSS2.p3.6.m6.1.1.2" xref="S4.SS2.SSS2.p3.6.m6.1.1.2.cmml">⁢</mo><mrow id="S4.SS2.SSS2.p3.6.m6.1.1.1.1" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.cmml"><mo id="S4.SS2.SSS2.p3.6.m6.1.1.1.1.2" stretchy="false" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.cmml"><mi id="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.2" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.2.cmml">x</mi><mo id="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.1" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.1.cmml">+</mo><mi id="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.3" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.3.cmml">δ</mi></mrow><mo id="S4.SS2.SSS2.p3.6.m6.1.1.1.1.3" stretchy="false" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.6.m6.1b"><apply id="S4.SS2.SSS2.p3.6.m6.1.1.cmml" xref="S4.SS2.SSS2.p3.6.m6.1.1"><times id="S4.SS2.SSS2.p3.6.m6.1.1.2.cmml" xref="S4.SS2.SSS2.p3.6.m6.1.1.2"></times><ci id="S4.SS2.SSS2.p3.6.m6.1.1.3.cmml" xref="S4.SS2.SSS2.p3.6.m6.1.1.3">𝑓</ci><apply id="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1"><plus id="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.1"></plus><ci id="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.2.cmml" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.2">𝑥</ci><ci id="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.3.cmml" xref="S4.SS2.SSS2.p3.6.m6.1.1.1.1.1.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.6.m6.1c">f(x+\delta)</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.6.m6.1d">italic_f ( italic_x + italic_δ )</annotation></semantics></math> and the label <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.7.m7.1"><semantics id="S4.SS2.SSS2.p3.7.m7.1a"><mi id="S4.SS2.SSS2.p3.7.m7.1.1" xref="S4.SS2.SSS2.p3.7.m7.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.7.m7.1b"><ci id="S4.SS2.SSS2.p3.7.m7.1.1.cmml" xref="S4.SS2.SSS2.p3.7.m7.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.7.m7.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.7.m7.1d">italic_y</annotation></semantics></math>, post-perturbation. The term <math alttext="c\cdot\|\delta\|" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.8.m8.1"><semantics id="S4.SS2.SSS2.p3.8.m8.1a"><mrow id="S4.SS2.SSS2.p3.8.m8.1.2" xref="S4.SS2.SSS2.p3.8.m8.1.2.cmml"><mi id="S4.SS2.SSS2.p3.8.m8.1.2.2" xref="S4.SS2.SSS2.p3.8.m8.1.2.2.cmml">c</mi><mo id="S4.SS2.SSS2.p3.8.m8.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.SSS2.p3.8.m8.1.2.1.cmml">⋅</mo><mrow id="S4.SS2.SSS2.p3.8.m8.1.2.3.2" xref="S4.SS2.SSS2.p3.8.m8.1.2.3.1.cmml"><mo id="S4.SS2.SSS2.p3.8.m8.1.2.3.2.1" stretchy="false" xref="S4.SS2.SSS2.p3.8.m8.1.2.3.1.1.cmml">‖</mo><mi id="S4.SS2.SSS2.p3.8.m8.1.1" xref="S4.SS2.SSS2.p3.8.m8.1.1.cmml">δ</mi><mo id="S4.SS2.SSS2.p3.8.m8.1.2.3.2.2" stretchy="false" xref="S4.SS2.SSS2.p3.8.m8.1.2.3.1.1.cmml">‖</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.8.m8.1b"><apply id="S4.SS2.SSS2.p3.8.m8.1.2.cmml" xref="S4.SS2.SSS2.p3.8.m8.1.2"><ci id="S4.SS2.SSS2.p3.8.m8.1.2.1.cmml" xref="S4.SS2.SSS2.p3.8.m8.1.2.1">⋅</ci><ci id="S4.SS2.SSS2.p3.8.m8.1.2.2.cmml" xref="S4.SS2.SSS2.p3.8.m8.1.2.2">𝑐</ci><apply id="S4.SS2.SSS2.p3.8.m8.1.2.3.1.cmml" xref="S4.SS2.SSS2.p3.8.m8.1.2.3.2"><csymbol cd="latexml" id="S4.SS2.SSS2.p3.8.m8.1.2.3.1.1.cmml" xref="S4.SS2.SSS2.p3.8.m8.1.2.3.2.1">norm</csymbol><ci id="S4.SS2.SSS2.p3.8.m8.1.1.cmml" xref="S4.SS2.SSS2.p3.8.m8.1.1">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.8.m8.1c">c\cdot\|\delta\|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.8.m8.1d">italic_c ⋅ ∥ italic_δ ∥</annotation></semantics></math> quantifies the perturbation’s impact on the original audio, where <math alttext="c" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.9.m9.1"><semantics id="S4.SS2.SSS2.p3.9.m9.1a"><mi id="S4.SS2.SSS2.p3.9.m9.1.1" xref="S4.SS2.SSS2.p3.9.m9.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.9.m9.1b"><ci id="S4.SS2.SSS2.p3.9.m9.1.1.cmml" xref="S4.SS2.SSS2.p3.9.m9.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.9.m9.1c">c</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.9.m9.1d">italic_c</annotation></semantics></math> is a balancing coefficient between attack effectiveness and audio quality. Higher values of <math alttext="c" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.10.m10.1"><semantics id="S4.SS2.SSS2.p3.10.m10.1a"><mi id="S4.SS2.SSS2.p3.10.m10.1.1" xref="S4.SS2.SSS2.p3.10.m10.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.10.m10.1b"><ci id="S4.SS2.SSS2.p3.10.m10.1.1.cmml" xref="S4.SS2.SSS2.p3.10.m10.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.10.m10.1c">c</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.10.m10.1d">italic_c</annotation></semantics></math> indicate substantial degradation in audio quality, potentially compromising the original content’s integrity.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p4">
<p class="ltx_p" id="S4.SS2.SSS2.p4.8">In untargeted attacks, the attacker seeks the smallest <math alttext="\delta" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p4.1.m1.1"><semantics id="S4.SS2.SSS2.p4.1.m1.1a"><mi id="S4.SS2.SSS2.p4.1.m1.1.1" xref="S4.SS2.SSS2.p4.1.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p4.1.m1.1b"><ci id="S4.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p4.1.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p4.1.m1.1c">\delta</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p4.1.m1.1d">italic_δ</annotation></semantics></math> that drastically alters the output <math alttext="f(x+\delta)" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p4.2.m2.1"><semantics id="S4.SS2.SSS2.p4.2.m2.1a"><mrow id="S4.SS2.SSS2.p4.2.m2.1.1" xref="S4.SS2.SSS2.p4.2.m2.1.1.cmml"><mi id="S4.SS2.SSS2.p4.2.m2.1.1.3" xref="S4.SS2.SSS2.p4.2.m2.1.1.3.cmml">f</mi><mo id="S4.SS2.SSS2.p4.2.m2.1.1.2" xref="S4.SS2.SSS2.p4.2.m2.1.1.2.cmml">⁢</mo><mrow id="S4.SS2.SSS2.p4.2.m2.1.1.1.1" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.cmml"><mo id="S4.SS2.SSS2.p4.2.m2.1.1.1.1.2" stretchy="false" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.cmml"><mi id="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.2" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.2.cmml">x</mi><mo id="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.1" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.1.cmml">+</mo><mi id="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.3" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.3.cmml">δ</mi></mrow><mo id="S4.SS2.SSS2.p4.2.m2.1.1.1.1.3" stretchy="false" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p4.2.m2.1b"><apply id="S4.SS2.SSS2.p4.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p4.2.m2.1.1"><times id="S4.SS2.SSS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.SSS2.p4.2.m2.1.1.2"></times><ci id="S4.SS2.SSS2.p4.2.m2.1.1.3.cmml" xref="S4.SS2.SSS2.p4.2.m2.1.1.3">𝑓</ci><apply id="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1"><plus id="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.1"></plus><ci id="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.2.cmml" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.2">𝑥</ci><ci id="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.3.cmml" xref="S4.SS2.SSS2.p4.2.m2.1.1.1.1.1.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p4.2.m2.1c">f(x+\delta)</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p4.2.m2.1d">italic_f ( italic_x + italic_δ )</annotation></semantics></math> from <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p4.3.m3.1"><semantics id="S4.SS2.SSS2.p4.3.m3.1a"><mi id="S4.SS2.SSS2.p4.3.m3.1.1" xref="S4.SS2.SSS2.p4.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p4.3.m3.1b"><ci id="S4.SS2.SSS2.p4.3.m3.1.1.cmml" xref="S4.SS2.SSS2.p4.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p4.3.m3.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p4.3.m3.1d">italic_y</annotation></semantics></math> (given <math alttext="f(x)=y" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p4.4.m4.1"><semantics id="S4.SS2.SSS2.p4.4.m4.1a"><mrow id="S4.SS2.SSS2.p4.4.m4.1.2" xref="S4.SS2.SSS2.p4.4.m4.1.2.cmml"><mrow id="S4.SS2.SSS2.p4.4.m4.1.2.2" xref="S4.SS2.SSS2.p4.4.m4.1.2.2.cmml"><mi id="S4.SS2.SSS2.p4.4.m4.1.2.2.2" xref="S4.SS2.SSS2.p4.4.m4.1.2.2.2.cmml">f</mi><mo id="S4.SS2.SSS2.p4.4.m4.1.2.2.1" xref="S4.SS2.SSS2.p4.4.m4.1.2.2.1.cmml">⁢</mo><mrow id="S4.SS2.SSS2.p4.4.m4.1.2.2.3.2" xref="S4.SS2.SSS2.p4.4.m4.1.2.2.cmml"><mo id="S4.SS2.SSS2.p4.4.m4.1.2.2.3.2.1" stretchy="false" xref="S4.SS2.SSS2.p4.4.m4.1.2.2.cmml">(</mo><mi id="S4.SS2.SSS2.p4.4.m4.1.1" xref="S4.SS2.SSS2.p4.4.m4.1.1.cmml">x</mi><mo id="S4.SS2.SSS2.p4.4.m4.1.2.2.3.2.2" stretchy="false" xref="S4.SS2.SSS2.p4.4.m4.1.2.2.cmml">)</mo></mrow></mrow><mo id="S4.SS2.SSS2.p4.4.m4.1.2.1" xref="S4.SS2.SSS2.p4.4.m4.1.2.1.cmml">=</mo><mi id="S4.SS2.SSS2.p4.4.m4.1.2.3" xref="S4.SS2.SSS2.p4.4.m4.1.2.3.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p4.4.m4.1b"><apply id="S4.SS2.SSS2.p4.4.m4.1.2.cmml" xref="S4.SS2.SSS2.p4.4.m4.1.2"><eq id="S4.SS2.SSS2.p4.4.m4.1.2.1.cmml" xref="S4.SS2.SSS2.p4.4.m4.1.2.1"></eq><apply id="S4.SS2.SSS2.p4.4.m4.1.2.2.cmml" xref="S4.SS2.SSS2.p4.4.m4.1.2.2"><times id="S4.SS2.SSS2.p4.4.m4.1.2.2.1.cmml" xref="S4.SS2.SSS2.p4.4.m4.1.2.2.1"></times><ci id="S4.SS2.SSS2.p4.4.m4.1.2.2.2.cmml" xref="S4.SS2.SSS2.p4.4.m4.1.2.2.2">𝑓</ci><ci id="S4.SS2.SSS2.p4.4.m4.1.1.cmml" xref="S4.SS2.SSS2.p4.4.m4.1.1">𝑥</ci></apply><ci id="S4.SS2.SSS2.p4.4.m4.1.2.3.cmml" xref="S4.SS2.SSS2.p4.4.m4.1.2.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p4.4.m4.1c">f(x)=y</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p4.4.m4.1d">italic_f ( italic_x ) = italic_y</annotation></semantics></math>). Conversely, in targeted attacks, the goal is to minimize <math alttext="\delta" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p4.5.m5.1"><semantics id="S4.SS2.SSS2.p4.5.m5.1a"><mi id="S4.SS2.SSS2.p4.5.m5.1.1" xref="S4.SS2.SSS2.p4.5.m5.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p4.5.m5.1b"><ci id="S4.SS2.SSS2.p4.5.m5.1.1.cmml" xref="S4.SS2.SSS2.p4.5.m5.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p4.5.m5.1c">\delta</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p4.5.m5.1d">italic_δ</annotation></semantics></math> such that <math alttext="f(x+\delta)" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p4.6.m6.1"><semantics id="S4.SS2.SSS2.p4.6.m6.1a"><mrow id="S4.SS2.SSS2.p4.6.m6.1.1" xref="S4.SS2.SSS2.p4.6.m6.1.1.cmml"><mi id="S4.SS2.SSS2.p4.6.m6.1.1.3" xref="S4.SS2.SSS2.p4.6.m6.1.1.3.cmml">f</mi><mo id="S4.SS2.SSS2.p4.6.m6.1.1.2" xref="S4.SS2.SSS2.p4.6.m6.1.1.2.cmml">⁢</mo><mrow id="S4.SS2.SSS2.p4.6.m6.1.1.1.1" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.cmml"><mo id="S4.SS2.SSS2.p4.6.m6.1.1.1.1.2" stretchy="false" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.cmml"><mi id="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.2" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.2.cmml">x</mi><mo id="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.1" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.1.cmml">+</mo><mi id="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.3" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.3.cmml">δ</mi></mrow><mo id="S4.SS2.SSS2.p4.6.m6.1.1.1.1.3" stretchy="false" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p4.6.m6.1b"><apply id="S4.SS2.SSS2.p4.6.m6.1.1.cmml" xref="S4.SS2.SSS2.p4.6.m6.1.1"><times id="S4.SS2.SSS2.p4.6.m6.1.1.2.cmml" xref="S4.SS2.SSS2.p4.6.m6.1.1.2"></times><ci id="S4.SS2.SSS2.p4.6.m6.1.1.3.cmml" xref="S4.SS2.SSS2.p4.6.m6.1.1.3">𝑓</ci><apply id="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1"><plus id="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.1"></plus><ci id="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.2.cmml" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.2">𝑥</ci><ci id="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.3.cmml" xref="S4.SS2.SSS2.p4.6.m6.1.1.1.1.1.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p4.6.m6.1c">f(x+\delta)</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p4.6.m6.1d">italic_f ( italic_x + italic_δ )</annotation></semantics></math> closely matches a specified target output <math alttext="y^{\prime}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p4.7.m7.1"><semantics id="S4.SS2.SSS2.p4.7.m7.1a"><msup id="S4.SS2.SSS2.p4.7.m7.1.1" xref="S4.SS2.SSS2.p4.7.m7.1.1.cmml"><mi id="S4.SS2.SSS2.p4.7.m7.1.1.2" xref="S4.SS2.SSS2.p4.7.m7.1.1.2.cmml">y</mi><mo id="S4.SS2.SSS2.p4.7.m7.1.1.3" xref="S4.SS2.SSS2.p4.7.m7.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p4.7.m7.1b"><apply id="S4.SS2.SSS2.p4.7.m7.1.1.cmml" xref="S4.SS2.SSS2.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p4.7.m7.1.1.1.cmml" xref="S4.SS2.SSS2.p4.7.m7.1.1">superscript</csymbol><ci id="S4.SS2.SSS2.p4.7.m7.1.1.2.cmml" xref="S4.SS2.SSS2.p4.7.m7.1.1.2">𝑦</ci><ci id="S4.SS2.SSS2.p4.7.m7.1.1.3.cmml" xref="S4.SS2.SSS2.p4.7.m7.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p4.7.m7.1c">y^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p4.7.m7.1d">italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> (where <math alttext="f(x)\neq y" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p4.8.m8.1"><semantics id="S4.SS2.SSS2.p4.8.m8.1a"><mrow id="S4.SS2.SSS2.p4.8.m8.1.2" xref="S4.SS2.SSS2.p4.8.m8.1.2.cmml"><mrow id="S4.SS2.SSS2.p4.8.m8.1.2.2" xref="S4.SS2.SSS2.p4.8.m8.1.2.2.cmml"><mi id="S4.SS2.SSS2.p4.8.m8.1.2.2.2" xref="S4.SS2.SSS2.p4.8.m8.1.2.2.2.cmml">f</mi><mo id="S4.SS2.SSS2.p4.8.m8.1.2.2.1" xref="S4.SS2.SSS2.p4.8.m8.1.2.2.1.cmml">⁢</mo><mrow id="S4.SS2.SSS2.p4.8.m8.1.2.2.3.2" xref="S4.SS2.SSS2.p4.8.m8.1.2.2.cmml"><mo id="S4.SS2.SSS2.p4.8.m8.1.2.2.3.2.1" stretchy="false" xref="S4.SS2.SSS2.p4.8.m8.1.2.2.cmml">(</mo><mi id="S4.SS2.SSS2.p4.8.m8.1.1" xref="S4.SS2.SSS2.p4.8.m8.1.1.cmml">x</mi><mo id="S4.SS2.SSS2.p4.8.m8.1.2.2.3.2.2" stretchy="false" xref="S4.SS2.SSS2.p4.8.m8.1.2.2.cmml">)</mo></mrow></mrow><mo id="S4.SS2.SSS2.p4.8.m8.1.2.1" xref="S4.SS2.SSS2.p4.8.m8.1.2.1.cmml">≠</mo><mi id="S4.SS2.SSS2.p4.8.m8.1.2.3" xref="S4.SS2.SSS2.p4.8.m8.1.2.3.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p4.8.m8.1b"><apply id="S4.SS2.SSS2.p4.8.m8.1.2.cmml" xref="S4.SS2.SSS2.p4.8.m8.1.2"><neq id="S4.SS2.SSS2.p4.8.m8.1.2.1.cmml" xref="S4.SS2.SSS2.p4.8.m8.1.2.1"></neq><apply id="S4.SS2.SSS2.p4.8.m8.1.2.2.cmml" xref="S4.SS2.SSS2.p4.8.m8.1.2.2"><times id="S4.SS2.SSS2.p4.8.m8.1.2.2.1.cmml" xref="S4.SS2.SSS2.p4.8.m8.1.2.2.1"></times><ci id="S4.SS2.SSS2.p4.8.m8.1.2.2.2.cmml" xref="S4.SS2.SSS2.p4.8.m8.1.2.2.2">𝑓</ci><ci id="S4.SS2.SSS2.p4.8.m8.1.1.cmml" xref="S4.SS2.SSS2.p4.8.m8.1.1">𝑥</ci></apply><ci id="S4.SS2.SSS2.p4.8.m8.1.2.3.cmml" xref="S4.SS2.SSS2.p4.8.m8.1.2.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p4.8.m8.1c">f(x)\neq y</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p4.8.m8.1d">italic_f ( italic_x ) ≠ italic_y</annotation></semantics></math>).</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p5">
<p class="ltx_p" id="S4.SS2.SSS2.p5.1">To tackle the optimization problem inherent in designing adversarial attacks in the preprocessing layer of VCS, several methods, primarily centered around gradient descent and deep learning techniques, have been proposed in the industry.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p6">
<p class="ltx_p" id="S4.SS2.SSS2.p6.1"><em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p6.1.1">Gradient Descent (GD).</em>
Gradient Descent (GD) is a primary method for creating adversarial audio, widely studied in current research <cite class="ltx_cite ltx_citemacro_citep">(Cisse
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib30" title="">2017</a>; Iter
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib65" title="">2017</a>; Yakura and Sakuma, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib172" title="">2018</a>)</cite>. GD optimizes adversarial samples by iteratively calculating the local minimum of a loss function using partial derivatives and the chain rule. Typically utilized in white-box attack scenarios, GD requires an understanding of the target loss function’s specifics. While increasing the number of iterations can enhance the success rate of the attack, it may also compromise the adversarial audio’s quality <cite class="ltx_cite ltx_citemacro_citep">(Schönherr et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib123" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p7">
<p class="ltx_p" id="S4.SS2.SSS2.p7.1"><em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p7.1.1">Deep Learning-based Methods.</em>
To overcome the time and computational resource constraints of iterative GD, deep learning models, such as Recurrent Neural Networks (RNNs) <cite class="ltx_cite ltx_citemacro_citep">(Chang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib21" title="">2020</a>)</cite>, are employed. These pre-trained models simulate the gradient descent process, enabling real-time generation of adversarial samples, thus enhancing efficiency.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p8">
<p class="ltx_p" id="S4.SS2.SSS2.p8.1"><em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p8.1.1">Fast Gradient Sign Method (FGSM).</em>
FGSM, introduced by Goodfellow et al. <cite class="ltx_cite ltx_citemacro_citep">(Goodfellow
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib52" title="">2014</a>)</cite>, offers a faster approach to generate adversarial samples. It involves adding perturbations in the gradient direction of the original audio using a sign function, requiring only a single gradient calculation and addition/subtraction operation. Proven effective in the audio domain, FGSM can efficiently produce adversarial samples <cite class="ltx_cite ltx_citemacro_citep">(Kreuk
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib76" title="">2018</a>; Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib86" title="">2020d</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p9">
<p class="ltx_p" id="S4.SS2.SSS2.p9.1"><em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS2.p9.1.1">Transferability of Adversarial Samples.</em>
Given the limited access to commercial VCS models, attackers often rely on gray-box or black-box approaches, relying on querying the model and interpreting outputs. Transferability of adversarial samples between models becomes crucial in such scenarios. Studies in computer vision have shown the effectiveness of transferring adversarial samples across different models <cite class="ltx_cite ltx_citemacro_citep">(Fawzi
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib44" title="">2018</a>; Szegedy et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib139" title="">2013</a>)</cite>. In audio, the success of transfer-based attacks is linked to the similarity between the parameters and structures of different models <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib26" title="">2020b</a>)</cite>. Xu et al. <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib86" title="">2020d</a>)</cite> demonstrated this by successfully executing a transfer-based adversarial attack between i-vector and x-vector models, exploiting their structural similarities.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3. </span>The Characteristics of Adversarial Attacks in Preprocessing Layer</h4>
<div class="ltx_para" id="S4.SS2.SSS3.p1">
<p class="ltx_p" id="S4.SS2.SSS3.p1.1">A key characteristic of adversarial attacks in the preprocessing layer is the indirect addition of perturbations. Rather than directly altering the audio signal, attackers inject perturbations into neural network features, such as those obtained from Short-Time Fourier Transform (STFT) or Mel Frequency Cepstral Coefficients (MFCC). For STFT-based approaches, benign audio is first converted into a spectrogram, and adversarial perturbations are added at this stage, followed by inverse transformation to generate adversarial audio <cite class="ltx_cite ltx_citemacro_citep">(Chang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib21" title="">2020</a>; Cisse
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib30" title="">2017</a>)</cite>. In contrast, perturbing MFCC features, while mitigating some challenges, results in a significant quality reduction in the adversarial audio due to the lossy nature of inverse MFCC transformation <cite class="ltx_cite ltx_citemacro_citep">(Du
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib39" title="">2020</a>; Iter
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib65" title="">2017</a>; Yakura and Sakuma, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib172" title="">2018</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4. </span>Defense Schemes against Adversarial Attacks.</h4>
<div class="ltx_para" id="S4.SS2.SSS4.p1">
<p class="ltx_p" id="S4.SS2.SSS4.p1.1">Adversarial training, a method proven effective in image processing, involves integrating adversarial examples into training data to enhance model robustness <cite class="ltx_cite ltx_citemacro_citep">(Madry et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib92" title="">2018</a>)</cite>. However, this approach has limitations:</p>
<ol class="ltx_enumerate" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">It can lead to decreased accuracy in predicting legitimate examples due to label leakage <cite class="ltx_cite ltx_citemacro_citep">(Wang, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib154" title="">2021</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">The effectiveness of adversarial training depends on the availability of a diverse set of known adversarial examples, making it less effective against novel attacks <cite class="ltx_cite ltx_citemacro_citep">(Gong and
Poellabauer, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib49" title="">2018a</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">This method increases training iterations, thereby raising the model’s training cost.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p2">
<p class="ltx_p" id="S4.SS2.SSS4.p2.1">Given that these attacks often require in-depth knowledge of the VCS’s preprocessing techniques, they are generally categorized as white-box attacks. A counter-strategy involves modifying the targeted data preprocessing methods. For example, if attacks primarily target MFCC processing, alternative feature extraction techniques like neural networks or other methods may be employed <cite class="ltx_cite ltx_citemacro_citep">(Abdel-Hamid et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib3" title="">2014</a>; Hai and Joo, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib58" title="">2003</a>)</cite>. However, introducing new neural network modules to the preprocessing layer may inadvertently create new vulnerabilities within the system.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 3. </span>Comparison of voice-synthesis attacks and adversarial attacks in preprocessing layer</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S4.T3.7">
<tr class="ltx_tr" id="S4.T3.7.8">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.8.1" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.8.1.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.8.1.1.1"></span> <span class="ltx_text" id="S4.T3.7.8.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.8.1.1.2.1">
<span class="ltx_tr" id="S4.T3.7.8.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Attack</span></span>
<span class="ltx_tr" id="S4.T3.7.8.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.1.1.2.1.2.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Type</span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.8.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.8.2" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.8.2.1" style="font-size:70%;">Paper</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.8.3" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.8.3.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.8.3.1.1"></span> <span class="ltx_text" id="S4.T3.7.8.3.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.8.3.1.2.1">
<span class="ltx_tr" id="S4.T3.7.8.3.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.3.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Attack</span></span>
<span class="ltx_tr" id="S4.T3.7.8.3.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.3.1.2.1.2.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Method</span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.8.3.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.8.4" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.8.4.1" style="font-size:70%;">Goal</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.8.5" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.8.5.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.8.5.1.1"></span> <span class="ltx_text" id="S4.T3.7.8.5.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.8.5.1.2.1">
<span class="ltx_tr" id="S4.T3.7.8.5.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.5.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Attack Target</span></span>
<span class="ltx_tr" id="S4.T3.7.8.5.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.5.1.2.1.2.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">(Category)</span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.8.5.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.8.6" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.8.6.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.8.6.1.1"></span> <span class="ltx_text" id="S4.T3.7.8.6.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.8.6.1.2.1">
<span class="ltx_tr" id="S4.T3.7.8.6.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.6.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Model</span></span>
<span class="ltx_tr" id="S4.T3.7.8.6.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.6.1.2.1.2.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Knowledge</span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.8.6.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.8.7" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.8.7.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.8.7.1.1"></span> <span class="ltx_text" id="S4.T3.7.8.7.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.8.7.1.2.1">
<span class="ltx_tr" id="S4.T3.7.8.7.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.7.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.8.7.1.2.1.1.1.1"></span> <span class="ltx_text" id="S4.T3.7.8.7.1.2.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.8.7.1.2.1.1.1.2.1">
<span class="ltx_tr" id="S4.T3.7.8.7.1.2.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.7.1.2.1.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Attack</span></span>
<span class="ltx_tr" id="S4.T3.7.8.7.1.2.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.7.1.2.1.1.1.2.1.2.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Vector</span></span>
</span></span><span class="ltx_text" id="S4.T3.7.8.7.1.2.1.1.1.3"></span></span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.8.7.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.8.8" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.8.8.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.8.8.1.1"></span> <span class="ltx_text" id="S4.T3.7.8.8.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.8.8.1.2.1">
<span class="ltx_tr" id="S4.T3.7.8.8.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.8.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Cost</span></span>
<span class="ltx_tr" id="S4.T3.7.8.8.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.8.8.1.2.1.2.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">(Time)</span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.8.8.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T3.7.8.9" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.8.9.1" style="font-size:70%;">Performance</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.9">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.9.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.9.1.1" style="font-size:70%;">Success</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.9.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.9.2.1" style="font-size:70%;">Distance</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.10">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.10.1" rowspan="7" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.10.1.1" style="font-size:70%;">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T3.7.10.1.1.1" style="width:36.0pt;height:56.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:56.7pt;transform:translate(-10.34pt,-10.34pt) rotate(-90deg) ;">
<span class="ltx_p" id="S4.T3.7.10.1.1.1.1"><span class="ltx_text" id="S4.T3.7.10.1.1.1.1.1"></span> <span class="ltx_text" id="S4.T3.7.10.1.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.10.1.1.1.1.2.1">
<span class="ltx_tr" id="S4.T3.7.10.1.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.10.1.1.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Voice-synthesis</span></span>
<span class="ltx_tr" id="S4.T3.7.10.1.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.10.1.1.1.1.2.1.2.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Attacks</span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.10.1.1.1.1.3"></span></span>
</span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.10.2" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.7.10.2.1"></span><span class="ltx_text" id="S4.T3.7.10.2.2" style="font-size:70%;"> </span><span class="ltx_text" id="S4.T3.7.10.2.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.10.2.3.1">
<span class="ltx_tr" id="S4.T3.7.10.2.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.10.2.3.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Bispham
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib16" title="">2019</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T3.7.10.2.4"></span><span class="ltx_text" id="S4.T3.7.10.2.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.10.3" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.7.10.3.1" style="font-size:70%;">RCP</span><sup class="ltx_sup" id="S4.T3.7.10.3.2"><span class="ltx_text" id="S4.T3.7.10.3.2.1" style="font-size:70%;">1</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.10.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.10.4.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.10.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.10.5.1" style="font-size:70%;">Google Assist (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.10.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.10.6.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.10.7" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.10.7.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.10.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.10.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.10.9" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.10.9.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.10.10" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.10.10.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.11">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.11.1" rowspan="3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.11.1.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.11.1.1.1"></span> <span class="ltx_text" id="S4.T3.7.11.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.11.1.1.2.1">
<span class="ltx_tr" id="S4.T3.7.11.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.11.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Abdullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib4" title="">2019</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.11.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.11.2" rowspan="3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.11.2.1" style="font-size:70%;">SP<sup class="ltx_sup" id="S4.T3.7.11.2.1.1">2</sup></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.11.3" rowspan="3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.11.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.11.4" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.11.4.1" style="font-size:70%;">10 models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.11.5" rowspan="3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.11.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.11.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.11.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.11.7" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.11.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.11.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.11.8.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.11.9" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.11.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.12">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.12.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.12.1.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.12.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.12.2.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.12.3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.12.3.1" style="font-size:70%;">80%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.12.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.12.4.1" style="font-size:70%;">1 foot</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.13">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.13.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.13.1.1" style="font-size:70%;">2 models (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.13.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.13.2.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.13.3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.13.3.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.13.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.13.4.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.13.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.13.5.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.14">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.14.1" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.14.1.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.14.1.1.1"></span> <span class="ltx_text" id="S4.T3.7.14.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.14.1.1.2.1">
<span class="ltx_tr" id="S4.T3.7.14.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.14.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Carlini et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib19" title="">2016</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.14.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.14.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.14.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.14.3" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.14.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.14.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.14.4.1" style="font-size:70%;">CMU Sphinx (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.14.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.14.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.14.6" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.14.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.14.7" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.14.7.1" style="font-size:70%;">32h</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.14.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.14.8.1" style="font-size:70%;">82%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.14.9" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.14.9.1" style="font-size:70%;">0.5m</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.2" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.1.1.2.1" style="font-size:70%;">IMFCC</span><sup class="ltx_sup" id="S4.T3.1.1.2.2"><span class="ltx_text" id="S4.T3.1.1.2.2.1" style="font-size:70%;">3</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.1.1.3.1" style="font-size:70%;">Google Now (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.1.1.4.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.1.1.5.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.1.1.6.1" style="font-size:70%;">80%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<math alttext="\leq 3.5" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mrow id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml"><mi id="S4.T3.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.m1.1.1.2.cmml"></mi><mo id="S4.T3.1.1.1.m1.1.1.1" mathsize="70%" xref="S4.T3.1.1.1.m1.1.1.1.cmml">≤</mo><mn id="S4.T3.1.1.1.m1.1.1.3" mathsize="70%" xref="S4.T3.1.1.1.m1.1.1.3.cmml">3.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1"><leq id="S4.T3.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S4.T3.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.m1.1.1.2">absent</csymbol><cn id="S4.T3.1.1.1.m1.1.1.3.cmml" type="float" xref="S4.T3.1.1.1.m1.1.1.3">3.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\leq 3.5</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">≤ 3.5</annotation></semantics></math><span class="ltx_text" id="S4.T3.1.1.1.1" style="font-size:70%;">m</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.15">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.15.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.7.15.1.1"></span><span class="ltx_text" id="S4.T3.7.15.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S4.T3.7.15.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.15.1.3.1">
<span class="ltx_tr" id="S4.T3.7.15.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.15.1.3.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.15.1.3.1.1.1.1"></span> <span class="ltx_text" id="S4.T3.7.15.1.3.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.15.1.3.1.1.1.2.1">
<span class="ltx_tr" id="S4.T3.7.15.1.3.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.15.1.3.1.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Vaidya
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib147" title="">2015</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T3.7.15.1.3.1.1.1.3"></span></span></span>
</span></span><span class="ltx_text" id="S4.T3.7.15.1.4"></span><span class="ltx_text" id="S4.T3.7.15.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.15.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.15.2.1" style="font-size:70%;">IMFCC</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.15.3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.15.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.15.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.15.4.1" style="font-size:70%;">Google Now (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.15.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.15.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.15.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.15.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.15.7" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.15.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.15.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.15.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.15.9" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.15.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.16">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.7.16.1" rowspan="15" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.16.1.1" style="font-size:70%;">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T3.7.16.1.1.1" style="width:4.9pt;height:60.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:60.6pt;transform:translate(-27.86pt,-27.86pt) rotate(-90deg) ;">
<span class="ltx_p" id="S4.T3.7.16.1.1.1.1">Adversarial Attacks</span>
</span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.16.2" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.16.2.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.16.2.1.1"></span> <span class="ltx_text" id="S4.T3.7.16.2.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.16.2.1.2.1">
<span class="ltx_tr" id="S4.T3.7.16.2.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.16.2.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Cisse
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib30" title="">2017</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.16.2.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.16.3" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.16.3.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.16.4" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.16.4.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.16.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.16.5.1" style="font-size:70%;">DeepSpeech-2 (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.16.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.16.6.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.16.7" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.16.7.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.16.8" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.16.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.16.9" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.16.9.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.16.10" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.16.10.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.17">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.17.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.17.1.1" style="font-size:70%;">Google Voice (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.17.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.17.2.1" style="font-size:70%;">Black</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.18">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.18.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.7.18.1.1"></span><span class="ltx_text" id="S4.T3.7.18.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S4.T3.7.18.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.18.1.3.1">
<span class="ltx_tr" id="S4.T3.7.18.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.18.1.3.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Iter
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib65" title="">2017</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T3.7.18.1.4"></span><span class="ltx_text" id="S4.T3.7.18.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.18.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.18.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.18.3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.18.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.18.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.18.4.1" style="font-size:70%;">WaveNet (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.18.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.18.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.18.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.18.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.18.7" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.18.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.18.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.18.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.18.9" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.18.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.3.3.3.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.3.3.3.1.1"></span> <span class="ltx_text" id="S4.T3.3.3.3.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.3.3.3.1.2.1">
<span class="ltx_tr" id="S4.T3.3.3.3.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.3.3.3.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yakura and Sakuma, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib172" title="">2018</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S4.T3.3.3.3.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.4" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.3.3.4.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.5" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.3.3.5.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.6" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.3.3.6.1" style="font-size:70%;">DeepSpeech (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.7" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.3.3.7.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.3.3.8.1" style="font-size:70%;">WWA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.9" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.3.3.9.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.2.2.1.1" style="font-size:70%;">50</span><math alttext="\sim" class="ltx_Math" display="inline" id="S4.T3.2.2.1.m1.1"><semantics id="S4.T3.2.2.1.m1.1a"><mo id="S4.T3.2.2.1.m1.1.1" mathsize="70%" xref="S4.T3.2.2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.m1.1b"><csymbol cd="latexml" id="S4.T3.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S4.T3.2.2.1.2" style="font-size:70%;">100%</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.2" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.3.3.2.1" style="font-size:70%;"><math alttext="\leq 0.5" class="ltx_Math" display="inline" id="S4.T3.3.3.2.1.m1.1"><semantics id="S4.T3.3.3.2.1.m1.1a"><mrow id="S4.T3.3.3.2.1.m1.1.1" xref="S4.T3.3.3.2.1.m1.1.1.cmml"><mi id="S4.T3.3.3.2.1.m1.1.1.2" xref="S4.T3.3.3.2.1.m1.1.1.2.cmml"></mi><mo id="S4.T3.3.3.2.1.m1.1.1.1" xref="S4.T3.3.3.2.1.m1.1.1.1.cmml">≤</mo><mn id="S4.T3.3.3.2.1.m1.1.1.3" xref="S4.T3.3.3.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.2.1.m1.1b"><apply id="S4.T3.3.3.2.1.m1.1.1.cmml" xref="S4.T3.3.3.2.1.m1.1.1"><leq id="S4.T3.3.3.2.1.m1.1.1.1.cmml" xref="S4.T3.3.3.2.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S4.T3.3.3.2.1.m1.1.1.2.cmml" xref="S4.T3.3.3.2.1.m1.1.1.2">absent</csymbol><cn id="S4.T3.3.3.2.1.m1.1.1.3.cmml" type="float" xref="S4.T3.3.3.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.2.1.m1.1c">\leq 0.5</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.2.1.m1.1d">≤ 0.5</annotation></semantics></math>m</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.4">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.4.4.2.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.4.4.1.1" style="font-size:70%;">60</span><math alttext="\sim" class="ltx_Math" display="inline" id="S4.T3.4.4.1.m1.1"><semantics id="S4.T3.4.4.1.m1.1a"><mo id="S4.T3.4.4.1.m1.1.1" mathsize="70%" xref="S4.T3.4.4.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.1.m1.1b"><csymbol cd="latexml" id="S4.T3.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S4.T3.4.4.1.2" style="font-size:70%;">90%</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.6.6.3" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.6.6.3.1"></span><span class="ltx_text" id="S4.T3.6.6.3.2" style="font-size:70%;"> </span><span class="ltx_text" id="S4.T3.6.6.3.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.3.3.1">
<span class="ltx_tr" id="S4.T3.6.6.3.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.6.6.3.3.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.6.6.3.3.1.1.1.1"></span> <span class="ltx_text" id="S4.T3.6.6.3.3.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.3.3.1.1.1.2.1">
<span class="ltx_tr" id="S4.T3.6.6.3.3.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.6.6.3.3.1.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib21" title="">2020</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T3.6.6.3.3.1.1.1.3"></span></span></span>
</span></span><span class="ltx_text" id="S4.T3.6.6.3.4"></span><span class="ltx_text" id="S4.T3.6.6.3.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.6.6.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.6.6.4.1" style="font-size:70%;">RNN</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.6.6.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.6.6.5.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.6.6.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.6.6.6.1" style="font-size:70%;">KWS (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.6.6.7" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.6.6.7.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.6.6.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.6.6.8.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<math alttext="\thickapprox 0.096" class="ltx_Math" display="inline" id="S4.T3.5.5.1.m1.1"><semantics id="S4.T3.5.5.1.m1.1a"><mrow id="S4.T3.5.5.1.m1.1.1" xref="S4.T3.5.5.1.m1.1.1.cmml"><mi id="S4.T3.5.5.1.m1.1.1.2" xref="S4.T3.5.5.1.m1.1.1.2.cmml"></mi><mo id="S4.T3.5.5.1.m1.1.1.1" mathsize="70%" xref="S4.T3.5.5.1.m1.1.1.1.cmml">≈</mo><mn id="S4.T3.5.5.1.m1.1.1.3" mathsize="70%" xref="S4.T3.5.5.1.m1.1.1.3.cmml">0.096</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.1.m1.1b"><apply id="S4.T3.5.5.1.m1.1.1.cmml" xref="S4.T3.5.5.1.m1.1.1"><approx id="S4.T3.5.5.1.m1.1.1.1.cmml" xref="S4.T3.5.5.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S4.T3.5.5.1.m1.1.1.2.cmml" xref="S4.T3.5.5.1.m1.1.1.2">absent</csymbol><cn id="S4.T3.5.5.1.m1.1.1.3.cmml" type="float" xref="S4.T3.5.5.1.m1.1.1.3">0.096</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.1.m1.1c">\thickapprox 0.096</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.5.1.m1.1d">≈ 0.096</annotation></semantics></math><span class="ltx_text" id="S4.T3.5.5.1.1" style="font-size:70%;">s</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.6.6.9" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.6.6.9.1" style="font-size:70%;">84.30%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.6.2" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<math alttext="\leq 4" class="ltx_Math" display="inline" id="S4.T3.6.6.2.m1.1"><semantics id="S4.T3.6.6.2.m1.1a"><mrow id="S4.T3.6.6.2.m1.1.1" xref="S4.T3.6.6.2.m1.1.1.cmml"><mi id="S4.T3.6.6.2.m1.1.1.2" xref="S4.T3.6.6.2.m1.1.1.2.cmml"></mi><mo id="S4.T3.6.6.2.m1.1.1.1" mathsize="70%" xref="S4.T3.6.6.2.m1.1.1.1.cmml">≤</mo><mn id="S4.T3.6.6.2.m1.1.1.3" mathsize="70%" xref="S4.T3.6.6.2.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.2.m1.1b"><apply id="S4.T3.6.6.2.m1.1.1.cmml" xref="S4.T3.6.6.2.m1.1.1"><leq id="S4.T3.6.6.2.m1.1.1.1.cmml" xref="S4.T3.6.6.2.m1.1.1.1"></leq><csymbol cd="latexml" id="S4.T3.6.6.2.m1.1.1.2.cmml" xref="S4.T3.6.6.2.m1.1.1.2">absent</csymbol><cn id="S4.T3.6.6.2.m1.1.1.3.cmml" type="integer" xref="S4.T3.6.6.2.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.2.m1.1c">\leq 4</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.6.2.m1.1d">≤ 4</annotation></semantics></math><span class="ltx_text" id="S4.T3.6.6.2.1" style="font-size:70%;">m</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.7">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.7.2" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.7.2.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.7.2.1.1"></span> <span class="ltx_text" id="S4.T3.7.7.2.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.7.2.1.2.1">
<span class="ltx_tr" id="S4.T3.7.7.2.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.7.2.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.7.2.1.2.1.1.1.1"></span> <span class="ltx_text" id="S4.T3.7.7.2.1.2.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.7.2.1.2.1.1.1.2.1">
<span class="ltx_tr" id="S4.T3.7.7.2.1.2.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.7.2.1.2.1.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Kreuk
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib76" title="">2018</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T3.7.7.2.1.2.1.1.1.3"></span></span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.7.2.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.7.3" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.7.3.1" style="font-size:70%;">FGSM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.7.4" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.7.4.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.7.5" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.7.5.1" style="font-size:70%;">DNN End-to-end (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.7.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.7.6.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.7.7" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.7.7.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.7.8" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.7.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.7.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.7.7.1.1" style="font-size:70%;">64</span><math alttext="\sim" class="ltx_Math" display="inline" id="S4.T3.7.7.1.m1.1"><semantics id="S4.T3.7.7.1.m1.1a"><mo id="S4.T3.7.7.1.m1.1.1" mathsize="70%" xref="S4.T3.7.7.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.1.m1.1b"><csymbol cd="latexml" id="S4.T3.7.7.1.m1.1.1.cmml" xref="S4.T3.7.7.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.T3.7.7.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S4.T3.7.7.1.2" style="font-size:70%;">94%(FAR)</span><sup class="ltx_sup" id="S4.T3.7.7.1.3"><span class="ltx_text" id="S4.T3.7.7.1.3.1" style="font-size:70%;">4</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.7.9" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.7.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.19">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.19.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.19.1.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.19.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.19.2.1" style="font-size:70%;">46%(FAR)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.20">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.20.1" rowspan="3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.20.1.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.20.1.1.1"></span> <span class="ltx_text" id="S4.T3.7.20.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.20.1.1.2.1">
<span class="ltx_tr" id="S4.T3.7.20.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.20.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.20.1.1.2.1.1.1.1"></span> <span class="ltx_text" id="S4.T3.7.20.1.1.2.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.20.1.1.2.1.1.1.2.1">
<span class="ltx_tr" id="S4.T3.7.20.1.1.2.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.20.1.1.2.1.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib86" title="">2020d</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T3.7.20.1.1.2.1.1.1.3"></span></span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.20.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.20.2" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.20.2.1" style="font-size:70%;">FGSM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.20.3" rowspan="3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.20.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.20.4" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.20.4.1" style="font-size:70%;">GMM i-vector (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.20.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.20.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.20.6" rowspan="3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.20.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.20.7" rowspan="3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.20.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.20.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.20.8.1" style="font-size:70%;">99.99%(FAR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.20.9" rowspan="3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.20.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.21">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.21.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.21.1.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.21.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.21.2.1" style="font-size:70%;">&lt;70%(FAR)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.22">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.22.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.22.1.1" style="font-size:70%;">Transfer</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.22.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.22.2.1" style="font-size:70%;">DNN x-vector (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.22.3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.22.3.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.22.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.22.4.1" style="font-size:70%;">&lt;60%(FAR)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.23">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.23.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.7.23.1.1"></span><span class="ltx_text" id="S4.T3.7.23.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S4.T3.7.23.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.23.1.3.1">
<span class="ltx_tr" id="S4.T3.7.23.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.23.1.3.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Marras et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib94" title="">2019</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T3.7.23.1.4"></span><span class="ltx_text" id="S4.T3.7.23.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.23.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.23.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.23.3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.23.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.23.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.23.4.1" style="font-size:70%;">VGGVox (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.23.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.23.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.23.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.23.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.23.7" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.23.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.23.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.23.8.1" style="font-size:70%;">&lt;80%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.23.9" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.23.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.24">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.24.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">
<span class="ltx_text" id="S4.T3.7.24.1.1"></span><span class="ltx_text" id="S4.T3.7.24.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S4.T3.7.24.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.24.1.3.1">
<span class="ltx_tr" id="S4.T3.7.24.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.24.1.3.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib155" title="">2020c</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T3.7.24.1.4"></span><span class="ltx_text" id="S4.T3.7.24.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.24.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.24.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.24.3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.24.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.24.4" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.24.4.1" style="font-size:70%;">DNN x-vector (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.24.5" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.24.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.24.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.24.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.24.7" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.24.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.24.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.24.8.1" style="font-size:70%;">&lt;98.5%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.24.9" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.24.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.25">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.7.25.1" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.25.1.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.25.1.1.1"></span> <span class="ltx_text" id="S4.T3.7.25.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.25.1.1.2.1">
<span class="ltx_tr" id="S4.T3.7.25.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.25.1.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><cite class="ltx_cite ltx_citemacro_citep">(Guo
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib55" title="">2022</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.25.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.7.25.2" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.25.2.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.25.2.1.1"></span> <span class="ltx_text" id="S4.T3.7.25.2.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.25.2.1.2.1">
<span class="ltx_tr" id="S4.T3.7.25.2.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.25.2.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">RCP</span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.25.2.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.7.25.3" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.25.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.7.25.4" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.25.4.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.25.4.1.1"></span> <span class="ltx_text" id="S4.T3.7.25.4.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.25.4.1.2.1">
<span class="ltx_tr" id="S4.T3.7.25.4.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.25.4.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">DeepSpeech2 (ASR)</span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.25.4.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.7.25.5" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.25.5.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.25.5.1.1"></span> <span class="ltx_text" id="S4.T3.7.25.5.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.25.5.1.2.1">
<span class="ltx_tr" id="S4.T3.7.25.5.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.25.5.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">Black</span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.25.5.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.25.6" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.25.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.7.25.7" rowspan="2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.25.7.1" style="font-size:70%;"><span class="ltx_text" id="S4.T3.7.25.7.1.1"></span> <span class="ltx_text" id="S4.T3.7.25.7.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.7.25.7.1.2.1">
<span class="ltx_tr" id="S4.T3.7.25.7.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.7.25.7.1.2.1.1.1" style="padding-top:3.15pt;padding-bottom:3.15pt;">n.a</span></span>
</span></span> <span class="ltx_text" id="S4.T3.7.25.7.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.7.25.8" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.25.8.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.7.25.9" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.25.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.7.26">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.7.26.1" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.26.1.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.7.26.2" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.26.2.1" style="font-size:70%;">80%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T3.7.26.3" style="padding-top:3.15pt;padding-bottom:3.15pt;"><span class="ltx_text" id="S4.T3.7.26.3.1" style="font-size:70%;">1m</span></td>
</tr>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.4"><sup class="ltx_sup" id="S4.I2.i1.p1.4.1"><span class="ltx_text" id="S4.I2.i1.p1.4.1.1" style="font-size:70%;">1</span></sup><span class="ltx_text" id="S4.I2.i1.p1.4.2" style="font-size:70%;"> RCP: replacing the consonant phonemes. </span><sup class="ltx_sup" id="S4.I2.i1.p1.4.3"><span class="ltx_text" id="S4.I2.i1.p1.4.3.1" style="font-size:70%;">2</span></sup><span class="ltx_text" id="S4.I2.i1.p1.4.4" style="font-size:70%;"> SP: signal processing. </span><sup class="ltx_sup" id="S4.I2.i1.p1.4.5"><span class="ltx_text" id="S4.I2.i1.p1.4.5.1" style="font-size:70%;">3</span></sup><span class="ltx_text" id="S4.I2.i1.p1.4.6" style="font-size:70%;"> IMFCC: inverse MFCC. </span><sup class="ltx_sup" id="S4.I2.i1.p1.4.7"><span class="ltx_text" id="S4.I2.i1.p1.4.7.1" style="font-size:70%;">4</span></sup><span class="ltx_text" id="S4.I2.i1.p1.4.8" style="font-size:70%;"> FAR: false acceptance rate.</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Kernel Layer</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In VCS, the kernel layer plays a crucial role in decoding audio feature vectors processed in the preprocessing layer. This decoding is traditionally achieved through an acoustic model, which translates feature vectors into phonemes, and a language model, predicting word sequence probabilities to output the most probable sentence. Historically, decoding methods have included Hidden Markov Models (HMM), Recurrent Neural Networks (RNN), and N-gram models. However, the rise of deep learning technologies has led to advanced models like Wav2Letter (CNNs-based), Kaldi (DNN-HMM), and CMU Sphinx (GMM-HMM) becoming mainstream due to their enhanced accuracy in speech recognition <cite class="ltx_cite ltx_citemacro_citep">(Nassif et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib100" title="">2019</a>)</cite>. Despite these advancements, the kernel layer remains vulnerable to adversarial attacks that manipulate the decoding process and spoofing attacks, where attackers mimic legitimate audio inputs to deceive the system, highlighting the need for robust security measures in this critical component of VCS.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Spoofing Attacks in Kernel Layer</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Spoofing attacks in the kernel layer of VCS primarily target the Speaker Verification (SV) component. These attacks are executed with the intention of impersonating a target speaker to gain unauthorized access or privileges within the VCS system <cite class="ltx_cite ltx_citemacro_citep">(Ergünay et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib41" title="">2015</a>; Evans
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib42" title="">2013</a>)</cite>. Commonly, spoofing attacks are categorized into four types: replay, impersonation, speech synthesis, and voice conversion.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1. </span>Replay</h4>
<div class="ltx_para" id="S5.SS1.SSS1.p1">
<p class="ltx_p" id="S5.SS1.SSS1.p1.1">A replay attack involves recording a victim’s voice using a recording device and then replaying this captured audio to deceive the SV system. This method is straightforward yet highly effective, posing a significant threat to various SV systems due to its simplicity and reliability. The effectiveness of replay attacks has been demonstrated against many types of SV systems <cite class="ltx_cite ltx_citemacro_citep">(Lindberg and
Blomberg, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib89" title="">1999</a>; Villalba and
Lleida, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib149" title="">2010</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib150" title="">2011a</a>; Yoon
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib180" title="">2020</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2. </span>Impersonation</h4>
<div class="ltx_para" id="S5.SS1.SSS2.p1">
<p class="ltx_p" id="S5.SS1.SSS2.p1.1">Impersonation attacks are executed by an attacker manually mimicking the voice patterns and speech behavior of the target individual, without the aid of any computerized devices. These attacks aim to trick the SV component into falsely recognizing the attacker as the target. Research has indicated that even non-professional impersonators can be successful, particularly if they are familiar with the target’s voice pattern or possess a naturally similar voice <cite class="ltx_cite ltx_citemacro_citep">(Lau
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib80" title="">2005</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib81" title="">2004</a>)</cite>. Professional impersonators often try to replicate rhythmic features of the target’s speech to enhance the deception <cite class="ltx_cite ltx_citemacro_citep">(Farrús et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib43" title="">2008</a>)</cite>. However, it has been observed that significant differences between the impersonator’s and the target’s natural voice can still be detected by SV systems <cite class="ltx_cite ltx_citemacro_citep">(Hautamäki et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib61" title="">2013</a>; Mariéthoz and
Bengio, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib93" title="">2005</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3. </span>Speech Synthesis</h4>
<div class="ltx_para" id="S5.SS1.SSS3.p1">
<p class="ltx_p" id="S5.SS1.SSS3.p1.1">Speech Synthesis (SS) is a technology that aims to generate speech resembling the victim’s voice from input text, distinct from standard text-to-speech (TTS) applications. The goal is to deceive the SV component by impersonating the victim. Traditional SS techniques include unit selection <cite class="ltx_cite ltx_citemacro_citep">(Hunt and Black, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib63" title="">1996</a>)</cite>, statistical parametric modeling <cite class="ltx_cite ltx_citemacro_citep">(Zen
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib186" title="">2009</a>)</cite>, and hybrid approaches combining both <cite class="ltx_cite ltx_citemacro_citep">(Qian
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib109" title="">2012</a>)</cite>. Advancements in deep learning have led to the use of neural networks in SS, such as Generative Adversarial Networks (GAN) for enhancing speech quality <cite class="ltx_cite ltx_citemacro_citep">(Bińkowski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib15" title="">2019</a>; Pascual
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib104" title="">2017</a>; Saito
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib120" title="">2017</a>)</cite>, and specific models like WaveNet <cite class="ltx_cite ltx_citemacro_citep">(Oord
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib103" title="">2018</a>; van den Oord
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib148" title="">2016</a>)</cite> and Tacotron <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib162" title="">2017a</a>)</cite> for victim-specific speech generation.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.4. </span>Voice Conversion</h4>
<div class="ltx_para" id="S5.SS1.SSS4.p1">
<p class="ltx_p" id="S5.SS1.SSS4.p1.1">Voice Conversion (VC) differs from SS as it transforms the attacker’s speech to match the victim’s speech patterns. Traditional VC methods used statistical models like Hidden Markov Models (HMM) <cite class="ltx_cite ltx_citemacro_citep">(Kim et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib74" title="">1997</a>)</cite>, Gaussian Mixture Models (GMM) <cite class="ltx_cite ltx_citemacro_citep">(Stylianou
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib136" title="">1998</a>)</cite>, Principal Component Analysis (PCA) <cite class="ltx_cite ltx_citemacro_citep">(Wilde and
Martinez, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib165" title="">2004</a>)</cite>, and Non-negative Matrix Factorization (NMF) <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib195" title="">2015</a>)</cite>. Modern approaches leverage neural networks, including Artificial Neural Networks (ANN) <cite class="ltx_cite ltx_citemacro_citep">(Desai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib37" title="">2009</a>)</cite>, WaveNet, and GANs. Recent research has focused on challenges such as low-resource languages <cite class="ltx_cite ltx_citemacro_citep">(Ghorbandoost et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib46" title="">2015</a>; Jannati and
Sayadiyan, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib66" title="">2018</a>)</cite> and cross-lingual voice conversion <cite class="ltx_cite ltx_citemacro_citep">(Wahlster, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib152" title="">2013</a>; Zhou
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib200" title="">2019b</a>)</cite>. Innovative techniques involving specially designed tubes have been explored to bypass liveness detection systems by modifying the attacker’s voice to resemble the victim’s <cite class="ltx_cite ltx_citemacro_citep">(Ahmed et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib8" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.5. </span>Twins</h4>
<div class="ltx_para" id="S5.SS1.SSS5.p1">
<p class="ltx_p" id="S5.SS1.SSS5.p1.1">Identical twins present a unique challenge in SV due to their highly similar speech characteristics. While SV systems are generally effective in distinguishing between different individuals, they struggle to differentiate between identical twins. Studies have indicated that twins share similar speech signal patterns, pitch contours, formant contours, and spectrograms <cite class="ltx_cite ltx_citemacro_citep">(Patil and Parhi, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib106" title="">2009</a>; Kersta and
Colangelo, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib72" title="">1970</a>)</cite>, leading to higher False Acceptance Rates (FAR) in SV. Incidents have been reported where twins were able to access each other’s accounts by bypassing SV checks <cite class="ltx_cite ltx_citemacro_citep">(BBC, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib14" title="">2017</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS6">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.6. </span>Defense Schemes against Spoofing Attacks.</h4>
<div class="ltx_para" id="S5.SS1.SSS6.p1">
<p class="ltx_p" id="S5.SS1.SSS6.p1.1">Defense strategies against spoofing attacks in VCS primarily focus on identifying distortions in audio signals during transcription.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS6.p2">
<p class="ltx_p" id="S5.SS1.SSS6.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS6.p2.1.1">For Replay Attacks:</span> Techniques have been developed to distinguish between original and replayed audio by analyzing far-field recordings characteristic of distant attacks <cite class="ltx_cite ltx_citemacro_citep">(Villalba and
Lleida, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib150" title="">2011a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib151" title="">b</a>)</cite>. Another approach involves maintaining a database of previous audio recordings in VCS and calculating similarity scores for new inputs to detect replays <cite class="ltx_cite ltx_citemacro_citep">(Shang and
Stevenson, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib130" title="">2010</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS6.p3">
<p class="ltx_p" id="S5.SS1.SSS6.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS6.p3.1.1">For Speech Synthesis (SS):</span> Traditional SS detection methods often rely on understanding acoustic differences based on specific SS algorithms, such as analyzing spectral parameter ranges <cite class="ltx_cite ltx_citemacro_citep">(Satoh
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib121" title="">2001</a>)</cite> and variations in mel-cepstral coefficients <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib23" title="">2010</a>)</cite>. Differences in pitch patterns and vocal tract models between human and synthesized audio offer additional detection markers <cite class="ltx_cite ltx_citemacro_citep">(Ogihara
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib102" title="">2005</a>; De Leon
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib35" title="">2012b</a>; De Leon et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib34" title="">2012a</a>; Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib168" title="">2012a</a>; Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib169" title="">2012b</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS6.p4">
<p class="ltx_p" id="S5.SS1.SSS6.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS6.p4.1.1">For Voice Conversion (VC):</span> Defenses against VC attacks draw inspiration from SS defense strategies, with studies showing that SVM classifiers based on super-vectors demonstrate inherent robustness against VC <cite class="ltx_cite ltx_citemacro_citep">(Alegre
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib10" title="">2012</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib9" title="">2013</a>)</cite>. Analyzing pairwise distances between continuous feature vectors in human versus VC-generated audio has also proven effective.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS6.p5">
<p class="ltx_p" id="S5.SS1.SSS6.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS6.p5.1.1">Machine Learning-based Approaches:</span> State-of-the-art methods involve using machine learning models to discern spectral differences between human and generated audio <cite class="ltx_cite ltx_citemacro_citep">(Gong
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib51" title="">2020</a>; Jelil
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib67" title="">2018</a>; Kamble
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib69" title="">2018</a>; Patil
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib105" title="">2019</a>; Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib159" title="">2017b</a>; Witkowski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib166" title="">2017</a>)</cite>. The ASVspoof challenges have been instrumental in driving advancements in anti-spoofing technology, with RawNet2 emerging as a successful model in this domain <cite class="ltx_cite ltx_citemacro_citep">(Tak et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib141" title="">2021</a>; Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib170" title="">2015</a>; Kinnunen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib75" title="">2017</a>; Todisco et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib144" title="">2019</a>; Yamagishi
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib173" title="">2021</a>)</cite>. Additionally, research combining articulatory phonetics to reconstruct vocal tracts from audio signals has shown promise in distinguishing between human and machine sources <cite class="ltx_cite ltx_citemacro_citep">(Blue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib18" title="">2022</a>)</cite>. A novel approach proposed in <cite class="ltx_cite ltx_citemacro_citep">(Deng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib36" title="">2023</a>)</cite> shifts focus from preemptively rejecting VC-generated audio to reconstructing the source speaker’s voiceprint for attacker identification.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Adversarial Attacks in Kernel Layer</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The kernel layer of VCS, much like the preprocessing layer, is vulnerable to adversarial attacks. However, the attack methodology in the kernel layer typically involves directly adding adversarial perturbations to the audio waveforms of legitimate audio samples. This direct manipulation of audio waveforms distinguishes these attacks from those in the preprocessing layer. Adversarial attacks in the kernel layer pose a significant challenge to audio classifiers, often leading to misclassifications and subsequent security breaches. A detailed summary and comparative analysis of recent advancements in adversarial attacks targeting the kernel layer can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S5.T4" title="Table 4 ‣ 5.2.2. Defense Schemes against Adversarial Attacks. ‣ 5.2. Adversarial Attacks in Kernel Layer ‣ 5. Kernel Layer ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_tag">4</span></a>. This table provides insights into the various techniques and strategies employed in these attacks, underlining their potential impact on VCS performance and security.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1. </span>Adversarial Examples Crafting</h4>
<div class="ltx_para" id="S5.SS2.SSS1.p1">
<p class="ltx_p" id="S5.SS2.SSS1.p1.1">In the kernel layer of VCS, the shift towards black-box models has made traditional gradient-based adversarial sample generation methods like Gradient Descent (GD) and Fast Gradient Sign Method (FGSM) less effective. To address this, researchers have developed gradient-agnostic algorithms for crafting adversarial examples.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.p2">
<p class="ltx_p" id="S5.SS2.SSS1.p2.1"><em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p2.1.1">Genetic Algorithm (GA).</em> GA employs a search-based approach, iterating through potential samples to deceive machine learning models. By using techniques like crossover and mutation, GA refines search results, prioritizing samples with higher fitness scores for subsequent iterations. This method is suitable for gray-box or black-box attacks due to its reliance solely on model output rather than gradient information <cite class="ltx_cite ltx_citemacro_citep">(Taori
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib143" title="">2019</a>; Han et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib59" title="">2019</a>; Khare
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib73" title="">2019</a>; Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib167" title="">2019</a>; Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib156" title="">2020d</a>)</cite>. However, GA’s iterative nature leads to high computational resource demands.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.p3">
<p class="ltx_p" id="S5.SS2.SSS1.p3.1"><em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p3.1.1">Particle Swarm Optimization (PSO).</em> Originating from swarm intelligence, PSO mimics collective animal behaviors to search for optimal solutions <cite class="ltx_cite ltx_citemacro_citep">(Kennedy and
Eberhart, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib71" title="">1995</a>)</cite>. In adversarial example generation, samples are treated as swarm particles, moving towards the most effective position in the search space iteratively <cite class="ltx_cite ltx_citemacro_citep">(Du
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib39" title="">2020</a>)</cite>. PSO benefits from fast convergence and does not require gradient information, making it efficient for gray-box and black-box attacks.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.p4">
<p class="ltx_p" id="S5.SS2.SSS1.p4.1"><em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p4.1.1">Ensemble Algorithm.</em> Chen et al. <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib22" title="">2021</a>)</cite> introduced a novel black-box approach combining the Natural Evolution Strategy (NES) <cite class="ltx_cite ltx_citemacro_citep">(Wierstra et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib164" title="">2014</a>)</cite> and the Basic Iterative Method (BIM) <cite class="ltx_cite ltx_citemacro_citep">(Kurakin
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib78" title="">2018</a>)</cite>. NES estimates the gradient of the black-box model, and this estimated gradient is then used in BIM to generate adversarial examples iteratively. This method efficiently crafts adversarial examples suitable for black-box settings.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.p5">
<p class="ltx_p" id="S5.SS2.SSS1.p5.1"><em class="ltx_emph ltx_font_italic" id="S5.SS2.SSS1.p5.1.1">Deep Learning-based Methods.</em> Approaches like the Gated Convolutional Auto-encoder (GCA) <cite class="ltx_cite ltx_citemacro_citep">(Shamsabadi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib125" title="">2021</a>)</cite>, Adversarial Transformation Network (ATN) <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib84" title="">2021</a>)</cite>, and Generative Network (GN) <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib83" title="">2020c</a>)</cite> employ deep learning for adversarial example generation. GN is effective in gray-box model attacks, while ATN significantly reduces the time required to generate adversarial examples.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2. </span>Defense Schemes against Adversarial Attacks.</h4>
<div class="ltx_para" id="S5.SS2.SSS2.p1">
<p class="ltx_p" id="S5.SS2.SSS2.p1.1">While the defense methods used in the preprocessing layer of VCS are also applicable to the kernel layer, the nature of attacks targeting the kernel layer demands additional strategies. Since these attacks are typically directed at the model itself, the transferability of adversarial examples between different models tends to be limited. Zeng et al. <cite class="ltx_cite ltx_citemacro_citep">(Zeng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib187" title="">2019</a>)</cite> observed that adversarial examples crafted for one specific model often yield different prediction results when applied to another model, a discrepancy not seen with normal audio signals. This unique behavior of adversarial examples provides a basis for detecting and countering attacks in the kernel layer. By exploiting the differences in model responses to adversarial versus normal audio, defense mechanisms can be designed to effectively identify and mitigate adversarial attacks targeting this crucial layer of VCS.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 4. </span>Comparison of voice-synthesis attacks and adversarial attacks in kernel layer</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S5.T4.3">
<tr class="ltx_tr" id="S5.T4.3.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.1.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.1.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.1.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.1.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Attack</span></span>
<span class="ltx_tr" id="S5.T4.3.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.1.1.2.1.2.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Type</span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.1.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.1.2" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.1.2.1" style="font-size:70%;">Paper</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.1.3" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.1.3.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.1.3.1.1"></span> <span class="ltx_text" id="S5.T4.3.1.3.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.1.3.1.2.1">
<span class="ltx_tr" id="S5.T4.3.1.3.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.3.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Attack</span></span>
<span class="ltx_tr" id="S5.T4.3.1.3.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.3.1.2.1.2.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Method</span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.1.3.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.1.4" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.1.4.1" style="font-size:70%;">Goal</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.1.5" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.1.5.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.1.5.1.1"></span> <span class="ltx_text" id="S5.T4.3.1.5.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.1.5.1.2.1">
<span class="ltx_tr" id="S5.T4.3.1.5.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.5.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Attack Target</span></span>
<span class="ltx_tr" id="S5.T4.3.1.5.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.5.1.2.1.2.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">(Category)</span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.1.5.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.1.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.1.6.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.1.6.1.1"></span> <span class="ltx_text" id="S5.T4.3.1.6.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.1.6.1.2.1">
<span class="ltx_tr" id="S5.T4.3.1.6.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.6.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Model</span></span>
<span class="ltx_tr" id="S5.T4.3.1.6.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.6.1.2.1.2.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Knowledge</span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.1.6.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.1.7" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.1.7.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.1.7.1.1"></span> <span class="ltx_text" id="S5.T4.3.1.7.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.1.7.1.2.1">
<span class="ltx_tr" id="S5.T4.3.1.7.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.7.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Attack</span></span>
<span class="ltx_tr" id="S5.T4.3.1.7.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.7.1.2.1.2.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Vector</span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.1.7.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.1.8" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.1.8.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.1.8.1.1"></span> <span class="ltx_text" id="S5.T4.3.1.8.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.1.8.1.2.1">
<span class="ltx_tr" id="S5.T4.3.1.8.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.8.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Cost</span></span>
<span class="ltx_tr" id="S5.T4.3.1.8.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.1.8.1.2.1.2.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">(Time)</span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.1.8.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T4.3.1.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.1.9.1" style="font-size:70%;">Performance</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.2.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.2.1.1" style="font-size:70%;">Success</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.2.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.2.2.1" style="font-size:70%;">Distance</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.3">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.3.3.1" rowspan="60" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.3.1.1" style="font-size:70%;">
<span class="ltx_inline-block ltx_transformed_outer" id="S5.T4.3.3.1.1.1" style="width:4.9pt;height:60.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:60.6pt;transform:translate(-27.86pt,-27.86pt) rotate(-90deg) ;">
<span class="ltx_p" id="S5.T4.3.3.1.1.1.1">Adversarial Attacks</span>
</span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.3.2" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.3.2.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.3.2.1.1"></span> <span class="ltx_text" id="S5.T4.3.3.2.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.3.2.1.2.1">
<span class="ltx_tr" id="S5.T4.3.3.2.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.3.2.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Yuan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib184" title="">2018b</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.3.2.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.3.3" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.3.3.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.3.4" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.3.4.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.3.5" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.3.5.1" style="font-size:70%;">Kaldi (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.3.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.3.6.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.3.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.3.7.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.3.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.3.8.1" style="font-size:70%;">&lt;1.9h</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.3.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.3.9.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.3.10" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.3.10.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.4">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.4.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.4.1.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.4.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.4.2.1" style="font-size:70%;">&lt;2h</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.4.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.4.3.1" style="font-size:70%;">96%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.4.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.4.4.1" style="font-size:70%;">1.5m</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.5">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.5.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.5.1.1" style="font-size:70%;">iFLYTEK (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.5.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.5.2.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.5.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.5.3.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.5.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.5.4.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.5.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.5.5.1" style="font-size:70%;">66%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.5.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.5.6.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.6">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.6.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.6.1.1"></span><span class="ltx_text" id="S5.T4.3.6.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.6.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.6.1.3.1">
<span class="ltx_tr" id="S5.T4.3.6.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.6.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Schönherr et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib124" title="">2019</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.6.1.4"></span><span class="ltx_text" id="S5.T4.3.6.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.6.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.6.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.6.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.6.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.6.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.6.4.1" style="font-size:70%;">Kaldi (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.6.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.6.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.6.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.6.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.6.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.6.7.1" style="font-size:70%;">2min</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.6.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.6.8.1" style="font-size:70%;">98%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.6.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.6.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.7">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.7.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.7.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.7.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.7.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.7.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.7.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.7.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Qin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib110" title="">2019</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.7.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.7.2" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.7.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.7.3" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.7.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.7.4" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.7.4.1" style="font-size:70%;">Lingvo (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.7.5" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.7.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.7.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.7.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.7.7" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.7.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.7.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.7.8.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.7.9" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.7.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.8">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.8.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.8.1.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.8.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.8.2.1" style="font-size:70%;">60%</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.9">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.9.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.9.1.1"></span><span class="ltx_text" id="S5.T4.3.9.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.9.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.9.1.3.1">
<span class="ltx_tr" id="S5.T4.3.9.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.9.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Taori
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib143" title="">2019</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.9.1.4"></span><span class="ltx_text" id="S5.T4.3.9.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.9.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.9.2.1" style="font-size:70%;">GD+GA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.9.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.9.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.9.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.9.4.1" style="font-size:70%;">DeepSpeech (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.9.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.9.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.9.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.9.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.9.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.9.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.9.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.9.8.1" style="font-size:70%;">35%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.9.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.9.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.10">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.10.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.10.1.1"></span><span class="ltx_text" id="S5.T4.3.10.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.10.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.10.1.3.1">
<span class="ltx_tr" id="S5.T4.3.10.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.10.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Neekhara et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib101" title="">2019</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.10.1.4"></span><span class="ltx_text" id="S5.T4.3.10.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.10.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.10.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.10.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.10.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.10.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.10.4.1" style="font-size:70%;">2 model (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.10.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.10.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.10.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.10.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.10.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.10.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.10.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.10.8.1" style="font-size:70%;">89.6%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.10.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.10.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.11">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.11.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.11.1.1"></span><span class="ltx_text" id="S5.T4.3.11.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.11.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.11.1.3.1">
<span class="ltx_tr" id="S5.T4.3.11.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.11.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Kwon
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib79" title="">2019</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.11.1.4"></span><span class="ltx_text" id="S5.T4.3.11.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.11.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.11.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.11.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.11.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.11.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.11.4.1" style="font-size:70%;">DeepSpeech (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.11.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.11.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.11.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.11.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.11.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.11.7.1" style="font-size:70%;">1h</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.11.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.11.8.1" style="font-size:70%;">91.7%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.11.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.11.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.12">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.12.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.12.1.1"></span><span class="ltx_text" id="S5.T4.3.12.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.12.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.12.1.3.1">
<span class="ltx_tr" id="S5.T4.3.12.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.12.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib82" title="">2019</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.12.1.4"></span><span class="ltx_text" id="S5.T4.3.12.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.12.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.12.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.12.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.12.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.12.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.12.4.1" style="font-size:70%;">Amazon Alexa (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.12.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.12.5.1" style="font-size:70%;">Gray</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.12.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.12.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.12.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.12.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.12.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.12.8.1" style="font-size:70%;">50%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.12.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.12.9.1" style="font-size:70%;">7.7ft</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.13">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.13.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.13.1.1"></span><span class="ltx_text" id="S5.T4.3.13.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.13.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.13.1.3.1">
<span class="ltx_tr" id="S5.T4.3.13.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.13.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Gong
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib48" title="">2019a</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.13.1.4"></span><span class="ltx_text" id="S5.T4.3.13.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.13.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.13.2.1" style="font-size:70%;">RL+RNN</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.13.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.13.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.13.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.13.4.1" style="font-size:70%;">KWS (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.13.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.13.5.1" style="font-size:70%;">Gray</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.13.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.13.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.13.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.13.7.1" style="font-size:70%;">0.15s</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.13.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.13.8.1" style="font-size:70%;">43.5%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.13.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.13.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.14">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.14.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.14.1.1"></span><span class="ltx_text" id="S5.T4.3.14.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.14.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.14.1.3.1">
<span class="ltx_tr" id="S5.T4.3.14.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.14.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib91" title="">2020</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.14.1.4"></span><span class="ltx_text" id="S5.T4.3.14.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.14.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.14.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.14.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.14.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.14.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.14.4.1" style="font-size:70%;">DeepSpeech (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.14.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.14.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.14.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.14.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.14.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.14.7.1" style="font-size:70%;">4-5min</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.14.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.14.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.14.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.14.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.15">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.15.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.15.1.1"></span><span class="ltx_text" id="S5.T4.3.15.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.15.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.15.1.3.1">
<span class="ltx_tr" id="S5.T4.3.15.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.15.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Schönherr et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib122" title="">2020</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.15.1.4"></span><span class="ltx_text" id="S5.T4.3.15.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.15.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.15.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.15.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.15.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.15.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.15.4.1" style="font-size:70%;">Kaldi (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.15.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.15.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.15.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.15.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.15.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.15.7.1" style="font-size:70%;">80min</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.15.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.15.8.1" style="font-size:70%;">25%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.15.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.15.9.1" style="font-size:70%;">3m</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.16">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.16.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.16.1.1"></span><span class="ltx_text" id="S5.T4.3.16.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.16.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.16.1.3.1">
<span class="ltx_tr" id="S5.T4.3.16.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.16.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Szurley and
Kolter, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib140" title="">2019</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.16.1.4"></span><span class="ltx_text" id="S5.T4.3.16.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.16.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.16.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.16.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.16.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.16.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.16.4.1" style="font-size:70%;">DeepSpeech (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.16.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.16.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.16.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.16.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.16.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.16.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.16.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.16.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.16.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.16.9.1" style="font-size:70%;">6 in</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.17">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.17.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.17.1.1"></span><span class="ltx_text" id="S5.T4.3.17.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.17.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.17.1.3.1">
<span class="ltx_tr" id="S5.T4.3.17.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.17.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Han et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib59" title="">2019</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.17.1.4"></span><span class="ltx_text" id="S5.T4.3.17.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.17.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.17.2.1" style="font-size:70%;">GA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.17.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.17.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.17.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.17.4.1" style="font-size:70%;">Google Cloud (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.17.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.17.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.17.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.17.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.17.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.17.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.17.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.17.8.1" style="font-size:70%;">86%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.17.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.17.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.18">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.18.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.18.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.18.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.18.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.18.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.18.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.18.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Khare
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib73" title="">2019</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.18.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.18.2" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.18.2.1" style="font-size:70%;">GA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.18.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.18.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.18.4" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.18.4.1" style="font-size:70%;">2 models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.18.5" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.18.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.18.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.18.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.18.7" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.18.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.18.8" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.18.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.18.9" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.18.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.19">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.19.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.19.1.1" style="font-size:70%;">Targeted</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.20">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.20.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.20.1.1"></span><span class="ltx_text" id="S5.T4.3.20.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.20.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.20.1.3.1">
<span class="ltx_tr" id="S5.T4.3.20.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.20.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib167" title="">2019</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.20.1.4"></span><span class="ltx_text" id="S5.T4.3.20.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.20.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.20.2.1" style="font-size:70%;">GA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.20.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.20.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.20.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.20.4.1" style="font-size:70%;">Kaldi (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.20.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.20.5.1" style="font-size:70%;">Gray</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.20.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.20.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.20.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.20.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.20.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.20.8.1" style="font-size:70%;">90%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.20.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.20.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.21">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.21.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.21.1.1"></span><span class="ltx_text" id="S5.T4.3.21.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.21.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.21.1.3.1">
<span class="ltx_tr" id="S5.T4.3.21.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.21.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib47" title="">2019b</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.21.1.4"></span><span class="ltx_text" id="S5.T4.3.21.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.21.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.21.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.21.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.21.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.21.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.21.4.1" style="font-size:70%;">2 models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.21.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.21.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.21.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.21.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.21.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.21.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.21.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.21.8.1" style="font-size:70%;">78%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.21.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.21.9.1" style="font-size:70%;">30cm</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.22">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.22.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.22.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.22.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.22.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.22.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.22.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.22.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib26" title="">2020b</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.22.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.22.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.22.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.22.3" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.22.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.22.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.22.4.1" style="font-size:70%;">4 models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.22.5" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.22.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.22.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.22.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.22.7" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.22.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.22.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.22.8.1" style="font-size:70%;">98%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.22.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.22.9.1" style="font-size:70%;">2m</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.23">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.23.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.23.1.1" style="font-size:70%;">Transfer</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.23.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.23.2.1" style="font-size:70%;">Apple Siri (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.23.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.23.3.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.23.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.23.4.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.24">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.24.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.24.1.1"></span><span class="ltx_text" id="S5.T4.3.24.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.24.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.24.1.3.1">
<span class="ltx_tr" id="S5.T4.3.24.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.24.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib25" title="">2020a</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.24.1.4"></span><span class="ltx_text" id="S5.T4.3.24.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.24.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.24.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.24.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.24.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.24.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.24.4.1" style="font-size:70%;">DeepSpeech (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.24.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.24.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.24.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.24.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.24.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.24.7.1" style="font-size:70%;">5-7h</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.24.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.24.8.1" style="font-size:70%;">90%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.24.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.24.9.1" style="font-size:70%;">6m</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.25">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.25.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.25.1.1"></span><span class="ltx_text" id="S5.T4.3.25.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.25.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.25.1.3.1">
<span class="ltx_tr" id="S5.T4.3.25.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.25.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib153" title="">2020b</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.25.1.4"></span><span class="ltx_text" id="S5.T4.3.25.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.25.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.25.2.1" style="font-size:70%;">GAN</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.25.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.25.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.25.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.25.4.1" style="font-size:70%;">2 models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.25.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.25.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.25.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.25.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.25.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.25.7.1" style="font-size:70%;">0.009s</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.25.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.25.8.1" style="font-size:70%;">92.33%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.25.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.25.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.26">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.26.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.26.1.1"></span><span class="ltx_text" id="S5.T4.3.26.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.26.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.26.1.3.1">
<span class="ltx_tr" id="S5.T4.3.26.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.26.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib156" title="">2020d</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.26.1.4"></span><span class="ltx_text" id="S5.T4.3.26.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.26.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.26.2.1" style="font-size:70%;">GA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.26.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.26.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.26.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.26.4.1" style="font-size:70%;">DeepSpeech (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.26.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.26.5.1" style="font-size:70%;">Gray</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.26.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.26.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.26.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.26.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.26.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.26.8.1" style="font-size:70%;">98%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.26.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.26.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.27">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.27.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.27.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.27.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.27.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.27.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.27.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.27.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib88" title="">2020b</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.27.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.27.2" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.27.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.27.3" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.27.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.27.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.27.4.1" style="font-size:70%;">KWS (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.27.5" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.27.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.27.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.27.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.27.7" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.27.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.27.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.27.8.1" style="font-size:70%;">89.9%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.27.9" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.27.9.1" style="font-size:70%;">3m</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.28">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.28.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.28.1.1" style="font-size:70%;">DNN x-vector (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.28.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.28.2.1" style="font-size:70%;">89.3%</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.29">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.29.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.29.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.29.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.29.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.29.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.29.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.29.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Abdullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib5" title="">2021a</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.29.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.29.2" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.29.2.1" style="font-size:70%;">SP</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.29.3" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.29.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.29.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.29.4.1" style="font-size:70%;">7models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.29.5" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.29.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.29.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.29.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.29.7" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.29.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.29.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.29.8.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.29.9" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.29.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.30">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.30.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.30.1.1" style="font-size:70%;">Microsoft Azure (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.30.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.30.2.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.31">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.31.1" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.31.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.31.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.31.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.31.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.31.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.31.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Du
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib39" title="">2020</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.31.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.31.2" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.31.2.1" style="font-size:70%;">PSO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.31.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.31.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.31.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.31.4.1" style="font-size:70%;">DeepSpeech (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.31.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.31.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.31.6" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.31.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.31.7" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.31.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.31.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.31.8.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.31.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.31.9.1" style="font-size:70%;">1201.7s</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.32">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.32.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.32.1.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.32.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.32.2.1" style="font-size:70%;">7models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.32.3" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.32.3.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.32.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.32.4.1" style="font-size:70%;">95.25%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.32.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.32.5.1" style="font-size:70%;">100.7s</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.33">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.33.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.33.1.1" style="font-size:70%;">7models (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.33.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.33.2.1" style="font-size:70%;">99.45%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.33.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.33.3.1" style="font-size:70%;">376.4s</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.34">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.34.1" rowspan="5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.34.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.34.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.34.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.34.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.34.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.34.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib22" title="">2021</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.34.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.34.2" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.34.2.1" style="font-size:70%;">NES+BIM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.34.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.34.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.34.4" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.34.4.1" style="font-size:70%;">3 models (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.34.5" rowspan="5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.34.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.34.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.34.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.34.7" rowspan="5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.34.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.34.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.34.8.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.34.9" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.34.9.1" style="font-size:70%;">2m</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.35">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.35.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.35.1.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.35.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.35.2.1" style="font-size:70%;">95%</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.36">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.36.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.36.1.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.36.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.36.2.1" style="font-size:70%;">Talentedsoft (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.36.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.36.3.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.36.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.36.4.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.36.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.36.5.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.37">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.37.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.37.1.1" style="font-size:70%;">Transfer</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.37.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.37.2.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.37.3" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.37.3.1" style="font-size:70%;">Microsoft Azure (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.37.4" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.37.4.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.37.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.37.5.1" style="font-size:70%;">57%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.37.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.37.6.1" style="font-size:70%;">2m</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.38">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.38.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.38.1.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.38.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.38.2.1" style="font-size:70%;">34%</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.39">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.39.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.39.1.1"></span><span class="ltx_text" id="S5.T4.3.39.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.39.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.39.1.3.1">
<span class="ltx_tr" id="S5.T4.3.39.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.39.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib158" title="">2019b</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.39.1.4"></span><span class="ltx_text" id="S5.T4.3.39.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.39.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.39.2.1" style="font-size:70%;">FGSM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.39.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.39.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.39.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.39.4.1" style="font-size:70%;">GE2E (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.39.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.39.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.39.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.39.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.39.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.39.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.39.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.39.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.39.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.39.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.40">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.40.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.40.1.1"></span><span class="ltx_text" id="S5.T4.3.40.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.40.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.40.1.3.1">
<span class="ltx_tr" id="S5.T4.3.40.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.40.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Xie
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib171" title="">2020</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.40.1.4"></span><span class="ltx_text" id="S5.T4.3.40.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.40.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.40.2.1" style="font-size:70%;">SP</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.40.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.40.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.40.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.40.4.1" style="font-size:70%;">DNN x-vector (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.40.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.40.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.40.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.40.6.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.40.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.40.7.1" style="font-size:70%;">0.015s</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.40.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.40.8.1" style="font-size:70%;">90%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.40.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.40.9.1" style="font-size:70%;">5m</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.41">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.41.1" rowspan="4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.41.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.41.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.41.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.41.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.41.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.41.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib87" title="">2020a</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.41.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.41.2" rowspan="4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.41.2.1" style="font-size:70%;">FGSM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.41.3" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.41.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.41.4" rowspan="4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.41.4.1" style="font-size:70%;">DNN x-vector (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.41.5" rowspan="4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.41.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.41.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.41.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.41.7" rowspan="4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.41.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.41.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.41.8.1" style="font-size:70%;">99%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.41.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.41.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.42">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.42.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.42.1.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.42.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.42.2.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.42.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.42.3.1" style="font-size:70%;">1m</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.43">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.43.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.43.1.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.43.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.43.2.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.43.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.43.3.1" style="font-size:70%;">96.01%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.43.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.43.4.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.44">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.44.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.44.1.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.44.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.44.2.1" style="font-size:70%;">50%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.44.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.44.3.1" style="font-size:70%;">1m</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.45">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.45.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.45.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.45.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.45.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.45.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.45.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.45.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib83" title="">2020c</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.45.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.45.2" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.45.2.1" style="font-size:70%;">GN</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.45.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.45.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.45.4" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.45.4.1" style="font-size:70%;">SineNet (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.45.5" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.45.5.1" style="font-size:70%;">Gray</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.45.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.45.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.45.7" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.45.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.45.8" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.45.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.45.9" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.45.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.46">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.46.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.46.1.1" style="font-size:70%;">Targeted</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.47">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.47.1" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.47.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.47.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.47.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.47.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.47.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.47.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib191" title="">2020a</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.47.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.47.2" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.47.2.1" style="font-size:70%;">GD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.47.3" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.47.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.47.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.47.4.1" style="font-size:70%;">VGGVox (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.47.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.47.5.1" style="font-size:70%;">Gray</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.47.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.47.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.47.7" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.47.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.47.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.47.8.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.47.9" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.47.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.48">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.48.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.48.1.1" style="font-size:70%;">Microsoft Azure (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.48.2" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.48.2.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.48.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.48.3.1" style="font-size:70%;">75%</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.49">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.49.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.49.1.1" style="font-size:70%;">Transfer</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.49.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.49.2.1" style="font-size:70%;">Apple Homekit (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.49.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.49.3.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.49.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.49.4.1" style="font-size:70%;">67.5%</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.50">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.50.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.50.1.1"></span><span class="ltx_text" id="S5.T4.3.50.1.2" style="font-size:70%;"> </span><span class="ltx_text" id="S5.T4.3.50.1.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.50.1.3.1">
<span class="ltx_tr" id="S5.T4.3.50.1.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.50.1.3.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib84" title="">2021</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S5.T4.3.50.1.4"></span><span class="ltx_text" id="S5.T4.3.50.1.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.50.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.50.2.1" style="font-size:70%;">ATN</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.50.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.50.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.50.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.50.4.1" style="font-size:70%;">SineNet (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.50.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.50.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.50.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.50.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.50.7" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.50.7.1" style="font-size:70%;">0.042RTF</span><sup class="ltx_sup" id="S5.T4.3.50.7.2"><span class="ltx_text" id="S5.T4.3.50.7.2.1" style="font-size:70%;">1</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.50.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.50.8.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.50.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.50.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.51">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.51.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.51.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.51.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.51.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.51.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.51.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.51.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Shamsabadi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib125" title="">2021</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.51.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.51.2" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.51.2.1" style="font-size:70%;">GCA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.51.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.51.3.1" style="font-size:70%;">Untargeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.51.4" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.51.4.1" style="font-size:70%;">DNN x-vector (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.51.5" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.51.5.1" style="font-size:70%;">White</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.51.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.51.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.51.7" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.51.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.51.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.51.8.1" style="font-size:70%;">99.6%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.51.9" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.51.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.52">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.52.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.52.1.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.52.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.52.2.1" style="font-size:70%;">99.2%</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.53">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.53.1" rowspan="4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.53.1.1" style="font-size:70%;"><span class="ltx_text" id="S5.T4.3.53.1.1.1"></span> <span class="ltx_text" id="S5.T4.3.53.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.3.53.1.1.2.1">
<span class="ltx_tr" id="S5.T4.3.53.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.3.53.1.1.2.1.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"> <cite class="ltx_cite ltx_citemacro_citep">(Yu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib182" title="">2023</a>)</cite></span></span>
</span></span> <span class="ltx_text" id="S5.T4.3.53.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.53.2" rowspan="4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.53.2.1" style="font-size:70%;">GA + GE</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.53.3" rowspan="4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.53.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.53.4" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.53.4.1" style="font-size:70%;">5 models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.53.5" rowspan="4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.53.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.53.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.53.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.53.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.53.7.1" style="font-size:70%;">474s</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.53.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.53.8.1" style="font-size:70%;">87.7%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.53.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.53.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.54">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.54.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.54.1.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.54.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.54.2.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.54.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.54.3.1" style="font-size:70%;">43.3%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.54.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.54.4.1" style="font-size:70%;">200cm</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.55">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.55.1" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.55.1.1" style="font-size:70%;">2 models (SV)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.55.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.55.2.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.55.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.55.3.1" style="font-size:70%;">525s</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.55.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.55.4.1" style="font-size:70%;">99.2%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.55.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.55.5.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.56">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.56.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.56.1.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.56.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.56.2.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.56.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.56.3.1" style="font-size:70%;">35.8%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.56.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.56.4.1" style="font-size:70%;">200cm</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.57">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.57.1" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.57.1.1" style="font-size:70%;"> <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib198" title="">2021</a>)</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.57.2" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.57.2.1" style="font-size:70%;">CC-CMA-ES</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.57.3" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.57.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.57.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.57.4.1" style="font-size:70%;">5 models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.57.5" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.57.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.57.6" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.57.6.1" style="font-size:70%;">WTA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.57.7" rowspan="3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.57.7.1" style="font-size:70%;">n.a</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.57.8" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.57.8.1" style="font-size:70%;">100%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.57.9" rowspan="2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.57.9.1" style="font-size:70%;">n.a</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.58">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.58.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.58.1.1" style="font-size:70%;">2 models (SV)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.59">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.59.1" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.59.1.1" style="font-size:70%;">DNN</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.59.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.59.2.1" style="font-size:70%;">5 models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.59.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.59.3.1" style="font-size:70%;">WAA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.3.59.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.59.4.1" style="font-size:70%;">60%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.59.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.59.5.1" style="font-size:70%;">15cm</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.3.60">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.3.60.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_text" id="S5.T4.3.60.1.1" style="font-size:70%;"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S5.T4.3.60.1.2.1" style="font-size:70%;">(</span>Liu et al<span class="ltx_text">.</span><span class="ltx_text" id="S5.T4.3.60.1.3.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib90" title="">2022</a><span class="ltx_text" id="S5.T4.3.60.1.4.3" style="font-size:70%;">)</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.3.60.2" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.60.2.1" style="font-size:70%;">GE</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.3.60.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.60.3.1" style="font-size:70%;">Targeted</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.3.60.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.60.4.1" style="font-size:70%;">4 models (ASR)</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.3.60.5" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.60.5.1" style="font-size:70%;">Black</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.3.60.6" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.60.6.1" style="font-size:70%;">WNA</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.3.60.7" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.60.7.1" style="font-size:70%;">362.18s</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T4.3.60.8" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.60.8.1" style="font-size:70%;">87.7%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T4.3.60.9" style="padding-top:1.25pt;padding-bottom:1.25pt;"><span class="ltx_text" id="S5.T4.3.60.9.1" style="font-size:70%;">n.a</span></td>
</tr>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S5.I1">
<li class="ltx_item" id="S5.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1</span>
<div class="ltx_para" id="S5.I1.ix1.p1">
<p class="ltx_p" id="S5.I1.ix1.p1.1"><span class="ltx_text" id="S5.I1.ix1.p1.1.1" style="font-size:70%;">RTF: the ratio of the processing time to the input duration</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p2">
<svg class="ltx_picture" height="157.63" id="S5.SS2.SSS2.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,157.63) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 151.72 C 0 154.98 2.64 157.63 5.91 157.63 L 594.09 157.63 C 597.36 157.63 600 154.98 600 151.72 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 151.72 C 1.97 153.9 3.73 155.66 5.91 155.66 L 594.09 155.66 C 596.27 155.66 598.03 153.9 598.03 151.72 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="130.07" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.SSS2.p2.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S5.SS2.SSS2.p2.pic1.1.1.1.1.1.1">Remark 1: Communication and video conferencing through IP have become the main way of community communication nowadays. In <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib90" title="">2022</a>)</cite>, researchers found that due to the special characteristics of IP channels,
audio signal transmission can cause signal attenuation, random channel noise, and other interference,
which can affect the effectiveness of audio adversarial samples.
Therefore, in future research, it is necessary to focus on investigating the potential impact of malicious audio in the transmission process over IP channels.
In this paper, we refer to attacks that are transmitted through IP channels as Wav-Network-API (WNA).</span>
</span></foreignobject></g></g></svg>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Service Layer</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The evolution of VCS has led to the integration of third-party services, enhancing functionality beyond basic speech content recognition or identity verification. Examples include Amazon Echo and Google Assistant. While this expansion addresses user demands, it also introduces heightened security risks. This section explores the potential vulnerabilities and threats posed by these third-party integrations in VCS.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Squatting Attacks in Service Layer</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">Despite mandatory reviews for third-party services in VCS to ensure compliance with security and privacy policies, many services still breach these regulations <cite class="ltx_cite ltx_citemacro_citep">(Guo
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib57" title="">2020a</a>; Su
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib137" title="">2020</a>)</cite>, and current review processes struggle to identify such violations <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib28" title="">2020</a>)</cite>. This oversight allows attackers to introduce malicious services, posing significant privacy risks. Squatting attacks occur when attackers create services with names resembling legitimate ones, deceiving users into accessing these malicious options instead. There are two primary methods of squatting attacks:</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<ol class="ltx_enumerate" id="S6.I1">
<li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S6.I1.i1.p1">
<p class="ltx_p" id="S6.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i1.p1.1.1">Similar Sounding Service Names:</span> Attackers may design service names phonetically similar to legitimate ones, leading to accidental activation of the malicious service. For instance, a service named “Capital Won” could be mistaken for “Capital One”, especially in noisy settings or based on user dialect or gender <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib194" title="">2019a</a>; Kumar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib77" title="">2018</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S6.I1.i2.p1">
<p class="ltx_p" id="S6.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i2.p1.1.1">Exploiting Longest Matching Rule:</span> VCS typically match service names using the longest matching rule. Attackers leverage this and user habits to construct squatting attacks. Since many users add polite terms like “please” to service commands, a malicious service named “Capital One Please” could be preferentially activated over the intended “Capital One” service, as observed in user habit surveys <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib194" title="">2019a</a>)</cite>.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S6.SS1.p3">
<p class="ltx_p" id="S6.SS1.p3.1">These squatting tactics demonstrate the nuanced vulnerabilities introduced by third-party service integration in VCS, highlighting the need for more robust security measures.</p>
</div>
<div class="ltx_para" id="S6.SS1.p4">
<p class="ltx_p" id="S6.SS1.p4.1"><em class="ltx_emph ltx_font_italic" id="S6.SS1.p4.1.1">Misunderstanding Attack.</em>
A misunderstanding attack is a nuanced form of squatting attack where the goal is not to activate a malicious service, but to induce errors within a legitimate service. These attacks exploit the limitations of VCS in accurately interpreting words outside their programmed understanding <cite class="ltx_cite ltx_citemacro_citep">(Stolk
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib135" title="">2016</a>)</cite>. For example, Siri might misinterpret “bank” in the context of “river bank”. Bispham et al.  <cite class="ltx_cite ltx_citemacro_citep">(Bispham
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib16" title="">2019</a>)</cite> demonstrated that by altering a single word in a command, VCS can be misled. In a banking service, changing “money” to “dough” in the query “how much money do I have?” could result in unintended information disclosure due to “dough” being slang for money. The Natural Language Understanding (NLU)’s Intent Classifier, which uses fuzzy matching to accommodate user speech variations, is often the exploitable component in such scenarios <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib197" title="">2019b</a>)</cite>.</p>
</div>
<section class="ltx_subsubsection" id="S6.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.1. </span>Defense Schemes against Squatting Attacks.</h4>
<div class="ltx_para" id="S6.SS1.SSS1.p1">
<p class="ltx_p" id="S6.SS1.SSS1.p1.1">Squatting attacks often involve similar-sounding service names or variants to trick VCS. Zhang et al.  <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib194" title="">2019a</a>)</cite> developed a phoneme-based service name scanner to identify suspicious third-party services. Additionally, it is suggested that service platform providers analyze new services for potential naming conflicts or utilize interactive tools for policy violation detection <cite class="ltx_cite ltx_citemacro_citep">(Kumar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib77" title="">2018</a>; Young
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib181" title="">2022</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>Faking Termination in Service Layer</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">Users’ misunderstandings about service termination protocols in VCS like Alexa and Google Assistant can be exploited. Users often assume that services end automatically after silence or a farewell response. However, malicious services can simulate termination sounds while remaining active, posing significant security risks if users then disclose private information or issue commands. Such deceptive practices highlight the need for greater awareness and more explicit termination protocols in VCS <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib194" title="">2019a</a>)</cite>.</p>
</div>
<section class="ltx_subsubsection" id="S6.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.1. </span>Defense Schemes against Faking Termination.</h4>
<div class="ltx_para" id="S6.SS2.SSS1.p1">
<p class="ltx_p" id="S6.SS2.SSS1.p1.1">To mitigate the risks associated with faking termination in VCS, various studies recommend enhancing service publishing authentication mechanisms <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib28" title="">2020</a>; Guo
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib57" title="">2020a</a>)</cite>. Service platform providers should conduct thorough word-based or phoneme-based reviews of new services to avoid confusion with existing ones. Additionally, methods such as voice interaction analysis and backend code review are effective in identifying privacy breaches or discrepancies between a service’s functionality and its description. Recent research suggests that context-sensitive detectors could effectively identify instances of faking termination <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib194" title="">2019a</a>)</cite>. Notably, a proposed hardening framework for VCS in  <cite class="ltx_cite ltx_citemacro_citep">(Vaere and Perrig, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib146" title="">2023</a>)</cite> focuses on ensuring that data collected by microphones is used only for local processing unless explicitly permitted by the user, thereby safeguarding against privacy data leakage caused by faking termination.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>General Attack Mitigation Strategy</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In earlier sections, we discussed defense schemes that were primarily focused on countering specific types of attacks in VCS. This section shifts the focus to state-of-the-art general attack mitigation strategies that are capable of defending against more attacks, encompassing different types and layers. These comprehensive strategies are essential for providing a more holistic defense mechanism for VCS systems. We have systematized existing general attack mitigation strategies and evaluated their efficacy against various attack types and characteristics. The comparative analysis of these strategies, including their strengths and limitations in resisting different forms of attacks, is presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S7.T5" title="Table 5 ‣ 7.2. Audio Conversion ‣ 7. General Attack Mitigation Strategy ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_tag">5</span></a>. This systematic overview aims to guide researchers and practitioners in selecting and implementing effective, multi-faceted defense strategies for VCS.</p>
</div>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1. </span>Liveness Detection</h3>
<div class="ltx_para" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">Liveness detection has emerged as a prevalent defense strategy in VCS, primarily designed to ascertain whether voice commands originate from actual humans. The fundamental premise behind this approach is the recognition that most malicious commands are machine-generated. These commands are typically played through speakers or directly input into the VCS API via audio files, such as WAV files. Unlike these artificially produced commands, genuine human users do not generate voice commands in this manner. Therefore, by identifying the characteristics of human speech, liveness detection aims to filter out these non-human, machine-generated inputs, thereby enhancing the security of VCS.
<em class="ltx_emph ltx_font_italic" id="S7.SS1.p1.1.1">Passive Detection.</em>
In the context of liveness detection for VCS, passive detection plays a crucial role in distinguishing between human-spoken voice commands and those generated by speakers. This is achieved through the analysis of sound characteristics using two main techniques:</p>
</div>
<div class="ltx_para" id="S7.SS1.p2">
<ol class="ltx_enumerate" id="S7.I1">
<li class="ltx_item" id="S7.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S7.I1.i1.p1">
<p class="ltx_p" id="S7.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S7.I1.i1.p1.1.1">Detecting Speaker Characteristics:</span> Voice commands emitted from speakers often carry unique signal distortions, which are a result of circuit noise inherent to the speaker’s hardware. These distortions differ significantly from the patterns found in human speech and can be identified using classifiers trained specifically for this purpose <cite class="ltx_cite ltx_citemacro_citep">(Ahmed
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib7" title="">2020</a>; Blue
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib17" title="">2018</a>; Gong and
Poellabauer, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib50" title="">2018b</a>; Pradhan
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib107" title="">2019</a>; Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib157" title="">2020a</a>)</cite>. Moreover, the electromagnetic fields generated by speakers during sound emission, owing to the electronic components, can be detected using a magnetometer in smart devices, further aiding in the determination of the voice command’s origin <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib24" title="">2017</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S7.I1.i2.p1">
<p class="ltx_p" id="S7.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S7.I1.i2.p1.1.1">Detecting Human Voice Characteristics:</span> Human speech is produced through a complex physiological process involving the coordinated action of the mouth, vocal tract, vocal cords, and lungs. The airflow from the lungs, passing through the glottis, causes vocal cord vibrations, which are then amplified by resonances in the mouth and vocal tract to form the final sound signal. Identifying features inherent to this process, such as breathing airflow patterns <cite class="ltx_cite ltx_citemacro_citep">(Mochizuki
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib99" title="">2018</a>; Pradhan
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib107" title="">2019</a>; Shiota et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib131" title="">2016</a>; Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib160" title="">2019a</a>; Zhou
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib199" title="">2019a</a>)</cite>, mouth movements <cite class="ltx_cite ltx_citemacro_citep">(Meng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib97" title="">2018</a>; Shang and Wu, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib129" title="">2020b</a>; Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib193" title="">2017a</a>; Yang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib178" title="">2023b</a>)</cite>, and bone vibrations <cite class="ltx_cite ltx_citemacro_citep">(Feng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib45" title="">2017</a>; Sahidullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib118" title="">2017</a>; Shang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib126" title="">2018</a>; Shang and Wu, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib127" title="">2019</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib128" title="">2020a</a>; Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib192" title="">2020b</a>)</cite>, provides a basis for determining whether a voice command is human-generated. These features can be monitored using microphones, cameras, or other specialized sensors. In practical applications, integrating additional devices or sensors might be necessary to enhance the accuracy and reliability of such verifications.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S7.SS1.p3">
<p class="ltx_p" id="S7.SS1.p3.1">These passive detection methods are instrumental in bolstering the security of VCS by ensuring that voice commands are genuinely human and not artificially generated or replayed through electronic devices.</p>
</div>
<div class="ltx_para" id="S7.SS1.p4">
<p class="ltx_p" id="S7.SS1.p4.1"><em class="ltx_emph ltx_font_italic" id="S7.SS1.p4.1.1">Active Interaction.</em>
The active interaction defense scheme in VCS involves engaging users in a manner similar to a CAPTCHA to ascertain the authenticity of voice commands. A prevalent form of this scheme is the Challenge-Response mechanism. Upon receiving a voice command, VCS issues a challenge to the user, requiring an appropriate response within a predetermined time frame. Failure to respond correctly within this window leads to the assumption that the command is machine-generated, and thus, the command execution is denied <cite class="ltx_cite ltx_citemacro_citep">(Carlini et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib19" title="">2016</a>; Sugawara et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib138" title="">2020</a>; Yuan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib183" title="">2018a</a>)</cite>. While effective in thwarting voice attacks to an extent, this method introduces additional steps for the user, potentially compromising the usability of the VCS.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p5">
<svg class="ltx_picture" height="120.19" id="S7.SS1.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,120.19) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 114.28 C 0 117.55 2.64 120.19 5.91 120.19 L 594.09 120.19 C 597.36 120.19 600 117.55 600 114.28 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 114.28 C 1.97 116.46 3.73 118.22 5.91 118.22 L 594.09 118.22 C 596.27 118.22 598.03 116.46 598.03 114.28 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="92.63" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S7.SS1.p5.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S7.SS1.p5.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.p5.pic1.1.1.1.1.1.1.1">Remark 2:</span> Recent research <cite class="ltx_cite ltx_citemacro_citep">(Ahmed et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib8" title="">2023</a>)</cite> has demonstrated that malicious attacks can manipulate a speaker’s voice commands into harmful instructions using a specially designed tube. As these instructions are essentially uttered by a real person, they can effectively circumvent traditional liveness detection methods. Future research in VCS security must account for the implications of such attacks on the efficacy of existing liveness detection schemes.</span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2. </span>Audio Conversion</h3>
<div class="ltx_para" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">The conversion of audio in the preprocessing layer of VCS, before it is passed to subsequent layers for further processing, serves as a defensive measure against voice-synthesis and adversarial attacks. This effectiveness stems from the conversion process’s ability to disrupt the specific patterns and structures that these attacks aim to exploit or deceive. As a result, the converted audio loses the characteristics intended by the attack, rendering it ineffective. In contrast, benign audio typically exhibits greater resilience to these conversions and is only minimally affected, preserving its integrity while mitigating potential threats.</p>
</div>
<div class="ltx_para" id="S7.SS2.p2">
<p class="ltx_p" id="S7.SS2.p2.1"><em class="ltx_emph ltx_font_italic" id="S7.SS2.p2.1.1">Audio Encoding.</em>
Encoding incoming audio has been shown to effectively diminish the success rate of malicious audio attacks. Utilizing codecs like Advanced Audio Coding (AAC) <cite class="ltx_cite ltx_citemacro_citep">(Rajaratnam
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib113" title="">2018a</a>)</cite>, MP3 <cite class="ltx_cite ltx_citemacro_citep">(Andronic et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib12" title="">2020</a>; Das et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib32" title="">2019</a>; Rajaratnam
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib113" title="">2018a</a>; Zhang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib190" title="">2019c</a>)</cite>, Speex <cite class="ltx_cite ltx_citemacro_citep">(Rajaratnam
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib113" title="">2018a</a>)</cite>, Opus <cite class="ltx_cite ltx_citemacro_citep">(Rajaratnam
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib113" title="">2018a</a>)</cite>, Adaptive Multi-Rate (AMR) <cite class="ltx_cite ltx_citemacro_citep">(Das et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib32" title="">2019</a>)</cite>, and integrated multiple codecs <cite class="ltx_cite ltx_citemacro_citep">(Rajaratnam
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib114" title="">2018b</a>; Das et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib32" title="">2019</a>)</cite> can provide a substantial level of defense against malicious audio.</p>
</div>
<div class="ltx_para" id="S7.SS2.p3">
<p class="ltx_p" id="S7.SS2.p3.1"><em class="ltx_emph ltx_font_italic" id="S7.SS2.p3.1.1">Audio Filtering.</em>
Voice-synthesis and adversarial attacks rely heavily on precise algorithmic perturbations. Filtering these malicious audio inputs, using methods like median filters <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib26" title="">2020b</a>; Du
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib39" title="">2020</a>; Yang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib179" title="">2018</a>)</cite>, quantization <cite class="ltx_cite ltx_citemacro_citep">(Yang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib179" title="">2018</a>)</cite>, and other noise reduction algorithms <cite class="ltx_cite ltx_citemacro_citep">(Tamura
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib142" title="">2019</a>; Guo
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib56" title="">2020b</a>)</cite>, effectively destroys these perturbations, thereby safeguarding the VCS from such attacks.</p>
</div>
<div class="ltx_para" id="S7.SS2.p4">
<p class="ltx_p" id="S7.SS2.p4.1"><em class="ltx_emph ltx_font_italic" id="S7.SS2.p4.1.1">Audio Downsampling.</em>
Experiments have demonstrated that downsampling audio to a lower rate and then upsampling it back to a rate suitable for VCS input can effectively mitigate attack impacts. While benign audio remains relatively unaffected, the malicious audio loses its carefully added perturbations, thus failing to achieve the intended effect on the target VCS <cite class="ltx_cite ltx_citemacro_citep">(Carlini et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib19" title="">2016</a>; Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib26" title="">2020b</a>; Du
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib39" title="">2020</a>; Yang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib179" title="">2018</a>; Yuan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib184" title="">2018b</a>; Tamura
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib142" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS2.p5">
<svg class="ltx_picture" height="103.59" id="S7.SS2.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,103.59) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 97.68 C 0 100.94 2.64 103.59 5.91 103.59 L 594.09 103.59 C 597.36 103.59 600 100.94 600 97.68 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 97.68 C 1.97 99.85 3.73 101.62 5.91 101.62 L 594.09 101.62 C 596.27 101.62 598.03 99.85 598.03 97.68 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="76.03" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S7.SS2.p5.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S7.SS2.p5.pic1.1.1.1.1.1.1">Remark 3: Audio conversion as a defense strategy exploits the resilience of benign audio to counteract the fragility of malicious audio. This process disrupts the attacker’s carefully engineered perturbations. However, in a white-box scenario, attackers aware of the VCS’s audio conversion methods can adjust their strategies accordingly, potentially neutralizing the defense’s effectiveness.</span>
</span></foreignobject></g></g></svg>
</div>
<figure class="ltx_table" id="S7.T5">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 5. </span>Capability of defending against different attacks in different layers.
(TA: transduction attack,
VsA: voice-synthesis attack,
AA: adversarial attack,
SpA: spoofing attack,
SqA: squatting attack, FT: faking termination, <math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.4.m1.1"><semantics id="S7.T5.4.m1.1b"><mo id="S7.T5.4.m1.1.1" xref="S7.T5.4.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.4.m1.1c"><csymbol cd="latexml" id="S7.T5.4.m1.1.1.cmml" xref="S7.T5.4.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.4.m1.1d">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.4.m1.1e">⨁</annotation></semantics></math> : Defensible, <math alttext="\bigodot" class="ltx_Math" display="inline" id="S7.T5.5.m2.1"><semantics id="S7.T5.5.m2.1b"><mo id="S7.T5.5.m2.1.1" xref="S7.T5.5.m2.1.1.cmml">⨀</mo><annotation-xml encoding="MathML-Content" id="S7.T5.5.m2.1c"><ci id="S7.T5.5.m2.1.1.cmml" xref="S7.T5.5.m2.1.1">⨀</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.5.m2.1d">\bigodot</annotation><annotation encoding="application/x-llamapun" id="S7.T5.5.m2.1e">⨀</annotation></semantics></math>: Probably Defensible, <math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.6.m3.1"><semantics id="S7.T5.6.m3.1b"><mo id="S7.T5.6.m3.1.1" xref="S7.T5.6.m3.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.6.m3.1c"><csymbol cd="latexml" id="S7.T5.6.m3.1.1.cmml" xref="S7.T5.6.m3.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.6.m3.1d">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.6.m3.1e">⨂</annotation></semantics></math> : Indefensible)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S7.T5.54">
<tr class="ltx_tr" id="S7.T5.54.49">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S7.T5.54.49.1" rowspan="3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.49.1.1" style="font-size:70%;"><span class="ltx_text" id="S7.T5.54.49.1.1.1"></span> <span class="ltx_text" id="S7.T5.54.49.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S7.T5.54.49.1.1.2.1">
<span class="ltx_tr" id="S7.T5.54.49.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.54.49.1.1.2.1.1.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">Defense schemes</span></span>
</span></span> <span class="ltx_text" id="S7.T5.54.49.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="8" id="S7.T5.54.49.2" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.49.2.1" style="font-size:70%;">Attacks</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T5.54.49.3" rowspan="3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.49.3.1" style="font-size:70%;">Papers</span></td>
</tr>
<tr class="ltx_tr" id="S7.T5.54.50">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S7.T5.54.50.1" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.50.1.1" style="font-size:70%;">Physical Layer</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S7.T5.54.50.2" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.50.2.1" style="font-size:70%;">Preprocessing Layer</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S7.T5.54.50.3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.50.3.1" style="font-size:70%;">Kernel Layer</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S7.T5.54.50.4" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.50.4.1" style="font-size:70%;">Service Layer</span></td>
</tr>
<tr class="ltx_tr" id="S7.T5.54.51">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.54.51.1" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.51.1.1" style="font-size:70%;">TA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.54.51.2" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.51.2.1" style="font-size:70%;">VsA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.54.51.3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.51.3.1" style="font-size:70%;">VsA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.54.51.4" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.51.4.1" style="font-size:70%;">AA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.54.51.5" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.51.5.1" style="font-size:70%;">SpA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.54.51.6" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.51.6.1" style="font-size:70%;">AA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.54.51.7" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.51.7.1" style="font-size:70%;">SqA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.54.51.8" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.51.8.1" style="font-size:70%;">FT</span></td>
</tr>
<tr class="ltx_tr" id="S7.T5.14.8">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.14.8.9" rowspan="3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.14.8.9.1" style="font-size:70%;"><span class="ltx_text" id="S7.T5.14.8.9.1.1"></span> <span class="ltx_text" id="S7.T5.14.8.9.1.2">
<span class="ltx_tabular ltx_align_middle" id="S7.T5.14.8.9.1.2.1">
<span class="ltx_tr" id="S7.T5.14.8.9.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.14.8.9.1.2.1.1.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">Liveness</span></span>
<span class="ltx_tr" id="S7.T5.14.8.9.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.14.8.9.1.2.1.2.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">detection</span></span>
</span></span> <span class="ltx_text" id="S7.T5.14.8.9.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.14.8.10" style="padding-top:3.85pt;padding-bottom:3.85pt;">
<span class="ltx_text" id="S7.T5.14.8.10.1"></span><span class="ltx_text" id="S7.T5.14.8.10.2" style="font-size:70%;"> </span><span class="ltx_text" id="S7.T5.14.8.10.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S7.T5.14.8.10.3.1">
<span class="ltx_tr" id="S7.T5.14.8.10.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.14.8.10.3.1.1.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">Speaker</span></span>
<span class="ltx_tr" id="S7.T5.14.8.10.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.14.8.10.3.1.2.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">characteristics</span></span>
</span></span><span class="ltx_text" id="S7.T5.14.8.10.4"></span><span class="ltx_text" id="S7.T5.14.8.10.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.7.1.1" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.7.1.1.m1.1"><semantics id="S7.T5.7.1.1.m1.1a"><mo id="S7.T5.7.1.1.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.7.1.1.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.7.1.1.m1.1b"><csymbol cd="latexml" id="S7.T5.7.1.1.m1.1.1.cmml" xref="S7.T5.7.1.1.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.7.1.1.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.7.1.1.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.8.2.2" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.8.2.2.m1.1"><semantics id="S7.T5.8.2.2.m1.1a"><mo id="S7.T5.8.2.2.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.8.2.2.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.8.2.2.m1.1b"><csymbol cd="latexml" id="S7.T5.8.2.2.m1.1.1.cmml" xref="S7.T5.8.2.2.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.8.2.2.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.8.2.2.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.9.3.3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.9.3.3.m1.1"><semantics id="S7.T5.9.3.3.m1.1a"><mo id="S7.T5.9.3.3.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.9.3.3.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.9.3.3.m1.1b"><csymbol cd="latexml" id="S7.T5.9.3.3.m1.1.1.cmml" xref="S7.T5.9.3.3.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.9.3.3.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.9.3.3.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.10.4.4" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.10.4.4.m1.1"><semantics id="S7.T5.10.4.4.m1.1a"><mo id="S7.T5.10.4.4.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.10.4.4.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.10.4.4.m1.1b"><csymbol cd="latexml" id="S7.T5.10.4.4.m1.1.1.cmml" xref="S7.T5.10.4.4.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.10.4.4.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.10.4.4.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.11.5.5" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.11.5.5.m1.1"><semantics id="S7.T5.11.5.5.m1.1a"><mo id="S7.T5.11.5.5.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.11.5.5.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.11.5.5.m1.1b"><csymbol cd="latexml" id="S7.T5.11.5.5.m1.1.1.cmml" xref="S7.T5.11.5.5.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.11.5.5.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.11.5.5.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.12.6.6" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.12.6.6.m1.1"><semantics id="S7.T5.12.6.6.m1.1a"><mo id="S7.T5.12.6.6.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.12.6.6.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.12.6.6.m1.1b"><csymbol cd="latexml" id="S7.T5.12.6.6.m1.1.1.cmml" xref="S7.T5.12.6.6.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.12.6.6.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.12.6.6.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.13.7.7" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.13.7.7.m1.1"><semantics id="S7.T5.13.7.7.m1.1a"><mo id="S7.T5.13.7.7.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.13.7.7.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.13.7.7.m1.1b"><csymbol cd="latexml" id="S7.T5.13.7.7.m1.1.1.cmml" xref="S7.T5.13.7.7.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.13.7.7.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.13.7.7.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.14.8.8" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.14.8.8.m1.1"><semantics id="S7.T5.14.8.8.m1.1a"><mo id="S7.T5.14.8.8.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.14.8.8.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.14.8.8.m1.1b"><csymbol cd="latexml" id="S7.T5.14.8.8.m1.1.1.cmml" xref="S7.T5.14.8.8.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.14.8.8.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.14.8.8.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S7.T5.14.8.11" style="padding-top:3.85pt;padding-bottom:3.85pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S7.T5.14.8.11.1.1" style="font-size:70%;">(</span>Ahmed
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.14.8.11.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib7" title="">2020</a>; Blue
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.14.8.11.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib17" title="">2018</a>; Gong and
Poellabauer<span class="ltx_text" id="S7.T5.14.8.11.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib50" title="">2018b</a>; Pradhan
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.14.8.11.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib107" title="">2019</a>; Wang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.14.8.11.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib157" title="">2020a</a>; Chen et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.14.8.11.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib24" title="">2017</a><span class="ltx_text" id="S7.T5.14.8.11.3.3" style="font-size:70%;">)</span></cite></td>
</tr>
<tr class="ltx_tr" id="S7.T5.22.16">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.22.16.9" style="padding-top:3.85pt;padding-bottom:3.85pt;">
<span class="ltx_text" id="S7.T5.22.16.9.1"></span><span class="ltx_text" id="S7.T5.22.16.9.2" style="font-size:70%;"> </span><span class="ltx_text" id="S7.T5.22.16.9.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S7.T5.22.16.9.3.1">
<span class="ltx_tr" id="S7.T5.22.16.9.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.22.16.9.3.1.1.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">Human voice</span></span>
<span class="ltx_tr" id="S7.T5.22.16.9.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.22.16.9.3.1.2.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">characteristics</span></span>
</span></span><span class="ltx_text" id="S7.T5.22.16.9.4"></span><span class="ltx_text" id="S7.T5.22.16.9.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.15.9.1" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.15.9.1.m1.1"><semantics id="S7.T5.15.9.1.m1.1a"><mo id="S7.T5.15.9.1.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.15.9.1.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.15.9.1.m1.1b"><csymbol cd="latexml" id="S7.T5.15.9.1.m1.1.1.cmml" xref="S7.T5.15.9.1.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.15.9.1.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.15.9.1.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.16.10.2" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.16.10.2.m1.1"><semantics id="S7.T5.16.10.2.m1.1a"><mo id="S7.T5.16.10.2.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.16.10.2.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.16.10.2.m1.1b"><csymbol cd="latexml" id="S7.T5.16.10.2.m1.1.1.cmml" xref="S7.T5.16.10.2.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.16.10.2.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.16.10.2.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.17.11.3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.17.11.3.m1.1"><semantics id="S7.T5.17.11.3.m1.1a"><mo id="S7.T5.17.11.3.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.17.11.3.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.17.11.3.m1.1b"><csymbol cd="latexml" id="S7.T5.17.11.3.m1.1.1.cmml" xref="S7.T5.17.11.3.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.17.11.3.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.17.11.3.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.18.12.4" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.18.12.4.m1.1"><semantics id="S7.T5.18.12.4.m1.1a"><mo id="S7.T5.18.12.4.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.18.12.4.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.18.12.4.m1.1b"><csymbol cd="latexml" id="S7.T5.18.12.4.m1.1.1.cmml" xref="S7.T5.18.12.4.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.18.12.4.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.18.12.4.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.19.13.5" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.19.13.5.m1.1"><semantics id="S7.T5.19.13.5.m1.1a"><mo id="S7.T5.19.13.5.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.19.13.5.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.19.13.5.m1.1b"><csymbol cd="latexml" id="S7.T5.19.13.5.m1.1.1.cmml" xref="S7.T5.19.13.5.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.19.13.5.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.19.13.5.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.20.14.6" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.20.14.6.m1.1"><semantics id="S7.T5.20.14.6.m1.1a"><mo id="S7.T5.20.14.6.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.20.14.6.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.20.14.6.m1.1b"><csymbol cd="latexml" id="S7.T5.20.14.6.m1.1.1.cmml" xref="S7.T5.20.14.6.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.20.14.6.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.20.14.6.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.21.15.7" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.21.15.7.m1.1"><semantics id="S7.T5.21.15.7.m1.1a"><mo id="S7.T5.21.15.7.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.21.15.7.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.21.15.7.m1.1b"><csymbol cd="latexml" id="S7.T5.21.15.7.m1.1.1.cmml" xref="S7.T5.21.15.7.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.21.15.7.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.21.15.7.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.22.16.8" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.22.16.8.m1.1"><semantics id="S7.T5.22.16.8.m1.1a"><mo id="S7.T5.22.16.8.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.22.16.8.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.22.16.8.m1.1b"><csymbol cd="latexml" id="S7.T5.22.16.8.m1.1.1.cmml" xref="S7.T5.22.16.8.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.22.16.8.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.22.16.8.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S7.T5.22.16.10" style="padding-top:3.85pt;padding-bottom:3.85pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S7.T5.22.16.10.1.1" style="font-size:70%;">(</span>Mochizuki
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib99" title="">2018</a>; Pradhan
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib107" title="">2019</a>; Shiota et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib131" title="">2016</a>; Wang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib160" title="">2019a</a>; Zhou
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib199" title="">2019a</a>; Meng et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib97" title="">2018</a>; Shang and Wu<span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib129" title="">2020b</a>; Zhang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib193" title="">2017a</a>; Feng
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib45" title="">2017</a>; Sahidullah et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib118" title="">2017</a>; Shang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib126" title="">2018</a>; Shang and Wu<span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib127" title="">2019</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib128" title="">2020a</a>; Zhang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib192" title="">2020b</a>; Yang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.22.16.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib178" title="">2023b</a><span class="ltx_text" id="S7.T5.22.16.10.3.3" style="font-size:70%;">)</span></cite></td>
</tr>
<tr class="ltx_tr" id="S7.T5.30.24">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.30.24.9" style="padding-top:3.85pt;padding-bottom:3.85pt;">
<span class="ltx_text" id="S7.T5.30.24.9.1"></span><span class="ltx_text" id="S7.T5.30.24.9.2" style="font-size:70%;"> </span><span class="ltx_text" id="S7.T5.30.24.9.3" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S7.T5.30.24.9.3.1">
<span class="ltx_tr" id="S7.T5.30.24.9.3.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.30.24.9.3.1.1.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">Active</span></span>
<span class="ltx_tr" id="S7.T5.30.24.9.3.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.30.24.9.3.1.2.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">interaction</span></span>
</span></span><span class="ltx_text" id="S7.T5.30.24.9.4"></span><span class="ltx_text" id="S7.T5.30.24.9.5" style="font-size:70%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.23.17.1" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.23.17.1.m1.1"><semantics id="S7.T5.23.17.1.m1.1a"><mo id="S7.T5.23.17.1.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.23.17.1.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.23.17.1.m1.1b"><csymbol cd="latexml" id="S7.T5.23.17.1.m1.1.1.cmml" xref="S7.T5.23.17.1.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.23.17.1.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.23.17.1.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.24.18.2" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.24.18.2.m1.1"><semantics id="S7.T5.24.18.2.m1.1a"><mo id="S7.T5.24.18.2.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.24.18.2.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.24.18.2.m1.1b"><csymbol cd="latexml" id="S7.T5.24.18.2.m1.1.1.cmml" xref="S7.T5.24.18.2.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.24.18.2.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.24.18.2.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.25.19.3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.25.19.3.m1.1"><semantics id="S7.T5.25.19.3.m1.1a"><mo id="S7.T5.25.19.3.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.25.19.3.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.25.19.3.m1.1b"><csymbol cd="latexml" id="S7.T5.25.19.3.m1.1.1.cmml" xref="S7.T5.25.19.3.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.25.19.3.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.25.19.3.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.26.20.4" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.26.20.4.m1.1"><semantics id="S7.T5.26.20.4.m1.1a"><mo id="S7.T5.26.20.4.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.26.20.4.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.26.20.4.m1.1b"><csymbol cd="latexml" id="S7.T5.26.20.4.m1.1.1.cmml" xref="S7.T5.26.20.4.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.26.20.4.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.26.20.4.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.27.21.5" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.27.21.5.m1.1"><semantics id="S7.T5.27.21.5.m1.1a"><mo id="S7.T5.27.21.5.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.27.21.5.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.27.21.5.m1.1b"><csymbol cd="latexml" id="S7.T5.27.21.5.m1.1.1.cmml" xref="S7.T5.27.21.5.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.27.21.5.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.27.21.5.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.28.22.6" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.28.22.6.m1.1"><semantics id="S7.T5.28.22.6.m1.1a"><mo id="S7.T5.28.22.6.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.28.22.6.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.28.22.6.m1.1b"><csymbol cd="latexml" id="S7.T5.28.22.6.m1.1.1.cmml" xref="S7.T5.28.22.6.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.28.22.6.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.28.22.6.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.29.23.7" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigodot" class="ltx_Math" display="inline" id="S7.T5.29.23.7.m1.1"><semantics id="S7.T5.29.23.7.m1.1a"><mo id="S7.T5.29.23.7.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.29.23.7.m1.1.1.cmml">⨀</mo><annotation-xml encoding="MathML-Content" id="S7.T5.29.23.7.m1.1b"><ci id="S7.T5.29.23.7.m1.1.1.cmml" xref="S7.T5.29.23.7.m1.1.1">⨀</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.29.23.7.m1.1c">\bigodot</annotation><annotation encoding="application/x-llamapun" id="S7.T5.29.23.7.m1.1d">⨀</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.30.24.8" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigodot" class="ltx_Math" display="inline" id="S7.T5.30.24.8.m1.1"><semantics id="S7.T5.30.24.8.m1.1a"><mo id="S7.T5.30.24.8.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.30.24.8.m1.1.1.cmml">⨀</mo><annotation-xml encoding="MathML-Content" id="S7.T5.30.24.8.m1.1b"><ci id="S7.T5.30.24.8.m1.1.1.cmml" xref="S7.T5.30.24.8.m1.1.1">⨀</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.30.24.8.m1.1c">\bigodot</annotation><annotation encoding="application/x-llamapun" id="S7.T5.30.24.8.m1.1d">⨀</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S7.T5.30.24.10" style="padding-top:3.85pt;padding-bottom:3.85pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S7.T5.30.24.10.1.1" style="font-size:70%;">(</span>Carlini et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.30.24.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib19" title="">2016</a>; Sugawara et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.30.24.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib138" title="">2020</a>; Yuan et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.30.24.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib183" title="">2018a</a>; Rajaratnam
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.30.24.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib114" title="">2018b</a><span class="ltx_text" id="S7.T5.30.24.10.3.3" style="font-size:70%;">)</span></cite></td>
</tr>
<tr class="ltx_tr" id="S7.T5.38.32">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.38.32.9" rowspan="3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.38.32.9.1" style="font-size:70%;"><span class="ltx_text" id="S7.T5.38.32.9.1.1"></span> <span class="ltx_text" id="S7.T5.38.32.9.1.2">
<span class="ltx_tabular ltx_align_middle" id="S7.T5.38.32.9.1.2.1">
<span class="ltx_tr" id="S7.T5.38.32.9.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.38.32.9.1.2.1.1.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">Audio</span></span>
<span class="ltx_tr" id="S7.T5.38.32.9.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S7.T5.38.32.9.1.2.1.2.1" style="padding-top:3.85pt;padding-bottom:3.85pt;">conversion</span></span>
</span></span> <span class="ltx_text" id="S7.T5.38.32.9.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.38.32.10" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.38.32.10.1" style="font-size:70%;">Encoding</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.31.25.1" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.31.25.1.m1.1"><semantics id="S7.T5.31.25.1.m1.1a"><mo id="S7.T5.31.25.1.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.31.25.1.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.31.25.1.m1.1b"><csymbol cd="latexml" id="S7.T5.31.25.1.m1.1.1.cmml" xref="S7.T5.31.25.1.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.31.25.1.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.31.25.1.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.32.26.2" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigodot" class="ltx_Math" display="inline" id="S7.T5.32.26.2.m1.1"><semantics id="S7.T5.32.26.2.m1.1a"><mo id="S7.T5.32.26.2.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.32.26.2.m1.1.1.cmml">⨀</mo><annotation-xml encoding="MathML-Content" id="S7.T5.32.26.2.m1.1b"><ci id="S7.T5.32.26.2.m1.1.1.cmml" xref="S7.T5.32.26.2.m1.1.1">⨀</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.32.26.2.m1.1c">\bigodot</annotation><annotation encoding="application/x-llamapun" id="S7.T5.32.26.2.m1.1d">⨀</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.33.27.3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.33.27.3.m1.1"><semantics id="S7.T5.33.27.3.m1.1a"><mo id="S7.T5.33.27.3.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.33.27.3.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.33.27.3.m1.1b"><csymbol cd="latexml" id="S7.T5.33.27.3.m1.1.1.cmml" xref="S7.T5.33.27.3.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.33.27.3.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.33.27.3.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.34.28.4" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.34.28.4.m1.1"><semantics id="S7.T5.34.28.4.m1.1a"><mo id="S7.T5.34.28.4.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.34.28.4.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.34.28.4.m1.1b"><csymbol cd="latexml" id="S7.T5.34.28.4.m1.1.1.cmml" xref="S7.T5.34.28.4.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.34.28.4.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.34.28.4.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.35.29.5" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.35.29.5.m1.1"><semantics id="S7.T5.35.29.5.m1.1a"><mo id="S7.T5.35.29.5.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.35.29.5.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.35.29.5.m1.1b"><csymbol cd="latexml" id="S7.T5.35.29.5.m1.1.1.cmml" xref="S7.T5.35.29.5.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.35.29.5.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.35.29.5.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.36.30.6" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.36.30.6.m1.1"><semantics id="S7.T5.36.30.6.m1.1a"><mo id="S7.T5.36.30.6.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.36.30.6.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.36.30.6.m1.1b"><csymbol cd="latexml" id="S7.T5.36.30.6.m1.1.1.cmml" xref="S7.T5.36.30.6.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.36.30.6.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.36.30.6.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.37.31.7" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.37.31.7.m1.1"><semantics id="S7.T5.37.31.7.m1.1a"><mo id="S7.T5.37.31.7.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.37.31.7.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.37.31.7.m1.1b"><csymbol cd="latexml" id="S7.T5.37.31.7.m1.1.1.cmml" xref="S7.T5.37.31.7.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.37.31.7.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.37.31.7.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.38.32.8" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.38.32.8.m1.1"><semantics id="S7.T5.38.32.8.m1.1a"><mo id="S7.T5.38.32.8.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.38.32.8.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.38.32.8.m1.1b"><csymbol cd="latexml" id="S7.T5.38.32.8.m1.1.1.cmml" xref="S7.T5.38.32.8.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.38.32.8.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.38.32.8.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S7.T5.38.32.11" style="padding-top:3.85pt;padding-bottom:3.85pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S7.T5.38.32.11.1.1" style="font-size:70%;">(</span>Andronic et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.38.32.11.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib12" title="">2020</a>; Das et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.38.32.11.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib32" title="">2019</a>; Rajaratnam
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.38.32.11.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib113" title="">2018a</a>; Zhang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.38.32.11.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib190" title="">2019c</a><span class="ltx_text" id="S7.T5.38.32.11.3.3" style="font-size:70%;">)</span></cite></td>
</tr>
<tr class="ltx_tr" id="S7.T5.46.40">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.46.40.9" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.46.40.9.1" style="font-size:70%;">Filtering</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.39.33.1" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.39.33.1.m1.1"><semantics id="S7.T5.39.33.1.m1.1a"><mo id="S7.T5.39.33.1.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.39.33.1.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.39.33.1.m1.1b"><csymbol cd="latexml" id="S7.T5.39.33.1.m1.1.1.cmml" xref="S7.T5.39.33.1.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.39.33.1.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.39.33.1.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.40.34.2" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigodot" class="ltx_Math" display="inline" id="S7.T5.40.34.2.m1.1"><semantics id="S7.T5.40.34.2.m1.1a"><mo id="S7.T5.40.34.2.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.40.34.2.m1.1.1.cmml">⨀</mo><annotation-xml encoding="MathML-Content" id="S7.T5.40.34.2.m1.1b"><ci id="S7.T5.40.34.2.m1.1.1.cmml" xref="S7.T5.40.34.2.m1.1.1">⨀</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.40.34.2.m1.1c">\bigodot</annotation><annotation encoding="application/x-llamapun" id="S7.T5.40.34.2.m1.1d">⨀</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.41.35.3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.41.35.3.m1.1"><semantics id="S7.T5.41.35.3.m1.1a"><mo id="S7.T5.41.35.3.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.41.35.3.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.41.35.3.m1.1b"><csymbol cd="latexml" id="S7.T5.41.35.3.m1.1.1.cmml" xref="S7.T5.41.35.3.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.41.35.3.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.41.35.3.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.42.36.4" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.42.36.4.m1.1"><semantics id="S7.T5.42.36.4.m1.1a"><mo id="S7.T5.42.36.4.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.42.36.4.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.42.36.4.m1.1b"><csymbol cd="latexml" id="S7.T5.42.36.4.m1.1.1.cmml" xref="S7.T5.42.36.4.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.42.36.4.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.42.36.4.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.43.37.5" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.43.37.5.m1.1"><semantics id="S7.T5.43.37.5.m1.1a"><mo id="S7.T5.43.37.5.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.43.37.5.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.43.37.5.m1.1b"><csymbol cd="latexml" id="S7.T5.43.37.5.m1.1.1.cmml" xref="S7.T5.43.37.5.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.43.37.5.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.43.37.5.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.44.38.6" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.44.38.6.m1.1"><semantics id="S7.T5.44.38.6.m1.1a"><mo id="S7.T5.44.38.6.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.44.38.6.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.44.38.6.m1.1b"><csymbol cd="latexml" id="S7.T5.44.38.6.m1.1.1.cmml" xref="S7.T5.44.38.6.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.44.38.6.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.44.38.6.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.45.39.7" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.45.39.7.m1.1"><semantics id="S7.T5.45.39.7.m1.1a"><mo id="S7.T5.45.39.7.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.45.39.7.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.45.39.7.m1.1b"><csymbol cd="latexml" id="S7.T5.45.39.7.m1.1.1.cmml" xref="S7.T5.45.39.7.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.45.39.7.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.45.39.7.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T5.46.40.8" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.46.40.8.m1.1"><semantics id="S7.T5.46.40.8.m1.1a"><mo id="S7.T5.46.40.8.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.46.40.8.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.46.40.8.m1.1b"><csymbol cd="latexml" id="S7.T5.46.40.8.m1.1.1.cmml" xref="S7.T5.46.40.8.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.46.40.8.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.46.40.8.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S7.T5.46.40.10" style="padding-top:3.85pt;padding-bottom:3.85pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S7.T5.46.40.10.1.1" style="font-size:70%;">(</span>Chen et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.46.40.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib26" title="">2020b</a>; Du
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.46.40.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib39" title="">2020</a>; Yang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.46.40.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib179" title="">2018</a>; Tamura
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.46.40.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib142" title="">2019</a>; Guo
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.46.40.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib56" title="">2020b</a><span class="ltx_text" id="S7.T5.46.40.10.3.3" style="font-size:70%;">)</span></cite></td>
</tr>
<tr class="ltx_tr" id="S7.T5.54.48">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.54.48.9" style="padding-top:3.85pt;padding-bottom:3.85pt;"><span class="ltx_text" id="S7.T5.54.48.9.1" style="font-size:70%;">Downsampling</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.47.41.1" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.47.41.1.m1.1"><semantics id="S7.T5.47.41.1.m1.1a"><mo id="S7.T5.47.41.1.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.47.41.1.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.47.41.1.m1.1b"><csymbol cd="latexml" id="S7.T5.47.41.1.m1.1.1.cmml" xref="S7.T5.47.41.1.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.47.41.1.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.47.41.1.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.48.42.2" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigodot" class="ltx_Math" display="inline" id="S7.T5.48.42.2.m1.1"><semantics id="S7.T5.48.42.2.m1.1a"><mo id="S7.T5.48.42.2.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.48.42.2.m1.1.1.cmml">⨀</mo><annotation-xml encoding="MathML-Content" id="S7.T5.48.42.2.m1.1b"><ci id="S7.T5.48.42.2.m1.1.1.cmml" xref="S7.T5.48.42.2.m1.1.1">⨀</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.48.42.2.m1.1c">\bigodot</annotation><annotation encoding="application/x-llamapun" id="S7.T5.48.42.2.m1.1d">⨀</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.49.43.3" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.49.43.3.m1.1"><semantics id="S7.T5.49.43.3.m1.1a"><mo id="S7.T5.49.43.3.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.49.43.3.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.49.43.3.m1.1b"><csymbol cd="latexml" id="S7.T5.49.43.3.m1.1.1.cmml" xref="S7.T5.49.43.3.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.49.43.3.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.49.43.3.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.50.44.4" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.50.44.4.m1.1"><semantics id="S7.T5.50.44.4.m1.1a"><mo id="S7.T5.50.44.4.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.50.44.4.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.50.44.4.m1.1b"><csymbol cd="latexml" id="S7.T5.50.44.4.m1.1.1.cmml" xref="S7.T5.50.44.4.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.50.44.4.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.50.44.4.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.51.45.5" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.51.45.5.m1.1"><semantics id="S7.T5.51.45.5.m1.1a"><mo id="S7.T5.51.45.5.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.51.45.5.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.51.45.5.m1.1b"><csymbol cd="latexml" id="S7.T5.51.45.5.m1.1.1.cmml" xref="S7.T5.51.45.5.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.51.45.5.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.51.45.5.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.52.46.6" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigoplus" class="ltx_Math" display="inline" id="S7.T5.52.46.6.m1.1"><semantics id="S7.T5.52.46.6.m1.1a"><mo id="S7.T5.52.46.6.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.52.46.6.m1.1.1.cmml">⨁</mo><annotation-xml encoding="MathML-Content" id="S7.T5.52.46.6.m1.1b"><csymbol cd="latexml" id="S7.T5.52.46.6.m1.1.1.cmml" xref="S7.T5.52.46.6.m1.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.52.46.6.m1.1c">\bigoplus</annotation><annotation encoding="application/x-llamapun" id="S7.T5.52.46.6.m1.1d">⨁</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.53.47.7" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.53.47.7.m1.1"><semantics id="S7.T5.53.47.7.m1.1a"><mo id="S7.T5.53.47.7.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.53.47.7.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.53.47.7.m1.1b"><csymbol cd="latexml" id="S7.T5.53.47.7.m1.1.1.cmml" xref="S7.T5.53.47.7.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.53.47.7.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.53.47.7.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.54.48.8" style="padding-top:3.85pt;padding-bottom:3.85pt;"><math alttext="\bigotimes" class="ltx_Math" display="inline" id="S7.T5.54.48.8.m1.1"><semantics id="S7.T5.54.48.8.m1.1a"><mo id="S7.T5.54.48.8.m1.1.1" maxsize="70%" minsize="70%" stretchy="true" xref="S7.T5.54.48.8.m1.1.1.cmml">⨂</mo><annotation-xml encoding="MathML-Content" id="S7.T5.54.48.8.m1.1b"><csymbol cd="latexml" id="S7.T5.54.48.8.m1.1.1.cmml" xref="S7.T5.54.48.8.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.54.48.8.m1.1c">\bigotimes</annotation><annotation encoding="application/x-llamapun" id="S7.T5.54.48.8.m1.1d">⨂</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T5.54.48.10" style="padding-top:3.85pt;padding-bottom:3.85pt;"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S7.T5.54.48.10.1.1" style="font-size:70%;">(</span>Carlini et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.54.48.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib19" title="">2016</a>; Chen et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.54.48.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib26" title="">2020b</a>; Du
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.54.48.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib39" title="">2020</a>; Yang
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.54.48.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib179" title="">2018</a>; Yuan et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.54.48.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib184" title="">2018b</a>; Tamura
et al<span class="ltx_text">.</span><span class="ltx_text" id="S7.T5.54.48.10.2.2.1.1" style="font-size:70%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib142" title="">2019</a><span class="ltx_text" id="S7.T5.54.48.10.3.3" style="font-size:70%;">)</span></cite></td>
</tr>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S7.SS2.p6">
<svg class="ltx_picture" height="139.48" id="S7.SS2.p6.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,139.48) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 133.58 C 0 136.84 2.64 139.48 5.91 139.48 L 594.09 139.48 C 597.36 139.48 600 136.84 600 133.58 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 133.58 C 1.97 135.75 3.73 137.52 5.91 137.52 L 594.09 137.52 C 596.27 137.52 598.03 135.75 598.03 133.58 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="111.93" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S7.SS2.p6.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S7.SS2.p6.pic1.1.1.1.1.1.1">Remark 4: As delineated in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#S7.T5" title="Table 5 ‣ 7.2. Audio Conversion ‣ 7. General Attack Mitigation Strategy ‣ Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems"><span class="ltx_text ltx_ref_tag">5</span></a>, liveness detection effectively counters a wide array of attacks, particularly those outside the service layer. While active interaction also offers some resistance against service layer attacks, its effectiveness comes at the cost of user experience. Given this trade-off, a preferable approach would be to combine passive detection with an enhanced service release and authentication mechanism. This combination would enable a more holistic defense against the diverse types of attacks encountered in VCS, optimizing both security and user experience.</span>
</span></foreignobject></g></g></svg>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Challenges and Future Directions</h2>
<section class="ltx_subsection" id="S8.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.1. </span>Challenges</h3>
<div class="ltx_para" id="S8.SS1.p1">
<p class="ltx_p" id="S8.SS1.p1.1"><em class="ltx_emph ltx_font_italic" id="S8.SS1.p1.1.1">Hardware Enhancement.</em> The effectiveness of physical layer attacks in VCS often hinges on exploiting hardware vulnerabilities, particularly in microphones. However, these vulnerabilities are not uniformly present across all microphone types. A notable example is the iPhone 6 Plus, which has been shown to effectively resist voice-synthesis attacks due to its unique microphone design, as highlighted in <cite class="ltx_cite ltx_citemacro_citep">(He
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib62" title="">2019</a>)</cite>. This variability in hardware susceptibility presents significant challenges for executing consistent attacks at the physical layer.</p>
</div>
<div class="ltx_para" id="S8.SS1.p2">
<p class="ltx_p" id="S8.SS1.p2.1"><em class="ltx_emph ltx_font_italic" id="S8.SS1.p2.1.1">Model Knowledge.</em> As VCS technology has evolved, commercial models have become increasingly prevalent. These models are often proprietary and not open-sourced, a strategy employed by companies to protect their intellectual property and prevent replication by competitors. This secrecy forces attackers to operate in a black-box environment, substantially lowering the success rate of adversarial attacks. Additionally, the challenge of creating universal adversarial perturbations that can produce similar attack outcomes across different models remains a significant hurdle in the realm of adversarial attacks.</p>
</div>
<div class="ltx_para" id="S8.SS1.p3">
<p class="ltx_p" id="S8.SS1.p3.1"><em class="ltx_emph ltx_font_italic" id="S8.SS1.p3.1.1">Noise Disturbance.</em> Noise disturbance is a critical factor for both attackers and defenders in real-world VCS applications. For attackers, ambient noise can diminish the effectiveness and reach of malicious audio. Conversely, for defenders, noise can interfere with the accuracy of defense mechanisms, such as liveness detection systems, as evidenced in <cite class="ltx_cite ltx_citemacro_citep">(Meng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib96" title="">2022</a>)</cite>. Thus, both parties must account for the impact of noise in their strategies, which adds another layer of complexity to the security landscape of VCS.</p>
</div>
</section>
<section class="ltx_subsection" id="S8.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2. </span>Future Directions</h3>
<div class="ltx_para" id="S8.SS2.p1">
<p class="ltx_p" id="S8.SS2.p1.1">The challenges identified in VCS security research open avenues for future work. To enhance the robustness of both attacks and defenses in practical scenarios, we propose the following directions:</p>
</div>
<div class="ltx_para" id="S8.SS2.p2">
<ul class="ltx_itemize" id="S8.I1">
<li class="ltx_item" id="S8.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S8.I1.i1.p1">
<p class="ltx_p" id="S8.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I1.i1.p1.1.1">Focus on Black-box Attack Scenarios:</span> With the rise of closed-source models in VCS, attackers in real-world scenarios should concentrate on executing successful black-box attacks. This could involve crafting adversarial perturbations specifically for black-box models or designing transferable adversarial perturbations that can be applied from a known white-box model to an unknown black-box model.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S8.I1.i2.p1">
<p class="ltx_p" id="S8.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I1.i2.p1.1.1">Targeting Combined ASR and SV Functions:</span> Modern VCS, such as Apple’s Siri, often integrate both Automatic Speech Recognition (ASR) and Speaker Verification (SV) functionalities. Attackers, therefore, need to develop malicious audio capable of simultaneously compromising both ASR and SV systems.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S8.I1.i3.p1">
<p class="ltx_p" id="S8.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I1.i3.p1.1.1">Optimizing Defense Schemes:</span> Future defense strategies should aim for high effectiveness while minimizing additional hardware requirements and system complexity. Leveraging existing device hardware for defense, as demonstrated in studies like <cite class="ltx_cite ltx_citemacro_citep">(Ahmed
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib7" title="">2020</a>; Meng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.17100v1#bib.bib96" title="">2022</a>)</cite>, could offer more practical and efficient solutions.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S8.I1.i4.p1">
<p class="ltx_p" id="S8.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I1.i4.p1.1.1">Establishing Unified Standards for Evaluation:</span> The development of a unified standard for assessing attacks and defense mechanisms in VCS is crucial. This standard would provide reliable and consistent evaluation metrics, akin to the Common Vulnerability Scoring System (CVSS), aiding VCS designers in accurately assessing the security landscape.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S8.SS2.p3">
<p class="ltx_p" id="S8.SS2.p3.1">These proposed directions aim to address the evolving landscape of VCS security, encouraging a balanced approach to unveiling sophisticated attacks and designing robust defenses.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9. </span>Conclusion</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">This paper offers a thorough and methodical examination of the security landscape in VCS. We introduce a hierarchical model structure, dividing VCS into four layers: physical, preprocessing, kernel, and service. Within this framework, we develop a threat model and meticulously analyze the security threats unique to each layer, including transduction, voice-synthesis, adversarial, spoofing, squatting attacks, and false termination. We not only identify and describe the characteristics of these threats but also assess existing defense mechanisms and propose effective defense strategy combinations to enhance VCS security. Additionally, the paper provides strategic recommendations for future research, underscoring the necessity for ongoing innovation in addressing the evolving security challenges in VCS.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sma (2023)</span>
<span class="ltx_bibblock">
2023.

</span>
<span class="ltx_bibblock">Smart Speakers Global Market Report 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.reportlinker.com/p06247523/Smart-Speakers-Global-Market-Report.html-utm-source-PRN" title="">https://www.reportlinker.com/p06247523/Smart-Speakers-Global-Market-Report.html-utm-source-PRN</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdel-Hamid et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2014)</span>
<span class="ltx_bibblock">
Ossama Abdel-Hamid,
Abdel-rahman Mohamed, Hui Jiang,
Li Deng, Gerald Penn, and
Dong Yu. 2014.

</span>
<span class="ltx_bibblock">Convolutional neural networks for speech
recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">IEEE/ACM Transactions on audio, speech, and
language processing</em> (2014).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdullah et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Hadi Abdullah, Washington
Garcia, Christian Peeters, Patrick
Traynor, Kevin RB Butler, and Joseph
Wilson. 2019.

</span>
<span class="ltx_bibblock">Practical hidden voice attacks against speech and
speaker recognition systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">arXiv preprint arXiv:1904.05734</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdullah et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2021a)</span>
<span class="ltx_bibblock">
Hadi Abdullah,
Muhammad Sajidur Rahman, Washington
Garcia, Kevin Warren, Anurag Swarnim
Yadav, Tom Shrimpton, and Patrick
Traynor. 2021a.

</span>
<span class="ltx_bibblock">Hear” no evil”, see” kenansville”: Efficient and
transferable black-box attacks on speech recognition and voice identification
systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">IEEE Symposium on Security and
Privacy</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdullah et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2021b)</span>
<span class="ltx_bibblock">
Hadi Abdullah, Kevin
Warren, Vincent Bindschaedler, Nicolas
Papernot, and Patrick Traynor.
2021b.

</span>
<span class="ltx_bibblock">Sok: The faults in our asrs: An overview of attacks
against automatic speech recognition and speaker identification systems. In
<em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">IEEE symposium on security and privacy</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmed
et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Muhammad Ejaz Ahmed,
Il-Youp Kwak, Jun Ho Huh,
Iljoo Kim, Taekkyung Oh, and
Hyoungshick Kim. 2020.

</span>
<span class="ltx_bibblock">Void: A fast and light voice liveness detection
system. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">29th USENIX Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmed et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Shimaa Ahmed, Yash Wani,
Jian Xiangyong, Mohammad Yaghini,
Ilia Shumailov, Nicolas Papernot, and
Kassem Fawaz. 2023.

</span>
<span class="ltx_bibblock">Tubes Among Us: Analog Attack on Automatic Speaker
Identification. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">USENIX Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alegre
et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Federico Alegre, Asmaa
Amehraye, and Nicholas Evans.
2013.

</span>
<span class="ltx_bibblock">Spoofing countermeasures to protect automatic
speaker verification from voice conversion. In
<em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">IEEE International Conference on Acoustics, Speech
and Signal Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alegre
et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Federico Alegre,
Ravichander Vipperla, and Nicholas
Evans. 2012.

</span>
<span class="ltx_bibblock">Spoofing countermeasures for the protection of
automatic speaker recognition systems against attacks with artificial
signals. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Thirteenth Annual Conference of the
International Speech Communication Association</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alzantot
et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Moustafa Alzantot,
Bharathan Balaji, and Mani Srivastava.
2018.

</span>
<span class="ltx_bibblock">Did you hear that? adversarial examples against
automatic speech recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">arXiv preprint arXiv:1801.00554</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andronic et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Iustina Andronic, Ludwig
Kürzinger, Edgar Ricardo Chavez Rosas,
Gerhard Rigoll, and Bernhard U Seeber.
2020.

</span>
<span class="ltx_bibblock">MP3 compression to diminish adversarial noise in
end-to-end speech recognition. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Speech and
Computer</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai
et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Yang Bai, Li Lu,
Jerry Cheng, Jian Liu,
Yingying Chen, and Jiadi Yu.
2020.

</span>
<span class="ltx_bibblock">Acoustic-based sensing and applications: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">Computer Networks</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">BBC (2017)</span>
<span class="ltx_bibblock">
BBC. 2017.

</span>
<span class="ltx_bibblock">BBC reporter fools bank voice-ID security.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.bbc.co.uk/news/technology-39973217" title="">https://www.bbc.co.uk/news/technology-39973217</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bińkowski et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Mikołaj Bińkowski,
Jeff Donahue, Sander Dieleman,
Aidan Clark, Erich Elsen,
Norman Casagrande, Luis C Cobo, and
Karen Simonyan. 2019.

</span>
<span class="ltx_bibblock">High fidelity speech synthesis with adversarial
networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">arXiv preprint arXiv:1909.11646</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bispham
et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Mary K Bispham, Ioannis
Agrafiotis, and Michael Goldsmith.
2019.

</span>
<span class="ltx_bibblock">Nonsense attacks on google assistant and missense
attacks on amazon alexa. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">International
Conference on Information Systems Security and Privacy</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blue
et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Logan Blue, Luis Vargas,
and Patrick Traynor. 2018.

</span>
<span class="ltx_bibblock">Hello, is it me you’re looking for? differentiating
between human and electronic speakers for voice interface security. In
<em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">ACM Conference on Security &amp; Privacy in Wireless
and Mobile Networks</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blue et al<span class="ltx_text" id="bib.bib18.4.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Logan Blue, Kevin Warren,
Hadi Abdullah, Cassidy Gibson,
Luis Vargas, Jessica O’Dell,
Kevin Butler, and Patrick Traynor.
2022.

</span>
<span class="ltx_bibblock">Who Are You I Really Wanna Know? Detecting Audio
<math alttext="\{" class="ltx_Math" display="inline" id="bib.bib18.1.m1.1"><semantics id="bib.bib18.1.m1.1a"><mo id="bib.bib18.1.m1.1.1" stretchy="false" xref="bib.bib18.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib18.1.m1.1b"><ci id="bib.bib18.1.m1.1.1.cmml" xref="bib.bib18.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib18.1.m1.1c">\{</annotation><annotation encoding="application/x-llamapun" id="bib.bib18.1.m1.1d">{</annotation></semantics></math>DeepFakes<math alttext="\}" class="ltx_Math" display="inline" id="bib.bib18.2.m2.1"><semantics id="bib.bib18.2.m2.1a"><mo id="bib.bib18.2.m2.1.1" stretchy="false" xref="bib.bib18.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib18.2.m2.1b"><ci id="bib.bib18.2.m2.1.1.cmml" xref="bib.bib18.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib18.2.m2.1c">\}</annotation><annotation encoding="application/x-llamapun" id="bib.bib18.2.m2.1d">}</annotation></semantics></math> Through Vocal Tract Reconstruction. In
<em class="ltx_emph ltx_font_italic" id="bib.bib18.5.1">USENIX Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Nicholas Carlini, Pratyush
Mishra, Tavish Vaidya, Yuankai Zhang,
Micah Sherr, Clay Shields,
David A Wagner, and Wenchao Zhou.
2016.

</span>
<span class="ltx_bibblock">Hidden voice commands.. In
<em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Usenix security symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini and
Wagner (2018)</span>
<span class="ltx_bibblock">
Nicholas Carlini and
David Wagner. 2018.

</span>
<span class="ltx_bibblock">Audio adversarial examples: Targeted attacks on
speech-to-text. In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">IEEE security and privacy
workshops</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang
et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Kuei-Huan Chang, Po-Hao
Huang, Honggang Yu, Yier Jin, and
Ting-Chi Wang. 2020.

</span>
<span class="ltx_bibblock">Audio adversarial examples generation with
recurrent neural networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Asia and South
Pacific Design Automation Conference</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Guangke Chen, Sen Chenb,
Lingling Fan, Xiaoning Du,
Zhe Zhao, Fu Song, and
Yang Liu. 2021.

</span>
<span class="ltx_bibblock">Who is real bob? adversarial attacks on speaker
recognition systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">IEEE Symposium on Security
and Privacy</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2010)</span>
<span class="ltx_bibblock">
Lian-Wu Chen, Wu Guo,
and Li-Rong Dai. 2010.

</span>
<span class="ltx_bibblock">Speaker verification against synthetic speech. In
<em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">International Symposium on Chinese Spoken Language
Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Si Chen, Kui Ren,
Sixu Piao, Cong Wang,
Qian Wang, Jian Weng, Lu
Su, and Aziz Mohaisen. 2017.

</span>
<span class="ltx_bibblock">You can hear but you cannot steal: Defending
against voice impersonation attacks on smartphones. In
<em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">IEEE international conference on distributed
computing systems</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
Tao Chen, Longfei
Shangguan, Zhenjiang Li, and Kyle
Jamieson. 2020a.

</span>
<span class="ltx_bibblock">Metamorph: Injecting inaudible commands into
over-the-air voice controlled systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Network
and Distributed Systems Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Yuxuan Chen, Xuejing
Yuan, Jiangshan Zhang, Yue Zhao,
Shengzhi Zhang, Kai Chen, and
XiaoFeng Wang. 2020b.

</span>
<span class="ltx_bibblock">Devil’s Whisper: A General Approach for Physical
Adversarial Attacks against Commercial Black-box Speech Recognition
Devices.. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">USENIX Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yuxuan Chen, Jiangshan
Zhang, Xuejing Yuan, Shengzhi Zhang,
Kai Chen, Xiaofeng Wang, and
Shanqing Guo. 2022.

</span>
<span class="ltx_bibblock">Sok: A modularized approach to study the security
of automatic speech recognition systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">ACM Transactions on Privacy and Security</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Long Cheng, Christin
Wilson, Song Liao, Jeffrey Young,
Daniel Dong, and Hongxin Hu.
2020.

</span>
<span class="ltx_bibblock">Dangerous skills got certified: Measuring the
trustworthiness of skill certification in voice personal assistant
platforms. In <em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">ACM SIGSAC Conference on Computer
and Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chorowski et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Jan K Chorowski, Dzmitry
Bahdanau, Dmitriy Serdyuk, Kyunghyun
Cho, and Yoshua Bengio.
2015.

</span>
<span class="ltx_bibblock">Attention-based models for speech recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">Advances in neural information processing
systems</em> (2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cisse
et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Moustapha M Cisse, Yossi
Adi, Natalia Neverova, and Joseph
Keshet. 2017.

</span>
<span class="ltx_bibblock">Houdini: Fooling deep structured visual and speech
recognition models with adversarial examples.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Advances in neural information processing
systems</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Donghui Dai, Zhenlin An,
and Lei Yang. 2022.

</span>
<span class="ltx_bibblock">Inducing wireless chargers to voice out for
inaudible command attacks. In <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">IEEE Symposium on
Security and Privacy</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Das et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Nilaksh Das, Madhuri
Shanbhogue, Shang-Tse Chen, Li Chen,
Michael E Kounavis, and Duen Horng
Chau. 2019.

</span>
<span class="ltx_bibblock">Adagio: Interactive experimentation with
adversarial attack and defense for audio. In
<em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">Machine Learning and Knowledge Discovery in
Databases: European Conference, ECML PKDD 2018, Dublin, Ireland, September
10–14, 2018, Proceedings, Part III 18</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Davidson et al<span class="ltx_text" id="bib.bib33.4.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Drew Davidson, Hao Wu,
Rob Jellinek, Vikas Singh, and
Thomas Ristenpart. 2016.

</span>
<span class="ltx_bibblock">Controlling <math alttext="\{" class="ltx_Math" display="inline" id="bib.bib33.1.m1.1"><semantics id="bib.bib33.1.m1.1a"><mo id="bib.bib33.1.m1.1.1" stretchy="false" xref="bib.bib33.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib33.1.m1.1b"><ci id="bib.bib33.1.m1.1.1.cmml" xref="bib.bib33.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib33.1.m1.1c">\{</annotation><annotation encoding="application/x-llamapun" id="bib.bib33.1.m1.1d">{</annotation></semantics></math>UAVs<math alttext="\}" class="ltx_Math" display="inline" id="bib.bib33.2.m2.1"><semantics id="bib.bib33.2.m2.1a"><mo id="bib.bib33.2.m2.1.1" stretchy="false" xref="bib.bib33.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib33.2.m2.1b"><ci id="bib.bib33.2.m2.1.1.cmml" xref="bib.bib33.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib33.2.m2.1c">\}</annotation><annotation encoding="application/x-llamapun" id="bib.bib33.2.m2.1d">}</annotation></semantics></math> with Sensor Input Spoofing
Attacks. In <em class="ltx_emph ltx_font_italic" id="bib.bib33.5.1">10th USENIX workshop on offensive
technologies</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De Leon et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2012a)</span>
<span class="ltx_bibblock">
Phillip L De Leon, Michael
Pucher, Junichi Yamagishi, Inma Hernaez,
and Ibon Saratxaga. 2012a.

</span>
<span class="ltx_bibblock">Evaluation of speaker verification security and
detection of HMM-based synthetic speech.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">IEEE Transactions on Audio, Speech, and
Language Processing</em> (2012).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De Leon
et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2012b)</span>
<span class="ltx_bibblock">
Phillip L De Leon, Bryan
Stewart, and Junichi Yamagishi.
2012b.

</span>
<span class="ltx_bibblock">Synthetic Speech Discrimination using Pitch Pattern
Statistics Derived from Image Analysis.. In
<em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">Interspeech</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng
et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jiangyi Deng, Yanjiao
Chen, Yinan Zhong, Qianhao Miao,
Xueluan Gong, and Weyuan Xu.
2023.

</span>
<span class="ltx_bibblock">CATCH YOU AND I CAN: Revealing Source Voiceprint
Against Voice Conversion. In <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">USENIX Security
Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Desai et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2009)</span>
<span class="ltx_bibblock">
Srinivas Desai, E Veera
Raghavendra, B Yegnanarayana, Alan W
Black, and Kishore Prahallad.
2009.

</span>
<span class="ltx_bibblock">Voice conversion using artificial neural networks.
In <em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">IEEE International Conference on Acoustics</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin
et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei
Chang, Kenton Lee, and Kristina
Toutanova. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional
transformers for language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">arXiv preprint arXiv:1810.04805</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du
et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Tianyu Du, Shouling Ji,
Jinfeng Li, Qinchen Gu,
Ting Wang, and Raheem Beyah.
2020.

</span>
<span class="ltx_bibblock">Sirenattack: Generating adversarial audio for
end-to-end acoustic systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">Proceedings of the
15th ACM Asia Conference on Computer and Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Edu
et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Jide S Edu, Jose M Such,
and Guillermo Suarez-Tangil.
2020.

</span>
<span class="ltx_bibblock">Smart home personal assistants: a security and
privacy review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">Comput. Surveys</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ergünay et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Serife Kucur Ergünay,
Elie Khoury, Alexandros Lazaridis, and
Sebastien Marcel. 2015.

</span>
<span class="ltx_bibblock">On the vulnerability of speaker verification to
realistic voice spoofing. In <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">International
Conference on Biometrics Theory</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Evans
et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Nicholas WD Evans, Tomi
Kinnunen, and Junichi Yamagishi.
2013.

</span>
<span class="ltx_bibblock">Spoofing and countermeasures for automatic speaker
verification.. In <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Interspeech</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Farrús et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2008)</span>
<span class="ltx_bibblock">
Mireia Farrús, Michael
Wagner, Jan Anguita, and Javier
Hernando. 2008.

</span>
<span class="ltx_bibblock">How vulnerable are prosodic features to
professional imitators?. In <em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">The Speaker and
Language Recognition Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fawzi
et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Alhussein Fawzi, Hamza
Fawzi, and Omar Fawzi. 2018.

</span>
<span class="ltx_bibblock">Adversarial vulnerability for any classifier.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">Advances in neural information processing
systems</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng
et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Huan Feng, Kassem Fawaz,
and Kang G Shin. 2017.

</span>
<span class="ltx_bibblock">Continuous authentication for voice assistants. In
<em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">International Conference on Mobile Computing and
Networking</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghorbandoost et al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Mostafa Ghorbandoost,
Abolghasem Sayadiyan, Mohsen Ahangar,
Hamid Sheikhzadeh, Abdoreza Sabzi
Shahrebabaki, and Jamal Amini.
2015.

</span>
<span class="ltx_bibblock">Voice conversion based on feature combination with
limited training data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">Speech Communication</em>
(2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2019b)</span>
<span class="ltx_bibblock">
Taesik Gong, Alberto
Gil CP Ramos, Sourav Bhattacharya, Akhil
Mathur, and Fahim Kawsar.
2019b.

</span>
<span class="ltx_bibblock">AudiDoS: Real-Time denial-of-service adversarial
attacks on deep audio models. In <em class="ltx_emph ltx_font_italic" id="bib.bib47.3.1">2019 18th IEEE
International Conference on Machine Learning and Applications</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong
et al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2019a)</span>
<span class="ltx_bibblock">
Yuan Gong, Boyang Li,
Christian Poellabauer, and Yiyu Shi.
2019a.

</span>
<span class="ltx_bibblock">Real-time adversarial attacks. In
<em class="ltx_emph ltx_font_italic" id="bib.bib48.3.1">International Joint Conference on Artificial
Intelligence</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong and
Poellabauer (2018a)</span>
<span class="ltx_bibblock">
Yuan Gong and Christian
Poellabauer. 2018a.

</span>
<span class="ltx_bibblock">An overview of vulnerabilities of voice controlled
systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:1803.09156</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong and
Poellabauer (2018b)</span>
<span class="ltx_bibblock">
Yuan Gong and Christian
Poellabauer. 2018b.

</span>
<span class="ltx_bibblock">Protecting voice controlled systems using sound
source identification based on acoustic cues. In
<em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">International Conference on Computer Communication
and Networks</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong
et al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Yuan Gong, Jian Yang,
and Christian Poellabauer.
2020.

</span>
<span class="ltx_bibblock">Detecting replay attacks using multi-channel audio:
A neural network-based method.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">IEEE Signal Processing Letters</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow
et al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> (2014)</span>
<span class="ltx_bibblock">
Ian J Goodfellow, Jonathon
Shlens, and Christian Szegedy.
2014.

</span>
<span class="ltx_bibblock">Explaining and harnessing adversarial examples. In
<em class="ltx_emph ltx_font_italic" id="bib.bib52.3.1">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves (2012)</span>
<span class="ltx_bibblock">
Alex Graves.
2012.

</span>
<span class="ltx_bibblock">Sequence transduction with recurrent neural
networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv preprint arXiv:1211.3711</em>
(2012).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves et al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2006)</span>
<span class="ltx_bibblock">
Alex Graves, Santiago
Fernández, Faustino Gomez, and
Jürgen Schmidhuber. 2006.

</span>
<span class="ltx_bibblock">Connectionist temporal classification: labelling
unsegmented sequence data with recurrent neural networks. In
<em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">Proceedings of the 23rd international conference on
Machine learning</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo
et al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Hanqing Guo, Yuanda Wang,
Nikolay Ivanov, Li Xiao, and
Qiben Yan. 2022.

</span>
<span class="ltx_bibblock">Specpatch: Human-in-the-loop adversarial audio
spectrogram patch attack on speech recognition. In
<em class="ltx_emph ltx_font_italic" id="bib.bib55.3.1">2022 ACM SIGSAC Conference on Computer and
Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo
et al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Qingli Guo, Jing Ye,
Yiran Chen, Yu Hu, Yazhu
Lan, Guohe Zhang, and Xiaowei Li.
2020b.

</span>
<span class="ltx_bibblock">INOR—An Intelligent noise reduction method to
defend against adversarial audio examples.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">Neurocomputing</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo
et al<span class="ltx_text" id="bib.bib57.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
Zhixiu Guo, Zijin Lin,
Pan Li, and Kai Chen.
2020a.

</span>
<span class="ltx_bibblock">Skillexplorer: Understanding the behavior of skills
in large scale. In <em class="ltx_emph ltx_font_italic" id="bib.bib57.3.1">USENIX Conference on Security
Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hai and Joo (2003)</span>
<span class="ltx_bibblock">
Jiang Hai and Er Meng
Joo. 2003.

</span>
<span class="ltx_bibblock">Improved linear predictive coding method for speech
recognition. In <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">international conference on
information, communications and signal processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al<span class="ltx_text" id="bib.bib59.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Joon Kuy Han, Hyoungshick
Kim, and Simon S Woo. 2019.

</span>
<span class="ltx_bibblock">Nickel to LEGO: using Foolgle to create adversarial
examples to fool Google cloud speech-to-text API. In
<em class="ltx_emph ltx_font_italic" id="bib.bib59.3.1">ACM SIGSAC Conference on Computer and
Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hartpence (2013)</span>
<span class="ltx_bibblock">
Bruce Hartpence.
2013.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Packet Guide to Voice over IP: A system
administrator’s guide to VoIP technologies</em>.

</span>
<span class="ltx_bibblock">” O’Reilly Media, Inc.”.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hautamäki et al<span class="ltx_text" id="bib.bib61.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Rosa González Hautamäki,
Tomi Kinnunen, Ville Hautamäki,
Timo Leino, and Anne-Maria Laukkanen.
2013.

</span>
<span class="ltx_bibblock">I-vectors meet imitators: on vulnerability of
speaker verification systems against voice mimicry.. In
<em class="ltx_emph ltx_font_italic" id="bib.bib61.3.1">Interspeech</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He
et al<span class="ltx_text" id="bib.bib62.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Yitao He, Junyu Bian,
Xinyu Tong, Zihui Qian,
Wei Zhu, Xiaohua Tian, and
Xinbing Wang. 2019.

</span>
<span class="ltx_bibblock">Canceling inaudible voice commands against voice
control systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib62.3.1">International Conference on
Mobile Computing and Networking</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hunt and Black (1996)</span>
<span class="ltx_bibblock">
Andrew J Hunt and Alan W
Black. 1996.

</span>
<span class="ltx_bibblock">Unit selection in a concatenative speech synthesis
system using a large speech database. In
<em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">International Conference on Acoustics, Speech, and
Signal Processing Conference Proceedings</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iijima et al<span class="ltx_text" id="bib.bib64.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Ryo Iijima, Shota Minami,
Zhou Yunao, Tatsuya Takehisa,
Takeshi Takahashi, Yasuhiro Oikawa, and
Tatsuya Mori. 2018.

</span>
<span class="ltx_bibblock">Audio hotspot attack: An attack on voice assistance
systems using directional sound beams. In
<em class="ltx_emph ltx_font_italic" id="bib.bib64.3.1">Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iter
et al<span class="ltx_text" id="bib.bib65.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Dan Iter, Jade Huang,
and Mike Jermann. 2017.

</span>
<span class="ltx_bibblock">Generating adversarial examples for speech
recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.3.1">Stanford Technical Report</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jannati and
Sayadiyan (2018)</span>
<span class="ltx_bibblock">
Mohammad Javad Jannati and
Abolghasem Sayadiyan. 2018.

</span>
<span class="ltx_bibblock">Part-syllable transformation-based voice conversion
with very limited training data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">Circuits, Systems, and Signal Processing</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jelil
et al<span class="ltx_text" id="bib.bib67.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Sarfaraz Jelil, Sishir
Kalita, SR Mahadeva Prasanna, and Rohit
Sinha. 2018.

</span>
<span class="ltx_bibblock">Exploration of Compressed ILPR Features for Replay
Attack Detection.. In <em class="ltx_emph ltx_font_italic" id="bib.bib67.3.1">Interspeech</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji
et al<span class="ltx_text" id="bib.bib68.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Xiaoyu Ji, Juchuan Zhang,
Shui Jiang, Jishen Li, and
Wenyuan Xu. 2021.

</span>
<span class="ltx_bibblock">CapSpeaker: Injecting Voices to Microphones via
Capacitors. In <em class="ltx_emph ltx_font_italic" id="bib.bib68.3.1">Proceedings of the 2021 ACM SIGSAC
Conference on Computer and Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kamble
et al<span class="ltx_text" id="bib.bib69.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Madhu R Kamble, Hemlata
Tak, and Hemant A Patil.
2018.

</span>
<span class="ltx_bibblock">Effectiveness of Speech Demodulation-Based Features
for Replay Detection.. In <em class="ltx_emph ltx_font_italic" id="bib.bib69.3.1">Interspeech</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kasmi and Esteves (2015)</span>
<span class="ltx_bibblock">
Chaouki Kasmi and
Jose Lopes Esteves. 2015.

</span>
<span class="ltx_bibblock">IEMI threats for information security: Remote
command injection on modern smartphones.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">IEEE Transactions on Electromagnetic
Compatibility</em> (2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kennedy and
Eberhart (1995)</span>
<span class="ltx_bibblock">
James Kennedy and
Russell Eberhart. 1995.

</span>
<span class="ltx_bibblock">Particle swarm optimization. In
<em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">ICNN’95-international conference on neural
networks</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kersta and
Colangelo (1970)</span>
<span class="ltx_bibblock">
LG Kersta and JA
Colangelo. 1970.

</span>
<span class="ltx_bibblock">Spectrographic speech patterns of identical twins.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">The Journal of the Acoustical Society of
America</em> (1970).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khare
et al<span class="ltx_text" id="bib.bib73.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Shreya Khare, Rahul
Aralikatte, and Senthil Mani.
2019.

</span>
<span class="ltx_bibblock">Adversarial black-box attacks on automatic speech
recognition systems using multi-objective evolutionary optimization. In
<em class="ltx_emph ltx_font_italic" id="bib.bib73.3.1">Annual Conference of the International Speech
Communication Association</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al<span class="ltx_text" id="bib.bib74.2.2.1">.</span> (1997)</span>
<span class="ltx_bibblock">
Eun-Kyoung Kim, Sangho
Lee, and Yung-Hwan Oh. 1997.

</span>
<span class="ltx_bibblock">Hidden Markov model based voice conversion using
dynamic characteristics of speaker. In <em class="ltx_emph ltx_font_italic" id="bib.bib74.3.1">European
Conference On Speech Communication And Technology</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kinnunen et al<span class="ltx_text" id="bib.bib75.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Tomi Kinnunen, Md
Sahidullah, Héctor Delgado,
Massimiliano Todisco, Nicholas Evans,
Junichi Yamagishi, and Kong Aik Lee.
2017.

</span>
<span class="ltx_bibblock">The ASVspoof 2017 challenge: Assessing the limits
of replay spoofing attack detection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib75.3.1">International Speech Communication
Association)</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kreuk
et al<span class="ltx_text" id="bib.bib76.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Felix Kreuk, Yossi Adi,
Moustapha Cisse, and Joseph Keshet.
2018.

</span>
<span class="ltx_bibblock">Fooling end-to-end speaker verification with
adversarial examples. In <em class="ltx_emph ltx_font_italic" id="bib.bib76.3.1">IEEE international
conference on acoustics, speech and signal processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et al<span class="ltx_text" id="bib.bib77.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Deepak Kumar, Riccardo
Paccagnella, Paul Murley, Eric
Hennenfent, Joshua Mason, Adam Bates,
and Michael Bailey. 2018.

</span>
<span class="ltx_bibblock">Skill squatting attacks on Amazon Alexa. In
<em class="ltx_emph ltx_font_italic" id="bib.bib77.3.1">USENIX Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kurakin
et al<span class="ltx_text" id="bib.bib78.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Alexey Kurakin, Ian J
Goodfellow, and Samy Bengio.
2018.

</span>
<span class="ltx_bibblock">Adversarial examples in the physical world.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib78.3.1">Artificial intelligence safety and
security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwon
et al<span class="ltx_text" id="bib.bib79.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Hyun Kwon, Yongchul Kim,
Hyunsoo Yoon, and Daeseon Choi.
2019.

</span>
<span class="ltx_bibblock">Selective audio adversarial example in evasion
attack on speech recognition system.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib79.3.1">IEEE Transactions on Information Forensics
and Security</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lau
et al<span class="ltx_text" id="bib.bib80.2.2.1">.</span> (2005)</span>
<span class="ltx_bibblock">
Yee W Lau, Dat Tran,
and Michael Wagner. 2005.

</span>
<span class="ltx_bibblock">Testing voice mimicry with the YOHO speaker
verification corpus. In <em class="ltx_emph ltx_font_italic" id="bib.bib80.3.1">Knowledge-Based
Intelligent Information and Engineering Systems</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lau
et al<span class="ltx_text" id="bib.bib81.2.2.1">.</span> (2004)</span>
<span class="ltx_bibblock">
Yee Wah Lau, Michael
Wagner, and Dat Tran. 2004.

</span>
<span class="ltx_bibblock">Vulnerability of speaker verification to voice
mimicking. In <em class="ltx_emph ltx_font_italic" id="bib.bib81.3.1">International Symposium on
Intelligent Multimedia</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span class="ltx_text" id="bib.bib82.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Juncheng Li, Shuhui Qu,
Xinjian Li, Joseph Szurley,
J Zico Kolter, and Florian Metze.
2019.

</span>
<span class="ltx_bibblock">Adversarial music: Real world audio adversary
against wake-word detection system.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib82.3.1">Advances in Neural Information Processing
Systems</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib83.2.2.1">.</span> (2020c)</span>
<span class="ltx_bibblock">
Jiguo Li, Xinfeng Zhang,
Chuanmin Jia, Jizheng Xu,
Li Zhang, Yue Wang,
Siwei Ma, and Wen Gao.
2020c.

</span>
<span class="ltx_bibblock">Universal adversarial perturbations generative
network for speaker recognition. In <em class="ltx_emph ltx_font_italic" id="bib.bib83.3.1">IEEE
International Conference on Multimedia and Expo</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span class="ltx_text" id="bib.bib84.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jiguo Li, Xinfeng Zhang,
Jizheng Xu, Siwei Ma, and
Wen Gao. 2021.

</span>
<span class="ltx_bibblock">Learning to fool the speaker recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib84.3.1">ACM Transactions on Multimedia Computing,
Communications, and Applications</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span class="ltx_text" id="bib.bib85.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xinfeng Li, Xiaoyu Ji,
Chen Yan, Chaohao Li,
Yichen Li, Zhenning Zhang, and
Weyuan Xu. 2023.

</span>
<span class="ltx_bibblock">Learning Normality is Enough: A Software-based
Mitigation against Inaudible Voice Attacks. In
<em class="ltx_emph ltx_font_italic" id="bib.bib85.3.1">USENIX Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span class="ltx_text" id="bib.bib86.2.2.1">.</span> (2020d)</span>
<span class="ltx_bibblock">
Xu Li, Jinghua Zhong,
Xixin Wu, Jianwei Yu,
Xunying Liu, and Helen Meng.
2020d.

</span>
<span class="ltx_bibblock">Adversarial attacks on GMM i-vector based speaker
verification systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib86.3.1">IEEE International
Conference on Acoustics, Speech and Signal Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span class="ltx_text" id="bib.bib87.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
Zhuohang Li, Cong Shi,
Yi Xie, Jian Liu, Bo
Yuan, and Yingying Chen.
2020a.

</span>
<span class="ltx_bibblock">Practical adversarial attacks against speaker
recognition systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib87.3.1">international workshop on
mobile computing systems and applications</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span class="ltx_text" id="bib.bib88.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Zhuohang Li, Yi Wu,
Jian Liu, Yingying Chen, and
Bo Yuan. 2020b.

</span>
<span class="ltx_bibblock">Advpulse: Universal, synchronization-free, and
targeted audio adversarial attacks via subsecond perturbations. In
<em class="ltx_emph ltx_font_italic" id="bib.bib88.3.1">ACM SIGSAC Conference on Computer and
Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lindberg and
Blomberg (1999)</span>
<span class="ltx_bibblock">
Johan Lindberg and Mats
Blomberg. 1999.

</span>
<span class="ltx_bibblock">Vulnerability in speaker verification-a study of
technical impostor techniques. In <em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">European
conference on speech communication and technology</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib90.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Han Liu, Zhiyuan Yu,
Mingming Zha, XiaoFeng Wang,
William Yeoh, Yevgeniy Vorobeychik, and
Ning Zhang. 2022.

</span>
<span class="ltx_bibblock">When evil calls: Targeted adversarial voice over ip
network. In <em class="ltx_emph ltx_font_italic" id="bib.bib90.3.1">ACM SIGSAC Conference on Computer and
Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
et al<span class="ltx_text" id="bib.bib91.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiaolei Liu, Kun Wan,
Yufei Ding, Xiaosong Zhang, and
Qingxin Zhu. 2020.

</span>
<span class="ltx_bibblock">Weighted-sampling audio adversarial example
attack. In <em class="ltx_emph ltx_font_italic" id="bib.bib91.3.1">AAAI Conference on Artificial
Intelligence</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madry et al<span class="ltx_text" id="bib.bib92.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Aleksander Madry,
Aleksandar Makelov, Ludwig Schmidt,
Dimitris Tsipras, and Adrian Vladu.
2018.

</span>
<span class="ltx_bibblock">Towards deep learning models resistant to
adversarial attacks. In <em class="ltx_emph ltx_font_italic" id="bib.bib92.3.1">International Conference
on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mariéthoz and
Bengio (2005)</span>
<span class="ltx_bibblock">
Johnny Mariéthoz and
Samy Bengio. 2005.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">Can a professional imitator fool a
GMM-based speaker verification system?</em>
</span>
<span class="ltx_bibblock">Technical Report. IDIAP.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marras et al<span class="ltx_text" id="bib.bib94.3.3.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Mirko Marras, Pawel
Korus, Nasir D Memon, Gianni Fenu,
et al<span class="ltx_text" id="bib.bib94.4.1">.</span> 2019.

</span>
<span class="ltx_bibblock">Adversarial Optimization for Dictionary Attacks on
Speaker Verification.. In <em class="ltx_emph ltx_font_italic" id="bib.bib94.5.1">Interspeech</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">May (2005)</span>
<span class="ltx_bibblock">
Matt May. 2005.

</span>
<span class="ltx_bibblock">Inaccessibility of CAPTCHA: Alternatives to Visual
Turing Tests on the Web.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.w3.org/TR/turingtest/" title="">https://www.w3.org/TR/turingtest/</a>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et al<span class="ltx_text" id="bib.bib96.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yan Meng, Jiachun Li,
Matthew Pillari, Arjun Deopujari,
Liam Brennan, Hafsah Shamsie,
Haojin Zhu, and Yuan Tian.
2022.

</span>
<span class="ltx_bibblock">Your microphone array retains your identity: A
robust voice liveness detection system for smart speaker. In
<em class="ltx_emph ltx_font_italic" id="bib.bib96.3.1">USENIX Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et al<span class="ltx_text" id="bib.bib97.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Yan Meng, Zichang Wang,
Wei Zhang, Peilin Wu,
Haojin Zhu, Xiaohui Liang, and
Yao Liu. 2018.

</span>
<span class="ltx_bibblock">Wivo: Enhancing the security of voice control
system via wireless signal in iot environment. In
<em class="ltx_emph ltx_font_italic" id="bib.bib97.3.1">ACM international symposium on mobile ad hoc
networking and computing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mikolov
et al<span class="ltx_text" id="bib.bib98.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Tomas Mikolov, Kai Chen,
Greg Corrado, and Jeffrey Dean.
2013.

</span>
<span class="ltx_bibblock">Efficient estimation of word representations in
vector space.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib98.3.1">arXiv preprint arXiv:1301.3781</em>
(2013).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mochizuki
et al<span class="ltx_text" id="bib.bib99.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Shihono Mochizuki, Sayaka
Shiota, and Hitoshi Kiya.
2018.

</span>
<span class="ltx_bibblock">Voice liveness detection using phoneme-based
pop-noise detector for speaker verifcation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib99.3.1">Threshold</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nassif et al<span class="ltx_text" id="bib.bib100.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Ali Bou Nassif, Ismail
Shahin, Imtinan Attili, Mohammad Azzeh,
and Khaled Shaalan. 2019.

</span>
<span class="ltx_bibblock">Speech recognition using deep neural networks: A
systematic review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib100.3.1">IEEE access</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neekhara et al<span class="ltx_text" id="bib.bib101.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Paarth Neekhara, Shehzeen
Hussain, Prakhar Pandey, Shlomo Dubnov,
Julian J. McAuley, and Farinaz
Koushanfar. 2019.

</span>
<span class="ltx_bibblock">Universal Adversarial Perturbations for Speech
Recognition Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib101.3.1">International Speech
Communication Association</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ogihara
et al<span class="ltx_text" id="bib.bib102.2.2.1">.</span> (2005)</span>
<span class="ltx_bibblock">
Akio Ogihara, Hitoshi
Unno, and Akira Shiozaki.
2005.

</span>
<span class="ltx_bibblock">Discrimination method of synthetic speech using
pitch frequency against synthetic speech falsification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib102.3.1">IEICE transactions on fundamentals of
electronics, communications and computer sciences</em> (2005).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oord
et al<span class="ltx_text" id="bib.bib103.3.3.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Aaron Oord, Yazhe Li,
Igor Babuschkin, Karen Simonyan,
Oriol Vinyals, Koray Kavukcuoglu,
George Driessche, Edward Lockhart,
Luis Cobo, Florian Stimberg,
et al<span class="ltx_text" id="bib.bib103.4.1">.</span> 2018.

</span>
<span class="ltx_bibblock">Parallel wavenet: Fast high-fidelity speech
synthesis. In <em class="ltx_emph ltx_font_italic" id="bib.bib103.5.1">International conference on machine
learning</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pascual
et al<span class="ltx_text" id="bib.bib104.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Santiago Pascual, Antonio
Bonafonte, and Joan Serra.
2017.

</span>
<span class="ltx_bibblock">SEGAN: Speech enhancement generative adversarial
network.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib104.3.1">arXiv preprint arXiv:1703.09452</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patil
et al<span class="ltx_text" id="bib.bib105.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Ankur T Patil, Rajul
Acharya, Pulikonda Krishna Aditya Sai, and
Hemant A Patil. 2019.

</span>
<span class="ltx_bibblock">Energy Separation-Based Instantaneous Frequency
Estimation for Cochlear Cepstral Feature for Replay Spoof Detection.. In
<em class="ltx_emph ltx_font_italic" id="bib.bib105.3.1">Interspeech</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patil and Parhi (2009)</span>
<span class="ltx_bibblock">
Hemant A Patil and
Keshab K Parhi. 2009.

</span>
<span class="ltx_bibblock">Variable length Teager energy based mel cepstral
features for identification of twins. In <em class="ltx_emph ltx_font_italic" id="bib.bib106.1.1">Pattern
Recognition and Machine Intelligence</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pradhan
et al<span class="ltx_text" id="bib.bib107.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Swadhin Pradhan, Wei Sun,
Ghufran Baig, and Lili Qiu.
2019.

</span>
<span class="ltx_bibblock">Combating replay attacks against voice assistants.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib107.3.1">ACM on Interactive, Mobile, Wearable and
Ubiquitous Technologies</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi
et al<span class="ltx_text" id="bib.bib108.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xia Qi, Chen Qian, and
Xu Shouhuai. 2023.

</span>
<span class="ltx_bibblock">Near-Ultrasound lnaudible Trojan(NUIT): Exploiting
Your Speaker toAttack Your Microphone. In <em class="ltx_emph ltx_font_italic" id="bib.bib108.3.1">USENIX
Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qian
et al<span class="ltx_text" id="bib.bib109.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Yao Qian, Frank K Soong,
and Zhi-Jie Yan. 2012.

</span>
<span class="ltx_bibblock">A unified trajectory tiling approach to high
quality speech rendering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib109.3.1">IEEE transactions on audio, speech, and
language processing</em> (2012).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin et al<span class="ltx_text" id="bib.bib110.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Yao Qin, Nicholas
Carlini, Garrison Cottrell, Ian
Goodfellow, and Colin Raffel.
2019.

</span>
<span class="ltx_bibblock">Imperceptible, robust, and targeted adversarial
examples for automatic speech recognition. In
<em class="ltx_emph ltx_font_italic" id="bib.bib110.3.1">International conference on machine learning</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rabiner and Juang (1993)</span>
<span class="ltx_bibblock">
Lawrence Rabiner and
Biing-Hwang Juang. 1993.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib111.1.1">Fundamentals of speech recognition</em>.

</span>
<span class="ltx_bibblock">Prentice-Hall, Inc.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rabiner (1978)</span>
<span class="ltx_bibblock">
Lawrence R Rabiner.
1978.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib112.1.1">Digital processing of speech signals</em>.

</span>
<span class="ltx_bibblock">Pearson Education India.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajaratnam
et al<span class="ltx_text" id="bib.bib113.2.2.1">.</span> (2018a)</span>
<span class="ltx_bibblock">
Krishan Rajaratnam,
Basemah Alshemali, and J Kalita.
2018a.

</span>
<span class="ltx_bibblock">Speech coding and audio preprocessing for
mitigating and detecting audio adversarial examples on automatic speech
recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib113.3.1">Rajaratnam. pdf</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajaratnam
et al<span class="ltx_text" id="bib.bib114.2.2.1">.</span> (2018b)</span>
<span class="ltx_bibblock">
Krishan Rajaratnam, Kunal
Shah, and Jugal Kalita.
2018b.

</span>
<span class="ltx_bibblock">Isolated and ensemble audio preprocessing methods
for detecting adversarial examples against automatic speech recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib114.3.1">arXiv preprint arXiv:1809.04397</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramirez
et al<span class="ltx_text" id="bib.bib115.2.2.1">.</span> (2007)</span>
<span class="ltx_bibblock">
Javier Ramirez,
Juan Manuel Górriz, and
José Carlos Segura. 2007.

</span>
<span class="ltx_bibblock">Voice activity detection. fundamentals and speech
recognition system robustness.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib115.3.1">Robust speech recognition and understanding</em>
(2007).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy
et al<span class="ltx_text" id="bib.bib116.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Nirupam Roy, Sheng Shen,
Haitham Hassanieh, and Romit Roy
Choudhury. 2018.

</span>
<span class="ltx_bibblock">Inaudible Voice Commands: The Long-Range Attack and
Defense. In <em class="ltx_emph ltx_font_italic" id="bib.bib116.3.1">USENIX Symposium on Networked Systems
Design and Implementation</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ryant
et al<span class="ltx_text" id="bib.bib117.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Neville Ryant, Mark
Liberman, and Jiahong Yuan.
2013.

</span>
<span class="ltx_bibblock">Speech activity detection on youtube using deep
neural networks.. In <em class="ltx_emph ltx_font_italic" id="bib.bib117.3.1">INTERSPEECH</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sahidullah et al<span class="ltx_text" id="bib.bib118.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Md Sahidullah, Dennis
Alexander Lehmann Thomsen, Rosa Gonzalez Hautamäki,
Tomi Kinnunen, Zheng-Hua Tan,
Robert Parts, and Martti Pitkänen.
2017.

</span>
<span class="ltx_bibblock">Robust voice liveness detection and speaker
verification using throat microphones.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib118.3.1">IEEE/ACM Transactions on Audio, Speech, and
Language Processing</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sainath
et al<span class="ltx_text" id="bib.bib119.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Tara N Sainath, Oriol
Vinyals, Andrew Senior, and Haşim
Sak. 2015.

</span>
<span class="ltx_bibblock">Convolutional, long short-term memory, fully
connected deep neural networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib119.3.1">IEEE
international conference on acoustics, speech and signal processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saito
et al<span class="ltx_text" id="bib.bib120.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Yuki Saito, Shinnosuke
Takamichi, and Hiroshi Saruwatari.
2017.

</span>
<span class="ltx_bibblock">Statistical parametric speech synthesis
incorporating generative adversarial networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib120.3.1">IEEE/ACM Transactions on Audio, Speech, and
Language Processing</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Satoh
et al<span class="ltx_text" id="bib.bib121.2.2.1">.</span> (2001)</span>
<span class="ltx_bibblock">
Takayuki Satoh, Takashi
Masuko, Takao Kobayashi, and Keiichi
Tokuda. 2001.

</span>
<span class="ltx_bibblock">A robust speaker verification system against
imposture using an HMM-based speech synthesis system. In
<em class="ltx_emph ltx_font_italic" id="bib.bib121.3.1">Seventh European Conference on Speech Communication
and Technology</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schönherr et al<span class="ltx_text" id="bib.bib122.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Lea Schönherr,
Thorsten Eisenhofer, Steffen Zeiler,
Thorsten Holz, and Dorothea Kolossa.
2020.

</span>
<span class="ltx_bibblock">Imperio: Robust over-the-air adversarial examples
for automatic speech recognition systems. In
<em class="ltx_emph ltx_font_italic" id="bib.bib122.3.1">Annual Computer Security Applications Conference</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schönherr et al<span class="ltx_text" id="bib.bib123.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Lea Schönherr,
Katharina Kohls, Steffen Zeiler,
Thorsten Holz, and Dorothea Kolossa.
2018.

</span>
<span class="ltx_bibblock">Adversarial attacks against automatic speech
recognition systems via psychoacoustic hiding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib123.3.1">arXiv preprint arXiv:1808.05665</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schönherr et al<span class="ltx_text" id="bib.bib124.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Lea Schönherr,
Katharina Kohls, Steffen Zeiler,
Thorsten Holz, and Dorothea Kolossa.
2019.

</span>
<span class="ltx_bibblock">Adversarial Attacks Against Automatic Speech
Recognition Systems via Psychoacoustic Hiding. In
<em class="ltx_emph ltx_font_italic" id="bib.bib124.3.1">Network and Distributed System Security
Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shamsabadi et al<span class="ltx_text" id="bib.bib125.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Ali Shahin Shamsabadi,
Francisco Sepúlveda Teixeira, Alberto
Abad, Bhiksha Raj, Andrea Cavallaro,
and Isabel Trancoso. 2021.

</span>
<span class="ltx_bibblock">FoolHD: Fooling Speaker Identification by Highly
Imperceptible Adversarial Disturbances. In <em class="ltx_emph ltx_font_italic" id="bib.bib125.3.1">IEEE
International Conference on Acoustics, Speech and Signal Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shang
et al<span class="ltx_text" id="bib.bib126.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Jiacheng Shang, Si Chen,
and Jie Wu. 2018.

</span>
<span class="ltx_bibblock">Defending against voice spoofing: A robust
software-based liveness detection system. In <em class="ltx_emph ltx_font_italic" id="bib.bib126.3.1">IEEE
International Conference on Mobile Ad Hoc and Sensor Systems</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shang and Wu (2019)</span>
<span class="ltx_bibblock">
Jiacheng Shang and Jie
Wu. 2019.

</span>
<span class="ltx_bibblock">Enabling secure voice input on augmented reality
headsets using internal body voice. In <em class="ltx_emph ltx_font_italic" id="bib.bib127.1.1">IEEE
International Conference on Sensing, Communication, and Networking</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shang and Wu (2020a)</span>
<span class="ltx_bibblock">
Jiacheng Shang and Jie
Wu. 2020a.

</span>
<span class="ltx_bibblock">Secure voice input on augmented reality headsets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib128.1.1">IEEE Transactions on Mobile Computing</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shang and Wu (2020b)</span>
<span class="ltx_bibblock">
Jiacheng Shang and Jie
Wu. 2020b.

</span>
<span class="ltx_bibblock">Voice liveness detection for voice assistants using
ear canal pressure. In <em class="ltx_emph ltx_font_italic" id="bib.bib129.1.1">International Conference on
Mobile Ad Hoc and Sensor Systems</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shang and
Stevenson (2010)</span>
<span class="ltx_bibblock">
Wei Shang and Maryhelen
Stevenson. 2010.

</span>
<span class="ltx_bibblock">Score normalization in playback attack detection.
In <em class="ltx_emph ltx_font_italic" id="bib.bib130.1.1">IEEE international conference on acoustics,
speech and signal processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib131">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shiota et al<span class="ltx_text" id="bib.bib131.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Sayaka Shiota, Fernando
Villavicencio, Junichi Yamagishi,
Nobutaka Ono, Isao Echizen, and
Tomoko Matsui. 2016.

</span>
<span class="ltx_bibblock">Voice Liveness Detection for Speaker Verification
based on a Tandem Single/Double-channel Pop Noise Detector.. In
<em class="ltx_emph ltx_font_italic" id="bib.bib131.3.1">Odyssey</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib132">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sigurdsson et al<span class="ltx_text" id="bib.bib132.2.2.1">.</span> (2006)</span>
<span class="ltx_bibblock">
Sigurdur Sigurdsson,
Kaare Brandt Petersen, and Tue
Lehn-Schiøler. 2006.

</span>
<span class="ltx_bibblock">Mel Frequency Cepstral Coefficients: An Evaluation
of Robustness of MP3 Encoded Music.. In <em class="ltx_emph ltx_font_italic" id="bib.bib132.3.1">ISMIR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib133">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sohn
et al<span class="ltx_text" id="bib.bib133.2.2.1">.</span> (1999)</span>
<span class="ltx_bibblock">
Jongseo Sohn, Nam Soo
Kim, and Wonyong Sung. 1999.

</span>
<span class="ltx_bibblock">A statistical model-based voice activity
detection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib133.3.1">IEEE signal processing letters</em>
(1999).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib134">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song and Mittal (2017)</span>
<span class="ltx_bibblock">
Liwei Song and Prateek
Mittal. 2017.

</span>
<span class="ltx_bibblock">Poster: Inaudible voice commands. In
<em class="ltx_emph ltx_font_italic" id="bib.bib134.1.1">Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib135">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stolk
et al<span class="ltx_text" id="bib.bib135.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Arjen Stolk, Lennart
Verhagen, and Ivan Toni.
2016.

</span>
<span class="ltx_bibblock">Conceptual alignment: How brains achieve mutual
understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib135.3.1">Trends in cognitive sciences</em>
(2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib136">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stylianou
et al<span class="ltx_text" id="bib.bib136.2.2.1">.</span> (1998)</span>
<span class="ltx_bibblock">
Yannis Stylianou, Olivier
Cappé, and Eric Moulines.
1998.

</span>
<span class="ltx_bibblock">Continuous probabilistic transform for voice
conversion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib136.3.1">IEEE Transactions on speech and audio
processing</em> (1998).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib137">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su
et al<span class="ltx_text" id="bib.bib137.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Dan Su, Jiqiang Liu,
Sencun Zhu, Xiaoyang Wang, and
Wei Wang. 2020.

</span>
<span class="ltx_bibblock">” Are you home alone?”” Yes” Disclosing Security
and Privacy Vulnerabilities in Alexa Skills.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib137.3.1">arXiv preprint arXiv:2010.10788</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib138">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sugawara et al<span class="ltx_text" id="bib.bib138.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Takeshi Sugawara, Benjamin
Cyr, Sara Rampazzi, Daniel Genkin, and
Kevin Fu. 2020.

</span>
<span class="ltx_bibblock">Light Commands:Laser-Based Audio Injection Attacks
on Voice-Controllable Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib138.3.1">USENIX Security
Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib139">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Szegedy et al<span class="ltx_text" id="bib.bib139.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Christian Szegedy,
Wojciech Zaremba, Ilya Sutskever,
Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus.
2013.

</span>
<span class="ltx_bibblock">Intriguing properties of neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib139.3.1">arXiv preprint arXiv:1312.6199</em>
(2013).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib140">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Szurley and
Kolter (2019)</span>
<span class="ltx_bibblock">
Joseph Szurley and
J Zico Kolter. 2019.

</span>
<span class="ltx_bibblock">Perceptual based adversarial audio attacks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib140.1.1">arXiv preprint arXiv:1906.06355</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib141">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tak et al<span class="ltx_text" id="bib.bib141.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Hemlata Tak, Jose Patino,
Massimiliano Todisco, Andreas Nautsch,
Nicholas Evans, and Anthony Larcher.
2021.

</span>
<span class="ltx_bibblock">End-to-end anti-spoofing with rawnet2. In
<em class="ltx_emph ltx_font_italic" id="bib.bib141.3.1">IEEE International Conference on Acoustics, Speech
and Signal Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib142">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tamura
et al<span class="ltx_text" id="bib.bib142.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Keiichi Tamura, Akitada
Omagari, and Shuichi Hashida.
2019.

</span>
<span class="ltx_bibblock">Novel defense method against audio adversarial
example for speech-to-text transcription neural networks. In
<em class="ltx_emph ltx_font_italic" id="bib.bib142.3.1">IEEE International Workshop on Computational
Intelligence and Applications</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib143">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori
et al<span class="ltx_text" id="bib.bib143.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Rohan Taori, Amog
Kamsetty, Brenton Chu, and Nikita
Vemuri. 2019.

</span>
<span class="ltx_bibblock">Targeted adversarial examples for black box audio
systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib143.3.1">IEEE security and privacy workshops</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib144">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Todisco et al<span class="ltx_text" id="bib.bib144.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Massimiliano Todisco, Xin
Wang, Ville Vestman, Md Sahidullah,
Héctor Delgado, Andreas Nautsch,
Junichi Yamagishi, Nicholas Evans,
Tomi Kinnunen, and Kong Aik Lee.
2019.

</span>
<span class="ltx_bibblock">ASVspoof 2019: Future Horizons in Spoofed and Fake
Audio Detection. In <em class="ltx_emph ltx_font_italic" id="bib.bib144.3.1">Annual Conference of the
International Speech Communication Association</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib145">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vadillo and
Santana (2019)</span>
<span class="ltx_bibblock">
Jon Vadillo and Roberto
Santana. 2019.

</span>
<span class="ltx_bibblock">Universal adversarial examples in speech command
classification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib145.1.1">arXiv preprint arXiv:1911.10182</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib146">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaere and Perrig (2023)</span>
<span class="ltx_bibblock">
Piet De Vaere and Adrian
Perrig. 2023.

</span>
<span class="ltx_bibblock">Hey Kimya, Is My Smart Speaker Spying on Me? Taking
Control of Sensor Privacy Through Isolation and Amnesia. In
<em class="ltx_emph ltx_font_italic" id="bib.bib146.1.1">USENIX Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib147">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaidya
et al<span class="ltx_text" id="bib.bib147.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Tavish Vaidya, Yuankai
Zhang, Micah Sherr, and Clay Shields.
2015.

</span>
<span class="ltx_bibblock">Cocaine noodles: exploiting the gap between human
and machine speech recognition. In <em class="ltx_emph ltx_font_italic" id="bib.bib147.3.1">USENIX Workshop
on Offensive Technologies</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib148">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">van den Oord
et al<span class="ltx_text" id="bib.bib148.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Aäron van den Oord,
Sander Dieleman, Heiga Zen,
Karen Simonyan, Oriol Vinyals,
Alex Graves, Nal Kalchbrenner,
Andrew Senior, and Koray Kavukcuoglu.
2016.

</span>
<span class="ltx_bibblock">WaveNet: A Generative Model for Raw Audio. In
<em class="ltx_emph ltx_font_italic" id="bib.bib148.3.1">ISCA Speech Synthesis Workshop</em>.
125–125.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib149">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Villalba and
Lleida (2010)</span>
<span class="ltx_bibblock">
Jesús Villalba and
Eduardo Lleida. 2010.

</span>
<span class="ltx_bibblock">Speaker verification performance degradation
against spoofing and tampering attacks. In <em class="ltx_emph ltx_font_italic" id="bib.bib149.1.1">FALA
workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib150">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Villalba and
Lleida (2011a)</span>
<span class="ltx_bibblock">
Jesús Villalba and
Eduardo Lleida. 2011a.

</span>
<span class="ltx_bibblock">Detecting replay attacks from far-field recordings
on speaker verification systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib150.1.1">Biometrics and
ID Management</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib151">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Villalba and
Lleida (2011b)</span>
<span class="ltx_bibblock">
Jesus Villalba and
Eduardo Lleida. 2011b.

</span>
<span class="ltx_bibblock">Preventing replay attacks on speaker verification
systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib151.1.1">Carnahan Conference on Security
Technology</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib152">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wahlster (2013)</span>
<span class="ltx_bibblock">
Wolfgang Wahlster.
2013.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib152.1.1">Verbmobil: foundations of speech-to-speech
translation</em>.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib153">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib153.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Donghua Wang, Li Dong,
Rangding Wang, Diqun Yan, and
Jie Wang. 2020b.

</span>
<span class="ltx_bibblock">Targeted speech adversarial example generation with
generative adversarial network.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib153.3.1">IEEE Access</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib154">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang (2021)</span>
<span class="ltx_bibblock">
Jiakai Wang.
2021.

</span>
<span class="ltx_bibblock">Adversarial Examples in Physical World.. In
<em class="ltx_emph ltx_font_italic" id="bib.bib154.1.1">IJCAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib155">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib155.2.2.1">.</span> (2020c)</span>
<span class="ltx_bibblock">
Qing Wang, Pengcheng Guo,
and Lei Xie. 2020c.

</span>
<span class="ltx_bibblock">Inaudible adversarial perturbations for targeted
attack in speaker recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib155.3.1">arXiv preprint arXiv:2005.10637</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib156">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib156.2.2.1">.</span> (2020d)</span>
<span class="ltx_bibblock">
Qian Wang, Baolin Zheng,
Qi Li, Chao Shen, and
Zhongjie Ba. 2020d.

</span>
<span class="ltx_bibblock">Towards query-efficient adversarial attacks against
automatic speech recognition systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib156.3.1">IEEE Transactions on Information Forensics
and Security</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib157">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib157.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
Shu Wang, Jiahao Cao,
Xu He, Kun Sun, and Qi
Li. 2020a.

</span>
<span class="ltx_bibblock">When the differences in frequency domain are
compensated: Understanding and defeating modulated replay attacks on
automatic speech recognition. In <em class="ltx_emph ltx_font_italic" id="bib.bib157.3.1">ACM SIGSAC
Conference on Computer and Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib158">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib158.2.2.1">.</span> (2019b)</span>
<span class="ltx_bibblock">
Xiong Wang, Sining Sun,
Changhao Shan, Jingyong Hou,
Lei Xie, Shen Li, and
Xin Lei. 2019b.

</span>
<span class="ltx_bibblock">Adversarial examples for improving end-to-end
attention-based small-footprint keyword spotting. In
<em class="ltx_emph ltx_font_italic" id="bib.bib158.3.1">IEEE International Conference on Acoustics, Speech
and Signal Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib159">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib159.2.2.1">.</span> (2017b)</span>
<span class="ltx_bibblock">
Xianliang Wang, Yanhong
Xiao, and Xuan Zhu. 2017b.

</span>
<span class="ltx_bibblock">Feature Selection Based on CQCCs for Automatic
Speaker Verification Spoofing.. In <em class="ltx_emph ltx_font_italic" id="bib.bib159.3.1">Interspeech</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib160">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib160.2.2.1">.</span> (2019a)</span>
<span class="ltx_bibblock">
Yao Wang, Wandong Cai,
Tao Gu, Wei Shao, Yannan
Li, and Yong Yu. 2019a.

</span>
<span class="ltx_bibblock">Secure your voice: An oral airflow-based continuous
liveness detection for voice assistants.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib160.3.1">ACM on interactive, mobile, wearable and
ubiquitous technologies</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib161">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib161.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yuanda Wang, Hanqing Guo,
and Qiben Yan. 2022.

</span>
<span class="ltx_bibblock">GhostTalk: Interactive Attack on Smartphone Voice
System Through Power Line.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib161.3.1">arXiv preprint arXiv:2202.02585</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib162">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib162.3.3.1">.</span> (2017a)</span>
<span class="ltx_bibblock">
Yuxuan Wang, RJ
Skerry-Ryan, Daisy Stanton, Yonghui Wu,
Ron J Weiss, Navdeep Jaitly,
Zongheng Yang, Ying Xiao,
Zhifeng Chen, Samy Bengio,
et al<span class="ltx_text" id="bib.bib162.4.1">.</span> 2017a.

</span>
<span class="ltx_bibblock">Tacotron: Towards End-to-End Speech Synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib162.5.1">Proc. Interspeech</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib163">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib163.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Zhe Wang, Quanbo Zou,
Qinglin Song, and Jifang Tao.
2015.

</span>
<span class="ltx_bibblock">The era of silicon MEMS microphone and look
beyond. In <em class="ltx_emph ltx_font_italic" id="bib.bib163.3.1">International Conference on Solid-State
Sensors, Actuators and Microsystems</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib164">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wierstra et al<span class="ltx_text" id="bib.bib164.2.2.1">.</span> (2014)</span>
<span class="ltx_bibblock">
Daan Wierstra, Tom
Schaul, Tobias Glasmachers, Yi Sun,
Jan Peters, and Jürgen
Schmidhuber. 2014.

</span>
<span class="ltx_bibblock">Natural evolution strategies.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib164.3.1">The Journal of Machine Learning Research</em>
(2014).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib165">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilde and
Martinez (2004)</span>
<span class="ltx_bibblock">
Mark M Wilde and
Andrew B Martinez. 2004.

</span>
<span class="ltx_bibblock">Probabilistic principal component analysis applied
to voice conversion. In <em class="ltx_emph ltx_font_italic" id="bib.bib165.1.1">Conference Record of the
Thirty-Eighth Asilomar Conference on Signals</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib166">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Witkowski et al<span class="ltx_text" id="bib.bib166.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Marcin Witkowski,
Stanislaw Kacprzak, Piotr Zelasko,
Konrad Kowalczyk, and Jakub Galka.
2017.

</span>
<span class="ltx_bibblock">Audio Replay Attack Detection Using High-Frequency
Features.. In <em class="ltx_emph ltx_font_italic" id="bib.bib166.3.1">Interspeech</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib167">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu
et al<span class="ltx_text" id="bib.bib167.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Yi Wu, Jian Liu,
Yingying Chen, and Jerry Cheng.
2019.

</span>
<span class="ltx_bibblock">Semi-black-box attacks against speech recognition
systems using adversarial samples. In <em class="ltx_emph ltx_font_italic" id="bib.bib167.3.1">IEEE
International symposium on dynamic spectrum access networks</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib168">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib168.2.2.1">.</span> (2012a)</span>
<span class="ltx_bibblock">
Zhizheng Wu, Eng Siong
Chng, and Haizhou Li. 2012a.

</span>
<span class="ltx_bibblock">Detecting converted speech and natural speech for
anti-spoofing attack in speaker recognition. In
<em class="ltx_emph ltx_font_italic" id="bib.bib168.3.1">Thirteenth Annual Conference of the International
Speech Communication Association</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib169">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu
et al<span class="ltx_text" id="bib.bib169.2.2.1">.</span> (2012b)</span>
<span class="ltx_bibblock">
Zhizheng Wu, Tomi
Kinnunen, Eng Siong Chng, Haizhou Li,
and Eliathamby Ambikairajah.
2012b.

</span>
<span class="ltx_bibblock">A study on spoofing attack in state-of-the-art
speaker verification: the telephone speech case. In
<em class="ltx_emph ltx_font_italic" id="bib.bib169.3.1">Asia Pacific Signal and Information Processing
Association Annual Summit and Conference</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib170">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib170.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Zhizheng Wu, Tomi
Kinnunen, Nicholas Evans, Junichi
Yamagishi, Cemal Hanilci, Md Sahidullah,
and Aleksandr Sizov. 2015.

</span>
<span class="ltx_bibblock">ASVspoof 2015: the First Automatic Speaker
Verification Spoofing and Countermeasures Challenge. In
<em class="ltx_emph ltx_font_italic" id="bib.bib170.3.1">Annual Conference of the International Speech
Communication Association</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib171">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie
et al<span class="ltx_text" id="bib.bib171.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Yi Xie, Cong Shi,
Zhuohang Li, Jian Liu,
Yingying Chen, and Bo Yuan.
2020.

</span>
<span class="ltx_bibblock">Real-time, universal, and robust adversarial
attacks against speaker recognition systems. In
<em class="ltx_emph ltx_font_italic" id="bib.bib171.3.1">IEEE international conference on acoustics, speech
and signal processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib172">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yakura and Sakuma (2018)</span>
<span class="ltx_bibblock">
Hiromu Yakura and Jun
Sakuma. 2018.

</span>
<span class="ltx_bibblock">Robust audio adversarial example for a physical
attack.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib172.1.1">arXiv preprint arXiv:1810.11793</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib173">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yamagishi
et al<span class="ltx_text" id="bib.bib173.3.3.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Junichi Yamagishi, Xin
Wang, Massimiliano Todisco, Md
Sahidullah, Jose Patino, Andreas
Nautsch, Xuechen Liu, Kong Aik Lee,
Tomi Kinnunen, Nicholas Evans,
et al<span class="ltx_text" id="bib.bib173.4.1">.</span> 2021.

</span>
<span class="ltx_bibblock">ASVspoof 2021: accelerating progress in spoofed and
deepfake speech detection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib173.5.1">arXiv preprint arXiv:2109.00537</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib174">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan
et al<span class="ltx_text" id="bib.bib174.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Chen Yan, Xiaoyu Ji,
Kai Wang, Qinhong Jiang,
Zizhi Jin, and Wenyuan Xu.
2023.

</span>
<span class="ltx_bibblock">A Survey on Voice Assistant Security: Attacks and
Countermeasures.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib174.3.1">Comput. Surv.</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib175">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan
et al<span class="ltx_text" id="bib.bib175.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Chen Yan, Guoming Zhang,
Xiaoyu Ji, Tianchen Zhang,
Taimin Zhang, and Wenyuan Xu.
2019.

</span>
<span class="ltx_bibblock">The feasibility of injecting inaudible voice
commands to voice assistants.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib175.3.1">IEEE Transactions on Dependable and Secure
Computing</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib176">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan
et al<span class="ltx_text" id="bib.bib176.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Qiben Yan, Kehai Liu,
Qin Zhou, Hanqing Guo, and
Ning Zhang. 2020.

</span>
<span class="ltx_bibblock">Surfingattack: Interactive hidden attack on voice
assistants using ultrasonic guided waves. In
<em class="ltx_emph ltx_font_italic" id="bib.bib176.3.1">Network and Distributed Systems Security
Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib177">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
et al<span class="ltx_text" id="bib.bib177.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Lanqing Yang, Xinqi Chen,
Xiangyong Jian, Leping Yang, and
Yijie Li. 2023a.

</span>
<span class="ltx_bibblock">Remote Attacks on Speech Recognition Systems Using
Sound from Power Supply. In <em class="ltx_emph ltx_font_italic" id="bib.bib177.3.1">USENIX Security
Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib178">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
et al<span class="ltx_text" id="bib.bib178.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Qiang Yang, Kaiyan Cui,
and Yuanqing Zheng. 2023b.

</span>
<span class="ltx_bibblock">VoShield: Voice Liveness Detection with Sound Field
Dynamics. In <em class="ltx_emph ltx_font_italic" id="bib.bib178.3.1">Proceedings of IEEE INFOCOM</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib179">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
et al<span class="ltx_text" id="bib.bib179.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Zhuolin Yang, Bo Li,
Pin-Yu Chen, and Dawn Song.
2018.

</span>
<span class="ltx_bibblock">Characterizing audio adversarial examples using
temporal dependency.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib179.3.1">arXiv preprint arXiv:1809.10875</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib180">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoon
et al<span class="ltx_text" id="bib.bib180.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Sung-Hyun Yoon, Min-Sung
Koh, Jae-Han Park, and Ha-Jin Yu.
2020.

</span>
<span class="ltx_bibblock">A new replay attack against automatic speaker
verification systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib180.3.1">IEEE Access</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib181">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Young
et al<span class="ltx_text" id="bib.bib181.6.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jeffrey Young, Song Liao,
Long Cheng, Hongxin Hu, and
Huixing Deng. 2022.

</span>
<span class="ltx_bibblock"><math alttext="\{" class="ltx_Math" display="inline" id="bib.bib181.1.m1.1"><semantics id="bib.bib181.1.m1.1a"><mo id="bib.bib181.1.m1.1.1" stretchy="false" xref="bib.bib181.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib181.1.m1.1b"><ci id="bib.bib181.1.m1.1.1.cmml" xref="bib.bib181.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib181.1.m1.1c">\{</annotation><annotation encoding="application/x-llamapun" id="bib.bib181.1.m1.1d">{</annotation></semantics></math>SkillDetective<math alttext="\}" class="ltx_Math" display="inline" id="bib.bib181.2.m2.1"><semantics id="bib.bib181.2.m2.1a"><mo id="bib.bib181.2.m2.1.1" stretchy="false" xref="bib.bib181.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib181.2.m2.1b"><ci id="bib.bib181.2.m2.1.1.cmml" xref="bib.bib181.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib181.2.m2.1c">\}</annotation><annotation encoding="application/x-llamapun" id="bib.bib181.2.m2.1d">}</annotation></semantics></math>: Automated
<math alttext="\{" class="ltx_Math" display="inline" id="bib.bib181.3.m3.1"><semantics id="bib.bib181.3.m3.1a"><mo id="bib.bib181.3.m3.1.1" stretchy="false" xref="bib.bib181.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib181.3.m3.1b"><ci id="bib.bib181.3.m3.1.1.cmml" xref="bib.bib181.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib181.3.m3.1c">\{</annotation><annotation encoding="application/x-llamapun" id="bib.bib181.3.m3.1d">{</annotation></semantics></math>Policy-Violation<math alttext="\}" class="ltx_Math" display="inline" id="bib.bib181.4.m4.1"><semantics id="bib.bib181.4.m4.1a"><mo id="bib.bib181.4.m4.1.1" stretchy="false" xref="bib.bib181.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib181.4.m4.1b"><ci id="bib.bib181.4.m4.1.1.cmml" xref="bib.bib181.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib181.4.m4.1c">\}</annotation><annotation encoding="application/x-llamapun" id="bib.bib181.4.m4.1d">}</annotation></semantics></math> Detection of Voice Assistant Applications in the
Wild. In <em class="ltx_emph ltx_font_italic" id="bib.bib181.7.1">USENIX Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib182">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu
et al<span class="ltx_text" id="bib.bib182.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhiyuan Yu, Yuanhaur
Chang, Ning Zhang, and Chaowei Xiao.
2023.

</span>
<span class="ltx_bibblock">SMACK: Semantically Meaningful Adversarial Audio
Attack. In <em class="ltx_emph ltx_font_italic" id="bib.bib182.3.1">USENIX Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib183">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al<span class="ltx_text" id="bib.bib183.2.2.1">.</span> (2018a)</span>
<span class="ltx_bibblock">
Xuejing Yuan, Yuxuan
Chen, Aohui Wang, Kai Chen,
Shengzhi Zhang, Heqing Huang, and
Ian M Molloy. 2018a.

</span>
<span class="ltx_bibblock">All your alexa are belong to us: A remote voice
control attack against echo. In <em class="ltx_emph ltx_font_italic" id="bib.bib183.3.1">IEEE global
communications conference</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib184">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al<span class="ltx_text" id="bib.bib184.2.2.1">.</span> (2018b)</span>
<span class="ltx_bibblock">
Xuejing Yuan, Yuxuan
Chen, Yue Zhao, Yunhui Long,
Xiaokang Liu, Kai Chen,
Shengzhi Zhang, Heqing Huang,
Xiaofeng Wang, and Carl A Gunter.
2018b.

</span>
<span class="ltx_bibblock">Commandersong: A systematic approach for practical
adversarial voice recognition. In <em class="ltx_emph ltx_font_italic" id="bib.bib184.3.1">USENIX Security
Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib185">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zawawi
et al<span class="ltx_text" id="bib.bib185.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Siti Aisyah Zawawi,
Azrul Azlan Hamzah, Burhanuddin Yeop
Majlis, and Faisal Mohd-Yasin.
2020.

</span>
<span class="ltx_bibblock">A review of MEMS capacitive microphones.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib185.3.1">Micromachines</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib186">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zen
et al<span class="ltx_text" id="bib.bib186.2.2.1">.</span> (2009)</span>
<span class="ltx_bibblock">
Heiga Zen, Keiichi
Tokuda, and Alan W Black.
2009.

</span>
<span class="ltx_bibblock">Statistical parametric speech synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib186.3.1">speech communication</em>
(2009).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib187">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al<span class="ltx_text" id="bib.bib187.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Qiang Zeng, Jianhai Su,
Chenglong Fu, Golam Kayas,
Lannan Luo, Xiaojiang Du,
Chiu C Tan, and Jie Wu.
2019.

</span>
<span class="ltx_bibblock">A multiversion programming inspired approach to
detecting audio adversarial examples. In <em class="ltx_emph ltx_font_italic" id="bib.bib187.3.1">IEEE/IFIP
international conference on dependable systems and networks</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib188">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span class="ltx_text" id="bib.bib188.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Guoming Zhang, Xiaoyu Ji,
Xinfeng Li, Gang Qu, and
Wenyuan Xu. 2021.

</span>
<span class="ltx_bibblock">EarArray: Defending against DolphinAttack via
Acoustic Attenuation.. In <em class="ltx_emph ltx_font_italic" id="bib.bib188.3.1">NDSS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib189">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span class="ltx_text" id="bib.bib189.2.2.1">.</span> (2017b)</span>
<span class="ltx_bibblock">
Guoming Zhang, Chen Yan,
Xiaoyu Ji, Tianchen Zhang,
Taimin Zhang, and Wenyuan Xu.
2017b.

</span>
<span class="ltx_bibblock">Dolphinattack: Inaudible voice commands. In
<em class="ltx_emph ltx_font_italic" id="bib.bib189.3.1">Proceedings of the 2017 ACM SIGSAC conference on
computer and communications security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib190">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span class="ltx_text" id="bib.bib190.2.2.1">.</span> (2019c)</span>
<span class="ltx_bibblock">
Jiajie Zhang, Bingsheng
Zhang, and Bincheng Zhang.
2019c.

</span>
<span class="ltx_bibblock">Defending adversarial attacks on cloud-aided
automatic speech recognition systems. In
<em class="ltx_emph ltx_font_italic" id="bib.bib190.3.1">Proceedings of the Seventh International Workshop
on Security in Cloud Computing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib191">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span class="ltx_text" id="bib.bib191.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
Lei Zhang, Yan Meng,
Jiahao Yu, Chong Xiang,
Brandon Falk, and Haojin Zhu.
2020a.

</span>
<span class="ltx_bibblock">Voiceprint mimicry attack towards speaker
verification system in smart home. In <em class="ltx_emph ltx_font_italic" id="bib.bib191.3.1">IEEE INFOCOM
2020-IEEE Conference on Computer Communications</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib192">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span class="ltx_text" id="bib.bib192.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Linghan Zhang, Sheng Tan,
Zi Wang, Yili Ren, Zhi
Wang, and Jie Yang. 2020b.

</span>
<span class="ltx_bibblock">Viblive: A continuous liveness detection for secure
voice user interface in iot environment. In
<em class="ltx_emph ltx_font_italic" id="bib.bib192.3.1">Computer Security Applications Conference</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib193">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span class="ltx_text" id="bib.bib193.2.2.1">.</span> (2017a)</span>
<span class="ltx_bibblock">
Linghan Zhang, Sheng Tan,
and Jie Yang. 2017a.

</span>
<span class="ltx_bibblock">Hearing your voice is not enough: An articulatory
gesture based liveness detection for voice authentication. In
<em class="ltx_emph ltx_font_italic" id="bib.bib193.3.1">ACM SIGSAC Conference on Computer and
Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib194">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span class="ltx_text" id="bib.bib194.2.2.1">.</span> (2019a)</span>
<span class="ltx_bibblock">
Nan Zhang, Xianghang Mi,
Xuan Feng, XiaoFeng Wang,
Yuan Tian, and Feng Qian.
2019a.

</span>
<span class="ltx_bibblock">Dangerous skills: Understanding and mitigating
security risks of voice-controlled third-party functions on virtual personal
assistant systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib194.3.1">IEEE Symposium on Security
and Privacy</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib195">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span class="ltx_text" id="bib.bib195.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Shaofei Zhang, Dongyan
Huang, Lei Xie, Eng Siong Chng,
Haizhou Li, and Minghui Dong.
2015.

</span>
<span class="ltx_bibblock">Non-negative matrix factorization using stable
alternating direction method of multipliers for source separation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib195.3.1">Asia-Pacific Signal and Information Processing
Association Annual Summit and Conference</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib196">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span class="ltx_text" id="bib.bib196.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Xiao Zhang, Hao Tan,
Xuan Huang, Denghui Zhang,
Keke Tang, and Zhaoquan Gu.
2022.

</span>
<span class="ltx_bibblock">Adversarial Example Attacks against ASR Systems: An
Overview. In <em class="ltx_emph ltx_font_italic" id="bib.bib196.3.1">IEEE International Conference on Data
Science in Cyberspace</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib197">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib197.2.2.1">.</span> (2019b)</span>
<span class="ltx_bibblock">
Yangyong Zhang, Lei Xu,
Abner Mendoza, Guangliang Yang,
Phakpoom Chinprutthiwong, and Guofei
Gu. 2019b.

</span>
<span class="ltx_bibblock">Life after speech recognition: Fuzzing semantic
misinterpretation for voice assistant applications. In
<em class="ltx_emph ltx_font_italic" id="bib.bib197.3.1">Proc. of the Network and Distributed System
Security Symposium</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib198">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span class="ltx_text" id="bib.bib198.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Baolin Zheng, Peipei
Jiang, Qian Wang, Qi Li,
Chao Shen, Cong Wang,
Yunjie Ge, Qingyang Teng, and
Shenyi Zhang. 2021.

</span>
<span class="ltx_bibblock">Black-box adversarial attacks on commercial speech
platforms with minimal information. In <em class="ltx_emph ltx_font_italic" id="bib.bib198.3.1">ACM SIGSAC
Conference on Computer and Communications Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib199">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou
et al<span class="ltx_text" id="bib.bib199.2.2.1">.</span> (2019a)</span>
<span class="ltx_bibblock">
Man Zhou, Zhan Qin,
Xiu Lin, Shengshan Hu,
Qian Wang, and Kui Ren.
2019a.

</span>
<span class="ltx_bibblock">Hidden voice commands: Attacks and defenses on the
VCS of autonomous driving cars.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib199.3.1">IEEE Wireless Communications</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib200">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou
et al<span class="ltx_text" id="bib.bib200.2.2.1">.</span> (2019b)</span>
<span class="ltx_bibblock">
Yi Zhou, Xiaohai Tian,
Haihua Xu, Rohan Kumar Das, and
Haizhou Li. 2019b.

</span>
<span class="ltx_bibblock">Cross-lingual voice conversion with bilingual
phonetic posteriorgram and average modeling. In
<em class="ltx_emph ltx_font_italic" id="bib.bib200.3.1">IEEE International Conference on Acoustics, Speech
and Signal Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon May 27 12:20:02 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
