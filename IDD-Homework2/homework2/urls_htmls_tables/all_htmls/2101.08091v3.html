<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2101.08091] A survey of joint intent detection and slot-filling models in natural language understanding</title><meta property="og:description" content="Intent classification and slot filling are two critical tasks for natural language understanding. Traditionally the two tasks have been deemed to proceed independently. However, more recently, joint models for intent c…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A survey of joint intent detection and slot-filling models in natural language understanding">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A survey of joint intent detection and slot-filling models in natural language understanding">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2101.08091">

<!--Generated on Sat Mar  2 07:29:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="intent detection,  slot labelling,  spoken language understanding,  natural language understanding">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">A survey of joint intent detection and slot-filling models in natural language understanding</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Henry Weld
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:hwel4188@uni.sydney.edu.au">hwel4188@uni.sydney.edu.au</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">The University of Sydney</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Sydney</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">Australia</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaoqi Huang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:xhua7314@uni.sydney.edu.au">xhua7314@uni.sydney.edu.au</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">The University of Sydney</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Sydney</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">Australia</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Siqu Long
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:slon6753@uni.sydney.edu.au">slon6753@uni.sydney.edu.au</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">The University of Sydney</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_city">Sydney</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_country">Australia</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Josiah Poon
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:Josiah.Poon@sydney.edu.au">Josiah.Poon@sydney.edu.au</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id10.1.id1" class="ltx_text ltx_affiliation_institution">The University of Sydney</span><span id="id11.2.id2" class="ltx_text ltx_affiliation_city">Sydney</span><span id="id12.3.id3" class="ltx_text ltx_affiliation_country">Australia</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Soyeon Caren Han
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:caren.han@sydney.edu.au">caren.han@sydney.edu.au</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id13.1.id1" class="ltx_text ltx_affiliation_institution">The University of Sydney</span><span id="id14.2.id2" class="ltx_text ltx_affiliation_city">Sydney</span><span id="id15.3.id3" class="ltx_text ltx_affiliation_country">Australia</span>
</span></span></span>
</div>
<div class="ltx_dates">(2020)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id16.id1" class="ltx_p">Intent classification and slot filling are two critical tasks for natural language understanding. Traditionally the two tasks have been deemed to proceed independently. However, more recently, joint models for intent classification and slot filling have achieved state-of-the-art performance, and have proved that there exists a strong relationship between the two tasks.
This article is a compilation of past work in natural language understanding, especially joint intent classification and slot filling. We observe three milestones in this research so far:
Intent detection to identify the speaker’s intention, slot filling to label each word token in the speech/text, and finally, joint intent classification and slot filling tasks. In this article, we describe trends, approaches, issues, data sets, evaluation metrics in intent classification and slot filling. We also discuss representative performance values, describe shared tasks, and provide pointers to future work, as given in prior works. To interpret the state-of-the-art trends, we provide multiple tables that describe and summarise past research along different dimensions, including the types of features, base approaches, and dataset domain used.</p>
</div>
<div class="ltx_keywords">intent detection, slot labelling, spoken language understanding, natural language understanding
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2020</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/1122445.1122456</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_journal"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journal: </span>TOG</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_journalvolume"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalvolume: </span>37</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_journalnumber"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalnumber: </span>4</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_article"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">article: </span>111</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_publicationmonth"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">publicationmonth: </span>8</span></span></span><span id="id9" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Natural language processing</span></span></span><span id="id10" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Information extraction</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The efficacy of virtual assistants becomes more important as their popularity rises. Central to their performance is the ability for the electronic assistant to understand what the human user is saying, in order to act, or reply, in a way that meaningfully satisfies the requester.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The human-device interface may be text based, but is now most frequently voice, and will probably in the near future include image or video. To put the understanding of human utterances within a framework, within the natural language processing (NLP) stack lies spoken language understanding (SLU). SLU starts with automatic speech recognition (ASR), the task of taking the sound waves or images of expressed language, and transcribing to text. Natural language understanding (NLU) then takes the text and extracts the semantics for use in further processes - information gathering, question answering, dialogue management, request fulfilment, and so on.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The concept of a hierarchical semantic frame has developed to represent the levels of meaning within spoken utterances. At the highest level is a domain, then intent and then slots. The domain is the area of information the utterance is concerned with. The intent (a.k.a. goal in early papers) is the speaker’s desired outcome from the utterance. The slots are the types of the words or spans of words in the utterance that contain semantic information relevant to the fulfilment of the intent. An example is given in Table <a href="#S1.T1" title="Table 1 ‣ 1. Introduction ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for the domain <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">movies</span>. Within this domain the example has intent <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">find_movie</span> and the individual tokens are labelled with their slot tag using the IOB tagging format.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<table id="S1.T1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.1.1.1" class="ltx_tr">
<th id="S1.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">query</span></th>
<th id="S1.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">find</th>
<th id="S1.T1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">recent</th>
<th id="S1.T1.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">comedies</th>
<th id="S1.T1.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">by</th>
<th id="S1.T1.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">james</th>
<th id="S1.T1.1.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">cameron</th>
</tr>
<tr id="S1.T1.1.2.2" class="ltx_tr">
<th id="S1.T1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T1.1.2.2.1.1" class="ltx_text ltx_font_bold">slots</span></th>
<th id="S1.T1.1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">O</th>
<th id="S1.T1.1.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">B-date</th>
<th id="S1.T1.1.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">B-genre</th>
<th id="S1.T1.1.2.2.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">O</th>
<th id="S1.T1.1.2.2.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">B-dir</th>
<th id="S1.T1.1.2.2.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">I-dir</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.1.3.1" class="ltx_tr">
<th id="S1.T1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T1.1.3.1.1.1" class="ltx_text ltx_font_bold">intent</span></th>
<td id="S1.T1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="6">find_movie</td>
</tr>
<tr id="S1.T1.1.4.2" class="ltx_tr">
<th id="S1.T1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T1.1.4.2.1.1" class="ltx_text ltx_font_bold">domain</span></th>
<td id="S1.T1.1.4.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" colspan="6">movies</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>An example of an utterance as semantic frame with domain, intent and IOB slot annotation (from <cite class="ltx_cite ltx_citemacro_citep">(Hakkani-Tür et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite>)</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The NLU task is thus the extraction of the semantic frame elements from the utterance. NLU is important - it is central to devices that desire a spoken interface with humans - for example, conversational agents, instruction in vehicles (driverless or otherwise), Internet of Things (IoT), personal assistants, online helpdesks/chatbots, robot instruction, and so on. Improving the quality of the semantic detection will improve the quality of the experience for the user, and from here it draws its importance and popularity as a research topic.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In many data sets, and indeed real world applications, the domain is limited; it is concerned only with hotel bookings, or air flight information, for example. In these cases the domain level is generally not part the analysis. However in wider ranging applications, for example the SNIPS data set discussed later, or the manifold personal voice assistants which are expected to field requests from various domains, inclusion of the domain detection in the problem can lead to better results. However, for the purposes of this survey we will treat the domain as ancillary.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">This leaves us with intent and slot identification. What does the human user want from the communication, and what semantic entities carry the details? The two sub-tasks are known as intent detection and slot filling. The latter may be a misnomer as the task is more correctly slot labelling, or slot tagging. Slot filling is more precisely giving the slot a value of a type matching the label. For example, a slot labelled “B-city” could be filled with the value “Sydney”. Intent detection is usually approached as a supervised classification task, mapping the entire input sentence to an element of a finite set of classes. Slot filling then is a labelling of the sequence of tokens in the utterance, making it within the sequence-to-sequence (seq2seq) class of problems.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">While early research looked at the tasks separately, or put them in a series pipeline, it was quickly noted that the slot labels present and the intent class should and do influence each other in ways that solving the two tasks simultaneously should garner better results for both tasks. This has been the at the centre of NLU over recent years though work on the single tasks has continued.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">A joint model which simultaneously addresses each sub-task must, to be successful, capture the joint distributions of intent and slot labels, with respect also to the words in the utterance, their local context, and the global context in the sentence. A joint model has the advantage over pipeline models that it is less susceptible to error propagation, and over separate models in general that there is a only a single model to train and fine tune.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">A drawback is that a large annotated corpus is usually required, though this is also true of separate models. The model may also be relatively complicated and take time to train. It has also been observed that joint models may not generalise well to unseen data, due to the variety of natural language expressions of similar intent. In real world applications the domains and label sets may change over time.</p>
</div>
<div id="S1.p10" class="ltx_para">
<p id="S1.p10.1" class="ltx_p">In many ways the development of the field has followed a similar path to other areas of NLP, starting with classical (statistical or probabilistic) models. Neural networks were applied as computing power increased. In particular, due to the sequential nature of the slot labelling sub-task, recurrent neural networks (RNNs) have been a technology frequently used in the field. In more recent years the transformer architecture has debuted to address issues like long range dependency. As a result, attention has increased in importance. As far as feature creation goes, convolution, word embeddings, and pre-trained language models have all been applied, amongst many other methods. The use of external knowledge bases has been observed in more recent papers.</p>
</div>
<div id="S1.p11" class="ltx_para">
<p id="S1.p11.1" class="ltx_p">The most regularly used data sets are two freely available sets - ATIS and SNIPS. A common experiment is implied by the literature, from which the reported results are compared in this survey. In addition, one of the aims of this survey is to address further standardisation, in terms of the parameters of the experiment and the evaluation metrics used.</p>
</div>
<div id="S1.p12" class="ltx_para">
<p id="S1.p12.1" class="ltx_p">The approaches to the joint task have been manifold and have shown excellent results in standard supervised training/test experiments. As new techniques make what may appear to be incremental increases to the state of the art it is perhaps time to recast the measures of success in the field. Rather than just developing new, more challenging annotated data sets, increasingly important must be the development of unstructured semantic detection in new domains.</p>
</div>
<div id="S1.p13" class="ltx_para">
<p id="S1.p13.1" class="ltx_p">The motivation for this survey is to take stock of the state of the field in 2020 following a surge of ideas and approaches over recent years, particularly in the joint task. We collect information on the approaches pursued so far and the issues encountered and addressed. With the survey completed we propose some future directions for the field.</p>
</div>
<div id="S1.p14" class="ltx_para">
<p id="S1.p14.1" class="ltx_p">In summary, this survey address three major questions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Q1: How do these joint models achieve and balance two aspects, intent classification and slot filling?</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Q2: Have syntactic clues/features been fully exploited or does semantics override this consideration?</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Q3: Can successful models in one supervised domain be made more generalisable to new domains or languages or unseen data?</p>
</div>
</li>
</ul>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1. </span>Scope</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">The focus of this survey is on extraction of the intent and slots of single utterances. The separate tasks are covered and then the joint task is addressed in detail. Papers on the following aspects will be reviewed but the information considered as ancillary only:</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">Multi-domain data sets with annotated domain. Extraction of the domain is a classification task like intent detection, albeit less granular. Inclusion of the domain identification task may aid the two sub-tasks of interest and this will be mentioned;</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">Dialogue action. Dialogue action is the identification of the next action to be taken by a dialogue management system once intent and slots have been identified. In some cases dialogue action is a direct substitute for intent and in others a mapping is made from intent and slot labels to the action. We review papers that include a strong focus on intent and slot detection;</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">Multi-intent data sets. An utterance may have multiple intent (for example, flight booking and hotel booking). More work has been done in pure intent detection on this aspect than in the joint task. We will consider it in the pure intent task in particular and make comments on expansion to the joint task;</p>
</div>
</li>
<li id="S1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i4.p1" class="ltx_para">
<p id="S1.I2.i4.p1.1" class="ltx_p">Automatic speech recognition (ASR). Some papers begin with the ASR step and look at error propagation from ASR to intent or slot prediction. We don’t consider this aspect.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Historical overview of intent detection papers</figcaption>
<table id="S1.T2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T2.1.1.1" class="ltx_tr">
<th id="S1.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S1.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Year</span></th>
<th id="S1.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S1.T2.1.1.1.2.1" class="ltx_text ltx_font_bold"># papers</span></th>
<th id="S1.T2.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S1.T2.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.1.1.3.1.1" class="ltx_p" style="width:156.5pt;"><span id="S1.T2.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Feature engineering</span></span>
</span>
</th>
<th id="S1.T2.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S1.T2.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.1.1.4.1.1" class="ltx_p" style="width:256.1pt;"><span id="S1.T2.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Technologies</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T2.1.2.1" class="ltx_tr">
<th id="S1.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">2011</th>
<th id="S1.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">3</th>
<td id="S1.T2.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T2.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.2.1.3.1.1" class="ltx_p" style="width:156.5pt;">Dependency parse</span>
</span>
</td>
<td id="S1.T2.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T2.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.2.1.4.1.1" class="ltx_p" style="width:256.1pt;">SVM, DBN, multi-layer NN, AdaBoost</span>
</span>
</td>
</tr>
<tr id="S1.T2.1.3.2" class="ltx_tr">
<th id="S1.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2012</th>
<th id="S1.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S1.T2.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.3.2.3.1.1" class="ltx_p" style="width:156.5pt;">Bag-of-words</span>
</span>
</td>
<td id="S1.T2.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.3.2.4.1.1" class="ltx_p" style="width:256.1pt;">C4.5, RF, NB, KNN, Linear SVM</span>
</span>
</td>
</tr>
<tr id="S1.T2.1.4.3" class="ltx_tr">
<th id="S1.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2013</th>
<th id="S1.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S1.T2.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.4.3.3.1.1" class="ltx_p" style="width:156.5pt;">n-gram</span>
</span>
</td>
<td id="S1.T2.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.4.3.4.1.1" class="ltx_p" style="width:256.1pt;">SVM, SVM-HMMs</span>
</span>
</td>
</tr>
<tr id="S1.T2.1.5.4" class="ltx_tr">
<th id="S1.T2.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2015</th>
<th id="S1.T2.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">4</th>
<td id="S1.T2.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.5.4.3.1.1" class="ltx_p" style="width:156.5pt;">n-gram, word2vec,</span>
</span>
</td>
<td id="S1.T2.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.5.4.4.1.1" class="ltx_p" style="width:256.1pt;">LSTM, RNN, ensemble, RF, clustering, SVM, AdaBoost, NN, J48, FFN</span>
</span>
</td>
</tr>
<tr id="S1.T2.1.6.5" class="ltx_tr">
<th id="S1.T2.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2016</th>
<th id="S1.T2.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S1.T2.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.6.5.3.1.1" class="ltx_p" style="width:156.5pt;">CNN</span>
</span>
</td>
<td id="S1.T2.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.6.5.4.1.1" class="ltx_p" style="width:256.1pt;">RF</span>
</span>
</td>
</tr>
<tr id="S1.T2.1.7.6" class="ltx_tr">
<th id="S1.T2.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2018</th>
<th id="S1.T2.1.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">7</th>
<td id="S1.T2.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.7.6.3.1.1" class="ltx_p" style="width:156.5pt;">GloVe, word2vec, character embedding, grammatical features, dependency parse, knowledge base, POS, CRF, Regex, PCFG-ML, fastText</span>
</span>
</td>
<td id="S1.T2.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.7.6.4.1.1" class="ltx_p" style="width:256.1pt;">(Bi)CNN, (Bi)LSTM, (Bi)GRU, ensemble, Capsule networks, attention, (Bi)RNN, adversarial networks, gradient reversal layer, SVM, J48, Logistic regression, PPN, RF, Gaussian Naïve Bayes, KNN, NB, softmax regression</span>
</span>
</td>
</tr>
<tr id="S1.T2.1.8.7" class="ltx_tr">
<th id="S1.T2.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2019</th>
<th id="S1.T2.1.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">4</th>
<td id="S1.T2.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.8.7.3.1.1" class="ltx_p" style="width:156.5pt;">n-gram, character, word2vec, CNN, BiLSTM</span>
</span>
</td>
<td id="S1.T2.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T2.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.8.7.4.1.1" class="ltx_p" style="width:256.1pt;">BiLSTM, attention, Ridge, KNN, MLP, passive aggressive, RF, linear SVC, SGD, nearest centroid, multinominal NB, Bernoulli NB, K-means, CNN, BiGRU, density-based novelty detection algorithm, local outlier factor</span>
</span>
</td>
</tr>
<tr id="S1.T2.1.9.8" class="ltx_tr">
<th id="S1.T2.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">2020</th>
<th id="S1.T2.1.9.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">1</th>
<td id="S1.T2.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S1.T2.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.9.8.3.1.1" class="ltx_p" style="width:156.5pt;">BERT, word2vec, CNN</span>
</span>
</td>
<td id="S1.T2.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S1.T2.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T2.1.9.8.4.1.1" class="ltx_p" style="width:256.1pt;">Siamese, triple loss</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2. </span>Related surveys</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Tur and De Mori, <a href="#bib.bib103" title="" class="ltx_ref">2011</a>)</cite> is a complete summary of the SLU field at the advent of the neural era (2011). <cite class="ltx_cite ltx_citemacro_citep">(Wang and Yuan, <a href="#bib.bib111" title="" class="ltx_ref">2016</a>)</cite> concentrate on models that jointly address sub-tasks in dialogue systems, including NLU, dialogue management (DM) and Natural Language Generation (NLG). They cover the early models in the joint task but predate the works explicitly tying NLU to dialogue action covered here.</p>
</div>
<div id="S1.SS2.p2" class="ltx_para">
<p id="S1.SS2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Tur et al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2018</a>)</cite> concentrates on goal-oriented conversational language understanding but within that field provide an excellent precursor to this survey, covering the state of the art to 2017 in the two sub-tasks and 2016 in the joint task. <cite class="ltx_cite ltx_citemacro_citep">(Hou
et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2019</a>)</cite> give a small overview of the separate and joint tasks. <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2019a</a>)</cite> provides a good survey of intent detection methods up to 2018 including multi-intent detection and evaluation methods.</p>
</div>
<div id="S1.SS2.p3" class="ltx_para">
<p id="S1.SS2.p3.1" class="ltx_p">Tangentially related surveys include <cite class="ltx_cite ltx_citemacro_citep">(Serban et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2018</a>)</cite> which surveys dialogue data sets available for research, and <cite class="ltx_cite ltx_citemacro_citep">(Deriu et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite> which gives an overview of evaluation methods for dialogue systems.</p>
</div>
<div id="S1.SS2.p4" class="ltx_para">
<p id="S1.SS2.p4.1" class="ltx_p">In this survey we bring the coverage of methods up to mid-2020 including the many applications of deep learning in the field. As well as a technological survey we look at issues addressed in each task and the joint task, and the approaches designed to address these issues. We also supply a summary of reported performance on the standard data sets.</p>
</div>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3. </span>Structure of the survey</h3>

<div id="S1.SS3.p1" class="ltx_para">
<p id="S1.SS3.p1.1" class="ltx_p">The survey begins with a broad overview of the literature in Section <a href="#S2" title="2. Overview of the literature ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We then give a detailed description of the methods for each sub-task (Sections <a href="#S3" title="3. Intent Detection ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S4" title="4. Slot filling ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) and the joint task in Section <a href="#S5" title="5. Joint intent and slot models ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, along with the issues addressed and solutions proposed. In Section <a href="#S6" title="6. Data sets ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> a survey of the data sets encountered takes place. In Sections <a href="#S7" title="7. Evaluation metrics ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and <a href="#S8" title="8. Experimental Setup ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> there is a description of the experiments and evaluation methods applied and a discussion of standardisation of these. A summary of the results achieved over the history of the field is given in Section <a href="#S9" title="9. Performance summary ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. We finish with a discussion of the challenges and opportunities for research in the field and give concluding remarks in Section <a href="#S10" title="10. Critical Discussion and Conclusions ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<figure id="S1.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span>Historical overview of slot labelling papers</figcaption>
<table id="S1.T3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T3.1.1.1" class="ltx_tr">
<th id="S1.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S1.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Year</span></th>
<th id="S1.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S1.T3.1.1.1.2.1" class="ltx_text ltx_font_bold"># papers</span></th>
<th id="S1.T3.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S1.T3.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.1.1.3.1.1" class="ltx_p" style="width:156.5pt;"><span id="S1.T3.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Feature engineering</span></span>
</span>
</th>
<th id="S1.T3.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S1.T3.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.1.1.4.1.1" class="ltx_p" style="width:256.1pt;"><span id="S1.T3.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Technologies</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T3.1.2.1" class="ltx_tr">
<th id="S1.T3.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">2011</th>
<th id="S1.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1</th>
<td id="S1.T3.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T3.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.2.1.3.1.1" class="ltx_p" style="width:156.5pt;">Neural network, observation feature vector</span>
</span>
</td>
<td id="S1.T3.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T3.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.2.1.4.1.1" class="ltx_p" style="width:256.1pt;">Deep learning, CRF</span>
</span>
</td>
</tr>
<tr id="S1.T3.1.3.2" class="ltx_tr">
<th id="S1.T3.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2012</th>
<th id="S1.T3.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S1.T3.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.3.2.3.1.1" class="ltx_p" style="width:156.5pt;">n-gram, K-DCN</span>
</span>
</td>
<td id="S1.T3.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.3.2.4.1.1" class="ltx_p" style="width:256.1pt;">Kernel learning, deep learning, DCN, log-linear model</span>
</span>
</td>
</tr>
<tr id="S1.T3.1.4.3" class="ltx_tr">
<th id="S1.T3.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2013</th>
<th id="S1.T3.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">3</th>
<td id="S1.T3.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.4.3.3.1.1" class="ltx_p" style="width:156.5pt;">Discriminative embedding, named entity, dependency parse, POS, SENNA, RNNLM, bag-of-words</span>
</span>
</td>
<td id="S1.T3.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.4.3.4.1.1" class="ltx_p" style="width:256.1pt;">DBN, RNN, RNN-LM</span>
</span>
</td>
</tr>
<tr id="S1.T3.1.5.4" class="ltx_tr">
<th id="S1.T3.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2014</th>
<th id="S1.T3.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2</th>
<td id="S1.T3.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.5.4.3.1.1" class="ltx_p" style="width:156.5pt;">RNN, lexicon feature</span>
</span>
</td>
<td id="S1.T3.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.5.4.4.1.1" class="ltx_p" style="width:256.1pt;">CRF, LSTM, regression model, deep learning</span>
</span>
</td>
</tr>
<tr id="S1.T3.1.6.5" class="ltx_tr">
<th id="S1.T3.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2015</th>
<th id="S1.T3.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">3</th>
<td id="S1.T3.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.6.5.3.1.1" class="ltx_p" style="width:156.5pt;">Word embedding, named entity, word embedding</span>
</span>
</td>
<td id="S1.T3.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.6.5.4.1.1" class="ltx_p" style="width:256.1pt;">RNN, sampling approach, external memory</span>
</span>
</td>
</tr>
<tr id="S1.T3.1.7.6" class="ltx_tr">
<th id="S1.T3.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2016</th>
<th id="S1.T3.1.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">3</th>
<td id="S1.T3.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.7.6.3.1.1" class="ltx_p" style="width:156.5pt;">Word embedding, context window, RNN, CNN</span>
</span>
</td>
<td id="S1.T3.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.7.6.4.1.1" class="ltx_p" style="width:256.1pt;">BiRNN, attention, LSTM, encoder-labeler, CNN</span>
</span>
</td>
</tr>
<tr id="S1.T3.1.8.7" class="ltx_tr">
<th id="S1.T3.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2017</th>
<th id="S1.T3.1.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S1.T3.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.8.7.3.1.1" class="ltx_p" style="width:156.5pt;">Word embedding</span>
</span>
</td>
<td id="S1.T3.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.8.7.4.1.1" class="ltx_p" style="width:256.1pt;">(Bi)LSTM, encoder-decoder, focus mechanism, entity position-aware attention</span>
</span>
</td>
</tr>
<tr id="S1.T3.1.9.8" class="ltx_tr">
<th id="S1.T3.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2018</th>
<th id="S1.T3.1.9.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">5</th>
<td id="S1.T3.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.9.8.3.1.1" class="ltx_p" style="width:156.5pt;">BiLSTM, word embedding, character, CNN, delexicalisation</span>
</span>
</td>
<td id="S1.T3.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.9.8.4.1.1" class="ltx_p" style="width:256.1pt;">CRF, MTL, segment tagging, NER, BiLSTM, attention, delexicalised sentence generation, DNN, reinforcement learning, GRU, pointer network</span>
</span>
</td>
</tr>
<tr id="S1.T3.1.10.9" class="ltx_tr">
<th id="S1.T3.1.10.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2019</th>
<th id="S1.T3.1.10.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">6</th>
<td id="S1.T3.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.10.9.3.1.1" class="ltx_p" style="width:156.5pt;">Word embedding, web-data, expert feedback, contextual information, GloVe, POS, character, BERT</span>
</span>
</td>
<td id="S1.T3.1.10.9.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T3.1.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.10.9.4.1.1" class="ltx_p" style="width:256.1pt;">BiLSTM, BiGRU, different knowledge sources, context gate, MTL, CNN</span>
</span>
</td>
</tr>
<tr id="S1.T3.1.11.10" class="ltx_tr">
<th id="S1.T3.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">2020</th>
<th id="S1.T3.1.11.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">2</th>
<td id="S1.T3.1.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S1.T3.1.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.11.10.3.1.1" class="ltx_p" style="width:156.5pt;">ResTDNN</span>
</span>
</td>
<td id="S1.T3.1.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S1.T3.1.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.1.11.10.4.1.1" class="ltx_p" style="width:256.1pt;">Prior knowledge driven label embedding, CRF, TDNN, RNN</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Overview of the literature</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Intent classification is a form of text classification where the text is a single sentence that comes from a spoken or written utterance. Much effort has been made to construct features which encapsulate the sentence, both semantically and syntactically, and the words within it. These features have been passed to classifiers from the suite of classical and, from 2011, deep learning methods, as outlined in Table <a href="#S1.T2" title="Table 2 ‣ 1.1. Scope ‣ 1. Introduction ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Issues around ambiguity, shortness of sentences, treatment of out-of-vocabulary words and emerging label sets are amongst those covered in the literature.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Slot tagging (see Table <a href="#S1.T3" title="Table 3 ‣ 1.3. Structure of the survey ‣ 1. Introduction ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) is framed as a sequence labelling problem and in early years drew from methods for statistically modelling the dependencies within sequences, like conditional random fields (CRFs) and Hidden Markov models (HMMs). Around 2013 the strength of RNNs in this area had been observed and was applied to the task and developed over the ensuing years. Interestingly the use of CRFs returned, often as a post-RNN step, due to their efficacy at handling label dependency issues. As far as feature creation goes the general goal of the task is to use the semantic information within the words and various context windows from small to long-range within the sentence. Attention is used as one approach for eliciting useful context. Slot tagging has experimented with external knowledge bases for extra performance.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Methods used by both sub-tasks to extend their features include looking at meta-data from the data collection. Multi-task learning has also been used by both tasks to look for synergistic learning from other related tasks. Of course the joint task itself is an example of this synergistic approach. Both tasks have also considered methods for transfer learning to other languages and to data with new, unseen tag sets.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">The two earliest papers (2008-9) addressing the joint task drew methods from classical NLP. Features were constructed from words, n-grams and suffixes, or from a semantic parsing of the utterances. A CRF or a support vector machine (SVM) was used for the analysis. In 2013 the first neural network was used though it really just constructed convolutional neural network (CNN) features for use in the CRF model from 2008. In 2014 a recursive neural network (RecNN), which works over trees, was applied to the dependency parse of the utterances. In 2015 the first completely neural network was devised, using a recurrent neural network (RNN, different to a recursive neural network) embedding of words, CNN representation of sentences, and a feed forward network (FFN) for the analysis.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">By 2016 the RNN encoder-decoder architecture had been found to be useful for seq2seq tasks and started to make its impact in the joint task. Unidirectional and bi-directional Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) cells were tested within circuits. Attention made its first appearance. On the input feature side K-SAN graphs were used as a knowledge base.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">In 2017 the field appeared to stay progress, with only character embedding being added to the input features and no improvement of performance results on the major data sets. Perhaps though, researchers were working on the many developments which exploded in 2018. Word embeddings were introduced - word2vec, GloVe and ELMo. The circuits were still largely RNN based. For new architectures a capsule neural network and bidirectional circuits were introduced. Here bidirectional refers to explicit influence paths through the circuit: intent2slot refers to intent information being used as part of slot prediction and slot2intent the opposite, slot information being used as part of intent prediction.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">In 2019 BERT debuted as a word embedding technology and ELMo fell away. More knowledge bases were used as input features. Work on pre-processing the data sets included delexicalisation, augmentation, and sparse word embeddings using a lasso method. In architecture RNN and attention continued to be used and CRF made a return to handle label dependency issues. Newly applied architectures included the transformer, and memory neural networks.</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.1" class="ltx_p">The indications from 2020 are that graph embeddings are being used more to capture slot-intent and word-slot-intent relationships.</p>
</div>
<figure id="S2.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4. </span>Historical overview of joint task papers</figcaption>
<table id="S2.T4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T4.1.1.1" class="ltx_tr">
<th id="S2.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S2.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Year</span></th>
<th id="S2.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S2.T4.1.1.1.2.1" class="ltx_text ltx_font_bold"># papers</span></th>
<th id="S2.T4.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S2.T4.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.1.1.3.1.1" class="ltx_p" style="width:156.5pt;"><span id="S2.T4.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Feature engineering</span></span>
</span>
</th>
<th id="S2.T4.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S2.T4.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.1.1.4.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T4.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Technologies</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T4.1.2.1" class="ltx_tr">
<th id="S2.T4.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">2008</th>
<th id="S2.T4.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1</th>
<td id="S2.T4.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.2.1.3.1.1" class="ltx_p" style="width:156.5pt;">words/n-grams/suffixes</span>
</span>
</td>
<td id="S2.T4.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T4.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.2.1.4.1.1" class="ltx_p" style="width:256.1pt;">CRF</span>
</span>
</td>
</tr>
<tr id="S2.T4.1.3.2" class="ltx_tr">
<th id="S2.T4.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2009</th>
<th id="S2.T4.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S2.T4.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.3.2.3.1.1" class="ltx_p" style="width:156.5pt;">semantic tree</span>
</span>
</td>
<td id="S2.T4.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.3.2.4.1.1" class="ltx_p" style="width:256.1pt;">SVM</span>
</span>
</td>
</tr>
<tr id="S2.T4.1.4.3" class="ltx_tr">
<th id="S2.T4.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2013</th>
<th id="S2.T4.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S2.T4.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.4.3.3.1.1" class="ltx_p" style="width:156.5pt;">CNN</span>
</span>
</td>
<td id="S2.T4.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.4.3.4.1.1" class="ltx_p" style="width:256.1pt;">CRF</span>
</span>
</td>
</tr>
<tr id="S2.T4.1.5.4" class="ltx_tr">
<th id="S2.T4.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2014</th>
<th id="S2.T4.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S2.T4.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.5.4.3.1.1" class="ltx_p" style="width:156.5pt;">dependency parse</span>
</span>
</td>
<td id="S2.T4.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.5.4.4.1.1" class="ltx_p" style="width:256.1pt;">RecNN (diff to RNN)</span>
</span>
</td>
</tr>
<tr id="S2.T4.1.6.5" class="ltx_tr">
<th id="S2.T4.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2015</th>
<th id="S2.T4.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S2.T4.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.6.5.3.1.1" class="ltx_p" style="width:156.5pt;">RNN words, CNN sentence, Bag of words</span>
</span>
</td>
<td id="S2.T4.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.6.5.4.1.1" class="ltx_p" style="width:256.1pt;">MLP</span>
</span>
</td>
</tr>
<tr id="S2.T4.1.7.6" class="ltx_tr">
<th id="S2.T4.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2016</th>
<th id="S2.T4.1.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">6</th>
<td id="S2.T4.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.7.6.3.1.1" class="ltx_p" style="width:156.5pt;">RNN, K-SAN</span>
</span>
</td>
<td id="S2.T4.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.7.6.4.1.1" class="ltx_p" style="width:256.1pt;">(Bi)LSTM, (Bi)GRU, encoder-decoder RNN, attention</span>
</span>
</td>
</tr>
<tr id="S2.T4.1.8.7" class="ltx_tr">
<th id="S2.T4.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2017</th>
<th id="S2.T4.1.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">4</th>
<td id="S2.T4.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.8.7.3.1.1" class="ltx_p" style="width:156.5pt;">character, word, CNN</span>
</span>
</td>
<td id="S2.T4.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.8.7.4.1.1" class="ltx_p" style="width:256.1pt;">BiLSTM</span>
</span>
</td>
</tr>
<tr id="S2.T4.1.9.8" class="ltx_tr">
<th id="S2.T4.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2018</th>
<th id="S2.T4.1.9.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">18</th>
<td id="S2.T4.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.9.8.3.1.1" class="ltx_p" style="width:156.5pt;">word2vec, GloVe, ELMo, CNN sentence, attention sentence</span>
</span>
</td>
<td id="S2.T4.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.9.8.4.1.1" class="ltx_p" style="width:256.1pt;">BiLSTM, BiGRU, encoder-decoder RNN, Capsule NN, BiDirectional</span>
</span>
</td>
</tr>
<tr id="S2.T4.1.10.9" class="ltx_tr">
<th id="S2.T4.1.10.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2019</th>
<th id="S2.T4.1.10.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">29</th>
<td id="S2.T4.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.10.9.3.1.1" class="ltx_p" style="width:156.5pt;">BERT, GloVe, character, knowledge base (tuples), delexicalisation</span>
</span>
</td>
<td id="S2.T4.1.10.9.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T4.1.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.10.9.4.1.1" class="ltx_p" style="width:256.1pt;">memory NN, transformer, CRF, attention, BiDirectional</span>
</span>
</td>
</tr>
<tr id="S2.T4.1.11.10" class="ltx_tr">
<th id="S2.T4.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">2020</th>
<th id="S2.T4.1.11.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">10</th>
<td id="S2.T4.1.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S2.T4.1.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.11.10.3.1.1" class="ltx_p" style="width:156.5pt;">BERT, Graph embedding</span>
</span>
</td>
<td id="S2.T4.1.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S2.T4.1.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T4.1.11.10.4.1.1" class="ltx_p" style="width:256.1pt;">Graph S-LSTM, BiDirectional, GCN, Capsule</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S2.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5. </span>Intent detection papers reviewed with addressed issue, approach and techniques</figcaption>
<table id="S2.T5.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T5.1.1.1" class="ltx_tr">
<th id="S2.T5.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="S2.T5.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.1.1.1.1.1" class="ltx_p" style="width:99.6pt;"><span id="S2.T5.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Paper</span></span>
</span>
</th>
<th id="S2.T5.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="S2.T5.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.1.1.2.1.1" class="ltx_p" style="width:139.4pt;"><span id="S2.T5.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Addressed issue</span></span>
</span>
</th>
<th id="S2.T5.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="S2.T5.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.1.1.3.1.1" class="ltx_p" style="width:239.0pt;"><span id="S2.T5.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Approach</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T5.1.2.1" class="ltx_tr">
<td id="S2.T5.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.2.1.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(González-Caro and Baeza-Yates, <a href="#bib.bib33" title="" class="ltx_ref">2011</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.2.1.2.1.1" class="ltx_p" style="width:139.4pt;">Multi-faceted query intent prediction</span>
</span>
</td>
<td id="S2.T5.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.2.1.3.1.1" class="ltx_p" style="width:239.0pt;">Combined multifaceted (multi-label) intent classification</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.3.2" class="ltx_tr">
<td id="S2.T5.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.3.2.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Sarikaya
et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2011</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.3.2.2.1.1" class="ltx_p" style="width:139.4pt;">Small/lack of labelled training data</span>
</span>
</td>
<td id="S2.T5.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.3.2.3.1.1" class="ltx_p" style="width:239.0pt;">Initialise FFN using DBN derived from trained stacked RBMs</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.4.3" class="ltx_tr">
<td id="S2.T5.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.4.3.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Tur
et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2011</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.4.3.2.1.1" class="ltx_p" style="width:139.4pt;">Short text query in web search</span>
</span>
</td>
<td id="S2.T5.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.4.3.3.1.1" class="ltx_p" style="width:239.0pt;">Simplified sentence structure as additional feature</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.5.4" class="ltx_tr">
<td id="S2.T5.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.5.4.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2012</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.5.4.2.1.1" class="ltx_p" style="width:139.4pt;">Contextual/temporal information modeling</span>
</span>
</td>
<td id="S2.T5.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.5.4.3.1.1" class="ltx_p" style="width:239.0pt;">Semi-supervised co-training based on two independent features (text/metadata)</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.6.5" class="ltx_tr">
<td id="S2.T5.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.6.5.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Bhargava et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2013</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.6.5.2.1.1" class="ltx_p" style="width:139.4pt;">Small/lack of labelled training data</span>
</span>
</td>
<td id="S2.T5.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.6.5.3.1.1" class="ltx_p" style="width:239.0pt;">1) Incorporating temporal information as additional feature; 2) Modeling temporal/session information as a sequence</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.7.6" class="ltx_tr">
<td id="S2.T5.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.7.6.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Ravuri and
Stolcke, <a href="#bib.bib83" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.7.6.2.1.1" class="ltx_p" style="width:139.4pt;">OOV issue</span>
</span>
</td>
<td id="S2.T5.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.7.6.3.1.1" class="ltx_p" style="width:239.0pt;">Incorporating temporal information using RNN-based models with one-hot word embedding and n-gram hashing</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.8.7" class="ltx_tr">
<td id="S2.T5.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.8.7.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Hasanuzzaman et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.8.7.2.1.1" class="ltx_p" style="width:139.4pt;">Small/lack of labelled training data</span>
</span>
</td>
<td id="S2.T5.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.8.7.3.1.1" class="ltx_p" style="width:239.0pt;">Multi-objective ensemble learning with feature engineering (external resource used)</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.9.8" class="ltx_tr">
<td id="S2.T5.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.9.8.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Purohit et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.9.8.2.1.1" class="ltx_p" style="width:139.4pt;">Ambiguity in interpretation; Imbalanced data</span>
</span>
</td>
<td id="S2.T5.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.9.8.3.1.1" class="ltx_p" style="width:239.0pt;">Hybrid feature representation created by combining top-down processing using knowledge-guided patterns with bottom-up processing using a bag-of-tokens model</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.10.9" class="ltx_tr">
<td id="S2.T5.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.10.9.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Kanhabua
et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.10.9.2.1.1" class="ltx_p" style="width:139.4pt;">Event-based web searching</span>
</span>
</td>
<td id="S2.T5.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.10.9.3.1.1" class="ltx_p" style="width:239.0pt;">Time-based and event-based clustering with click-through and standard statistical feature-based classification</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.11.10" class="ltx_tr">
<td id="S2.T5.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.11.10.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Hashemi
et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.11.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.11.10.2.1.1" class="ltx_p" style="width:139.4pt;">Complex feature engineering</span>
</span>
</td>
<td id="S2.T5.1.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.11.10.3.1.1" class="ltx_p" style="width:239.0pt;">CNN feature extracted vector representation</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.12.11" class="ltx_tr">
<td id="S2.T5.1.12.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.12.11.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.12.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.12.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.12.11.2.1.1" class="ltx_p" style="width:139.4pt;">Co-occurrence of words from different intents; word correlations addressing</span>
</span>
</td>
<td id="S2.T5.1.12.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.12.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.12.11.3.1.1" class="ltx_p" style="width:239.0pt;">Heterogeneous features of pairwise word correlation and POS information</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.13.12" class="ltx_tr">
<td id="S2.T5.1.13.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.13.12.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2018b</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.13.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.13.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.13.12.2.1.1" class="ltx_p" style="width:139.4pt;">Exploring combination of deep learning architectures</span>
</span>
</td>
<td id="S2.T5.1.13.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.13.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.13.12.3.1.1" class="ltx_p" style="width:239.0pt;">Pre-trained embedding with ensemble of deep learning models</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.14.13" class="ltx_tr">
<td id="S2.T5.1.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.14.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.14.13.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Xia
et al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.14.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.14.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.14.13.2.1.1" class="ltx_p" style="width:139.4pt;">Emerging intents detection</span>
</span>
</td>
<td id="S2.T5.1.14.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.14.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.14.13.3.1.1" class="ltx_p" style="width:239.0pt;">Capsule-based architectures with zero-shot learning to discriminate emerging intents via knowledge transfer</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.15.14" class="ltx_tr">
<td id="S2.T5.1.15.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.15.14.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Costello et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.15.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.15.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.15.14.2.1.1" class="ltx_p" style="width:139.4pt;">Multi-domain/multi-lingual generalisation ability</span>
</span>
</td>
<td id="S2.T5.1.15.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.15.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.15.14.3.1.1" class="ltx_p" style="width:239.0pt;">Multi-layer ensemble models of different deep learning techniques</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.16.15" class="ltx_tr">
<td id="S2.T5.1.16.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.16.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.16.15.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Masumura et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.16.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.16.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.16.15.2.1.1" class="ltx_p" style="width:139.4pt;">Multi-task and multi-lingual joint modelling</span>
</span>
</td>
<td id="S2.T5.1.16.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.16.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.16.15.3.1.1" class="ltx_p" style="width:239.0pt;">Adversarial training method for the multi-task and multi-lingual joint modelling</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.17.16" class="ltx_tr">
<td id="S2.T5.1.17.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.17.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.17.16.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Mohasseb
et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.17.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.17.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.17.16.2.1.1" class="ltx_p" style="width:139.4pt;">Grammar feature exploration</span>
</span>
</td>
<td id="S2.T5.1.17.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.17.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.17.16.3.1.1" class="ltx_p" style="width:239.0pt;">Grammar-based framework with 3 main features</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.18.17" class="ltx_tr">
<td id="S2.T5.1.18.17.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.18.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.18.17.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Xie
et al<span class="ltx_text">.</span>, <a href="#bib.bib122" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.18.17.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.18.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.18.17.2.1.1" class="ltx_p" style="width:139.4pt;">Short text; Semantic feature expansion</span>
</span>
</td>
<td id="S2.T5.1.18.17.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.18.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.18.17.3.1.1" class="ltx_p" style="width:239.0pt;">Semantic Tag-empowered combined features</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.19.18" class="ltx_tr">
<td id="S2.T5.1.19.18.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.19.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.19.18.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Qiu
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.19.18.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.19.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.19.18.2.1.1" class="ltx_p" style="width:139.4pt;">Potential consciousness information mining</span>
</span>
</td>
<td id="S2.T5.1.19.18.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.19.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.19.18.3.1.1" class="ltx_p" style="width:239.0pt;">A similarity calculation method based on LSTM and a traditional machine learning method based on multi-feature extraction</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.20.19" class="ltx_tr">
<td id="S2.T5.1.20.19.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.20.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.20.19.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Kim and Kim, <a href="#bib.bib47" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.20.19.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.20.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.20.19.2.1.1" class="ltx_p" style="width:139.4pt;">OOD utterances</span>
</span>
</td>
<td id="S2.T5.1.20.19.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.20.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.20.19.3.1.1" class="ltx_p" style="width:239.0pt;">Multi-task learning</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.21.20" class="ltx_tr">
<td id="S2.T5.1.21.20.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.21.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.21.20.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Cohan
et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.21.20.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.21.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.21.20.2.1.1" class="ltx_p" style="width:139.4pt;">Utilisation of naturally labelled data</span>
</span>
</td>
<td id="S2.T5.1.21.20.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.21.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.21.20.3.1.1" class="ltx_p" style="width:239.0pt;">Multitask learning based on joint loss</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.22.21" class="ltx_tr">
<td id="S2.T5.1.22.21.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.22.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.22.21.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Shridhar
et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.22.21.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.22.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.22.21.2.1.1" class="ltx_p" style="width:139.4pt;">OOV issue; Small/lack of labelled training data</span>
</span>
</td>
<td id="S2.T5.1.22.21.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.22.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.22.21.3.1.1" class="ltx_p" style="width:239.0pt;">Subword semantic hashing</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.23.22" class="ltx_tr">
<td id="S2.T5.1.23.22.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.23.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.23.22.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib114" title="" class="ltx_ref">2019b</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.23.22.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.23.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.23.22.2.1.1" class="ltx_p" style="width:139.4pt;">Learning of deep semantic information</span>
</span>
</td>
<td id="S2.T5.1.23.22.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.23.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.23.22.3.1.1" class="ltx_p" style="width:239.0pt;">Hybrid CNN and bidirectional GRU neural network with pre-trained embeddings (Char-CNN-BGRU)</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.24.23" class="ltx_tr">
<td id="S2.T5.1.24.23.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.24.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.24.23.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Lin and Xu, <a href="#bib.bib57" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.24.23.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.24.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.24.23.2.1.1" class="ltx_p" style="width:139.4pt;">Emerging intents detection</span>
</span>
</td>
<td id="S2.T5.1.24.23.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.24.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.24.23.3.1.1" class="ltx_p" style="width:239.0pt;">Maximise inter-class variance and minimise intra-class variance to get the discriminative feature</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.25.24" class="ltx_tr">
<td id="S2.T5.1.25.24.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.25.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.25.24.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Ren and Xue, <a href="#bib.bib87" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.25.24.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.25.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.25.24.2.1.1" class="ltx_p" style="width:139.4pt;">Similar utterance with different intent</span>
</span>
</td>
<td id="S2.T5.1.25.24.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T5.1.25.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.25.24.3.1.1" class="ltx_p" style="width:239.0pt;">Triples of samples used for training</span>
</span>
</td>
</tr>
<tr id="S2.T5.1.26.25" class="ltx_tr">
<td id="S2.T5.1.26.25.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T5.1.26.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.26.25.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yilmaz and
Toraman, <a href="#bib.bib130" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S2.T5.1.26.25.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T5.1.26.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.26.25.2.1.1" class="ltx_p" style="width:139.4pt;">OOD utterances</span>
</span>
</td>
<td id="S2.T5.1.26.25.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T5.1.26.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T5.1.26.25.3.1.1" class="ltx_p" style="width:239.0pt;">KL divergence vector for classification</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Intent Detection</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Intent detection is typically set up as a sentence classification problem. That is, a feature or features are constructed from the sentence and these are passed through a classification algorithm to predict a class for the sentence from a predefined set of classes. As a classification problem the techniques applied look to discover a well defined decision boundary between the features. Intent classification differs from classification tasks in other fields due to the nature of the data which are text sentences, coming from spoken language utterances. Hence, at least initially, the features should look to capture semantic information in the sentence. Beyond the semantic information within the words many approaches have been made to extend the feature set using internal (syntactic, word context) or external (meta-data, sentence context) information.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Major areas of research</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Research into intent classification in SLU has generally come from four areas: search engines, question answering systems, dialogue systems, and text categorisation. Early search engines applied text similarity to select results for users. More recently, intent classification has been applied to understand the searcher’s intent further and this approach has been proven to give better search results. However, web queries are usually short and informal, causing difficulties in classifying intents because of insufficient information. Similarly, answering questions from users also benefits from understanding the intents of questions to generate better quality responses. In dialogue systems it has been shown to be useful to identify intents of users in order to give appropriate responses to users. Moreover, intent classification can be applied in more general NLP tasks, such as text classification, sentiment analysis and scientific citation.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Overview of technological approaches</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Before 2015, most papers focused on classical machine learning approaches, such as SVM, K-nearest neighbours and random forest. Features used by these models were mainly generated by dependency parsing, word embedding and n-grams. One deep learning method explored early on was deep belief networks (DBN). In more recent years, with the success of deep learning in other areas, neural networks, especially RNNs, started to be widely used for this task. Attention mechanisms have been integrated in models for identifying which parts of sentences should contribute to the classification. Since intent classification is proposed to be integrated with web engineering, which requires the ability to understand short texts that contain less information, features used for training have been enriched by feature engineering using web metadata.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Issues addressed in intent detection</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In this section we survey the issues encountered in the literature around intent detection, and the solutions proposed. The issues may be specific to the task, like ambiguity of semantic intent. They may be general machine learning issues like lack of training data, and dealing with new or adapting domains. They may be issues specific to the available data like imbalanced data, short sentences, or the out-of-vocabulary (OOV) issue. Feature creation to capture information extra to that in the words is considered to boost performance. Extending the range of the task to multiple intents or to identify out-of-domain sentences is covered.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1. </span>Ambiguity in interpretation</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">In essence, this issue is at the heart of intent classification; identifying the decision boundary between samples close together in feature space, yet belonging to different classes. This issue may be more prevalent with short texts, since they may include insufficient information and not follow correct grammar.</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">An early approach from <cite class="ltx_cite ltx_citemacro_citep">(Purohit et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2015</a>)</cite> was to propose a rich feature representation with an ensemble learning framework giving different perspectives on the classification. The feature creation is covered further in ensuing sections.</p>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p">A more recent approach from <cite class="ltx_cite ltx_citemacro_citep">(Ren and Xue, <a href="#bib.bib87" title="" class="ltx_ref">2020</a>)</cite> proposed training triples of samples - an anchor sample, a positive sample in the same class and a negative sample from a different class. Combining convolutional and BERT encodings of each one and mapping them to Euclidean space with Siamese shared weights, an intermediate loss of the anchor-positive distance minus the anchor-negative distance is minimised. The Euclidean mapping of the anchor is used for classification.</p>
</div>
<div id="S3.SS3.SSS1.p4" class="ltx_para">
<p id="S3.SS3.SSS1.p4.1" class="ltx_p">This latter approach feeds in to the emerging field of contrastive learning and methods from there should be deployed in the NLU field.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2. </span>Lack of labelled training data or small training sets</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">Collecting and labelling large amounts of data for training can be expensive. With small data sets, models are more likely to be over-trained. Further, the out-of-vocabulary (OOV) issue, where words appear in the test set that are not in the training set, is more likely to occur with them.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Sarikaya
et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2011</a>)</cite> proposed a DBN-initialised neural network for intent classification to learn from unlabelled data and generate features for a feed-forward network. The feed forward network is then fine-tuned on labelled data which may be small in number but still give reasonable results. A DBN is a stack of Restricted Boltzmann Machines (RBMs). To train a DBN, the RBMs are trained layer-by-layer in sequence using parameters learned by previous layers. After training the stack of RBMs, the weights of the DBN are used to initialise the weights of a feed-forward neural network. This approach performed better than traditional machine learning models, such as maximum entropy and boosting, and similarly to SVM.</p>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Hasanuzzaman et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2015</a>)</cite> tried to include temporal query understanding into web search query intent classification. They tackled two major issues: one is the inadequacy of limited training data while the other is the limited literal features able to be extracted from queries of short length (typically 3-4 words). They utilised external resources collected from the web that may help bolster temporal information, such as web snippets for queries and the most relevant year, date etc. Based on this 28 features were designed and extracted. They then proposed an ensemble learning solution framework defined as a multi-objective optimisation problem (MOO) and explored with 28 classifiers using different optimisation strategies. The utilisation of external resources and ensemble learning was intended to reduce bias to better handle the limited training data.</p>
</div>
<div id="S3.SS3.SSS2.p4" class="ltx_para">
<p id="S3.SS3.SSS2.p4.1" class="ltx_p">Methods for dealing with new unannotated domains and data sets by transfer of concept from existing data sets or models weights combined with few shot methodologies have been explored in the slot labelling and joint task area and are discussed later.</p>
</div>
<div id="S3.SS3.SSS2.p5" class="ltx_para">
<p id="S3.SS3.SSS2.p5.1" class="ltx_p">Sufficient data is essential for training a model. To work with unlabelled data, unsupervised training methods could be investigated in further research.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3. </span>Multi-domain/multi-lingual generalisability</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">Most text classification models focus on only one language, one domain and also one task. Some models have been proposed to have better generalisability.</p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Costello et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2018</a>)</cite> developed a novel multi-layer ensembling approach that ensembles both different model initialisation and different model architectures to determine how multi-layer ensembling improves performance on multilingual intent classification. They constructed a CNN with character-level embedding and a bidirectional CNN with attention mechanism. In addition, they explored LSTM and GRU with or without character-level embedding and attention mechanism. When ensembling models, they use a majority vote with confidence approach.</p>
</div>
<div id="S3.SS3.SSS3.p3" class="ltx_para">
<p id="S3.SS3.SSS3.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Masumura et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2018</a>)</cite> proposed an adversarial training method for the multi-task and multi-lingual joint modelling to improve performance on minority data. The language-specific network can be shared between multiple tasks, where words in the input utterance are converted into language-specific hidden representations. Next, each word representation is converted into a hidden representation that uses BiLSTMs to take neighbouring word context information into account. Task-specific networks can be shared between multiple languages, where the language-specific hidden representations are converted into task-specific hidden representations. The proposed method combines a language-specific task adversarial network with a task-specific language adversarial network.</p>
</div>
</section>
<section id="S3.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.4. </span>Emerging intents detection</h4>

<div id="S3.SS3.SSS4.p1" class="ltx_para">
<p id="S3.SS3.SSS4.p1.1" class="ltx_p">In dynamic real world applications the intent set evolves. A method to detect and classify emerging intents is a desirable adjunct task.</p>
</div>
<div id="S3.SS3.SSS4.p2" class="ltx_para">
<p id="S3.SS3.SSS4.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Hashemi
et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2016</a>)</cite> proposed to use a CNN to extract query features for intent classification, which is trained based on word-level embeddings generated by word2vec trained on Google News. Query representations are taken after a max pooling layer. They perform clustering on these representations and observe that new examples far from the clusters could be used to identify emerging intents, though they do not perform that task.</p>
</div>
<div id="S3.SS3.SSS4.p3" class="ltx_para">
<p id="S3.SS3.SSS4.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Xia
et al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2018</a>)</cite> proposed two capsule-based architectures to detect emerging intents. They construct three capsules, SemanticCaps, DetectionCaps and Zero-shot DetectionCaps. SemanticCaps is based on a bidirectional RNN with multiple self-attention heads and is used to extract semantic features from utterances. Then, DetectionCaps aggregate the low-level information from SemanticCaps to high-level information in an unsupervised routing-by-agreement approach and obtain intent representations. For detecting emerging intents, the Zero-shot DetectionCap takes information from SemanticCaps and DetectionCaps to calculate vote vectors for information transferral. Then, the vote vectors are multiplied with similarity between embeddings of existing intents and emerging intents and summed to generate representations of emerging intent labels.</p>
</div>
</section>
<section id="S3.SS3.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.5. </span>Unseen intents</h4>

<div id="S3.SS3.SSS5.p1" class="ltx_para">
<p id="S3.SS3.SSS5.p1.1" class="ltx_p">Dealing with intents which are unseen in the training data is a related challenging task. <cite class="ltx_cite ltx_citemacro_citep">(Lin and Xu, <a href="#bib.bib57" title="" class="ltx_ref">2019</a>)</cite> proposed a two-stage method to detect unseen intent labels. First, they used a Bi-LSTM to extract features of a sentence. Then, the forward output vector and the backward output vector were concatenated and the concatenation result was used as the input of the next stage. The model uses large margin cosine loss (LMCL) as the loss function, instead of softmax loss, which aims to maximise the decision margin. Thus, the inter-class variance is maximised and the intra-class variance is minimised. This is to ensure that the features extracted by Bi-LSTM can be more discriminative. In the second stage, the model takes the concatenation vector and applies a local outlier factor (LOF) to detect unseen intents, which is a density-based detection algorithm.</p>
</div>
<section id="S3.SS3.SSS5.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">The OOV issue</h5>

<div id="S3.SS3.SSS5.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS5.Px1.p1.1" class="ltx_p">Most word embedding based approaches are dependent on vocabularies and may suffer to some extent from OOV issues, though small training data sets may be affected more. Using character n-grams is a common approach to handle unseen words based on the idea that similar words may come from a common root. Another is to replace all words below a chosen frequency in the training set with a special token, say UNKNOWN.</p>
</div>
<div id="S3.SS3.SSS5.Px1.p2" class="ltx_para">
<p id="S3.SS3.SSS5.Px1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Ravuri and
Stolcke, <a href="#bib.bib83" title="" class="ltx_ref">2015</a>)</cite> proposed character n-grams as their word input encoding method with both RNN and LSTM, since they thought the OOV issues became more severe when using RNNs because an unknown word could propagate an effect to the consequent words. Similarly, <cite class="ltx_cite ltx_citemacro_citep">(Shridhar
et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite> proposed sub-word semantic hashing inspired by the Deep Semantic Similarity Model for solving the OOV issue which comes with small training data sets. Before sub-word semantic hashing, sentences are transferred into lower case, pronouns in sentences are replaced by ‘-PRON-’, and special characters except stop characters are removed. Then, classes with less sentences are oversampled by adding augmented sentences, which are generated using synonym replacement. After this, every token in each sentence is wrapped by two ’#’ symbols and represented using trigrams. These sub-tokens are then vectorised using an inverse document frequency vector and the Euclidean norm. In the end, the vectors can be used in any intent classification model.</p>
</div>
</section>
</section>
<section id="S3.SS3.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.6. </span>Short text queries</h4>

<div id="S3.SS3.SSS6.p1" class="ltx_para">
<p id="S3.SS3.SSS6.p1.1" class="ltx_p">User queries for search engines are usually short (3-4 words) and lack context, so it is essential to extract more information from queries for successful classification. Syntactic features, such as POS tags, and also external knowledge sources have been used to enrich query features.</p>
</div>
<div id="S3.SS3.SSS6.p2" class="ltx_para">
<p id="S3.SS3.SSS6.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Hasanuzzaman et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2015</a>)</cite> included temporal query understanding into web search query intent classification and their model works well with the limited literal features for queries of short length. <cite class="ltx_cite ltx_citemacro_citep">(Purohit et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2015</a>)</cite> focused on intent understanding of social media text such as tweets. Some of these can be short, leading to ambiguity of interpretation and sparsity of relevant behaviours. They try to improve the expressiveness of data by utilising multiple patterns from knowledge sources and fuse the top-down knowledge-guided patterns with bottom-up frequency-based representation for feature formation. Based on this, they utilise an ensemble learning strategy to reduce the bias.</p>
</div>
<div id="S3.SS3.SSS6.p3" class="ltx_para">
<p id="S3.SS3.SSS6.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Xie
et al<span class="ltx_text">.</span>, <a href="#bib.bib122" title="" class="ltx_ref">2018</a>)</cite> proposed a model called Semantic Tag-empowered User Intent Classification (ST-UIC), based on a constructed semantic tag repository. This model uses a combination of four kinds of features including characters, non-key-noun part-of-speech tags, target words, and semantic tags. After pre-processing, characters and target word features are extracted for maintaining the contextual information. Then, key nouns are expanded using semantic tags and POS tags are used as features if a query does not contain target words. With this approach, representation can be enriched for short queries.</p>
</div>
<div id="S3.SS3.SSS6.p4" class="ltx_para">
<p id="S3.SS3.SSS6.p4.1" class="ltx_p">In contrast, <cite class="ltx_cite ltx_citemacro_citep">(Tur
et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2011</a>)</cite> tried to simplify the query input based on a dependency parser to generate simple and well-formed queries. They were motivated by the performance gain of existing statistical SLU models on simple, well-formed queries as well as the need for handling increased web search queries formed by key words. They simply kept the top level predicate and its dependants for the query simplification, and combined it with the sentence input for further classification using AdaBoost. The essence here is to try to provide the extracted key word pieces as auxiliary information, which proved to decrease the intent classification error rate. Because some semantic and syntactic information contained in the sentence are filtered out, when this simplified syntactic structure of sentence was used alone as input for classification, a decrease of performance was reported.</p>
</div>
<div id="S3.SS3.SSS6.p5" class="ltx_para">
<p id="S3.SS3.SSS6.p5.1" class="ltx_p">This issue mainly occurs with user queries for web searching. While not widely reported on in the joint task literature, short texts do occur in other data sets and the methods described above can be applied there. Rather than the rule based feature construction approach, knowledge graphs may be further investigated as a method for adding relevant external information.</p>
</div>
</section>
<section id="S3.SS3.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.7. </span>Other feature engineering</h4>

<div id="S3.SS3.SSS7.p1" class="ltx_para">
<p id="S3.SS3.SSS7.p1.1" class="ltx_p">Even when the utterances are longer the challenge is to extract information relevant to the classification task. One early solution generating features using neural networks was by <cite class="ltx_cite ltx_citemacro_citep">(Sarikaya
et al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2011</a>)</cite>, who generated features for a feed-forward network using their DBN-initialised neural network. After training, the features generated by DBNs were found to be useful in discriminative classification tasks.</p>
</div>
<div id="S3.SS3.SSS7.p2" class="ltx_para">
<p id="S3.SS3.SSS7.p2.1" class="ltx_p">Many papers since have used standard word embeddings, RNN and CNN feature creation. In order to boost semantic understanding <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib114" title="" class="ltx_ref">2019b</a>)</cite> proposed to use both in a model called Character-CNN-BGRU. Firstly this model uses character embeddings to represent sentences, rather than word embeddings. A CNN takes the character embedding as the input and extracts local features via max pooling after a convolutional layer. Meanwhile, a window feature sequence layer is added on the convolutional layer to obtain temporal information, which is important for the bidirectional gated recurrent unit (BiGRU). Finally, the output of the max pooling layer and the output of BiGRU are concatenated and passed to a softmax layer.</p>
</div>
<div id="S3.SS3.SSS7.p3" class="ltx_para">
<p id="S3.SS3.SSS7.p3.1" class="ltx_p">While semantic features are useful, methods to extract other usable information for classification have been developed.</p>
</div>
<section id="S3.SS3.SSS7.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Grammar feature exploration</h5>

<div id="S3.SS3.SSS7.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS7.Px1.p1.1" class="ltx_p">From the question answering field comes a feature creation technique based on grammar. Question words, such as ”what”, ”how” and ”where”, and also domain specific grammar may indicate the class of a question. Based on this idea, <cite class="ltx_cite ltx_citemacro_citep">(Mohasseb
et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2018</a>)</cite> proposed a grammar-based framework for question classification, which utilises three features: grammatical features, domain specific grammatical features and grammatical patterns. Grammatical features are used to parse a question into a sequence of grammatical terms. Domain specific features are used to identify the domains which grammatical terms in the sentence correspond to and tag them. After parsing and tagging each term in the question, the pattern is formulated. The classification task is processed using machine learning models, such as SVM or the J48 algorithm.</p>
</div>
</section>
</section>
<section id="S3.SS3.SSS8" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.8. </span>Imbalanced data</h4>

<div id="S3.SS3.SSS8.p1" class="ltx_para">
<p id="S3.SS3.SSS8.p1.1" class="ltx_p">A data set is unlikely to have the same number of samples for each class and sometimes data can be quite imbalanced. Training a model using imbalanced data can cause poor performance on minority classes.</p>
</div>
<div id="S3.SS3.SSS8.p2" class="ltx_para">
<p id="S3.SS3.SSS8.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Purohit et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2015</a>)</cite> noticed that social media text corpora can have such imbalanced data. They suggested that two of their constructed features aid with imbalanced data in their data set. These are Contrast Patterns features, where they mine sequential patterns within each intent class then contrast them. <cite class="ltx_cite ltx_citemacro_citep">(Shridhar
et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2019</a>)</cite> dealt with imbalanced data through oversampling by adding augmented sentences for classes with less samples during the pre-processing stage of their model.</p>
</div>
<div id="S3.SS3.SSS8.p3" class="ltx_para">
<p id="S3.SS3.SSS8.p3.1" class="ltx_p">ATIS, one of the major data sets for the joint task is very imbalanced in the intent aspect, and yet performance is excellent. The imbalanced data issue is rarely brought up in the joint task literature.</p>
</div>
</section>
<section id="S3.SS3.SSS9" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.9. </span>Co-occurrence of words from different intents</h4>

<div id="S3.SS3.SSS9.p1" class="ltx_para">
<p id="S3.SS3.SSS9.p1.1" class="ltx_p">This is a particular form of ambiguity. Words important to different intents may co-occur in a query of a particular intent and how these words are positioned may convey crucial information for intent detection of the current query.</p>
</div>
<div id="S3.SS3.SSS9.p2" class="ltx_para">
<p id="S3.SS3.SSS9.p2.1" class="ltx_p">Based on this idea, <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2016</a>)</cite> proposed two types of heterogeneous information: (1) pairwise word feature correlations (2) POS tags of the queries. The pairwise feature correlations are calculated based on cosine similarity between each semantic feature pair and learned by CNNs with pooling layers. Here each dimension of the word vector is deemed to be a semantic feature. It tries to model the intent through these feature-level representations. Meanwhile the POS tags provide the word-level information about word categories. Their experiment results show that utilising the feature-level semantic representation outperform the baseline model using only word-level features and incorporating POS information with the feature-level representation significantly improves the performance.</p>
</div>
</section>
<section id="S3.SS3.SSS10" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.10. </span>Contextual/temporal information modelling</h4>

<div id="S3.SS3.SSS10.p1" class="ltx_para">
<p id="S3.SS3.SSS10.p1.1" class="ltx_p">A single sentence in a conversation can be ambiguous, but the ambiguity can be eliminated if previous utterances are considered during intent classification. Meanwhile, web queries are sensitive to time and the intent carried by them may change over time; for example as world events wax and wane in importance. Therefore, some studies incorporated contextual and temporal information in intent classification.</p>
</div>
<div id="S3.SS3.SSS10.p2" class="ltx_para">
<p id="S3.SS3.SSS10.p2.1" class="ltx_p">With multi-turn dialogue <cite class="ltx_cite ltx_citemacro_citep">(Bhargava et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2013</a>)</cite> included the context from previous queries for the intent classification and slot filling of the current query. Each sub-task is treated separately, so this is not a joint model. For intent classification, they compared two approaches. The first is to construct a context sessions feature by simply using 1 for the type of intent inferred from the previous utterance set and 0 to all others. This is combined with a basic bag-of-n-gram feature for the current utterance and fed to an SVM for intent classification. The second approach is to treat the query sequence as a sequential tagging problem using SVM-HMMs with a Viterbi algorithm. The incorporation of intent from previous utterances as additional information showed a significant reduction in error rate.</p>
</div>
<div id="S3.SS3.SSS10.p3" class="ltx_para">
<p id="S3.SS3.SSS10.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Hasanuzzaman et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2015</a>)</cite> utilised external resources collected from the web that may help bolster temporal information, such as web snippets for queries and the most relevant year, date and other time indicators. Based on this, 28 features are designed and extracted. Another solution to generate features is referring to one of a set of contemporaneous events, known as event-based web searching. <cite class="ltx_cite ltx_citemacro_citep">(Kanhabua
et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2015</a>)</cite> utilised the event-related log patterns that reveal both implicit and explicit temporal information needs, together with general lexical information such as named entities for feature representation. Classification is performed by SVM, AdaBoost, decision tree/J48, and a neural network.</p>
</div>
<div id="S3.SS3.SSS10.p4" class="ltx_para">
<p id="S3.SS3.SSS10.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2012</a>)</cite> included temporal information in their model as well. They proposed a metadata feature for enhancing community query intent classification. The metadata feature included query topic, query time, and user experience indicated by the number of previous queries. They firstly explored supervised learning using the text and metadata features separately. The result showed that using both two features together outperformed the separate experiment for query intent classification. This drove them to use a co-training procedure, which is a semi-supervised learning framework that can utilise a small amount of annotated queries plus a large amount of unlabelled ones. During the training, two separate and independent classifiers are trained first based on the two features. Then the prediction with higher confidence from either of the classifiers will be used as the label for the unlabelled query for training until a stopping criteria is reached. Utilising the predictions of the two separate classifiers as labels for further training requires that the two features are conditionally independent and sufficient for classification. Experimenting with SVM, higher micro and macro F1 scores were achieved from semi-supervised co-training compared to supervised learning with a combination of the two features.</p>
</div>
<div id="S3.SS3.SSS10.p5" class="ltx_para">
<p id="S3.SS3.SSS10.p5.1" class="ltx_p">Rather than temporal information <cite class="ltx_cite ltx_citemacro_citep">(Qiu
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite> proposed the construction of multiple features from user metadata, regex extraction of named entities, and probabilistic context free grammar of composite entities.</p>
</div>
<div id="S3.SS3.SSS10.p6" class="ltx_para">
<p id="S3.SS3.SSS10.p6.1" class="ltx_p">Contextual and temporal information may be not suitable for all data sets, but, when available, future research can attempt to use it with their models. The multi-turn dialogue approach will be explored further under the joint task. Graphs may also be explored for integration of contemporaneous topics and events.</p>
</div>
</section>
<section id="S3.SS3.SSS11" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.11. </span>Target variation</h4>

<div id="S3.SS3.SSS11.p1" class="ltx_para">
<p id="S3.SS3.SSS11.p1.1" class="ltx_p">Typically in intent classification the pre-defined intents are enumerated and a cross-entropy loss is calculated. <cite class="ltx_cite ltx_citemacro_citep">(Qiu
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite> rather calculated LSTM embeddings of the training sentences and averaged them within samples of the same intent. For test prediction they calculate a similarity measure of the LSTM embedded test sample with the training samples averaged by intent and choose the closest.</p>
</div>
<div id="S3.SS3.SSS11.p2" class="ltx_para">
<p id="S3.SS3.SSS11.p2.1" class="ltx_p">A label can be composed from several words; ”play_music” is composed of ”play” and ”music”, for example. Future research may investigate whether some words in the sentence correspond to ”play” and some other words correspond to ”music”.</p>
</div>
</section>
<section id="S3.SS3.SSS12" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.12. </span>Generalisability via ensembles</h4>

<div id="S3.SS3.SSS12.p1" class="ltx_para">
<p id="S3.SS3.SSS12.p1.1" class="ltx_p">Overfitting of models to the training data distribution leads to poor generalisability. One method to address this is to use ensembles of models to synergistically exploit the benefits of each. Deep learning architectures, such as LSTM, GRU and CNN, have been used frequently in intent classification. <cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2018b</a>)</cite> proposed to combine those deep learning architectures. They used GloVe and word2vec for word embedding. To start exploring combinations of different models, they constructed CNN, LSTM and GRU individually. Then, four ensemble models were built, which are CNN-LSTM, CNN-GRU, LSTM-GRU and CNN-LSTM-GRU. In these models, predictions from individual models are combined using a MLP model. <cite class="ltx_cite ltx_citemacro_citep">(Qiu
et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2018</a>)</cite> also used an ensemble of classical methods, being random forest, SVM, Naïve Bayes and softmax regression, with the ensemble outperforming the components.</p>
</div>
<section id="S3.SS3.SSS12.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Out-of-domain utterances</h5>

<div id="S3.SS3.SSS12.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS12.Px1.p1.1" class="ltx_p">Not all utterances made to SLU devices contain an intent related to the purpose of the device. They may be incidental conversation or have intent that the device is not meant to fulfil.</p>
</div>
<div id="S3.SS3.SSS12.Px1.p2" class="ltx_para">
<p id="S3.SS3.SSS12.Px1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Kim and Kim, <a href="#bib.bib47" title="" class="ltx_ref">2018</a>)</cite> augmented a dataset with such utterances and performed a multi-task learning approach to perform classification of in domain utterances and detection of out-of-domain (OOD) utterances simultaneously. A loss function which maximises the intent accuracy while accepting a value of false acceptance rate (1-recall) for OOD utterances below a threshold is back-propagated. Including the second task boosts the intent detection performance.</p>
</div>
<div id="S3.SS3.SSS12.Px1.p3" class="ltx_para">
<p id="S3.SS3.SSS12.Px1.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Yilmaz and
Toraman, <a href="#bib.bib130" title="" class="ltx_ref">2020</a>)</cite> also constructed augmented data sets with OOD utterances. They constructed a vector of KL divergence values for subsequent pairs of intent probabilities determined from hidden states of a unidirectional LSTM fed with word embeddings. The KL vectors are fed to an SVM, Naïve Bayes and Logistic Regression for OOD classification. Logistic regression gives the best results.</p>
</div>
</section>
</section>
<section id="S3.SS3.SSS13" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.13. </span>Multifaceted query intent prediction</h4>

<div id="S3.SS3.SSS13.p1" class="ltx_para">
<p id="S3.SS3.SSS13.p1.1" class="ltx_p">Most annotated queries in training data sets express only one intent. In real life however, queries may contain more than one intent. For example, the query “find Beyonce’s movie and music” has two intents, ‘find_movie’ and ‘find_music’. An NLU system should be able to handle multi-intent queries.</p>
</div>
<div id="S3.SS3.SSS13.p2" class="ltx_para">
<p id="S3.SS3.SSS13.p2.1" class="ltx_p">One straightforward solution is to use the top couple of predictions from existing single label classifiers. Another solution is having binary classifiers for every label in single classifiers. <cite class="ltx_cite ltx_citemacro_citep">(González-Caro and Baeza-Yates, <a href="#bib.bib33" title="" class="ltx_ref">2011</a>)</cite> used this approach. In their model, each utterances has multiple facets, each a class with at least two categorical labels. For instance, in the Task facet the intent can be ’Informational’, ’Not Informational’, or ’Ambiguous’. They experimented with linear SVMs for intent classification of different combination of the facets. Compared with the corresponding single facet classification, additional supervision from multiple labels led to improvement of the overall performance. This additional information was found beneficial to small categories (classes with few samples in the corpus) with the recall of those small categories improving.</p>
</div>
<div id="S3.SS3.SSS13.p3" class="ltx_para">
<p id="S3.SS3.SSS13.p3.1" class="ltx_p">Treating multi-labels as atomic labels has been explored in some studies. This approach may suffer data sparsity problem, but has good classification accuracy. Based on this, <cite class="ltx_cite ltx_citemacro_citep">(Xu and Sarikaya, <a href="#bib.bib125" title="" class="ltx_ref">2013</a>)</cite> proposed two approaches to exploit the information shared among different intent combinations. The first one is adding class features, which is to add n-gram features for combined intent appropriate to the separated intents. For example, the multi-intent label, ’buy_game#play_game’, should have added two features for the embedded intents ’buy_game’ and ’play_game’. The other is adding hidden variables to identify segments belonging to each intent. Instead of using existing segmentation algorithms, they add a layer of hidden states corresponding to each word. This can indicate the embedded intent which a word most strongly aligns to. Following that, a perceptron layer performs the classification.</p>
</div>
<div id="S3.SS3.SSS13.p4" class="ltx_para">
<p id="S3.SS3.SSS13.p4.1" class="ltx_p">Understanding queries with multiple intents can make conversations with dialogue systems more natural and smooth, but there is not much work in this area. Further research could explore more approaches on modelling relations among label combinations.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Slot filling</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Slot filling is the second critical task in natural language understanding. It is the attachment of a label to each token in an utterance. The label describes the type of semantic information contained in the word represented by the token. A span is a contiguous set of words which together make up a semantic unit, for example “new york city” is a single span represented in BIO notation with the labels <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">B-city I-city I-city</span>. Slot filling is treated as a sequence labelling task. The task is learning not just slot label distributions for words but also what slot labels typically co-occur in utterances (label dependency), and in what order. Reference to context in both directions of a word should be included to maximise performance.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Major areas of research</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Slot filling is a key task in dialogue systems, to interpret natural language from users, from which the system can judge what information to retrieve or what task to complete for the user. Slot filling models are also integrated with online shopping websites, whose core is a task-oriented dialog system. Product search queries can be better understood and shopping assistance can be provided to customers. The field of question answering has provided research to extract the semantic features within queries.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Overview of technological approaches</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Traditionally, generative models (for example, HMMs <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib119" title="" class="ltx_ref">2005</a>)</cite>) which capture the joint probability distribution of the utterance tokens and their slot labels, and discriminative models (like CRFs) that estimate slot label conditional probabilities given the observed token sequence, were used to address this problem. With the success of deep learning, researchers experimented with putting components, for example, CRFs and brief networks, within a deep structure.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Since 2013, RNNs have been increasingly popular in this field. In RNNs each word can access information from the previous words. Later, bi-directional RNNs were applied to utilise both the past and future context. However, the distance between words is linear in RNNs, and the vanishing gradient problem may occur, meaning that long-term dependencies cannot be learnt by the model. As a result, LSTM cells began to be used more frequently because of their ability to forget unimportant information and more successfully model longer dependencies. However, even LSTMs can underperform with very long sentences. Other models are thus incorporated to capture label dependency, which refers to the situation that some slots appear in context with some other slots more frequently, and perform sequence-level optimisation. The combination of CRF layers attached to RNNs is often seen.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Another issue is that RNNs are typically not able to process multiple words simultaneously due to their sequential nature. Thus, attention mechanisms which can take more tokens into account simultaneously than RNNs are used. Additional features are also incorporated to improve the performance of RNNs, such as named entity features, segment features and external memory. Integrating extra knowledge from different sources is also considered an effective approach. Some recent slot filling models also attempt to handle unseen semantic labels and multiple domain tasks by adapting neural CRFs and label embedding.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Exploring new models in detail</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">Models that have proved reliable for sequence labelling in other fields have been adopted in addressing the slot filling problem. In particular, deep learning models have been applied in slot filling.</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Deng
et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2012</a>)</cite> made an early deep model by constructing a stacked model, in their case a deep convex network (DCN), and extended it to the kernel version (K-DCN) for domain and intent classification tasks. With the kernel approach, the number of layers can be increased. Later, they attempted to solve slot filling problems using K-DCN as feature extractors.</p>
</div>
<div id="S4.SS2.SSS1.p3" class="ltx_para">
<p id="S4.SS2.SSS1.p3.1" class="ltx_p">RNNs with different architectures have been explored in many studies, considering their promising performance in sequence modeling elsewhere. In 2013, <cite class="ltx_cite ltx_citemacro_citep">(Mesnil
et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2013</a>)</cite> compared recurrent neural networks, including Elman-type and Jordan-type networks and bi-directional Jordan-type RNNs. Two years later, <cite class="ltx_cite ltx_citemacro_citep">(Mesnil et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2015</a>)</cite> implemented Elman-type and Jordan-type networks and also their variations. Both Elman and Jordan-type networks are constructed with a 3-word context window. Moreover, a bi-directional Jordan-type network was implemented which takes both past and future information into account.</p>
</div>
<div id="S4.SS2.SSS1.p4" class="ltx_para">
<p id="S4.SS2.SSS1.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Yao
et al<span class="ltx_text">.</span>, <a href="#bib.bib129" title="" class="ltx_ref">2013</a>)</cite> adopted Recurrent Neural Network Language Models (RNN-LMs) to predict slot labels rather than words. This model used an Elman architecture RNN which can remember past words. Originally, the output of the training model is exactly the input word sequence, but in the new model, the outputs are sequences of labels instead. Future words, named entities, syntactic features and word-class information were also integrated in the analysis.</p>
</div>
<div id="S4.SS2.SSS1.p5" class="ltx_para">
<p id="S4.SS2.SSS1.p5.1" class="ltx_p">In the first models using RNNs in NLU, only words preceding the current word were considered. However, words occurring after the current word can also provide useful information. Therefore, <cite class="ltx_cite ltx_citemacro_citep">(Vu
et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2016</a>)</cite> use bi-directional Elman-type networks with a 3-word context window. In their network, the BiLSTM generates forward output and backward output, which are combined for making predictions. The model adopts the ranking loss function, so the model is not forced to learn a pattern for the artificial class O. In an extension <cite class="ltx_cite ltx_citemacro_citep">(Vu, <a href="#bib.bib108" title="" class="ltx_ref">2016</a>)</cite> proposed a bi-directional sequential CNN for slot labelling which considers both previous contextual words with preserved order, surrounding context and also past and future information. To label a word, two matrices are separately generated for the previous and future context words of the word. These are combined to form a matrix for the current word. Then, the two matrices for the past and future information are passed to corresponding vanilla sequential CNNs. The output of networks are concatenated with the matrix for the current word. After that two matrices can be combined using a weighted sum of the forward and the backward hidden layer or by concatenating. For training, the ranking loss function is again applied.</p>
</div>
<div id="S4.SS2.SSS1.p6" class="ltx_para">
<p id="S4.SS2.SSS1.p6.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Korpusik
et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2019</a>)</cite> perform a useful comparison of BiGRU, CNN and BERT based models with the then new BERT outperforming the other candidates.</p>
</div>
<div id="S4.SS2.SSS1.p7" class="ltx_para">
<p id="S4.SS2.SSS1.p7.1" class="ltx_p">The incorporation of newer technologies for slot labelling, particularly seemingly suitable attention based methods like the Transformer, has been subsumed by the joint task in more recent years as will be explored in Section <a href="#S5" title="5. Joint intent and slot models ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6. </span>Slot filling papers reviewed with addressed issue and approach</figcaption>
<table id="S4.T6.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T6.1.1.1" class="ltx_tr">
<td id="S4.T6.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.1.1.1.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T6.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Paper</span></span>
</span>
</td>
<td id="S4.T6.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.1.1.2.1.1" class="ltx_p" style="width:139.4pt;"><span id="S4.T6.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Addressed issue</span></span>
</span>
</td>
<td id="S4.T6.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.1.1.3.1.1" class="ltx_p" style="width:239.0pt;"><span id="S4.T6.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Approach</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.1.2.2" class="ltx_tr">
<td id="S4.T6.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.2.2.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib131" title="" class="ltx_ref">2011</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.2.2.2.1.1" class="ltx_p" style="width:139.4pt;">Long-range state dependency</span>
</span>
</td>
<td id="S4.T6.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.2.2.3.1.1" class="ltx_p" style="width:239.0pt;">Deep learning, CRF</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.3.3" class="ltx_tr">
<td id="S4.T6.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.3.3.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Deng
et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2012</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.3.3.2.1.1" class="ltx_p" style="width:139.4pt;">To extend DCN</span>
</span>
</td>
<td id="S4.T6.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.3.3.3.1.1" class="ltx_p" style="width:239.0pt;">Kernel learning, deep learning, DCN, log-linear model</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.4.4" class="ltx_tr">
<td id="S4.T6.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.4.4.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Deoras and
Sarikaya, <a href="#bib.bib24" title="" class="ltx_ref">2013</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.4.4.2.1.1" class="ltx_p" style="width:139.4pt;">Data sparsity problem (CRF)</span>
</span>
</td>
<td id="S4.T6.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.4.4.3.1.1" class="ltx_p" style="width:239.0pt;">Deep belief network (DBN)</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.5.5" class="ltx_tr">
<td id="S4.T6.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.5.5.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Mesnil
et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2013</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.5.5.2.1.1" class="ltx_p" style="width:139.4pt;">To explore RNN</span>
</span>
</td>
<td id="S4.T6.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.5.5.3.1.1" class="ltx_p" style="width:239.0pt;">RNN</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.6.6" class="ltx_tr">
<td id="S4.T6.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.6.6.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yao
et al<span class="ltx_text">.</span>, <a href="#bib.bib129" title="" class="ltx_ref">2013</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.6.6.2.1.1" class="ltx_p" style="width:139.4pt;">To explore RNN-LM</span>
</span>
</td>
<td id="S4.T6.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.6.6.3.1.1" class="ltx_p" style="width:239.0pt;">RNN-LM</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.7.7" class="ltx_tr">
<td id="S4.T6.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.7.7.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib128" title="" class="ltx_ref">2014b</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.7.7.2.1.1" class="ltx_p" style="width:139.4pt;">Label dependencies, label bias problem</span>
</span>
</td>
<td id="S4.T6.1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.7.7.3.1.1" class="ltx_p" style="width:239.0pt;">RNN, CRF</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.8.8" class="ltx_tr">
<td id="S4.T6.1.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.8.8.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2014a</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.8.8.2.1.1" class="ltx_p" style="width:139.4pt;">Gradient diminishing and exploding problem, label dependencies, label bias problem</span>
</span>
</td>
<td id="S4.T6.1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.8.8.3.1.1" class="ltx_p" style="width:239.0pt;">LSTM, regression model, deep learning</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.9.9" class="ltx_tr">
<td id="S4.T6.1.9.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.9.9.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib58" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.9.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.9.9.2.1.1" class="ltx_p" style="width:139.4pt;">Label dependencies</span>
</span>
</td>
<td id="S4.T6.1.9.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.9.9.3.1.1" class="ltx_p" style="width:239.0pt;">RNN, sampling approach</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.10.10" class="ltx_tr">
<td id="S4.T6.1.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.10.10.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Mesnil et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.10.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.10.10.2.1.1" class="ltx_p" style="width:139.4pt;">To explore RNN</span>
</span>
</td>
<td id="S4.T6.1.10.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.10.10.3.1.1" class="ltx_p" style="width:239.0pt;">RNN</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.11.11" class="ltx_tr">
<td id="S4.T6.1.11.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.11.11.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Peng and Yao, <a href="#bib.bib76" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.11.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.11.11.2.1.1" class="ltx_p" style="width:139.4pt;">Vanishing and exploding gradient</span>
</span>
</td>
<td id="S4.T6.1.11.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.11.11.3.1.1" class="ltx_p" style="width:239.0pt;">RNN, external memory</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.12.12" class="ltx_tr">
<td id="S4.T6.1.12.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.12.12.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Kurata
et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.12.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.12.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.12.12.2.1.1" class="ltx_p" style="width:139.4pt;">Label dependencies</span>
</span>
</td>
<td id="S4.T6.1.12.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.12.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.12.12.3.1.1" class="ltx_p" style="width:239.0pt;">LSTM, encoder-labeler</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.13.13" class="ltx_tr">
<td id="S4.T6.1.13.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.13.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.13.13.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Vu
et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.13.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.13.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.13.13.2.1.1" class="ltx_p" style="width:139.4pt;">To explore past and future information</span>
</span>
</td>
<td id="S4.T6.1.13.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.13.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.13.13.3.1.1" class="ltx_p" style="width:239.0pt;">Bi-directional RNN, ranking loss function</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.14.14" class="ltx_tr">
<td id="S4.T6.1.14.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.14.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.14.14.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Vu, <a href="#bib.bib108" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.14.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.14.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.14.14.2.1.1" class="ltx_p" style="width:139.4pt;">To explore CNN</span>
</span>
</td>
<td id="S4.T6.1.14.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.14.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.14.14.3.1.1" class="ltx_p" style="width:239.0pt;">CNN</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.15.15" class="ltx_tr">
<td id="S4.T6.1.15.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.15.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.15.15.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhu and Yu, <a href="#bib.bib147" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.15.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.15.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.15.15.2.1.1" class="ltx_p" style="width:139.4pt;">To explore attention mechanism</span>
</span>
</td>
<td id="S4.T6.1.15.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.15.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.15.15.3.1.1" class="ltx_p" style="width:239.0pt;">Bi-directional LSTM, LSTM, encoder-decoder, focus mechanism</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.16.16" class="ltx_tr">
<td id="S4.T6.1.16.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T6.1.16.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.16.16.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Dai et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.16.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T6.1.16.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.16.16.2.1.1" class="ltx_p" style="width:139.4pt;">Unseen slots</span>
</span>
</td>
<td id="S4.T6.1.16.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T6.1.16.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.16.16.3.1.1" class="ltx_p" style="width:239.0pt;">CRF</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.17.17" class="ltx_tr">
<td id="S4.T6.1.17.17.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.17.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.17.17.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.17.17.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.17.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.17.17.2.1.1" class="ltx_p" style="width:139.4pt;">To explore MTL</span>
</span>
</td>
<td id="S4.T6.1.17.17.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.17.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.17.17.3.1.1" class="ltx_p" style="width:239.0pt;">MTL, segment tagging, NER</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.18.18" class="ltx_tr">
<td id="S4.T6.1.18.18.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.18.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.18.18.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Louvan and
Magnini, <a href="#bib.bib64" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.18.18.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.18.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.18.18.2.1.1" class="ltx_p" style="width:139.4pt;">To explore MTL</span>
</span>
</td>
<td id="S4.T6.1.18.18.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.18.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.18.18.3.1.1" class="ltx_p" style="width:239.0pt;">MTL, NER, bi-LSTM, CRF</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.19.19" class="ltx_tr">
<td id="S4.T6.1.19.19.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.19.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.19.19.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Shin
et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.19.19.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.19.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.19.19.2.1.1" class="ltx_p" style="width:139.4pt;">To better labelling common words</span>
</span>
</td>
<td id="S4.T6.1.19.19.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.19.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.19.19.3.1.1" class="ltx_p" style="width:239.0pt;">Encoder-decoder attention, delexicalised sentence generation</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.20.20" class="ltx_tr">
<td id="S4.T6.1.20.20.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.20.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.20.20.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018a</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.20.20.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.20.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.20.20.2.1.1" class="ltx_p" style="width:139.4pt;">Imbalanced data</span>
</span>
</td>
<td id="S4.T6.1.20.20.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.20.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.20.20.3.1.1" class="ltx_p" style="width:239.0pt;">DNN, reinforcement learning</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.21.21" class="ltx_tr">
<td id="S4.T6.1.21.21.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.21.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.21.21.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhao and Feng, <a href="#bib.bib143" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.21.21.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.21.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.21.21.2.1.1" class="ltx_p" style="width:139.4pt;">OOV</span>
</span>
</td>
<td id="S4.T6.1.21.21.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.21.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.21.21.3.1.1" class="ltx_p" style="width:239.0pt;">GRU, attention, pointer network</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.22.22" class="ltx_tr">
<td id="S4.T6.1.22.22.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.22.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.22.22.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.22.22.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.22.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.22.22.2.1.1" class="ltx_p" style="width:139.4pt;">To explore MTL</span>
</span>
</td>
<td id="S4.T6.1.22.22.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.22.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.22.22.3.1.1" class="ltx_p" style="width:239.0pt;">MTL, segment tagging, NER</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.23.23" class="ltx_tr">
<td id="S4.T6.1.23.23.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.23.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.23.23.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Kim
et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.23.23.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.23.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.23.23.2.1.1" class="ltx_p" style="width:139.4pt;">To extend original SLU to H2H conversations</span>
</span>
</td>
<td id="S4.T6.1.23.23.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.23.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.23.23.3.1.1" class="ltx_p" style="width:239.0pt;">Bi-LSTM, different knowledge sources</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.24.24" class="ltx_tr">
<td id="S4.T6.1.24.24.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.24.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.24.24.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2019b</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.24.24.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.24.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.24.24.2.1.1" class="ltx_p" style="width:139.4pt;">Continual learning</span>
</span>
</td>
<td id="S4.T6.1.24.24.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.24.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.24.24.3.1.1" class="ltx_p" style="width:239.0pt;">Bi-LSTM, context gate</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.25.25" class="ltx_tr">
<td id="S4.T6.1.25.25.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.25.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.25.25.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Veyseh
et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.25.25.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.25.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.25.25.2.1.1" class="ltx_p" style="width:139.4pt;">Restricted utilising contextual information</span>
</span>
</td>
<td id="S4.T6.1.25.25.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.25.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.25.25.3.1.1" class="ltx_p" style="width:239.0pt;">MTL, Bi-LSTM</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.26.26" class="ltx_tr">
<td id="S4.T6.1.26.26.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.26.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.26.26.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Korpusik
et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.26.26.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.26.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.26.26.2.1.1" class="ltx_p" style="width:139.4pt;">Architecture comparison</span>
</span>
</td>
<td id="S4.T6.1.26.26.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.26.26.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.26.26.3.1.1" class="ltx_p" style="width:239.0pt;">BiGRU, CNN, BERT</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.27.27" class="ltx_tr">
<td id="S4.T6.1.27.27.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.27.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.27.27.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Louvan and
Magnini, <a href="#bib.bib65" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.27.27.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.27.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.27.27.2.1.1" class="ltx_p" style="width:139.4pt;">Low resource data set</span>
</span>
</td>
<td id="S4.T6.1.27.27.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.27.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.27.27.3.1.1" class="ltx_p" style="width:239.0pt;">MTL</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.28.28" class="ltx_tr">
<td id="S4.T6.1.28.28.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.28.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.28.28.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhu
et al<span class="ltx_text">.</span>, <a href="#bib.bib148" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.28.28.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.28.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.28.28.2.1.1" class="ltx_p" style="width:139.4pt;">Data sparsity problem</span>
</span>
</td>
<td id="S4.T6.1.28.28.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.1.28.28.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.28.28.3.1.1" class="ltx_p" style="width:239.0pt;">Prior knowledge driven label embedding, CRF</span>
</span>
</td>
</tr>
<tr id="S4.T6.1.29.29" class="ltx_tr">
<td id="S4.T6.1.29.29.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t">
<span id="S4.T6.1.29.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.29.29.1.1.1" class="ltx_p" style="width:99.6pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020a</a>)</cite></span>
</span>
</td>
<td id="S4.T6.1.29.29.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t">
<span id="S4.T6.1.29.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.29.29.2.1.1" class="ltx_p" style="width:139.4pt;">Long range dependency, vanishing gradient</span>
</span>
</td>
<td id="S4.T6.1.29.29.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t">
<span id="S4.T6.1.29.29.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.1.29.29.3.1.1" class="ltx_p" style="width:239.0pt;">TDNN</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Issues addressed by slot labelling papers</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Like intent detection, issues found in slot filling can be task specific, more general machine learning issues, data set issues, or may involve feature engineering or methodological approaches for better results. Slot filling introduces issues typical to seq2seq tasks like label dependency and long distance dependency.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1. </span>Label dependency</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">There are dependencies between slot labels, meaning that some slots appear more commonly with some other slots in the same utterance. For example, in a travel data set it is highly probable that <span id="S4.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_italic">B-FromCity</span> and <span id="S4.SS3.SSS1.p1.1.2" class="ltx_text ltx_font_italic">B-ToCity</span> are in the same sentence. Capturing such label dependencies would help find the best slot combinations and generate better prediction results.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p">One approach is to integrate CRFs and regression models. <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2014a</a>)</cite> applied an LSTM for the slot labelling task and included a regression model to capture label dependencies. <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib128" title="" class="ltx_ref">2014b</a>)</cite> proposed a recurrent conditional random ﬁeld (R-CRF) which integrates recurrent neural networks and a CRF to explicitly model the dependencies between semantic labels and achieve sequence-level optimisation. The R-CRF can use the RNN activations as features of the CRF. Similar to CRFs, this model can use sequence-level optimisation as well.</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p id="S4.SS3.SSS1.p3.1" class="ltx_p">Another solution utilises the encoder-decoder architecture, which had been applied for machine translation previously and is able to encode the global information of the input sentence. <cite class="ltx_cite ltx_citemacro_citep">(Kurata
et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2016</a>)</cite> proposed the encoder-labeler LSTM. This architecture encodes the sentence to a fixed length vector. Then, the encoding vectors are used as the input of another LSTM, the labeler LSTM, which considers label dependencies. The labeler LSTM can predict the slot label conditioned on the encoded sentence information. With such a method, the model is able to label slots utilising the whole sentence information. <cite class="ltx_cite ltx_citemacro_citep">(Zhu and Yu, <a href="#bib.bib147" title="" class="ltx_ref">2017</a>)</cite> proposed a BiLSTM-LSTM encoder-decoder model, where a sentence is encoded using a bi-directional LSTM and the encoded sentence is then decoded using a uni-directional LSTM. At the same time, they developed a focus mechanism for this model because of the alignment limitation of attention mechanisms.</p>
</div>
<div id="S4.SS3.SSS1.p4" class="ltx_para">
<p id="S4.SS3.SSS1.p4.1" class="ltx_p">Moreover, <cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib58" title="" class="ltx_ref">2015</a>)</cite> used continuous vectors to represent possible output labels, which are fed to recurrent connections. These continuous vectors are also fed to hidden layers, so every hidden layer can utilise word input, previous hidden states and predicted output labels. Moreover, both true labels and the predicted output labels can be fed to some layers in a fashion decided by a sampling approach for robustness. Because the previous predicted labels are used as input to the next step, error propagation should be studied further.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2. </span>Long range dependency</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">Long-range dependency (LRD), also called long memory or long-range persistence, is a phenomenon that may arise in the analysis of spatial or time series data. It relates to the rate of decay of statistical dependence of two points with increasing time interval or spatial distance between the points. While the short text queries described in the intent section should not suffer from this, utterances in SLU data sets can be much longer.</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p id="S4.SS3.SSS2.p2.1" class="ltx_p">The approach from <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib131" title="" class="ltx_ref">2011</a>)</cite> is a deep structured CRF which is made up of several simple CRFs. Lower layers can generate frame-level marginal posterior probabilities. Then the higher layer takes these probabilities along with the observation sequence of the previous layer. In the end, the highest level will make the final predictions. In the training process, layers are trained separately for efficiency. For each layer, the parameters are determined once the layer is trained.</p>
</div>
<div id="S4.SS3.SSS2.p3" class="ltx_para">
<p id="S4.SS3.SSS2.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020a</a>)</cite> addressed the shortcomings of RNN being the long range dependency issue and vanishing or exploding gradient. They used a deep stacking of time delay neural networks for feature creation. These create convolutional features from context windows of varying size and varying step sizes through the sentences. The features are then passed through a final RNN and classified.</p>
</div>
<div id="S4.SS3.SSS2.p4" class="ltx_para">
<p id="S4.SS3.SSS2.p4.1" class="ltx_p">The Transformer architecture, which utilises self attention across utterances, and memory networks which can store longer range information, are now studied in the joint task, as described in the next section. Focused research using these methods for only the slot task may uncover useful methods for use in the joint task.</p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3. </span>The label bias problem</h4>

<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p id="S4.SS3.SSS3.p1.1" class="ltx_p">Label bias is a seq2seq issue related to maximum entropy Markov models (MEMM). In MEMM, the states with a single outgoing transition can ignore their observation, meaning that the model can tend to stay in a state which is unlikely to happen. Most approaches to this problem combine CRFs with RNNs.</p>
</div>
<div id="S4.SS3.SSS3.p2" class="ltx_para">
<p id="S4.SS3.SSS3.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2014a</a>)</cite> applied LSTM cells, which contain a gate which can forget unimportant information, and also incorporated a regression model to model label dependencies. In order to avoid the label bias problem, the regression model took non-normalised scores before softmax. The R-CRF of <cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib128" title="" class="ltx_ref">2014b</a>)</cite> also addresses label bias. Similarly, <cite class="ltx_cite ltx_citemacro_citep">(Mesnil et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2015</a>)</cite> explored RNNs with multiple different architectures and proposed to apply Viterbi encodings and recurrent CRFs to eliminate the label bias problem.</p>
</div>
</section>
<section id="S4.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.4. </span>Learning common words</h4>

<div id="S4.SS3.SSS4.p1" class="ltx_para">
<p id="S4.SS3.SSS4.p1.1" class="ltx_p">The surrounding words of one slot in different sentences are usually similar. For example, the word ”to” is highly likely to be lie between <span id="S4.SS3.SSS4.p1.1.1" class="ltx_text ltx_font_italic">B-FromCity</span> and <span id="S4.SS3.SSS4.p1.1.2" class="ltx_text ltx_font_italic">B-ToCity</span>. Therefore, <cite class="ltx_cite ltx_citemacro_citep">(Kurata
et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2016</a>)</cite> thought that learning the common words around slots in different ways may be helpful for slot filling.</p>
</div>
<div id="S4.SS3.SSS4.p2" class="ltx_para">
<p id="S4.SS3.SSS4.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Shin
et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2018</a>)</cite> introduced a model which can jointly generate delexicalised sentences and predict labels using the encoder-decoder framework with input alignment. In the delexicalised sentences, words are replaced by their corresponding slot labels. For example, to delexicalise the sentence “i want to fly from baltimore to dallas”, the words ‘baltimore’ and ‘dallas’ should be replaced by <span id="S4.SS3.SSS4.p2.1.1" class="ltx_text ltx_font_italic">B-FromCity</span> and <span id="S4.SS3.SSS4.p2.1.2" class="ltx_text ltx_font_italic">B-ToCity</span>. This approach is based on the fact that different words that correspond to the same slot usually play a similar semantic and syntactic role in the sentence, which allows the model to learn the common words surrounding the slots.</p>
</div>
</section>
<section id="S4.SS3.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.5. </span>Low resource data sets</h4>

<div id="S4.SS3.SSS5.p1" class="ltx_para">
<p id="S4.SS3.SSS5.p1.1" class="ltx_p">A more general machine learning issue is that methods generally rely on the presence of annotated training data which is costly to produce. <cite class="ltx_cite ltx_citemacro_citep">(Louvan and
Magnini, <a href="#bib.bib65" title="" class="ltx_ref">2019</a>)</cite> tested models which also trained on a large freely available annotated data set for a similar task (NER for example) in a multi-task learning environment (see Section <a href="#S4.SS3.SSS11" title="4.3.11. Exploring multi-task learning ‣ 4.3. Issues addressed by slot labelling papers ‣ 4. Slot filling ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.11</span></a>. They then used just 10% of the available training data from slot tagging data sets to train the slot labelling task. They varied this proportion and observed when it reached 40% that the auxiliary task stopped having much effect.</p>
</div>
</section>
<section id="S4.SS3.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.6. </span>Diminishing and exploding gradients</h4>

<div id="S4.SS3.SSS6.p1" class="ltx_para">
<p id="S4.SS3.SSS6.p1.1" class="ltx_p">In neural networks with multiple layers, or long RNN sequences, the gradient may become vanishingly small, preventing the weights from changing value during back-propagation. Alternatively, large gradients may self-propagate and lead to unstable networks.</p>
</div>
<div id="S4.SS3.SSS6.p2" class="ltx_para">
<p id="S4.SS3.SSS6.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2014a</a>)</cite> combined an LSTM and a regression model for slot filling. LSTM are partially designed to address these issues. To avoid the gradient diminishing and exploding problem, the memory cells within them are linearly activated and propagated between different time steps.</p>
</div>
<div id="S4.SS3.SSS6.p3" class="ltx_para">
<p id="S4.SS3.SSS6.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Peng and Yao, <a href="#bib.bib76" title="" class="ltx_ref">2015</a>)</cite> introduced an external memory to overcome the limitations on memory capacity of simple RNNs and therefore the diminishing and exploding gradient problems can be addressed. The new model is call RNN-EM, where the hidden layer has an additional input that comes from the external memory. A weight vector is used to retrieve the content from the external memory, which is determined according to the similarity between the contents and the hidden layer.</p>
</div>
</section>
<section id="S4.SS3.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.7. </span>Data sparsity problem</h4>

<div id="S4.SS3.SSS7.p1" class="ltx_para">
<p id="S4.SS3.SSS7.p1.1" class="ltx_p">Data sparsity can be an issue when there are a large number of discrete features. If those discrete feature are represented using matrices, those matrices can be large and sparse, which may lead to a model ignoring the relations among features.</p>
</div>
<div id="S4.SS3.SSS7.p2" class="ltx_para">
<p id="S4.SS3.SSS7.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Deoras and
Sarikaya, <a href="#bib.bib24" title="" class="ltx_ref">2013</a>)</cite> applied deep belief networks (DBN) for semantic tagging integrated with lexical, named entity, dependency parser based syntactic features and part of speech (POS) tags. A DBN is a stack of Restricted Boltzmann Machines (RBMs), where the input of one layer is the output of the previous one and each layer applies a sigmoid activation function on their inputs. In this model, features are embedded into vectors at the first layer and passed to the next layer due to the large input layer. During the pre-training process, the parameters of neurons are learnt using the online version of conjugate gradient (CG) optimisation on several small batches. Compared to CRF, DBN is more general.</p>
</div>
<div id="S4.SS3.SSS7.p3" class="ltx_para">
<p id="S4.SS3.SSS7.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Zhu
et al<span class="ltx_text">.</span>, <a href="#bib.bib148" title="" class="ltx_ref">2020</a>)</cite> noticed that the data sparsity problem can also occur with labels because labels are usually encoded using one-hot vectors, so they also proposed a label embedding which is constructed using prior knowledge including atomic concepts, slot descriptions, and slot exemplars. An atomic concept assumes that each slot can be represented as a set of atoms. Slot descriptions are the textual description for slots in natural language. Slot exemplars are to extract label embeddings for slot labels which contain values of each slot and their neighbour contexts.</p>
</div>
</section>
<section id="S4.SS3.SSS8" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.8. </span>Continuous learning</h4>

<div id="S4.SS3.SSS8.p1" class="ltx_para">
<p id="S4.SS3.SSS8.p1.1" class="ltx_p">With new data becoming available quickly, it is desirable to have a retrained model incorporating the new data. However, the training process could be time and cost consuming and keeping all the existing data can introduce redundancy. Thus, there is a problem of how to continuously learn from new data.</p>
</div>
<div id="S4.SS3.SSS8.p2" class="ltx_para">
<p id="S4.SS3.SSS8.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2019b</a>)</cite> proposed a ProgModel, consisting of a context gate. This gate aims to transfer previously learned knowledge to a small expanded component, which is placed after the hidden state of the new model. The training procedure is progressively conducted at each batch. Therefore, the model can learn faster from the new training data without forgetting the previous expressions.</p>
</div>
</section>
<section id="S4.SS3.SSS9" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.9. </span>Imbalanced data</h4>

<div id="S4.SS3.SSS9.p1" class="ltx_para">
<p id="S4.SS3.SSS9.p1.1" class="ltx_p">Training data sets can be imbalanced, dominated by some tags while only containing a small number of examples of other tags. This can lead to poorer performance in the minority tags. One solution from the slot labelling literature comes from <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018a</a>)</cite> who design a deep reinforcement learning (DRL) based augmented tagger with a deep neural network, which includes a training part and an inference part. While the whole data set is used in the training part, only partial data with unsatisfactory performance will be evaluated by the augmented tagger.</p>
</div>
<div id="S4.SS3.SSS9.p2" class="ltx_para">
<p id="S4.SS3.SSS9.p2.1" class="ltx_p">Similarly to intent classification, augmentation via generating sentences which contain the minor tags could be researched.</p>
</div>
</section>
<section id="S4.SS3.SSS10" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.10. </span>Unseen labels</h4>

<div id="S4.SS3.SSS10.p1" class="ltx_para">
<p id="S4.SS3.SSS10.p1.1" class="ltx_p">As with intent classification models, slot labelling models can rely heavily on the training data and will struggle to correctly assign a label which does not appear in the training data.</p>
</div>
<div id="S4.SS3.SSS10.p2" class="ltx_para">
<p id="S4.SS3.SSS10.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Zhao and Feng, <a href="#bib.bib143" title="" class="ltx_ref">2018</a>)</cite> proposed a seq2seq model together with a pointer network to solve this problem. This model predicts slot values by jointly learning to copy a word which may be out-of-vocabulary (OOV) from an input utterance through a pointer network, or generate a word within the vocabulary through a seq2Seq model with attention.</p>
</div>
<div id="S4.SS3.SSS10.p3" class="ltx_para">
<p id="S4.SS3.SSS10.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Dai et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2018</a>)</cite> proposed an elastic conditional random field (eCRF) which can utilise semantic meaning in slot embedding for open-ontology slot filling. The model has a slot description encoder which takes all slot descriptions as input, and outputs distributed representations for slots. Meanwhile, a BiLSTM is used to extract features from utterances. Then, the eCRF labeller, which is a potential function containing two terms for semantic similarity of the slot descriptions and the extracted contextual features and interactions between the slot labels, is applied.</p>
</div>
</section>
<section id="S4.SS3.SSS11" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.11. </span>Exploring multi-task learning</h4>

<div id="S4.SS3.SSS11.p1" class="ltx_para">
<p id="S4.SS3.SSS11.p1.1" class="ltx_p">Multi-task learning (MTL) is the idea that similar auxiliary tasks can assist a main task. Some papers have used this idea setting slot labelling as the main task.</p>
</div>
<div id="S4.SS3.SSS11.p2" class="ltx_para">
<p id="S4.SS3.SSS11.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Louvan and
Magnini, <a href="#bib.bib64" title="" class="ltx_ref">2018</a>)</cite> attempted to perform slot filling and named entity recognition (NER) jointly in a multi-task framework considering that most slot values are also named entities and NER has high state-of-the-art performance. They mentioned that a better slot tagging result can be achieved if NER is at a lower level. Similarly, <cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2019</a>)</cite> investigated hierarchical multi-task learning to perform low-level tasks first, namely named entity tagging and segment tagging, and then the high-level task, that is slot labelling, can make use of the results from the low levels with cascade and residual connections. <cite class="ltx_cite ltx_citemacro_citep">(Louvan and
Magnini, <a href="#bib.bib65" title="" class="ltx_ref">2019</a>)</cite> then performed a more wide ranging experiment with two auxiliary tasks (NER and semantic tagging (SemTag)), and a comparison of a training on auxiliary task(s) followed by fine-tuning on the main task approach versus the previously explored hierarchical approach. They found generally the hierarchical approach gave better results and that parsimoniously using only one auxiliary task (NER) worked better.</p>
</div>
<div id="S4.SS3.SSS11.p3" class="ltx_para">
<p id="S4.SS3.SSS11.p3.1" class="ltx_p">Most models utilise contextual information, but they use it in a restricted manner, for example, self-attention. Therefore, <cite class="ltx_cite ltx_citemacro_citep">(Veyseh
et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2019</a>)</cite> proposed a multi-task setting to train a model to incorporate the contextual information in two different levels which are representation level and task-specific level. This multi-task setting includes the slot filling as the main task and two auxiliary tasks. The first one is to increase consistency between the word representation and its context and another one is to enhance task specific information in contextual information.</p>
</div>
</section>
<section id="S4.SS3.SSS12" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.12. </span>Extending to human-to-human conversations</h4>

<div id="S4.SS3.SSS12.p1" class="ltx_para">
<p id="S4.SS3.SSS12.p1.1" class="ltx_p">As the main thrust of this survey shows, task oriented language understanding in human-to-machine (H2M) conversations has been extensively studied. An interesting twist is to perform slot tagging in human-to-human (H2H) conversations. Here the agent is a third party listening in, not being directly asked to perform a task.</p>
</div>
<div id="S4.SS3.SSS12.p2" class="ltx_para">
<p id="S4.SS3.SSS12.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Kim
et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2019</a>)</cite> focused on slot filling in H2H conversations and explored LSTMs with different knowledge sources. First, the character embedding and the word embedding are concatenated for each word. Then, the embeddings are passed to a bi-directional LSTM, which will be used for making final predictions. Furthermore, there is an additional model which can utilise knowledge from multiple sources, including sentence embeddings for H2H conversation, contextual information and H2M expert feedback. The sentence embeddings are generated by a sentence level embedding model trained using tweets with URL and web search queries to the same URL. The contextual information is extracted from previous utterances in the conversation. Also, this model uses pre-trained slot filling models for H2M conversations on similar domains as the expert model. The knowledge from three sources is encoded into vectors which are then combined and aggregated with the output of the bi-directional LSTM.</p>
</div>
<div id="S4.SS3.SSS12.p3" class="ltx_para">
<p id="S4.SS3.SSS12.p3.1" class="ltx_p">Slot tagging introduces the problem of generating a sequence of hidden labels to a sequence of word tokens, qualitatively different to the intent classification task. Together, in SLU, the two sub-tasks contribute to a better representation of the semantics of an utterance than each one separately. In the next section we consider the joint task where both are addressed in one model.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Joint intent and slot models</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The joint task marries the objectives of the two sub-tasks. As most papers point out there is a relationship between the slot labels we should expect to see conditional on the intent, and vice versa. A statistical view of this is that a model needs to learn the joint distributions of intent and slot labels. The model should also pay regard to the distributions of slot labels within utterances, and one would expect to inherit approaches to label dependency from the slot-labelling sub-task. Approaches to the joint task range from implicit learning of the distribution, through explicit learning of the conditional distribution of slot labels over the intent label, and vice versa, to fully explicit learning of the full joint distribution.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">The joint task should also expect to inherit most of the issues of each sub-task and we find this is true. The mass of research now appears in the joint task and as such newer methods tried there have not been tried previosly in the sub-tasks.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Major areas of research</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Research in the joint task has largely come from the personal assistant or chatbot fields. The chatbot is usually task-oriented within a single domain, while the personal assistant may be single or multi-domain.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Other areas to contribute papers are IoT instruction, robotic instruction (there is also a different concept of intent in robotics to describe what action the robot is attempting), and in vehicle dialogue for driverless vehicles. These areas also need to filter out utterances not applied to the device.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">Researchers have also drawn data from question answering systems, for example <cite class="ltx_cite ltx_citemacro_citep">(Zhang and Wang, <a href="#bib.bib140" title="" class="ltx_ref">2016</a>)</cite> who annotated a Chinese question dataset from Baidu Knows.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Overview of technological approaches</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">In this section we give an overview of papers which focused on the joint task itself, measuring their efficacy largely on performance against state-of-the-art. Generally they are using new technologies as they became available, or new architectures to make the learning more explicit.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1. </span>Classical methods</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">The earliest work on the joint task used a tri-level CRF with the three layers being token features, slot labels and intent labels. <cite class="ltx_cite ltx_citemacro_citep">(Jeong and Lee, <a href="#bib.bib44" title="" class="ltx_ref">2008</a>)</cite> showed this architecture performed better than performing the two sub-tasks in a pipeline. Other early statistical models used a maximum entropy model (MEM) for intent and a CRF for slot labelling (<cite class="ltx_cite ltx_citemacro_citep">(Wang, <a href="#bib.bib118" title="" class="ltx_ref">2010</a>)</cite>), and a multilayer HMM (<cite class="ltx_cite ltx_citemacro_citep">(Celikyilmaz and
Hakkani-Tur, <a href="#bib.bib10" title="" class="ltx_ref">2012</a>)</cite>.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2. </span>Recursive neural networks</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">The earliest attempt at a neural model to address the joint task was in <cite class="ltx_cite ltx_citemacro_citep">(Guo
et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2014</a>)</cite> which used recursive neural networks (RecNNs) (different to recurrent neural networks (RNN)). RecNNs work over trees, in this case the constituency parse tree of the utterance, with leaves corresponding to the words (represented by word vectors). A neural network is applied at each node of the tree, recursively upwards to the root, computing a state for each node. At each node the states from children nodes are combined with a weight vector representing the node’s syntactic type. Individual slot label classifiers are applied to each leaf using a combination of the word vectors of itself and its neighbours and the state vectors along the path from the leaf to the root. The state at the root is passed to an intent classifier. A combined loss over the slots and intent (and domain) is back-propagated. An optional post-processing, Viterbi decoded Markov layer is applied to the slots. Results were close to, but below, the then state-of the art for the tasks treated separately.</p>
</div>
</section>
<section id="S5.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.3. </span>Recurrent neural networks</h4>

<div id="S5.SS2.SSS3.p1" class="ltx_para">
<p id="S5.SS2.SSS3.p1.1" class="ltx_p">In 2016 the power of the RNN circuit for seq2seq tasks was explored in multiple papers. Features representing tokens are passed in temporal sequence to RNN units which have a hidden state. Intermediate hidden states may be used for slot labelling. The final hidden state is an embedding of the entire utterance and may be used for intent prediction. The classic encoder-decoder, which produces a sequential output, is the most commonly used architecture (<cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>)</cite>. Issues with the original RNN cells are addressed by LSTM and GRU cells. Bidirectional RNNs, where the input sequence is passed in in both forward and backward direction, address issues with unidirectional capturing of context.</p>
</div>
<div id="S5.SS2.SSS3.p2" class="ltx_para">
<p id="S5.SS2.SSS3.p2.1" class="ltx_p">Other architectures include (a joint loss is back-propagated unless mentioned):</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">a two layer LSTM with the top layer hidden states informing slot labelling and the first layer final state informing intent classification <cite class="ltx_cite ltx_citemacro_citep">(Zhou
et al<span class="ltx_text">.</span>, <a href="#bib.bib146" title="" class="ltx_ref">2016</a>)</cite>;</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">the slot tagging task is softmax classifiers applied to the output of a simple BiLSTM using the concatenated hidden states. A special token is added to encapsulate the whole utterance for use in intent classification <cite class="ltx_cite ltx_citemacro_citep">(Hakkani-Tür et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite>;</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">a Bi-LSTM encoder decoder but with separate losses for intent and slot prediction (<cite class="ltx_cite ltx_citemacro_citep">(Zheng
et al<span class="ltx_text">.</span>, <a href="#bib.bib145" title="" class="ltx_ref">2017</a>)</cite>;</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i4.p1" class="ltx_para">
<p id="S5.I1.i4.p1.1" class="ltx_p">rather than seq2seq <cite class="ltx_cite ltx_citemacro_citep">(Kim
et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2017</a>)</cite> perform a global slot prediction (learning the joint distribution) from a matrix of the hidden states to a matrix of slot tag probabilities for each word, intent is predicted from a sum of hidden states;</p>
</div>
</li>
<li id="S5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i5.p1" class="ltx_para">
<p id="S5.I1.i5.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Wen
et al<span class="ltx_text">.</span>, <a href="#bib.bib120" title="" class="ltx_ref">2018</a>)</cite> propose to use both a hierarchical (multi-layer) and a contextual (BiLSTM or LSTM) approach, investigating various combinations and using differing layers for intent and slot prediction;</p>
</div>
</li>
<li id="S5.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i6.p1" class="ltx_para">
<p id="S5.I1.i6.p1.1" class="ltx_p">an ensemble using both BiLSTM and BiGRU fed to separate MLPs whose outputs are fused then projected and a softmax applied to predict intent and slots concurrently is proposed by <cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2018a</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S5.SS2.SSS3.p3" class="ltx_para">
<p id="S5.SS2.SSS3.p3.1" class="ltx_p">For RNNs the input is typically token feature by token feature in temporal sequence. <cite class="ltx_cite ltx_citemacro_citep">(Hakkani-Tür et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite> compared that to using context windows with superior results. However <cite class="ltx_cite ltx_citemacro_citep">(Zheng
et al<span class="ltx_text">.</span>, <a href="#bib.bib145" title="" class="ltx_ref">2017</a>)</cite> showed inferior results with context windows.</p>
</div>
<div id="S5.SS2.SSS3.p4" class="ltx_para">
<p id="S5.SS2.SSS3.p4.1" class="ltx_p">One critical observation made of many purely recurrent models is that the sharing of the information between the two sub-tasks is implicit. That is, while the sub-tasks are addressed jointly, it is often only through back-propagation of a joint loss.</p>
</div>
</section>
<section id="S5.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.4. </span>Attention</h4>

<div id="S5.SS2.SSS4.p1" class="ltx_para">
<p id="S5.SS2.SSS4.p1.1" class="ltx_p">Attention is an obvious technique for forcing an interaction between information from the two sub-tasks, in a learned way. Some attention constructions may still be seen as an implicit way of sharing information, but stronger methods start to force explicit learning.</p>
</div>
<div id="S5.SS2.SSS4.p2" class="ltx_para">
<p id="S5.SS2.SSS4.p2.1" class="ltx_p">In early papers a basic concept of attention used was the weighted sum of Bi-RNN hidden states as an input to slot and intent prediction (<cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>)</cite>). Then <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite> used a stronger, more explicit attention. The base circuit is a BiLSTM taking word vectors in sequence and using a different learned weighted sum of the intermediate states of the BiLSTM for each slot prediction (the slot attention) and the final state for intent detection. The new addition is a slot gate which takes the current slot attention vector and combines it with the current intent vector in an attention operation. The output of the slot gate feeds the slot prediction. This circuit is an early example of intent2slot, a path through the circuit where intent prediction information is also fed explicitly to the slot prediction element. Another variation on intent2slot is provided in <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S5.SS2.SSS4.p3" class="ltx_para">
<p id="S5.SS2.SSS4.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2019</a>)</cite> also use an intent2slot architecture but with BERT encoding and and using stack propagation. Rather than a gate like <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite>, the intent detection itself directly feeds the slot filling. Also the intent detection is performed at token level and the final intent is taken by vote. <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib110" title="" class="ltx_ref">2020b</a>)</cite> too use an intent2slot gate with BERT embeddings.</p>
</div>
<div id="S5.SS2.SSS4.p4" class="ltx_para">
<p id="S5.SS2.SSS4.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Yu
et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2018</a>)</cite> in a sense provide the dual approach to that of <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite>, providing an attended slot prediction as the main input into intent prediction. The attention is additive on the weighted hidden states of a BiLSTM encoder and the weighted sum of the predicted slot labels. We call this explicit feed of slot information to the intent slot2intent.</p>
</div>
<div id="S5.SS2.SSS4.p5" class="ltx_para">
<p id="S5.SS2.SSS4.p5.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib139" title="" class="ltx_ref">2019</a>)</cite> extend the intent2slot gate of <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite> with a pair of slot gates, one carrying the global intent information to the slot task, and one taking it to each slot location individually. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib142" title="" class="ltx_ref">2019b</a>)</cite> also apply intent2slot but only to tokens determined to be not labelled ‘O’.</p>
</div>
<div id="S5.SS2.SSS4.p6" class="ltx_para">
<p id="S5.SS2.SSS4.p6.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2018b</a>)</cite> introduce self-attention to the BiLSTM architecture to force a stronger learning “at the semantic level” between the slots and the intent. A first self-attention layer performs attention on word and convolutional character embeddings. This is concatenated with the word embeddings and fed to a BiLSTM layer. The final state informs intent detection. Self attention is performed between the intermediate states of the BiLSTM. This self attention is combined with the intent prediction which is then combined with the intermediate states to perform slot tagging. <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019a</a>)</cite> starts with word and character embeddings from a BiLSTM layer, then performs multi-head self-attention on these, followed by a BiLSTM encoder whose final state informs intent prediction. Another multi-head self-attention on the second BiLSTM hidden states, combined with the masked intent prediction, feed a CRF for slot prediction.</p>
</div>
<div id="S5.SS2.SSS4.p7" class="ltx_para">
<p id="S5.SS2.SSS4.p7.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_citep">(Chen and Yu, <a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite> a BiLSTM layer takes the word inputs. State attention is performed as follows. For slots each hidden state is combined with the softmax of a weighted sum of all the hidden states passed through a feed forward network. Intent detection takes the last hidden state in combination with a similar weighted sum of the intermediate states. A similar formulation is used for word attention by weighting sums of word vectors rather than hidden states. All these features are combined in a fusion layer to inform the two tasks.</p>
</div>
<div id="S5.SS2.SSS4.p8" class="ltx_para">
<p id="S5.SS2.SSS4.p8.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Xu
et al<span class="ltx_text">.</span>, <a href="#bib.bib123" title="" class="ltx_ref">2020</a>)</cite> use a standard encoder-decoder LSTM which incorporates a length variable attention, that is attention of a sub-sequence of learned width over the hidden states.</p>
</div>
<section id="S5.SS2.SSS4.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Transformer</h5>

<div id="S5.SS2.SSS4.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS4.Px1.p1.1" class="ltx_p">The transformer architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2017</a>)</cite>, a non-recurrent model useful for capturing global dependencies via multi-head self-attention (among other strengths) appears in <cite class="ltx_cite ltx_citemacro_citep">(Thi Do and
Gaspers, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite> to construct contextual embeddings of the word tokens. In their model attention is applied between all these to inform the intent prediction sub-task where it gives a superior result.</p>
</div>
<div id="S5.SS2.SSS4.Px1.p2" class="ltx_para">
<p id="S5.SS2.SSS4.Px1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Zhang and Wang, <a href="#bib.bib138" title="" class="ltx_ref">2019</a>)</cite> also use the transformer architecture. They pass word embeddings to a 3 level transformer layer, then extract a global output to inform intent detection and token level output to pass to a CRF for slot detection. Differently to <cite class="ltx_cite ltx_citemacro_citep">(Thi Do and
Gaspers, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite>, a special token is added to represent the whole utterance. Both these models only use the bidirectional encoder of <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S5.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.5. </span>Hierarchical models</h4>

<div id="S5.SS2.SSS5.p1" class="ltx_para">
<p id="S5.SS2.SSS5.p1.1" class="ltx_p">A hierarchical model passes information learned to be relevant through ordered levels. While this flow is explicit it is often unidirectional. For example, <cite class="ltx_cite ltx_citemacro_citep">(Lee
et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2018</a>)</cite> supply a hierarchical approach with slot, intent and domain levels. Each element of the intent level is represented as the vector sum of the components in the slot layer coming from the same utterance.</p>
</div>
<div id="S5.SS2.SSS5.p2" class="ltx_para">
<p id="S5.SS2.SSS5.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib135" title="" class="ltx_ref">2019a</a>)</cite> provided relevant feedback from the highest level back to the lowest in their capsule network solution, a novel approach that sought to explicitly capture the words-slots-intent hierarchy. A capsule represents of a group of neurons whose output can be used for predictions at the next level; word capsules can be used to make slot label predictions, and so on. The hierarchy is learned using a routing-by-agreement mechanism: the prediction is only endorsed when there is strong agreement from the incoming capsule. The authors also propose a mechanism whereby a strong intent message at the highest level can be fed back to the earlier levels to help them in their task. This explicit and direct feedback is stronger than the implicit or indirect joint learning typically found in RNN models. <cite class="ltx_cite ltx_citemacro_citep">(Staliūnaitė and Iacobacci, <a href="#bib.bib98" title="" class="ltx_ref">2020</a>)</cite> extended this work to a multi-task setting with extra mid-level capsules for NER and POS labels, with mixed results.</p>
</div>
<figure id="S5.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7. </span>Joint task papers reviewed with addressed issue, approach and techniques</figcaption>
<table id="S5.T7.1" class="ltx_tabular">
<tr id="S5.T7.1.1" class="ltx_tr">
<td id="S5.T7.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.1.1.1" class="ltx_p" style="width:93.9pt;"><span id="S5.T7.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Paper</span></span>
</span>
</td>
<td id="S5.T7.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.2.1.1" class="ltx_p" style="width:162.2pt;"><span id="S5.T7.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Addressed issue</span></span>
</span>
</td>
<td id="S5.T7.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.3.1.1" class="ltx_p" style="width:199.2pt;"><span id="S5.T7.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Approach</span></span>
</span>
</td>
</tr>
<tr id="S5.T7.1.2" class="ltx_tr">
<td id="S5.T7.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.2.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Jeong and Lee, <a href="#bib.bib44" title="" class="ltx_ref">2008</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.2.2.1.1" class="ltx_p" style="width:162.2pt;">Joint solution of related tasks</span>
</span>
</td>
<td id="S5.T7.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.2.3.1.1" class="ltx_p" style="width:199.2pt;">Tri-layer CRF, extra layer for classification</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.3" class="ltx_tr">
<td id="S5.T7.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.3.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang, <a href="#bib.bib118" title="" class="ltx_ref">2010</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.3.2.1.1" class="ltx_p" style="width:162.2pt;">Small training sets</span>
</span>
</td>
<td id="S5.T7.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.3.3.1.1" class="ltx_p" style="width:199.2pt;">MEM and CRF, joint task versus pipeline</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.4" class="ltx_tr">
<td id="S5.T7.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.4.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Celikyilmaz and
Hakkani-Tur, <a href="#bib.bib10" title="" class="ltx_ref">2012</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.4.2.1.1" class="ltx_p" style="width:162.2pt;">Small training sets</span>
</span>
</td>
<td id="S5.T7.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.4.3.1.1" class="ltx_p" style="width:199.2pt;">Tri-level HMM, bolstered features</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.5" class="ltx_tr">
<td id="S5.T7.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.5.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Xu and
Sarikaya, <a href="#bib.bib124" title="" class="ltx_ref">2013</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.5.2.1.1" class="ltx_p" style="width:162.2pt;">Automated feature creation</span>
</span>
</td>
<td id="S5.T7.1.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.5.3.1.1" class="ltx_p" style="width:199.2pt;">CNN features into TriCRF</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.6" class="ltx_tr">
<td id="S5.T7.1.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.6.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Guo
et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.6.2.1.1" class="ltx_p" style="width:162.2pt;">Incorporate discrete constituency parse of utterance</span>
</span>
</td>
<td id="S5.T7.1.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.6.3.1.1" class="ltx_p" style="width:199.2pt;">RecNN on word vecs and parse tree</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.7" class="ltx_tr">
<td id="S5.T7.1.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.7.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.7.2.1.1" class="ltx_p" style="width:162.2pt;">Context from multi-turn dialogue</span>
</span>
</td>
<td id="S5.T7.1.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.7.3.1.1" class="ltx_p" style="width:199.2pt;">RNN (token) and CNN (sentence) features, MLP</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.8" class="ltx_tr">
<td id="S5.T7.1.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.8.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhou
et al<span class="ltx_text">.</span>, <a href="#bib.bib146" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.8.2.1.1" class="ltx_p" style="width:162.2pt;">Hierarchical task relationship</span>
</span>
</td>
<td id="S5.T7.1.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.8.3.1.1" class="ltx_p" style="width:199.2pt;">RNN, LSTM</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.9" class="ltx_tr">
<td id="S5.T7.1.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.9.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Hakkani-Tür et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.9.2.1.1" class="ltx_p" style="width:162.2pt;">Seq2seq, joint model, architectures</span>
</span>
</td>
<td id="S5.T7.1.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.9.3.1.1" class="ltx_p" style="width:199.2pt;">BiLSTM</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.10" class="ltx_tr">
<td id="S5.T7.1.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.10.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.10.2.1.1" class="ltx_p" style="width:162.2pt;">Incorporate language knowledge</span>
</span>
</td>
<td id="S5.T7.1.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.10.3.1.1" class="ltx_p" style="width:199.2pt;">K-SAN attention network, GRU</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.11" class="ltx_tr">
<td id="S5.T7.1.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.11.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang and Wang, <a href="#bib.bib140" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.11.2.1.1" class="ltx_p" style="width:162.2pt;">Apply RNN to intent</span>
</span>
</td>
<td id="S5.T7.1.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.11.3.1.1" class="ltx_p" style="width:199.2pt;">GRU</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.12" class="ltx_tr">
<td id="S5.T7.1.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.12.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.12.2.1.1" class="ltx_p" style="width:162.2pt;">Employ encoder-decoder with attention</span>
</span>
</td>
<td id="S5.T7.1.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.12.3.1.1" class="ltx_p" style="width:199.2pt;">Encoder-decoder with attention</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.13" class="ltx_tr">
<td id="S5.T7.1.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.13.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib60" title="" class="ltx_ref">2016b</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.13.2.1.1" class="ltx_p" style="width:162.2pt;">Real time analysis</span>
</span>
</td>
<td id="S5.T7.1.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.13.3.1.1" class="ltx_p" style="width:199.2pt;">LSTM, MLP</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.14" class="ltx_tr">
<td id="S5.T7.1.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.14.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zheng
et al<span class="ltx_text">.</span>, <a href="#bib.bib145" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.14.2.1.1" class="ltx_p" style="width:162.2pt;">NLP in navigation dialogue</span>
</span>
</td>
<td id="S5.T7.1.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.14.3.1.1" class="ltx_p" style="width:199.2pt;">BiLSTM encoder decoder, seq2seq</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.15" class="ltx_tr">
<td id="S5.T7.1.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.15.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Ma
et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.15.2.1.1" class="ltx_p" style="width:162.2pt;">No long term memory, linearity</span>
</span>
</td>
<td id="S5.T7.1.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.15.3.1.1" class="ltx_p" style="width:199.2pt;">LSTM, sparse attention</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.16" class="ltx_tr">
<td id="S5.T7.1.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.16.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Kim
et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.16.2.1.1" class="ltx_p" style="width:162.2pt;">Error propagation, information sharing between tasks</span>
</span>
</td>
<td id="S5.T7.1.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.16.3.1.1" class="ltx_p" style="width:199.2pt;">Word and character RNN embedding</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.17" class="ltx_tr">
<td id="S5.T7.1.17.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.17.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.17.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.17.2.1.1" class="ltx_p" style="width:162.2pt;">Noisy NLU outputs</span>
</span>
</td>
<td id="S5.T7.1.17.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.17.3.1.1" class="ltx_p" style="width:199.2pt;">Dialogue act unit after NLU</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.18" class="ltx_tr">
<td id="S5.T7.1.18.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.18.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.18.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.18.2.1.1" class="ltx_p" style="width:162.2pt;">Learn relationship between slot and intent attention vectors</span>
</span>
</td>
<td id="S5.T7.1.18.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.18.3.1.1" class="ltx_p" style="width:199.2pt;">Slot gate, BiLSTM</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.19" class="ltx_tr">
<td id="S5.T7.1.19.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.19.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Pan
et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.19.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.19.2.1.1" class="ltx_p" style="width:162.2pt;">Multiple utterance dialogue</span>
</span>
</td>
<td id="S5.T7.1.19.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.19.3.1.1" class="ltx_p" style="width:199.2pt;">Utterance to utterance attention</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.20" class="ltx_tr">
<td id="S5.T7.1.20.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.20.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wen
et al<span class="ltx_text">.</span>, <a href="#bib.bib120" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.20.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.20.2.1.1" class="ltx_p" style="width:162.2pt;">Using hierarchy and context</span>
</span>
</td>
<td id="S5.T7.1.20.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.20.3.1.1" class="ltx_p" style="width:199.2pt;">Two layer (Bi)LSTM</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.21" class="ltx_tr">
<td id="S5.T7.1.21.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.21.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2018c</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.21.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.21.2.1.1" class="ltx_p" style="width:162.2pt;">Capturing local semantic information</span>
</span>
</td>
<td id="S5.T7.1.21.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.21.3.1.1" class="ltx_p" style="width:199.2pt;">CNN, BiLSTM encoder decoder</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.22" class="ltx_tr">
<td id="S5.T7.1.22.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.22.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2018a</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.22.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.22.2.1.1" class="ltx_p" style="width:162.2pt;">Domain dependence</span>
</span>
</td>
<td id="S5.T7.1.22.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.22.3.1.1" class="ltx_p" style="width:199.2pt;">Ensemble model, GRU</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.23" class="ltx_tr">
<td id="S5.T7.1.23.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.23.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.23.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.23.2.1.1" class="ltx_p" style="width:162.2pt;">Slow training time</span>
</span>
</td>
<td id="S5.T7.1.23.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.23.3.1.1" class="ltx_p" style="width:199.2pt;">Progressive multi-task model using user information</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.24" class="ltx_tr">
<td id="S5.T7.1.24.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.24.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2018a</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.24.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.24.2.1.1" class="ltx_p" style="width:162.2pt;">Correlation of different tasks</span>
</span>
</td>
<td id="S5.T7.1.24.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.24.3.1.1" class="ltx_p" style="width:199.2pt;">Multi-task model incl. POS tag</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.25" class="ltx_tr">
<td id="S5.T7.1.25.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.25.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2018b</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.25.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.25.2.1.1" class="ltx_p" style="width:162.2pt;">Sharing semantic information</span>
</span>
</td>
<td id="S5.T7.1.25.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.25.3.1.1" class="ltx_p" style="width:199.2pt;">Self-attention</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.26" class="ltx_tr">
<td id="S5.T7.1.26.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.26.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib136" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.26.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.26.2.1.1" class="ltx_p" style="width:162.2pt;">Tagging strategy</span>
</span>
</td>
<td id="S5.T7.1.26.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.26.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.26.3.1.1" class="ltx_p" style="width:199.2pt;">Token tags include intent and slot</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.27" class="ltx_tr">
<td id="S5.T7.1.27.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.27.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib135" title="" class="ltx_ref">2019a</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.27.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.27.2.1.1" class="ltx_p" style="width:162.2pt;">Hierarchical structure</span>
</span>
</td>
<td id="S5.T7.1.27.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.27.3.1.1" class="ltx_p" style="width:199.2pt;">Capsule network with rerouting (feedback)</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.28" class="ltx_tr">
<td id="S5.T7.1.28.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.28.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib144" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.28.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.28.2.1.1" class="ltx_p" style="width:162.2pt;">Spatial (context) and serial (order) information</span>
</span>
</td>
<td id="S5.T7.1.28.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.28.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.28.3.1.1" class="ltx_p" style="width:199.2pt;">Encoder-decoder, CNN</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.29" class="ltx_tr">
<td id="S5.T7.1.29.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.29.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib116" title="" class="ltx_ref">2018b</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.29.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.29.2.1.1" class="ltx_p" style="width:162.2pt;">slot2intent and intent2slot</span>
</span>
</td>
<td id="S5.T7.1.29.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.29.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.29.3.1.1" class="ltx_p" style="width:199.2pt;">Bi-directional architecture</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.30" class="ltx_tr">
<td id="S5.T7.1.30.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.30.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Siddhant
et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.30.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.30.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.30.2.1.1" class="ltx_p" style="width:162.2pt;">Unsupervised learning</span>
</span>
</td>
<td id="S5.T7.1.30.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.30.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.30.3.1.1" class="ltx_p" style="width:199.2pt;">ELMo on unused utterances, BiLSTM</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.31" class="ltx_tr">
<td id="S5.T7.1.31.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.31.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.31.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Yu
et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.31.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.31.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.31.2.1.1" class="ltx_p" style="width:162.2pt;">Use sequence labelling output for intent</span>
</span>
</td>
<td id="S5.T7.1.31.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.31.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.31.3.1.1" class="ltx_p" style="width:199.2pt;">Cross attention, BiLSTM, CRF</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.32" class="ltx_tr">
<td id="S5.T7.1.32.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.32.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.32.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Lee
et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.32.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.32.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.32.2.1.1" class="ltx_p" style="width:162.2pt;">Hierarchical vector approach</span>
</span>
</td>
<td id="S5.T7.1.32.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.32.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.32.3.1.1" class="ltx_p" style="width:199.2pt;">Learn vectors representing elements of frame</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.33" class="ltx_tr">
<td id="S5.T7.1.33.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.33.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.33.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Jung
et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.33.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.33.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.33.2.1.1" class="ltx_p" style="width:162.2pt;">Model relationship between text and its semantic frame</span>
</span>
</td>
<td id="S5.T7.1.33.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.33.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.33.3.1.1" class="ltx_p" style="width:199.2pt;">Vector representation of frame</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.34" class="ltx_tr">
<td id="S5.T7.1.34.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.34.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.34.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Ray et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.34.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.34.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.34.2.1.1" class="ltx_p" style="width:162.2pt;">Rare, OOV words</span>
</span>
</td>
<td id="S5.T7.1.34.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.34.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.34.3.1.1" class="ltx_p" style="width:199.2pt;">Paraphrasing input utterances</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.35" class="ltx_tr">
<td id="S5.T7.1.35.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.35.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.35.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019b</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.35.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.35.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.35.2.1.1" class="ltx_p" style="width:162.2pt;">Unidirectional information flow</span>
</span>
</td>
<td id="S5.T7.1.35.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.35.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.35.3.1.1" class="ltx_p" style="width:199.2pt;">Memory network</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.36" class="ltx_tr">
<td id="S5.T7.1.36.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.36.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.36.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib91" title="" class="ltx_ref">2019a</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.36.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.36.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.36.2.1.1" class="ltx_p" style="width:162.2pt;">Poor generalisation in deployment</span>
</span>
</td>
<td id="S5.T7.1.36.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.36.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.36.3.1.1" class="ltx_p" style="width:199.2pt;">Sparse word embedding (prune useless words)</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.37" class="ltx_tr">
<td id="S5.T7.1.37.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.37.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.37.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Ray et al<span class="ltx_text">.</span>, <a href="#bib.bib85" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.37.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.37.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.37.2.1.1" class="ltx_p" style="width:162.2pt;">Slots which take many values perform poorly</span>
</span>
</td>
<td id="S5.T7.1.37.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.37.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.37.3.1.1" class="ltx_p" style="width:199.2pt;">Delexicalisation</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.38" class="ltx_tr">
<td id="S5.T7.1.38.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.38.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.38.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2019a</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.38.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.38.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.38.2.1.1" class="ltx_p" style="width:162.2pt;">Language knowledge base, history context</span>
</span>
</td>
<td id="S5.T7.1.38.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.38.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.38.3.1.1" class="ltx_p" style="width:199.2pt;">Attention over external knowledge base, multiturn history</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.39" class="ltx_tr">
<td id="S5.T7.1.39.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.39.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.39.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.39.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.39.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.39.2.1.1" class="ltx_p" style="width:162.2pt;">Implicit knowledge sharing between tasks</span>
</span>
</td>
<td id="S5.T7.1.39.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.39.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.39.3.1.1" class="ltx_p" style="width:199.2pt;">BiLSTM, multi-task (DA)</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.40" class="ltx_tr">
<td id="S5.T7.1.40.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.40.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.40.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2019a</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.40.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.40.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.40.2.1.1" class="ltx_p" style="width:162.2pt;">Speed</span>
</span>
</td>
<td id="S5.T7.1.40.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.40.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.40.3.1.1" class="ltx_p" style="width:199.2pt;">Non-recurrent and label recurrent networks</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.41" class="ltx_tr">
<td id="S5.T7.1.41.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.41.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.41.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2019b</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.41.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.41.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.41.2.1.1" class="ltx_p" style="width:162.2pt;">Multi-turn dialogue, using context</span>
</span>
</td>
<td id="S5.T7.1.41.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.41.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.41.3.1.1" class="ltx_p" style="width:199.2pt;">Token attention, previous history</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.42" class="ltx_tr">
<td id="S5.T7.1.42.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.42.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.42.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019a</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.42.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.42.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.42.2.1.1" class="ltx_p" style="width:162.2pt;">Capturing intent-slot correlation</span>
</span>
</td>
<td id="S5.T7.1.42.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.42.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.42.3.1.1" class="ltx_p" style="width:199.2pt;">Multi-head self attention, masked intent</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.43" class="ltx_tr">
<td id="S5.T7.1.43.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.43.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.43.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019b</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.43.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.43.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.43.2.1.1" class="ltx_p" style="width:162.2pt;">Poor generalisation</span>
</span>
</td>
<td id="S5.T7.1.43.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.43.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.43.3.1.1" class="ltx_p" style="width:199.2pt;">BERT</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.44" class="ltx_tr">
<td id="S5.T7.1.44.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.44.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.44.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Bhasin et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.44.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.44.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.44.2.1.1" class="ltx_p" style="width:162.2pt;">Learning joint distribution</span>
</span>
</td>
<td id="S5.T7.1.44.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.44.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.44.3.1.1" class="ltx_p" style="width:199.2pt;">CNN, BiLSTM, cross-fusion, masking</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.45" class="ltx_tr">
<td id="S5.T7.1.45.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.45.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.45.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Thi Do and
Gaspers, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.45.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.45.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.45.2.1.1" class="ltx_p" style="width:162.2pt;">Lack of annotated data, flexibility</span>
</span>
</td>
<td id="S5.T7.1.45.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.45.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.45.3.1.1" class="ltx_p" style="width:199.2pt;">Language transfer, multitasking, modularisation</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.46" class="ltx_tr">
<td id="S5.T7.1.46.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.46.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.46.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib139" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.46.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.46.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.46.2.1.1" class="ltx_p" style="width:162.2pt;">Key verb-slot correlation</span>
</span>
</td>
<td id="S5.T7.1.46.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.46.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.46.3.1.1" class="ltx_p" style="width:199.2pt;">Key verb in features, BiLSTM, attention</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.47" class="ltx_tr">
<td id="S5.T7.1.47.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.47.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.47.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang and Wang, <a href="#bib.bib138" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.47.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.47.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.47.2.1.1" class="ltx_p" style="width:162.2pt;">Learning joint distribution</span>
</span>
</td>
<td id="S5.T7.1.47.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.47.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.47.3.1.1" class="ltx_p" style="width:199.2pt;">Transformer architecture</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.48" class="ltx_tr">
<td id="S5.T7.1.48.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.48.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.48.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Daha and
Hewavitharana, <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.48.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.48.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.48.2.1.1" class="ltx_p" style="width:162.2pt;">Efficient modelling of temporal dependency</span>
</span>
</td>
<td id="S5.T7.1.48.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.48.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.48.3.1.1" class="ltx_p" style="width:199.2pt;">Character embedding and RNN</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.49" class="ltx_tr">
<td id="S5.T7.1.49.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.49.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.49.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Dadas
et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.49.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.49.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.49.2.1.1" class="ltx_p" style="width:162.2pt;">Lack of annotated data, small data sets</span>
</span>
</td>
<td id="S5.T7.1.49.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.49.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.49.3.1.1" class="ltx_p" style="width:199.2pt;">Augmented data set</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.50" class="ltx_tr">
<td id="S5.T7.1.50.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.50.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.50.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Chen and Yu, <a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.50.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.50.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.50.2.1.1" class="ltx_p" style="width:162.2pt;">Learning joint distribution</span>
</span>
</td>
<td id="S5.T7.1.50.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.50.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.50.3.1.1" class="ltx_p" style="width:199.2pt;">Word embedding attention</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.51" class="ltx_tr">
<td id="S5.T7.1.51.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.51.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.51.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(E
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.51.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.51.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.51.2.1.1" class="ltx_p" style="width:162.2pt;">Learning joint distribution</span>
</span>
</td>
<td id="S5.T7.1.51.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.51.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.51.3.1.1" class="ltx_p" style="width:199.2pt;">Bidirectional architecture, feedback</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.52" class="ltx_tr">
<td id="S5.T7.1.52.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.52.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.52.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib142" title="" class="ltx_ref">2019b</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.52.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.52.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.52.2.1.1" class="ltx_p" style="width:162.2pt;">Poor generalisation</span>
</span>
</td>
<td id="S5.T7.1.52.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.52.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.52.3.1.1" class="ltx_p" style="width:199.2pt;">BERT encoding, multi-head self attention</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.53" class="ltx_tr">
<td id="S5.T7.1.53.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.53.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.53.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.53.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.53.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.53.2.1.1" class="ltx_p" style="width:162.2pt;">Weak influence of intent on slot</span>
</span>
</td>
<td id="S5.T7.1.53.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.53.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.53.3.1.1" class="ltx_p" style="width:199.2pt;">Use intent prediction instead of summarised intent info in slot tagging</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.54" class="ltx_tr">
<td id="S5.T7.1.54.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.54.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.54.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Gangadharaiah
and Narayanaswamy, <a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.54.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.54.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.54.2.1.1" class="ltx_p" style="width:162.2pt;">Multi-intent samples</span>
</span>
</td>
<td id="S5.T7.1.54.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.54.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.54.3.1.1" class="ltx_p" style="width:199.2pt;">Multi-label classification methods</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.55" class="ltx_tr">
<td id="S5.T7.1.55.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.55.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.55.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.55.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.55.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.55.2.1.1" class="ltx_p" style="width:162.2pt;">Multi-turn dialogue history, learning joint distribution</span>
</span>
</td>
<td id="S5.T7.1.55.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.55.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.55.3.1.1" class="ltx_p" style="width:199.2pt;">RNN, CRF</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.56" class="ltx_tr">
<td id="S5.T7.1.56.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.56.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.56.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Pentyala
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.56.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.56.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.56.2.1.1" class="ltx_p" style="width:162.2pt;">Optimal architecture</span>
</span>
</td>
<td id="S5.T7.1.56.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.56.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.56.3.1.1" class="ltx_p" style="width:199.2pt;">BiLSTM, different architectures</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.57" class="ltx_tr">
<td id="S5.T7.1.57.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.57.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.57.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Castellucci et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.57.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.57.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.57.2.1.1" class="ltx_p" style="width:162.2pt;">Non-recurrent model, transfer learning</span>
</span>
</td>
<td id="S5.T7.1.57.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.57.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.57.3.1.1" class="ltx_p" style="width:199.2pt;">BERT, language transfer</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.58" class="ltx_tr">
<td id="S5.T7.1.58.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.58.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.58.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Schuster
et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.58.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.58.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.58.2.1.1" class="ltx_p" style="width:162.2pt;">Low resource languages</span>
</span>
</td>
<td id="S5.T7.1.58.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.58.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.58.3.1.1" class="ltx_p" style="width:199.2pt;">Transfer methods with SLU test case</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.59" class="ltx_tr">
<td id="S5.T7.1.59.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.59.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.59.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Okur
et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.59.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.59.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.59.2.1.1" class="ltx_p" style="width:162.2pt;">Natural language</span>
</span>
</td>
<td id="S5.T7.1.59.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.59.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.59.3.1.1" class="ltx_p" style="width:199.2pt;">Locate intent keywords, non-other slots</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.60" class="ltx_tr">
<td id="S5.T7.1.60.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.60.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.60.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Xu
et al<span class="ltx_text">.</span>, <a href="#bib.bib123" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.60.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.60.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.60.2.1.1" class="ltx_p" style="width:162.2pt;">Only good performance in one sub-task</span>
</span>
</td>
<td id="S5.T7.1.60.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.60.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.60.3.1.1" class="ltx_p" style="width:199.2pt;">Joint intent/slot tagging, length variable attention</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.61" class="ltx_tr">
<td id="S5.T7.1.61.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.61.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.61.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Bhasin et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.61.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.61.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.61.2.1.1" class="ltx_p" style="width:162.2pt;">Learning joint distribution</span>
</span>
</td>
<td id="S5.T7.1.61.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.61.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.61.3.1.1" class="ltx_p" style="width:199.2pt;">Multimodal Low-rank Bilinear Attention Network</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.62" class="ltx_tr">
<td id="S5.T7.1.62.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.62.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.62.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.62.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.62.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.62.2.1.1" class="ltx_p" style="width:162.2pt;">Learning joint distribution</span>
</span>
</td>
<td id="S5.T7.1.62.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.62.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.62.3.1.1" class="ltx_p" style="width:199.2pt;">Stacked BiLSTM</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.63" class="ltx_tr">
<td id="S5.T7.1.63.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.63.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.63.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2020b</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.63.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.63.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.63.2.1.1" class="ltx_p" style="width:162.2pt;">Limitations of sequential analysis</span>
</span>
</td>
<td id="S5.T7.1.63.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.63.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.63.3.1.1" class="ltx_p" style="width:199.2pt;">Graph representation of text</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.64" class="ltx_tr">
<td id="S5.T7.1.64.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.64.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.64.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2020a</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.64.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.64.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.64.2.1.1" class="ltx_p" style="width:162.2pt;">Non-convex optimisation</span>
</span>
</td>
<td id="S5.T7.1.64.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.64.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.64.3.1.1" class="ltx_p" style="width:199.2pt;">Convex combination of ensemble of models</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.65" class="ltx_tr">
<td id="S5.T7.1.65.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.65.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.65.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib110" title="" class="ltx_ref">2020b</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.65.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.65.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.65.2.1.1" class="ltx_p" style="width:162.2pt;">BERT issues with logical dependency (I before B)</span>
</span>
</td>
<td id="S5.T7.1.65.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.65.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.65.3.1.1" class="ltx_p" style="width:199.2pt;">CRF and self attention over BERT</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.66" class="ltx_tr">
<td id="S5.T7.1.66.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.66.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.66.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Ni
et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.66.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.66.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.66.2.1.1" class="ltx_p" style="width:162.2pt;">Model transfer, IoT</span>
</span>
</td>
<td id="S5.T7.1.66.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.66.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.66.3.1.1" class="ltx_p" style="width:199.2pt;">Pipeline structure from medical analogue</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.67" class="ltx_tr">
<td id="S5.T7.1.67.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.67.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.67.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Krone
et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.67.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.67.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.67.2.1.1" class="ltx_p" style="width:162.2pt;">Unseen labels</span>
</span>
</td>
<td id="S5.T7.1.67.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.67.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.67.3.1.1" class="ltx_p" style="width:199.2pt;">Few-shot meta-learning</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.68" class="ltx_tr">
<td id="S5.T7.1.68.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.68.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.68.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Bhathiya and
Thayasivam, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.68.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.68.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.68.2.1.1" class="ltx_p" style="width:162.2pt;">Unseen labels, language transfer</span>
</span>
</td>
<td id="S5.T7.1.68.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.68.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.68.3.1.1" class="ltx_p" style="width:199.2pt;">Few-shot meta-learning</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.69" class="ltx_tr">
<td id="S5.T7.1.69.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.69.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.69.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Tang
et al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.69.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.69.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.69.2.1.1" class="ltx_p" style="width:162.2pt;">Linear chain CRF limitations</span>
</span>
</td>
<td id="S5.T7.1.69.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.69.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.69.3.1.1" class="ltx_p" style="width:199.2pt;">GCN based CRF</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.70" class="ltx_tr">
<td id="S5.T7.1.70.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T7.1.70.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.70.1.1.1" class="ltx_p" style="width:93.9pt;"><cite class="ltx_cite ltx_citemacro_citep">(Staliūnaitė and Iacobacci, <a href="#bib.bib98" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S5.T7.1.70.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T7.1.70.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.70.2.1.1" class="ltx_p" style="width:162.2pt;">Extend capsule network</span>
</span>
</td>
<td id="S5.T7.1.70.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T7.1.70.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.70.3.1.1" class="ltx_p" style="width:199.2pt;">Capsule network with MTL</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S5.SS2.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.6. </span>Bi-directional models</h4>

<div id="S5.SS2.SSS6.p1" class="ltx_para">
<p id="S5.SS2.SSS6.p1.1" class="ltx_p">A model where there is a pipeline from one sub-task to the other may be seen as unidirectional. A bi-directional model, different to the bi-directionality seen in RNNs, has an explicit path from slot processing into intent prediction and also from intent processing into slot prediction. This can form two parallel paths through the circuit, often with a fusion layer or a joint loss.</p>
</div>
<div id="S5.SS2.SSS6.p2" class="ltx_para">
<p id="S5.SS2.SSS6.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib116" title="" class="ltx_ref">2018b</a>)</cite> proposes the first such bi-directional circuit. In this paper each path is a a BiLSTM and the hidden states from each path are shared with the other, another form of explicit influence between the tasks. An optional LSTM decoder is supplied on each side. Interestingly the loss is not a joint loss but the circuit alternates between predicting intent for a batch, and back-propagating intent loss, then predicting slots for the same batch and back-propagating slot loss. They call this asynchronous training.</p>
</div>
<div id="S5.SS2.SSS6.p3" class="ltx_para">
<p id="S5.SS2.SSS6.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Bhasin et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite> also uses bi-directional paths. Starting with GloVe word embeddings, an intent path converts them to convolutional features which are concatenated then projected. The slot path passes the word vectors through a BiLSTM with a CRF on top with the results also projected. Three types of fusion of the paths (after reshaping/broadcasting) were tested: addition, average or concatenation.</p>
</div>
<div id="S5.SS2.SSS6.p4" class="ltx_para">
<p id="S5.SS2.SSS6.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(E
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite> also consider bi-directionality. They start with a BiLSTM encoder. A weighted sum of intermediate states for each step (the slot contexts) feeds a slot sub-net, while the weighted final hidden state (the intent context) feeds an intent sub-net. These two interact in either a slot2intent fashion (slot affects intent) or intent2slot. The outputs then feed a softmax intent classifier and a CRF respectively. In slot2intent mode a learned combination of the slot contexts and intent context then feed the intent sub-net, where they are combined with the intent context for prediction. In intent2slot mode the intent context is combined with the slot contexts to form a slot informed intent context. This is then fed to the slot sub-net where it is combined with the slot contexts to feed the CRF for prediction. As may be expected intent2slot gave better slot results and slot2intent gave better intent results. That only one can be applied is a weakness of the architecture.</p>
</div>
</section>
<section id="S5.SS2.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.7. </span>Memory networks</h4>

<div id="S5.SS2.SSS7.p1" class="ltx_para">
<p id="S5.SS2.SSS7.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019b</a>)</cite> consider that even with the inclusion of feedback that the circuit of <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib135" title="" class="ltx_ref">2019a</a>)</cite> is still overly unidirectional. To overcome this they consider the use of memory networks to the joint task. As they see the typical interaction as a pipeline from words to slots to intent, they alternate interaction from slots to intent and vice versa via multiple blocks of memory nets. The network begins with GloVe word embeddings and max pooled convolutional character embeddings. These feed the first memory block, which constructs slot features, intent features and hidden states. Further memory blocks in the stack take the previous block’s hidden states as inputs. The memory blocks perform three operations, which also strive to capture local context and global sequential patterns:</p>
</div>
<div id="S5.SS2.SSS7.p2" class="ltx_para">
<ul id="S5.I2" class="ltx_itemize">
<li id="S5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i1.p1" class="ltx_para">
<p id="S5.I2.i1.p1.1" class="ltx_p">Deliberate Attention: a slot memory (with number of cells equal to number of slot labels) and intent memory (ditto for number of intent labels) are randomly initialised then updated. At each word position each memory is updated as a weighted sum of the other memory and of the block hidden states for the current word. Diffusion of influence between slots and intents thus takes place and can inform the hidden states for the next word.</p>
</div>
</li>
<li id="S5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i2.p1" class="ltx_para">
<p id="S5.I2.i2.p1.1" class="ltx_p">Local Calculation: this is a recurrent process receiving the input embeddings or previous block’s hidden states. It calculates slot representation and intent representations as interactions between its inputs and the slot and intent memories. It is an LSTM network.</p>
</div>
</li>
<li id="S5.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i3.p1" class="ltx_para">
<p id="S5.I2.i3.p1.1" class="ltx_p">Global Recurrence: a BiLSTM layer on top which encodes global sequential interactions.</p>
</div>
</li>
</ul>
</div>
<div id="S5.SS2.SSS7.p3" class="ltx_para">
<p id="S5.SS2.SSS7.p3.1" class="ltx_p">After the stacked blocks a final prediction takes place. Slots are labelled via a CRF on the final hidden states and slot representations. Intent is via an average of the final hidden states and intent representations.</p>
</div>
</section>
<section id="S5.SS2.SSS8" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.8. </span>Meta-studies of flow architectures</h4>

<div id="S5.SS2.SSS8.p1" class="ltx_para">
<p id="S5.SS2.SSS8.p1.1" class="ltx_p">In an approach which considers both feature creation and architecture <cite class="ltx_cite ltx_citemacro_citep">(Pentyala
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2019</a>)</cite> give an interesting generalisation of multi-task learning architectures then apply it to the joint task. For example a three sub-task parallel architecture would take samples with training labels for each sub-task, develop universal features, task specific features, and grouped features, concatenate them and then feed them to task specific decoders. Series architectures are also given. Their base circuit uses word and character embeddings and is a standard BiLSTM encoder feeding an LSTM decoder for slots and a softmax classifier on the final hidden states for intent. No attention or slot gating occur. The base circuit is then adjusted to match some of the series and parallel architectures. <cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite> also look at varieties of series architectures from multi-task circuit design.</p>
</div>
</section>
<section id="S5.SS2.SSS9" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.9. </span>Graph networks</h4>

<div id="S5.SS2.SSS9.p1" class="ltx_para">
<p id="S5.SS2.SSS9.p1.1" class="ltx_p">Graph networks can be used to address shortcomings of limited context windows suffered by RNNs and CRFs, as they can learn global relationships between words and labels.</p>
</div>
<div id="S5.SS2.SSS9.p2" class="ltx_para">
<p id="S5.SS2.SSS9.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2020b</a>)</cite> use a graph S-LSTM network to overcome perceived shortcomings of RNNs, being lack of parallelisation (due to sequential nature), weak local context use, and lack of long range detection. The graph has as nodes the word representations and sentence representation from an LSTM, hence the network simultaneously works on the whole sentence. Only word nodes within a context window are connected by edges. The sentence node is connected to all word nodes. Messages are passed between the nodes to enable global coordination. The final node states for each slot go through a convolution unit and self attention before being used for slot filling. The final sentence node state is used directly for intent detection.</p>
</div>
<div id="S5.SS2.SSS9.p3" class="ltx_para">
<p id="S5.SS2.SSS9.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Tang
et al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2020</a>)</cite> see shortcomings of linear chain CRFs as being limited context and only applicable to the slot sequence. They construct a graph based CRF graph convolutional network which learns relationships between words, slot labels and intent labels. BERT embeddings are passed through a BiLSTM which feed the GCN for prediction. A weighted joint loss is back-propagated.</p>
</div>
</section>
<section id="S5.SS2.SSS10" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.10. </span>Importing methods from analogous fields</h4>

<div id="S5.SS2.SSS10.p1" class="ltx_para">
<p id="S5.SS2.SSS10.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Bhasin et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> propose an interesting analogy; that the relationship between intent and slots is similar to that between the query and image in visual question answering. Thus they borrow an idea from the latter field - Multimodal Low Rank Bilinear (MLB) fusion, between the features of each part.</p>
</div>
<div id="S5.SS2.SSS10.p2" class="ltx_para">
<p id="S5.SS2.SSS10.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Ni
et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2020</a>)</cite> also propose an analogy with the joint task of clinical domain detection and entity recognition in medical literature. Coming from the IoT field they also propose a pipeline structure where intent is detected first and then slots determined in a closed domain setting.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Feature creation and enhancement</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">As discussed in the sub-task sections, feature creation is a critical part of the design of circuits in NLU as it ideally should capture, at least, semantic information of the individual tokens, their context, and of the entire sentence. Then, any other information that may be used to enhance the result may be considered, including meta-data and syntactic information.</p>
</div>
<section id="S5.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.1. </span>Token embedding</h4>

<div id="S5.SS3.SSS1.p1" class="ltx_para">
<p id="S5.SS3.SSS1.p1.1" class="ltx_p">The earliest models used features familiar from methods like POS tagging and containing one-hot word embedding, n-grams, affixes etc. (<cite class="ltx_cite ltx_citemacro_citep">(Jeong and Lee, <a href="#bib.bib44" title="" class="ltx_ref">2008</a>)</cite>). <cite class="ltx_cite ltx_citemacro_citep">(Celikyilmaz and
Hakkani-Tur, <a href="#bib.bib10" title="" class="ltx_ref">2012</a>)</cite> incorporated entity lists from sites such as IMDB (movie titles) or Trip Advisor (hotel names).</p>
</div>
<div id="S5.SS3.SSS1.p2" class="ltx_para">
<p id="S5.SS3.SSS1.p2.1" class="ltx_p">Neural models enable the embedding of diverse natural language without such feature engineering. The first neural features were convolutional embeddings of the utterance words in <cite class="ltx_cite ltx_citemacro_citep">(Xu and
Sarikaya, <a href="#bib.bib124" title="" class="ltx_ref">2013</a>)</cite>, which fed to a statistical model after <cite class="ltx_cite ltx_citemacro_citep">(Jeong and Lee, <a href="#bib.bib44" title="" class="ltx_ref">2008</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2015</a>)</cite> was the first to use RNN based token embeddings but also combined those into a CNN based sentence embedding.</p>
</div>
<div id="S5.SS3.SSS1.p3" class="ltx_para">
<p id="S5.SS3.SSS1.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Ma
et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2017</a>)</cite> used for input at each step a convolution of the current word and the previously predicted slot labels. <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2018c</a>)</cite> used multiple convolutional features of the embedding words but also maintained the order of the words within the convolutions. These were then fed to an RNN layer.</p>
</div>
<div id="S5.SS3.SSS1.p4" class="ltx_para">
<p id="S5.SS3.SSS1.p4.1" class="ltx_p">The gamut of word embedding methods have been used including word2vec (<cite class="ltx_cite ltx_citemacro_citep">(Pan
et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2018</a>; Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2018c</a>)</cite>), fastText (<cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite>), GloVe (<cite class="ltx_cite ltx_citemacro_citep">(Zhang and Wang, <a href="#bib.bib140" title="" class="ltx_ref">2016</a>; Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019b</a>; Dadas
et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2019</a>; Okur
et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2019</a>; Bhasin et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>; Thi Do and
Gaspers, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>; Pentyala
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2019</a>; Bhasin et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite>), ELMo <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2020b</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Krone
et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>)</cite> (pre-print only), BERT (<cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib142" title="" class="ltx_ref">2019b</a>; Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2019</a>; Ni
et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2020</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019b</a>; Castellucci et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2019</a>; Krone
et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>)</cite> (pre-print only). <cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2018a</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite> used concatenated GloVe and word2vec embeddings to capture more word information.</p>
</div>
<div id="S5.SS3.SSS1.p5" class="ltx_para">
<p id="S5.SS3.SSS1.p5.1" class="ltx_p">While BERT displays impressive performance, <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib110" title="" class="ltx_ref">2020b</a>)</cite> identify a limitation (logical dependency for slot filling) and counter it by feeding it to an intent2slot gate, an attention layer and a CRF.</p>
</div>
<div id="S5.SS3.SSS1.p6" class="ltx_para">
<p id="S5.SS3.SSS1.p6.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2019a</a>)</cite> tested ten different word contextualisation embeddings from four different method groups (feed forward, CNN, attention, LSTM) with different depths.</p>
</div>
<div id="S5.SS3.SSS1.p7" class="ltx_para">
<p id="S5.SS3.SSS1.p7.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Kim
et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2017</a>)</cite> were the first to use a combination of character and word embedding. Others also used this (<cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019b</a>; Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019a</a>; Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>; Pentyala
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2019</a>)</cite>. On the other hand, <cite class="ltx_cite ltx_citemacro_citep">(Daha and
Hewavitharana, <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite> use only character embedding.</p>
</div>
<div id="S5.SS3.SSS1.p8" class="ltx_para">
<p id="S5.SS3.SSS1.p8.1" class="ltx_p">Pre-computed syntactic features, for example POS tags for each token using the nltk library (<cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2018a</a>)</cite> have been included with word embeddings.</p>
</div>
<div id="S5.SS3.SSS1.p9" class="ltx_para">
<p id="S5.SS3.SSS1.p9.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib139" title="" class="ltx_ref">2019</a>)</cite> take from the service robotics field the importance of a key verb in an instruction in informing the slot labels. The key verb is deduced from a dependency parsing. A feature is constructed from the training data to encode a priori dependencies between words and key verbs. The circuit takes the key verb feature and concatenates it with each word’s one hot encoding. These are passed to a BiLSTM layer to produce token embeddings.</p>
</div>
</section>
<section id="S5.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.2. </span>Sentence embedding</h4>

<div id="S5.SS3.SSS2.p1" class="ltx_para">
<p id="S5.SS3.SSS2.p1.1" class="ltx_p">The use of the final hidden state in an RNN as the sentence embedding was used frequently (<cite class="ltx_cite ltx_citemacro_citep">(Zhou
et al<span class="ltx_text">.</span>, <a href="#bib.bib146" title="" class="ltx_ref">2016</a>; Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>; Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2018c</a>)</cite>). Sentences were also embedded by using a special token for the whole sentence in <cite class="ltx_cite ltx_citemacro_citep">(Hakkani-Tür et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2016</a>; Zhang and Wang, <a href="#bib.bib138" title="" class="ltx_ref">2019</a>)</cite>, as a max pooling of the RNN hidden states (<cite class="ltx_cite ltx_citemacro_citep">(Zhang and Wang, <a href="#bib.bib140" title="" class="ltx_ref">2016</a>)</cite>, as a learned weighted sum of Bi-RNN hidden states (<cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>)</cite>), as an average pooling of RNN hidden states (<cite class="ltx_cite ltx_citemacro_citep">(Ma
et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2017</a>)</cite>), as a convolutional combination of the input word vectors (<cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib144" title="" class="ltx_ref">2018</a>; Bhasin et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite>, and as self-attention over BERT word embeddings (<cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib142" title="" class="ltx_ref">2019b</a>)</cite>).</p>
</div>
<div id="S5.SS3.SSS2.p2" class="ltx_para">
<p id="S5.SS3.SSS2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Ma
et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2017</a>)</cite> also apply a sparse attention mechanism which evaluates word importance over a batch and applies weights within each sample utterance for the intent detection.</p>
</div>
<div id="S5.SS3.SSS2.p3" class="ltx_para">
<p id="S5.SS3.SSS2.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Daha and
Hewavitharana, <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite> used an extra ¡TAGG¿ token after the end-of-sentence ¡EOS¿ token for sentence encapsulation and see better intent prediction performance. <cite class="ltx_cite ltx_citemacro_citep">(Okur
et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2019</a>)</cite> encode both a ¡BOU¿ and ¡EOU¿ token at the beginning and end of the utterance in their BiLSTMs.</p>
</div>
</section>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4. </span>Target variations</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">The targets are typically the annotated intent and slot labels. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib136" title="" class="ltx_ref">2018</a>)</cite> construct a single tag for each token which incorporates the slot tag and the sentence intent. Their circuit then just performs a single seq2seq task and the sentence intent is deduced by a majority vote of the intent portion of the predicted tags. <cite class="ltx_cite ltx_citemacro_citep">(Xu
et al<span class="ltx_text">.</span>, <a href="#bib.bib123" title="" class="ltx_ref">2020</a>)</cite> use the same single tag set. <cite class="ltx_cite ltx_citemacro_citep">(Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2019</a>)</cite> perform the intent detection at token level though separate to the slot prediction, and the final intent is taken by vote.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Lee
et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2018</a>)</cite> works with learned embeddings of slot labels, intents and domains where the sum of slot label embeddings for an utterance is close to the intent embedding in vector space. A network can then be trained to map tokens to vectors close to the slot labels and intent for the utterance.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Jung
et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2018</a>)</cite> proposes a vector embedding of the entire semantic frame (intent, slot labels, slot values) as the target. In training the utterance and the semantic frame are input and vectorised. A semantic frame vector is output. The distance between the output vector and input frame vector is minimised. In testing the text is input and a vector is output and the nearest semantic frame vector is chosen.</p>
</div>
<div id="S5.SS4.p4" class="ltx_para">
<p id="S5.SS4.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Okur
et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2019</a>)</cite> proposed an extra token tag for intent keywords, for example the word “play” in an utterance with intent <span id="S5.SS4.p4.1.1" class="ltx_text ltx_font_italic">PlayMusic</span>. In one of their models only intent keywords and non-Other slot tokens contribute to intent detection.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5. </span>Issues addressed and solutions proposed</h3>

<section id="S5.SS5.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.1. </span>Narrowness of approach</h4>

<div id="S5.SS5.SSS1.p1" class="ltx_para">
<p id="S5.SS5.SSS1.p1.1" class="ltx_p">The use of features constructed only from the tokens in the sentences may be too narrow an approach. External knowledge about the words’ places in the language, or the syntactic structure of the sentence, or of co-occurrence statistics amongst word and labels may aid the task. Methods to incorporate extra elements have been developed.</p>
</div>
<section id="S5.SS5.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Knowledge bases</h5>

<div id="S5.SS5.SSS1.Px1.p1" class="ltx_para">
<p id="S5.SS5.SSS1.Px1.p1.1" class="ltx_p">Knowledge bases are constructs containing information or statistical priors that may be useful to the task at hand. They may be constructed independent of the task, or as a preliminary step using information from the training data. They have been used for feature construction, as features themselves, and to be consulted via attention.</p>
</div>
<div id="S5.SS5.SSS1.Px1.p2" class="ltx_para">
<p id="S5.SS5.SSS1.Px1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2016</a>)</cite> was the first to use an extra knowledge base to inform the joint task. They use a K-SAN input, being a structured knowledge network. Two K-SANs are constructed, one taking a dependency parse of the utterance (syntactic), and the other an Abstract Meaning Representation (AMR) graph (semantic). Each representation is tested separately. A CNN encodes the representation into a vector, while a separate CNN encodes the sentence itself into another vector. Attention is applied between the two vectors and the results combined to give a “knowledge guided representation” of the utterance. This is included as an input to a GRU RNN cell along with the word encodings in sequence. A second RNN just takes the utterance words as input. A weighted sum of the hidden states of the two RNNs is used for prediction.</p>
</div>
<div id="S5.SS5.SSS1.Px1.p3" class="ltx_para">
<p id="S5.SS5.SSS1.Px1.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2019a</a>)</cite> incorporate the ConceptNet<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>http://conceptnet.io</span></span></span> framework as a knowledge base source. (Head, Relation, Tail) triples are extracted for each word in the utterance. The TransE model (<cite class="ltx_cite ltx_citemacro_citep">(Bordes et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2013</a>)</cite>) for embedding multi-relational data is used to encode the knowledge. Attention is applied between words and the knowledge base encoding.</p>
</div>
<div id="S5.SS5.SSS1.Px1.p4" class="ltx_para">
<p id="S5.SS5.SSS1.Px1.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2020b</a>)</cite> capture the interaction between multiple intents, and slots, with a graph representation. For multi-intent a score is calculated for each intent and those above a threshold are returned. The graphs use graph attention networks. Tokens are encoded by a BiLSTM and then multiple intents are predicted. These slot path takes the token embeddings through an LSTM which provides a feature for each token which interacts with the intent predictions and the slot-intent graph to make slot predictions.</p>
</div>
<div id="S5.SS5.SSS1.Px1.p5" class="ltx_para">
<p id="S5.SS5.SSS1.Px1.p5.1" class="ltx_p">The inclusion of knowledge embedded in graph representations, or networks that perform tasks on such graphs has borne fruit in the very recent literature. Further research in this area could include other types of such graphical representations and incorporate information not just from the current training set or external knowledge bases but some combination of the two, or data from several training sets.</p>
</div>
</section>
</section>
<section id="S5.SS5.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.2. </span>Multi-turn dialogue</h4>

<div id="S5.SS5.SSS2.p1" class="ltx_para">
<p id="S5.SS5.SSS2.p1.1" class="ltx_p">Typically in NLU only the current single utterance is analysed. Temporal information or previous utterance context or previous dialogue action are not considered. However as noted in the intent and slot sections using such information in the model can lead to better performance.</p>
</div>
<div id="S5.SS5.SSS2.p2" class="ltx_para">
<p id="S5.SS5.SSS2.p2.1" class="ltx_p">There are multiple data sets available which contain a multi-turn dialogue around a single intent or set of related intents. In these cases incorporating the history from previous turns can be incorporated. <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2015</a>)</cite> fed a sentence embedding along with the predicted intent and domain labels of previous turns into the intent prediction for the current turn. <cite class="ltx_cite ltx_citemacro_citep">(Pan
et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2018</a>)</cite> calculate attention between the BiGRU embeddings of successive utterances which make up a single sample and contribute to a single intent. <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2019a</a>)</cite> similarly use attention between the BiLSTM encoding of each utterance to the previous utterances in the history.</p>
</div>
<div id="S5.SS5.SSS2.p3" class="ltx_para">
<p id="S5.SS5.SSS2.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2019b</a>)</cite> look at multiple contextual inputs in multi-turn dialogues for the current utterance. For the current utterance they apply token2token attention and sentence2token attention at the input. Information from previous turns, including intents, slots and dialogue actions can then be attached.</p>
</div>
<div id="S5.SS5.SSS2.p4" class="ltx_para">
<p id="S5.SS5.SSS2.p4.1" class="ltx_p">While it is sensible for the research to focus on single utterance analysis it should be noted that SLU devices are often listening to all dialogue, filtering out-of-domain utterances using methods discussed in Section <a href="#S3.SS3.SSS4" title="3.3.4. Emerging intents detection ‣ 3.3. Issues addressed in intent detection ‣ 3. Intent Detection ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.4</span></a>, and that incorporating lead in dialogue can be useful to the joint task.</p>
</div>
<section id="S5.SS5.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Multi-task learning</h5>

<div id="S5.SS5.SSS2.Px1.p1" class="ltx_para">
<p id="S5.SS5.SSS2.Px1.p1.1" class="ltx_p">Looking for synergies with related tasks has been an approach in the two sub-tasks and has been actively applied in the joint task. As described earlier the full semantic frame contains three levels - domain, intent and slots. Simultaneously solving the domain with the other layers has been explored <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2015</a>; Hakkani-Tür et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
<div id="S5.SS5.SSS2.Px1.p2" class="ltx_para">
<p id="S5.SS5.SSS2.Px1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2018</a>)</cite> introduced an extra task to predict tags for known user information from metadata (for example location, timestamp). The metadata task is preliminary and thus informs the BiLSTM word embedding. The results of the preliminary task feed the regular joint task training and the BiLSTM word embeddings are updated.</p>
</div>
<div id="S5.SS5.SSS2.Px1.p3" class="ltx_para">
<p id="S5.SS5.SSS2.Px1.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2018a</a>)</cite> works on the theory that adding a further sequential task (POS tagging) will aid the joint tasks. A single LSTM layer takes word embeddings and performs an intent and slot prediction at each step, feeding those predictions with the LSTM hidden state to a next-word POS tagger. A joint loss across all tasks is calculated. The results show that the extra task helps improve intent detection.</p>
</div>
<div id="S5.SS5.SSS2.Px1.p4" class="ltx_para">
<p id="S5.SS5.SSS2.Px1.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2017</a>)</cite> claim that noisy SLU output can be mitigated by making it part of an end-to-end network including dialogue action prediction in the dialogue manager, with errors back-propagating from the dialogue manager refining the NLU prediction. The hidden states of a BiLSTM SLU model also feed a second BiLSTM which performs the dialogue action prediction. A joint loss across all tasks is back-propagated. In related work, <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite> also tied together an SLU network and a network to predict the next dialogue action. They use a stronger NLU segment to improve overall results. A joint loss across intent, slots and actions was back-propagated and performance exceeded the SLU model alone. <cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2019b</a>)</cite> use dialogue action in a multi-turn data set. <cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite> incorporate dialogue action, typically as the first task in a multi-task pipeline, rather than the last.</p>
</div>
<div id="S5.SS5.SSS2.Px1.p5" class="ltx_para">
<p id="S5.SS5.SSS2.Px1.p5.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Staliūnaitė and Iacobacci, <a href="#bib.bib98" title="" class="ltx_ref">2020</a>)</cite> incorporated POS and NER tagging simultaneously with slot tagging and intent detection using a capsule network, however the results were generally poorer when both NER and POS were included rather than just one, and mixed for different data sets indicating a generalisability issue.</p>
</div>
<div id="S5.SS5.SSS2.Px1.p6" class="ltx_para">
<p id="S5.SS5.SSS2.Px1.p6.1" class="ltx_p">The method of using SLU as fine-tuning with pre-training on another task, or vice versa, has shown improvements in the SLU performance. However the results of <cite class="ltx_cite ltx_citemacro_citep">(Staliūnaitė and Iacobacci, <a href="#bib.bib98" title="" class="ltx_ref">2020</a>)</cite>, echoing those of <cite class="ltx_cite ltx_citemacro_citep">(Louvan and
Magnini, <a href="#bib.bib65" title="" class="ltx_ref">2019</a>)</cite> on slot tagging, indicate a parsimonious approach to adding extra tasks simultaneously more often yields a better result.</p>
</div>
</section>
</section>
<section id="S5.SS5.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.3. </span>Generalisability</h4>

<section id="S5.SS5.SSS3.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Domain dependence</h5>

<div id="S5.SS5.SSS3.Px1.p1" class="ltx_para">
<p id="S5.SS5.SSS3.Px1.p1.1" class="ltx_p">An issue found is that a model trained successfully on one domain or data set does not perform as well on a different domain or data set, implying it has simply learned statistical properties of the training data set. One issue suggested by <cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2018a</a>)</cite> is that the language in the data sets is not particularly “natural”. Though their ensemble model with syntactic POS features performed well on ATIS it is unclear it generalised to a second data set.</p>
</div>
<div id="S5.SS5.SSS3.Px1.p2" class="ltx_para">
<p id="S5.SS5.SSS3.Px1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2018a</a>)</cite> propose to design a domain invariant model by using an ensemble of word embeddings in an ensemble circuit with a BiGRU unit and a BiLSTM unit. While together they outperform each unit used alone, the circuit didn’t transfer well to a new dataset. This approach of using multiple methods in one circuit for generalisability appears to rely too much on chance than good design.</p>
</div>
<div id="S5.SS5.SSS3.Px1.p3" class="ltx_para">
<p id="S5.SS5.SSS3.Px1.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib91" title="" class="ltx_ref">2019a</a>)</cite> looked at the drop off of performance of state-of-the-art architectures when deployed. Some issues that cause drop off in performance are personalised language of users not matching the training data, and the cost of annotated training sets (and hence their limited size and spread). Focusing on the vocabulary they propose a sparse vocabulary embedding which they apply to two existing architectures and show improved results. The embedding uses lasso regularisation to penalise words useless to the tasks. They apply the method to the networks of <cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite> and find that while using sparse vocabulary that intent accuracy increases but slot f1 decreases. They qualitatively discuss these results with observations on what words/structures help the two sub-tasks and the joint task.</p>
</div>
<div id="S5.SS5.SSS3.Px1.p4" class="ltx_para">
<p id="S5.SS5.SSS3.Px1.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib142" title="" class="ltx_ref">2019b</a>)</cite> use BERT encoding, claiming that a pre-trained model should address the poor generalisability of models that perform their own embedding. They use a two step decoder where the first step decodes intent which feeds the intent classifier and also the second decoder which works on slot labelling. The intent decoder performs multi-head self attention on the BERT encodings. In the slot decoder a BERT embedding for a word is concatenated with the attended intent in training only if it is a “real slot”, i.e. non-’O’; otherwise it is concatenated with a random vector. Each concatenation feeds a softmax classifier for the token. A joint loss is back-propagated. The results are good for both ATIS and SNIPS.</p>
</div>
</section>
<section id="S5.SS5.SSS3.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Non-English data and transfer learning</h5>

<div id="S5.SS5.SSS3.Px2.p1" class="ltx_para">
<p id="S5.SS5.SSS3.Px2.p1.1" class="ltx_p">NLU is eventually required in many languages, most of which do not have the large annotated training datasets required. An aspect of generalisability of models is thus whether they can be used outside the language on which they are trained.</p>
</div>
<div id="S5.SS5.SSS3.Px2.p2" class="ltx_para">
<p id="S5.SS5.SSS3.Px2.p2.1" class="ltx_p">Papers have used the same architecture for both English and non-English data sets to give comparative studies across languages. <cite class="ltx_cite ltx_citemacro_citep">(Jeong and Lee, <a href="#bib.bib44" title="" class="ltx_ref">2008</a>)</cite> used ATIS and a Korean banking dataset. <cite class="ltx_cite ltx_citemacro_citep">(Zhang and Wang, <a href="#bib.bib140" title="" class="ltx_ref">2016</a>)</cite> used ATIS and Chinese questions collected from Baidu Knows. <cite class="ltx_cite ltx_citemacro_citep">(Pan
et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2018</a>)</cite> work only with a Chinese data set where word boundaries are not clearly identified.</p>
</div>
<div id="S5.SS5.SSS3.Px2.p3" class="ltx_para">
<p id="S5.SS5.SSS3.Px2.p3.1" class="ltx_p">Other papers considered the transfer of the model from English to other languages to address lack of annotated data in those languages. <cite class="ltx_cite ltx_citemacro_citep">(Thi Do and
Gaspers, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite> consider a simple weight transfer from an English model for use in German. <cite class="ltx_cite ltx_citemacro_citep">(Castellucci et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2019</a>)</cite> (pre-print only) consider transfer learning from English to Italian.</p>
</div>
<div id="S5.SS5.SSS3.Px2.p4" class="ltx_para">
<p id="S5.SS5.SSS3.Px2.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Schuster
et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2019</a>)</cite> study transfer to low resource languages, in this case from English to Spanish and Thai. The circuit is a basic BiLSTM with CRF. They evaluate three different cross-lingual transfer methods: (1) translating the training data, (2) using cross-lingual pre-trained embeddings (CoVE), and (3) using a multilingual machine translation encoder as contextual word representations. They find that using cross-lingual transfer well outperforms training on limited data from the low resource language. The work is extended by <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2019c</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citep">(Bhathiya and
Thayasivam, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2020a</a>)</cite> but moves into cross-lingual transfer theory and out of the scope of this survey.</p>
</div>
<div id="S5.SS5.SSS3.Px2.p5" class="ltx_para">
<p id="S5.SS5.SSS3.Px2.p5.1" class="ltx_p">This issue of generalisability is still very much open and in demand by endusers. Methods discussed in Section <a href="#S5.SS5.SSS4.Px2" title="Lack of annotated data ‣ 5.5.4. Limited training data ‣ 5.5. Issues addressed and solutions proposed ‣ 5. Joint intent and slot models ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.5.4</span></a> for using few-shot methods to boost performance of existing models in new domains or data sets warrant further investigation.</p>
</div>
</section>
</section>
<section id="S5.SS5.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.4. </span>Limited training data</h4>

<div id="S5.SS5.SSS4.p1" class="ltx_para">
<p id="S5.SS5.SSS4.p1.1" class="ltx_p">Annotated training data is costly in time and resources to produce. With new domains and applications for SLU appearing, with existing domains changing, and with colloquial language shifting, there is a need for methods to perform well with limited training data.</p>
</div>
<section id="S5.SS5.SSS4.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Small data sets</h5>

<div id="S5.SS5.SSS4.Px1.p1" class="ltx_para">
<p id="S5.SS5.SSS4.Px1.p1.1" class="ltx_p">In an early statistical model <cite class="ltx_cite ltx_citemacro_citep">(Wang, <a href="#bib.bib118" title="" class="ltx_ref">2010</a>)</cite> test two-pass (pipeline, intent then slot) versus one-pass (simultaneous solving) for a small training set. They show that intent classification is much better in the two pass model while token level slot f1 suffers slightly. <cite class="ltx_cite ltx_citemacro_citep">(Tam
et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2015</a>)</cite> proposed using an RNN network to learn the word/label dependency distributions from available training data. For intent, the intent label is attached to each word in an utterance. Synthetic samples are then generated for use in training. They showed that this can lead to better results for slot tagging using a CRF on three data sets but that the results for intent were inconsistent.</p>
</div>
<div id="S5.SS5.SSS4.Px1.p2" class="ltx_para">
<p id="S5.SS5.SSS4.Px1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Dadas
et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2019</a>)</cite> propose a data set augmentation scheme which generates new training samples from existing ones via three methods: labelled word replacement from an external synonym lexicon; random replacement of outside words with a synonym; and “sequence order mutation” - change of order of spans for utterances with one labelled span. They showed that augmentation can improve the slot f1 result, more so for smaller data sets, but has little effect on intent accuracy. There is a further literature on data set augmentation for SLU which we will not cover here.</p>
</div>
</section>
<section id="S5.SS5.SSS4.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Lack of annotated data</h5>

<div id="S5.SS5.SSS4.Px2.p1" class="ltx_para">
<p id="S5.SS5.SSS4.Px2.p1.1" class="ltx_p">As new domains appear it takes time and cost to develop annotated data sets for training. <cite class="ltx_cite ltx_citemacro_citep">(Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2018</a>)</cite> address this by training on user metadata as a preliminary step. They show they can achieve higher slot f1 scores on smaller training sets and with less epochs than only using the intent and slot annotations. <cite class="ltx_cite ltx_citemacro_citep">(Siddhant
et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2019</a>)</cite> construct an unlabelled utterance data set collected from ASR interactions with their agent. They train an ELMo style word embedding on this data set. For the joint task they find their embedding outperforms fastText. As well as language transfer, <cite class="ltx_cite ltx_citemacro_citep">(Bhathiya and
Thayasivam, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite> also address the transfer to new label domains with minimal samples available via a few-shot meta-learning approach.</p>
</div>
</section>
<section id="S5.SS5.SSS4.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Unseen labels</h5>

<div id="S5.SS5.SSS4.Px3.p1" class="ltx_para">
<p id="S5.SS5.SSS4.Px3.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Krone
et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>)</cite> (pre-print only) address the issue of unseen test classes by applying two few-shot algorithms: model agnostic meta-learning (MAML) and prototypical networks, in combination with three word embeddings - GloVe, BERT and ELMo. They find the prototypical network algorithm performs best, that joint training significantly improves slot filling span based F1, and that ELMo and BERT share the spoils from the word embeddings.</p>
</div>
</section>
</section>
<section id="S5.SS5.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.5. </span>The OOV issue</h4>

<div id="S5.SS5.SSS5.p1" class="ltx_para">
<p id="S5.SS5.SSS5.p1.1" class="ltx_p">Out-of-vocabulary words in the test set, that is words that do not appear in the training set, may lead to lower test performance. Similarly the use of rare words in the training set may introduce unwanted bias. This issue is related to generalisability and also to changing vocabulary from user to user, or over time.</p>
</div>
<div id="S5.SS5.SSS5.p2" class="ltx_para">
<p id="S5.SS5.SSS5.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Zhang and Wang, <a href="#bib.bib140" title="" class="ltx_ref">2016</a>)</cite> set all words that only appear once in the training set to an unknown UNK token. Then new words in the test set are also set to the UNK token. They also replace all numbers with a generic DIGIT token. This is also applied by <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2018b</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2020b</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citep">(Ray et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2018</a>)</cite> perform a paraphrasing of input utterances to cater for rare or OOV words, or for unusually phrased requests. The paraphrasing is performed by an encoder-decoder RNN and is performing a kind of translation. The paraphrase can be applied to any downstream model. <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019b</a>)</cite> propose BERT embeddings as a sop to rare or OOV words. BERT uses word-piece encoding to provide a meaningful embedding for all words.</p>
</div>
<div id="S5.SS5.SSS5.p3" class="ltx_para">
<p id="S5.SS5.SSS5.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Ray et al<span class="ltx_text">.</span>, <a href="#bib.bib85" title="" class="ltx_ref">2019</a>)</cite> address the issue of networks having trouble with slots with large semantic variability - that is, there are many values the slot can take during training and many unseen values during testing/deployment. They call these out-of-distribution (OOD) slots. They propose a new delexicalisation method. This replaces values in OOD slot locations with default values in pre-processing.</p>
</div>
</section>
<section id="S5.SS5.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.6. </span>Obfuscation and speed</h4>

<div id="S5.SS5.SSS6.p1" class="ltx_para">
<p id="S5.SS5.SSS6.p1.1" class="ltx_p">Taking a contrary view, <cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2019a</a>)</cite> consider how joint modelling may obfuscate, or hide, information and may also be unnecessarily slow. They propose a modularised network with separated tasks after a common word contextualisation pre-processing. The modularisation enables easier analysis of results. They perform speed analysis within their model suite.</p>
</div>
<div id="S5.SS5.SSS6.p2" class="ltx_para">
<p id="S5.SS5.SSS6.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2020a</a>)</cite> propose a convex combined multiple model approach to counter limitations of non-convex optimisation, one of which is slow speed of convergence due to being stuck near non-optimal solutions. Each network in the circuit has the same structure but different initialised weights. A convex combination of label predictions from each network is used as the label prediction for each slot and the intent. Both a local loss function for each network and a global loss function on the combination are back-propagated. The networks are BiLSTMs with a context layer. The convex combination outperforms single classifiers. The speed improvements are significant.</p>
</div>
</section>
<section id="S5.SS5.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.7. </span>Real time learning</h4>

<div id="S5.SS5.SSS7.p1" class="ltx_para">
<p id="S5.SS5.SSS7.p1.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib60" title="" class="ltx_ref">2016b</a>)</cite>, the authors consider real time analysis where the whole utterance isn’t analysed but a prediction is made at each time step. In this RNN the intent is predicted at each step and used as context to the slot prediction (as well as a next word language model). Thus the current slot prediction is conditional on the input words to that point, the previous slot predictions and the previous intent predictions. The recurrent unit is an LSTM but the current intent and slot predictions use MLPs on the current hidden state.</p>
</div>
</section>
<section id="S5.SS5.SSS8" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.8. </span>Label dependency</h4>

<div id="S5.SS5.SSS8.p1" class="ltx_para">
<p id="S5.SS5.SSS8.p1.1" class="ltx_p">This is an issue covered in the slot filling section and the methods used there including CRFs and encoder-decoder seq2seq models have been used in the joint task. We note further that the use of CRFs after a deep learning solution became popular again from 2018 (see Table <a href="#S2.T4" title="Table 4 ‣ 2. Overview of the literature ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) to counter this issue (<cite class="ltx_cite ltx_citemacro_citep">(Yu
et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2018</a>; Zhang and Wang, <a href="#bib.bib138" title="" class="ltx_ref">2019</a>; E
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>; Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite>). <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib110" title="" class="ltx_ref">2020b</a>)</cite> use a CRF to counter a label dependency limitation for slot-filling in using BERT due to its non-recurrent nature.</p>
</div>
<div id="S5.SS5.SSS8.p2" class="ltx_para">
<p id="S5.SS5.SSS8.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019a</a>)</cite> claim earlier models do not perform slot filling realistically enough (so reflecting the language priors) nor explore intent-slot correlation well. They propose to use a CRF for the former and a masked intent prediction as an input to the CRF for the latter. The mask is “a conditional probability distribution of slot given intent, obtained from training data”. <cite class="ltx_cite ltx_citemacro_citep">(Bhasin et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite> also use a CRF with masking, prior conditional probabilities of slot/intent co-occurrence obtained from training data, for slot prediction.</p>
</div>
</section>
<section id="S5.SS5.SSS9" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.5.9. </span>Handling multi-labels</h4>

<div id="S5.SS5.SSS9.p1" class="ltx_para">
<p id="S5.SS5.SSS9.p1.1" class="ltx_p">The multi-label issue was addressed for intent classification in Section <a href="#S3.SS3.SSS13" title="3.3.13. Multifaceted query intent prediction ‣ 3.3. Issues addressed in intent detection ‣ 3. Intent Detection ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.13</span></a>. With the move into neural models similar methods have been applied.</p>
</div>
<div id="S5.SS5.SSS9.p2" class="ltx_para">
<p id="S5.SS5.SSS9.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Wen
et al<span class="ltx_text">.</span>, <a href="#bib.bib120" title="" class="ltx_ref">2018</a>)</cite> simply removed multi-label samples from their data set. <cite class="ltx_cite ltx_citemacro_citep">(Dadas
et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2019</a>)</cite> tried using both the first label as the only label, and merging labels to a compound label. <cite class="ltx_cite ltx_citemacro_citep">(Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2020b</a>)</cite> consider multi-intent data sets, including their own extension of SNIPS to multi-intent. For multi-intent a score is calculated for each intent and those above a threshold are returned.</p>
</div>
<div id="S5.SS5.SSS9.p3" class="ltx_para">
<p id="S5.SS5.SSS9.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Gangadharaiah
and Narayanaswamy, <a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> studied both sentence level and token level multi-intent detection. For ATIS, they split the compound multi-labels, giving about 2% of the data set with multi-labels. They also use an internal data set with 52% of the samples having multi-labels. Although the assignment method is unclear a sentence may be assigned multi-labels during prediction, and these are then assigned to individual tokens in the sentence to aid with slot filling.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Data sets</h2>

<figure id="S6.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8. </span>Major data sets used in the literature, single turn in English unless noted, Train-Val-Test gives the number of utterances</figcaption>
<table id="S6.T8.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T8.1.1.1" class="ltx_tr">
<td id="S6.T8.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">Name</td>
<td id="S6.T8.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">Public</td>
<td id="S6.T8.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Train-Val-Test</td>
<td id="S6.T8.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Num Intents</td>
<td id="S6.T8.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">Num Slots</td>
<td id="S6.T8.1.1.1.6" class="ltx_td ltx_align_left ltx_border_tt">Domain,Notes</td>
</tr>
<tr id="S6.T8.1.2.2" class="ltx_tr">
<td id="S6.T8.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t">ATIS</td>
<td id="S6.T8.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">Y</td>
<td id="S6.T8.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">4478/500/893</td>
<td id="S6.T8.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">21</td>
<td id="S6.T8.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">128</td>
<td id="S6.T8.1.2.2.6" class="ltx_td ltx_align_left ltx_border_t">air travel</td>
</tr>
<tr id="S6.T8.1.3.3" class="ltx_tr">
<td id="S6.T8.1.3.3.1" class="ltx_td ltx_align_center">SNIPS-NLU</td>
<td id="S6.T8.1.3.3.2" class="ltx_td ltx_align_center">Y</td>
<td id="S6.T8.1.3.3.3" class="ltx_td ltx_align_center">13084/700/700</td>
<td id="S6.T8.1.3.3.4" class="ltx_td ltx_align_center">7</td>
<td id="S6.T8.1.3.3.5" class="ltx_td ltx_align_center">72</td>
<td id="S6.T8.1.3.3.6" class="ltx_td ltx_align_left">personal assist.</td>
</tr>
<tr id="S6.T8.1.4.4" class="ltx_tr">
<td id="S6.T8.1.4.4.1" class="ltx_td ltx_align_center">FRAMES</td>
<td id="S6.T8.1.4.4.2" class="ltx_td ltx_align_center">Y</td>
<td id="S6.T8.1.4.4.3" class="ltx_td ltx_align_center">20006/-/6598</td>
<td id="S6.T8.1.4.4.4" class="ltx_td ltx_align_center">24</td>
<td id="S6.T8.1.4.4.5" class="ltx_td ltx_align_center">136</td>
<td id="S6.T8.1.4.4.6" class="ltx_td ltx_align_left">hotel, multiturn</td>
</tr>
<tr id="S6.T8.1.5.5" class="ltx_tr">
<td id="S6.T8.1.5.5.1" class="ltx_td ltx_align_center">CQUD</td>
<td id="S6.T8.1.5.5.2" class="ltx_td ltx_align_center">N</td>
<td id="S6.T8.1.5.5.3" class="ltx_td ltx_align_center">3286</td>
<td id="S6.T8.1.5.5.4" class="ltx_td ltx_align_center">43</td>
<td id="S6.T8.1.5.5.5" class="ltx_td ltx_align_center">20</td>
<td id="S6.T8.1.5.5.6" class="ltx_td ltx_align_left">Chinese, question answering</td>
</tr>
<tr id="S6.T8.1.6.6" class="ltx_tr">
<td id="S6.T8.1.6.6.1" class="ltx_td ltx_align_center">TREC</td>
<td id="S6.T8.1.6.6.2" class="ltx_td ltx_align_center">Y</td>
<td id="S6.T8.1.6.6.3" class="ltx_td ltx_align_center">5500/-/500</td>
<td id="S6.T8.1.6.6.4" class="ltx_td ltx_align_center">6(50)</td>
<td id="S6.T8.1.6.6.5" class="ltx_td ltx_align_center">-</td>
<td id="S6.T8.1.6.6.6" class="ltx_td ltx_align_left">question classification</td>
</tr>
<tr id="S6.T8.1.7.7" class="ltx_tr">
<td id="S6.T8.1.7.7.1" class="ltx_td ltx_align_center">TRAINS</td>
<td id="S6.T8.1.7.7.2" class="ltx_td ltx_align_center">N</td>
<td id="S6.T8.1.7.7.3" class="ltx_td ltx_align_center">5355/-/1336</td>
<td id="S6.T8.1.7.7.4" class="ltx_td ltx_align_center">12</td>
<td id="S6.T8.1.7.7.5" class="ltx_td ltx_align_center">32</td>
<td id="S6.T8.1.7.7.6" class="ltx_td ltx_align_left">problem solving, multiturn</td>
</tr>
<tr id="S6.T8.1.8.8" class="ltx_tr">
<td id="S6.T8.1.8.8.1" class="ltx_td ltx_align_center">Microsoft Cortana</td>
<td id="S6.T8.1.8.8.2" class="ltx_td ltx_align_center">N</td>
<td id="S6.T8.1.8.8.3" class="ltx_td ltx_align_center">10k/1k/15k</td>
<td id="S6.T8.1.8.8.4" class="ltx_td ltx_align_center">10-20</td>
<td id="S6.T8.1.8.8.5" class="ltx_td ltx_align_center">15-63</td>
<td id="S6.T8.1.8.8.6" class="ltx_td ltx_align_left">personal assist., multi-domain</td>
</tr>
<tr id="S6.T8.1.9.9" class="ltx_tr">
<td id="S6.T8.1.9.9.1" class="ltx_td ltx_align_center">Facebook</td>
<td id="S6.T8.1.9.9.2" class="ltx_td ltx_align_center">Y</td>
<td id="S6.T8.1.9.9.3" class="ltx_td ltx_align_center">30521/4181/8621</td>
<td id="S6.T8.1.9.9.4" class="ltx_td ltx_align_center">12</td>
<td id="S6.T8.1.9.9.5" class="ltx_td ltx_align_center">11</td>
<td id="S6.T8.1.9.9.6" class="ltx_td ltx_align_left">multi-lingual task oriented</td>
</tr>
<tr id="S6.T8.1.10.10" class="ltx_tr">
<td id="S6.T8.1.10.10.1" class="ltx_td ltx_align_center">SRTS FrameNet</td>
<td id="S6.T8.1.10.10.2" class="ltx_td ltx_align_center">N</td>
<td id="S6.T8.1.10.10.3" class="ltx_td ltx_align_center">2803/-/312</td>
<td id="S6.T8.1.10.10.4" class="ltx_td ltx_align_center">12</td>
<td id="S6.T8.1.10.10.5" class="ltx_td ltx_align_center">61</td>
<td id="S6.T8.1.10.10.6" class="ltx_td ltx_align_left">robotics</td>
</tr>
<tr id="S6.T8.1.11.11" class="ltx_tr">
<td id="S6.T8.1.11.11.1" class="ltx_td ltx_align_center">Alexa</td>
<td id="S6.T8.1.11.11.2" class="ltx_td ltx_align_center">N</td>
<td id="S6.T8.1.11.11.3" class="ltx_td ltx_align_center">264000/-/-</td>
<td id="S6.T8.1.11.11.4" class="ltx_td ltx_align_center">246</td>
<td id="S6.T8.1.11.11.5" class="ltx_td ltx_align_center">3409</td>
<td id="S6.T8.1.11.11.6" class="ltx_td ltx_align_left">17 domains</td>
</tr>
<tr id="S6.T8.1.12.12" class="ltx_tr">
<td id="S6.T8.1.12.12.1" class="ltx_td ltx_align_center">DSTC2</td>
<td id="S6.T8.1.12.12.2" class="ltx_td ltx_align_center">Y</td>
<td id="S6.T8.1.12.12.3" class="ltx_td ltx_align_center">4790/1579/4485</td>
<td id="S6.T8.1.12.12.4" class="ltx_td ltx_align_center">13</td>
<td id="S6.T8.1.12.12.5" class="ltx_td ltx_align_center">9</td>
<td id="S6.T8.1.12.12.6" class="ltx_td ltx_align_left">multi-turn, restaurant search</td>
</tr>
<tr id="S6.T8.1.13.13" class="ltx_tr">
<td id="S6.T8.1.13.13.1" class="ltx_td ltx_align_center">DSTC4</td>
<td id="S6.T8.1.13.13.2" class="ltx_td ltx_align_center">Y</td>
<td id="S6.T8.1.13.13.3" class="ltx_td ltx_align_center">5648/1939/3178</td>
<td id="S6.T8.1.13.13.4" class="ltx_td ltx_align_center">87</td>
<td id="S6.T8.1.13.13.5" class="ltx_td ltx_align_center">68</td>
<td id="S6.T8.1.13.13.6" class="ltx_td ltx_align_left">multi-turn, Skype tour guide dialogues</td>
</tr>
<tr id="S6.T8.1.14.14" class="ltx_tr">
<td id="S6.T8.1.14.14.1" class="ltx_td ltx_align_center">DSTC5</td>
<td id="S6.T8.1.14.14.2" class="ltx_td ltx_align_center">Y</td>
<td id="S6.T8.1.14.14.3" class="ltx_td ltx_align_center">27528/3441/3447</td>
<td id="S6.T8.1.14.14.4" class="ltx_td ltx_align_center">84</td>
<td id="S6.T8.1.14.14.5" class="ltx_td ltx_align_center">533</td>
<td id="S6.T8.1.14.14.6" class="ltx_td ltx_align_left">dialogue with social robots</td>
</tr>
<tr id="S6.T8.1.15.15" class="ltx_tr">
<td id="S6.T8.1.15.15.1" class="ltx_td ltx_align_center">CMRS</td>
<td id="S6.T8.1.15.15.2" class="ltx_td ltx_align_center">N</td>
<td id="S6.T8.1.15.15.3" class="ltx_td ltx_align_center">2901/969/967</td>
<td id="S6.T8.1.15.15.4" class="ltx_td ltx_align_center">5</td>
<td id="S6.T8.1.15.15.5" class="ltx_td ltx_align_center">11</td>
<td id="S6.T8.1.15.15.6" class="ltx_td ltx_align_left">Chinese, meeting room reservations</td>
</tr>
<tr id="S6.T8.1.16.16" class="ltx_tr">
<td id="S6.T8.1.16.16.1" class="ltx_td ltx_align_center">CU-Move</td>
<td id="S6.T8.1.16.16.2" class="ltx_td ltx_align_center">N</td>
<td id="S6.T8.1.16.16.3" class="ltx_td ltx_align_center">57584/-/-</td>
<td id="S6.T8.1.16.16.4" class="ltx_td ltx_align_center">5</td>
<td id="S6.T8.1.16.16.5" class="ltx_td ltx_align_center">38</td>
<td id="S6.T8.1.16.16.6" class="ltx_td ltx_align_left">in-vehicle dialogue</td>
</tr>
<tr id="S6.T8.1.17.17" class="ltx_tr">
<td id="S6.T8.1.17.17.1" class="ltx_td ltx_align_center">AMIE</td>
<td id="S6.T8.1.17.17.2" class="ltx_td ltx_align_center">N</td>
<td id="S6.T8.1.17.17.3" class="ltx_td ltx_align_center">3418/-/-</td>
<td id="S6.T8.1.17.17.4" class="ltx_td ltx_align_center">10</td>
<td id="S6.T8.1.17.17.5" class="ltx_td ltx_align_center">7</td>
<td id="S6.T8.1.17.17.6" class="ltx_td ltx_align_left">in-vehicle dialogue</td>
</tr>
<tr id="S6.T8.1.18.18" class="ltx_tr">
<td id="S6.T8.1.18.18.1" class="ltx_td ltx_align_center">TeleBank</td>
<td id="S6.T8.1.18.18.2" class="ltx_td ltx_align_center">N</td>
<td id="S6.T8.1.18.18.3" class="ltx_td ltx_align_center">2238/-/-</td>
<td id="S6.T8.1.18.18.4" class="ltx_td ltx_align_center">25</td>
<td id="S6.T8.1.18.18.5" class="ltx_td ltx_align_center">17</td>
<td id="S6.T8.1.18.18.6" class="ltx_td ltx_align_left">Korean, banking</td>
</tr>
<tr id="S6.T8.1.19.19" class="ltx_tr">
<td id="S6.T8.1.19.19.1" class="ltx_td ltx_align_center">MIT MOVIE_ENG</td>
<td id="S6.T8.1.19.19.2" class="ltx_td ltx_align_center">Y</td>
<td id="S6.T8.1.19.19.3" class="ltx_td ltx_align_center">8798/97/2443</td>
<td id="S6.T8.1.19.19.4" class="ltx_td ltx_align_center">-</td>
<td id="S6.T8.1.19.19.5" class="ltx_td ltx_align_center">25</td>
<td id="S6.T8.1.19.19.6" class="ltx_td ltx_align_left">movies, slot only</td>
</tr>
<tr id="S6.T8.1.20.20" class="ltx_tr">
<td id="S6.T8.1.20.20.1" class="ltx_td ltx_align_center ltx_border_bb">MIT RESTAURANT</td>
<td id="S6.T8.1.20.20.2" class="ltx_td ltx_align_center ltx_border_bb">Y</td>
<td id="S6.T8.1.20.20.3" class="ltx_td ltx_align_center ltx_border_bb">6894/766/1521</td>
<td id="S6.T8.1.20.20.4" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S6.T8.1.20.20.5" class="ltx_td ltx_align_center ltx_border_bb">17</td>
<td id="S6.T8.1.20.20.6" class="ltx_td ltx_align_left ltx_border_bb">restaurants, slot only</td>
</tr>
</tbody>
</table>
</figure>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Introduction</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">A summary of the most commonly used data sets is presented in Table <a href="#S6.T8" title="Table 8 ‣ 6. Data sets ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. Here we cover the most commonly used data sets, ATIS and SNIPS, popular due to their easy availability and ubiquity of use allowing comparison between models. We then briefly cover the other data sets.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>The Air Travel Information System (ATIS)</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">ATIS was introduced in 1990 in <cite class="ltx_cite ltx_citemacro_citep">(Hemphill
et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">1990</a>)</cite> and its history is instructive in understanding some of the conventions of the field. The domain is air travel information including “information about flights, fares, airlines, cities, airports, and ground services”. The first release, ATIS-0, collected 740 evaluable samples. Each sample contained a sound file of a single utterances question, a transcription of the question, a set of tuples constituting the answer, and the SQL query that produced the tuples.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">Tokens were generated according to Standard Normal Orthographic Representation (SNOR) rules: whitespace-separated lexical tokens, case insensitive alphabetic text, spelled letters are represented with the letter followed by a fullstop (e.g., “a. b. c.”), no non-alphabetic characters (except apostrophes for contractions and possessives and hyphens for hyphenated words and fragments). The average length of the SNOR translated utterances was 11.3 tokens.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">Extensions to the data set were made available in subsequent years ATIS-1 (<cite class="ltx_cite ltx_citemacro_citep">(Pallett et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">1992</a>)</cite>, ATIS-2 (<cite class="ltx_cite ltx_citemacro_citep">(Hirschman, <a href="#bib.bib42" title="" class="ltx_ref">1992</a>)</cite>) and ATIS-3 (<cite class="ltx_cite ltx_citemacro_citep">(Dahl et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">1994</a>)</cite>) in late 1993 to mid-1994.</p>
</div>
<div id="S6.SS2.p4" class="ltx_para">
<p id="S6.SS2.p4.1" class="ltx_p">The set which evolved to become the standard ATIS for NLU analysis was drawn from the annotated samples in ATIS-2 and 3. <cite class="ltx_cite ltx_citemacro_citep">(Yulan He and
Young, <a href="#bib.bib133" title="" class="ltx_ref">2003</a>)</cite> were the first to use the combined set for language understanding. <cite class="ltx_cite ltx_citemacro_citep">(Raymond and
Riccardi, <a href="#bib.bib86" title="" class="ltx_ref">2007</a>)</cite> used the same set but tweaked the annotation to something more closely resembling the ATIS set used today. The set contains 4978 training samples and 893 test samples. In more recent years with the advent of neural net models, 500 of the training samples are set aside as a validation set.</p>
</div>
<div id="S6.SS2.p5" class="ltx_para">
<p id="S6.SS2.p5.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Tur
et al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2010</a>)</cite> work towards formalising the ATIS data set, using the same samples as <cite class="ltx_cite ltx_citemacro_citep">(Yulan He and
Young, <a href="#bib.bib133" title="" class="ltx_ref">2003</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Raymond and
Riccardi, <a href="#bib.bib86" title="" class="ltx_ref">2007</a>)</cite>. The intents listed by <cite class="ltx_cite ltx_citemacro_citep">(Tur
et al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2010</a>)</cite> are not the current ones as they list 17 intents each of which have non-zero frequency in train and test set.</p>
</div>
<div id="S6.SS2.p6" class="ltx_para">
<p id="S6.SS2.p6.1" class="ltx_p">In later releases some joint intents are included to give 21 intents. Also in later releases the SNOR rules are relaxed. For example punctuation is allowed (“st. louis”), utterances are all lowercase, numbers are allowed for times and years but not dates. We note that in the version of the data set used today that the intents are highly imbalanced with 75% of the samples in a single intent.</p>
</div>
<div id="S6.SS2.p7" class="ltx_para">
<p id="S6.SS2.p7.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Tur
et al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2010</a>)</cite> perform an AdaBoost classification on word n-gram features for intent classification and then separately a CRF method to label slots and then perform a classification of error types into 6 types for intent and 5 types for slots. They then suggest research directions based on these errors, being: use of parsers to identify head words or clauses; a priori information (knowledge bases); and, methods to enable long distance pattern identification, as opposed to more local, shorter patterns. They also measure the high mis-annotation rate (2.5% for intent and 8.4% for slots).</p>
</div>
<div id="S6.SS2.p8" class="ltx_para">
<p id="S6.SS2.p8.1" class="ltx_p">In 2018 <cite class="ltx_cite ltx_citemacro_citep">(Béchet and
Raymond, <a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite> performed the next analysis specifically to question the usefulness of ATIS. They ran a set of different methods from a boosted tree ensemble to a BiLSTM net on ATIS slot tagging with and without named entity tag labelling. They use the same data as <cite class="ltx_cite ltx_citemacro_citep">(Raymond and
Riccardi, <a href="#bib.bib86" title="" class="ltx_ref">2007</a>)</cite>, which removes issues with position labels (B,I,O) by collapsing semantic spans as single tokens. For example, ‘san jose’ is a single token not two. While this weakens their approach the results are worth looking at.</p>
</div>
<div id="S6.SS2.p9" class="ltx_para">
<p id="S6.SS2.p9.1" class="ltx_p">They chose their five best models and cluster the predicted slots according to:</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">agree/correct (AC) - all models get the slot correct and agree on the answer;</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">non-agreement/error (NE) - all models got wrong but there is no agreement on the errors;</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p">agree/error (AE) - all models got the wrong slot but they all made the same error;</p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i4.p1" class="ltx_para">
<p id="S6.I1.i4.p1.1" class="ltx_p">non-agreement/correct (NC) - models don’t agree on the solution but at least one is correct.</p>
</div>
</li>
</ul>
</div>
<div id="S6.SS2.p10" class="ltx_para">
<p id="S6.SS2.p10.1" class="ltx_p">These clusters suggest future directions for research. While AC is ‘solved’, AE and NE are open problems (aspects of the data set not captured by the models), and NC are useful for model comparison between those that got them right and those that did not.</p>
</div>
<div id="S6.SS2.p11" class="ltx_para">
<p id="S6.SS2.p11.1" class="ltx_p">They also highlight issues with the data set - bad annotations, ambiguity “where slots could be labelled with different labels”, and repetition errors where “only the first mention of an entity is labelled”, e.g. in “show flight and prices Kansas city to Chicago on next Wednesday arriving in Chicago by 7pm” Chicago is only labelled once.</p>
</div>
<div id="S6.SS2.p12" class="ltx_para">
<p id="S6.SS2.p12.1" class="ltx_p">They estimate that about 2.5% of the utterances are erroneously slot-tagged and conclude that ATIS is at the end of its useful life for analysis.</p>
</div>
<div id="S6.SS2.p13" class="ltx_para">
<p id="S6.SS2.p13.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Niu and Penn, <a href="#bib.bib72" title="" class="ltx_ref">2019</a>)</cite> performed the next deep analysis of the ATIS data set and extensively reviewed the shortcomings of the data set. They have subsequently re-annotated the data set fixing what they deem errors.</p>
</div>
<div id="S6.SS2.p14" class="ltx_para">
<p id="S6.SS2.p14.1" class="ltx_p">Even without this re-annotated version of ATIS results reported in the literature show that the test intent accuracy being achieved is now above 99% and slot f1 above 98%. It appears that the models to date have successfully captured the joint distributions of words, slots and intents in the data set. Further models may only make improvements at the edges and while useful may be hidden by what appear non-significant increase in the evaluation measures.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3. </span>SNIPS</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">The SNIPS Natural Language Understanding data set and its creation are fully described in <cite class="ltx_cite ltx_citemacro_citep">(Coucke
et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite>. It contains 15884 utterances (train 13084, development 700, test 700) in 7 balanced intent classes. In training there are 72 slot labels and a vocabulary size of 11241 words. The average sequence length is 9.05. Unlike ATIS, SNIPS covers different domains - weather, restaurants and entertainment. <cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019b</a>)</cite> show an interesting visualisation that the slot labels used for different domains form largely disjoint sets. These differences have made it a useful counterpoint for experimentation in NLU and models addressing both ATIS and SNIPS successfully show they can handle imbalanced data. However, the reported test results for SNIPS too are excellent - intent accuracy above 99% and slot f1 around 98%.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4. </span>Other data sets</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">Microsoft have several non-publicly available sets which have been used by Microsoft researchers. For example FRAMES is multi-turn dialogues around hotel bookings. The Microsoft Cortana personal voice assistant data sets have at least six domains - weather, calendar, communication, reminder, alarm, places. Other software houses with data sets include Facebook (public) and Alexa (private).</p>
</div>
<div id="S6.SS4.p2" class="ltx_para">
<p id="S6.SS4.p2.1" class="ltx_p">Some competitions have applicable data sets, for example the DSTC 2, 3 and 5 competitions have been used in papers. These often contain multi-turn dialogues. Also the Chinese competition based CCKS data set has been used for research.</p>
</div>
<div id="S6.SS4.p3" class="ltx_para">
<p id="S6.SS4.p3.1" class="ltx_p">The TRAINS data set, a collection of problem-solving dialogues, has been used in four papers. Data sets from diverse but relevant fields have been FrameNet from robotics, CU-Move and AMIE from in vehicle communication, and from question answering CQUD (from Baidu Knows), Yahoo and TREC (only intent annotated).</p>
</div>
<div id="S6.SS4.p4" class="ltx_para">
<p id="S6.SS4.p4.1" class="ltx_p">Non-English data sets have been generated, for example <cite class="ltx_cite ltx_citemacro_citep">(Bellomaria et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite> derived an Italian data set starting by translating SNIPS and then using Italian words for tokens like cities or movie names.</p>
</div>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5. </span>Discussion</h3>

<div id="S6.SS5.p1" class="ltx_para">
<p id="S6.SS5.p1.1" class="ltx_p">It is argued that ATIS and SNIPS have reached near to the end of their useful lives as benchmarks for the joint task. Excellent test results show that the methods developed in this survey can successfully learn the joint distributions of intent and slot labels, and slot labels with each other, in a supervised learning setting. They appear to be set to continue being the benchmarks due to the ability to compare a new approach to previous ones, though this should be tempered by the use of non-standard experimental set up discussed in Section <a href="#S8" title="8. Experimental Setup ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<div id="S6.SS5.p2" class="ltx_para">
<p id="S6.SS5.p2.1" class="ltx_p">They are useful for study because they are single utterance, have reasonable numbers of intents and slots, are task focused (so have a clear intent), have reasonable utterance lengths. Challenges include mis-annotation, OOV issues and perhaps the level of unnaturalness of the language.</p>
</div>
<div id="S6.SS5.p3" class="ltx_para">
<p id="S6.SS5.p3.1" class="ltx_p">In their defence they provide differences - class imbalance versus imbalance, single versus multi-domain - and a model that scores well on both can claim to have some generalised ability. However as noted in the literature the greater generalisability of such supervised learning models to new domains is in question.</p>
</div>
<div id="S6.SS5.p4" class="ltx_para">
<p id="S6.SS5.p4.1" class="ltx_p">It is probable that more naturally conversational data should be tested. To avoid costly annotation this should be largely unannotated, encouraging research in zero or few shot methods. Such methods can still be tested on ATIS and SNIPS (as in <cite class="ltx_cite ltx_citemacro_citep">(Krone
et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2020</a>)</cite> (pre-print only). Metrics for measuring the efficacy of such models in the absence of annotation need to be considered.</p>
</div>
<div id="S6.SS5.p5" class="ltx_para">
<p id="S6.SS5.p5.1" class="ltx_p">We further note that all the few and zero shot papers reviewed use annotated datasets for evaluation, hence still need to be transferred to new unseen datasets.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Evaluation metrics</h2>

<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1. </span>Intent classification</h3>

<section id="S7.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.1.1. </span>Intent accuracy</h4>

<div id="S7.SS1.SSS1.p1" class="ltx_para">
<p id="S7.SS1.SSS1.p1.1" class="ltx_p">For intent classification the widely used metric of accuracy is most commonly used for evaluation. Accuracy is the ratio of the number of correct predictions of intent to the total number of sentences.</p>
</div>
<div id="S7.SS1.SSS1.p2" class="ltx_para">
<p id="S7.SS1.SSS1.p2.1" class="ltx_p">Some utterances in the ATIS data set have more than one intent label. Most researchers, since they are not doing multiple label detection, consider the combined label as a new label type, e.g. atis_airfare#atis_flight_time. <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2020b</a>)</cite> note “some researchers (<cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>)</cite>; <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2018b</a>)</cite>) count an utterance as a correct classification if any ground truth label is predicted. Others (<cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite>; <cite class="ltx_cite ltx_citemacro_citep">(E
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite>) require that all of these intent labels have to be correctly predicted if an utterance is to be counted as a correct classification.”</p>
</div>
</section>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2. </span>Error rate</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">Some papers, <cite class="ltx_cite ltx_citemacro_citep">(Mohasseb
et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2018</a>)</cite> for example, instead use error rate, the ratio of wrongly classified samples to the total number of samples or 100% - accuracy, to measure intent classification performance.</p>
</div>
<section id="S7.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.1. </span>Intent precision, recall and F1</h4>

<div id="S7.SS2.SSS1.p1" class="ltx_para">
<p id="S7.SS2.SSS1.p1.1" class="ltx_p">Less frequently (e.g. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite>) precision, recall and F1 are used to evaluate intent prediction. For an intent class <math id="S7.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S7.SS2.SSS1.p1.1.m1.1a"><mi id="S7.SS2.SSS1.p1.1.m1.1.1" xref="S7.SS2.SSS1.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.SSS1.p1.1.m1.1b"><ci id="S7.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S7.SS2.SSS1.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.SSS1.p1.1.m1.1c">C</annotation></semantics></math>,</p>
</div>
<div id="S7.SS2.SSS1.p2" class="ltx_para">
<ul id="S7.I1" class="ltx_itemize">
<li id="S7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i1.p1" class="ltx_para">
<p id="S7.I1.i1.p1.1" class="ltx_p">TP is the number of True positives, intents which are correctly classified as of class <math id="S7.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S7.I1.i1.p1.1.m1.1a"><mi id="S7.I1.i1.p1.1.m1.1.1" xref="S7.I1.i1.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S7.I1.i1.p1.1.m1.1b"><ci id="S7.I1.i1.p1.1.m1.1.1.cmml" xref="S7.I1.i1.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I1.i1.p1.1.m1.1c">C</annotation></semantics></math>.</p>
</div>
</li>
<li id="S7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i2.p1" class="ltx_para">
<p id="S7.I1.i2.p1.1" class="ltx_p">FP is the number of False positives, intents which belong to other classes but are incorrectly classified as class <math id="S7.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S7.I1.i2.p1.1.m1.1a"><mi id="S7.I1.i2.p1.1.m1.1.1" xref="S7.I1.i2.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S7.I1.i2.p1.1.m1.1b"><ci id="S7.I1.i2.p1.1.m1.1.1.cmml" xref="S7.I1.i2.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I1.i2.p1.1.m1.1c">C</annotation></semantics></math>.</p>
</div>
</li>
<li id="S7.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i3.p1" class="ltx_para">
<p id="S7.I1.i3.p1.1" class="ltx_p">FN is the number of False negatives, intents of class <math id="S7.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S7.I1.i3.p1.1.m1.1a"><mi id="S7.I1.i3.p1.1.m1.1.1" xref="S7.I1.i3.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S7.I1.i3.p1.1.m1.1b"><ci id="S7.I1.i3.p1.1.m1.1.1.cmml" xref="S7.I1.i3.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I1.i3.p1.1.m1.1c">C</annotation></semantics></math> which are incorrectly classified as other classes.</p>
</div>
</li>
</ul>
</div>
<div id="S7.SS2.SSS1.p3" class="ltx_para">
<p id="S7.SS2.SSS1.p3.1" class="ltx_p">Two approaches are used; micro-averaged and macro-averaged. In the micro-averaged approach, the TP, FP and FN are summed across all classes:</p>
</div>
<div id="S7.SS2.SSS1.p4" class="ltx_para">
<table id="S7.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E1.m1.1" class="ltx_Math" alttext="Precision\ =\ \frac{\sum{TP}}{\sum{TP}+\sum{FP}}" display="block"><semantics id="S7.E1.m1.1a"><mrow id="S7.E1.m1.1.1" xref="S7.E1.m1.1.1.cmml"><mrow id="S7.E1.m1.1.1.2" xref="S7.E1.m1.1.1.2.cmml"><mi id="S7.E1.m1.1.1.2.2" xref="S7.E1.m1.1.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.2.1" xref="S7.E1.m1.1.1.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.2.3" xref="S7.E1.m1.1.1.2.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.2.1a" xref="S7.E1.m1.1.1.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.2.4" xref="S7.E1.m1.1.1.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.2.1b" xref="S7.E1.m1.1.1.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.2.5" xref="S7.E1.m1.1.1.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.2.1c" xref="S7.E1.m1.1.1.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.2.6" xref="S7.E1.m1.1.1.2.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.2.1d" xref="S7.E1.m1.1.1.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.2.7" xref="S7.E1.m1.1.1.2.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.2.1e" xref="S7.E1.m1.1.1.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.2.8" xref="S7.E1.m1.1.1.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.2.1f" xref="S7.E1.m1.1.1.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.2.9" xref="S7.E1.m1.1.1.2.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.2.1g" xref="S7.E1.m1.1.1.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.2.10" xref="S7.E1.m1.1.1.2.10.cmml">n</mi></mrow><mo lspace="0.778em" rspace="0.778em" id="S7.E1.m1.1.1.1" xref="S7.E1.m1.1.1.1.cmml">=</mo><mfrac id="S7.E1.m1.1.1.3" xref="S7.E1.m1.1.1.3.cmml"><mrow id="S7.E1.m1.1.1.3.2" xref="S7.E1.m1.1.1.3.2.cmml"><mo id="S7.E1.m1.1.1.3.2.1" xref="S7.E1.m1.1.1.3.2.1.cmml">∑</mo><mrow id="S7.E1.m1.1.1.3.2.2" xref="S7.E1.m1.1.1.3.2.2.cmml"><mi id="S7.E1.m1.1.1.3.2.2.2" xref="S7.E1.m1.1.1.3.2.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.3.2.2.1" xref="S7.E1.m1.1.1.3.2.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.3.2.2.3" xref="S7.E1.m1.1.1.3.2.2.3.cmml">P</mi></mrow></mrow><mrow id="S7.E1.m1.1.1.3.3" xref="S7.E1.m1.1.1.3.3.cmml"><mrow id="S7.E1.m1.1.1.3.3.2" xref="S7.E1.m1.1.1.3.3.2.cmml"><mo id="S7.E1.m1.1.1.3.3.2.1" xref="S7.E1.m1.1.1.3.3.2.1.cmml">∑</mo><mrow id="S7.E1.m1.1.1.3.3.2.2" xref="S7.E1.m1.1.1.3.3.2.2.cmml"><mi id="S7.E1.m1.1.1.3.3.2.2.2" xref="S7.E1.m1.1.1.3.3.2.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.3.3.2.2.1" xref="S7.E1.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.3.3.2.2.3" xref="S7.E1.m1.1.1.3.3.2.2.3.cmml">P</mi></mrow></mrow><mo rspace="0.055em" id="S7.E1.m1.1.1.3.3.1" xref="S7.E1.m1.1.1.3.3.1.cmml">+</mo><mrow id="S7.E1.m1.1.1.3.3.3" xref="S7.E1.m1.1.1.3.3.3.cmml"><mo id="S7.E1.m1.1.1.3.3.3.1" xref="S7.E1.m1.1.1.3.3.3.1.cmml">∑</mo><mrow id="S7.E1.m1.1.1.3.3.3.2" xref="S7.E1.m1.1.1.3.3.3.2.cmml"><mi id="S7.E1.m1.1.1.3.3.3.2.2" xref="S7.E1.m1.1.1.3.3.3.2.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.E1.m1.1.1.3.3.3.2.1" xref="S7.E1.m1.1.1.3.3.3.2.1.cmml">​</mo><mi id="S7.E1.m1.1.1.3.3.3.2.3" xref="S7.E1.m1.1.1.3.3.3.2.3.cmml">P</mi></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S7.E1.m1.1b"><apply id="S7.E1.m1.1.1.cmml" xref="S7.E1.m1.1.1"><eq id="S7.E1.m1.1.1.1.cmml" xref="S7.E1.m1.1.1.1"></eq><apply id="S7.E1.m1.1.1.2.cmml" xref="S7.E1.m1.1.1.2"><times id="S7.E1.m1.1.1.2.1.cmml" xref="S7.E1.m1.1.1.2.1"></times><ci id="S7.E1.m1.1.1.2.2.cmml" xref="S7.E1.m1.1.1.2.2">𝑃</ci><ci id="S7.E1.m1.1.1.2.3.cmml" xref="S7.E1.m1.1.1.2.3">𝑟</ci><ci id="S7.E1.m1.1.1.2.4.cmml" xref="S7.E1.m1.1.1.2.4">𝑒</ci><ci id="S7.E1.m1.1.1.2.5.cmml" xref="S7.E1.m1.1.1.2.5">𝑐</ci><ci id="S7.E1.m1.1.1.2.6.cmml" xref="S7.E1.m1.1.1.2.6">𝑖</ci><ci id="S7.E1.m1.1.1.2.7.cmml" xref="S7.E1.m1.1.1.2.7">𝑠</ci><ci id="S7.E1.m1.1.1.2.8.cmml" xref="S7.E1.m1.1.1.2.8">𝑖</ci><ci id="S7.E1.m1.1.1.2.9.cmml" xref="S7.E1.m1.1.1.2.9">𝑜</ci><ci id="S7.E1.m1.1.1.2.10.cmml" xref="S7.E1.m1.1.1.2.10">𝑛</ci></apply><apply id="S7.E1.m1.1.1.3.cmml" xref="S7.E1.m1.1.1.3"><divide id="S7.E1.m1.1.1.3.1.cmml" xref="S7.E1.m1.1.1.3"></divide><apply id="S7.E1.m1.1.1.3.2.cmml" xref="S7.E1.m1.1.1.3.2"><sum id="S7.E1.m1.1.1.3.2.1.cmml" xref="S7.E1.m1.1.1.3.2.1"></sum><apply id="S7.E1.m1.1.1.3.2.2.cmml" xref="S7.E1.m1.1.1.3.2.2"><times id="S7.E1.m1.1.1.3.2.2.1.cmml" xref="S7.E1.m1.1.1.3.2.2.1"></times><ci id="S7.E1.m1.1.1.3.2.2.2.cmml" xref="S7.E1.m1.1.1.3.2.2.2">𝑇</ci><ci id="S7.E1.m1.1.1.3.2.2.3.cmml" xref="S7.E1.m1.1.1.3.2.2.3">𝑃</ci></apply></apply><apply id="S7.E1.m1.1.1.3.3.cmml" xref="S7.E1.m1.1.1.3.3"><plus id="S7.E1.m1.1.1.3.3.1.cmml" xref="S7.E1.m1.1.1.3.3.1"></plus><apply id="S7.E1.m1.1.1.3.3.2.cmml" xref="S7.E1.m1.1.1.3.3.2"><sum id="S7.E1.m1.1.1.3.3.2.1.cmml" xref="S7.E1.m1.1.1.3.3.2.1"></sum><apply id="S7.E1.m1.1.1.3.3.2.2.cmml" xref="S7.E1.m1.1.1.3.3.2.2"><times id="S7.E1.m1.1.1.3.3.2.2.1.cmml" xref="S7.E1.m1.1.1.3.3.2.2.1"></times><ci id="S7.E1.m1.1.1.3.3.2.2.2.cmml" xref="S7.E1.m1.1.1.3.3.2.2.2">𝑇</ci><ci id="S7.E1.m1.1.1.3.3.2.2.3.cmml" xref="S7.E1.m1.1.1.3.3.2.2.3">𝑃</ci></apply></apply><apply id="S7.E1.m1.1.1.3.3.3.cmml" xref="S7.E1.m1.1.1.3.3.3"><sum id="S7.E1.m1.1.1.3.3.3.1.cmml" xref="S7.E1.m1.1.1.3.3.3.1"></sum><apply id="S7.E1.m1.1.1.3.3.3.2.cmml" xref="S7.E1.m1.1.1.3.3.3.2"><times id="S7.E1.m1.1.1.3.3.3.2.1.cmml" xref="S7.E1.m1.1.1.3.3.3.2.1"></times><ci id="S7.E1.m1.1.1.3.3.3.2.2.cmml" xref="S7.E1.m1.1.1.3.3.3.2.2">𝐹</ci><ci id="S7.E1.m1.1.1.3.3.3.2.3.cmml" xref="S7.E1.m1.1.1.3.3.3.2.3">𝑃</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E1.m1.1c">Precision\ =\ \frac{\sum{TP}}{\sum{TP}+\sum{FP}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S7.SS2.SSS1.p5" class="ltx_para">
<table id="S7.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E2.m1.1" class="ltx_Math" alttext="Recall\ =\ \frac{\sum{TP}}{\sum{TP}+\sum{FN}}" display="block"><semantics id="S7.E2.m1.1a"><mrow id="S7.E2.m1.1.1" xref="S7.E2.m1.1.1.cmml"><mrow id="S7.E2.m1.1.1.2" xref="S7.E2.m1.1.1.2.cmml"><mi id="S7.E2.m1.1.1.2.2" xref="S7.E2.m1.1.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S7.E2.m1.1.1.2.1" xref="S7.E2.m1.1.1.2.1.cmml">​</mo><mi id="S7.E2.m1.1.1.2.3" xref="S7.E2.m1.1.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.E2.m1.1.1.2.1a" xref="S7.E2.m1.1.1.2.1.cmml">​</mo><mi id="S7.E2.m1.1.1.2.4" xref="S7.E2.m1.1.1.2.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S7.E2.m1.1.1.2.1b" xref="S7.E2.m1.1.1.2.1.cmml">​</mo><mi id="S7.E2.m1.1.1.2.5" xref="S7.E2.m1.1.1.2.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.E2.m1.1.1.2.1c" xref="S7.E2.m1.1.1.2.1.cmml">​</mo><mi id="S7.E2.m1.1.1.2.6" xref="S7.E2.m1.1.1.2.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S7.E2.m1.1.1.2.1d" xref="S7.E2.m1.1.1.2.1.cmml">​</mo><mi id="S7.E2.m1.1.1.2.7" xref="S7.E2.m1.1.1.2.7.cmml">l</mi></mrow><mo lspace="0.778em" rspace="0.778em" id="S7.E2.m1.1.1.1" xref="S7.E2.m1.1.1.1.cmml">=</mo><mfrac id="S7.E2.m1.1.1.3" xref="S7.E2.m1.1.1.3.cmml"><mrow id="S7.E2.m1.1.1.3.2" xref="S7.E2.m1.1.1.3.2.cmml"><mo id="S7.E2.m1.1.1.3.2.1" xref="S7.E2.m1.1.1.3.2.1.cmml">∑</mo><mrow id="S7.E2.m1.1.1.3.2.2" xref="S7.E2.m1.1.1.3.2.2.cmml"><mi id="S7.E2.m1.1.1.3.2.2.2" xref="S7.E2.m1.1.1.3.2.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E2.m1.1.1.3.2.2.1" xref="S7.E2.m1.1.1.3.2.2.1.cmml">​</mo><mi id="S7.E2.m1.1.1.3.2.2.3" xref="S7.E2.m1.1.1.3.2.2.3.cmml">P</mi></mrow></mrow><mrow id="S7.E2.m1.1.1.3.3" xref="S7.E2.m1.1.1.3.3.cmml"><mrow id="S7.E2.m1.1.1.3.3.2" xref="S7.E2.m1.1.1.3.3.2.cmml"><mo id="S7.E2.m1.1.1.3.3.2.1" xref="S7.E2.m1.1.1.3.3.2.1.cmml">∑</mo><mrow id="S7.E2.m1.1.1.3.3.2.2" xref="S7.E2.m1.1.1.3.3.2.2.cmml"><mi id="S7.E2.m1.1.1.3.3.2.2.2" xref="S7.E2.m1.1.1.3.3.2.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E2.m1.1.1.3.3.2.2.1" xref="S7.E2.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S7.E2.m1.1.1.3.3.2.2.3" xref="S7.E2.m1.1.1.3.3.2.2.3.cmml">P</mi></mrow></mrow><mo rspace="0.055em" id="S7.E2.m1.1.1.3.3.1" xref="S7.E2.m1.1.1.3.3.1.cmml">+</mo><mrow id="S7.E2.m1.1.1.3.3.3" xref="S7.E2.m1.1.1.3.3.3.cmml"><mo id="S7.E2.m1.1.1.3.3.3.1" xref="S7.E2.m1.1.1.3.3.3.1.cmml">∑</mo><mrow id="S7.E2.m1.1.1.3.3.3.2" xref="S7.E2.m1.1.1.3.3.3.2.cmml"><mi id="S7.E2.m1.1.1.3.3.3.2.2" xref="S7.E2.m1.1.1.3.3.3.2.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.E2.m1.1.1.3.3.3.2.1" xref="S7.E2.m1.1.1.3.3.3.2.1.cmml">​</mo><mi id="S7.E2.m1.1.1.3.3.3.2.3" xref="S7.E2.m1.1.1.3.3.3.2.3.cmml">N</mi></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S7.E2.m1.1b"><apply id="S7.E2.m1.1.1.cmml" xref="S7.E2.m1.1.1"><eq id="S7.E2.m1.1.1.1.cmml" xref="S7.E2.m1.1.1.1"></eq><apply id="S7.E2.m1.1.1.2.cmml" xref="S7.E2.m1.1.1.2"><times id="S7.E2.m1.1.1.2.1.cmml" xref="S7.E2.m1.1.1.2.1"></times><ci id="S7.E2.m1.1.1.2.2.cmml" xref="S7.E2.m1.1.1.2.2">𝑅</ci><ci id="S7.E2.m1.1.1.2.3.cmml" xref="S7.E2.m1.1.1.2.3">𝑒</ci><ci id="S7.E2.m1.1.1.2.4.cmml" xref="S7.E2.m1.1.1.2.4">𝑐</ci><ci id="S7.E2.m1.1.1.2.5.cmml" xref="S7.E2.m1.1.1.2.5">𝑎</ci><ci id="S7.E2.m1.1.1.2.6.cmml" xref="S7.E2.m1.1.1.2.6">𝑙</ci><ci id="S7.E2.m1.1.1.2.7.cmml" xref="S7.E2.m1.1.1.2.7">𝑙</ci></apply><apply id="S7.E2.m1.1.1.3.cmml" xref="S7.E2.m1.1.1.3"><divide id="S7.E2.m1.1.1.3.1.cmml" xref="S7.E2.m1.1.1.3"></divide><apply id="S7.E2.m1.1.1.3.2.cmml" xref="S7.E2.m1.1.1.3.2"><sum id="S7.E2.m1.1.1.3.2.1.cmml" xref="S7.E2.m1.1.1.3.2.1"></sum><apply id="S7.E2.m1.1.1.3.2.2.cmml" xref="S7.E2.m1.1.1.3.2.2"><times id="S7.E2.m1.1.1.3.2.2.1.cmml" xref="S7.E2.m1.1.1.3.2.2.1"></times><ci id="S7.E2.m1.1.1.3.2.2.2.cmml" xref="S7.E2.m1.1.1.3.2.2.2">𝑇</ci><ci id="S7.E2.m1.1.1.3.2.2.3.cmml" xref="S7.E2.m1.1.1.3.2.2.3">𝑃</ci></apply></apply><apply id="S7.E2.m1.1.1.3.3.cmml" xref="S7.E2.m1.1.1.3.3"><plus id="S7.E2.m1.1.1.3.3.1.cmml" xref="S7.E2.m1.1.1.3.3.1"></plus><apply id="S7.E2.m1.1.1.3.3.2.cmml" xref="S7.E2.m1.1.1.3.3.2"><sum id="S7.E2.m1.1.1.3.3.2.1.cmml" xref="S7.E2.m1.1.1.3.3.2.1"></sum><apply id="S7.E2.m1.1.1.3.3.2.2.cmml" xref="S7.E2.m1.1.1.3.3.2.2"><times id="S7.E2.m1.1.1.3.3.2.2.1.cmml" xref="S7.E2.m1.1.1.3.3.2.2.1"></times><ci id="S7.E2.m1.1.1.3.3.2.2.2.cmml" xref="S7.E2.m1.1.1.3.3.2.2.2">𝑇</ci><ci id="S7.E2.m1.1.1.3.3.2.2.3.cmml" xref="S7.E2.m1.1.1.3.3.2.2.3">𝑃</ci></apply></apply><apply id="S7.E2.m1.1.1.3.3.3.cmml" xref="S7.E2.m1.1.1.3.3.3"><sum id="S7.E2.m1.1.1.3.3.3.1.cmml" xref="S7.E2.m1.1.1.3.3.3.1"></sum><apply id="S7.E2.m1.1.1.3.3.3.2.cmml" xref="S7.E2.m1.1.1.3.3.3.2"><times id="S7.E2.m1.1.1.3.3.3.2.1.cmml" xref="S7.E2.m1.1.1.3.3.3.2.1"></times><ci id="S7.E2.m1.1.1.3.3.3.2.2.cmml" xref="S7.E2.m1.1.1.3.3.3.2.2">𝐹</ci><ci id="S7.E2.m1.1.1.3.3.3.2.3.cmml" xref="S7.E2.m1.1.1.3.3.3.2.3">𝑁</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E2.m1.1c">Recall\ =\ \frac{\sum{TP}}{\sum{TP}+\sum{FN}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S7.SS2.SSS1.p6" class="ltx_para">
<p id="S7.SS2.SSS1.p6.1" class="ltx_p">In the macro-averaged approach, the precision and recall are computed for each class first, then the average across all <math id="S7.SS2.SSS1.p6.1.m1.1" class="ltx_Math" alttext="n_{C}" display="inline"><semantics id="S7.SS2.SSS1.p6.1.m1.1a"><msub id="S7.SS2.SSS1.p6.1.m1.1.1" xref="S7.SS2.SSS1.p6.1.m1.1.1.cmml"><mi id="S7.SS2.SSS1.p6.1.m1.1.1.2" xref="S7.SS2.SSS1.p6.1.m1.1.1.2.cmml">n</mi><mi id="S7.SS2.SSS1.p6.1.m1.1.1.3" xref="S7.SS2.SSS1.p6.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.SSS1.p6.1.m1.1b"><apply id="S7.SS2.SSS1.p6.1.m1.1.1.cmml" xref="S7.SS2.SSS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S7.SS2.SSS1.p6.1.m1.1.1.1.cmml" xref="S7.SS2.SSS1.p6.1.m1.1.1">subscript</csymbol><ci id="S7.SS2.SSS1.p6.1.m1.1.1.2.cmml" xref="S7.SS2.SSS1.p6.1.m1.1.1.2">𝑛</ci><ci id="S7.SS2.SSS1.p6.1.m1.1.1.3.cmml" xref="S7.SS2.SSS1.p6.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.SSS1.p6.1.m1.1c">n_{C}</annotation></semantics></math> classes is reported.</p>
</div>
<div id="S7.SS2.SSS1.p7" class="ltx_para">
<table id="S7.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E3.m1.1" class="ltx_Math" alttext="Precision\ =\ \frac{1}{n_{C}}\sum{\frac{TP}{TP+FP}}" display="block"><semantics id="S7.E3.m1.1a"><mrow id="S7.E3.m1.1.1" xref="S7.E3.m1.1.1.cmml"><mrow id="S7.E3.m1.1.1.2" xref="S7.E3.m1.1.1.2.cmml"><mi id="S7.E3.m1.1.1.2.2" xref="S7.E3.m1.1.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.2.1" xref="S7.E3.m1.1.1.2.1.cmml">​</mo><mi id="S7.E3.m1.1.1.2.3" xref="S7.E3.m1.1.1.2.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.2.1a" xref="S7.E3.m1.1.1.2.1.cmml">​</mo><mi id="S7.E3.m1.1.1.2.4" xref="S7.E3.m1.1.1.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.2.1b" xref="S7.E3.m1.1.1.2.1.cmml">​</mo><mi id="S7.E3.m1.1.1.2.5" xref="S7.E3.m1.1.1.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.2.1c" xref="S7.E3.m1.1.1.2.1.cmml">​</mo><mi id="S7.E3.m1.1.1.2.6" xref="S7.E3.m1.1.1.2.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.2.1d" xref="S7.E3.m1.1.1.2.1.cmml">​</mo><mi id="S7.E3.m1.1.1.2.7" xref="S7.E3.m1.1.1.2.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.2.1e" xref="S7.E3.m1.1.1.2.1.cmml">​</mo><mi id="S7.E3.m1.1.1.2.8" xref="S7.E3.m1.1.1.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.2.1f" xref="S7.E3.m1.1.1.2.1.cmml">​</mo><mi id="S7.E3.m1.1.1.2.9" xref="S7.E3.m1.1.1.2.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.2.1g" xref="S7.E3.m1.1.1.2.1.cmml">​</mo><mi id="S7.E3.m1.1.1.2.10" xref="S7.E3.m1.1.1.2.10.cmml">n</mi></mrow><mo lspace="0.778em" rspace="0.778em" id="S7.E3.m1.1.1.1" xref="S7.E3.m1.1.1.1.cmml">=</mo><mrow id="S7.E3.m1.1.1.3" xref="S7.E3.m1.1.1.3.cmml"><mfrac id="S7.E3.m1.1.1.3.2" xref="S7.E3.m1.1.1.3.2.cmml"><mn id="S7.E3.m1.1.1.3.2.2" xref="S7.E3.m1.1.1.3.2.2.cmml">1</mn><msub id="S7.E3.m1.1.1.3.2.3" xref="S7.E3.m1.1.1.3.2.3.cmml"><mi id="S7.E3.m1.1.1.3.2.3.2" xref="S7.E3.m1.1.1.3.2.3.2.cmml">n</mi><mi id="S7.E3.m1.1.1.3.2.3.3" xref="S7.E3.m1.1.1.3.2.3.3.cmml">C</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.3.1" xref="S7.E3.m1.1.1.3.1.cmml">​</mo><mrow id="S7.E3.m1.1.1.3.3" xref="S7.E3.m1.1.1.3.3.cmml"><mo movablelimits="false" id="S7.E3.m1.1.1.3.3.1" xref="S7.E3.m1.1.1.3.3.1.cmml">∑</mo><mfrac id="S7.E3.m1.1.1.3.3.2" xref="S7.E3.m1.1.1.3.3.2.cmml"><mrow id="S7.E3.m1.1.1.3.3.2.2" xref="S7.E3.m1.1.1.3.3.2.2.cmml"><mi id="S7.E3.m1.1.1.3.3.2.2.2" xref="S7.E3.m1.1.1.3.3.2.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.3.3.2.2.1" xref="S7.E3.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S7.E3.m1.1.1.3.3.2.2.3" xref="S7.E3.m1.1.1.3.3.2.2.3.cmml">P</mi></mrow><mrow id="S7.E3.m1.1.1.3.3.2.3" xref="S7.E3.m1.1.1.3.3.2.3.cmml"><mrow id="S7.E3.m1.1.1.3.3.2.3.2" xref="S7.E3.m1.1.1.3.3.2.3.2.cmml"><mi id="S7.E3.m1.1.1.3.3.2.3.2.2" xref="S7.E3.m1.1.1.3.3.2.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.3.3.2.3.2.1" xref="S7.E3.m1.1.1.3.3.2.3.2.1.cmml">​</mo><mi id="S7.E3.m1.1.1.3.3.2.3.2.3" xref="S7.E3.m1.1.1.3.3.2.3.2.3.cmml">P</mi></mrow><mo id="S7.E3.m1.1.1.3.3.2.3.1" xref="S7.E3.m1.1.1.3.3.2.3.1.cmml">+</mo><mrow id="S7.E3.m1.1.1.3.3.2.3.3" xref="S7.E3.m1.1.1.3.3.2.3.3.cmml"><mi id="S7.E3.m1.1.1.3.3.2.3.3.2" xref="S7.E3.m1.1.1.3.3.2.3.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.1.1.3.3.2.3.3.1" xref="S7.E3.m1.1.1.3.3.2.3.3.1.cmml">​</mo><mi id="S7.E3.m1.1.1.3.3.2.3.3.3" xref="S7.E3.m1.1.1.3.3.2.3.3.3.cmml">P</mi></mrow></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E3.m1.1b"><apply id="S7.E3.m1.1.1.cmml" xref="S7.E3.m1.1.1"><eq id="S7.E3.m1.1.1.1.cmml" xref="S7.E3.m1.1.1.1"></eq><apply id="S7.E3.m1.1.1.2.cmml" xref="S7.E3.m1.1.1.2"><times id="S7.E3.m1.1.1.2.1.cmml" xref="S7.E3.m1.1.1.2.1"></times><ci id="S7.E3.m1.1.1.2.2.cmml" xref="S7.E3.m1.1.1.2.2">𝑃</ci><ci id="S7.E3.m1.1.1.2.3.cmml" xref="S7.E3.m1.1.1.2.3">𝑟</ci><ci id="S7.E3.m1.1.1.2.4.cmml" xref="S7.E3.m1.1.1.2.4">𝑒</ci><ci id="S7.E3.m1.1.1.2.5.cmml" xref="S7.E3.m1.1.1.2.5">𝑐</ci><ci id="S7.E3.m1.1.1.2.6.cmml" xref="S7.E3.m1.1.1.2.6">𝑖</ci><ci id="S7.E3.m1.1.1.2.7.cmml" xref="S7.E3.m1.1.1.2.7">𝑠</ci><ci id="S7.E3.m1.1.1.2.8.cmml" xref="S7.E3.m1.1.1.2.8">𝑖</ci><ci id="S7.E3.m1.1.1.2.9.cmml" xref="S7.E3.m1.1.1.2.9">𝑜</ci><ci id="S7.E3.m1.1.1.2.10.cmml" xref="S7.E3.m1.1.1.2.10">𝑛</ci></apply><apply id="S7.E3.m1.1.1.3.cmml" xref="S7.E3.m1.1.1.3"><times id="S7.E3.m1.1.1.3.1.cmml" xref="S7.E3.m1.1.1.3.1"></times><apply id="S7.E3.m1.1.1.3.2.cmml" xref="S7.E3.m1.1.1.3.2"><divide id="S7.E3.m1.1.1.3.2.1.cmml" xref="S7.E3.m1.1.1.3.2"></divide><cn type="integer" id="S7.E3.m1.1.1.3.2.2.cmml" xref="S7.E3.m1.1.1.3.2.2">1</cn><apply id="S7.E3.m1.1.1.3.2.3.cmml" xref="S7.E3.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S7.E3.m1.1.1.3.2.3.1.cmml" xref="S7.E3.m1.1.1.3.2.3">subscript</csymbol><ci id="S7.E3.m1.1.1.3.2.3.2.cmml" xref="S7.E3.m1.1.1.3.2.3.2">𝑛</ci><ci id="S7.E3.m1.1.1.3.2.3.3.cmml" xref="S7.E3.m1.1.1.3.2.3.3">𝐶</ci></apply></apply><apply id="S7.E3.m1.1.1.3.3.cmml" xref="S7.E3.m1.1.1.3.3"><sum id="S7.E3.m1.1.1.3.3.1.cmml" xref="S7.E3.m1.1.1.3.3.1"></sum><apply id="S7.E3.m1.1.1.3.3.2.cmml" xref="S7.E3.m1.1.1.3.3.2"><divide id="S7.E3.m1.1.1.3.3.2.1.cmml" xref="S7.E3.m1.1.1.3.3.2"></divide><apply id="S7.E3.m1.1.1.3.3.2.2.cmml" xref="S7.E3.m1.1.1.3.3.2.2"><times id="S7.E3.m1.1.1.3.3.2.2.1.cmml" xref="S7.E3.m1.1.1.3.3.2.2.1"></times><ci id="S7.E3.m1.1.1.3.3.2.2.2.cmml" xref="S7.E3.m1.1.1.3.3.2.2.2">𝑇</ci><ci id="S7.E3.m1.1.1.3.3.2.2.3.cmml" xref="S7.E3.m1.1.1.3.3.2.2.3">𝑃</ci></apply><apply id="S7.E3.m1.1.1.3.3.2.3.cmml" xref="S7.E3.m1.1.1.3.3.2.3"><plus id="S7.E3.m1.1.1.3.3.2.3.1.cmml" xref="S7.E3.m1.1.1.3.3.2.3.1"></plus><apply id="S7.E3.m1.1.1.3.3.2.3.2.cmml" xref="S7.E3.m1.1.1.3.3.2.3.2"><times id="S7.E3.m1.1.1.3.3.2.3.2.1.cmml" xref="S7.E3.m1.1.1.3.3.2.3.2.1"></times><ci id="S7.E3.m1.1.1.3.3.2.3.2.2.cmml" xref="S7.E3.m1.1.1.3.3.2.3.2.2">𝑇</ci><ci id="S7.E3.m1.1.1.3.3.2.3.2.3.cmml" xref="S7.E3.m1.1.1.3.3.2.3.2.3">𝑃</ci></apply><apply id="S7.E3.m1.1.1.3.3.2.3.3.cmml" xref="S7.E3.m1.1.1.3.3.2.3.3"><times id="S7.E3.m1.1.1.3.3.2.3.3.1.cmml" xref="S7.E3.m1.1.1.3.3.2.3.3.1"></times><ci id="S7.E3.m1.1.1.3.3.2.3.3.2.cmml" xref="S7.E3.m1.1.1.3.3.2.3.3.2">𝐹</ci><ci id="S7.E3.m1.1.1.3.3.2.3.3.3.cmml" xref="S7.E3.m1.1.1.3.3.2.3.3.3">𝑃</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E3.m1.1c">Precision\ =\ \frac{1}{n_{C}}\sum{\frac{TP}{TP+FP}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S7.SS2.SSS1.p8" class="ltx_para">
<table id="S7.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E4.m1.1" class="ltx_Math" alttext="Recall\ =\ \frac{1}{n_{C}}\sum{\frac{TP}{TP+FN}}" display="block"><semantics id="S7.E4.m1.1a"><mrow id="S7.E4.m1.1.1" xref="S7.E4.m1.1.1.cmml"><mrow id="S7.E4.m1.1.1.2" xref="S7.E4.m1.1.1.2.cmml"><mi id="S7.E4.m1.1.1.2.2" xref="S7.E4.m1.1.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S7.E4.m1.1.1.2.1" xref="S7.E4.m1.1.1.2.1.cmml">​</mo><mi id="S7.E4.m1.1.1.2.3" xref="S7.E4.m1.1.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.E4.m1.1.1.2.1a" xref="S7.E4.m1.1.1.2.1.cmml">​</mo><mi id="S7.E4.m1.1.1.2.4" xref="S7.E4.m1.1.1.2.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S7.E4.m1.1.1.2.1b" xref="S7.E4.m1.1.1.2.1.cmml">​</mo><mi id="S7.E4.m1.1.1.2.5" xref="S7.E4.m1.1.1.2.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.E4.m1.1.1.2.1c" xref="S7.E4.m1.1.1.2.1.cmml">​</mo><mi id="S7.E4.m1.1.1.2.6" xref="S7.E4.m1.1.1.2.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S7.E4.m1.1.1.2.1d" xref="S7.E4.m1.1.1.2.1.cmml">​</mo><mi id="S7.E4.m1.1.1.2.7" xref="S7.E4.m1.1.1.2.7.cmml">l</mi></mrow><mo lspace="0.778em" rspace="0.778em" id="S7.E4.m1.1.1.1" xref="S7.E4.m1.1.1.1.cmml">=</mo><mrow id="S7.E4.m1.1.1.3" xref="S7.E4.m1.1.1.3.cmml"><mfrac id="S7.E4.m1.1.1.3.2" xref="S7.E4.m1.1.1.3.2.cmml"><mn id="S7.E4.m1.1.1.3.2.2" xref="S7.E4.m1.1.1.3.2.2.cmml">1</mn><msub id="S7.E4.m1.1.1.3.2.3" xref="S7.E4.m1.1.1.3.2.3.cmml"><mi id="S7.E4.m1.1.1.3.2.3.2" xref="S7.E4.m1.1.1.3.2.3.2.cmml">n</mi><mi id="S7.E4.m1.1.1.3.2.3.3" xref="S7.E4.m1.1.1.3.2.3.3.cmml">C</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S7.E4.m1.1.1.3.1" xref="S7.E4.m1.1.1.3.1.cmml">​</mo><mrow id="S7.E4.m1.1.1.3.3" xref="S7.E4.m1.1.1.3.3.cmml"><mo movablelimits="false" id="S7.E4.m1.1.1.3.3.1" xref="S7.E4.m1.1.1.3.3.1.cmml">∑</mo><mfrac id="S7.E4.m1.1.1.3.3.2" xref="S7.E4.m1.1.1.3.3.2.cmml"><mrow id="S7.E4.m1.1.1.3.3.2.2" xref="S7.E4.m1.1.1.3.3.2.2.cmml"><mi id="S7.E4.m1.1.1.3.3.2.2.2" xref="S7.E4.m1.1.1.3.3.2.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E4.m1.1.1.3.3.2.2.1" xref="S7.E4.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="S7.E4.m1.1.1.3.3.2.2.3" xref="S7.E4.m1.1.1.3.3.2.2.3.cmml">P</mi></mrow><mrow id="S7.E4.m1.1.1.3.3.2.3" xref="S7.E4.m1.1.1.3.3.2.3.cmml"><mrow id="S7.E4.m1.1.1.3.3.2.3.2" xref="S7.E4.m1.1.1.3.3.2.3.2.cmml"><mi id="S7.E4.m1.1.1.3.3.2.3.2.2" xref="S7.E4.m1.1.1.3.3.2.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E4.m1.1.1.3.3.2.3.2.1" xref="S7.E4.m1.1.1.3.3.2.3.2.1.cmml">​</mo><mi id="S7.E4.m1.1.1.3.3.2.3.2.3" xref="S7.E4.m1.1.1.3.3.2.3.2.3.cmml">P</mi></mrow><mo id="S7.E4.m1.1.1.3.3.2.3.1" xref="S7.E4.m1.1.1.3.3.2.3.1.cmml">+</mo><mrow id="S7.E4.m1.1.1.3.3.2.3.3" xref="S7.E4.m1.1.1.3.3.2.3.3.cmml"><mi id="S7.E4.m1.1.1.3.3.2.3.3.2" xref="S7.E4.m1.1.1.3.3.2.3.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.E4.m1.1.1.3.3.2.3.3.1" xref="S7.E4.m1.1.1.3.3.2.3.3.1.cmml">​</mo><mi id="S7.E4.m1.1.1.3.3.2.3.3.3" xref="S7.E4.m1.1.1.3.3.2.3.3.3.cmml">N</mi></mrow></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E4.m1.1b"><apply id="S7.E4.m1.1.1.cmml" xref="S7.E4.m1.1.1"><eq id="S7.E4.m1.1.1.1.cmml" xref="S7.E4.m1.1.1.1"></eq><apply id="S7.E4.m1.1.1.2.cmml" xref="S7.E4.m1.1.1.2"><times id="S7.E4.m1.1.1.2.1.cmml" xref="S7.E4.m1.1.1.2.1"></times><ci id="S7.E4.m1.1.1.2.2.cmml" xref="S7.E4.m1.1.1.2.2">𝑅</ci><ci id="S7.E4.m1.1.1.2.3.cmml" xref="S7.E4.m1.1.1.2.3">𝑒</ci><ci id="S7.E4.m1.1.1.2.4.cmml" xref="S7.E4.m1.1.1.2.4">𝑐</ci><ci id="S7.E4.m1.1.1.2.5.cmml" xref="S7.E4.m1.1.1.2.5">𝑎</ci><ci id="S7.E4.m1.1.1.2.6.cmml" xref="S7.E4.m1.1.1.2.6">𝑙</ci><ci id="S7.E4.m1.1.1.2.7.cmml" xref="S7.E4.m1.1.1.2.7">𝑙</ci></apply><apply id="S7.E4.m1.1.1.3.cmml" xref="S7.E4.m1.1.1.3"><times id="S7.E4.m1.1.1.3.1.cmml" xref="S7.E4.m1.1.1.3.1"></times><apply id="S7.E4.m1.1.1.3.2.cmml" xref="S7.E4.m1.1.1.3.2"><divide id="S7.E4.m1.1.1.3.2.1.cmml" xref="S7.E4.m1.1.1.3.2"></divide><cn type="integer" id="S7.E4.m1.1.1.3.2.2.cmml" xref="S7.E4.m1.1.1.3.2.2">1</cn><apply id="S7.E4.m1.1.1.3.2.3.cmml" xref="S7.E4.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S7.E4.m1.1.1.3.2.3.1.cmml" xref="S7.E4.m1.1.1.3.2.3">subscript</csymbol><ci id="S7.E4.m1.1.1.3.2.3.2.cmml" xref="S7.E4.m1.1.1.3.2.3.2">𝑛</ci><ci id="S7.E4.m1.1.1.3.2.3.3.cmml" xref="S7.E4.m1.1.1.3.2.3.3">𝐶</ci></apply></apply><apply id="S7.E4.m1.1.1.3.3.cmml" xref="S7.E4.m1.1.1.3.3"><sum id="S7.E4.m1.1.1.3.3.1.cmml" xref="S7.E4.m1.1.1.3.3.1"></sum><apply id="S7.E4.m1.1.1.3.3.2.cmml" xref="S7.E4.m1.1.1.3.3.2"><divide id="S7.E4.m1.1.1.3.3.2.1.cmml" xref="S7.E4.m1.1.1.3.3.2"></divide><apply id="S7.E4.m1.1.1.3.3.2.2.cmml" xref="S7.E4.m1.1.1.3.3.2.2"><times id="S7.E4.m1.1.1.3.3.2.2.1.cmml" xref="S7.E4.m1.1.1.3.3.2.2.1"></times><ci id="S7.E4.m1.1.1.3.3.2.2.2.cmml" xref="S7.E4.m1.1.1.3.3.2.2.2">𝑇</ci><ci id="S7.E4.m1.1.1.3.3.2.2.3.cmml" xref="S7.E4.m1.1.1.3.3.2.2.3">𝑃</ci></apply><apply id="S7.E4.m1.1.1.3.3.2.3.cmml" xref="S7.E4.m1.1.1.3.3.2.3"><plus id="S7.E4.m1.1.1.3.3.2.3.1.cmml" xref="S7.E4.m1.1.1.3.3.2.3.1"></plus><apply id="S7.E4.m1.1.1.3.3.2.3.2.cmml" xref="S7.E4.m1.1.1.3.3.2.3.2"><times id="S7.E4.m1.1.1.3.3.2.3.2.1.cmml" xref="S7.E4.m1.1.1.3.3.2.3.2.1"></times><ci id="S7.E4.m1.1.1.3.3.2.3.2.2.cmml" xref="S7.E4.m1.1.1.3.3.2.3.2.2">𝑇</ci><ci id="S7.E4.m1.1.1.3.3.2.3.2.3.cmml" xref="S7.E4.m1.1.1.3.3.2.3.2.3">𝑃</ci></apply><apply id="S7.E4.m1.1.1.3.3.2.3.3.cmml" xref="S7.E4.m1.1.1.3.3.2.3.3"><times id="S7.E4.m1.1.1.3.3.2.3.3.1.cmml" xref="S7.E4.m1.1.1.3.3.2.3.3.1"></times><ci id="S7.E4.m1.1.1.3.3.2.3.3.2.cmml" xref="S7.E4.m1.1.1.3.3.2.3.3.2">𝐹</ci><ci id="S7.E4.m1.1.1.3.3.2.3.3.3.cmml" xref="S7.E4.m1.1.1.3.3.2.3.3.3">𝑁</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E4.m1.1c">Recall\ =\ \frac{1}{n_{C}}\sum{\frac{TP}{TP+FN}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S7.SS2.SSS1.p9" class="ltx_para">
<p id="S7.SS2.SSS1.p9.1" class="ltx_p">For both approaches, F1 is computed as:</p>
</div>
<div id="S7.SS2.SSS1.p10" class="ltx_para">
<table id="S7.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E5.m1.1" class="ltx_Math" alttext="F1=\frac{2\times precision\times recall}{precision+recall}" display="block"><semantics id="S7.E5.m1.1a"><mrow id="S7.E5.m1.1.1" xref="S7.E5.m1.1.1.cmml"><mrow id="S7.E5.m1.1.1.2" xref="S7.E5.m1.1.1.2.cmml"><mi id="S7.E5.m1.1.1.2.2" xref="S7.E5.m1.1.1.2.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.2.1" xref="S7.E5.m1.1.1.2.1.cmml">​</mo><mn id="S7.E5.m1.1.1.2.3" xref="S7.E5.m1.1.1.2.3.cmml">1</mn></mrow><mo id="S7.E5.m1.1.1.1" xref="S7.E5.m1.1.1.1.cmml">=</mo><mfrac id="S7.E5.m1.1.1.3" xref="S7.E5.m1.1.1.3.cmml"><mrow id="S7.E5.m1.1.1.3.2" xref="S7.E5.m1.1.1.3.2.cmml"><mrow id="S7.E5.m1.1.1.3.2.2" xref="S7.E5.m1.1.1.3.2.2.cmml"><mrow id="S7.E5.m1.1.1.3.2.2.2" xref="S7.E5.m1.1.1.3.2.2.2.cmml"><mrow id="S7.E5.m1.1.1.3.2.2.2.2" xref="S7.E5.m1.1.1.3.2.2.2.2.cmml"><mn id="S7.E5.m1.1.1.3.2.2.2.2.2" xref="S7.E5.m1.1.1.3.2.2.2.2.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S7.E5.m1.1.1.3.2.2.2.2.1" xref="S7.E5.m1.1.1.3.2.2.2.2.1.cmml">×</mo><mi id="S7.E5.m1.1.1.3.2.2.2.2.3" xref="S7.E5.m1.1.1.3.2.2.2.2.3.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.2.2.1" xref="S7.E5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.2.2.3" xref="S7.E5.m1.1.1.3.2.2.2.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.2.2.1a" xref="S7.E5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.2.2.4" xref="S7.E5.m1.1.1.3.2.2.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.2.2.1b" xref="S7.E5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.2.2.5" xref="S7.E5.m1.1.1.3.2.2.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.2.2.1c" xref="S7.E5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.2.2.6" xref="S7.E5.m1.1.1.3.2.2.2.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.2.2.1d" xref="S7.E5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.2.2.7" xref="S7.E5.m1.1.1.3.2.2.2.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.2.2.1e" xref="S7.E5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.2.2.8" xref="S7.E5.m1.1.1.3.2.2.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.2.2.1f" xref="S7.E5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.2.2.9" xref="S7.E5.m1.1.1.3.2.2.2.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.2.2.1g" xref="S7.E5.m1.1.1.3.2.2.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.2.2.10" xref="S7.E5.m1.1.1.3.2.2.2.10.cmml">n</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S7.E5.m1.1.1.3.2.2.1" xref="S7.E5.m1.1.1.3.2.2.1.cmml">×</mo><mi id="S7.E5.m1.1.1.3.2.2.3" xref="S7.E5.m1.1.1.3.2.2.3.cmml">r</mi></mrow><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.1" xref="S7.E5.m1.1.1.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.3" xref="S7.E5.m1.1.1.3.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.1a" xref="S7.E5.m1.1.1.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.4" xref="S7.E5.m1.1.1.3.2.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.1b" xref="S7.E5.m1.1.1.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.5" xref="S7.E5.m1.1.1.3.2.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.1c" xref="S7.E5.m1.1.1.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.6" xref="S7.E5.m1.1.1.3.2.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.2.1d" xref="S7.E5.m1.1.1.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.2.7" xref="S7.E5.m1.1.1.3.2.7.cmml">l</mi></mrow><mrow id="S7.E5.m1.1.1.3.3" xref="S7.E5.m1.1.1.3.3.cmml"><mrow id="S7.E5.m1.1.1.3.3.2" xref="S7.E5.m1.1.1.3.3.2.cmml"><mi id="S7.E5.m1.1.1.3.3.2.2" xref="S7.E5.m1.1.1.3.3.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.2.1" xref="S7.E5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.2.3" xref="S7.E5.m1.1.1.3.3.2.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.2.1a" xref="S7.E5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.2.4" xref="S7.E5.m1.1.1.3.3.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.2.1b" xref="S7.E5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.2.5" xref="S7.E5.m1.1.1.3.3.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.2.1c" xref="S7.E5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.2.6" xref="S7.E5.m1.1.1.3.3.2.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.2.1d" xref="S7.E5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.2.7" xref="S7.E5.m1.1.1.3.3.2.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.2.1e" xref="S7.E5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.2.8" xref="S7.E5.m1.1.1.3.3.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.2.1f" xref="S7.E5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.2.9" xref="S7.E5.m1.1.1.3.3.2.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.2.1g" xref="S7.E5.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.2.10" xref="S7.E5.m1.1.1.3.3.2.10.cmml">n</mi></mrow><mo id="S7.E5.m1.1.1.3.3.1" xref="S7.E5.m1.1.1.3.3.1.cmml">+</mo><mrow id="S7.E5.m1.1.1.3.3.3" xref="S7.E5.m1.1.1.3.3.3.cmml"><mi id="S7.E5.m1.1.1.3.3.3.2" xref="S7.E5.m1.1.1.3.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.3.1" xref="S7.E5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.3.3" xref="S7.E5.m1.1.1.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.3.1a" xref="S7.E5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.3.4" xref="S7.E5.m1.1.1.3.3.3.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.3.1b" xref="S7.E5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.3.5" xref="S7.E5.m1.1.1.3.3.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.3.1c" xref="S7.E5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.3.6" xref="S7.E5.m1.1.1.3.3.3.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.3.3.1d" xref="S7.E5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3.3.7" xref="S7.E5.m1.1.1.3.3.3.7.cmml">l</mi></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S7.E5.m1.1b"><apply id="S7.E5.m1.1.1.cmml" xref="S7.E5.m1.1.1"><eq id="S7.E5.m1.1.1.1.cmml" xref="S7.E5.m1.1.1.1"></eq><apply id="S7.E5.m1.1.1.2.cmml" xref="S7.E5.m1.1.1.2"><times id="S7.E5.m1.1.1.2.1.cmml" xref="S7.E5.m1.1.1.2.1"></times><ci id="S7.E5.m1.1.1.2.2.cmml" xref="S7.E5.m1.1.1.2.2">𝐹</ci><cn type="integer" id="S7.E5.m1.1.1.2.3.cmml" xref="S7.E5.m1.1.1.2.3">1</cn></apply><apply id="S7.E5.m1.1.1.3.cmml" xref="S7.E5.m1.1.1.3"><divide id="S7.E5.m1.1.1.3.1.cmml" xref="S7.E5.m1.1.1.3"></divide><apply id="S7.E5.m1.1.1.3.2.cmml" xref="S7.E5.m1.1.1.3.2"><times id="S7.E5.m1.1.1.3.2.1.cmml" xref="S7.E5.m1.1.1.3.2.1"></times><apply id="S7.E5.m1.1.1.3.2.2.cmml" xref="S7.E5.m1.1.1.3.2.2"><times id="S7.E5.m1.1.1.3.2.2.1.cmml" xref="S7.E5.m1.1.1.3.2.2.1"></times><apply id="S7.E5.m1.1.1.3.2.2.2.cmml" xref="S7.E5.m1.1.1.3.2.2.2"><times id="S7.E5.m1.1.1.3.2.2.2.1.cmml" xref="S7.E5.m1.1.1.3.2.2.2.1"></times><apply id="S7.E5.m1.1.1.3.2.2.2.2.cmml" xref="S7.E5.m1.1.1.3.2.2.2.2"><times id="S7.E5.m1.1.1.3.2.2.2.2.1.cmml" xref="S7.E5.m1.1.1.3.2.2.2.2.1"></times><cn type="integer" id="S7.E5.m1.1.1.3.2.2.2.2.2.cmml" xref="S7.E5.m1.1.1.3.2.2.2.2.2">2</cn><ci id="S7.E5.m1.1.1.3.2.2.2.2.3.cmml" xref="S7.E5.m1.1.1.3.2.2.2.2.3">𝑝</ci></apply><ci id="S7.E5.m1.1.1.3.2.2.2.3.cmml" xref="S7.E5.m1.1.1.3.2.2.2.3">𝑟</ci><ci id="S7.E5.m1.1.1.3.2.2.2.4.cmml" xref="S7.E5.m1.1.1.3.2.2.2.4">𝑒</ci><ci id="S7.E5.m1.1.1.3.2.2.2.5.cmml" xref="S7.E5.m1.1.1.3.2.2.2.5">𝑐</ci><ci id="S7.E5.m1.1.1.3.2.2.2.6.cmml" xref="S7.E5.m1.1.1.3.2.2.2.6">𝑖</ci><ci id="S7.E5.m1.1.1.3.2.2.2.7.cmml" xref="S7.E5.m1.1.1.3.2.2.2.7">𝑠</ci><ci id="S7.E5.m1.1.1.3.2.2.2.8.cmml" xref="S7.E5.m1.1.1.3.2.2.2.8">𝑖</ci><ci id="S7.E5.m1.1.1.3.2.2.2.9.cmml" xref="S7.E5.m1.1.1.3.2.2.2.9">𝑜</ci><ci id="S7.E5.m1.1.1.3.2.2.2.10.cmml" xref="S7.E5.m1.1.1.3.2.2.2.10">𝑛</ci></apply><ci id="S7.E5.m1.1.1.3.2.2.3.cmml" xref="S7.E5.m1.1.1.3.2.2.3">𝑟</ci></apply><ci id="S7.E5.m1.1.1.3.2.3.cmml" xref="S7.E5.m1.1.1.3.2.3">𝑒</ci><ci id="S7.E5.m1.1.1.3.2.4.cmml" xref="S7.E5.m1.1.1.3.2.4">𝑐</ci><ci id="S7.E5.m1.1.1.3.2.5.cmml" xref="S7.E5.m1.1.1.3.2.5">𝑎</ci><ci id="S7.E5.m1.1.1.3.2.6.cmml" xref="S7.E5.m1.1.1.3.2.6">𝑙</ci><ci id="S7.E5.m1.1.1.3.2.7.cmml" xref="S7.E5.m1.1.1.3.2.7">𝑙</ci></apply><apply id="S7.E5.m1.1.1.3.3.cmml" xref="S7.E5.m1.1.1.3.3"><plus id="S7.E5.m1.1.1.3.3.1.cmml" xref="S7.E5.m1.1.1.3.3.1"></plus><apply id="S7.E5.m1.1.1.3.3.2.cmml" xref="S7.E5.m1.1.1.3.3.2"><times id="S7.E5.m1.1.1.3.3.2.1.cmml" xref="S7.E5.m1.1.1.3.3.2.1"></times><ci id="S7.E5.m1.1.1.3.3.2.2.cmml" xref="S7.E5.m1.1.1.3.3.2.2">𝑝</ci><ci id="S7.E5.m1.1.1.3.3.2.3.cmml" xref="S7.E5.m1.1.1.3.3.2.3">𝑟</ci><ci id="S7.E5.m1.1.1.3.3.2.4.cmml" xref="S7.E5.m1.1.1.3.3.2.4">𝑒</ci><ci id="S7.E5.m1.1.1.3.3.2.5.cmml" xref="S7.E5.m1.1.1.3.3.2.5">𝑐</ci><ci id="S7.E5.m1.1.1.3.3.2.6.cmml" xref="S7.E5.m1.1.1.3.3.2.6">𝑖</ci><ci id="S7.E5.m1.1.1.3.3.2.7.cmml" xref="S7.E5.m1.1.1.3.3.2.7">𝑠</ci><ci id="S7.E5.m1.1.1.3.3.2.8.cmml" xref="S7.E5.m1.1.1.3.3.2.8">𝑖</ci><ci id="S7.E5.m1.1.1.3.3.2.9.cmml" xref="S7.E5.m1.1.1.3.3.2.9">𝑜</ci><ci id="S7.E5.m1.1.1.3.3.2.10.cmml" xref="S7.E5.m1.1.1.3.3.2.10">𝑛</ci></apply><apply id="S7.E5.m1.1.1.3.3.3.cmml" xref="S7.E5.m1.1.1.3.3.3"><times id="S7.E5.m1.1.1.3.3.3.1.cmml" xref="S7.E5.m1.1.1.3.3.3.1"></times><ci id="S7.E5.m1.1.1.3.3.3.2.cmml" xref="S7.E5.m1.1.1.3.3.3.2">𝑟</ci><ci id="S7.E5.m1.1.1.3.3.3.3.cmml" xref="S7.E5.m1.1.1.3.3.3.3">𝑒</ci><ci id="S7.E5.m1.1.1.3.3.3.4.cmml" xref="S7.E5.m1.1.1.3.3.3.4">𝑐</ci><ci id="S7.E5.m1.1.1.3.3.3.5.cmml" xref="S7.E5.m1.1.1.3.3.3.5">𝑎</ci><ci id="S7.E5.m1.1.1.3.3.3.6.cmml" xref="S7.E5.m1.1.1.3.3.3.6">𝑙</ci><ci id="S7.E5.m1.1.1.3.3.3.7.cmml" xref="S7.E5.m1.1.1.3.3.3.7">𝑙</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E5.m1.1c">F1=\frac{2\times precision\times recall}{precision+recall}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S7.SS2.SSS1.p11" class="ltx_para">
<p id="S7.SS2.SSS1.p11.1" class="ltx_p">A variation used for multi-label identification are precision and recall at the top-k predictions. Here precision is the ratio of correct labels in the top k predictions divided by k and recall is the ratio of correct labels in top k predictions over the total number of correct labels. This is used by <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
</section>
<section id="S7.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.2.2. </span>Tests for significance</h4>

<div id="S7.SS2.SSS2.p1" class="ltx_para">
<p id="S7.SS2.SSS2.p1.1" class="ltx_p">Standard tests for significance of difference between two models are used. Welch’s t-test is to test the hypothesis that two populations have the same mean. <cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2018b</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite> used this with the p-value threshold set to 0.05. Other papers use the student t-test for similar purposes.</p>
</div>
<div id="S7.SS2.SSS2.p2" class="ltx_para">
<p id="S7.SS2.SSS2.p2.1" class="ltx_p">McNemar’s test is to test paired binary classified data to evaluate how well two tests agree with each other. <cite class="ltx_cite ltx_citemacro_citep">(Jeong and Lee, <a href="#bib.bib44" title="" class="ltx_ref">2008</a>)</cite> used this for a classification of ATIS intents into two domains.</p>
</div>
</section>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3. </span>Slot labelling evaluation</h3>

<section id="S7.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.1. </span>Span slot precision, recall and F1</h4>

<div id="S7.SS3.SSS1.p1" class="ltx_para">
<p id="S7.SS3.SSS1.p1.1" class="ltx_p">A span (sometimes called a chunk) refers to a sequence of words with the same class. For example the labelling B-MISC I-MISC I-MISC is a span of class MISC.</p>
</div>
<div id="S7.SS3.SSS1.p2" class="ltx_para">
<p id="S7.SS3.SSS1.p2.1" class="ltx_p">For a class <math id="S7.SS3.SSS1.p2.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S7.SS3.SSS1.p2.1.m1.1a"><mi id="S7.SS3.SSS1.p2.1.m1.1.1" xref="S7.SS3.SSS1.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS1.p2.1.m1.1b"><ci id="S7.SS3.SSS1.p2.1.m1.1.1.cmml" xref="S7.SS3.SSS1.p2.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS1.p2.1.m1.1c">C</annotation></semantics></math> we can thus define at the span level:</p>
</div>
<div id="S7.SS3.SSS1.p3" class="ltx_para">
<ul id="S7.I2" class="ltx_itemize">
<li id="S7.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I2.i1.p1" class="ltx_para">
<p id="S7.I2.i1.p1.1" class="ltx_p">TP is the number of True positives, the number of spans of class <math id="S7.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S7.I2.i1.p1.1.m1.1a"><mi id="S7.I2.i1.p1.1.m1.1.1" xref="S7.I2.i1.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.1.m1.1b"><ci id="S7.I2.i1.p1.1.m1.1.1.cmml" xref="S7.I2.i1.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.1.m1.1c">C</annotation></semantics></math> which are wholly correctly predicted.</p>
</div>
</li>
<li id="S7.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I2.i2.p1" class="ltx_para">
<p id="S7.I2.i2.p1.1" class="ltx_p">FP is the number of False positives, the number of spans of a different class which are incorrectly predicted as of class <math id="S7.I2.i2.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S7.I2.i2.p1.1.m1.1a"><mi id="S7.I2.i2.p1.1.m1.1.1" xref="S7.I2.i2.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.1.m1.1b"><ci id="S7.I2.i2.p1.1.m1.1.1.cmml" xref="S7.I2.i2.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.1.m1.1c">C</annotation></semantics></math>.</p>
</div>
</li>
<li id="S7.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I2.i3.p1" class="ltx_para">
<p id="S7.I2.i3.p1.1" class="ltx_p">FN is the number of False negatives, the number of spans of class <math id="S7.I2.i3.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S7.I2.i3.p1.1.m1.1a"><mi id="S7.I2.i3.p1.1.m1.1.1" xref="S7.I2.i3.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i3.p1.1.m1.1b"><ci id="S7.I2.i3.p1.1.m1.1.1.cmml" xref="S7.I2.i3.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i3.p1.1.m1.1c">C</annotation></semantics></math> which are incorrectly predicted, partially or wholly, to another class.</p>
</div>
</li>
</ul>
</div>
<div id="S7.SS3.SSS1.p4" class="ltx_para">
<p id="S7.SS3.SSS1.p4.1" class="ltx_p">Micro-averaged and macro-averaged precision and recall and F1 can then be calculated, similarly to the previous intent section.</p>
</div>
<div id="S7.SS3.SSS1.p5" class="ltx_para">
<p id="S7.SS3.SSS1.p5.1" class="ltx_p">In most papers slot F1 is reported as the span based micro-averaged F1 over all classes excluding O. The conlleval.py<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://github.com/sighsmile/conlleval</span></span></span> script is regularly used (<cite class="ltx_cite ltx_citemacro_citep">(Deoras and
Sarikaya, <a href="#bib.bib24" title="" class="ltx_ref">2013</a>; Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019b</a>; Daha and
Hewavitharana, <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite>) to calculate F1 score, precision and recall with micro-averaging.</p>
</div>
</section>
<section id="S7.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.2. </span>Token-based slot precision, recall and F1</h4>

<div id="S7.SS3.SSS2.p1" class="ltx_para">
<p id="S7.SS3.SSS2.p1.1" class="ltx_p">In this evaluation metric, TP, FP and FN are calculated at the token level. For slot label <math id="S7.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S7.SS3.SSS2.p1.1.m1.1a"><mi id="S7.SS3.SSS2.p1.1.m1.1.1" xref="S7.SS3.SSS2.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S7.SS3.SSS2.p1.1.m1.1b"><ci id="S7.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S7.SS3.SSS2.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS3.SSS2.p1.1.m1.1c">L</annotation></semantics></math> (e.g B-MISC):</p>
</div>
<div id="S7.SS3.SSS2.p2" class="ltx_para">
<ul id="S7.I3" class="ltx_itemize">
<li id="S7.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I3.i1.p1" class="ltx_para">
<p id="S7.I3.i1.p1.1" class="ltx_p">TP is the number of True positives, is the number of tokens which are correctly predicted as label <math id="S7.I3.i1.p1.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S7.I3.i1.p1.1.m1.1a"><mi id="S7.I3.i1.p1.1.m1.1.1" xref="S7.I3.i1.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S7.I3.i1.p1.1.m1.1b"><ci id="S7.I3.i1.p1.1.m1.1.1.cmml" xref="S7.I3.i1.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i1.p1.1.m1.1c">L</annotation></semantics></math>.</p>
</div>
</li>
<li id="S7.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I3.i2.p1" class="ltx_para">
<p id="S7.I3.i2.p1.1" class="ltx_p">FP is the number of False positives, is the number of tokens which are from another label but incorrectly predicted as label <math id="S7.I3.i2.p1.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S7.I3.i2.p1.1.m1.1a"><mi id="S7.I3.i2.p1.1.m1.1.1" xref="S7.I3.i2.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S7.I3.i2.p1.1.m1.1b"><ci id="S7.I3.i2.p1.1.m1.1.1.cmml" xref="S7.I3.i2.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i2.p1.1.m1.1c">L</annotation></semantics></math>.</p>
</div>
</li>
<li id="S7.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I3.i3.p1" class="ltx_para">
<p id="S7.I3.i3.p1.1" class="ltx_p">FN is the number of False negatives, is the number of tokens of label <math id="S7.I3.i3.p1.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S7.I3.i3.p1.1.m1.1a"><mi id="S7.I3.i3.p1.1.m1.1.1" xref="S7.I3.i3.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S7.I3.i3.p1.1.m1.1b"><ci id="S7.I3.i3.p1.1.m1.1.1.cmml" xref="S7.I3.i3.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I3.i3.p1.1.m1.1c">L</annotation></semantics></math> which are incorrectly labelled.</p>
</div>
</li>
</ul>
</div>
<div id="S7.SS3.SSS2.p3" class="ltx_para">
<p id="S7.SS3.SSS2.p3.1" class="ltx_p">The formulas for precision, recall and F1 are the same as the span-based. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite> use token based slot measures.</p>
</div>
</section>
<section id="S7.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.3. </span>Slot accuracy</h4>

<div id="S7.SS3.SSS3.p1" class="ltx_para">
<p id="S7.SS3.SSS3.p1.1" class="ltx_p">Slot accuracy is the ratio of the number of correctly labelled slots to the total number of slots. This is used in <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib131" title="" class="ltx_ref">2011</a>)</cite> where it is referred as word labelling accuracy (WLA).</p>
</div>
</section>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4. </span>Semantic accuracy</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p id="S7.SS4.p1.1" class="ltx_p">A sentence is correctly analysed if both the intent is correctly predicted and all the slots (including O labels) are correctly predicted. Semantic accuracy is then the number of correctly analysed sentences divided by the number of sentences.</p>
</div>
</section>
<section id="S7.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.5. </span>Other accuracy measures</h3>

<div id="S7.SS5.p1" class="ltx_para">
<p id="S7.SS5.p1.1" class="ltx_p">Other classifications are done outside the joint task which are outside the scope of this paper. For example if a domain is predicted a domain accuracy is measured, and if a dialog act is predicted a dialog act accuracy is measured (<cite class="ltx_cite ltx_citemacro_citep">(Celikyilmaz and
Hakkani-Tur, <a href="#bib.bib10" title="" class="ltx_ref">2012</a>)</cite> used this to evaluate their dialogue model).</p>
</div>
</section>
<section id="S7.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.6. </span>Qualitative evaluation</h3>

<div id="S7.SS6.p1" class="ltx_para">
<p id="S7.SS6.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Jeong and Lee, <a href="#bib.bib44" title="" class="ltx_ref">2008</a>)</cite> used Hinton diagrams to visualise relationships between intent and slot labels arising from weights in their tri-CRF. Attention heat maps are used for similar purposes by <cite class="ltx_cite ltx_citemacro_citep">(Ma
et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2017</a>; Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2020b</a>)</cite>.</p>
</div>
<div id="S7.SS6.p2" class="ltx_para">
<p id="S7.SS6.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite> provided t-SNE plots of their intent features to illustrate their effectiveness in prediction.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Experimental Setup</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">The standard experiment trains on annotated utterances, creates features, and learns to predict an intent and slot labels for each utterance. A held out, unseen test set is used for evaluating performance.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">The experimental setup varies for different papers. Further, many do not clearly state their setup with respect to data sets and hyper-parameters. In those papers which do specify the setup for data sets, most utilised the train-test split, where usually 80% of observations were treated as training data and the remainder were for testing. The training data may be split further to make a validation set. Alternatively, papers use 5-fold or 10-fold cross-validation for evaluation. Results are sometimes reported to be averaged over a number of runs.</p>
</div>
<div id="S8.p3" class="ltx_para">
<p id="S8.p3.1" class="ltx_p">For parameter tuning, dropout rates ranged from 0.003 to 0.5 and the size of hidden states was normally between 100 and 200, with as low as 64. Some models indicate the use of the Adam optimisation method with a learning rate between 0.0001 and 0.01. <cite class="ltx_cite ltx_citemacro_citep">(Vu
et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2016</a>)</cite> used 0.02 as their initial learning rate in the first ten epochs and then halved it for the last 15 epochs. Similarly, <cite class="ltx_cite ltx_citemacro_citep">(Ravuri and
Stolcke, <a href="#bib.bib83" title="" class="ltx_ref">2015</a>)</cite> halved the learning rate once the cross entropy loss decreased less than 0.01 per example on the held out set. Moreover, a few papers mentioned that they set parameters randomly in the beginning, and then apply 5-fold validation when tuning parameters. Word embedding dimensions vary from 64 to 1024.</p>
</div>
<div id="S8.p4" class="ltx_para">
<p id="S8.p4.1" class="ltx_p">The same problem of lack of reporting occurred with the number of epochs. In papers which stated the number of epochs, most models were trained for less than 50 epochs, with some of these training models using early stopping. <cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2019a</a>)</cite> allowed unlimited number of epochs with a stopping criteria, meanwhile <cite class="ltx_cite ltx_citemacro_citep">(Lin and Xu, <a href="#bib.bib57" title="" class="ltx_ref">2019</a>)</cite> specified the maximum epoch can be 200 and applied early stopping as well. <cite class="ltx_cite ltx_citemacro_citep">(Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2019</a>)</cite> used 300 epochs with no early stopping. Further, some models report the final epoch results while other report the best results. In the joint task there is an effort to standardise the number of epochs for the benchmark data sets to 10 for ATIS and 20 for SNIPS (with early stopping strategy permitted), to allow for comparison between models. This was initialised by <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite> who also reran the experiments of <cite class="ltx_cite ltx_citemacro_citep">(Hakkani-Tür et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>)</cite> under that regime. Table <a href="#S9.T10" title="Table 10 ‣ 9. Performance summary ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> contains the results for experiments using this number of epochs.</p>
</div>
<div id="S8.p5" class="ltx_para">
<p id="S8.p5.1" class="ltx_p">Considering that many papers did not clearly state their experimental setup, it may bring difficulties in replicating the models and obtaining results similar to those shown in the papers. Therefore, it is recommended that papers include detailed information about setup in the experiments section.</p>
</div>
<div id="S8.p6" class="ltx_para">
<p id="S8.p6.1" class="ltx_p">Furthermore, standardisation of the experiment is worth consideration. As discussed in Section <a href="#S9" title="9. Performance summary ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, a standard number of epochs on the standard data sets allows for a level of comparison between models. Results should be reported at this level. This should not limit results for different experimental setup being reported.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9. </span>Performance summary</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">To summarise performance in the joint task we list the models and their reported test results for the ATIS and SNIPS data-sets for the three standard evaluation metrics (if available) in Table <a href="#S9.T9" title="Table 9 ‣ 9. Performance summary ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. Papers are included in this table if at least one of their results is better than the benchmarks reported in papers from the previous calendar year. Several interesting patterns can be observed based on the results available: (1) The overall improvement on Slot F1 and Semantic accuracy for SNIPS over time (from around 87.3 in 2016 to almost 98.78 in 2019 for Slot F1 and from 73.2 in 2016 to 93.6 in 2020 for Semantic accuracy) is much more significant than ATIS (from 93.96 in 2014 to 98.75 in 2019 for Slot F1 and from 78.9 in 2016 to 91.6 in 2020 for Semantic accuracy), while the Intent accuracy performs in the opposite way (from 78.9 in 2016 to 91.6 in 2020 for ATIS and from 96.7 in 2016 to 99.98 in 2019 for SNIPS. (2) For those models that reported Slot F1 and Intent accuracy on both data-sets, 17 out of 26 perform better in Slot F1 for ATIS and in Intent accuracy for SNIPS. (3) Before 2019, all best performance for Semantic accuracy come from ATIS while from 2019 and a shift to SNIPS starts from 2019 ending up with all best Semantic accuracy in SNIPS.</p>
</div>
<div id="S9.p2" class="ltx_para">
<p id="S9.p2.1" class="ltx_p">However, as mentioned in the previous section, there is a wide variety in the number of epochs for which neural models are allowed to run. In order to make fair comparison, we further extracted those models that use 10 epochs for ATIS and 20 epochs for SNIPS and provide the test results in Table <a href="#S9.T10" title="Table 10 ‣ 9. Performance summary ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. These results are either from papers who follow this etiquette, or from the reproduction by <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite>, or are replicated by us using the GitHub code supplied by the authors when indicated by <math id="S9.p2.1.m1.2" class="ltx_Math" alttext="\dagger\dagger" display="inline"><semantics id="S9.p2.1.m1.2a"><mrow id="S9.p2.1.m1.2.3.2" xref="S9.p2.1.m1.2.3.1.cmml"><mo id="S9.p2.1.m1.1.1" xref="S9.p2.1.m1.1.1.cmml">†</mo><mo lspace="0em" id="S9.p2.1.m1.2.3.2.1" xref="S9.p2.1.m1.2.3.1.cmml">⁣</mo><mo id="S9.p2.1.m1.2.2" xref="S9.p2.1.m1.2.2.cmml">†</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.p2.1.m1.2b"><list id="S9.p2.1.m1.2.3.1.cmml" xref="S9.p2.1.m1.2.3.2"><ci id="S9.p2.1.m1.1.1.cmml" xref="S9.p2.1.m1.1.1">†</ci><ci id="S9.p2.1.m1.2.2.cmml" xref="S9.p2.1.m1.2.2">†</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S9.p2.1.m1.2c">\dagger\dagger</annotation></semantics></math>. In the latter case we also confirm the consistent calculation of intent and semantic accuracy as well as span-based slot f1. A similar pattern to before can be observed, that a significant improvement in Slot F1 and Semantic accuracy for SNIPS has been made since 2019 and most of the models perform better in Slot F1 for ATIS and Intent accuracy for SNIPS. These patterns could be related to the various distribution of slot and intent labels and different nature of domains of the two data sets with regard to different architectures of the models.</p>
</div>
<div id="S9.p3" class="ltx_para">
<p id="S9.p3.1" class="ltx_p">In summary, we note that the results are now excellent for the two most commonly used data sets, and any fruitful newer developments that may be lost in results that appear to not significantly increase the results for these datasets. Just as SNIPS grew to become standard, and offered different aspects to ATIS (balanced data, multi-domain), it is probable that a new data set should become part of the SLU reporting canon. It should address the issues of unlabelled data and emerging domains as these problems should be addressed by newer models.</p>
</div>
<figure id="S9.T9" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9. </span>Natural language understanding (NLU) performance on ATIS and SNIPS-NLU data sets (%). * denotes ATIS 10 epoch, SNIPS 20 epoch, <math id="S9.T9.2.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T9.2.m1.1b"><mo id="S9.T9.2.m1.1.1" xref="S9.T9.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T9.2.m1.1c"><ci id="S9.T9.2.m1.1.1.cmml" xref="S9.T9.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T9.2.m1.1d">\dagger</annotation></semantics></math> indicates GitHub available</figcaption>
<table id="S9.T9.11" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S9.T9.11.10.1" class="ltx_tr">
<th id="S9.T9.11.10.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t" rowspan="2"><span id="S9.T9.11.10.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<td id="S9.T9.11.10.1.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" colspan="3"><span id="S9.T9.11.10.1.2.1" class="ltx_text ltx_font_bold">ATIS</span></td>
<td id="S9.T9.11.10.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S9.T9.11.10.1.3.1" class="ltx_text ltx_font_bold">SNIPS</span></td>
</tr>
<tr id="S9.T9.11.11.2" class="ltx_tr">
<td id="S9.T9.11.11.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T9.11.11.2.1.1" class="ltx_text ltx_font_bold">Slot f1</span></td>
<td id="S9.T9.11.11.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T9.11.11.2.2.1" class="ltx_text ltx_font_bold">Intent acc</span></td>
<td id="S9.T9.11.11.2.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S9.T9.11.11.2.3.1" class="ltx_text ltx_font_bold">Semantic acc</span></td>
<td id="S9.T9.11.11.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T9.11.11.2.4.1" class="ltx_text ltx_font_bold">Slot f1</span></td>
<td id="S9.T9.11.11.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T9.11.11.2.5.1" class="ltx_text ltx_font_bold">Intent acc</span></td>
<td id="S9.T9.11.11.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T9.11.11.2.6.1" class="ltx_text ltx_font_bold">Semantic acc</span></td>
</tr>
<tr id="S9.T9.11.12.3" class="ltx_tr">
<th id="S9.T9.11.12.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Jeong and Lee, <a href="#bib.bib44" title="" class="ltx_ref">2008</a>)</cite> Joint 2</th>
<td id="S9.T9.11.12.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.42</td>
<td id="S9.T9.11.12.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.07</td>
<td id="S9.T9.11.12.3.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.12.3.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.12.3.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.12.3.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.13.4" class="ltx_tr">
<th id="S9.T9.11.13.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Xu and
Sarikaya, <a href="#bib.bib124" title="" class="ltx_ref">2013</a>)</cite> CNN TriCRF</th>
<td id="S9.T9.11.13.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.42</td>
<td id="S9.T9.11.13.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.09</td>
<td id="S9.T9.11.13.4.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.13.4.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.13.4.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.13.4.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.14.5" class="ltx_tr">
<th id="S9.T9.11.14.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Guo
et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2014</a>)</cite> RecNN+Viterbi</th>
<td id="S9.T9.11.14.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.96</td>
<td id="S9.T9.11.14.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.4</td>
<td id="S9.T9.11.14.5.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.14.5.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.14.5.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.14.5.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.15.6" class="ltx_tr">
<th id="S9.T9.11.15.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2015</a>)</cite> RNN Joint + NE</th>
<td id="S9.T9.11.15.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.83</td>
<td id="S9.T9.11.15.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.4</td>
<td id="S9.T9.11.15.6.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.15.6.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.15.6.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.15.6.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.16.7" class="ltx_tr">
<th id="S9.T9.11.16.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Hakkani-Tür et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite> in <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite>*</th>
<td id="S9.T9.11.16.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.3</td>
<td id="S9.T9.11.16.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.6</td>
<td id="S9.T9.11.16.7.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">80.7</td>
<td id="S9.T9.11.16.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.3</td>
<td id="S9.T9.11.16.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.9</td>
<td id="S9.T9.11.16.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73.2</td>
</tr>
<tr id="S9.T9.11.17.8" class="ltx_tr">
<th id="S9.T9.11.17.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2016</a>)</cite> K-SAN Syntax</th>
<td id="S9.T9.11.17.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.38</td>
<td id="S9.T9.11.17.8.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.17.8.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">84.32</td>
<td id="S9.T9.11.17.8.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.17.8.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.17.8.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.18.9" class="ltx_tr">
<th id="S9.T9.11.18.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Zhang and Wang, <a href="#bib.bib140" title="" class="ltx_ref">2016</a>)</cite> W+N</th>
<td id="S9.T9.11.18.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.89</td>
<td id="S9.T9.11.18.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.32</td>
<td id="S9.T9.11.18.9.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.18.9.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.18.9.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.18.9.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.19.10" class="ltx_tr">
<th id="S9.T9.11.19.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>)</cite> in <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite>*</th>
<td id="S9.T9.11.19.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.2</td>
<td id="S9.T9.11.19.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.1</td>
<td id="S9.T9.11.19.10.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">78.9</td>
<td id="S9.T9.11.19.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.8</td>
<td id="S9.T9.11.19.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.7</td>
<td id="S9.T9.11.19.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.1</td>
</tr>
<tr id="S9.T9.3.1" class="ltx_tr">
<th id="S9.T9.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite> Slot-Gated (Full Atten.)* <math id="S9.T9.3.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T9.3.1.1.m1.1a"><mo id="S9.T9.3.1.1.m1.1.1" xref="S9.T9.3.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T9.3.1.1.m1.1b"><ci id="S9.T9.3.1.1.m1.1.1.cmml" xref="S9.T9.3.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T9.3.1.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T9.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.8</td>
<td id="S9.T9.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.6</td>
<td id="S9.T9.3.1.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">82.2</td>
<td id="S9.T9.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.8</td>
<td id="S9.T9.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.0</td>
<td id="S9.T9.3.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.5</td>
</tr>
<tr id="S9.T9.4.2" class="ltx_tr">
<th id="S9.T9.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite> Slot-Gated (Intent Atten.)* <math id="S9.T9.4.2.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T9.4.2.1.m1.1a"><mo id="S9.T9.4.2.1.m1.1.1" xref="S9.T9.4.2.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T9.4.2.1.m1.1b"><ci id="S9.T9.4.2.1.m1.1.1.cmml" xref="S9.T9.4.2.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T9.4.2.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T9.4.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.2</td>
<td id="S9.T9.4.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.1</td>
<td id="S9.T9.4.2.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">82.6</td>
<td id="S9.T9.4.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.3</td>
<td id="S9.T9.4.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.8</td>
<td id="S9.T9.4.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.6</td>
</tr>
<tr id="S9.T9.11.20.11" class="ltx_tr">
<th id="S9.T9.11.20.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2018c</a>)</cite> Attention and aligned</th>
<td id="S9.T9.11.20.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.76</td>
<td id="S9.T9.11.20.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.17</td>
<td id="S9.T9.11.20.11.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.20.11.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.20.11.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.20.11.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.21.12" class="ltx_tr">
<th id="S9.T9.11.21.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2018a</a>)</cite></th>
<td id="S9.T9.11.21.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.02</td>
<td id="S9.T9.11.21.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.43</td>
<td id="S9.T9.11.21.12.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.21.12.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.21.12.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.21.12.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.5.3" class="ltx_tr">
<th id="S9.T9.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2018b</a>)</cite> <math id="S9.T9.5.3.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T9.5.3.1.m1.1a"><mo id="S9.T9.5.3.1.m1.1.1" xref="S9.T9.5.3.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T9.5.3.1.m1.1b"><ci id="S9.T9.5.3.1.m1.1.1.cmml" xref="S9.T9.5.3.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T9.5.3.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T9.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.52</td>
<td id="S9.T9.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.77</td>
<td id="S9.T9.5.3.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.5.3.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.5.3.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.5.3.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.22.13" class="ltx_tr">
<th id="S9.T9.11.22.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2018a</a>)</cite></th>
<td id="S9.T9.11.22.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.81</td>
<td id="S9.T9.11.22.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.54</td>
<td id="S9.T9.11.22.13.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.22.13.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.22.13.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.22.13.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.6.4" class="ltx_tr">
<th id="S9.T9.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib116" title="" class="ltx_ref">2018b</a>)</cite> <math id="S9.T9.6.4.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T9.6.4.1.m1.1a"><mo id="S9.T9.6.4.1.m1.1.1" xref="S9.T9.6.4.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T9.6.4.1.m1.1b"><ci id="S9.T9.6.4.1.m1.1.1.cmml" xref="S9.T9.6.4.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T9.6.4.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T9.6.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.89</td>
<td id="S9.T9.6.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.99</td>
<td id="S9.T9.6.4.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.6.4.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.6.4.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.6.4.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.23.14" class="ltx_tr">
<th id="S9.T9.11.23.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Yu
et al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2018</a>)</cite> ACJIS Model</th>
<td id="S9.T9.11.23.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.43</td>
<td id="S9.T9.11.23.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.57</td>
<td id="S9.T9.11.23.14.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.23.14.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.23.14.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.23.14.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.24.15" class="ltx_tr">
<th id="S9.T9.11.24.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Siddhant
et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2019</a>)</cite> ELMo</th>
<td id="S9.T9.11.24.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.62</td>
<td id="S9.T9.11.24.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.42</td>
<td id="S9.T9.11.24.15.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">87.35</td>
<td id="S9.T9.11.24.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.9</td>
<td id="S9.T9.11.24.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.29</td>
<td id="S9.T9.11.24.15.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.43</td>
</tr>
<tr id="S9.T9.7.5" class="ltx_tr">
<th id="S9.T9.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(E
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite> SF First (with CRF) *? <math id="S9.T9.7.5.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T9.7.5.1.m1.1a"><mo id="S9.T9.7.5.1.m1.1.1" xref="S9.T9.7.5.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T9.7.5.1.m1.1b"><ci id="S9.T9.7.5.1.m1.1.1.cmml" xref="S9.T9.7.5.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T9.7.5.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T9.7.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.8</td>
<td id="S9.T9.7.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.8</td>
<td id="S9.T9.7.5.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">86.8</td>
<td id="S9.T9.7.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.4</td>
<td id="S9.T9.7.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.4</td>
<td id="S9.T9.7.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.6</td>
</tr>
<tr id="S9.T9.8.6" class="ltx_tr">
<th id="S9.T9.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib135" title="" class="ltx_ref">2019a</a>)</cite> Capsule *? <math id="S9.T9.8.6.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T9.8.6.1.m1.1a"><mo id="S9.T9.8.6.1.m1.1.1" xref="S9.T9.8.6.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T9.8.6.1.m1.1b"><ci id="S9.T9.8.6.1.m1.1.1.cmml" xref="S9.T9.8.6.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T9.8.6.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T9.8.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.2</td>
<td id="S9.T9.8.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.0</td>
<td id="S9.T9.8.6.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">83.4</td>
<td id="S9.T9.8.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.8</td>
<td id="S9.T9.8.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.3</td>
<td id="S9.T9.8.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.9</td>
</tr>
<tr id="S9.T9.11.25.16" class="ltx_tr">
<th id="S9.T9.11.25.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2019a</a>)</cite> CNN 3L, 5 kern., label recur.</th>
<td id="S9.T9.11.25.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.95</td>
<td id="S9.T9.11.25.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.36</td>
<td id="S9.T9.11.25.16.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.25.16.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.22</td>
<td id="S9.T9.11.25.16.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.1</td>
<td id="S9.T9.11.25.16.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.26.17" class="ltx_tr">
<th id="S9.T9.11.26.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2019a</a>)</cite> LSTM 1L, label recur.</th>
<td id="S9.T9.11.26.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.37</td>
<td id="S9.T9.11.26.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.36</td>
<td id="S9.T9.11.26.17.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.26.17.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.83</td>
<td id="S9.T9.11.26.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.68</td>
<td id="S9.T9.11.26.17.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.27.18" class="ltx_tr">
<th id="S9.T9.11.27.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2019a</a>)</cite> CNN 3L, 5 kern., label recur.*</th>
<td id="S9.T9.11.27.18.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.27</td>
<td id="S9.T9.11.27.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.37</td>
<td id="S9.T9.11.27.18.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.27.18.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.3</td>
<td id="S9.T9.11.27.18.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.57</td>
<td id="S9.T9.11.27.18.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.28.19" class="ltx_tr">
<th id="S9.T9.11.28.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019a</a>)</cite></th>
<td id="S9.T9.11.28.19.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.54</td>
<td id="S9.T9.11.28.19.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.91</td>
<td id="S9.T9.11.28.19.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.28.19.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.94</td>
<td id="S9.T9.11.28.19.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.71</td>
<td id="S9.T9.11.28.19.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.29.20" class="ltx_tr">
<th id="S9.T9.11.29.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Zhang and Wang, <a href="#bib.bib138" title="" class="ltx_ref">2019</a>)</cite></th>
<td id="S9.T9.11.29.20.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.1</td>
<td id="S9.T9.11.29.20.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.2</td>
<td id="S9.T9.11.29.20.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.29.20.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.3</td>
<td id="S9.T9.11.29.20.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.9</td>
<td id="S9.T9.11.29.20.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.30.21" class="ltx_tr">
<th id="S9.T9.11.30.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Daha and
Hewavitharana, <a href="#bib.bib20" title="" class="ltx_ref">2019</a>)</cite> BiLSTM-CRF</th>
<td id="S9.T9.11.30.21.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.6</td>
<td id="S9.T9.11.30.21.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.6</td>
<td id="S9.T9.11.30.21.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">86.2</td>
<td id="S9.T9.11.30.21.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.6</td>
<td id="S9.T9.11.30.21.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.4</td>
<td id="S9.T9.11.30.21.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.2</td>
</tr>
<tr id="S9.T9.11.31.22" class="ltx_tr">
<th id="S9.T9.11.31.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019b</a>)</cite> CM-Net with GloVe</th>
<td id="S9.T9.11.31.22.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.2</td>
<td id="S9.T9.11.31.22.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.1</td>
<td id="S9.T9.11.31.22.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.31.22.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.15</td>
<td id="S9.T9.11.31.22.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.29</td>
<td id="S9.T9.11.31.22.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.32.23" class="ltx_tr">
<th id="S9.T9.11.32.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Liu
et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2019b</a>)</cite> CM-Net with BERT</th>
<td id="S9.T9.11.32.23.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.32.23.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.32.23.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.32.23.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.31</td>
<td id="S9.T9.11.32.23.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.32</td>
<td id="S9.T9.11.32.23.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.9.7" class="ltx_tr">
<th id="S9.T9.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2019</a>)</cite> Our Model <math id="S9.T9.9.7.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T9.9.7.1.m1.1a"><mo id="S9.T9.9.7.1.m1.1.1" xref="S9.T9.9.7.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T9.9.7.1.m1.1b"><ci id="S9.T9.9.7.1.m1.1.1.cmml" xref="S9.T9.9.7.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T9.9.7.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T9.9.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.9</td>
<td id="S9.T9.9.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.9</td>
<td id="S9.T9.9.7.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">86.5</td>
<td id="S9.T9.9.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.2</td>
<td id="S9.T9.9.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98</td>
<td id="S9.T9.9.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.9</td>
</tr>
<tr id="S9.T9.11.33.24" class="ltx_tr">
<th id="S9.T9.11.33.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2019</a>)</cite> Model+BERT</th>
<td id="S9.T9.11.33.24.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.1</td>
<td id="S9.T9.11.33.24.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.5</td>
<td id="S9.T9.11.33.24.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">88.6</td>
<td id="S9.T9.11.33.24.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97</td>
<td id="S9.T9.11.33.24.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99</td>
<td id="S9.T9.11.33.24.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.9</td>
</tr>
<tr id="S9.T9.11.34.25" class="ltx_tr">
<th id="S9.T9.11.34.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite> HCNN+CRF, word+char embed’s</th>
<td id="S9.T9.11.34.25.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.32</td>
<td id="S9.T9.11.34.25.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.09</td>
<td id="S9.T9.11.34.25.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.34.25.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.38</td>
<td id="S9.T9.11.34.25.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.24</td>
<td id="S9.T9.11.34.25.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.35.26" class="ltx_tr">
<th id="S9.T9.11.35.26.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Castellucci et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2019</a>)</cite></th>
<td id="S9.T9.11.35.26.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.7</td>
<td id="S9.T9.11.35.26.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.8</td>
<td id="S9.T9.11.35.26.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">88.2</td>
<td id="S9.T9.11.35.26.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.2</td>
<td id="S9.T9.11.35.26.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99</td>
<td id="S9.T9.11.35.26.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.6</td>
</tr>
<tr id="S9.T9.11.36.27" class="ltx_tr">
<th id="S9.T9.11.36.27.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib142" title="" class="ltx_ref">2019b</a>)</cite></th>
<td id="S9.T9.11.36.27.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.75</td>
<td id="S9.T9.11.36.27.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.76</td>
<td id="S9.T9.11.36.27.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.36.27.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.78</td>
<td id="S9.T9.11.36.27.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.98</td>
<td id="S9.T9.11.36.27.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.37.28" class="ltx_tr">
<th id="S9.T9.11.37.28.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Pentyala
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2019</a>)</cite> Base</th>
<td id="S9.T9.11.37.28.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.4</td>
<td id="S9.T9.11.37.28.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.1</td>
<td id="S9.T9.11.37.28.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.37.28.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.8</td>
<td id="S9.T9.11.37.28.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98</td>
<td id="S9.T9.11.37.28.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.38.29" class="ltx_tr">
<th id="S9.T9.11.38.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Pentyala
et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2019</a>)</cite> Base+BERT</th>
<td id="S9.T9.11.38.29.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.8</td>
<td id="S9.T9.11.38.29.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.6</td>
<td id="S9.T9.11.38.29.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.38.29.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.5</td>
<td id="S9.T9.11.38.29.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.6</td>
<td id="S9.T9.11.38.29.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.10.8" class="ltx_tr">
<th id="S9.T9.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019b</a>)</cite> BERT <math id="S9.T9.10.8.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T9.10.8.1.m1.1a"><mo id="S9.T9.10.8.1.m1.1.1" xref="S9.T9.10.8.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T9.10.8.1.m1.1b"><ci id="S9.T9.10.8.1.m1.1.1.cmml" xref="S9.T9.10.8.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T9.10.8.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T9.10.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.1</td>
<td id="S9.T9.10.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.5</td>
<td id="S9.T9.10.8.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">88.2</td>
<td id="S9.T9.10.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97</td>
<td id="S9.T9.10.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.6</td>
<td id="S9.T9.10.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.8</td>
</tr>
<tr id="S9.T9.11.9" class="ltx_tr">
<th id="S9.T9.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019b</a>)</cite> BERT+CRF <math id="S9.T9.11.9.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T9.11.9.1.m1.1a"><mo id="S9.T9.11.9.1.m1.1.1" xref="S9.T9.11.9.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T9.11.9.1.m1.1b"><ci id="S9.T9.11.9.1.m1.1.1.cmml" xref="S9.T9.11.9.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T9.11.9.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T9.11.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96</td>
<td id="S9.T9.11.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.9</td>
<td id="S9.T9.11.9.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">88.6</td>
<td id="S9.T9.11.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.7</td>
<td id="S9.T9.11.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.4</td>
<td id="S9.T9.11.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.6</td>
</tr>
<tr id="S9.T9.11.39.30" class="ltx_tr">
<th id="S9.T9.11.39.30.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Firdaus et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite> BLSTM+atten+Multi:DAC+ID+SF</th>
<td id="S9.T9.11.39.30.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.11</td>
<td id="S9.T9.11.39.30.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.06</td>
<td id="S9.T9.11.39.30.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.39.30.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.39.30.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.39.30.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.40.31" class="ltx_tr">
<th id="S9.T9.11.40.31.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib110" title="" class="ltx_ref">2020b</a>)</cite> SASGBC</th>
<td id="S9.T9.11.40.31.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.69</td>
<td id="S9.T9.11.40.31.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.21</td>
<td id="S9.T9.11.40.31.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">91.6</td>
<td id="S9.T9.11.40.31.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.43</td>
<td id="S9.T9.11.40.31.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.86</td>
<td id="S9.T9.11.40.31.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.57</td>
</tr>
<tr id="S9.T9.11.41.32" class="ltx_tr">
<th id="S9.T9.11.41.32.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2020a</a>)</cite> CMA-BLSTMS n-128</th>
<td id="S9.T9.11.41.32.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.89</td>
<td id="S9.T9.11.41.32.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.88</td>
<td id="S9.T9.11.41.32.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T9.11.41.32.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.41.32.6" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S9.T9.11.41.32.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T9.11.42.33" class="ltx_tr">
<th id="S9.T9.11.42.33.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Tang
et al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2020</a>)</cite> fully-E@EMG-CRF</th>
<td id="S9.T9.11.42.33.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">96.4</td>
<td id="S9.T9.11.42.33.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">99.0</td>
<td id="S9.T9.11.42.33.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t">89.6</td>
<td id="S9.T9.11.42.33.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">97.2</td>
<td id="S9.T9.11.42.33.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">99.7</td>
<td id="S9.T9.11.42.33.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">93.6</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S9.T10" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 10. </span>Natural language understanding (NLU) performance on ATIS and SNIPS-NLU data sets (%) using ATIS 10 epoch, SNIPS 20 epoch. <math id="S9.T10.2.m1.2" class="ltx_Math" alttext="\dagger\dagger" display="inline"><semantics id="S9.T10.2.m1.2b"><mrow id="S9.T10.2.m1.2.3.2" xref="S9.T10.2.m1.2.3.1.cmml"><mo id="S9.T10.2.m1.1.1" xref="S9.T10.2.m1.1.1.cmml">†</mo><mo lspace="0em" id="S9.T10.2.m1.2.3.2.1" xref="S9.T10.2.m1.2.3.1.cmml">⁣</mo><mo id="S9.T10.2.m1.2.2" xref="S9.T10.2.m1.2.2.cmml">†</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.T10.2.m1.2c"><list id="S9.T10.2.m1.2.3.1.cmml" xref="S9.T10.2.m1.2.3.2"><ci id="S9.T10.2.m1.1.1.cmml" xref="S9.T10.2.m1.1.1">†</ci><ci id="S9.T10.2.m1.2.2.cmml" xref="S9.T10.2.m1.2.2">†</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S9.T10.2.m1.2d">\dagger\dagger</annotation></semantics></math> reproduced by this paper</figcaption>
<table id="S9.T10.11" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S9.T10.11.10.1" class="ltx_tr">
<th id="S9.T10.11.10.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t" rowspan="2"><span id="S9.T10.11.10.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<td id="S9.T10.11.10.1.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" colspan="3"><span id="S9.T10.11.10.1.2.1" class="ltx_text ltx_font_bold">ATIS</span></td>
<td id="S9.T10.11.10.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S9.T10.11.10.1.3.1" class="ltx_text ltx_font_bold">SNIPS</span></td>
</tr>
<tr id="S9.T10.11.11.2" class="ltx_tr">
<td id="S9.T10.11.11.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T10.11.11.2.1.1" class="ltx_text ltx_font_bold">Slot f1</span></td>
<td id="S9.T10.11.11.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T10.11.11.2.2.1" class="ltx_text ltx_font_bold">Intent acc</span></td>
<td id="S9.T10.11.11.2.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S9.T10.11.11.2.3.1" class="ltx_text ltx_font_bold">Semantic acc</span></td>
<td id="S9.T10.11.11.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T10.11.11.2.4.1" class="ltx_text ltx_font_bold">Slot f1</span></td>
<td id="S9.T10.11.11.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T10.11.11.2.5.1" class="ltx_text ltx_font_bold">Intent acc</span></td>
<td id="S9.T10.11.11.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T10.11.11.2.6.1" class="ltx_text ltx_font_bold">Semantic acc</span></td>
</tr>
<tr id="S9.T10.11.12.3" class="ltx_tr">
<th id="S9.T10.11.12.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Hakkani-Tür et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite> in <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite>*</th>
<td id="S9.T10.11.12.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.3</td>
<td id="S9.T10.11.12.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.6</td>
<td id="S9.T10.11.12.3.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">80.7</td>
<td id="S9.T10.11.12.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.3</td>
<td id="S9.T10.11.12.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.9</td>
<td id="S9.T10.11.12.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73.2</td>
</tr>
<tr id="S9.T10.11.13.4" class="ltx_tr">
<th id="S9.T10.11.13.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>)</cite> in <cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite>*</th>
<td id="S9.T10.11.13.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.2</td>
<td id="S9.T10.11.13.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.1</td>
<td id="S9.T10.11.13.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">78.9</td>
<td id="S9.T10.11.13.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.8</td>
<td id="S9.T10.11.13.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.7</td>
<td id="S9.T10.11.13.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.1</td>
</tr>
<tr id="S9.T10.3.1" class="ltx_tr">
<th id="S9.T10.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite> Slot-Gated (Full Atten.)* <math id="S9.T10.3.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T10.3.1.1.m1.1a"><mo id="S9.T10.3.1.1.m1.1.1" xref="S9.T10.3.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T10.3.1.1.m1.1b"><ci id="S9.T10.3.1.1.m1.1.1.cmml" xref="S9.T10.3.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T10.3.1.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T10.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.8</td>
<td id="S9.T10.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.6</td>
<td id="S9.T10.3.1.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">82.2</td>
<td id="S9.T10.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.8</td>
<td id="S9.T10.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.0</td>
<td id="S9.T10.3.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.5</td>
</tr>
<tr id="S9.T10.4.2" class="ltx_tr">
<th id="S9.T10.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Goo
et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite> Slot-Gated (Intent Atten.)* <math id="S9.T10.4.2.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T10.4.2.1.m1.1a"><mo id="S9.T10.4.2.1.m1.1.1" xref="S9.T10.4.2.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T10.4.2.1.m1.1b"><ci id="S9.T10.4.2.1.m1.1.1.cmml" xref="S9.T10.4.2.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T10.4.2.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T10.4.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.2</td>
<td id="S9.T10.4.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.1</td>
<td id="S9.T10.4.2.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">82.6</td>
<td id="S9.T10.4.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.3</td>
<td id="S9.T10.4.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.8</td>
<td id="S9.T10.4.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.6</td>
</tr>
<tr id="S9.T10.5.3" class="ltx_tr">
<th id="S9.T10.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2018b</a>)</cite> <math id="S9.T10.5.3.1.m1.2" class="ltx_Math" alttext="\dagger\dagger" display="inline"><semantics id="S9.T10.5.3.1.m1.2a"><mrow id="S9.T10.5.3.1.m1.2.3.2" xref="S9.T10.5.3.1.m1.2.3.1.cmml"><mo id="S9.T10.5.3.1.m1.1.1" xref="S9.T10.5.3.1.m1.1.1.cmml">†</mo><mo lspace="0em" id="S9.T10.5.3.1.m1.2.3.2.1" xref="S9.T10.5.3.1.m1.2.3.1.cmml">⁣</mo><mo id="S9.T10.5.3.1.m1.2.2" xref="S9.T10.5.3.1.m1.2.2.cmml">†</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.T10.5.3.1.m1.2b"><list id="S9.T10.5.3.1.m1.2.3.1.cmml" xref="S9.T10.5.3.1.m1.2.3.2"><ci id="S9.T10.5.3.1.m1.1.1.cmml" xref="S9.T10.5.3.1.m1.1.1">†</ci><ci id="S9.T10.5.3.1.m1.2.2.cmml" xref="S9.T10.5.3.1.m1.2.2">†</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S9.T10.5.3.1.m1.2c">\dagger\dagger</annotation></semantics></math>
</th>
<td id="S9.T10.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.82</td>
<td id="S9.T10.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.00</td>
<td id="S9.T10.5.3.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">84.00</td>
<td id="S9.T10.5.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.93</td>
<td id="S9.T10.5.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.71</td>
<td id="S9.T10.5.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.43</td>
</tr>
<tr id="S9.T10.6.4" class="ltx_tr">
<th id="S9.T10.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib116" title="" class="ltx_ref">2018b</a>)</cite> <math id="S9.T10.6.4.1.m1.2" class="ltx_Math" alttext="\dagger\dagger" display="inline"><semantics id="S9.T10.6.4.1.m1.2a"><mrow id="S9.T10.6.4.1.m1.2.3.2" xref="S9.T10.6.4.1.m1.2.3.1.cmml"><mo id="S9.T10.6.4.1.m1.1.1" xref="S9.T10.6.4.1.m1.1.1.cmml">†</mo><mo lspace="0em" id="S9.T10.6.4.1.m1.2.3.2.1" xref="S9.T10.6.4.1.m1.2.3.1.cmml">⁣</mo><mo id="S9.T10.6.4.1.m1.2.2" xref="S9.T10.6.4.1.m1.2.2.cmml">†</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.T10.6.4.1.m1.2b"><list id="S9.T10.6.4.1.m1.2.3.1.cmml" xref="S9.T10.6.4.1.m1.2.3.2"><ci id="S9.T10.6.4.1.m1.1.1.cmml" xref="S9.T10.6.4.1.m1.1.1">†</ci><ci id="S9.T10.6.4.1.m1.2.2.cmml" xref="S9.T10.6.4.1.m1.2.2">†</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S9.T10.6.4.1.m1.2c">\dagger\dagger</annotation></semantics></math>
</th>
<td id="S9.T10.6.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.14</td>
<td id="S9.T10.6.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.08</td>
<td id="S9.T10.6.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">84.87</td>
<td id="S9.T10.6.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.46</td>
<td id="S9.T10.6.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.71</td>
<td id="S9.T10.6.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.39</td>
</tr>
<tr id="S9.T10.7.5" class="ltx_tr">
<th id="S9.T10.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(E
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite> SF First (with CRF) *? <math id="S9.T10.7.5.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T10.7.5.1.m1.1a"><mo id="S9.T10.7.5.1.m1.1.1" xref="S9.T10.7.5.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T10.7.5.1.m1.1b"><ci id="S9.T10.7.5.1.m1.1.1.cmml" xref="S9.T10.7.5.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T10.7.5.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T10.7.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.8</td>
<td id="S9.T10.7.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.8</td>
<td id="S9.T10.7.5.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">86.8</td>
<td id="S9.T10.7.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.4</td>
<td id="S9.T10.7.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.4</td>
<td id="S9.T10.7.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.6</td>
</tr>
<tr id="S9.T10.8.6" class="ltx_tr">
<th id="S9.T10.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib135" title="" class="ltx_ref">2019a</a>)</cite> Capsule *? <math id="S9.T10.8.6.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S9.T10.8.6.1.m1.1a"><mo id="S9.T10.8.6.1.m1.1.1" xref="S9.T10.8.6.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.T10.8.6.1.m1.1b"><ci id="S9.T10.8.6.1.m1.1.1.cmml" xref="S9.T10.8.6.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T10.8.6.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S9.T10.8.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.2</td>
<td id="S9.T10.8.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.0</td>
<td id="S9.T10.8.6.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">83.4</td>
<td id="S9.T10.8.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.8</td>
<td id="S9.T10.8.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.3</td>
<td id="S9.T10.8.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.9</td>
</tr>
<tr id="S9.T10.11.14.5" class="ltx_tr">
<th id="S9.T10.11.14.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2019a</a>)</cite> CNN 3L, 5 kern., label recur.*</th>
<td id="S9.T10.11.14.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.27</td>
<td id="S9.T10.11.14.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.37</td>
<td id="S9.T10.11.14.5.4" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S9.T10.11.14.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.3</td>
<td id="S9.T10.11.14.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.57</td>
<td id="S9.T10.11.14.5.7" class="ltx_td ltx_border_r ltx_border_t"></td>
</tr>
<tr id="S9.T10.9.7" class="ltx_tr">
<th id="S9.T10.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Qin
et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2019</a>)</cite> Our Model <math id="S9.T10.9.7.1.m1.2" class="ltx_Math" alttext="\dagger\dagger" display="inline"><semantics id="S9.T10.9.7.1.m1.2a"><mrow id="S9.T10.9.7.1.m1.2.3.2" xref="S9.T10.9.7.1.m1.2.3.1.cmml"><mo id="S9.T10.9.7.1.m1.1.1" xref="S9.T10.9.7.1.m1.1.1.cmml">†</mo><mo lspace="0em" id="S9.T10.9.7.1.m1.2.3.2.1" xref="S9.T10.9.7.1.m1.2.3.1.cmml">⁣</mo><mo id="S9.T10.9.7.1.m1.2.2" xref="S9.T10.9.7.1.m1.2.2.cmml">†</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.T10.9.7.1.m1.2b"><list id="S9.T10.9.7.1.m1.2.3.1.cmml" xref="S9.T10.9.7.1.m1.2.3.2"><ci id="S9.T10.9.7.1.m1.1.1.cmml" xref="S9.T10.9.7.1.m1.1.1">†</ci><ci id="S9.T10.9.7.1.m1.2.2.cmml" xref="S9.T10.9.7.1.m1.2.2">†</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S9.T10.9.7.1.m1.2c">\dagger\dagger</annotation></semantics></math>
</th>
<td id="S9.T10.9.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.15</td>
<td id="S9.T10.9.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.9</td>
<td id="S9.T10.9.7.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">80.4</td>
<td id="S9.T10.9.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">90.88</td>
<td id="S9.T10.9.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.14</td>
<td id="S9.T10.9.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">79.71</td>
</tr>
<tr id="S9.T10.10.8" class="ltx_tr">
<th id="S9.T10.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019b</a>)</cite> BERT <math id="S9.T10.10.8.1.m1.2" class="ltx_Math" alttext="\dagger\dagger" display="inline"><semantics id="S9.T10.10.8.1.m1.2a"><mrow id="S9.T10.10.8.1.m1.2.3.2" xref="S9.T10.10.8.1.m1.2.3.1.cmml"><mo id="S9.T10.10.8.1.m1.1.1" xref="S9.T10.10.8.1.m1.1.1.cmml">†</mo><mo lspace="0em" id="S9.T10.10.8.1.m1.2.3.2.1" xref="S9.T10.10.8.1.m1.2.3.1.cmml">⁣</mo><mo id="S9.T10.10.8.1.m1.2.2" xref="S9.T10.10.8.1.m1.2.2.cmml">†</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.T10.10.8.1.m1.2b"><list id="S9.T10.10.8.1.m1.2.3.1.cmml" xref="S9.T10.10.8.1.m1.2.3.2"><ci id="S9.T10.10.8.1.m1.1.1.cmml" xref="S9.T10.10.8.1.m1.1.1">†</ci><ci id="S9.T10.10.8.1.m1.2.2.cmml" xref="S9.T10.10.8.1.m1.2.2">†</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S9.T10.10.8.1.m1.2c">\dagger\dagger</annotation></semantics></math>
</th>
<td id="S9.T10.10.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.54</td>
<td id="S9.T10.10.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.54</td>
<td id="S9.T10.10.8.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">87.35</td>
<td id="S9.T10.10.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T10.10.8.5.1" class="ltx_text ltx_font_bold">96.91</span></td>
<td id="S9.T10.10.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.43</td>
<td id="S9.T10.10.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T10.10.8.7.1" class="ltx_text ltx_font_bold">92.43</span></td>
</tr>
<tr id="S9.T10.11.9" class="ltx_tr">
<th id="S9.T10.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019b</a>)</cite> BERT+CRF <math id="S9.T10.11.9.1.m1.2" class="ltx_Math" alttext="\dagger\dagger" display="inline"><semantics id="S9.T10.11.9.1.m1.2a"><mrow id="S9.T10.11.9.1.m1.2.3.2" xref="S9.T10.11.9.1.m1.2.3.1.cmml"><mo id="S9.T10.11.9.1.m1.1.1" xref="S9.T10.11.9.1.m1.1.1.cmml">†</mo><mo lspace="0em" id="S9.T10.11.9.1.m1.2.3.2.1" xref="S9.T10.11.9.1.m1.2.3.1.cmml">⁣</mo><mo id="S9.T10.11.9.1.m1.2.2" xref="S9.T10.11.9.1.m1.2.2.cmml">†</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.T10.11.9.1.m1.2b"><list id="S9.T10.11.9.1.m1.2.3.1.cmml" xref="S9.T10.11.9.1.m1.2.3.2"><ci id="S9.T10.11.9.1.m1.1.1.cmml" xref="S9.T10.11.9.1.m1.1.1">†</ci><ci id="S9.T10.11.9.1.m1.2.2.cmml" xref="S9.T10.11.9.1.m1.2.2">†</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S9.T10.11.9.1.m1.2c">\dagger\dagger</annotation></semantics></math>
</th>
<td id="S9.T10.11.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S9.T10.11.9.2.1" class="ltx_text ltx_font_bold">96.03</span></td>
<td id="S9.T10.11.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S9.T10.11.9.3.1" class="ltx_text ltx_font_bold">97.76</span></td>
<td id="S9.T10.11.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t"><span id="S9.T10.11.9.4.1" class="ltx_text ltx_font_bold">88.47</span></td>
<td id="S9.T10.11.9.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">96.60</td>
<td id="S9.T10.11.9.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S9.T10.11.9.6.1" class="ltx_text ltx_font_bold">98.57</span></td>
<td id="S9.T10.11.9.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">92.14</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S9.T11" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 11. </span>Slot F1 Scores of slot filling models on ATIS</figcaption>
<table id="S9.T11.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S9.T11.2.3.1" class="ltx_tr">
<th id="S9.T11.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S9.T11.2.3.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S9.T11.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S9.T11.2.3.1.2.1" class="ltx_text ltx_font_bold">ATIS</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S9.T11.2.4.1" class="ltx_tr">
<td id="S9.T11.2.4.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Deng
et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2012</a>)</cite> Log-linear K-DCN</td>
<td id="S9.T11.2.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.88</td>
</tr>
<tr id="S9.T11.2.5.2" class="ltx_tr">
<td id="S9.T11.2.5.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Deoras and
Sarikaya, <a href="#bib.bib24" title="" class="ltx_ref">2013</a>)</cite> DBN + Sntc</td>
<td id="S9.T11.2.5.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.00</td>
</tr>
<tr id="S9.T11.2.6.3" class="ltx_tr">
<td id="S9.T11.2.6.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Mesnil
et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2013</a>)</cite> Bi-directional Jordan-RNN</td>
<td id="S9.T11.2.6.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.98</td>
</tr>
<tr id="S9.T11.2.7.4" class="ltx_tr">
<td id="S9.T11.2.7.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Yao
et al<span class="ltx_text">.</span>, <a href="#bib.bib129" title="" class="ltx_ref">2013</a>)</cite> RNN + Lex + NE</td>
<td id="S9.T11.2.7.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.60</td>
</tr>
<tr id="S9.T11.2.8.5" class="ltx_tr">
<td id="S9.T11.2.8.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib128" title="" class="ltx_ref">2014b</a>)</cite> R-CRF Model 2</td>
<td id="S9.T11.2.8.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.65</td>
</tr>
<tr id="S9.T11.2.9.6" class="ltx_tr">
<td id="S9.T11.2.9.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Yao et al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2014a</a>)</cite> Deep LSTM</td>
<td id="S9.T11.2.9.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.08</td>
</tr>
<tr id="S9.T11.1.1" class="ltx_tr">
<td id="S9.T11.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib58" title="" class="ltx_ref">2015</a>)</cite> RNN trained with sampled label linearly decreasing <math id="S9.T11.1.1.1.m1.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S9.T11.1.1.1.m1.1a"><msub id="S9.T11.1.1.1.m1.1.1" xref="S9.T11.1.1.1.m1.1.1.cmml"><mi id="S9.T11.1.1.1.m1.1.1.2" xref="S9.T11.1.1.1.m1.1.1.2.cmml">P</mi><mi id="S9.T11.1.1.1.m1.1.1.3" xref="S9.T11.1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S9.T11.1.1.1.m1.1b"><apply id="S9.T11.1.1.1.m1.1.1.cmml" xref="S9.T11.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S9.T11.1.1.1.m1.1.1.1.cmml" xref="S9.T11.1.1.1.m1.1.1">subscript</csymbol><ci id="S9.T11.1.1.1.m1.1.1.2.cmml" xref="S9.T11.1.1.1.m1.1.1.2">𝑃</ci><ci id="S9.T11.1.1.1.m1.1.1.3.cmml" xref="S9.T11.1.1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.T11.1.1.1.m1.1c">P_{i}</annotation></semantics></math>
</td>
<td id="S9.T11.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.87</td>
</tr>
<tr id="S9.T11.2.10.7" class="ltx_tr">
<td id="S9.T11.2.10.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Mesnil et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2015</a>)</cite> Hybrid</td>
<td id="S9.T11.2.10.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.06</td>
</tr>
<tr id="S9.T11.2.11.8" class="ltx_tr">
<td id="S9.T11.2.11.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Peng and Yao, <a href="#bib.bib76" title="" class="ltx_ref">2015</a>)</cite> RNN-EM</td>
<td id="S9.T11.2.11.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.25</td>
</tr>
<tr id="S9.T11.2.12.9" class="ltx_tr">
<td id="S9.T11.2.12.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Liu and Lane, <a href="#bib.bib59" title="" class="ltx_ref">2016a</a>)</cite> Attention Encoder-Decoder NN (with aligned inputs)</td>
<td id="S9.T11.2.12.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.78</td>
</tr>
<tr id="S9.T11.2.13.10" class="ltx_tr">
<td id="S9.T11.2.13.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Kurata
et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2016</a>)</cite> Encoder-labeler Deep LSTM (W)</td>
<td id="S9.T11.2.13.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.47</td>
</tr>
<tr id="S9.T11.2.14.11" class="ltx_tr">
<td id="S9.T11.2.14.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Vu
et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2016</a>)</cite> 5xR-biRNN</td>
<td id="S9.T11.2.14.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.56</td>
</tr>
<tr id="S9.T11.2.15.12" class="ltx_tr">
<td id="S9.T11.2.15.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Vu, <a href="#bib.bib108" title="" class="ltx_ref">2016</a>)</cite> R-bi-sCNN</td>
<td id="S9.T11.2.15.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.61</td>
</tr>
<tr id="S9.T11.2.16.13" class="ltx_tr">
<td id="S9.T11.2.16.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Zhu and Yu, <a href="#bib.bib147" title="" class="ltx_ref">2017</a>)</cite> BLSTM-LSTM (Focus)</td>
<td id="S9.T11.2.16.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.79</td>
</tr>
<tr id="S9.T11.2.17.14" class="ltx_tr">
<td id="S9.T11.2.17.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2019</a>)</cite> DCMTL</td>
<td id="S9.T11.2.17.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.83</td>
</tr>
<tr id="S9.T11.2.18.15" class="ltx_tr">
<td id="S9.T11.2.18.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Louvan and
Magnini, <a href="#bib.bib64" title="" class="ltx_ref">2018</a>)</cite> MTL, different supervision level</td>
<td id="S9.T11.2.18.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.94</td>
</tr>
<tr id="S9.T11.2.2" class="ltx_tr">
<td id="S9.T11.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018a</a>)</cite> DRL based Augmented Tagging System (<math id="S9.T11.2.2.1.m1.1" class="ltx_Math" alttext="\gamma=0.9" display="inline"><semantics id="S9.T11.2.2.1.m1.1a"><mrow id="S9.T11.2.2.1.m1.1.1" xref="S9.T11.2.2.1.m1.1.1.cmml"><mi id="S9.T11.2.2.1.m1.1.1.2" xref="S9.T11.2.2.1.m1.1.1.2.cmml">γ</mi><mo id="S9.T11.2.2.1.m1.1.1.1" xref="S9.T11.2.2.1.m1.1.1.1.cmml">=</mo><mn id="S9.T11.2.2.1.m1.1.1.3" xref="S9.T11.2.2.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S9.T11.2.2.1.m1.1b"><apply id="S9.T11.2.2.1.m1.1.1.cmml" xref="S9.T11.2.2.1.m1.1.1"><eq id="S9.T11.2.2.1.m1.1.1.1.cmml" xref="S9.T11.2.2.1.m1.1.1.1"></eq><ci id="S9.T11.2.2.1.m1.1.1.2.cmml" xref="S9.T11.2.2.1.m1.1.1.2">𝛾</ci><cn type="float" id="S9.T11.2.2.1.m1.1.1.3.cmml" xref="S9.T11.2.2.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.T11.2.2.1.m1.1c">\gamma=0.9</annotation></semantics></math>)</td>
<td id="S9.T11.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.86</td>
</tr>
<tr id="S9.T11.2.19.16" class="ltx_tr">
<td id="S9.T11.2.19.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Shen
et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2019b</a>)</cite> c-ProgModel</td>
<td id="S9.T11.2.19.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.91</td>
</tr>
<tr id="S9.T11.2.20.17" class="ltx_tr">
<td id="S9.T11.2.20.17.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib141" title="" class="ltx_ref">2020a</a>)</cite> SC-TDNN-C</td>
<td id="S9.T11.2.20.17.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">95.73</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S10" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10. </span>Critical Discussion and Conclusions</h2>

<div id="S10.p1" class="ltx_para">
<p id="S10.p1.1" class="ltx_p">Section <a href="#S1" title="1. Introduction ‣ A survey of joint intent detection and slot-filling models in natural language understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presented the following three questions concerning joint intent detection and slot filling:</p>
</div>
<div id="S10.p2" class="ltx_para">
<ul id="S10.I1" class="ltx_itemize">
<li id="S10.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S10.I1.i1.p1" class="ltx_para">
<p id="S10.I1.i1.p1.1" class="ltx_p">Q1: How do these joint models achieve and balance two aspects, intent classification and slot filling?</p>
</div>
</li>
<li id="S10.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S10.I1.i2.p1" class="ltx_para">
<p id="S10.I1.i2.p1.1" class="ltx_p">Q2: Have syntactic clues/features been fully exploited or does semantics override this consideration?</p>
</div>
</li>
<li id="S10.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S10.I1.i3.p1" class="ltx_para">
<p id="S10.I1.i3.p1.1" class="ltx_p">Q3: Can successful models in one supervised domain be made more generalisable to new domains or languages or unseen data?</p>
</div>
</li>
</ul>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Béchet and
Raymond (2018)</span>
<span class="ltx_bibblock">
Frédéric Béchet and
Christian Raymond. 2018.

</span>
<span class="ltx_bibblock">Is ATIS too shallow to go deeper for benchmarking
Spoken Language Understanding models?. In
<em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">InterSpeech 2018</em>. ISCA,
Hyderabad, India, 1–5.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://hal.inria.fr/hal-01835425" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://hal.inria.fr/hal-01835425</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bellomaria et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Valentina Bellomaria,
Giuseppe Castellucci, Andrea Favalli,
and Raniero Romagnoli. 2019.

</span>
<span class="ltx_bibblock">Almawave-SLU: A new dataset for SLU in Italian.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1907.07526

<a target="_blank" href="http://arxiv.org/abs/1907.07526" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1907.07526</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhargava et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Aditya Bhargava, Asli
Celikyilmaz, Dilek Hakkani-T”̈ur, and
Ruhi Sarikaya. 2013.

</span>
<span class="ltx_bibblock">Easy contextual intent prediction and slot
detection. In <em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">2013 IEEE International Conference
on Acoustics, Speech and Signal Processing</em>. IEEE,
IEEE, Vancouver, Canada,
8337–8341.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhasin et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Anmol Bhasin, Bharatram
Natarajan, Gaurav Mathur, Joo Hyuk Jeon,
and Jun-Seong Kim. 2019.

</span>
<span class="ltx_bibblock">Unified Parallel Intent and Slot Prediction with
Cross Fusion and Slot Masking. In <em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Natural Language
Processing and Information Systems</em>,
Elisabeth Métais,
Farid Meziane, Sunil Vadera,
Vijayan Sugumaran, and Mohamad Saraee
(Eds.). Springer International Publishing,
Cham, 277–285.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhasin et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Anmol Bhasin, Bharatram
Natarajan, Gaurav Mathur, and
Himanshu Mangla. 2020.

</span>
<span class="ltx_bibblock">Parallel Intent and Slot Prediction using MLB
Fusion. In <em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">2020 IEEE 14th International Conference
on Semantic Computing (ICSC)</em>. IEEE,
San Diego, USA, 217–220.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhathiya and
Thayasivam (2020)</span>
<span class="ltx_bibblock">
Hemanthage S. Bhathiya and
Uthayasanker Thayasivam. 2020.

</span>
<span class="ltx_bibblock">Meta Learning for Few-Shot Joint Intent Detection
and Slot-Filling. In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 5th
International Conference on Machine Learning Technologies</em> (Beijing, China)
<em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">(ICMLT 2020)</em>. Association for
Computing Machinery, New York, NY, USA,
86–92.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3409073.3409090" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3409073.3409090</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bordes et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Antoine Bordes, Nicolas
Usunier, Alberto Garcia-Duran, Jason
Weston, and Oksana Yakhnenko.
2013.

</span>
<span class="ltx_bibblock">Translating Embeddings for Modeling
Multi-relational Data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems 26</em>, C. J. C. Burges,
L. Bottou, M. Welling,
Z. Ghahramani, and K. Q. Weinberger
(Eds.). Curran Associates, Inc., Lake
Tahoe, USA, 2787–2795.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Castellucci et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Giuseppe Castellucci,
Valentina Bellomaria, Andrea Favalli,
and Raniero Romagnoli. 2019.

</span>
<span class="ltx_bibblock">Multi-lingual Intent Detection and Slot Filling in a
Joint BERT-based Model.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1907.02884

<a target="_blank" href="http://arxiv.org/abs/1907.02884" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1907.02884</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Celikyilmaz and
Hakkani-Tur (2012)</span>
<span class="ltx_bibblock">
Asli Celikyilmaz and
Dilek Hakkani-Tur. 2012.

</span>
<span class="ltx_bibblock">A Joint Model for Discovery of Aspects in
Utterances. In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 50th Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers)</em>. Association for Computational Linguistics,
Jeju Island, Korea, 330–338.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.aclweb.org/anthology/P12-1035" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P12-1035</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Long Chen, Dell Zhang,
and Levene Mark. 2012.

</span>
<span class="ltx_bibblock">Understanding user intent in community question
answering. In <em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 21st
International Conference Companion on World Wide Web - WWW
'12 Companion</em>. ACM Press,
Lyon, France, 823–828.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/2187980.2188206" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2187980.2188206</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Mengyang Chen, Jin Zeng,
and Jie Lou. 2019a.

</span>
<span class="ltx_bibblock">A Self-Attention Joint Model for Spoken Language
Understanding in Situational Dialog Applications.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1905.11393

<a target="_blank" href="http://arxiv.org/abs/1905.11393" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1905.11393</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Qian Chen, Zhu Zhuo,
and Wen Wang. 2019b.

</span>
<span class="ltx_bibblock">BERT for Joint Intent Classification and Slot
Filling.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1902.10909

<a target="_blank" href="http://arxiv.org/abs/1902.10909" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1902.10909</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Yu (2019)</span>
<span class="ltx_bibblock">
Sixuan Chen and Shuai
Yu. 2019.

</span>
<span class="ltx_bibblock">WAIS: Word Attention for Joint Intent Detection and
Slot Filling. In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI
Conference on Artificial Intelligence</em>, Vol. 33.
AAAI Press, Honolulu, USA,
9927–9928.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1609/aaai.v33i01.33019927" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1609/aaai.v33i01.33019927</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Yun-Nung Chen, Dilek
Hakanni-Tür, Gokhan Tur, Asli
Celikyilmaz, Jianfeng Guo, and Li
Deng. 2016.

</span>
<span class="ltx_bibblock">Syntax or semantics? Knowledge-guided joint
semantic frame parsing. In <em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">2016 IEEE Spoken
Language Technology Workshop (SLT)</em>. IEEE,
San Diego, USA, 348–355.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohan
et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Arman Cohan, Waleed
Ammar, Madeleine van Zuylen, and Field
Cady. 2019.

</span>
<span class="ltx_bibblock">Structural Scaffolds for Citation Intent
Classification in Scientific Publications. In
<em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies, Volume 1 (Long and Short Papers)</em>.
Association for Computational Linguistics,
Minneapolis, Minnesota, 3586–3596.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/N19-1361" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/N19-1361</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Costello et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Charles Costello, Ruixi
Lin, Vishwas Mruthyunjaya, Bettina
Bolla, and Charles Jankowski.
2018.

</span>
<span class="ltx_bibblock">Multi-Layer Ensembling Techniques for Multilingual
Intent Classification.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1806.07914 [cs.CL]

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Coucke
et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Alice Coucke, Alaa Saade,
Adrien Ball, Théodore Bluche,
Alexandre Caulier, David Leroy,
Clément Doumouro, Thibault
Gisselbrecht, Francesco Caltagirone,
Thibaut Lavril, Maël Primet, and
Joseph Dureau. 2018.

</span>
<span class="ltx_bibblock">Snips Voice Platform: an embedded Spoken Language
Understanding system for private-by-design voice interfaces.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1805.10190

<a target="_blank" href="http://arxiv.org/abs/1805.10190" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1805.10190</a>

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dadas
et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Slawomir Dadas, Jaroslaw
Protasiewicz, and Witold Pedrycz.
2019.

</span>
<span class="ltx_bibblock">A Deep Learning Model with Data Enrichment for
Intent Detection and Slot Filling. In <em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">2019 IEEE
International Conference on Systems, Man and Cybernetics, October 6-9,
2019</em>. IEEE, Bari, Italy,
3012–3018.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/SMC.2019.8914542" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/SMC.2019.8914542</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Daha and
Hewavitharana (2019)</span>
<span class="ltx_bibblock">
Fatima Daha and
Saniika Hewavitharana. 2019.

</span>
<span class="ltx_bibblock">Deep Neural Architecture with Character Embedding
for Semantic Frame Detection. In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">2019 IEEE 13th
International Conference on Semantic Computing (ICSC)</em>.
IEEE, Newport Beach, USA,
302–307.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dahl et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (1994)</span>
<span class="ltx_bibblock">
Deborah A. Dahl, Madeleine
Bates, Michael Brown, William Fisher,
Kate Hunicke-Smith, David Pallett,
Christine Pao, Alexander Rudnicky, and
Elizabeth Shriberg. 1994.

</span>
<span class="ltx_bibblock">Expanding the Scope of the ATIS Task: The
ATIS-3 Corpus. In <em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Human Language
Technology: Proceedings of a Workshop held at Plainsboro, New Jersey,
March 8-11, 1994</em>. Association for Computational
Linguistics, Plainsboro, USA, 43–48.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.aclweb.org/anthology/H94-1010" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/H94-1010</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Yinpei Dai, Yichi
Zhang, Zhijian Ou, Yanmeng Wang,
and Junlan Feng. 2018.

</span>
<span class="ltx_bibblock">Elastic CRFs for Open-ontology Slot Filling.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1811.01331

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng
et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Li Deng, Gokhan Tur,
Xiaodong He, and Dilek Hakkani-Tür.
2012.

</span>
<span class="ltx_bibblock">Use of kernel deep convex networks and end-to-end
learning for spoken language understanding. In
<em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">2012 IEEE Spoken Language Technology Workshop
(SLT)</em>. IEEE, Miami, USA,
210–215.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deoras and
Sarikaya (2013)</span>
<span class="ltx_bibblock">
Anoop Deoras and Ruhi
Sarikaya. 2013.

</span>
<span class="ltx_bibblock">Deep Belief Network based Semantic Taggers for
Spoken Language Understanding. In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>.
ISCA, Lyon, France,
2713–2717.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deriu et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jan Deriu, Alvaro
Rodrigo, Arantxa Otegi, Guillermo
Echegoyen, Sophie Rosset, Eneko Agirre,
and Mark Cieliebak. 2020.

</span>
<span class="ltx_bibblock">Survey on evaluation methods for dialogue systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">Artificial Intelligence Review</em>
53 (2020).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/s10462-020-09866-x" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s10462-020-09866-x</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">E
et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Haihong E, Peiqing Niu,
Zhongfu Chen, and Meina Song.
2019.

</span>
<span class="ltx_bibblock">A Novel Bi-directional Interrelated Model for Joint
Intent Detection and Slot Filling. In <em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">Proceedings
of the 57th Annual Meeting of the Association for Computational
Linguistics</em>. Association for Computational
Linguistics, Florence, Italy,
5467–5471.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/P19-1544" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P19-1544</a>

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Firdaus et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2018a)</span>
<span class="ltx_bibblock">
Mauajama Firdaus, Shobhit
Bhatnagar, Asif Ekbal, and Pushpak
Bhattacharyya. 2018a.

</span>
<span class="ltx_bibblock">A Deep Learning Based Multi-task Ensemble Model for
Intent Detection and Slot Filling in Spoken Language Understanding. In
<em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">Neural Information Processing</em>,
Long Cheng, Andrew
Chi Sing Leung, and Seiichi Ozawa (Eds.).
Springer International Publishing,
Cham, 647–658.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Firdaus et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2018b)</span>
<span class="ltx_bibblock">
Mauajama Firdaus, Shobhit
Bhatnagar, Asif Ekbal, and Pushpak
Bhattacharyya. 2018b.

</span>
<span class="ltx_bibblock">Intent Detection for Spoken Language Understanding
Using a Deep Ensemble Model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">Lecture Notes in Computer Science</em>.
Springer International Publishing,
Cham, 629–642.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/978-3-319-97304-3_48" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-319-97304-3_48</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Firdaus et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mauajama Firdaus, Hitesh
Golchha, Asif Ekbal, and Pushpak
Bhattacharyya. 2020.

</span>
<span class="ltx_bibblock">A Deep Multi-task Model for Dialogue Act
Classification, Intent Detection and Slot Filling.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">Cognitive Computation</em> 12
(2020).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/s12559-020-09718-4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s12559-020-09718-4</a>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Firdaus et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Mauajama Firdaus, Ankit
Kumar, Asif Ekbal, and Pushpak
Bhattacharyya. 2019.

</span>
<span class="ltx_bibblock">A Multi-Task Hierarchical Approach for Intent
Detection and Slot Filling.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">Knowledge-Based Systems</em>
183 (2019), 104846.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.knosys.2019.07.017" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.knosys.2019.07.017</a>

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gangadharaiah
and Narayanaswamy (2019)</span>
<span class="ltx_bibblock">
Rashmi Gangadharaiah and
Balakrishnan Narayanaswamy.
2019.

</span>
<span class="ltx_bibblock">Joint Multiple Intent Detection and Slot Labeling
for Goal-Oriented Dialog. In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
2019 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, Volume 1 (Long and
Short Papers)</em>. Association for Computational
Linguistics, Minneapolis, Minnesota,
564–569.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/N19-1055" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/N19-1055</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Yu Gong, Xusheng Luo,
Yu Zhu, Wenwu Ou, Zhao
Li, Muhua Zhu, Kenny Q. Zhu,
Lu Duan, and Xi Chen.
2019.

</span>
<span class="ltx_bibblock">Deep Cascade Multi-task Learning for Slot Filling
in Online Shopping Assistant. In <em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the AAAI Conference on Artificial Intelligence</em>, Vol. 33.
AAAI Press, Honolulu, USA,
6465–6472.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1609/aaai.v33i01.33016465" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1609/aaai.v33i01.33016465</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">González-Caro and Baeza-Yates (2011)</span>
<span class="ltx_bibblock">
Cristina González-Caro and
Ricardo Baeza-Yates. 2011.

</span>
<span class="ltx_bibblock">A Multi-faceted Approach to Query Intent
Classification. In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">String Processing and
Information Retrieval</em>, Roberto Grossi,
Fabrizio Sebastiani, and Fabrizio
Silvestri (Eds.). Springer Berlin Heidelberg,
Berlin, Heidelberg, 368–379.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goo
et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Chih-Wen Goo, Guang Gao,
Yun-Kai Hsu, Chih-Li Huo,
Tsung-Chieh Chen, Keng-Wei Hsu, and
Yun-Nung Chen. 2018.

</span>
<span class="ltx_bibblock">Slot-gated modeling for joint slot filling and
intent prediction. In <em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018
Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, Volume 2 (Short Papers)</em>.
Association for Computational Linguistics,
New Orleans, USA, 753–757.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo
et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Daniel Guo, Gokhan Tur,
Wen-tau Yih, and Geoffrey Zweig.
2014.

</span>
<span class="ltx_bibblock">Joint semantic utterance classification and slot
filling with recursive neural networks. In <em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">2014
IEEE Spoken Language Technology Workshop (SLT)</em>. IEEE,
IEEE, South Lake Tahoe, USA,
554–559.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta
et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Arshit Gupta, John
Hewitt, and Katrin Kirchhoff.
2019a.

</span>
<span class="ltx_bibblock">Simple, Fast, Accurate Intent Classification and
Slot Labeling for Goal-Oriented Dialogue Systems. In
<em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th Annual SIGdial Meeting on
Discourse and Dialogue</em>. Association for Computational
Linguistics, Stockholm, Sweden, 46–55.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/W19-5906" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/W19-5906</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta
et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Arshit Gupta, Peng Zhang,
Garima Lalwani, and Mona Diab.
2019b.

</span>
<span class="ltx_bibblock">CASA-NLU: Context-Aware Self-Attentive Natural
Language Understanding for Task-Oriented Chatbots. In
<em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-IJCNLP)</em>.
Association for Computational Linguistics,
Hong Kong, China, 1285–1290.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/D19-1127" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D19-1127</a>

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hakkani-Tür et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Dilek Hakkani-Tür,
Gökhan Tür, Asli Celikyilmaz,
Yun-Nung Chen, Jianfeng Gao,
Li Deng, and Ye-Yi Wang.
2016.

</span>
<span class="ltx_bibblock">Multi-domain joint semantic frame parsing using
bi-directional RNN-LSTM. In <em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Interspeech</em>.
ISCA, San Francisco, USA,
715–719.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hasanuzzaman et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Mohammed Hasanuzzaman,
Sriparna Saha, Gaël Dias, and
Stéphane Ferrari. 2015.

</span>
<span class="ltx_bibblock">Understanding Temporal Query Intent. In
<em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 38th International ACM SIGIR
Conference on Research and Development in Information Retrieval - SIGIR
'15</em>. ACM Press,
Santiago, Chile, 823–826.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/2766462.2767792" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2766462.2767792</a>

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hashemi
et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Homa B Hashemi, Amir
Asiaee, and Reiner Kraft.
2016.

</span>
<span class="ltx_bibblock">Query intent detection using convolutional neural
networks. In <em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">International Conference on Web
Search and Data Mining, Workshop on Query Understanding</em>.
Association for Computational Linguistics,
San Francisco, USA.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hemphill
et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (1990)</span>
<span class="ltx_bibblock">
Charles T. Hemphill,
John J. Godfrey, and George R.
Doddington. 1990.

</span>
<span class="ltx_bibblock">The ATIS Spoken Language Systems Pilot Corpus. In
<em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Workshop on Speech and Natural
Language</em> <em id="bib.bib41.4.2" class="ltx_emph ltx_font_italic">(HLT ’90)</em>.
Association for Computational Linguistics,
Hidden Valley, Pennsylvania, USA,
96–101.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.3115/116580.116613" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.3115/116580.116613</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hirschman (1992)</span>
<span class="ltx_bibblock">
Lynette Hirschman.
1992.

</span>
<span class="ltx_bibblock">Multi-Site Data Collection for a Spoken Language
Corpus - MAD COW. In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Second International
Conference on Spoken Language Processing (ICSLP’92)</em>.
International Speech Communication Association,
Banff, Canada, 903–906.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou
et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Lixian Hou, Yanling Li,
Chengcheng Li, and Min Lin.
2019.

</span>
<span class="ltx_bibblock">Review of Research on Task-Oriented Spoken Language
Understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">Journal of Physics: Conference Series</em>
1267 (Jul 2019),
012023.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1088/1742-6596/1267/1/012023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1088/1742-6596/1267/1/012023</a>

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeong and Lee (2008)</span>
<span class="ltx_bibblock">
Minwoo Jeong and
Gary Geunbae Lee. 2008.

</span>
<span class="ltx_bibblock">Triangular-Chain Conditional Random Fields.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Audio, Speech, and
Language Processing</em> 16, 7
(2008), 1287–1302.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jung
et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Sangkeun Jung, Jinsik
Lee, and Jiwon Kim. 2018.

</span>
<span class="ltx_bibblock">Learning to Embed Semantic Correspondence for
Natural Language Understanding. In <em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 22nd Conference on Computational Natural Language Learning</em>.
Association for Computational Linguistics,
Brussels, Belgium, 131–140.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/K18-1013" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/K18-1013</a>

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kanhabua
et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Nattiya Kanhabua, Tu
Ngoc Nguyen, and Wolfgang Nejdl.
2015.

</span>
<span class="ltx_bibblock">Learning to Detect Event-Related Queries for Web
Search. In <em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 24th International
Conference on World Wide Web</em> (Florence, Italy) <em id="bib.bib46.4.2" class="ltx_emph ltx_font_italic">(WWW
’15 Companion)</em>. Association for Computing Machinery,
New York, NY, USA, 1339–1344.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2740908.2741698" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2740908.2741698</a>

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim and Kim (2018)</span>
<span class="ltx_bibblock">
Joo-Kyung Kim and
Young-Bum Kim. 2018.

</span>
<span class="ltx_bibblock">Joint Learning of Domain Classification and
Out-of-Domain Detection with Dynamic Class Weighting for Satisficing False
Acceptance Rates. In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2018</em>.
ISCA, Hyderabad, India,
556–560.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.21437/Interspeech.2018-1581" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2018-1581</a>

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim
et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Kunho Kim, Rahul Jha,
Kyle Williams, Alex Marin, and
Imed Zitouni. 2019.

</span>
<span class="ltx_bibblock">Slot Tagging for Task Oriented Spoken Language
Understanding in Human-to-Human Conversation Scenarios. In
<em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 23rd Conference on Computational
Natural Language Learning (CoNLL)</em>. Association for
Computational Linguistics, Hong Kong, China,
757–767.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/K19-1071" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/K19-1071</a>

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim
et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Young-Bum Kim, Sungjin
Lee, and Karl Stratos.
2017.

</span>
<span class="ltx_bibblock">ONENET: Joint domain, intent, slot prediction for
spoken language understanding. In <em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">2017 IEEE
Automatic Speech Recognition and Understanding Workshop (ASRU)</em>.
IEEE, Okinawa, Japan,
547–553.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Korpusik
et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Mandy Korpusik, Zoe Liu,
and James Glass. 2019.

</span>
<span class="ltx_bibblock">A Comparison of Deep Learning Methods for Language
Understanding. In <em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2019</em>.
ISCA, Graz, Austria,
849–853.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.21437/Interspeech.2019-1262" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2019-1262</a>

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krone
et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jason Krone, Yi Zhang,
and Mona Diab. 2020.

</span>
<span class="ltx_bibblock">Learning to Classify Intents and Slot Labels Given a
Handful of Examples.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2004.10793 [cs.CL]

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kurata
et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Gakuto Kurata, Bing
Xiang, Bowen Zhou, and Mo Yu.
2016.

</span>
<span class="ltx_bibblock">Leveraging Sentence-level Information with Encoder
LSTM for Semantic Slot Filling. In <em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2016 Conference on Empirical Methods in Natural Language Processing</em>.
Association for Computational Linguistics,
Austin, Texas, 2077–2083.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/D16-1223" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D16-1223</a>

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee
et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Jihwan Lee, Dongchan
Kim, Ruhi Sarikaya, and Young-Bum
Kim. 2018.

</span>
<span class="ltx_bibblock">Coupled Representation Learning for Domains,
Intents and Slots in Spoken Language Understanding. In
<em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">2018 IEEE Spoken Language Technology Workshop
(SLT)</em>. IEEE, Athens, Greece,
714–719.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2018a)</span>
<span class="ltx_bibblock">
Changliang Li, Cunliang
Kong, and Yan Zhao. 2018a.

</span>
<span class="ltx_bibblock">A Joint Multi-Task Learning Framework for Spoken
Language Understanding. In <em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">2018 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.
IEEE, Calgary, Canada,
6054–6058.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2018b)</span>
<span class="ltx_bibblock">
Changliang Li, Liang Li,
and Ji Qi. 2018b.

</span>
<span class="ltx_bibblock">A Self-Attentive Model with Gate Mechanism for
Spoken Language Understanding. In <em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2018 Conference on Empirical Methods in Natural Language Processing</em>.
Association for Computational Linguistics,
Brussels, Belgium, 3824–3833.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/D18-1417" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D18-1417</a>

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Changliang Li, Yan Zhao,
and Dong Yu. 2019.

</span>
<span class="ltx_bibblock">Conditional Joint Model for Spoken Dialogue
System. In <em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">Cognitive Computing – ICCC 2019</em>,
Ruifeng Xu, Jianzong
Wang, and Liang-Jie Zhang (Eds.).
Springer International Publishing,
Cham, 26–36.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin and Xu (2019)</span>
<span class="ltx_bibblock">
Ting-En Lin and Hua
Xu. 2019.

</span>
<span class="ltx_bibblock">Deep Unknown Intent Detection with Margin Loss. In
<em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the
Association for Computational Linguistics</em>. Association
for Computational Linguistics, Florence, Italy,
5491–5496.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/P19-1548" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P19-1548</a>

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Lane (2015)</span>
<span class="ltx_bibblock">
Bing Liu and Ian Lane.
2015.

</span>
<span class="ltx_bibblock">Recurrent Neural Network Structured Output
Prediction for Spoken Language Understanding. In
<em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Proceedings of NIPS Workshop on Machine Learning
for Spoken Language Understanding and Interactions</em>.
Association for Computational Linguistics,
Montreal, Canada.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Lane (2016a)</span>
<span class="ltx_bibblock">
Bing Liu and Ian Lane.
2016a.

</span>
<span class="ltx_bibblock">Attention-Based Recurrent Neural Network Models for
Joint Intent Detection and Slot Filling. In
<em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Interspeech 2016</em>. ISCA,
San Francisco, USA, 685–689.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.21437/Interspeech.2016-1352" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2016-1352</a>

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Lane (2016b)</span>
<span class="ltx_bibblock">
Bing Liu and Ian Lane.
2016b.

</span>
<span class="ltx_bibblock">Joint Online Spoken Language Understanding and
Language Modeling with Recurrent Neural Networks. In
<em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Proceedings of the SIGDIAL 2016 Conference</em>.
Association for Computational Linguistics,
Los Angeles, USA, 22–30.

</span>
<span class="ltx_bibblock">arXiv:1609.01462

<a target="_blank" href="http://arxiv.org/abs/1609.01462" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1609.01462</a>

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Jiao Liu, Yanling Li,
and Min Lin. 2019a.

</span>
<span class="ltx_bibblock">Review of Intent Detection Methods in the
Human-Machine Dialogue System.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">Journal of Physics: Conference Series</em>
1267 (Jul 2019),
012059.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1088/1742-6596/1267/1/012059" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1088/1742-6596/1267/1/012059</a>

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Yijin Liu, Fandong Meng,
Jinchao Zhang, Jie Zhou,
Yufeng Chen, and Jinan Xu.
2019b.

</span>
<span class="ltx_bibblock">CM-Net: A Novel Collaborative Memory Network for
Spoken Language Understanding. In <em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing
(EMNLP-IJCNLP)</em>. Association for Computational
Linguistics, Hong Kong, China,
1051–1060.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/D19-1097" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D19-1097</a>

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2019c)</span>
<span class="ltx_bibblock">
Zihan Liu, Jamin Shin,
Yan Xu, Genta Indra Winata,
Peng Xu, Andrea Madotto, and
Pascale Fung. 2019c.

</span>
<span class="ltx_bibblock">Zero-shot Cross-lingual Dialogue Systems with
Transferable Latent Variables. In <em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing
(EMNLP-IJCNLP)</em>. Association for Computational
Linguistics, Hong Kong, China,
1297–1303.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/D19-1129" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D19-1129</a>

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Louvan and
Magnini (2018)</span>
<span class="ltx_bibblock">
Samuel Louvan and
Bernardo Magnini. 2018.

</span>
<span class="ltx_bibblock">Exploring Named Entity Recognition As an Auxiliary
Task for Slot Filling in Conversational Language Understanding. In
<em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 EMNLP Workshop SCAI:
The 2nd International Workshop on Search-Oriented Conversational AI</em>.
Association for Computational Linguistics,
Brussels, Belgium, 74–80.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/W18-5711" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/W18-5711</a>

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Louvan and
Magnini (2019)</span>
<span class="ltx_bibblock">
Samuel Louvan and
Bernardo Magnini. 2019.

</span>
<span class="ltx_bibblock">Leveraging Non-Conversational Tasks for Low
Resource Slot Filling: Does it help?. In
<em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th Annual SIGdial Meeting on
Discourse and Dialogue</em>. Association for Computational
Linguistics, Stockholm, Sweden, 85–91.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/W19-5911" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/W19-5911</a>

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma
et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Mingbo Ma, Kai Zhao,
Liang Huang, Bing Xiang, and
Bowen Zhou. 2017.

</span>
<span class="ltx_bibblock">Jointly Trained Sequential Labeling and
Classification by Sparse Attention Neural Networks. In
<em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">Interspeech</em>. ISCA,
Stockholm, Sweden, 3334–3338.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Masumura et al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Ryo Masumura, Yusuke
Shinohara, Ryuichiro Higashinaka, and
Yushi Aono. 2018.

</span>
<span class="ltx_bibblock">Adversarial Training for Multi-task and
Multi-lingual Joint Modeling of Utterance Intent Classification. In
<em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing</em>. Association for
Computational Linguistics, Brussels, Belgium,
633–639.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/d18-1064" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/d18-1064</a>

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mesnil et al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Grégoire Mesnil, Yann
Dauphin, Kaisheng Yao, Yoshua Bengio,
Li Deng, Dilek Hakkani-Tur,
Xiaodong He, Larry Heck,
Gokhan Tur, Dong Yu, and
Geoffrey Zweig. 2015.

</span>
<span class="ltx_bibblock">Using Recurrent Neural Networks for Slot Filling in
Spoken Language Understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">IEEE/ACM Trans. Audio, Speech and Language
Processing</em> 23, 3 (March
2015), 530–539.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TASLP.2014.2383614" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TASLP.2014.2383614</a>

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mesnil
et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Grégoire Mesnil,
Xiaodong He, Li Deng, and
Yoshua Bengio. 2013.

</span>
<span class="ltx_bibblock">Investigation of recurrent-neural-network
architectures and learning methods for spoken language understanding. In
<em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">Interspeech</em>. ISCA,
Lyon, France, 3771–3775.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohasseb
et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Alaa Mohasseb, Mohamed
Bader-El-Den, and Mihaela Cocea.
2018.

</span>
<span class="ltx_bibblock">Classification of factoid questions intent using
grammatical features.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">ICT Express</em> 4,
4 (Dec 2018),
239–242.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1016/j.icte.2018.10.004" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.icte.2018.10.004</a>

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni
et al<span id="bib.bib71.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Pin Ni, Yuming Li,
Gangmin Li, and Victor Chang.
2020.

</span>
<span class="ltx_bibblock">Natural language understanding approaches based on
joint task of intent detection and slot filling for IoT voice interaction.

</span>
<span class="ltx_bibblock"><em id="bib.bib71.3.1" class="ltx_emph ltx_font_italic">Neural Computing and Applications</em>
32 (2020).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/s00521-020-04805-x" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s00521-020-04805-x</a>

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niu and Penn (2019)</span>
<span class="ltx_bibblock">
Jingcheng Niu and Gerald
Penn. 2019.

</span>
<span class="ltx_bibblock">Rationally Reappraising ATIS-based Dialogue
Systems. In <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting
of the Association for Computational Linguistics</em>.
Association for Computational Linguistics,
Florence, Italy, 5503–5507.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Okur
et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Eda Okur, Shachi H Kumar,
Saurav Sahay, Asli Arslan Esme, and
Lama Nachman. 2019.

</span>
<span class="ltx_bibblock">Natural Language Interactions in Autonomous Vehicles:
Intent Detection and Slot Filling from Passenger Utterances.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1904.10500 [cs.CL]

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pallett et al<span id="bib.bib74.2.2.1" class="ltx_text">.</span> (1992)</span>
<span class="ltx_bibblock">
David S. Pallett, Nancy L.
Dahlgren, Jonathan G. Fiscus, William M.
Fisher, John S. Garofolo, and Brett C.
Tjaden. 1992.

</span>
<span class="ltx_bibblock">DARPA February 1992 ATIS Benchmark Test Results.
In <em id="bib.bib74.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Workshop on Speech and
Natural Language</em> (Harriman, New York) <em id="bib.bib74.4.2" class="ltx_emph ltx_font_italic">(HLT ’91)</em>.
Association for Computational Linguistics,
USA, 15–27.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.3115/1075527.1075532" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.3115/1075527.1075532</a>

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan
et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Lingfeng Pan, Yi Zhang,
Feiliang Ren, Yining Hou,
Yan Li, Xiaobo Liang, and
Yongkang Liu. 2018.

</span>
<span class="ltx_bibblock">A Multiple Utterances Based Neural Network Model
for Joint Intent Detection and Slot Filling. In
<em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Evaluation Tasks at the China
Conference on Knowledge Graph and Semantic Computing (CCKS 2018)</em>.
CEUR-WS.org, Tianjin, China,
25–33.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng and Yao (2015)</span>
<span class="ltx_bibblock">
Baolin Peng and Kaisheng
Yao. 2015.

</span>
<span class="ltx_bibblock">Recurrent Neural Networks with External Memory for
Language Understanding.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1506.00195 [cs.CL]

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pentyala
et al<span id="bib.bib77.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Shiva Pentyala, Mengwen
Liu, and Markus Dreyer.
2019.

</span>
<span class="ltx_bibblock">Multi-Task Networks with Universe, Group, and Task
Feature Learning. In <em id="bib.bib77.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th
Annual Meeting of the Association for Computational Linguistics</em>.
Association for Computational Linguistics,
Florence, Italy, 820–830.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/P19-1079" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P19-1079</a>

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Purohit et al<span id="bib.bib78.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Hemant Purohit, Guozhu
Dong, Valerie Shalin, Krishnaprasad
Thirunarayan, and Amit Sheth.
2015.

</span>
<span class="ltx_bibblock">Intent Classification of Short-Text on Social
Media. In <em id="bib.bib78.3.1" class="ltx_emph ltx_font_italic">2015 IEEE International Conference on
Smart City/SocialCom/SustainCom (SmartCity)</em>.
IEEE, Chengdu, China,
222–228.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/smartcity.2015.75" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/smartcity.2015.75</a>

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin
et al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Libo Qin, Wanxiang Che,
Yangming Li, Haoyang Wen, and
Ting Liu. 2019.

</span>
<span class="ltx_bibblock">A Stack-Propagation Framework with Token-Level
Intent Detection for Spoken Language Understanding. In
<em id="bib.bib79.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th International Joint
Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong,
China, November 3-7, 2019</em>, Kentaro
Inui, Jing Jiang, Vincent Ng, and
Xiaojun Wan (Eds.). Association for
Computational Linguistics, Hong Kong,
2078–2087.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/D19-1214" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D19-1214</a>

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin
et al<span id="bib.bib80.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Libo Qin, Minheng Ni,
Yue Zhang, and Wanxiang Che.
2020a.

</span>
<span class="ltx_bibblock">CoSDA-ML: Multi-Lingual Code-Switching Data
Augmentation for Zero-Shot Cross-Lingual NLP. In
<em id="bib.bib80.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Twenty-Ninth International Joint
Conference on Artificial Intelligence, IJCAI-20</em>,
Christian Bessiere (Ed.).
International Joint Conferences on Artificial
Intelligence Organization, Yokohama, Japan,
3853–3860.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.24963/ijcai.2020/533" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.24963/ijcai.2020/533</a>

</span>
<span class="ltx_bibblock">Main track.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin
et al<span id="bib.bib81.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Libo Qin, Xiao Xu,
Wanxiang Che, and Ting Liu.
2020b.

</span>
<span class="ltx_bibblock">AGIF: An Adaptive Graph-Interactive Framework for
Joint Multiple Intent Detection and Slot Filling. In
<em id="bib.bib81.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational
Linguistics: EMNLP 2020</em>. Association for Computational
Linguistics, Online, 1807–1816.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.findings-emnlp.163" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.findings-emnlp.163</a>

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu
et al<span id="bib.bib82.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Lirong Qiu, Yida Chen,
Haoran Jia, and Zhen Zhang.
2018.

</span>
<span class="ltx_bibblock">Query Intent Recognition Based on Multi-Class
Features.

</span>
<span class="ltx_bibblock"><em id="bib.bib82.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 6
(2018), 52195–52204.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/access.2018.2869585" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/access.2018.2869585</a>

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ravuri and
Stolcke (2015)</span>
<span class="ltx_bibblock">
Suman Ravuri and Andreas
Stolcke. 2015.

</span>
<span class="ltx_bibblock">Recurrent Neural Network and LSTM Models for
Lexical Utterance Classification. In <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">Proc.
Interspeech</em>. ISCA - International Speech Communication
Association, Dresden, Germany, 135–139.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.microsoft.com/en-us/research/publication/recurrent-neural-network-and-lstm-models-for-lexical-utterance-classification/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.microsoft.com/en-us/research/publication/recurrent-neural-network-and-lstm-models-for-lexical-utterance-classification/</a>

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ray et al<span id="bib.bib84.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Avik Ray, Yilin Shen,
and Hongxia Jin. 2018.

</span>
<span class="ltx_bibblock">Robust Spoken Language Understanding via
Paraphrasing. In <em id="bib.bib84.3.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2018</em>.
ISCA, Hyderabad, India,
3454–3458.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.21437/Interspeech.2018-2358" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2018-2358</a>

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ray et al<span id="bib.bib85.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Avik Ray, Yilin Shen,
and Hongxia Jin. 2019.

</span>
<span class="ltx_bibblock">Iterative Delexicalization for Improved Spoken
Language Understanding. In <em id="bib.bib85.3.1" class="ltx_emph ltx_font_italic">Interspeech</em>.
ISCA, Graz, Austria,
1183–1187.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.21437/Interspeech.2019-2955" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2019-2955</a>

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raymond and
Riccardi (2007)</span>
<span class="ltx_bibblock">
Christian Raymond and
Giuseppe Riccardi. 2007.

</span>
<span class="ltx_bibblock">Generative and discriminative algorithms for spoken
language understanding. In <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>.
ISCA, Antwerp, Belgium,
1605–1608.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren and Xue (2020)</span>
<span class="ltx_bibblock">
Fuji Ren and Siyuan
Xue. 2020.

</span>
<span class="ltx_bibblock">Intention Detection Based on Siamese Neural Network
With Triplet Loss.

</span>
<span class="ltx_bibblock"><em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 8
(2020), 82242–82254.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarikaya
et al<span id="bib.bib88.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
Ruhi Sarikaya, Geoffrey E.
Hinton, and Bhuvana Ramabhadran.
2011.

</span>
<span class="ltx_bibblock">Deep belief nets for natural language
call-routing. In <em id="bib.bib88.3.1" class="ltx_emph ltx_font_italic">2011 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.
IEEE, Prague, Czech Republic,
5680–5683.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/icassp.2011.5947649" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/icassp.2011.5947649</a>

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schuster
et al<span id="bib.bib89.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Sebastian Schuster, Sonal
Gupta, Rushin Shah, and Mike Lewis.
2019.

</span>
<span class="ltx_bibblock">Cross-lingual Transfer Learning for Multilingual
Task Oriented Dialog. In <em id="bib.bib89.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019
Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, Volume 1 (Long and
Short Papers)</em>. Association for Computational
Linguistics, Minneapolis, Minnesota,
3795–3805.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/N19-1380" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/N19-1380</a>

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Serban et al<span id="bib.bib90.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Iulian Vlad Serban, Ryan
Lowe, Peter Henderson, Laurent Charlin,
and Joelle Pineau. 2018.

</span>
<span class="ltx_bibblock">A Survey of Available Corpora For Building
Data-Driven Dialogue Systems: The Journal Version.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.3.1" class="ltx_emph ltx_font_italic">Dialogue &amp; Discourse</em> 9,
1 (2018), 1–49.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen
et al<span id="bib.bib91.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Yilin Shen, Wenhu Chen,
and Hongxia Jin. 2019a.

</span>
<span class="ltx_bibblock">Interpreting and Improving Deep Neural SLU Models
via Vocabulary Importance. In <em id="bib.bib91.3.1" class="ltx_emph ltx_font_italic">Interspeech</em>.
ISCA, Graz, Austria,
1328–1332.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.21437/Interspeech.2019-3184" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2019-3184</a>

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen
et al<span id="bib.bib92.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Yilin Shen, Xiangyu Zeng,
and Hongxia Jin. 2019b.

</span>
<span class="ltx_bibblock">A Progressive Model to Enable Continual Learning
for Semantic Slot Filling. In <em id="bib.bib92.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
2019 Conference on Empirical Methods in Natural Language Processing and the
9th International Joint Conference on Natural Language Processing
(EMNLP-IJCNLP)</em>. Association for Computational
Linguistics, Hong Kong, China,
1279–1284.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/D19-1126" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/D19-1126</a>

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen
et al<span id="bib.bib93.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Yilin Shen, Xiangyu Zeng,
Yu Wang, and Hongxia Jin.
2018.

</span>
<span class="ltx_bibblock">User Information Augmented Semantic Frame Parsing
Using Progressive Neural Networks. In <em id="bib.bib93.3.1" class="ltx_emph ltx_font_italic">Interspeech
2018, 19th Annual Conference of the International Speech Communication
Association, Hyderabad, India, 2-6 September 2018</em>,
B. Yegnanarayana (Ed.).
ISCA, Hyderabad, India,
3464–3468.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.21437/Interspeech.2018-1149" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2018-1149</a>

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span id="bib.bib94.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Yangyang Shi, Kaisheng
Yao, Hu Chen, Yi-Cheng Pan,
Mei-Yuh Hwang, and Baolin Peng.
2015.

</span>
<span class="ltx_bibblock">Contextual spoken language understanding using
recurrent neural networks. In <em id="bib.bib94.3.1" class="ltx_emph ltx_font_italic">2015 IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP)</em>. IEEE, Brisbane,
Australia, 5271–5275.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shin
et al<span id="bib.bib95.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Youhyun Shin, Kang Yoo,
and Sang-goo Lee. 2018.

</span>
<span class="ltx_bibblock">Slot Filling with Delexicalized Sentence
Generation. In <em id="bib.bib95.3.1" class="ltx_emph ltx_font_italic">Interspeech 2018, 19th Annual
Conference of the International Speech Communication Association, Hyderabad,
India, 2-6 September 2018</em>. ISCA,
Hyderabad, India, 2082–2086.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.21437/Interspeech.2018-1808" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2018-1808</a>

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shridhar
et al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Kumar Shridhar, Ayushman
Dash, Amit Sahu, Gustav Grund Pihlgren,
Pedro Alonso, Vinaychandran
Pondenkandath, Gyorgy Kovacs, Foteini
Simistira, and Marcus Liwicki.
2019.

</span>
<span class="ltx_bibblock">Subword Semantic Hashing for Intent Classification
on Small Datasets. In <em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">2019 International Joint
Conference on Neural Networks (IJCNN)</em>. IEEE,
Budapest, Hungary, 1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ijcnn.2019.8852420" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ijcnn.2019.8852420</a>

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siddhant
et al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Aditya Siddhant,
Anuj Kumar Goyal, and Angeliki
Metallinou. 2019.

</span>
<span class="ltx_bibblock">Unsupervised Transfer Learning for Spoken Language
Understanding in Intelligent Agents. In
<em id="bib.bib97.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, Vol. 33. AAAI Press,
Honolulu, USA, 4959–4966.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1609/aaai.v33i01.33014959" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1609/aaai.v33i01.33014959</a>

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Staliūnaitė and Iacobacci (2020)</span>
<span class="ltx_bibblock">
Ieva Staliūnaitė and
Ignacio Iacobacci. 2020.

</span>
<span class="ltx_bibblock">Auxiliary Capsules for Natural Language
Understanding. In <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020 - 2020 IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP)</em>. IEEE, Barcelona, Spain,
8154–8158.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tam
et al<span id="bib.bib99.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Yik-Cheung Tam, Yangyang
Shi, Hunk Chen, and Mei-Yuh Hwang.
2015.

</span>
<span class="ltx_bibblock">RNN-based labeled data generation for spoken
language understanding. In <em id="bib.bib99.3.1" class="ltx_emph ltx_font_italic">Interspeech</em>.
ISCA, Dresden, Germany,
125–129.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang
et al<span id="bib.bib100.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hao Tang, Donghong Ji,
and Qiji Zhou. 2020.

</span>
<span class="ltx_bibblock">End-to-end masked graph-based CRF for joint slot
filling and intent detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib100.3.1" class="ltx_emph ltx_font_italic">Neurocomputing</em> 413
(2020), 348–359.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.neucom.2019.06.113" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.neucom.2019.06.113</a>

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thi Do and
Gaspers (2019)</span>
<span class="ltx_bibblock">
Quynh Ngoc Thi Do and
Judith Gaspers. 2019.

</span>
<span class="ltx_bibblock">Cross-lingual Transfer Learning for Spoken Language
Understanding. In <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">ICASSP 2019 - 2019 IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP)</em>. IEEE, Brighton, United
Kingdom of Great Britain and Northern Ireland, 5956–5960.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tur et al<span id="bib.bib102.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Gokhan Tur, Asli
Celikyilmaz, Xiaodong He, Dilek
Hakkani-Tür, and Li Deng.
2018.

</span>
<span class="ltx_bibblock">Deep Learning in Conversational Language
Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib102.3.1" class="ltx_emph ltx_font_italic">Deep Learning in Natural Language
Processing</em>, Li Deng and
Yang Liu (Eds.). Springer Singapore,
Singapore, 23–48.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/978-981-10-5209-5_2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-981-10-5209-5_2</a>

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tur and De Mori (2011)</span>
<span class="ltx_bibblock">
Gokhan Tur and Renato
De Mori. 2011.

</span>
<span class="ltx_bibblock"><em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Spoken Language Understanding: Systems for
Extracting Semantic Information from Speech</em>.

</span>
<span class="ltx_bibblock">John Wiley and Sons, New York,
USA.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.microsoft.com/en-us/research/publication/spoken-language-understanding-systems-for-extracting-semantic-information-from-speech/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.microsoft.com/en-us/research/publication/spoken-language-understanding-systems-for-extracting-semantic-information-from-speech/</a>

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tur
et al<span id="bib.bib104.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Gokhan Tur, Dilek
Hakkani-Tür, and Larry Heck.
2010.

</span>
<span class="ltx_bibblock">What is left to be understood in ATIS?. In
<em id="bib.bib104.3.1" class="ltx_emph ltx_font_italic">2010 IEEE Spoken Language Technology Workshop</em>.
IEEE, IEEE, Berkeley, USA,
19–24.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tur
et al<span id="bib.bib105.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
Gokhan Tur, Dilek
Hakkani-Tur, Larry Heck, and S.
Parthasarathy. 2011.

</span>
<span class="ltx_bibblock">Sentence simplification for spoken language
understanding. In <em id="bib.bib105.3.1" class="ltx_emph ltx_font_italic">2011 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.
IEEE, Prague, Czech Republic,
5628 – 5631.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al<span id="bib.bib106.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam
Shazeer, Niki Parmar, Jakob Uszkoreit,
Llion Jones, Aidan N Gomez,
Łukasz Kaiser, and Illia
Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <em id="bib.bib106.3.1" class="ltx_emph ltx_font_italic">Advances in neural information
processing systems 30</em>. Curran Associates, Inc.,
Long Beach, USA, 5998–6008.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf</a>

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Veyseh
et al<span id="bib.bib107.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Amir Pouran Ben Veyseh,
Franck Dernoncourt, and Thien Huu
Nguyen. 2019.

</span>
<span class="ltx_bibblock">Improving Slot Filling by Utilizing Contextual
Information.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1911.01680 [cs.CL]

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vu (2016)</span>
<span class="ltx_bibblock">
Thang Vu. 2016.

</span>
<span class="ltx_bibblock">Sequential Convolutional Neural Networks for Slot
Filling in Spoken Language Understanding. In
<em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>. ISCA,
San Francisco, USA, 3250–3254.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.21437/Interspeech.2016-395" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2016-395</a>

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vu
et al<span id="bib.bib109.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Thang Vu, Pankaj Gupta,
Heike Adel, and Hinrich Schütze.
2016.

</span>
<span class="ltx_bibblock">Bi-directional recurrent neural network with
ranking loss for spoken language understanding. In
<em id="bib.bib109.3.1" class="ltx_emph ltx_font_italic">2016 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP)</em>. IEEE,
Shanghai, China, 6060–6064.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICASSP.2016.7472841" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICASSP.2016.7472841</a>

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib110.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Congrui Wang, Zhen Huang,
and Minghao Hu. 2020b.

</span>
<span class="ltx_bibblock">SASGBC: Improving Sequence Labeling Performance for
Joint Learning of Slot Filling and Intent Detection. In
<em id="bib.bib110.3.1" class="ltx_emph ltx_font_italic">Proceedings of 2020 the 6th International
Conference on Computing and Data Engineering</em> (Sanya, China)
<em id="bib.bib110.4.2" class="ltx_emph ltx_font_italic">(ICCDE 2020)</em>. Association for
Computing Machinery, New York, NY, USA,
29–33.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3379247.3379266" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3379247.3379266</a>

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Yuan (2016)</span>
<span class="ltx_bibblock">
Xiaojie Wang and Caixia
Yuan. 2016.

</span>
<span class="ltx_bibblock">Recent Advances on Human-Computer Dialogue.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">CAAI Transactions on Intelligence
Technology</em> 1, 4 (Oct
2016), 303–312.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1016/j.trit.2016.12.004" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.trit.2016.12.004</a>

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib112.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Yu Wang, Yue Deng,
Yilin Shen, and Hongxia Jin.
2020a.

</span>
<span class="ltx_bibblock">A New Concept of Multiple Neural Networks Structure
Using Convex Combination.

</span>
<span class="ltx_bibblock"><em id="bib.bib112.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and
Learning Systems</em> 31 (2020),
1–12.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib113.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Yufan Wang, Tingting He,
Rui Fan, Wenji Zhou, and
Xinhui Tu. 2019a.

</span>
<span class="ltx_bibblock">Effective Utilization of External Knowledge and
History Context in Multi-turn Spoken Language Understanding Model. In
<em id="bib.bib113.3.1" class="ltx_emph ltx_font_italic">2019 IEEE International Conference on Big Data (Big
Data)</em>. IEEE, Los Angeles, USA,
960–967.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib114.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Yufan Wang, Jiawei Huang,
Tingting He, and Xinhui Tu.
2019b.

</span>
<span class="ltx_bibblock">Dialogue intent classification with
character-CNN-BGRU networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib114.3.1" class="ltx_emph ltx_font_italic">Multimedia Tools and Applications</em>
79, 7-8 (Jun
2019), 4553–4572.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/s11042-019-7678-1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s11042-019-7678-1</a>

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib115.2.2.1" class="ltx_text">.</span> (2018a)</span>
<span class="ltx_bibblock">
Yu Wang, Abhishek Patel,
and Hongxia Jin. 2018a.

</span>
<span class="ltx_bibblock">A New Concept of Deep Reinforcement Learning based
Augmented General Tagging System. In <em id="bib.bib115.3.1" class="ltx_emph ltx_font_italic">Proceedings
of the 27th International Conference on Computational Linguistics</em>.
Association for Computational Linguistics,
Santa Fe, New Mexico, USA, 1683–1693.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.aclweb.org/anthology/C18-1143" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/C18-1143</a>

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib116.2.2.1" class="ltx_text">.</span> (2018b)</span>
<span class="ltx_bibblock">
Yu Wang, Yilin Shen,
and Hongxia Jin. 2018b.

</span>
<span class="ltx_bibblock">A Bi-model based RNN Semantic Frame Parsing Model for
Intent Detection and Slot Filling.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1812.10235 [cs.CL]

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib117.2.2.1" class="ltx_text">.</span> (2018c)</span>
<span class="ltx_bibblock">
Yufan Wang, Li Tang,
and Tingting He. 2018c.

</span>
<span class="ltx_bibblock">Attention-Based CNN-BLSTM Networks for Joint Intent
Detection and Slot Filling. In <em id="bib.bib117.3.1" class="ltx_emph ltx_font_italic">Chinese
Computational Linguistics and Natural Language Processing Based on Naturally
Annotated Big Data</em>, Maosong Sun,
Ting Liu, Xiaojie Wang,
Zhiyuan Liu, and Yang Liu (Eds.).
Springer International Publishing,
Cham, 250–261.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang (2010)</span>
<span class="ltx_bibblock">
Ye-Yi Wang.
2010.

</span>
<span class="ltx_bibblock">Strategies for statistical spoken language
understanding with small amount of data - an empirical study. In
<em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>. ISCA,
Makuhari, Japan, 2498–2501.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib119.2.2.1" class="ltx_text">.</span> (2005)</span>
<span class="ltx_bibblock">
Ye-Yi Wang, Li Deng,
and Alex Acero. 2005.

</span>
<span class="ltx_bibblock">Spoken Language Understanding: An Introduction to
the Statistical Framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib119.3.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>
22, 5 (January
2005), 16–31.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.microsoft.com/en-us/research/publication/spoken-language-understanding-an-introduction-to-the-statistical-framework/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.microsoft.com/en-us/research/publication/spoken-language-understanding-an-introduction-to-the-statistical-framework/</a>

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen
et al<span id="bib.bib120.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Liyun Wen, Xiaojie Wang,
Zhenjiang Dong, and Hong Chen.
2018.

</span>
<span class="ltx_bibblock">Jointly Modeling Intent Identification and Slot
Filling with Contextual and Hierarchical Information. In
<em id="bib.bib120.3.1" class="ltx_emph ltx_font_italic">Natural Language Processing and Chinese
Computing</em>, Xuanjing Huang,
Jing Jiang, Dongyan Zhao,
Yansong Feng, and Yu Hong (Eds.).
Springer International Publishing,
Cham, 3–15.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia
et al<span id="bib.bib121.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Congying Xia, Chenwei
Zhang, Xiaohui Yan, Yi Chang, and
Philip Yu. 2018.

</span>
<span class="ltx_bibblock">Zero-shot User Intent Detection via Capsule Neural
Networks. In <em id="bib.bib121.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Processing</em>.
Association for Computational Linguistics,
Brussels, Belgium, 3090–3099.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/d18-1348" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/d18-1348</a>

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie
et al<span id="bib.bib122.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Wenxiu Xie, Dongfa Gao,
Ruoyao Ding, and Tianyong Hao.
2018.

</span>
<span class="ltx_bibblock">A Feature-Enriched Method for User Intent
Classification by Leveraging Semantic Tag Expansion.

</span>
<span class="ltx_bibblock">In <em id="bib.bib122.3.1" class="ltx_emph ltx_font_italic">Natural Language Processing and Chinese
Computing</em>. Springer International Publishing,
Cham, 224–234.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/978-3-319-99501-4_19" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-319-99501-4_19</a>

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu
et al<span id="bib.bib123.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Cong Xu, Qing Li,
Dezheng Zhang, Jiarui Cui,
Zhenqi Sun, and Hao Zhou.
2020.

</span>
<span class="ltx_bibblock">A model with length-variable attention for spoken
language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib123.3.1" class="ltx_emph ltx_font_italic">Neurocomputing</em> 379
(2020), 197–202.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.neucom.2019.07.112" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.neucom.2019.07.112</a>

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and
Sarikaya (2013)</span>
<span class="ltx_bibblock">
Puyang Xu and Ruhi
Sarikaya. 2013.

</span>
<span class="ltx_bibblock">Convolutional neural network based triangular CRF
for joint intent detection and slot filling. In
<em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">2013 IEEE Workshop on Automatic Speech Recognition
and Understanding</em>. IEEE,
Vancouver, Canada, 78–83.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Sarikaya (2013)</span>
<span class="ltx_bibblock">
Puyang Xu and Ruhi
Sarikaya. 2013.

</span>
<span class="ltx_bibblock">Exploiting Shared Information for Multi-Intent
Natural Language Sentence Classification. In
<em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>. ISCA,
Lyon, France, 3785–3789.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib126.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Xuesong Yang, Yun-Nung
Chen, Dilek Hakkani-Tür, Paul
Crook, Xiujun Li, Jianfeng Gao,
and Li Deng. 2017.

</span>
<span class="ltx_bibblock">End-to-end joint learning of natural language
understanding and dialogue manager. In <em id="bib.bib126.3.1" class="ltx_emph ltx_font_italic">2017 IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP)</em>. IEEE, New Orleans, USA,
5690–5694.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al<span id="bib.bib127.2.2.1" class="ltx_text">.</span> (2014a)</span>
<span class="ltx_bibblock">
Kaisheng Yao, Baolin
Peng, Yu Zhang, Dong Yu,
Geoffrey Zweig, and Yangyang Shi.
2014a.

</span>
<span class="ltx_bibblock">Spoken language understanding using long short-term
memory neural networks. In <em id="bib.bib127.3.1" class="ltx_emph ltx_font_italic">2014 IEEE Spoken
Language Technology Workshop (SLT)</em>. IEEE,
South Lake Tahoe, USA, 189–194.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/SLT.2014.7078572" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/SLT.2014.7078572</a>

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al<span id="bib.bib128.2.2.1" class="ltx_text">.</span> (2014b)</span>
<span class="ltx_bibblock">
Kaisheng Yao, Baolin
Peng, Geoffrey Zweig, Dong Yu,
Xiaolong Li, and Feng Gao.
2014b.

</span>
<span class="ltx_bibblock">Recurrent conditional random field for language
understanding. In <em id="bib.bib128.3.1" class="ltx_emph ltx_font_italic">2014 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.
IEEE, Florence, Italy,
4077–4081.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao
et al<span id="bib.bib129.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Kaisheng Yao, Geoffrey
Zweig, Mei-Yuh Hwang, Yangyang Shi,
and Dong Yu. 2013.

</span>
<span class="ltx_bibblock">Recurrent Neural Networks for Language
Understanding. In <em id="bib.bib129.3.1" class="ltx_emph ltx_font_italic">Interspeech</em>.
ISCA, Lyon, France,
2524–2528.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.13140/2.1.2755.3285" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.13140/2.1.2755.3285</a>

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yilmaz and
Toraman (2020)</span>
<span class="ltx_bibblock">
Eyup Halit Yilmaz and
Cagri Toraman. 2020.

</span>
<span class="ltx_bibblock">KLOOS: KL Divergence-Based Out-of-Scope Intent
Detection in Human-to-Machine Conversations. In
<em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 43rd International ACM SIGIR
Conference on Research and Development in Information Retrieval</em> (Virtual
Event, China) <em id="bib.bib130.2.2" class="ltx_emph ltx_font_italic">(SIGIR ’20)</em>.
Association for Computing Machinery,
New York, NY, USA, 2105–2108.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3397271.3401318" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3397271.3401318</a>

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib131.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
Dong Yu, Shizhen Wang,
and li Deng. 2011.

</span>
<span class="ltx_bibblock">Sequential Labeling Using Deep-Structured
Conditional Random Fields.

</span>
<span class="ltx_bibblock"><em id="bib.bib131.3.1" class="ltx_emph ltx_font_italic">Selected Topics in Signal Processing, IEEE
Journal of</em> 4 (01 2011),
965 – 973.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/JSTSP.2010.2075990" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JSTSP.2010.2075990</a>

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu
et al<span id="bib.bib132.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Shuai Yu, Lei Shen,
Pengcheng Zhu, and Jiansong Chen.
2018.

</span>
<span class="ltx_bibblock">ACJIS: A Novel Attentive Cross Approach For Joint
Intent Detection And Slot Filling. In <em id="bib.bib132.3.1" class="ltx_emph ltx_font_italic">2018
International Joint Conference on Neural Networks (IJCNN)</em>.
IEEE, Rio de Janeiro, Brazil,
1–7.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yulan He and
Young (2003)</span>
<span class="ltx_bibblock">
Yulan He and Steve
Young. 2003.

</span>
<span class="ltx_bibblock">A data-driven spoken language understanding
system. In <em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">2003 IEEE Workshop on Automatic Speech
Recognition and Understanding (IEEE Cat. No.03EX721)</em>.
IEEE, Piscataway, USA,
583–588.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib134.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Chenwei Zhang, Wei Fan,
Nan Du, and Philip S. Yu.
2016.

</span>
<span class="ltx_bibblock">Mining User Intentions from Medical Queries: A
Neural Network Based Heterogeneous Jointly Modeling Approach. In
<em id="bib.bib134.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th International Conference on
World Wide Web</em> (Montréal, Québec, Canada)
<em id="bib.bib134.4.2" class="ltx_emph ltx_font_italic">(WWW ’16)</em>. International World
Wide Web Conferences Steering Committee, Republic and
Canton of Geneva, CHE, 1373–1384.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2872427.2874810" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2872427.2874810</a>

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib135.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Chenwei Zhang, Yaliang
Li, Nan Du, Wei Fan, and
Philip Yu. 2019a.

</span>
<span class="ltx_bibblock">Joint Slot Filling and Intent Detection via Capsule
Neural Networks. In <em id="bib.bib135.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual
Meeting of the Association for Computational Linguistics</em>.
Association for Computational Linguistics,
Florence, Italy, 5259–5267.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/P19-1519" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P19-1519</a>

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib136.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Dongjie Zhang, Zheng
Fang, Yanan Cao, Yanbing Liu,
Xiaojun Chen, and Jianlong Tan.
2018.

</span>
<span class="ltx_bibblock">Attention-Based RNN Model for Joint Extraction of
Intent and Word Slot Based on a Tagging Strategy. In
<em id="bib.bib136.3.1" class="ltx_emph ltx_font_italic">Artificial Neural Networks and Machine Learning –
ICANN 2018</em>, Věra
Kůrková, Yannis Manolopoulos,
Barbara Hammer, Lazaros Iliadis, and
Ilias Maglogiannis (Eds.). Springer
International Publishing, Cham,
178–188.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib137.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Linhao Zhang, Dehong Ma,
Xiaodong Zhang, Xiaohui Yan, and
Hou-Feng Wang. 2020b.

</span>
<span class="ltx_bibblock">Graph LSTM with Context-Gated Mechanism for Spoken
Language Understanding. In <em id="bib.bib137.3.1" class="ltx_emph ltx_font_italic">AAAI 2020</em>.
AAAI Press, New York, USA.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Wang (2019)</span>
<span class="ltx_bibblock">
Linhao Zhang and Houfeng
Wang. 2019.

</span>
<span class="ltx_bibblock">Using Bidirectional Transformer-CRF for Spoken
Language Understanding. In <em id="bib.bib138.1.1" class="ltx_emph ltx_font_italic">Natural Language
Processing and Chinese Computing</em>, Jie
Tang, Min-Yen Kan, Dongyan Zhao,
Sujian Li, and Hongying Zan (Eds.).
Springer International Publishing,
Cham, 130–141.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib139.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Shuyou Zhang, Junjie
Jiang, Zaixing He, Xinyue Zhao,
and Jinhui Fang. 2019.

</span>
<span class="ltx_bibblock">A Novel Slot-Gated Model Combined With a Key Verb
Context Feature for Task Request Understanding by Service Robots.

</span>
<span class="ltx_bibblock"><em id="bib.bib139.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 7
(2019), 105937–105947.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Wang (2016)</span>
<span class="ltx_bibblock">
Xiaodong Zhang and
Houfeng Wang. 2016.

</span>
<span class="ltx_bibblock">A Joint Model of Intent Determination and Slot
Filling for Spoken Language Understanding. In
<em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twenty-Fifth International Joint
Conference on Artificial Intelligence (IJCAI-16)</em>. AAAI
Press, New York, USA, 2993–2999.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib141.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Zhen Zhang, Hao Huang,
and Kai Wang. 2020a.

</span>
<span class="ltx_bibblock">Using Deep Time Delay Neural Network for Slot
Filling in Spoken Language Understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib141.3.1" class="ltx_emph ltx_font_italic">Symmetry</em> 12,
6 (06 2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib142.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Zhichang Zhang, Zhenwen
Zhang, Haoyuan Chen, and Zhiman
Zhang. 2019b.

</span>
<span class="ltx_bibblock">A Joint Learning Framework With BERT for Spoken
Language Understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib142.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 7
(2019), 168849–168858.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao and Feng (2018)</span>
<span class="ltx_bibblock">
Lin Zhao and Zhe Feng.
2018.

</span>
<span class="ltx_bibblock">Improving Slot Filling in Spoken Language
Understanding with Joint Pointer and Attention. In
<em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the
Association for Computational Linguistics (Volume 2: Short Papers)</em>.
Association for Computational Linguistics,
Melbourne, Australia, 426–431.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/P18-2068" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P18-2068</a>

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib144.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Xinlu Zhao, Haihong E,
and Meina Song. 2018.

</span>
<span class="ltx_bibblock">A Joint Model based on CNN-LSTMs in Dialogue
Understanding. In <em id="bib.bib144.3.1" class="ltx_emph ltx_font_italic">2018 International Conference on
Information Systems and Computer Aided Education (ICISCAE)</em>.
IEEE, Piscataway, USA,
471–475.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng
et al<span id="bib.bib145.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Yang Zheng, Yongkang
Liu, and John H. L. Hansen.
2017.

</span>
<span class="ltx_bibblock">Intent detection and semantic parsing for
navigation dialogue language processing. In <em id="bib.bib145.3.1" class="ltx_emph ltx_font_italic">2017
IEEE 20th International Conference on Intelligent Transportation Systems
(ITSC)</em>. IEEE, Yokohama, Japan,
1–6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou
et al<span id="bib.bib146.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Qianrong Zhou, Liyun Wen,
Xiaojie Wang, Long Ma, and
Yue Wang. 2016.

</span>
<span class="ltx_bibblock">A Hierarchical LSTM Model for Joint Tasks. In
<em id="bib.bib146.3.1" class="ltx_emph ltx_font_italic">Chinese Computational Linguistics and Natural
Language Processing Based on Naturally Annotated Big Data</em>,
Maosong Sun, Xuanjing
Huang, Hongfei Lin, Zhiyuan Liu, and
Yang Liu (Eds.). Springer
International Publishing, Cham,
324–335.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu and Yu (2017)</span>
<span class="ltx_bibblock">
Su Zhu and Kai Yu.
2017.

</span>
<span class="ltx_bibblock">Encoder-decoder with focus-mechanism for sequence
labelling based spoken language understanding. In
<em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP)</em>. IEEE,
New Orleans, USA, 5675–5679.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICASSP.2017.7953243" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICASSP.2017.7953243</a>

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu
et al<span id="bib.bib148.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Su Zhu, Zijian Zhao,
Rao Ma, and Kai Yu.
2020.

</span>
<span class="ltx_bibblock">Prior Knowledge Driven Label Embedding for Slot
Filling in Natural Language Understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib148.3.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and
Language Processing</em> PP (03
2020), 1–1.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TASLP.2020.2980152" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TASLP.2020.2980152</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2101.08090" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2101.08091" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2101.08091">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2101.08091" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2101.08092" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 07:29:14 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
