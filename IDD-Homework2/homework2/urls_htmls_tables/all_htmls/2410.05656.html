<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>On the Modeling Capabilities of Large Language Models for Sequential Decision Making</title>
<!--Generated on Tue Oct  8 03:11:51 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.05656v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S1" title="In On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">1</span> </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S2" title="In On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">2</span> </span>Using Language Models to Solve RL Tasks</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S2.SS0.SSS0.Px1" title="In 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title">Reinforcement Learning.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S2.SS0.SSS0.Px2" title="In 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title">Large Language Models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S2.SS1" title="In 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">2.1</span> </span>Prompting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S2.SS2" title="In 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">2.2</span> </span>Policy Modeling Using LLMs</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S2.SS2.SSS0.Px1" title="In 2.2 Policy Modeling Using LLMs ‣ 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title">Direct Policy Modeling.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S2.SS2.SSS0.Px2" title="In 2.2 Policy Modeling Using LLMs ‣ 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title">Indirect Policy Modeling.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S2.SS3" title="In 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">2.3</span> </span>Indirectly Modeling Policies through Reward Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S3" title="In On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">3</span> </span>Performance of Indirect and Direct Policy Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S3.SS0.SSS0.Px1" title="In 3 Performance of Indirect and Direct Policy Models ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title">Indirect policy modeling through rewards.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S3.SS0.SSS0.Px2" title="In 3 Performance of Indirect and Direct Policy Models ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title">Direct vs indirect policy modeling.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S4" title="In On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">4</span> </span>Analysis of AI Feedback for RL</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S4.SS1" title="In 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">4.1</span> </span>Credit Assignment</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S4.SS1.SSS0.Px1" title="In 4.1 Credit Assignment ‣ 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title">Qualitative experiment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S4.SS1.SSS0.Px2" title="In 4.1 Credit Assignment ‣ 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title">Quantitative experiment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S4.SS2" title="In 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">4.2</span> </span>Exploration</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S5" title="In On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">5</span> </span>Beyond Zero-Shot Reward Modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S6" title="In On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">6</span> </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1" title="In On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">A</span> </span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Appendix</span></span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS1" title="In Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">A.1</span> </span>Environment Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS2" title="In Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">A.2</span> </span>Details on Indirect Policy Modeling Through LLM-based Rewards</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS3" title="In Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">A.3</span> </span>Details on Direct Policy Modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS4" title="In Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">A.4</span> </span>Additional Indirect Policy Modeling Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS5" title="In Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">A.5</span> </span>Ablating Reward as Code</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS6" title="In Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">A.6</span> </span>Learning from Environment Rewards</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS7" title="In Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">A.7</span> </span>AI feedback and heuristic functions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS8" title="In Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">A.8</span> </span>Additional Considerations for Preference-based Reward Modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS9" title="In Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">A.9</span> </span>In-Context Learning for Reward Modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS10" title="In Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text ltx_font_serif ltx_font_medium">A.10</span> </span>LLMs as novelty detectors</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A2" title="In On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">B</span> </span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Additional Related Works</span></span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A2.SS0.SSS0.Px1" title="In Appendix B Additional Related Works ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_title">Prompt tuning</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\newmdenv</span>
<p class="ltx_p" id="p1.2">[
backgroundcolor=gray!2, linecolor=gray!20, linewidth=0.5pt, roundcorner=5pt, font=<span class="ltx_text ltx_font_sansserif" id="p1.2.1">, frametitlefont=<span class="ltx_text ltx_font_bold" id="p1.2.1.1">, frametitlerule=false, frametitlealignment=, innertopmargin=1em, innerbottommargin=1em, skipabove=1em, skipbelow=1em, ]mymessagebox














<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotetext: </span> <sup class="ltx_sup" id="footnotex1.1">*</sup> Work done during an Apple internship. Correspondence to: <span class="ltx_text ltx_font_typewriter" id="footnotex1.2">martin.klissarov@mail.mcgill.ca</span>.</span></span></span></span></span></p>
</div>
<h1 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_document">On the Modeling Capabilities of Large Language Models for Sequential Decision Making</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="id1.1.id1">Martin Klissarov</span><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Work</span></span></span>
<br class="ltx_break"/><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="id2.2.id2">Mila, McGill University</span>
<br class="ltx_break"/><span class="ltx_text" id="id3.3.id3">&amp;</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="id4.4.id4">Devon Hjelm</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="id5.5.id5">Apple
</span><span class="ltx_text" id="id6.6.id6">&amp;</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="id7.7.id7">Alexander Toshev</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="id8.8.id8">Apple
</span><span class="ltx_text" id="id9.9.id9">&amp;</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="id10.10.id10">Bogdan Mazoure</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="id11.11.id11">Apple</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id12.id1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="id12.id1.1">Large pretrained models are showing increasingly better performance in reasoning and planning tasks across different modalities, opening the possibility to leverage them for complex sequential decision making problems. In this paper, we investigate the capabilities of Large Language Models (LLMs) for reinforcement learning (RL) across a diversity of interactive domains. We evaluate their ability to produce decision-making policies, either directly, by generating actions, or indirectly, by first generating reward models to train an agent with RL. Our results show that, even without task-specific fine-tuning, LLMs excel at reward modeling. In particular, crafting rewards through artificial intelligence (AI) feedback yields the most generally applicable approach and can enhance performance by improving credit assignment and exploration. Finally, in environments with unfamiliar dynamics, we explore how fine-tuning LLMs with synthetic data can significantly improve their reward modeling capabilities while mitigating catastrophic forgetting, further broadening their utility in sequential decision-making tasks.</span></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S1.1.1.1">1</span> </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.1">Large Language Models (LLMs) are generative models of natural language that
can produce accurate general and domain-specific knowledge </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Singhal et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib47" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Imani et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib19" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Manigrasso et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib35" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Liu et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib31" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024a</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.5">, reason over long textual contexts </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.6.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Reid et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.7.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib43" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.8.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.9">, and generalize zero-shot </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.10.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Kojima et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.11.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib25" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.12.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.13">.
These capabilities suggest that LLMs might be well-suited for complex sequential decision-making problems, such as in embodied settings where an agent acts in an environment.
Recent research has begun exploring this potential, investigating how LLMs can serve as sources of intrinsic motivation </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.14.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Wang et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.15.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib59" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Klissarov et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.15.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib23" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.16.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.17">, demonstrating world modeling capabilities </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.18.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Lin et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.19.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib29" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Liu et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.19.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib32" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024b</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.20.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.21">, and for acting and/or planning directly in an environment </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.22.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Wang et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.23.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib58" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Padalkar et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.23.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib39" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Zhang et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.23.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib70" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024b</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.24.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p1.1.25">.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.1">However, as the predominant paradigm for training LLMs is not inherently aligned with the challenges of sequential decision-making problems, such as active exploration, it is not obvious how to best bridge their capabilities to tackle such challenges in a general manner.
We study this problem through the lens of reinforcement learning </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.2.1">(RL, </span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Sutton &amp; Barto</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib50" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2018</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.5">, which formalizes how an agent interacts with an environment, receiving scalar rewards for each of its actions over a trajectory.
We examine the capabilities of LLMs to solve RL tasks by comparing how they model policies 1) directly by generating action tokens, to 2) indirectly through a reward model derived from the LLM to be used within an RL algorithm.
We perform a comprehensive evaluation on a diverse set of domains, including MiniWob </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.6.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Liu et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.7.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib30" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2018</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.8.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.9">, NetHack </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.10.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Küttler et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.11.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib26" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2020</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.12.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.13">, and Wordle </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.14.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Lokshtanov &amp; Subercaseaux</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.15.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib33" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.16.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.17">, and MetaWorld </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.18.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yu et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.19.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib65" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2019</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.20.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p2.1.21">. The environments we study present a variety of challenges, such as different action space granularities, observation modalities ranging from natural language to pixel data, and varying horizon lengths.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p3.1.1">We first consider the off-the-shelf capabilities of LLMs for decision-making without updating them through additional gradient updates coming from the RL task.
We find that indirectly modeling policies by first extracting knowledge from LLMs in the form of a Bradley-Terry model </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p3.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Bradley &amp; Terry</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p3.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib5" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">1952</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Christiano et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p3.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib11" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2017</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p3.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p3.1.5"> provides the best and most consistent performance across the environments we study.
We empirically analyze the various benefits, and limitations, provided by this approach, showing that it improves on long-standing challenges in RL problems, such as credit assignment and exploration.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.1">Finally, while LLMs possess knowledge useful for many decision making tasks of interest, domains with complex or unfamiliar dynamics can significantly restrict their broader utility.
We explore how fine-tuning an LLM with domain-specific data can bridge this knowledge gap and study the effect of this procedure on the LLM’s previous knowledge, as measured through success on datasets like POPE </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yifan Li &amp; Wen</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib64" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.5">, GQA </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.6.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Hudson &amp; Manning</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.7.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib18" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2019</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.8.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.9">, AI2D </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.10.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Kembhavi et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.11.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib21" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2016</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.12.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.13"> and MMMU </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.14.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yue et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.15.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib67" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.16.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S1.p4.1.17">.
Our investigation reveals that fine-tuning for indirect policy modeling mitigates catastrophic forgetting more effectively than direct policy modeling, offering a broadly applicable strategy for leveraging LLMs across diverse sequential decision-making tasks.</span></p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S2.1.1.1">2</span> </span>Using Language Models to Solve RL Tasks</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.p1.1.1">We first introduce the types of RL problems as well as formalize the methodologies for using LLMs for RL tasks used in this work.</span></p>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_paragraph">Reinforcement Learning.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.9"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.1">An RL task can be defined through a Markov Decision Process </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.2.1">(MDP, </span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Puterman</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib40" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2014</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.5">, which is composed of a state space </span><math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.1.m1.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.1.m1.1d">caligraphic_S</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.6">, an action space </span><math alttext="\mathcal{A}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.2.m2.1"><semantics id="S2.SS0.SSS0.Px1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.2.m2.1b"><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.2.m2.1c">\mathcal{A}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.2.m2.1d">caligraphic_A</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.7">, a transition function </span><math alttext="p:\mathcal{S}\times\mathcal{A}\to\Delta(\mathcal{S})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.3.m3.1"><semantics id="S2.SS0.SSS0.Px1.p1.3.m3.1a"><mrow id="S2.SS0.SSS0.Px1.p1.3.m3.1.2" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.cmml"><mi id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.2" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.2.cmml">p</mi><mo id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.1" lspace="0.278em" rspace="0.278em" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.1.cmml">:</mo><mrow id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.cmml"><mrow id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.2" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.2.cmml">𝒮</mi><mo id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.1.cmml">×</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.3" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.3.cmml">𝒜</mi></mrow><mo id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.1" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.1.cmml">→</mo><mrow id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.2" mathvariant="normal" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.2.cmml">Δ</mi><mo id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.1" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.1.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.3.2" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.cmml"><mo id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.3.2.1" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1.cmml">𝒮</mi><mo id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.3.2.2" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.3.m3.1b"><apply id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2"><ci id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.1">:</ci><ci id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.2">𝑝</ci><apply id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3"><ci id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.1">→</ci><apply id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2"><times id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.1"></times><ci id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.2">𝒮</ci><ci id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.2.3">𝒜</ci></apply><apply id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3"><times id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.1"></times><ci id="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.2.3.3.2">Δ</ci><ci id="S2.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1">𝒮</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.3.m3.1c">p:\mathcal{S}\times\mathcal{A}\to\Delta(\mathcal{S})</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.3.m3.1d">italic_p : caligraphic_S × caligraphic_A → roman_Δ ( caligraphic_S )</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.8"> which describes the forward dynamics of the system, a reward function </span><math alttext="r:\mathcal{S}\times\mathcal{A}\to\mathbb{R}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.4.m4.1"><semantics id="S2.SS0.SSS0.Px1.p1.4.m4.1a"><mrow id="S2.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.2" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml">r</mi><mo id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.1" lspace="0.278em" rspace="0.278em" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.1.cmml">:</mo><mrow id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml"><mrow id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.2" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.2.cmml">𝒮</mi><mo id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.1.cmml">×</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.3" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.3.cmml">𝒜</mi></mrow><mo id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.1" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.1.cmml">→</mo><mi id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.3" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.3.cmml">ℝ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.4.m4.1b"><apply id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1"><ci id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.1">:</ci><ci id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.2">𝑟</ci><apply id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3"><ci id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.1">→</ci><apply id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2"><times id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.1"></times><ci id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.2">𝒮</ci><ci id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.2.3">𝒜</ci></apply><ci id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.3">ℝ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.4.m4.1c">r:\mathcal{S}\times\mathcal{A}\to\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.4.m4.1d">italic_r : caligraphic_S × caligraphic_A → blackboard_R</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.9"> and a discount factor </span><math alttext="\gamma\in[0,1]" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.5.m5.2"><semantics id="S2.SS0.SSS0.Px1.p1.5.m5.2a"><mrow id="S2.SS0.SSS0.Px1.p1.5.m5.2.3" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.5.m5.2.3.2" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3.2.cmml">γ</mi><mo id="S2.SS0.SSS0.Px1.p1.5.m5.2.3.1" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3.1.cmml">∈</mo><mrow id="S2.SS0.SSS0.Px1.p1.5.m5.2.3.3.2" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3.3.1.cmml"><mo id="S2.SS0.SSS0.Px1.p1.5.m5.2.3.3.2.1" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3.3.1.cmml">[</mo><mn id="S2.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.cmml">0</mn><mo id="S2.SS0.SSS0.Px1.p1.5.m5.2.3.3.2.2" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3.3.1.cmml">,</mo><mn id="S2.SS0.SSS0.Px1.p1.5.m5.2.2" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.2.cmml">1</mn><mo id="S2.SS0.SSS0.Px1.p1.5.m5.2.3.3.2.3" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.5.m5.2b"><apply id="S2.SS0.SSS0.Px1.p1.5.m5.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3"><in id="S2.SS0.SSS0.Px1.p1.5.m5.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3.1"></in><ci id="S2.SS0.SSS0.Px1.p1.5.m5.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3.2">𝛾</ci><interval closure="closed" id="S2.SS0.SSS0.Px1.p1.5.m5.2.3.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.3.3.2"><cn id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" type="integer" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1">0</cn><cn id="S2.SS0.SSS0.Px1.p1.5.m5.2.2.cmml" type="integer" xref="S2.SS0.SSS0.Px1.p1.5.m5.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.5.m5.2c">\gamma\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.5.m5.2d">italic_γ ∈ [ 0 , 1 ]</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.10">. Since it is often the case that the state is only partially observable, we also assume the environment emits an observation </span><math alttext="o_{t}\sim p_{\mathcal{O}}:\mathcal{S}\to\Delta(\mathcal{O})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.6.m6.1"><semantics id="S2.SS0.SSS0.Px1.p1.6.m6.1a"><mrow id="S2.SS0.SSS0.Px1.p1.6.m6.1.2" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.cmml"><mrow id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.cmml"><msub id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.cmml"><mi id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.2" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.2.cmml">o</mi><mi id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.3" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.3.cmml">t</mi></msub><mo id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.1" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.1.cmml">∼</mo><msub id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.2" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.2.cmml">p</mi><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.3" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.3.cmml">𝒪</mi></msub></mrow><mo id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.1" lspace="0.278em" rspace="0.278em" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.1.cmml">:</mo><mrow id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.2" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.2.cmml">𝒮</mi><mo id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.1" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.1.cmml">→</mo><mrow id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.2" mathvariant="normal" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.2.cmml">Δ</mi><mo id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.1" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.1.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.3.2" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.cmml"><mo id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.3.2.1" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.6.m6.1.1" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1.cmml">𝒪</mi><mo id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.3.2.2" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.6.m6.1b"><apply id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2"><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.1">:</ci><apply id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2"><csymbol cd="latexml" id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.1">similar-to</csymbol><apply id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.2">𝑜</ci><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.2.3">𝑡</ci></apply><apply id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.2">𝑝</ci><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.2.3.3">𝒪</ci></apply></apply><apply id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3"><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.1">→</ci><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.2">𝒮</ci><apply id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3"><times id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.1"></times><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.2.3.3.2">Δ</ci><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1">𝒪</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.6.m6.1c">o_{t}\sim p_{\mathcal{O}}:\mathcal{S}\to\Delta(\mathcal{O})</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.6.m6.1d">italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∼ italic_p start_POSTSUBSCRIPT caligraphic_O end_POSTSUBSCRIPT : caligraphic_S → roman_Δ ( caligraphic_O )</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.11"> from observation space </span><math alttext="\mathcal{O}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.7.m7.1"><semantics id="S2.SS0.SSS0.Px1.p1.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.7.m7.1.1" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1.cmml">𝒪</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.7.m7.1b"><ci id="S2.SS0.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1">𝒪</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.7.m7.1c">\mathcal{O}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.7.m7.1d">caligraphic_O</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.12">.
A policy, or </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S2.SS0.SSS0.Px1.p1.9.13">actor</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.14">, is a probability distribution </span><math alttext="\pi:\mathcal{S}\to\Delta(\mathcal{A})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.8.m8.1"><semantics id="S2.SS0.SSS0.Px1.p1.8.m8.1a"><mrow id="S2.SS0.SSS0.Px1.p1.8.m8.1.2" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.cmml"><mi id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.2" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.2.cmml">π</mi><mo id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.1" lspace="0.278em" rspace="0.278em" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.1.cmml">:</mo><mrow id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.2" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.2.cmml">𝒮</mi><mo id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.1" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.1.cmml">→</mo><mrow id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.2" mathvariant="normal" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.2.cmml">Δ</mi><mo id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.1" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.1.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.3.2" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.cmml"><mo id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.3.2.1" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.8.m8.1.1" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.1.cmml">𝒜</mi><mo id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.3.2.2" stretchy="false" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.8.m8.1b"><apply id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2"><ci id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.1">:</ci><ci id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.2">𝜋</ci><apply id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3"><ci id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.1">→</ci><ci id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.2">𝒮</ci><apply id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3"><times id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.1"></times><ci id="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.2.3.3.2">Δ</ci><ci id="S2.SS0.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.1">𝒜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.8.m8.1c">\pi:\mathcal{S}\to\Delta(\mathcal{A})</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.8.m8.1d">italic_π : caligraphic_S → roman_Δ ( caligraphic_A )</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.15"> which describes the action to be taken at every step.
The objective of a rational actor is to maximize the expected cumulative rewards over horizon </span><math alttext="H&gt;0" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p1.9.m9.1"><semantics id="S2.SS0.SSS0.Px1.p1.9.m9.1a"><mrow id="S2.SS0.SSS0.Px1.p1.9.m9.1.1" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.9.m9.1.1.2" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1.2.cmml">H</mi><mo id="S2.SS0.SSS0.Px1.p1.9.m9.1.1.1" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1.1.cmml">&gt;</mo><mn id="S2.SS0.SSS0.Px1.p1.9.m9.1.1.3" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.9.m9.1b"><apply id="S2.SS0.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1"><gt id="S2.SS0.SSS0.Px1.p1.9.m9.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1.1"></gt><ci id="S2.SS0.SSS0.Px1.p1.9.m9.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1.2">𝐻</ci><cn id="S2.SS0.SSS0.Px1.p1.9.m9.1.1.3.cmml" type="integer" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.9.m9.1c">H&gt;0</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.9.m9.1d">italic_H &gt; 0</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p1.9.16">,</span></p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\max_{\pi}\mathbb{E}[\sum_{t=0}^{H}\gamma^{t}r(s_{t},\pi(s_{t}))|s_{0}]=\max_{%
\pi}\mathbb{E}_{s_{0}}[V^{\pi}(s_{0})]," class="ltx_Math" display="block" id="S2.E1.m1.1"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.3.cmml"><munder id="S2.E1.m1.1.1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.1.1.3.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.3.1.2" xref="S2.E1.m1.1.1.1.1.1.3.1.2.cmml">max</mi><mi id="S2.E1.m1.1.1.1.1.1.3.1.3" xref="S2.E1.m1.1.1.1.1.1.3.1.3.cmml">π</mi></munder><mo id="S2.E1.m1.1.1.1.1.1.3a" lspace="0.167em" xref="S2.E1.m1.1.1.1.1.1.3.cmml">⁡</mo><mi id="S2.E1.m1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.3.2.cmml">𝔼</mi></mrow><mo id="S2.E1.m1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.2.cmml"><mo id="S2.E1.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.cmml"><munderover id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml"><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2" lspace="0em" movablelimits="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2.cmml">∑</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.1.cmml">=</mo><mn id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.3.cmml">0</mn></mrow><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml">H</mi></munderover><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml"><msup id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.2.cmml">γ</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.3.cmml">t</mi></msup><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.3.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.5" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.5.cmml">r</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.3a" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.3.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.3.cmml"><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">(</mo><msub id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.4" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">,</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.3.cmml">π</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.2.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.cmml"><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.cmml">(</mo><msub id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.2.cmml">s</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.3.cmml">t</mi></msub><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.5" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo fence="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.cmml">|</mo><msub id="S2.E1.m1.1.1.1.1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.1.1.1.1.4.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.4.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.4.2.cmml">s</mi><mn id="S2.E1.m1.1.1.1.1.1.1.1.1.4.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.4.3.cmml">0</mn></msub></mrow><mo id="S2.E1.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml"><mrow id="S2.E1.m1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.2.3.cmml"><munder id="S2.E1.m1.1.1.1.1.2.3.1" xref="S2.E1.m1.1.1.1.1.2.3.1.cmml"><mi id="S2.E1.m1.1.1.1.1.2.3.1.2" xref="S2.E1.m1.1.1.1.1.2.3.1.2.cmml">max</mi><mi id="S2.E1.m1.1.1.1.1.2.3.1.3" xref="S2.E1.m1.1.1.1.1.2.3.1.3.cmml">π</mi></munder><mo id="S2.E1.m1.1.1.1.1.2.3a" lspace="0.167em" xref="S2.E1.m1.1.1.1.1.2.3.cmml">⁡</mo><msub id="S2.E1.m1.1.1.1.1.2.3.2" xref="S2.E1.m1.1.1.1.1.2.3.2.cmml"><mi id="S2.E1.m1.1.1.1.1.2.3.2.2" xref="S2.E1.m1.1.1.1.1.2.3.2.2.cmml">𝔼</mi><msub id="S2.E1.m1.1.1.1.1.2.3.2.3" xref="S2.E1.m1.1.1.1.1.2.3.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.2.3.2.3.2" xref="S2.E1.m1.1.1.1.1.2.3.2.3.2.cmml">s</mi><mn id="S2.E1.m1.1.1.1.1.2.3.2.3.3" xref="S2.E1.m1.1.1.1.1.2.3.2.3.3.cmml">0</mn></msub></msub></mrow><mo id="S2.E1.m1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.2.2.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.2.1.1" xref="S2.E1.m1.1.1.1.1.2.1.2.cmml"><mo id="S2.E1.m1.1.1.1.1.2.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.2.1.2.1.cmml">[</mo><mrow id="S2.E1.m1.1.1.1.1.2.1.1.1" xref="S2.E1.m1.1.1.1.1.2.1.1.1.cmml"><msup id="S2.E1.m1.1.1.1.1.2.1.1.1.3" xref="S2.E1.m1.1.1.1.1.2.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.2.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.2.1.1.1.3.2.cmml">V</mi><mi id="S2.E1.m1.1.1.1.1.2.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.2.1.1.1.3.3.cmml">π</mi></msup><mo id="S2.E1.m1.1.1.1.1.2.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.1.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.cmml"><mo id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.2.cmml">s</mi><mn id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.3.cmml">0</mn></msub><mo id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.2.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"></eq><apply id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.2"></times><apply id="S2.E1.m1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3"><apply id="S2.E1.m1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.3.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.3.1">subscript</csymbol><max id="S2.E1.m1.1.1.1.1.1.3.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.3.1.2"></max><ci id="S2.E1.m1.1.1.1.1.1.3.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3.1.3">𝜋</ci></apply><ci id="S2.E1.m1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.3.2">𝔼</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3">conditional</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2"><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3">superscript</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3">subscript</csymbol><sum id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2"></sum><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3"><eq id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.1"></eq><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.2">𝑡</ci><cn id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.3.cmml" type="integer" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.3">0</cn></apply></apply><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.3">𝐻</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2"><times id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.3"></times><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.2">𝛾</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.4.3">𝑡</ci></apply><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.5.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.5">𝑟</ci><interval closure="open" id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2"><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑠</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2"><times id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.2"></times><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.3">𝜋</ci><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.2">𝑠</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.1.1.3">𝑡</ci></apply></apply></interval></apply></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.4.2">𝑠</ci><cn id="S2.E1.m1.1.1.1.1.1.1.1.1.4.3.cmml" type="integer" xref="S2.E1.m1.1.1.1.1.1.1.1.1.4.3">0</cn></apply></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"><times id="S2.E1.m1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2"></times><apply id="S2.E1.m1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.3"><apply id="S2.E1.m1.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.2.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.3.1.1.cmml" xref="S2.E1.m1.1.1.1.1.2.3.1">subscript</csymbol><max id="S2.E1.m1.1.1.1.1.2.3.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2.3.1.2"></max><ci id="S2.E1.m1.1.1.1.1.2.3.1.3.cmml" xref="S2.E1.m1.1.1.1.1.2.3.1.3">𝜋</ci></apply><apply id="S2.E1.m1.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.3.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.3.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.3.2.2">𝔼</ci><apply id="S2.E1.m1.1.1.1.1.2.3.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.3.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.2.3.2.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.3.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.2.3.2.3.2">𝑠</ci><cn id="S2.E1.m1.1.1.1.1.2.3.2.3.3.cmml" type="integer" xref="S2.E1.m1.1.1.1.1.2.3.2.3.3">0</cn></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1.2.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.2.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.2">delimited-[]</csymbol><apply id="S2.E1.m1.1.1.1.1.2.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1"><times id="S2.E1.m1.1.1.1.1.2.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.2"></times><apply id="S2.E1.m1.1.1.1.1.2.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.3">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.3.2">𝑉</ci><ci id="S2.E1.m1.1.1.1.1.2.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.3.3">𝜋</ci></apply><apply id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.2">𝑠</ci><cn id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.3">0</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\max_{\pi}\mathbb{E}[\sum_{t=0}^{H}\gamma^{t}r(s_{t},\pi(s_{t}))|s_{0}]=\max_{%
\pi}\mathbb{E}_{s_{0}}[V^{\pi}(s_{0})],</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.1d">roman_max start_POSTSUBSCRIPT italic_π end_POSTSUBSCRIPT blackboard_E [ ∑ start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT italic_γ start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_π ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) | italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ] = roman_max start_POSTSUBSCRIPT italic_π end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_V start_POSTSUPERSCRIPT italic_π end_POSTSUPERSCRIPT ( italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.3"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p2.3.1">where the value function, </span><math alttext="V^{\pi}(s)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.p2.1.m1.1a"><mrow id="S2.SS0.SSS0.Px1.p2.1.m1.1.2" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.cmml"><msup id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.cmml"><mi id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.2" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.2.cmml">V</mi><mi id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.3" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.3.cmml">π</mi></msup><mo id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.1" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.1.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.3.2" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.cmml"><mo id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.3.2.1" stretchy="false" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.cmml">(</mo><mi id="S2.SS0.SSS0.Px1.p2.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml">s</mi><mo id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.3.2.2" stretchy="false" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2"><times id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.1"></times><apply id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2">superscript</csymbol><ci id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.2">𝑉</ci><ci id="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.2.2.3">𝜋</ci></apply><ci id="S2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.1.m1.1c">V^{\pi}(s)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p2.1.m1.1d">italic_V start_POSTSUPERSCRIPT italic_π end_POSTSUPERSCRIPT ( italic_s )</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p2.3.2">, represents the expected discounted sum of rewards over the entire trajectory, re-weighted by the environment’s dynamics model, </span><math alttext="p" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.2.m2.1"><semantics id="S2.SS0.SSS0.Px1.p2.2.m2.1a"><mi id="S2.SS0.SSS0.Px1.p2.2.m2.1.1" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.2.m2.1b"><ci id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.2.m2.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p2.2.m2.1d">italic_p</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p2.3.3">, and the actor’s policy, </span><math alttext="\pi" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.3.m3.1"><semantics id="S2.SS0.SSS0.Px1.p2.3.m3.1a"><mi id="S2.SS0.SSS0.Px1.p2.3.m3.1.1" xref="S2.SS0.SSS0.Px1.p2.3.m3.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.3.m3.1b"><ci id="S2.SS0.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.3.m3.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.3.m3.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p2.3.m3.1d">italic_π</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px1.p2.3.4">.</span></p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_paragraph">Large Language Models.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px2.p1.2.1">An LLM is a generative model of discrete random variables (i.e. tokens) conditioned on a history (i.e. context). The LLM models the data distribution autoregressively:</span></p>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p(x_{t+1}|x_{1},..,x_{t})=\prod_{t^{\prime}=1}^{t}p(x_{t^{\prime}}|x_{&lt;t^{%
\prime}})\\
=\texttt{LLM}(x_{&lt;t},l)" class="ltx_math_unparsed" display="block" id="S2.E2.m1.1"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1b"><mi id="S2.E2.m1.1.1">p</mi><mrow id="S2.E2.m1.1.2"><mo id="S2.E2.m1.1.2.1" stretchy="false">(</mo><msub id="S2.E2.m1.1.2.2"><mi id="S2.E2.m1.1.2.2.2">x</mi><mrow id="S2.E2.m1.1.2.2.3"><mi id="S2.E2.m1.1.2.2.3.2">t</mi><mo id="S2.E2.m1.1.2.2.3.1">+</mo><mn id="S2.E2.m1.1.2.2.3.3">1</mn></mrow></msub><mo fence="false" id="S2.E2.m1.1.2.3" rspace="0.167em" stretchy="false">|</mo><msub id="S2.E2.m1.1.2.4"><mi id="S2.E2.m1.1.2.4.2">x</mi><mn id="S2.E2.m1.1.2.4.3">1</mn></msub><mo id="S2.E2.m1.1.2.5">,</mo><mo id="S2.E2.m1.1.2.6" lspace="0em" rspace="0.0835em">.</mo><mo id="S2.E2.m1.1.2.7" lspace="0.0835em" rspace="0.167em">.</mo><mo id="S2.E2.m1.1.2.8">,</mo><msub id="S2.E2.m1.1.2.9"><mi id="S2.E2.m1.1.2.9.2">x</mi><mi id="S2.E2.m1.1.2.9.3">t</mi></msub><mo id="S2.E2.m1.1.2.10" stretchy="false">)</mo></mrow><mo id="S2.E2.m1.1.3" rspace="0.111em">=</mo><munderover id="S2.E2.m1.1.4"><mo id="S2.E2.m1.1.4.2.2" movablelimits="false">∏</mo><mrow id="S2.E2.m1.1.4.2.3"><msup id="S2.E2.m1.1.4.2.3.2"><mi id="S2.E2.m1.1.4.2.3.2.2">t</mi><mo id="S2.E2.m1.1.4.2.3.2.3">′</mo></msup><mo id="S2.E2.m1.1.4.2.3.1">=</mo><mn id="S2.E2.m1.1.4.2.3.3">1</mn></mrow><mi id="S2.E2.m1.1.4.3">t</mi></munderover><mi id="S2.E2.m1.1.5">p</mi><mrow id="S2.E2.m1.1.6"><mo id="S2.E2.m1.1.6.1" stretchy="false">(</mo><msub id="S2.E2.m1.1.6.2"><mi id="S2.E2.m1.1.6.2.2">x</mi><msup id="S2.E2.m1.1.6.2.3"><mi id="S2.E2.m1.1.6.2.3.2">t</mi><mo id="S2.E2.m1.1.6.2.3.3">′</mo></msup></msub><mo fence="false" id="S2.E2.m1.1.6.3" rspace="0.167em" stretchy="false">|</mo><msub id="S2.E2.m1.1.6.4"><mi id="S2.E2.m1.1.6.4.2">x</mi><mrow id="S2.E2.m1.1.6.4.3"><mi id="S2.E2.m1.1.6.4.3.2"></mi><mo id="S2.E2.m1.1.6.4.3.1">&lt;</mo><msup id="S2.E2.m1.1.6.4.3.3"><mi id="S2.E2.m1.1.6.4.3.3.2">t</mi><mo id="S2.E2.m1.1.6.4.3.3.3">′</mo></msup></mrow></msub><mo id="S2.E2.m1.1.6.5" stretchy="false">)</mo></mrow><mo id="S2.E2.m1.1.7">=</mo><mtext class="ltx_mathvariant_monospace" id="S2.E2.m1.1.8">LLM</mtext><mrow id="S2.E2.m1.1.9"><mo id="S2.E2.m1.1.9.1" stretchy="false">(</mo><msub id="S2.E2.m1.1.9.2"><mi id="S2.E2.m1.1.9.2.2">x</mi><mrow id="S2.E2.m1.1.9.2.3"><mi id="S2.E2.m1.1.9.2.3.2"></mi><mo id="S2.E2.m1.1.9.2.3.1">&lt;</mo><mi id="S2.E2.m1.1.9.2.3.3">t</mi></mrow></msub><mo id="S2.E2.m1.1.9.3">,</mo><mi id="S2.E2.m1.1.9.4">l</mi><mo id="S2.E2.m1.1.9.5" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S2.E2.m1.1c">p(x_{t+1}|x_{1},..,x_{t})=\prod_{t^{\prime}=1}^{t}p(x_{t^{\prime}}|x_{&lt;t^{%
\prime}})\\
=\texttt{LLM}(x_{&lt;t},l)</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , . . , italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = ∏ start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_p ( italic_x start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT &lt; italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) = LLM ( italic_x start_POSTSUBSCRIPT &lt; italic_t end_POSTSUBSCRIPT , italic_l )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px2.p1.1.1">where </span><math alttext="x\in\mathcal{X}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="S2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">x</mi><mo id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1"><in id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1"></in><ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.1.m1.1c">x\in\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.1.m1.1d">italic_x ∈ caligraphic_X</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px2.p1.1.2"> are token variables taken from a valid vocabulary. The suitability of LLMs for solving RL tasks without additional fine-tuning primarily hinges on the hypothesis that LLMs contain information – i.e., </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.3">knowledge</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px2.p1.1.4"> – about the underlying MDP, for instance, through the policy or reward function.
</span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.5">How</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS0.SSS0.Px2.p1.1.6"> that information is extracted depends on the data the LLM was trained on, the ability of the practitioner to properly prompt the model and interpret its responses to solve decision-making tasks.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S2.SS1.1.1.1">2.1</span> </span>Prompting</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS1.p1.1.1">In this section, we describe the inputs, or </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S2.SS1.p1.1.2">prompts</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS1.p1.1.3">, to the LLM used in this work which allow to change the LLM’s output distribution to be useful for solving RL tasks.
All prompts in this work use 1) task specification using natural language as input to provide information about the MDP to the LLM as context and 2) episode history in order to address issues of partial-observability in some environments </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS1.p1.1.4.1">(similar to the Act-only baseline prompt found in </span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yao et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS1.p1.1.5.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib63" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS1.p1.1.6.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS1.p1.1.7">. We additionally use the following set of techniques,</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Chain of Thought</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i1.p1.1.2">. By prompting the LLM to provide a step-by-step reasoning process for its output, rather than just the final answer, we can help surface its internal decision-making and improve the resulting performance </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i1.p1.1.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Wei et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i1.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib61" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i1.p1.1.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i1.p1.1.6">.</span></p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">In-Context Learning</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i2.p1.1.2">. To enhance the LLM’s ability to solve the task, example solutions (e.g., from expert policies) are provided for in-context learning </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i2.p1.1.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Brown et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i2.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib8" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2020</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i2.p1.1.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i2.p1.1.6">, where solutions contain sequences of a combination of states, actions, and rewards.</span></p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Self-Refinement</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.2">. To further refine its output, the LLM is prompted to provide recursive criticism and improvement from its generated outputs. This general strategy knows many variants, such as feedback from an environment </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yao et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib63" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.6">, self-critique </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.7.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Zelikman et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.8.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib68" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.9.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.10">, or self-reflection </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.11.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Shinn et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.12.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib46" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.13.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.14">. In this work, we use Recursive Criticism and Improvement </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.15.1">(RCI, </span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Kim et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.16.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib22" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.17.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I1.i3.p1.1.18"> for its state-of-the-art performance on web agent domains and general applicability.
In its original form, the LLM is given a task description and generates a high-level plan. This plan is used along with the task description and current state to refine an action so that it is grounded in the current observation and the action space.</span></p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S2.SS2.1.1.1">2.2</span> </span>Policy Modeling Using LLMs</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.1">As shown in Equation </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S2.E1" title="Equation 1 ‣ Reinforcement Learning. ‣ 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.2">, the goal of a decision making agent is to learn a high performing policy </span><math alttext="\pi" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.1"><semantics id="S2.SS2.p1.1.m1.1a"><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.1d">italic_π</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.3">. This can be done either by maximizing the expected cumulative rewards and directly modeling the policy parameters </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.4.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Sutton et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.5.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib51" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">1999</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Kakade &amp; Langford</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.5.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib20" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2002</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.6.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.7">. Equivalently, this can be done indirectly by first modeling the parameters of the value function and applying a greedy operator, such as in Q-Learning </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.8.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Watkins &amp; Dayan</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.9.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib60" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">1992</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.10.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.p1.1.11">. A similar separation between direct and indirect approaches can be useful to study the capabilities of LLMs to model RL policies.</span></p>
</div>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_paragraph">Direct Policy Modeling.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.3"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.1">The most straightforward way to obtain a policy using LLMs is for the LLM to generate tokens that will be directly interpreted as actions from the environment, </span><math alttext="a\in\mathcal{A}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px1.p1.1.m1.1a"><mrow id="S2.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">a</mi><mo id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml">𝒜</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1"><in id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.1"></in><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2">𝑎</ci><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3">𝒜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.1.m1.1c">a\in\mathcal{A}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.1.m1.1d">italic_a ∈ caligraphic_A</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.2"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yao et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib63" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Shinn et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib46" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Kim et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib22" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.6">. To ensure the outputted actions adhere to the environment’s action set, the LLM output tokens can be projected back onto </span><math alttext="\mathcal{A}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S2.SS2.SSS0.Px1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.2.m2.1b"><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.2.m2.1c">\mathcal{A}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.2.m2.1d">caligraphic_A</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.7"> using projection operator </span><math alttext="\text{proj}(\cdot,\mathcal{A})" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.3.m3.2"><semantics id="S2.SS2.SSS0.Px1.p1.3.m3.2a"><mrow id="S2.SS2.SSS0.Px1.p1.3.m3.2.3" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.cmml"><mtext class="ltx_mathvariant_bold-sans-serif" id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.2" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.2a.cmml">proj</mtext><mo id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.1" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.1.cmml">⁢</mo><mrow id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.3.2" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.3.1.cmml"><mo id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.3.2.1" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.3.1.cmml">(</mo><mo id="S2.SS2.SSS0.Px1.p1.3.m3.1.1" lspace="0em" rspace="0em" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">⋅</mo><mo id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.3.2.2" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.3.m3.2.2" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.2.cmml">𝒜</mi><mo id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.3.2.3" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.3.m3.2b"><apply id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3"><times id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.1"></times><ci id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.2a.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.2"><mtext class="ltx_mathvariant_bold-sans-serif" id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.2">proj</mtext></ci><interval closure="open" id="S2.SS2.SSS0.Px1.p1.3.m3.2.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.3.3.2"><ci id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1">⋅</ci><ci id="S2.SS2.SSS0.Px1.p1.3.m3.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.2">𝒜</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.3.m3.2c">\text{proj}(\cdot,\mathcal{A})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.3.m3.2d">proj ( ⋅ , caligraphic_A )</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.8"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.9.1">(e.g., see </span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Huang et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.10.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib17" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Kim et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.10.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib22" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.11.3">, for examples of projection operators)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.12">. A variety of prompting techniques can be combined to increase the ability of the LLM to act, without task-specific fine-tuning, as a policy, which we detail in Section </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S2.SS1" title="2.1 Prompting ‣ 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">2.1</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px1.p1.3.13">. This direct policy method will be referred to in our experiments as LLM Policy.</span></p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_paragraph">Indirect Policy Modeling.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.1">On the other hand, we can prompt the LLM to output tokens representing intermediate quantities that will then be used to learn a policy. For example, one can model the forward dynamics of the environment for planning </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Liu et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib32" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024b</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.5">, or an affordance model for action selection </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.6.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Mullen Jr &amp; Manocha</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.7.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib37" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.8.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.9">.
In this work, we focus on the case where these intermediate quantities will be used to generate rewards – i.e., a reward model – which will then be maximized by an off-the-shelf RL policy.
In Section </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S2.SS3" title="2.3 Indirectly Modeling Policies through Reward Models ‣ 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">2.3</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.10">, we enumerate the different approaches for modeling reward functions with LLMs covered in our work.
</span><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup>It is important to note that there exists many more ways in which we could indirectly model the policy.
In Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS4" title="A.4 Additional Indirect Policy Modeling Methods ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.4</span></a>, we present in detail these possibilities and, in <a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#S3.F2.sf2" title="In Figure 2 ‣ 3 Performance of Indirect and Direct Policy Models ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2(b)</span></a>, provide initial investigations that showcase their potential and limitations.</span></span></span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p1.1.11"></span></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p2.1.1">In direct policy modeling experiments (LLM Policy), we found combining all of the prompting techniques in Section </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S2.SS1" title="2.1 Prompting ‣ 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">2.1</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p2.1.2"> to work the best, while for indirect modeling methods through reward we relied only on chain-of-thought prompting. Additional details, such specific prompt details and ablations on these choices are presented in the Appendix </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.SS3" title="A.3 Details on Direct Policy Modeling ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.3</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS2.SSS0.Px2.p2.1.3">.</span></p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S2.SS3.1.1.1">2.3</span> </span>Indirectly Modeling Policies through Reward Models</h3>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS3.p1.1.1">We consider a diversity of methods for modeling reward functions using LLMs, with a particular attention to methods that are applicable to a diversity of environments and modalities. We study the following set,</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<ul class="ltx_itemize" id="S2.I2">
<li class="ltx_item" id="S2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I2.i1.p1">
<p class="ltx_p" id="S2.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i1.p1.1.1">Direct Scalar</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i1.p1.1.2">. 
The LLM generates tokens that directly encode the reward (e.g., as a float or integer) given an observation (or a sequence of observations and actions). This reward is then given to the RL agent.</span></p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I2.i2.p1">
<p class="ltx_p" id="S2.I2.i2.p1.4"><span class="ltx_text ltx_font_bold" id="S2.I2.i2.p1.4.1">AI Feedback</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.4.2">  </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.4.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Lee et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.4.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib27" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Klissarov et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.4.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib23" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.4.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.4.6">.
Ask the LLM to express a preference </span><math alttext="y=\{1,2,\varnothing\}" class="ltx_Math" display="inline" id="S2.I2.i2.p1.1.m1.3"><semantics id="S2.I2.i2.p1.1.m1.3a"><mrow id="S2.I2.i2.p1.1.m1.3.4" xref="S2.I2.i2.p1.1.m1.3.4.cmml"><mi id="S2.I2.i2.p1.1.m1.3.4.2" xref="S2.I2.i2.p1.1.m1.3.4.2.cmml">y</mi><mo id="S2.I2.i2.p1.1.m1.3.4.1" xref="S2.I2.i2.p1.1.m1.3.4.1.cmml">=</mo><mrow id="S2.I2.i2.p1.1.m1.3.4.3.2" xref="S2.I2.i2.p1.1.m1.3.4.3.1.cmml"><mo id="S2.I2.i2.p1.1.m1.3.4.3.2.1" stretchy="false" xref="S2.I2.i2.p1.1.m1.3.4.3.1.cmml">{</mo><mn id="S2.I2.i2.p1.1.m1.1.1" xref="S2.I2.i2.p1.1.m1.1.1.cmml">1</mn><mo id="S2.I2.i2.p1.1.m1.3.4.3.2.2" xref="S2.I2.i2.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="S2.I2.i2.p1.1.m1.2.2" xref="S2.I2.i2.p1.1.m1.2.2.cmml">2</mn><mo id="S2.I2.i2.p1.1.m1.3.4.3.2.3" xref="S2.I2.i2.p1.1.m1.3.4.3.1.cmml">,</mo><mi id="S2.I2.i2.p1.1.m1.3.3" mathvariant="normal" xref="S2.I2.i2.p1.1.m1.3.3.cmml">∅</mi><mo id="S2.I2.i2.p1.1.m1.3.4.3.2.4" stretchy="false" xref="S2.I2.i2.p1.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i2.p1.1.m1.3b"><apply id="S2.I2.i2.p1.1.m1.3.4.cmml" xref="S2.I2.i2.p1.1.m1.3.4"><eq id="S2.I2.i2.p1.1.m1.3.4.1.cmml" xref="S2.I2.i2.p1.1.m1.3.4.1"></eq><ci id="S2.I2.i2.p1.1.m1.3.4.2.cmml" xref="S2.I2.i2.p1.1.m1.3.4.2">𝑦</ci><set id="S2.I2.i2.p1.1.m1.3.4.3.1.cmml" xref="S2.I2.i2.p1.1.m1.3.4.3.2"><cn id="S2.I2.i2.p1.1.m1.1.1.cmml" type="integer" xref="S2.I2.i2.p1.1.m1.1.1">1</cn><cn id="S2.I2.i2.p1.1.m1.2.2.cmml" type="integer" xref="S2.I2.i2.p1.1.m1.2.2">2</cn><emptyset id="S2.I2.i2.p1.1.m1.3.3.cmml" xref="S2.I2.i2.p1.1.m1.3.3"></emptyset></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i2.p1.1.m1.3c">y=\{1,2,\varnothing\}</annotation><annotation encoding="application/x-llamapun" id="S2.I2.i2.p1.1.m1.3d">italic_y = { 1 , 2 , ∅ }</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.4.7"> between two observations, </span><math alttext="o_{1}" class="ltx_Math" display="inline" id="S2.I2.i2.p1.2.m2.1"><semantics id="S2.I2.i2.p1.2.m2.1a"><msub id="S2.I2.i2.p1.2.m2.1.1" xref="S2.I2.i2.p1.2.m2.1.1.cmml"><mi id="S2.I2.i2.p1.2.m2.1.1.2" xref="S2.I2.i2.p1.2.m2.1.1.2.cmml">o</mi><mn id="S2.I2.i2.p1.2.m2.1.1.3" xref="S2.I2.i2.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.I2.i2.p1.2.m2.1b"><apply id="S2.I2.i2.p1.2.m2.1.1.cmml" xref="S2.I2.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.2.m2.1.1.1.cmml" xref="S2.I2.i2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I2.i2.p1.2.m2.1.1.2.cmml" xref="S2.I2.i2.p1.2.m2.1.1.2">𝑜</ci><cn id="S2.I2.i2.p1.2.m2.1.1.3.cmml" type="integer" xref="S2.I2.i2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i2.p1.2.m2.1c">o_{1}</annotation><annotation encoding="application/x-llamapun" id="S2.I2.i2.p1.2.m2.1d">italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.4.8"> and </span><math alttext="o_{2}" class="ltx_Math" display="inline" id="S2.I2.i2.p1.3.m3.1"><semantics id="S2.I2.i2.p1.3.m3.1a"><msub id="S2.I2.i2.p1.3.m3.1.1" xref="S2.I2.i2.p1.3.m3.1.1.cmml"><mi id="S2.I2.i2.p1.3.m3.1.1.2" xref="S2.I2.i2.p1.3.m3.1.1.2.cmml">o</mi><mn id="S2.I2.i2.p1.3.m3.1.1.3" xref="S2.I2.i2.p1.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.I2.i2.p1.3.m3.1b"><apply id="S2.I2.i2.p1.3.m3.1.1.cmml" xref="S2.I2.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.3.m3.1.1.1.cmml" xref="S2.I2.i2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I2.i2.p1.3.m3.1.1.2.cmml" xref="S2.I2.i2.p1.3.m3.1.1.2">𝑜</ci><cn id="S2.I2.i2.p1.3.m3.1.1.3.cmml" type="integer" xref="S2.I2.i2.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i2.p1.3.m3.1c">o_{2}</annotation><annotation encoding="application/x-llamapun" id="S2.I2.i2.p1.3.m3.1d">italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.4.9">, for the one showing the most progress towards a certain goal, or no preference if both observations are equally good. These labels can then be collected as a dataset of observation-preference tuples </span><math alttext="\mathcal{D}_{\text{pref}}=\{(o_{1}^{(i)},o_{2}^{(i)},y^{(i)})\}_{i=1}^{M}" class="ltx_Math" display="inline" id="S2.I2.i2.p1.4.m4.4"><semantics id="S2.I2.i2.p1.4.m4.4a"><mrow id="S2.I2.i2.p1.4.m4.4.4" xref="S2.I2.i2.p1.4.m4.4.4.cmml"><msub id="S2.I2.i2.p1.4.m4.4.4.3" xref="S2.I2.i2.p1.4.m4.4.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I2.i2.p1.4.m4.4.4.3.2" xref="S2.I2.i2.p1.4.m4.4.4.3.2.cmml">𝒟</mi><mtext class="ltx_mathvariant_bold-sans-serif" id="S2.I2.i2.p1.4.m4.4.4.3.3" xref="S2.I2.i2.p1.4.m4.4.4.3.3a.cmml">pref</mtext></msub><mo id="S2.I2.i2.p1.4.m4.4.4.2" xref="S2.I2.i2.p1.4.m4.4.4.2.cmml">=</mo><msubsup id="S2.I2.i2.p1.4.m4.4.4.1" xref="S2.I2.i2.p1.4.m4.4.4.1.cmml"><mrow id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.2.cmml"><mo id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.2" stretchy="false" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.2.cmml">{</mo><mrow id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.4.cmml"><mo id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.4" stretchy="false" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.4.cmml">(</mo><msubsup id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.cmml"><mi id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.2.2" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.2.2.cmml">o</mi><mn id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.2.3" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.2.3.cmml">1</mn><mrow id="S2.I2.i2.p1.4.m4.1.1.1.3" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.cmml"><mo id="S2.I2.i2.p1.4.m4.1.1.1.3.1" stretchy="false" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.cmml">(</mo><mi id="S2.I2.i2.p1.4.m4.1.1.1.1" xref="S2.I2.i2.p1.4.m4.1.1.1.1.cmml">i</mi><mo id="S2.I2.i2.p1.4.m4.1.1.1.3.2" stretchy="false" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.5" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.4.cmml">,</mo><msubsup id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.cmml"><mi id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.2.2" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.2.2.cmml">o</mi><mn id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.2.3" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.2.3.cmml">2</mn><mrow id="S2.I2.i2.p1.4.m4.2.2.1.3" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.cmml"><mo id="S2.I2.i2.p1.4.m4.2.2.1.3.1" stretchy="false" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.cmml">(</mo><mi id="S2.I2.i2.p1.4.m4.2.2.1.1" xref="S2.I2.i2.p1.4.m4.2.2.1.1.cmml">i</mi><mo id="S2.I2.i2.p1.4.m4.2.2.1.3.2" stretchy="false" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.cmml">)</mo></mrow></msubsup><mo id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.6" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.4.cmml">,</mo><msup id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3.cmml"><mi id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3.2" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3.2.cmml">y</mi><mrow id="S2.I2.i2.p1.4.m4.3.3.1.3" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3.cmml"><mo id="S2.I2.i2.p1.4.m4.3.3.1.3.1" stretchy="false" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3.cmml">(</mo><mi id="S2.I2.i2.p1.4.m4.3.3.1.1" xref="S2.I2.i2.p1.4.m4.3.3.1.1.cmml">i</mi><mo id="S2.I2.i2.p1.4.m4.3.3.1.3.2" stretchy="false" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3.cmml">)</mo></mrow></msup><mo id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.7" stretchy="false" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.4.cmml">)</mo></mrow><mo id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.3" stretchy="false" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.I2.i2.p1.4.m4.4.4.1.1.3" xref="S2.I2.i2.p1.4.m4.4.4.1.1.3.cmml"><mi id="S2.I2.i2.p1.4.m4.4.4.1.1.3.2" xref="S2.I2.i2.p1.4.m4.4.4.1.1.3.2.cmml">i</mi><mo id="S2.I2.i2.p1.4.m4.4.4.1.1.3.1" xref="S2.I2.i2.p1.4.m4.4.4.1.1.3.1.cmml">=</mo><mn id="S2.I2.i2.p1.4.m4.4.4.1.1.3.3" xref="S2.I2.i2.p1.4.m4.4.4.1.1.3.3.cmml">1</mn></mrow><mi id="S2.I2.i2.p1.4.m4.4.4.1.3" xref="S2.I2.i2.p1.4.m4.4.4.1.3.cmml">M</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i2.p1.4.m4.4b"><apply id="S2.I2.i2.p1.4.m4.4.4.cmml" xref="S2.I2.i2.p1.4.m4.4.4"><eq id="S2.I2.i2.p1.4.m4.4.4.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.2"></eq><apply id="S2.I2.i2.p1.4.m4.4.4.3.cmml" xref="S2.I2.i2.p1.4.m4.4.4.3"><csymbol cd="ambiguous" id="S2.I2.i2.p1.4.m4.4.4.3.1.cmml" xref="S2.I2.i2.p1.4.m4.4.4.3">subscript</csymbol><ci id="S2.I2.i2.p1.4.m4.4.4.3.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.3.2">𝒟</ci><ci id="S2.I2.i2.p1.4.m4.4.4.3.3a.cmml" xref="S2.I2.i2.p1.4.m4.4.4.3.3"><mtext class="ltx_mathvariant_bold-sans-serif" id="S2.I2.i2.p1.4.m4.4.4.3.3.cmml" mathsize="70%" xref="S2.I2.i2.p1.4.m4.4.4.3.3">pref</mtext></ci></apply><apply id="S2.I2.i2.p1.4.m4.4.4.1.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.4.m4.4.4.1.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1">superscript</csymbol><apply id="S2.I2.i2.p1.4.m4.4.4.1.1.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.4.m4.4.4.1.1.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1">subscript</csymbol><set id="S2.I2.i2.p1.4.m4.4.4.1.1.1.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1"><vector id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.4.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3"><apply id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.1.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.2.1.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.2.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.2.2">𝑜</ci><cn id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.2.3.cmml" type="integer" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.1.1.2.3">1</cn></apply><ci id="S2.I2.i2.p1.4.m4.1.1.1.1.cmml" xref="S2.I2.i2.p1.4.m4.1.1.1.1">𝑖</ci></apply><apply id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.1.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2">superscript</csymbol><apply id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.2.1.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.2.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.2.2">𝑜</ci><cn id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.2.3.cmml" type="integer" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.2.2.2.3">2</cn></apply><ci id="S2.I2.i2.p1.4.m4.2.2.1.1.cmml" xref="S2.I2.i2.p1.4.m4.2.2.1.1">𝑖</ci></apply><apply id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3.1.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3">superscript</csymbol><ci id="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.1.1.1.3.3.2">𝑦</ci><ci id="S2.I2.i2.p1.4.m4.3.3.1.1.cmml" xref="S2.I2.i2.p1.4.m4.3.3.1.1">𝑖</ci></apply></vector></set><apply id="S2.I2.i2.p1.4.m4.4.4.1.1.3.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.3"><eq id="S2.I2.i2.p1.4.m4.4.4.1.1.3.1.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.3.1"></eq><ci id="S2.I2.i2.p1.4.m4.4.4.1.1.3.2.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.1.3.2">𝑖</ci><cn id="S2.I2.i2.p1.4.m4.4.4.1.1.3.3.cmml" type="integer" xref="S2.I2.i2.p1.4.m4.4.4.1.1.3.3">1</cn></apply></apply><ci id="S2.I2.i2.p1.4.m4.4.4.1.3.cmml" xref="S2.I2.i2.p1.4.m4.4.4.1.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i2.p1.4.m4.4c">\mathcal{D}_{\text{pref}}=\{(o_{1}^{(i)},o_{2}^{(i)},y^{(i)})\}_{i=1}^{M}</annotation><annotation encoding="application/x-llamapun" id="S2.I2.i2.p1.4.m4.4d">caligraphic_D start_POSTSUBSCRIPT pref end_POSTSUBSCRIPT = { ( italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ) } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.4.10">, which are then used to train a reward function modeled as,</span></p>
<table class="ltx_equation ltx_eqn_table" id="S2.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\begin{split}r_{\theta}=\operatorname*{arg\,min}_{\theta}\mathbb{E}_{(o_{1},o_%
{2},y)\sim\mathcal{D}_{\text{pref}}}\bigg{[}&amp;\mathbb{I}[y=1]\log P_{\theta}[o_%
{1}\succ o_{2}]+\mathbb{I}[y=2]P_{\theta}[o_{2}\succ o_{1}]\\
&amp;+\frac{1}{2}\mathbb{I}[y=\varnothing]\log\big{(}P_{\theta}[o_{1}\succ o_{2}]P%
[o_{2}\succ o_{1}]\big{)}\bigg{]}\end{split}" class="ltx_Math" display="block" id="S2.E3.m1.74"><semantics id="S2.E3.m1.74a"><mtable columnspacing="0pt" displaystyle="true" id="S2.E3.m1.74.74.5" rowspacing="0pt" xref="S2.E3.m1.70.70.1.cmml"><mtr id="S2.E3.m1.74.74.5a" xref="S2.E3.m1.70.70.1.cmml"><mtd class="ltx_align_right" columnalign="right" id="S2.E3.m1.74.74.5b" xref="S2.E3.m1.70.70.1.cmml"><mrow id="S2.E3.m1.8.8.8.8.8" xref="S2.E3.m1.70.70.1.cmml"><msub id="S2.E3.m1.8.8.8.8.8.9" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.cmml">r</mi><mi id="S2.E3.m1.2.2.2.2.2.2.1" xref="S2.E3.m1.2.2.2.2.2.2.1.cmml">θ</mi></msub><mo id="S2.E3.m1.3.3.3.3.3.3" xref="S2.E3.m1.3.3.3.3.3.3.cmml">=</mo><munder id="S2.E3.m1.8.8.8.8.8.10" xref="S2.E3.m1.70.70.1.cmml"><mrow id="S2.E3.m1.4.4.4.4.4.4" xref="S2.E3.m1.4.4.4.4.4.4.cmml"><mi id="S2.E3.m1.4.4.4.4.4.4.2" xref="S2.E3.m1.4.4.4.4.4.4.2.cmml">arg</mi><mo id="S2.E3.m1.4.4.4.4.4.4.1" lspace="0.170em" xref="S2.E3.m1.4.4.4.4.4.4.1.cmml">⁢</mo><mi id="S2.E3.m1.4.4.4.4.4.4.3" xref="S2.E3.m1.4.4.4.4.4.4.3.cmml">min</mi></mrow><mi id="S2.E3.m1.5.5.5.5.5.5.1" xref="S2.E3.m1.5.5.5.5.5.5.1.cmml">θ</mi></munder><msub id="S2.E3.m1.8.8.8.8.8.11" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.6.6.6.6.6.6" xref="S2.E3.m1.6.6.6.6.6.6.cmml">𝔼</mi><mrow id="S2.E3.m1.7.7.7.7.7.7.1" xref="S2.E3.m1.7.7.7.7.7.7.1.cmml"><mrow id="S2.E3.m1.7.7.7.7.7.7.1.3.2" xref="S2.E3.m1.7.7.7.7.7.7.1.3.3.cmml"><mo id="S2.E3.m1.7.7.7.7.7.7.1.3.2.3" stretchy="false" xref="S2.E3.m1.7.7.7.7.7.7.1.3.3.cmml">(</mo><msub id="S2.E3.m1.7.7.7.7.7.7.1.2.1.1" xref="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.cmml"><mi id="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.2" xref="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.2.cmml">o</mi><mn id="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.3" xref="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.3.cmml">1</mn></msub><mo id="S2.E3.m1.7.7.7.7.7.7.1.3.2.4" xref="S2.E3.m1.7.7.7.7.7.7.1.3.3.cmml">,</mo><msub id="S2.E3.m1.7.7.7.7.7.7.1.3.2.2" xref="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.cmml"><mi id="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.2" xref="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.2.cmml">o</mi><mn id="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.3" xref="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.3.cmml">2</mn></msub><mo id="S2.E3.m1.7.7.7.7.7.7.1.3.2.5" xref="S2.E3.m1.7.7.7.7.7.7.1.3.3.cmml">,</mo><mi id="S2.E3.m1.7.7.7.7.7.7.1.1" xref="S2.E3.m1.7.7.7.7.7.7.1.1.cmml">y</mi><mo id="S2.E3.m1.7.7.7.7.7.7.1.3.2.6" stretchy="false" xref="S2.E3.m1.7.7.7.7.7.7.1.3.3.cmml">)</mo></mrow><mo id="S2.E3.m1.7.7.7.7.7.7.1.4" xref="S2.E3.m1.7.7.7.7.7.7.1.4.cmml">∼</mo><msub id="S2.E3.m1.7.7.7.7.7.7.1.5" xref="S2.E3.m1.7.7.7.7.7.7.1.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.7.7.7.7.7.7.1.5.2" xref="S2.E3.m1.7.7.7.7.7.7.1.5.2.cmml">𝒟</mi><mtext class="ltx_mathvariant_bold-sans-serif" id="S2.E3.m1.7.7.7.7.7.7.1.5.3" xref="S2.E3.m1.7.7.7.7.7.7.1.5.3a.cmml">pref</mtext></msub></mrow></msub><mo id="S2.E3.m1.8.8.8.8.8.8" maxsize="210%" minsize="210%" xref="S2.E3.m1.70.70.1.cmml">[</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E3.m1.74.74.5c" xref="S2.E3.m1.70.70.1.cmml"><mrow id="S2.E3.m1.74.74.5.73.44.36" xref="S2.E3.m1.70.70.1.cmml"><mrow id="S2.E3.m1.72.72.3.71.42.34.34" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.9.9.9.9.1.1" xref="S2.E3.m1.9.9.9.9.1.1.cmml">𝕀</mi><mo id="S2.E3.m1.72.72.3.71.42.34.34.3" xref="S2.E3.m1.70.70.1.cmml">⁢</mo><mrow id="S2.E3.m1.71.71.2.70.41.33.33.1.1" xref="S2.E3.m1.70.70.1.cmml"><mo id="S2.E3.m1.10.10.10.10.2.2" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">[</mo><mrow id="S2.E3.m1.71.71.2.70.41.33.33.1.1.1" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.11.11.11.11.3.3" xref="S2.E3.m1.11.11.11.11.3.3.cmml">y</mi><mo id="S2.E3.m1.12.12.12.12.4.4" xref="S2.E3.m1.12.12.12.12.4.4.cmml">=</mo><mn id="S2.E3.m1.13.13.13.13.5.5" xref="S2.E3.m1.13.13.13.13.5.5.cmml">1</mn></mrow><mo id="S2.E3.m1.14.14.14.14.6.6" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">]</mo></mrow><mo id="S2.E3.m1.72.72.3.71.42.34.34.3a" lspace="0.167em" xref="S2.E3.m1.70.70.1.cmml">⁢</mo><mrow id="S2.E3.m1.72.72.3.71.42.34.34.4" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.15.15.15.15.7.7" xref="S2.E3.m1.15.15.15.15.7.7.cmml">log</mi><mo id="S2.E3.m1.72.72.3.71.42.34.34.4a" lspace="0.167em" xref="S2.E3.m1.70.70.1.cmml">⁡</mo><msub id="S2.E3.m1.72.72.3.71.42.34.34.4.1" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.16.16.16.16.8.8" xref="S2.E3.m1.16.16.16.16.8.8.cmml">P</mi><mi id="S2.E3.m1.17.17.17.17.9.9.1" xref="S2.E3.m1.17.17.17.17.9.9.1.cmml">θ</mi></msub></mrow><mo id="S2.E3.m1.72.72.3.71.42.34.34.3b" xref="S2.E3.m1.70.70.1.cmml">⁢</mo><mrow id="S2.E3.m1.72.72.3.71.42.34.34.2.1" xref="S2.E3.m1.70.70.1.cmml"><mo id="S2.E3.m1.18.18.18.18.10.10" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">[</mo><mrow id="S2.E3.m1.72.72.3.71.42.34.34.2.1.1" xref="S2.E3.m1.70.70.1.cmml"><msub id="S2.E3.m1.72.72.3.71.42.34.34.2.1.1.1" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.19.19.19.19.11.11" xref="S2.E3.m1.19.19.19.19.11.11.cmml">o</mi><mn id="S2.E3.m1.20.20.20.20.12.12.1" xref="S2.E3.m1.20.20.20.20.12.12.1.cmml">1</mn></msub><mo id="S2.E3.m1.21.21.21.21.13.13" xref="S2.E3.m1.21.21.21.21.13.13.cmml">≻</mo><msub id="S2.E3.m1.72.72.3.71.42.34.34.2.1.1.2" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.22.22.22.22.14.14" xref="S2.E3.m1.22.22.22.22.14.14.cmml">o</mi><mn id="S2.E3.m1.23.23.23.23.15.15.1" xref="S2.E3.m1.23.23.23.23.15.15.1.cmml">2</mn></msub></mrow><mo id="S2.E3.m1.24.24.24.24.16.16" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">]</mo></mrow></mrow><mo id="S2.E3.m1.25.25.25.25.17.17" xref="S2.E3.m1.25.25.25.25.17.17.cmml">+</mo><mrow id="S2.E3.m1.74.74.5.73.44.36.36" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.26.26.26.26.18.18" xref="S2.E3.m1.26.26.26.26.18.18.cmml">𝕀</mi><mo id="S2.E3.m1.74.74.5.73.44.36.36.3" xref="S2.E3.m1.70.70.1.cmml">⁢</mo><mrow id="S2.E3.m1.73.73.4.72.43.35.35.1.1" xref="S2.E3.m1.70.70.1.cmml"><mo id="S2.E3.m1.27.27.27.27.19.19" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">[</mo><mrow id="S2.E3.m1.73.73.4.72.43.35.35.1.1.1" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.28.28.28.28.20.20" xref="S2.E3.m1.28.28.28.28.20.20.cmml">y</mi><mo id="S2.E3.m1.29.29.29.29.21.21" xref="S2.E3.m1.29.29.29.29.21.21.cmml">=</mo><mn id="S2.E3.m1.30.30.30.30.22.22" xref="S2.E3.m1.30.30.30.30.22.22.cmml">2</mn></mrow><mo id="S2.E3.m1.31.31.31.31.23.23" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">]</mo></mrow><mo id="S2.E3.m1.74.74.5.73.44.36.36.3a" xref="S2.E3.m1.70.70.1.cmml">⁢</mo><msub id="S2.E3.m1.74.74.5.73.44.36.36.4" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.32.32.32.32.24.24" xref="S2.E3.m1.32.32.32.32.24.24.cmml">P</mi><mi id="S2.E3.m1.33.33.33.33.25.25.1" xref="S2.E3.m1.33.33.33.33.25.25.1.cmml">θ</mi></msub><mo id="S2.E3.m1.74.74.5.73.44.36.36.3b" xref="S2.E3.m1.70.70.1.cmml">⁢</mo><mrow id="S2.E3.m1.74.74.5.73.44.36.36.2.1" xref="S2.E3.m1.70.70.1.cmml"><mo id="S2.E3.m1.34.34.34.34.26.26" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">[</mo><mrow id="S2.E3.m1.74.74.5.73.44.36.36.2.1.1" xref="S2.E3.m1.70.70.1.cmml"><msub id="S2.E3.m1.74.74.5.73.44.36.36.2.1.1.1" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.35.35.35.35.27.27" xref="S2.E3.m1.35.35.35.35.27.27.cmml">o</mi><mn id="S2.E3.m1.36.36.36.36.28.28.1" xref="S2.E3.m1.36.36.36.36.28.28.1.cmml">2</mn></msub><mo id="S2.E3.m1.37.37.37.37.29.29" xref="S2.E3.m1.37.37.37.37.29.29.cmml">≻</mo><msub id="S2.E3.m1.74.74.5.73.44.36.36.2.1.1.2" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.38.38.38.38.30.30" xref="S2.E3.m1.38.38.38.38.30.30.cmml">o</mi><mn id="S2.E3.m1.39.39.39.39.31.31.1" xref="S2.E3.m1.39.39.39.39.31.31.1.cmml">1</mn></msub></mrow><mo id="S2.E3.m1.40.40.40.40.32.32" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">]</mo></mrow></mrow></mrow></mtd></mtr><mtr id="S2.E3.m1.74.74.5d" xref="S2.E3.m1.70.70.1.cmml"><mtd id="S2.E3.m1.74.74.5e" xref="S2.E3.m1.70.70.1.cmml"></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E3.m1.74.74.5f" xref="S2.E3.m1.70.70.1.cmml"><mrow id="S2.E3.m1.69.69.69.29.29" xref="S2.E3.m1.70.70.1.cmml"><mo id="S2.E3.m1.41.41.41.1.1.1" xref="S2.E3.m1.70.70.1.cmml">+</mo><mfrac id="S2.E3.m1.42.42.42.2.2.2" xref="S2.E3.m1.42.42.42.2.2.2.cmml"><mn id="S2.E3.m1.42.42.42.2.2.2.2" xref="S2.E3.m1.42.42.42.2.2.2.2.cmml">1</mn><mn id="S2.E3.m1.42.42.42.2.2.2.3" xref="S2.E3.m1.42.42.42.2.2.2.3.cmml">2</mn></mfrac><mi id="S2.E3.m1.43.43.43.3.3.3" xref="S2.E3.m1.43.43.43.3.3.3.cmml">𝕀</mi><mrow id="S2.E3.m1.69.69.69.29.29.30" xref="S2.E3.m1.70.70.1.cmml"><mo id="S2.E3.m1.44.44.44.4.4.4" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">[</mo><mi id="S2.E3.m1.45.45.45.5.5.5" xref="S2.E3.m1.45.45.45.5.5.5.cmml">y</mi><mo id="S2.E3.m1.46.46.46.6.6.6" xref="S2.E3.m1.46.46.46.6.6.6.cmml">=</mo><mi id="S2.E3.m1.47.47.47.7.7.7" mathvariant="normal" xref="S2.E3.m1.47.47.47.7.7.7.cmml">∅</mi><mo id="S2.E3.m1.48.48.48.8.8.8" rspace="0.167em" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">]</mo></mrow><mi id="S2.E3.m1.49.49.49.9.9.9" xref="S2.E3.m1.49.49.49.9.9.9.cmml">log</mi><mrow id="S2.E3.m1.69.69.69.29.29.31" xref="S2.E3.m1.70.70.1.cmml"><mo id="S2.E3.m1.50.50.50.10.10.10" maxsize="120%" minsize="120%" xref="S2.E3.m1.70.70.1.cmml">(</mo><msub id="S2.E3.m1.69.69.69.29.29.31.1" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.51.51.51.11.11.11" xref="S2.E3.m1.51.51.51.11.11.11.cmml">P</mi><mi id="S2.E3.m1.52.52.52.12.12.12.1" xref="S2.E3.m1.52.52.52.12.12.12.1.cmml">θ</mi></msub><mrow id="S2.E3.m1.69.69.69.29.29.31.2" xref="S2.E3.m1.70.70.1.cmml"><mo id="S2.E3.m1.53.53.53.13.13.13" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">[</mo><msub id="S2.E3.m1.69.69.69.29.29.31.2.1" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.54.54.54.14.14.14" xref="S2.E3.m1.54.54.54.14.14.14.cmml">o</mi><mn id="S2.E3.m1.55.55.55.15.15.15.1" xref="S2.E3.m1.55.55.55.15.15.15.1.cmml">1</mn></msub><mo id="S2.E3.m1.56.56.56.16.16.16" xref="S2.E3.m1.56.56.56.16.16.16.cmml">≻</mo><msub id="S2.E3.m1.69.69.69.29.29.31.2.2" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.57.57.57.17.17.17" xref="S2.E3.m1.57.57.57.17.17.17.cmml">o</mi><mn id="S2.E3.m1.58.58.58.18.18.18.1" xref="S2.E3.m1.58.58.58.18.18.18.1.cmml">2</mn></msub><mo id="S2.E3.m1.59.59.59.19.19.19" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">]</mo></mrow><mi id="S2.E3.m1.60.60.60.20.20.20" xref="S2.E3.m1.60.60.60.20.20.20.cmml">P</mi><mrow id="S2.E3.m1.69.69.69.29.29.31.3" xref="S2.E3.m1.70.70.1.cmml"><mo id="S2.E3.m1.61.61.61.21.21.21" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">[</mo><msub id="S2.E3.m1.69.69.69.29.29.31.3.1" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.62.62.62.22.22.22" xref="S2.E3.m1.62.62.62.22.22.22.cmml">o</mi><mn id="S2.E3.m1.63.63.63.23.23.23.1" xref="S2.E3.m1.63.63.63.23.23.23.1.cmml">2</mn></msub><mo id="S2.E3.m1.64.64.64.24.24.24" xref="S2.E3.m1.64.64.64.24.24.24.cmml">≻</mo><msub id="S2.E3.m1.69.69.69.29.29.31.3.2" xref="S2.E3.m1.70.70.1.cmml"><mi id="S2.E3.m1.65.65.65.25.25.25" xref="S2.E3.m1.65.65.65.25.25.25.cmml">o</mi><mn id="S2.E3.m1.66.66.66.26.26.26.1" xref="S2.E3.m1.66.66.66.26.26.26.1.cmml">1</mn></msub><mo id="S2.E3.m1.67.67.67.27.27.27" stretchy="false" xref="S2.E3.m1.70.70.1.cmml">]</mo></mrow><mo id="S2.E3.m1.68.68.68.28.28.28" maxsize="120%" minsize="120%" xref="S2.E3.m1.70.70.1.cmml">)</mo></mrow><mo id="S2.E3.m1.69.69.69.29.29.29" maxsize="210%" minsize="210%" xref="S2.E3.m1.70.70.1.cmml">]</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S2.E3.m1.74b"><apply id="S2.E3.m1.70.70.1.cmml" xref="S2.E3.m1.74.74.5"><eq id="S2.E3.m1.3.3.3.3.3.3.cmml" xref="S2.E3.m1.3.3.3.3.3.3"></eq><apply id="S2.E3.m1.70.70.1.3.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.3.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1">𝑟</ci><ci id="S2.E3.m1.2.2.2.2.2.2.1.cmml" xref="S2.E3.m1.2.2.2.2.2.2.1">𝜃</ci></apply><apply id="S2.E3.m1.70.70.1.1.cmml" xref="S2.E3.m1.74.74.5"><times id="S2.E3.m1.70.70.1.1.2.cmml" xref="S2.E3.m1.74.74.5"></times><apply id="S2.E3.m1.70.70.1.1.3.cmml" xref="S2.E3.m1.74.74.5"><apply id="S2.E3.m1.70.70.1.1.3.1.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.3.1.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><apply id="S2.E3.m1.4.4.4.4.4.4.cmml" xref="S2.E3.m1.4.4.4.4.4.4"><times id="S2.E3.m1.4.4.4.4.4.4.1.cmml" xref="S2.E3.m1.4.4.4.4.4.4.1"></times><ci id="S2.E3.m1.4.4.4.4.4.4.2.cmml" xref="S2.E3.m1.4.4.4.4.4.4.2">arg</ci><ci id="S2.E3.m1.4.4.4.4.4.4.3.cmml" xref="S2.E3.m1.4.4.4.4.4.4.3">min</ci></apply><ci id="S2.E3.m1.5.5.5.5.5.5.1.cmml" xref="S2.E3.m1.5.5.5.5.5.5.1">𝜃</ci></apply><apply id="S2.E3.m1.70.70.1.1.3.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.3.2.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.6.6.6.6.6.6.cmml" xref="S2.E3.m1.6.6.6.6.6.6">𝔼</ci><apply id="S2.E3.m1.7.7.7.7.7.7.1.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1"><csymbol cd="latexml" id="S2.E3.m1.7.7.7.7.7.7.1.4.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.4">similar-to</csymbol><vector id="S2.E3.m1.7.7.7.7.7.7.1.3.3.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.3.2"><apply id="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.2.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.1.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.2.1.1">subscript</csymbol><ci id="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.2.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.2">𝑜</ci><cn id="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.3.cmml" type="integer" xref="S2.E3.m1.7.7.7.7.7.7.1.2.1.1.3">1</cn></apply><apply id="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.3.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.1.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.3.2.2">subscript</csymbol><ci id="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.2.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.2">𝑜</ci><cn id="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.3.cmml" type="integer" xref="S2.E3.m1.7.7.7.7.7.7.1.3.2.2.3">2</cn></apply><ci id="S2.E3.m1.7.7.7.7.7.7.1.1.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.1">𝑦</ci></vector><apply id="S2.E3.m1.7.7.7.7.7.7.1.5.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.5"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.7.7.7.7.1.5.1.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.5">subscript</csymbol><ci id="S2.E3.m1.7.7.7.7.7.7.1.5.2.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.5.2">𝒟</ci><ci id="S2.E3.m1.7.7.7.7.7.7.1.5.3a.cmml" xref="S2.E3.m1.7.7.7.7.7.7.1.5.3"><mtext class="ltx_mathvariant_bold-sans-serif" id="S2.E3.m1.7.7.7.7.7.7.1.5.3.cmml" mathsize="50%" xref="S2.E3.m1.7.7.7.7.7.7.1.5.3">pref</mtext></ci></apply></apply></apply></apply><apply id="S2.E3.m1.70.70.1.1.1.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.70.70.1.1.1.2.1.cmml" xref="S2.E3.m1.74.74.5">delimited-[]</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.cmml" xref="S2.E3.m1.74.74.5"><plus id="S2.E3.m1.25.25.25.25.17.17.cmml" xref="S2.E3.m1.25.25.25.25.17.17"></plus><apply id="S2.E3.m1.70.70.1.1.1.1.1.2.cmml" xref="S2.E3.m1.74.74.5"><times id="S2.E3.m1.70.70.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.74.74.5"></times><ci id="S2.E3.m1.9.9.9.9.1.1.cmml" xref="S2.E3.m1.9.9.9.9.1.1">𝕀</ci><apply id="S2.E3.m1.70.70.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.70.70.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.74.74.5">delimited-[]</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.74.74.5"><eq id="S2.E3.m1.12.12.12.12.4.4.cmml" xref="S2.E3.m1.12.12.12.12.4.4"></eq><ci id="S2.E3.m1.11.11.11.11.3.3.cmml" xref="S2.E3.m1.11.11.11.11.3.3">𝑦</ci><cn id="S2.E3.m1.13.13.13.13.5.5.cmml" type="integer" xref="S2.E3.m1.13.13.13.13.5.5">1</cn></apply></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.2.5.cmml" xref="S2.E3.m1.74.74.5"><log id="S2.E3.m1.15.15.15.15.7.7.cmml" xref="S2.E3.m1.15.15.15.15.7.7"></log><apply id="S2.E3.m1.70.70.1.1.1.1.1.2.5.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.2.5.2.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.16.16.16.16.8.8.cmml" xref="S2.E3.m1.16.16.16.16.8.8">𝑃</ci><ci id="S2.E3.m1.17.17.17.17.9.9.1.cmml" xref="S2.E3.m1.17.17.17.17.9.9.1">𝜃</ci></apply></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.70.70.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E3.m1.74.74.5">delimited-[]</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.2.2.1.1.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.21.21.21.21.13.13.cmml" xref="S2.E3.m1.21.21.21.21.13.13">succeeds</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.2.2.1.1.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.2.2.1.1.2.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.19.19.19.19.11.11.cmml" xref="S2.E3.m1.19.19.19.19.11.11">𝑜</ci><cn id="S2.E3.m1.20.20.20.20.12.12.1.cmml" type="integer" xref="S2.E3.m1.20.20.20.20.12.12.1">1</cn></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.2.2.1.1.3.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.2.2.1.1.3.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.22.22.22.22.14.14.cmml" xref="S2.E3.m1.22.22.22.22.14.14">𝑜</ci><cn id="S2.E3.m1.23.23.23.23.15.15.1.cmml" type="integer" xref="S2.E3.m1.23.23.23.23.15.15.1">2</cn></apply></apply></apply></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.4.cmml" xref="S2.E3.m1.74.74.5"><times id="S2.E3.m1.70.70.1.1.1.1.1.4.3.cmml" xref="S2.E3.m1.74.74.5"></times><ci id="S2.E3.m1.26.26.26.26.18.18.cmml" xref="S2.E3.m1.26.26.26.26.18.18">𝕀</ci><apply id="S2.E3.m1.70.70.1.1.1.1.1.3.1.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.70.70.1.1.1.1.1.3.1.2.1.cmml" xref="S2.E3.m1.74.74.5">delimited-[]</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.3.1.1.1.cmml" xref="S2.E3.m1.74.74.5"><eq id="S2.E3.m1.29.29.29.29.21.21.cmml" xref="S2.E3.m1.29.29.29.29.21.21"></eq><ci id="S2.E3.m1.28.28.28.28.20.20.cmml" xref="S2.E3.m1.28.28.28.28.20.20">𝑦</ci><cn id="S2.E3.m1.30.30.30.30.22.22.cmml" type="integer" xref="S2.E3.m1.30.30.30.30.22.22">2</cn></apply></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.4.5.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.4.5.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.32.32.32.32.24.24.cmml" xref="S2.E3.m1.32.32.32.32.24.24">𝑃</ci><ci id="S2.E3.m1.33.33.33.33.25.25.1.cmml" xref="S2.E3.m1.33.33.33.33.25.25.1">𝜃</ci></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.4.2.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.70.70.1.1.1.1.1.4.2.2.1.cmml" xref="S2.E3.m1.74.74.5">delimited-[]</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.4.2.1.1.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.37.37.37.37.29.29.cmml" xref="S2.E3.m1.37.37.37.37.29.29">succeeds</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.4.2.1.1.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.4.2.1.1.2.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.35.35.35.35.27.27.cmml" xref="S2.E3.m1.35.35.35.35.27.27">𝑜</ci><cn id="S2.E3.m1.36.36.36.36.28.28.1.cmml" type="integer" xref="S2.E3.m1.36.36.36.36.28.28.1">2</cn></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.4.2.1.1.3.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.4.2.1.1.3.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.38.38.38.38.30.30.cmml" xref="S2.E3.m1.38.38.38.38.30.30">𝑜</ci><cn id="S2.E3.m1.39.39.39.39.31.31.1.cmml" type="integer" xref="S2.E3.m1.39.39.39.39.31.31.1">1</cn></apply></apply></apply></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.cmml" xref="S2.E3.m1.74.74.5"><times id="S2.E3.m1.70.70.1.1.1.1.1.6.3.cmml" xref="S2.E3.m1.74.74.5"></times><apply id="S2.E3.m1.42.42.42.2.2.2.cmml" xref="S2.E3.m1.42.42.42.2.2.2"><divide id="S2.E3.m1.42.42.42.2.2.2.1.cmml" xref="S2.E3.m1.42.42.42.2.2.2"></divide><cn id="S2.E3.m1.42.42.42.2.2.2.2.cmml" type="integer" xref="S2.E3.m1.42.42.42.2.2.2.2">1</cn><cn id="S2.E3.m1.42.42.42.2.2.2.3.cmml" type="integer" xref="S2.E3.m1.42.42.42.2.2.2.3">2</cn></apply><ci id="S2.E3.m1.43.43.43.3.3.3.cmml" xref="S2.E3.m1.43.43.43.3.3.3">𝕀</ci><apply id="S2.E3.m1.70.70.1.1.1.1.1.5.1.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.70.70.1.1.1.1.1.5.1.2.1.cmml" xref="S2.E3.m1.74.74.5">delimited-[]</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.5.1.1.1.cmml" xref="S2.E3.m1.74.74.5"><eq id="S2.E3.m1.46.46.46.6.6.6.cmml" xref="S2.E3.m1.46.46.46.6.6.6"></eq><ci id="S2.E3.m1.45.45.45.5.5.5.cmml" xref="S2.E3.m1.45.45.45.5.5.5">𝑦</ci><emptyset id="S2.E3.m1.47.47.47.7.7.7.cmml" xref="S2.E3.m1.47.47.47.7.7.7"></emptyset></apply></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.2.cmml" xref="S2.E3.m1.74.74.5"><log id="S2.E3.m1.49.49.49.9.9.9.cmml" xref="S2.E3.m1.49.49.49.9.9.9"></log><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.cmml" xref="S2.E3.m1.74.74.5"><times id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.3.cmml" xref="S2.E3.m1.74.74.5"></times><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.4.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.4.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.51.51.51.11.11.11.cmml" xref="S2.E3.m1.51.51.51.11.11.11">𝑃</ci><ci id="S2.E3.m1.52.52.52.12.12.12.1.cmml" xref="S2.E3.m1.52.52.52.12.12.12.1">𝜃</ci></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.1.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.1.2.1.cmml" xref="S2.E3.m1.74.74.5">delimited-[]</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.1.1.1.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.56.56.56.16.16.16.cmml" xref="S2.E3.m1.56.56.56.16.16.16">succeeds</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.54.54.54.14.14.14.cmml" xref="S2.E3.m1.54.54.54.14.14.14">𝑜</ci><cn id="S2.E3.m1.55.55.55.15.15.15.1.cmml" type="integer" xref="S2.E3.m1.55.55.55.15.15.15.1">1</cn></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.57.57.57.17.17.17.cmml" xref="S2.E3.m1.57.57.57.17.17.17">𝑜</ci><cn id="S2.E3.m1.58.58.58.18.18.18.1.cmml" type="integer" xref="S2.E3.m1.58.58.58.18.18.18.1">2</cn></apply></apply></apply><ci id="S2.E3.m1.60.60.60.20.20.20.cmml" xref="S2.E3.m1.60.60.60.20.20.20">𝑃</ci><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.2.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.2.2.1.cmml" xref="S2.E3.m1.74.74.5">delimited-[]</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.2.1.1.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="latexml" id="S2.E3.m1.64.64.64.24.24.24.cmml" xref="S2.E3.m1.64.64.64.24.24.24">succeeds</csymbol><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.2.1.1.2.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.2.1.1.2.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.62.62.62.22.22.22.cmml" xref="S2.E3.m1.62.62.62.22.22.22">𝑜</ci><cn id="S2.E3.m1.63.63.63.23.23.23.1.cmml" type="integer" xref="S2.E3.m1.63.63.63.23.23.23.1">2</cn></apply><apply id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.2.1.1.3.cmml" xref="S2.E3.m1.74.74.5"><csymbol cd="ambiguous" id="S2.E3.m1.70.70.1.1.1.1.1.6.2.1.1.1.2.1.1.3.1.cmml" xref="S2.E3.m1.74.74.5">subscript</csymbol><ci id="S2.E3.m1.65.65.65.25.25.25.cmml" xref="S2.E3.m1.65.65.65.25.25.25">𝑜</ci><cn id="S2.E3.m1.66.66.66.26.26.26.1.cmml" type="integer" xref="S2.E3.m1.66.66.66.26.26.26.1">1</cn></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.74c">\begin{split}r_{\theta}=\operatorname*{arg\,min}_{\theta}\mathbb{E}_{(o_{1},o_%
{2},y)\sim\mathcal{D}_{\text{pref}}}\bigg{[}&amp;\mathbb{I}[y=1]\log P_{\theta}[o_%
{1}\succ o_{2}]+\mathbb{I}[y=2]P_{\theta}[o_{2}\succ o_{1}]\\
&amp;+\frac{1}{2}\mathbb{I}[y=\varnothing]\log\big{(}P_{\theta}[o_{1}\succ o_{2}]P%
[o_{2}\succ o_{1}]\big{)}\bigg{]}\end{split}</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.74d">start_ROW start_CELL italic_r start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT = start_OPERATOR roman_arg roman_min end_OPERATOR start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT ( italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_y ) ∼ caligraphic_D start_POSTSUBSCRIPT pref end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ end_CELL start_CELL blackboard_I [ italic_y = 1 ] roman_log italic_P start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT [ italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≻ italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] + blackboard_I [ italic_y = 2 ] italic_P start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT [ italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ≻ italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ] end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL + divide start_ARG 1 end_ARG start_ARG 2 end_ARG blackboard_I [ italic_y = ∅ ] roman_log ( italic_P start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT [ italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≻ italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] italic_P [ italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ≻ italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ] ) ] end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.I2.i2.p1.5"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.5.1">where </span><math alttext="P_{\theta}[o_{1}\succ o_{2}]=\frac{e^{r_{\theta}(o_{1})}}{e^{r_{\theta}(o_{1})%
}+e^{r_{\theta}(o_{2})}}" class="ltx_Math" display="inline" id="S2.I2.i2.p1.5.m1.4"><semantics id="S2.I2.i2.p1.5.m1.4a"><mrow id="S2.I2.i2.p1.5.m1.4.4" xref="S2.I2.i2.p1.5.m1.4.4.cmml"><mrow id="S2.I2.i2.p1.5.m1.4.4.1" xref="S2.I2.i2.p1.5.m1.4.4.1.cmml"><msub id="S2.I2.i2.p1.5.m1.4.4.1.3" xref="S2.I2.i2.p1.5.m1.4.4.1.3.cmml"><mi id="S2.I2.i2.p1.5.m1.4.4.1.3.2" xref="S2.I2.i2.p1.5.m1.4.4.1.3.2.cmml">P</mi><mi id="S2.I2.i2.p1.5.m1.4.4.1.3.3" xref="S2.I2.i2.p1.5.m1.4.4.1.3.3.cmml">θ</mi></msub><mo id="S2.I2.i2.p1.5.m1.4.4.1.2" xref="S2.I2.i2.p1.5.m1.4.4.1.2.cmml">⁢</mo><mrow id="S2.I2.i2.p1.5.m1.4.4.1.1.1" xref="S2.I2.i2.p1.5.m1.4.4.1.1.2.cmml"><mo id="S2.I2.i2.p1.5.m1.4.4.1.1.1.2" stretchy="false" xref="S2.I2.i2.p1.5.m1.4.4.1.1.2.1.cmml">[</mo><mrow id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.cmml"><msub id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.cmml"><mi id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.2" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.2.cmml">o</mi><mn id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.3" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.1" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.1.cmml">≻</mo><msub id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.cmml"><mi id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.2" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.2.cmml">o</mi><mn id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.3" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.3.cmml">2</mn></msub></mrow><mo id="S2.I2.i2.p1.5.m1.4.4.1.1.1.3" stretchy="false" xref="S2.I2.i2.p1.5.m1.4.4.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.I2.i2.p1.5.m1.4.4.2" xref="S2.I2.i2.p1.5.m1.4.4.2.cmml">=</mo><mfrac id="S2.I2.i2.p1.5.m1.3.3" xref="S2.I2.i2.p1.5.m1.3.3.cmml"><msup id="S2.I2.i2.p1.5.m1.1.1.1" xref="S2.I2.i2.p1.5.m1.1.1.1.cmml"><mi id="S2.I2.i2.p1.5.m1.1.1.1.3" xref="S2.I2.i2.p1.5.m1.1.1.1.3.cmml">e</mi><mrow id="S2.I2.i2.p1.5.m1.1.1.1.1.1" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.cmml"><msub id="S2.I2.i2.p1.5.m1.1.1.1.1.1.3" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.cmml"><mi id="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.2" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.2.cmml">r</mi><mi id="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.3" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S2.I2.i2.p1.5.m1.1.1.1.1.1.2" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.2" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.2.cmml">o</mi><mn id="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.3" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup><mrow id="S2.I2.i2.p1.5.m1.3.3.3" xref="S2.I2.i2.p1.5.m1.3.3.3.cmml"><msup id="S2.I2.i2.p1.5.m1.3.3.3.4" xref="S2.I2.i2.p1.5.m1.3.3.3.4.cmml"><mi id="S2.I2.i2.p1.5.m1.3.3.3.4.2" xref="S2.I2.i2.p1.5.m1.3.3.3.4.2.cmml">e</mi><mrow id="S2.I2.i2.p1.5.m1.2.2.2.1.1" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.cmml"><msub id="S2.I2.i2.p1.5.m1.2.2.2.1.1.3" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.cmml"><mi id="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.2" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.2.cmml">r</mi><mi id="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.3" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.3.cmml">θ</mi></msub><mo id="S2.I2.i2.p1.5.m1.2.2.2.1.1.2" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.2.cmml">⁢</mo><mrow id="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.cmml"><mo id="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.2" stretchy="false" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.cmml">(</mo><msub id="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.cmml"><mi id="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.2" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.2.cmml">o</mi><mn id="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.3" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.3" stretchy="false" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup><mo id="S2.I2.i2.p1.5.m1.3.3.3.3" xref="S2.I2.i2.p1.5.m1.3.3.3.3.cmml">+</mo><msup id="S2.I2.i2.p1.5.m1.3.3.3.5" xref="S2.I2.i2.p1.5.m1.3.3.3.5.cmml"><mi id="S2.I2.i2.p1.5.m1.3.3.3.5.2" xref="S2.I2.i2.p1.5.m1.3.3.3.5.2.cmml">e</mi><mrow id="S2.I2.i2.p1.5.m1.3.3.3.2.1" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.cmml"><msub id="S2.I2.i2.p1.5.m1.3.3.3.2.1.3" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.cmml"><mi id="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.2" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.2.cmml">r</mi><mi id="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.3" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.3.cmml">θ</mi></msub><mo id="S2.I2.i2.p1.5.m1.3.3.3.2.1.2" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.2.cmml">⁢</mo><mrow id="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.cmml"><mo id="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.2" stretchy="false" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.cmml">(</mo><msub id="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.cmml"><mi id="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.2" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.2.cmml">o</mi><mn id="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.3" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.3.cmml">2</mn></msub><mo id="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.3" stretchy="false" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.cmml">)</mo></mrow></mrow></msup></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.I2.i2.p1.5.m1.4b"><apply id="S2.I2.i2.p1.5.m1.4.4.cmml" xref="S2.I2.i2.p1.5.m1.4.4"><eq id="S2.I2.i2.p1.5.m1.4.4.2.cmml" xref="S2.I2.i2.p1.5.m1.4.4.2"></eq><apply id="S2.I2.i2.p1.5.m1.4.4.1.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1"><times id="S2.I2.i2.p1.5.m1.4.4.1.2.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.2"></times><apply id="S2.I2.i2.p1.5.m1.4.4.1.3.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.3"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.4.4.1.3.1.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.3">subscript</csymbol><ci id="S2.I2.i2.p1.5.m1.4.4.1.3.2.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.3.2">𝑃</ci><ci id="S2.I2.i2.p1.5.m1.4.4.1.3.3.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.3.3">𝜃</ci></apply><apply id="S2.I2.i2.p1.5.m1.4.4.1.1.2.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1"><csymbol cd="latexml" id="S2.I2.i2.p1.5.m1.4.4.1.1.2.1.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.2">delimited-[]</csymbol><apply id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1"><csymbol cd="latexml" id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.1.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.1">succeeds</csymbol><apply id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.1.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2">subscript</csymbol><ci id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.2.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.2">𝑜</ci><cn id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.3.cmml" type="integer" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.2.3">1</cn></apply><apply id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.1.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3">subscript</csymbol><ci id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.2.cmml" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.2">𝑜</ci><cn id="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.3.cmml" type="integer" xref="S2.I2.i2.p1.5.m1.4.4.1.1.1.1.3.3">2</cn></apply></apply></apply></apply><apply id="S2.I2.i2.p1.5.m1.3.3.cmml" xref="S2.I2.i2.p1.5.m1.3.3"><divide id="S2.I2.i2.p1.5.m1.3.3.4.cmml" xref="S2.I2.i2.p1.5.m1.3.3"></divide><apply id="S2.I2.i2.p1.5.m1.1.1.1.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.1.1.1.2.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1">superscript</csymbol><ci id="S2.I2.i2.p1.5.m1.1.1.1.3.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1.3">𝑒</ci><apply id="S2.I2.i2.p1.5.m1.1.1.1.1.1.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1"><times id="S2.I2.i2.p1.5.m1.1.1.1.1.1.2.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.2"></times><apply id="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.1.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.2.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.2">𝑟</ci><ci id="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.3.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.3.3">𝜃</ci></apply><apply id="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.2">𝑜</ci><cn id="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.I2.i2.p1.5.m1.1.1.1.1.1.1.1.1.3">1</cn></apply></apply></apply><apply id="S2.I2.i2.p1.5.m1.3.3.3.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3"><plus id="S2.I2.i2.p1.5.m1.3.3.3.3.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.3"></plus><apply id="S2.I2.i2.p1.5.m1.3.3.3.4.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.4"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.3.3.3.4.1.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.4">superscript</csymbol><ci id="S2.I2.i2.p1.5.m1.3.3.3.4.2.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.4.2">𝑒</ci><apply id="S2.I2.i2.p1.5.m1.2.2.2.1.1.cmml" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1"><times id="S2.I2.i2.p1.5.m1.2.2.2.1.1.2.cmml" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.2"></times><apply id="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.cmml" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.1.cmml" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.3">subscript</csymbol><ci id="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.2.cmml" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.2">𝑟</ci><ci id="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.3.cmml" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.3.3">𝜃</ci></apply><apply id="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.cmml" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.1.cmml" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1">subscript</csymbol><ci id="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.2.cmml" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.2">𝑜</ci><cn id="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.3.cmml" type="integer" xref="S2.I2.i2.p1.5.m1.2.2.2.1.1.1.1.1.3">1</cn></apply></apply></apply><apply id="S2.I2.i2.p1.5.m1.3.3.3.5.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.5"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.3.3.3.5.1.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.5">superscript</csymbol><ci id="S2.I2.i2.p1.5.m1.3.3.3.5.2.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.5.2">𝑒</ci><apply id="S2.I2.i2.p1.5.m1.3.3.3.2.1.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1"><times id="S2.I2.i2.p1.5.m1.3.3.3.2.1.2.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.2"></times><apply id="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.3"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.1.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.3">subscript</csymbol><ci id="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.2.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.2">𝑟</ci><ci id="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.3.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.3.3">𝜃</ci></apply><apply id="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1"><csymbol cd="ambiguous" id="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.1.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1">subscript</csymbol><ci id="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.2.cmml" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.2">𝑜</ci><cn id="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.3.cmml" type="integer" xref="S2.I2.i2.p1.5.m1.3.3.3.2.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.i2.p1.5.m1.4c">P_{\theta}[o_{1}\succ o_{2}]=\frac{e^{r_{\theta}(o_{1})}}{e^{r_{\theta}(o_{1})%
}+e^{r_{\theta}(o_{2})}}</annotation><annotation encoding="application/x-llamapun" id="S2.I2.i2.p1.5.m1.4d">italic_P start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT [ italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≻ italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] = divide start_ARG italic_e start_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT end_ARG start_ARG italic_e start_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT + italic_e start_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.5.2"> the probability of preferring an observation to another, referred to as the Bradley-Terry model for preference learning </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.5.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Bradley &amp; Terry</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.5.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib5" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">1952</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.5.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i2.p1.5.6">. The minimization of this equation is commonly done through binary cross-entropy.</span></p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I2.i3.p1">
<p class="ltx_p" id="S2.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i3.p1.1.1">Reward as Code</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i3.p1.1.2"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i3.p1.1.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yu et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i3.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib66" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Ma et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i3.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib34" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i3.p1.1.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i3.p1.1.6">. Prompt the LLM to write code that will take as input a subset of symbolic features from the environment observations and will produce a scalar output representing the reward. When symbolic features are not available, these are constructed as in </span><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text ltx_font_sansserif ltx_font_bold">Venuto et al.</span> <span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i3.p1.1.7.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib57" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i3.p1.1.8.2.2.1">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i3.p1.1.9">.</span></p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S2.I2.i4.p1">
<p class="ltx_p" id="S2.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i4.p1.1.1">Embedding-based</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i4.p1.1.2"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i4.p1.1.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Rocamonde et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i4.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib44" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Du et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i4.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib13" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i4.p1.1.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.I2.i4.p1.1.6">. Instead of querying language tokens from the LLM, we can instead, for a given input, leverage the information encoded in its latent represention, or embeddings. These embeddings are used to calculate the cosine similarity with respect to the embeddings of natural language specification of a goal or a behaviour. The resulting similarity value is given as a reward to the agent.</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS3.p3.1.1">Additional details, such specific prompts, are presented in the Appendix </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.SS2" title="A.2 Details on Indirect Policy Modeling Through LLM-based Rewards ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.2</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S2.SS3.p3.1.2">.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S3.1.1.1">3</span> </span>Performance of Indirect and Direct Policy Models</h2>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="254" id="S3.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S3.F1.3.1.1">Figure 1</span>: </span>AI feedback as the highest performance across different reward models derived from LLMs tested. AI feedback, which is a preference-based method for deriving a reward model from an LLM generally outperforms other methods.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.1">Due to fundamentally different challenges between direct and indirect policy modeling approaches, conducting a fair comparison requires care.
For example, using the LLM directly as a policy requires grounding its outputs in the action space defined by the environment </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Ahn et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib1" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Huang et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib17" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.5">. As the action space can vary
significantly between environments and attempting to solve this problem adds additional algorithm- or domain-specific complexities (e.g. by crafting skills, see </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_sansserif ltx_font_bold">Ahn et al.</span> <span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.6.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib1" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.7.2.2.1">)</span>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Wang et al.</span> <span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.6.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib58" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.7.2.2.1">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p1.1.8">), we fix our experimental setting to the following</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p2">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.I1.i1.p1.1.1">Atomic actions. We only study approaches which can directly interface with the action space supported in the environment.
In other words, the action space is at least a subspace of the space of language generated by the LLM.
This allows for a more direct comparison across a variety of domains and study the relationship between an LLM’s knowledge and the fixed action space defined by the environment.</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para ltx_noindent" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.I1.i2.p1.1.1">No finetuning. In most of the paper we assume that LLMs are used without any gradient updates, i.e. </span><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S3.I1.i2.p1.1.2">without fine-tuning</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.I1.i2.p1.1.3"> from the RL task, and evaluate their off-the-shelf capabilities.
In </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S5" title="5 Beyond Zero-Shot Reward Modeling ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.I1.i2.p1.1.4">, we perform a preliminary study on the trade-offs between fine-tuning for direct and indirect policy modeling.</span></p>
</div>
</li>
</ol>
</div>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="456" id="S3.F2.sf1.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S3.F2.sf1.2.1.1">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="415" id="S3.F2.sf2.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S3.F2.sf2.2.1.1">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S3.F2.3.1.1">Figure 2</span>: </span>a) Building a reward model more-readily solves RL tasks than using an LLM as an actor.
LLM-policy only performs well in domains with coarse-grained actions while LLM feedback presents strong performance across the entire range of action granularities.
b) LLMs have unreliable zero-shot understanding of the environment dynamics.
While LLMs can be used to craft useful reward models, their failure as direct policies may be explained by their poor understanding of the action space and the transition function.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.p3">
<p class="ltx_p" id="S3.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p3.1.1">We investigate four separate domains, where each domain aims to highlight a specific capability of LLMs: 1) MiniWob-Hard, a subset of hard tasks from the full MiniWob suite, tests web interaction in observation/action spaces close to natural language, 2) Wordle measures reasoning and planning capabilities, 3) NetHack presents the difficulty of exploring open-ended environments under partial observability, long horizons and procedural scenarios, and 4) MetaWorld assesses the ability to control low-level, high-frequency actions in continuous space.
We provide a detailed description of each domain in Appendix </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.SS1" title="A.1 Environment Details ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.1</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p3.1.2">.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p4">
<p class="ltx_p" id="S3.p4.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p4.1.1">Direct policy modeling is done by querying the closed source GPT-4o model, whereas indirect policy modeling is done through the open source models of Llama 3 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p4.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Dubey et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p4.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib14" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p4.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p4.1.5">, when environment observations consist of text, and PaliGemma </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p4.1.6.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Beyer et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p4.1.7.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib4" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p4.1.8.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.p4.1.9">, when environment observation consist of pixel images. All results are averaged over 10 seeds with error bars indicating the standard error.</span></p>
</div>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_paragraph">Indirect policy modeling through rewards.</h4>
<div class="ltx_para ltx_noindent" id="S3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px1.p1.1.1">We first present a comparison of the various indirect policy modeling approaches discussed in </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S2.SS3" title="2.3 Indirectly Modeling Policies through Reward Models ‣ 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2.3</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px1.p1.1.2">. In these experiments, the LLM generates a reward function which will be given to a RL agent for optimization, without access to any rewards coming from the environment. When learning policies through RL we do not perform any hyperparameter search and simply borrow the existing empirical setup for each domain, as detailed in Appendix </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.SS1" title="A.1 Environment Details ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.1</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px1.p1.1.3">.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px1.p2.1.1">In </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S3.F1" title="In 3 Performance of Indirect and Direct Policy Models ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px1.p2.1.2">, we present the performance across domains as measured by the average success rate on all domains,
except for NetHack, where performance (the in-game score) is normalized by the highest recorded value.
Results show that AI feedback is the only method that successfully crafts rewards across all environments and
modalities </span><span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup>In Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#A1.SS6" title="A.6 Learning from Environment Rewards ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.6</span></a>, we verify that AI feedback yields policies with performance on par with those optimized using human-designed environment rewards.</span></span></span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px1.p2.1.3">.
On easier domains such as MiniWob-Hard, which consists of short episodes and limited scope of variations, the Direct Scalar method performs nearly as well as AI feedback.
However, the disparity between methods is much more pronounced on harder, open-ended tasks such as NetHack.
Out of all the methods, Embedding-based leads to the lowest performance.
Finally, the effectiveness of Reward as Code appears to be highly contingent on the availability of symbolic features for code processing.
In Appendix </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.SS5" title="A.5 Ablating Reward as Code ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.5</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px1.p2.1.4">, we further examine the assumptions—such
as access to functional knowledge of the environment—under which Reward as Code can achieve performance comparable to AI feedback</span></p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_paragraph">Direct vs indirect policy modeling.</h4>
<div class="ltx_para ltx_noindent" id="S3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px2.p1.1.1">We now compare the direct policy modeling method, LLM Policy, to the best performing indirect modeling method, AI feedback, reporting performance across the same set of domains.
Results in </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S3.F2.sf1" title="In Figure 2 ‣ 3 Performance of Indirect and Direct Policy Models ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2(a)</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px2.p1.1.2"> show that, despite the more complex prompting strategies and the use of a more capable closed source model, LLM Policy is unable to perform well in most environments, with the exception of MiniWob-Hard, where the performance is on-par with AI feedback.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p2.3"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px2.p2.3.1">A question emerging from these results is: what factors cause this significant performance disparity between direct and indirect policy models? One possible explanation is that LLMs, when directly queried for actions in an unfamiliar environment, may struggle to understand its dynamics (e.g., the transition function and action space). To test this hypothesis, we conduct the following experiment. We prompt the LLM to select between 1) a pair of candidate </span><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S3.SS0.SSS0.Px2.p2.3.2">next observations</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px2.p2.3.3"> given the current observation and action (probing knowledge of </span><math alttext="p(o_{t+1}|a_{t},o_{\leq t})" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p2.1.m1.1"><semantics id="S3.SS0.SSS0.Px2.p2.1.m1.1a"><mrow id="S3.SS0.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.3" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml">p</mi><mo id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.2" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml"><msub id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.cmml"><mi id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.2" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.2.cmml">o</mi><mrow id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.cmml"><mi id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.2" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.2.cmml">t</mi><mo id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.1" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.1.cmml">+</mo><mn id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.3" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3.cmml">|</mo><mrow id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.3.cmml"><msub id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.2.cmml">a</mi><mi id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.3" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.2" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.2.cmml">o</mi><mrow id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.cmml"><mi id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.2" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.2.cmml"></mi><mo id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.1" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.1.cmml">≤</mo><mi id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.3" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.3.cmml">t</mi></mrow></msub></mrow></mrow><mo id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1"><times id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.2"></times><ci id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.3">𝑝</ci><apply id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3">conditional</csymbol><apply id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.1.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.2.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.2">𝑜</ci><apply id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3"><plus id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.1.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.1"></plus><ci id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.2.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.2">𝑡</ci><cn id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.3.cmml" type="integer" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.4.3.3">1</cn></apply></apply><list id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2"><apply id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.2">𝑎</ci><ci id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.2">𝑜</ci><apply id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3"><leq id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.1"></leq><csymbol cd="latexml" id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.2">absent</csymbol><ci id="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.2.2.3.3">𝑡</ci></apply></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p2.1.m1.1c">p(o_{t+1}|a_{t},o_{\leq t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p2.1.m1.1d">italic_p ( italic_o start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT ≤ italic_t end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px2.p2.3.4">), or 2) a pair of candidate </span><span class="ltx_text ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S3.SS0.SSS0.Px2.p2.3.5">actions</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px2.p2.3.6"> given the next observation and current observation (probing knowledge of </span><math alttext="p(a_{t}|o_{t+1},o_{\leq t})" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p2.2.m2.1"><semantics id="S3.SS0.SSS0.Px2.p2.2.m2.1a"><mrow id="S3.SS0.SSS0.Px2.p2.2.m2.1.1" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.3" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml">p</mi><mo id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.2" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml">⁢</mo><mrow id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml"><msub id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.cmml"><mi id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.2" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.2.cmml">a</mi><mi id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.3" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.3.cmml">t</mi></msub><mo fence="false" id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.3" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.3.cmml">|</mo><mrow id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.3.cmml"><msub id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.2" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.2.cmml">o</mi><mrow id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.2" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.1" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.1.cmml">+</mo><mn id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.3" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.3" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.cmml"><mi id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.2" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.2.cmml">o</mi><mrow id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.cmml"><mi id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.2" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.2.cmml"></mi><mo id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.1" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.1.cmml">≤</mo><mi id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.3" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.3.cmml">t</mi></mrow></msub></mrow></mrow><mo id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p2.2.m2.1b"><apply id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1"><times id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.2"></times><ci id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.3">𝑝</ci><apply id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1"><csymbol cd="latexml" id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.3">conditional</csymbol><apply id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.1.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4">subscript</csymbol><ci id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.2.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.2">𝑎</ci><ci id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.3.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.4.3">𝑡</ci></apply><list id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2"><apply id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.2">𝑜</ci><apply id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3"><plus id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.1"></plus><ci id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.2">𝑡</ci><cn id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.1.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.2">𝑜</ci><apply id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3"><leq id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.1"></leq><csymbol cd="latexml" id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.2">absent</csymbol><ci id="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.SS0.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.2.2.3.3">𝑡</ci></apply></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p2.2.m2.1c">p(a_{t}|o_{t+1},o_{\leq t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p2.2.m2.1d">italic_p ( italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_o start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT ≤ italic_t end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px2.p2.3.7">). In each case, the pair contains the ground-truth and random sample. In this experiment, a </span><math alttext="50\%" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p2.3.m3.1"><semantics id="S3.SS0.SSS0.Px2.p2.3.m3.1a"><mrow id="S3.SS0.SSS0.Px2.p2.3.m3.1.1" xref="S3.SS0.SSS0.Px2.p2.3.m3.1.1.cmml"><mn id="S3.SS0.SSS0.Px2.p2.3.m3.1.1.2" xref="S3.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml">50</mn><mo id="S3.SS0.SSS0.Px2.p2.3.m3.1.1.1" xref="S3.SS0.SSS0.Px2.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p2.3.m3.1b"><apply id="S3.SS0.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="latexml" id="S3.SS0.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p2.3.m3.1.1.1">percent</csymbol><cn id="S3.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml" type="integer" xref="S3.SS0.SSS0.Px2.p2.3.m3.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p2.3.m3.1c">50\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p2.3.m3.1d">50 %</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px2.p2.3.8"> accuracy corresponds to a random guess.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px2.p3.1.1">Results presented in </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S3.F2.sf2" title="In Figure 2 ‣ 3 Performance of Indirect and Direct Policy Models ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2(b)</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S3.SS0.SSS0.Px2.p3.1.2"> show that the LLM performs relatively poorly on both of these tasks, indicating limited understanding of both the action space and the environment dynamics. This can potentially explain the limited performance of the LLM Policy approach on MiniWob-Hard, NetHack, and MetaWorld, while results on Wordle suggest that additional contributing factors are at play.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S4.1.1.1">4</span> </span>Analysis of AI Feedback for RL</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.p1.1.1">Our results so far suggest that, without additional fine-tuning,
indirectly modeling policies by constructing reward functions through AI feedback is the most effective approach across the range of environments and modalities we studied.
In this section, we examine how rewards shaped by this method can assist RL agents in addressing core decision-making challenges, such as credit assignment and exploration. Through this analysis, we also emphasize the ways in which reward misspecification can unintentionally arise and severely impair performance.</span></p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="329" id="S4.F3.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S4.F3.3.1.1">Figure 3</span>: </span>Rewards learned through AI Feedback distribute rewards to key timesteps. By doing so, the problem of credit assignment, or learning from delayed rewards, is significantly reduced. Such distribution effectively shortens the horizon over which the RL algorithm must propagate credit through its update rule. </figcaption>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S4.SS1.1.1.1">4.1</span> </span>Credit Assignment</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.p1.1.1">AI feedback-based rewards depend on the prompt used to capture preferences. In the experiments conducted so far, these prompts were designed to elicit preferences by emphasizing states that contribute to task progress (see prompts Appendix </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.SS2" title="A.2 Details on Indirect Policy Modeling Through LLM-based Rewards ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.2</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.p1.1.2">). Additionally, a key aspect of our methodology involved presenting the LLM with observations sampled randomly within trajectories. This enabled querying preference for any observation in the environment, rather limiting the focus to final states - a distinction also known as process-based and outcome-based reward models </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.p1.1.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Uesato et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib56" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Lightman et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib28" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.p1.1.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.p1.1.6">. What are the resulting characteristics of the reward model under such choices?</span></p>
</div>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_paragraph">Qualitative experiment</h4>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.1">In Figure </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S4.F3" title="Figure 3 ‣ 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.2">, we present the output of the AI feedback-based reward model over each timestep of an episode within a simple grid world environment. This task includes an agent, a key, a door, and a goal </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Chevalier-Boisvert et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib10" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.6">.
We notice that this reward model naturally captures the fact that picking up the key, as well as opening the locked door, are important steps towards the goal.
By propagating credit over such key moments in a trajectory, the LLM effectively shortens the horizon over which the RL algorithm must assign credit through temporal difference learning </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.7.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Sutton &amp; Barto</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.8.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib50" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2018</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.9.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.10">.
This is manifested in Figure </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S4.F3" title="Figure 3 ‣ 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.11"> where the agent learning through AI feedback reaches a high success rate in a fraction of the timesteps required by a similar agent learning from the environment feedback (which in this case is sparse reward of +1 for reaching the goal).</span></p>
</div>
<figure class="ltx_figure" id="S4.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel" id="S4.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="623" id="S4.F4.sf1.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S4.F4.sf1.3.1.1">(a)</span> </span>Wordle</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel" id="S4.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="623" id="S4.F4.sf2.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S4.F4.sf2.3.1.1">(b)</span> </span>NetHack</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel" id="S4.F4.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="623" id="S4.F4.sf3.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S4.F4.sf3.3.1.1">(c)</span> </span>MetaWorld</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S4.F4.3.1.1">Figure 4</span>: </span>LLM preferences correlate with value function preferences. The correlation between Bradley-Terry models trained from frozen LLM state preferences and value function preferences increases as the online policy improves in 3 different domains.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_paragraph">Quantitative experiment</h4>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.1">In Figure </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S4.F4" title="Figure 4 ‣ Qualitative experiment ‣ 4.1 Credit Assignment ‣ 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.2">, we present the correlation between the reward model derived from AI feedback and the value function of an RL agent across various levels of policy optimality. We observe that AI feedback generates reward functions with a stronger correlation to value functions obtained later in the training process compared to those from earlier stages. Additionally, this correlation is higher than that observed with the environment reward.
In the Wordle game, we generate, in code, a near-optimal policy and estimate its value function using Monte Carlo. We then compare it to the LLM-derived reward function find an almost perfect correlation.
These findings suggest that the reward models derived from AI feedback inherently encode aspects of high-quality value functions, which, when used as rewards for the RL agent, can substantially simplify the credit assignment process.
In Appendix </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.SS7" title="A.7 AI feedback and heuristic functions ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.7</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.3">, we provide additional insights from the lens of heuristic-guided reinforcement learning </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.4.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Cheng et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.5.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib9" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2021</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.6.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.7">.</span></p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S4.SS2.1.1.1">4.2</span> </span>Exploration</h3>
<figure class="ltx_figure ltx_align_center" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="606" id="S4.F5.1.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S4.F5.4.1.1">Figure 5</span>: </span>By changing the prompt,
LLMs can be steered to provide feedback that promotes exploration on NetHack. Additionally, to avoid degenerate solutions, preferences should be elicited in an online fashion and the reward function be non-Markovian.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p1.1.1">In the previous section, we investigated how our standard prompting strategy can ease the problem of credit assignment in downstream RL tasks. This outcome stemmed from the specific preferences we requested from the LLM, that is, promoting task progress. However, to address different RL objectives, in particular the one of exploration, we may need to elicit alternative preferences.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.6"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.6.1">Previously, </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_sansserif ltx_font_bold">Klissarov et al.</span> <span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.6.2.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib23" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.6.3.2.2.1">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.6.4"> employed AI feedback to design an effective reward function for an agent operating in the open-ended environment of NetHack.
However, before applying this reward to the RL agent, the authors implemented the following transformation:</span></p>
<table class="ltx_equation ltx_eqn_table" id="S4.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="r(o_{t})\propto r_{AIF}(o_{t})/N(o_{t})^{\beta}," class="ltx_Math" display="block" id="S4.E4.m1.1"><semantics id="S4.E4.m1.1a"><mrow id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml"><mrow id="S4.E4.m1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml"><mrow id="S4.E4.m1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.3.cmml">r</mi><mo id="S4.E4.m1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E4.m1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E4.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S4.E4.m1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.cmml">o</mi><mi id="S4.E4.m1.1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.E4.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E4.m1.1.1.1.1.4" xref="S4.E4.m1.1.1.1.1.4.cmml">∝</mo><mrow id="S4.E4.m1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.3.cmml"><mrow id="S4.E4.m1.1.1.1.1.2.1" xref="S4.E4.m1.1.1.1.1.2.1.cmml"><mrow id="S4.E4.m1.1.1.1.1.2.1.1" xref="S4.E4.m1.1.1.1.1.2.1.1.cmml"><msub id="S4.E4.m1.1.1.1.1.2.1.1.3" xref="S4.E4.m1.1.1.1.1.2.1.1.3.cmml"><mi id="S4.E4.m1.1.1.1.1.2.1.1.3.2" xref="S4.E4.m1.1.1.1.1.2.1.1.3.2.cmml">r</mi><mrow id="S4.E4.m1.1.1.1.1.2.1.1.3.3" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3.cmml"><mi id="S4.E4.m1.1.1.1.1.2.1.1.3.3.2" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3.2.cmml">A</mi><mo id="S4.E4.m1.1.1.1.1.2.1.1.3.3.1" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.1.2.1.1.3.3.3" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3.3.cmml">I</mi><mo id="S4.E4.m1.1.1.1.1.2.1.1.3.3.1a" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.E4.m1.1.1.1.1.2.1.1.3.3.4" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3.4.cmml">F</mi></mrow></msub><mo id="S4.E4.m1.1.1.1.1.2.1.1.2" xref="S4.E4.m1.1.1.1.1.2.1.1.2.cmml">⁢</mo><mrow id="S4.E4.m1.1.1.1.1.2.1.1.1.1" xref="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.cmml"><mo id="S4.E4.m1.1.1.1.1.2.1.1.1.1.2" stretchy="false" xref="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.cmml">(</mo><msub id="S4.E4.m1.1.1.1.1.2.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.2.cmml">o</mi><mi id="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.E4.m1.1.1.1.1.2.1.1.1.1.3" stretchy="false" xref="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E4.m1.1.1.1.1.2.1.2" xref="S4.E4.m1.1.1.1.1.2.1.2.cmml">/</mo><mi id="S4.E4.m1.1.1.1.1.2.1.3" xref="S4.E4.m1.1.1.1.1.2.1.3.cmml">N</mi></mrow><mo id="S4.E4.m1.1.1.1.1.3.3" xref="S4.E4.m1.1.1.1.1.3.3.cmml">⁢</mo><msup id="S4.E4.m1.1.1.1.1.3.2" xref="S4.E4.m1.1.1.1.1.3.2.cmml"><mrow id="S4.E4.m1.1.1.1.1.3.2.1.1" xref="S4.E4.m1.1.1.1.1.3.2.1.1.1.cmml"><mo id="S4.E4.m1.1.1.1.1.3.2.1.1.2" stretchy="false" xref="S4.E4.m1.1.1.1.1.3.2.1.1.1.cmml">(</mo><msub id="S4.E4.m1.1.1.1.1.3.2.1.1.1" xref="S4.E4.m1.1.1.1.1.3.2.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.3.2.1.1.1.2" xref="S4.E4.m1.1.1.1.1.3.2.1.1.1.2.cmml">o</mi><mi id="S4.E4.m1.1.1.1.1.3.2.1.1.1.3" xref="S4.E4.m1.1.1.1.1.3.2.1.1.1.3.cmml">t</mi></msub><mo id="S4.E4.m1.1.1.1.1.3.2.1.1.3" stretchy="false" xref="S4.E4.m1.1.1.1.1.3.2.1.1.1.cmml">)</mo></mrow><mi id="S4.E4.m1.1.1.1.1.3.2.3" xref="S4.E4.m1.1.1.1.1.3.2.3.cmml">β</mi></msup></mrow></mrow><mo id="S4.E4.m1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.1b"><apply id="S4.E4.m1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"><csymbol cd="latexml" id="S4.E4.m1.1.1.1.1.4.cmml" xref="S4.E4.m1.1.1.1.1.4">proportional-to</csymbol><apply id="S4.E4.m1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1"><times id="S4.E4.m1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.2"></times><ci id="S4.E4.m1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.3">𝑟</ci><apply id="S4.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2">𝑜</ci><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply></apply><apply id="S4.E4.m1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.3"><times id="S4.E4.m1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.1.1.3.3"></times><apply id="S4.E4.m1.1.1.1.1.2.1.cmml" xref="S4.E4.m1.1.1.1.1.2.1"><divide id="S4.E4.m1.1.1.1.1.2.1.2.cmml" xref="S4.E4.m1.1.1.1.1.2.1.2"></divide><apply id="S4.E4.m1.1.1.1.1.2.1.1.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1"><times id="S4.E4.m1.1.1.1.1.2.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.2"></times><apply id="S4.E4.m1.1.1.1.1.2.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.2.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.3">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.2.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.3.2">𝑟</ci><apply id="S4.E4.m1.1.1.1.1.2.1.1.3.3.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3"><times id="S4.E4.m1.1.1.1.1.2.1.1.3.3.1.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3.1"></times><ci id="S4.E4.m1.1.1.1.1.2.1.1.3.3.2.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3.2">𝐴</ci><ci id="S4.E4.m1.1.1.1.1.2.1.1.3.3.3.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3.3">𝐼</ci><ci id="S4.E4.m1.1.1.1.1.2.1.1.3.3.4.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.3.3.4">𝐹</ci></apply></apply><apply id="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.1.1">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.2">𝑜</ci><ci id="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.2.1.1.1.1.1.3">𝑡</ci></apply></apply><ci id="S4.E4.m1.1.1.1.1.2.1.3.cmml" xref="S4.E4.m1.1.1.1.1.2.1.3">𝑁</ci></apply><apply id="S4.E4.m1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.3.2.2.cmml" xref="S4.E4.m1.1.1.1.1.3.2">superscript</csymbol><apply id="S4.E4.m1.1.1.1.1.3.2.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.3.2.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.3.2.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.3.2.1.1">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.3.2.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.3.2.1.1.1.2">𝑜</ci><ci id="S4.E4.m1.1.1.1.1.3.2.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.3.2.1.1.1.3">𝑡</ci></apply><ci id="S4.E4.m1.1.1.1.1.3.2.3.cmml" xref="S4.E4.m1.1.1.1.1.3.2.3">𝛽</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.1c">r(o_{t})\propto r_{AIF}(o_{t})/N(o_{t})^{\beta},</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m1.1d">italic_r ( italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ∝ italic_r start_POSTSUBSCRIPT italic_A italic_I italic_F end_POSTSUBSCRIPT ( italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) / italic_N ( italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_β end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.p2.5"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.1">where </span><math alttext="r_{AIF}" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><msub id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">r</mi><mrow id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml"><mi id="S4.SS2.p2.1.m1.1.1.3.2" xref="S4.SS2.p2.1.m1.1.1.3.2.cmml">A</mi><mo id="S4.SS2.p2.1.m1.1.1.3.1" xref="S4.SS2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p2.1.m1.1.1.3.3" xref="S4.SS2.p2.1.m1.1.1.3.3.cmml">I</mi><mo id="S4.SS2.p2.1.m1.1.1.3.1a" xref="S4.SS2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p2.1.m1.1.1.3.4" xref="S4.SS2.p2.1.m1.1.1.3.4.cmml">F</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">𝑟</ci><apply id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3"><times id="S4.SS2.p2.1.m1.1.1.3.1.cmml" xref="S4.SS2.p2.1.m1.1.1.3.1"></times><ci id="S4.SS2.p2.1.m1.1.1.3.2.cmml" xref="S4.SS2.p2.1.m1.1.1.3.2">𝐴</ci><ci id="S4.SS2.p2.1.m1.1.1.3.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3.3">𝐼</ci><ci id="S4.SS2.p2.1.m1.1.1.3.4.cmml" xref="S4.SS2.p2.1.m1.1.1.3.4">𝐹</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">r_{AIF}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">italic_r start_POSTSUBSCRIPT italic_A italic_I italic_F end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.2"> is the reward model obtained from AI feedback, </span><math alttext="N(o_{t})" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m2.1"><semantics id="S4.SS2.p2.2.m2.1a"><mrow id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">N</mi><mo id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">⁢</mo><mrow id="S4.SS2.p2.2.m2.1.1.1.1" xref="S4.SS2.p2.2.m2.1.1.1.1.1.cmml"><mo id="S4.SS2.p2.2.m2.1.1.1.1.2" stretchy="false" xref="S4.SS2.p2.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S4.SS2.p2.2.m2.1.1.1.1.1" xref="S4.SS2.p2.2.m2.1.1.1.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.1.1.1.2" xref="S4.SS2.p2.2.m2.1.1.1.1.1.2.cmml">o</mi><mi id="S4.SS2.p2.2.m2.1.1.1.1.1.3" xref="S4.SS2.p2.2.m2.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.SS2.p2.2.m2.1.1.1.1.3" stretchy="false" xref="S4.SS2.p2.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><times id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2"></times><ci id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3">𝑁</ci><apply id="S4.SS2.p2.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p2.2.m2.1.1.1.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.1.2">𝑜</ci><ci id="S4.SS2.p2.2.m2.1.1.1.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.1.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">N(o_{t})</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.2.m2.1d">italic_N ( italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.3"> denotes the number of times a particular observation </span><math alttext="o_{t}" class="ltx_Math" display="inline" id="S4.SS2.p2.3.m3.1"><semantics id="S4.SS2.p2.3.m3.1a"><msub id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml"><mi id="S4.SS2.p2.3.m3.1.1.2" xref="S4.SS2.p2.3.m3.1.1.2.cmml">o</mi><mi id="S4.SS2.p2.3.m3.1.1.3" xref="S4.SS2.p2.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><apply id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2">𝑜</ci><ci id="S4.SS2.p2.3.m3.1.1.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">o_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.3.m3.1d">italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.4"> was seen in an episode, and </span><math alttext="\beta" class="ltx_Math" display="inline" id="S4.SS2.p2.4.m4.1"><semantics id="S4.SS2.p2.4.m4.1a"><mi id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><ci id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">\beta</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.4.m4.1d">italic_β</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.5"> is a positive real-valued coefficient set to </span><math alttext="3" class="ltx_Math" display="inline" id="S4.SS2.p2.5.m5.1"><semantics id="S4.SS2.p2.5.m5.1a"><mn id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><cn id="S4.SS2.p2.5.m5.1.1.cmml" type="integer" xref="S4.SS2.p2.5.m5.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">3</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.5.m5.1d">3</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.6">.
The counting term was added to encourage exploration </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.7.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Henaff et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.8.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib16" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.9.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.10">, which is a key difficulty in NetHack. However, instantiating such a counting function proves difficult in many practical settings </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.11.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Bellemare et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.12.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib3" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2016</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.13.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p2.5.14">. Given the flexibility of natural language, can we alleviate the need for such a term and integrate the notion of exploration in the prompt itself?</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p3.1.1">In </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S4.F5" title="In 4.2 Exploration ‣ 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p3.1.2">, we demonstrate that this is indeed possible, leading to performance comparable when using count-based exploration by directly modifying the prompt used for preference elicitation. Specifically, when querying the LLM for preferences, we present it with a pair of sequences of observations (rather than a single observation) which provides crucial context. The prompt was also modified to steer the LLM towards avoiding low entropy sequences, i.e. sequences with repetitions (see Appendix </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.SS2" title="A.2 Details on Indirect Policy Modeling Through LLM-based Rewards ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.2</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p3.1.3">).</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p4.1.1">Our findings reveal two potential failure modes: the offline nature of the preference elicitation method and the assumption of a Markovian reward model.
Previous research has demonstrated that online preference querying can outperform offline methods when aligning LLMs </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p4.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Bai et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p4.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib2" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Touvron et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p4.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib55" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p4.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p4.1.5">. In our experiments, offline elicitation led to a performance collapse, likely due to frequent RL policy updates during online learning.
Additionally, assuming a Markov reward model—where the current observation fully determines the reward—can lead to an equally poor performance, as complex tasks often require historical context beyond immediate observations (see Appendix </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.SS8" title="A.8 Additional Considerations for Preference-based Reward Modeling ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A.8</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.SS2.p4.1.6"> for a full breakdown).</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S5.1.1.1">5</span> </span>Beyond Zero-Shot Reward Modeling</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p1.1.1">So far, we have explored the ability of LLMs to model policies, directly and indirectly, without any fine-tuning.
However, in many cases the prior knowledge encoded in LLM might not contain the necessary information to do so successfully. In such instances, fine-tuning becomes an effective method for incorporating task-specific knowledge into the model.</span></p>
</div>
<figure class="ltx_figure" id="S5.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="214" id="S5.F6.sf1.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S5.F6.sf1.3.1.1">(a)</span> </span>Fine-tuning for AI feedback</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="214" id="S5.F6.sf2.g1" src="x10.png" width="830"/>
<figcaption class="ltx_caption ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S5.F6.sf2.3.1.1">(b)</span> </span>Fine-tuning for direct policy modeling</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S5.F6.3.1.1">Figure 6</span>: </span>Fine-tuning LLMs for AI feedback better preserves their prior knowledge. LLMs fine-tuned for AI feedback in (a) retain a higher portion of their original language reasoning knowledge than those fine-tuned for direct action selection in (b).</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.p2">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p2.1.1">We consider the </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.p2.1.2">sweep-into</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p2.1.3"> task from MetaWorld, where AI feedback rewards lead to a success rate of only </span><math alttext="15\%" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><mrow id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mn id="S5.p2.1.m1.1.1.2" xref="S5.p2.1.m1.1.1.2.cmml">15</mn><mo id="S5.p2.1.m1.1.1.1" xref="S5.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1.1">percent</csymbol><cn id="S5.p2.1.m1.1.1.2.cmml" type="integer" xref="S5.p2.1.m1.1.1.2">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">15\%</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">15 %</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p2.1.4">. When measuring the perplexity score of the PaliGemma model on captions describing the pixel observations from the task, we obtain a value of 16.03. Both of these results indicate poor understanding and the necessity to adapt the model.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p3">
<p class="ltx_p" id="S5.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.1">We therefore fine-tune PaliGemma on image-caption pairs annotated by GPT-4o and trained the model to predict the caption for a given image. </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S5.F6.sf1" title="In Figure 6 ‣ 5 Beyond Zero-Shot Reward Modeling ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6(a)</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.2"> shows significant gains in downstream RL performance after only a few fine-tuning epochs and as few as approximately </span><math alttext="100" class="ltx_Math" display="inline" id="S5.p3.1.m1.1"><semantics id="S5.p3.1.m1.1a"><mn id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><cn id="S5.p3.1.m1.1.1.cmml" type="integer" xref="S5.p3.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">100</annotation><annotation encoding="application/x-llamapun" id="S5.p3.1.m1.1d">100</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.3"> image-caption pairs.
Moreover, </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S5.F6.sf1" title="In Figure 6 ‣ 5 Beyond Zero-Shot Reward Modeling ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6(a)</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.4"> shows how this procedure only marginally decreases performance of the LLM on the standard multi-modal reasoning benchmarks, such as POPE </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.5.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yifan Li &amp; Wen</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.6.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib64" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.7.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.8">, GQA </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.9.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Hudson &amp; Manning</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.10.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib18" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2019</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.11.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.12">, AI2D </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.13.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Kembhavi et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.14.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib21" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2016</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.15.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.16"> and MMMU </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.17.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yue et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.18.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib67" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.19.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.20">.
Surprisingly, performance on the AI2D benchmark </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="S5.p3.1.21">improves</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p3.1.22"> as the number of task-specific fine-tuning epochs increases.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p4">
<p class="ltx_p" id="S5.p4.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p4.1.1">We contrast these findings with </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S5.F6.sf2" title="In Figure 6 ‣ 5 Beyond Zero-Shot Reward Modeling ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6(b)</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p4.1.2">, where we fine-tune PaliGemma with behaviour cloning on expert data on the same MetaWorld task. Similarly to RT-2 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p4.1.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Brohan et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p4.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib6" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p4.1.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p4.1.6">, we overwrite the least frequent tokens with residual VQ-VAE codebooks </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p4.1.7.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Szot et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p4.1.8.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib53" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p4.1.9.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S5.p4.1.10">. In this case, any significant increase of RL performance comes at the cost of catastrophically forgetting all previous knowledge. These results hint at an important trade-off: if preserving prior language reasoning knowledge is important, fine-tuning for AI feedback offers a viable approach. However, if maximizing downstream RL performance is the sole objective, directly fine-tuning for action selection can be more effective.</span></p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_section">
<span class="ltx_tag ltx_tag_section"><span class="ltx_text ltx_font_serif ltx_font_medium" id="S6.1.1.1">6</span> </span>Discussion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S6.p1.1.1">In this paper, we explored two distinct approaches to leveraging LLMs for solving RL tasks: 1) directly, by modeling policies and 2) indirectly, by modeling rewards to be leveraged within a policy learning algorithm. Our results indicate that, without task-specific fine-tuning, current LLMs only show limited decision-making capabilities when directly generating actions. However, despite this limitation, LLMs are capable zero-shot reward modelers. In particular, when eliciting preferences to define rewards through the Bradley-Terry model, LLMs show strong performance across a wide range of domains presenting various challenges.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S6.p2.1.1">In cases where an LLM’s prior knowledge is not enough to obtain useful reward functions, we also investigated fine-tuning with task-specific data to bridge this gap.
Notably, fine-tuning to enhance reward modeling capabilities helps mitigate catastrophic forgetting, which is a crucial consideration for preserving the LLM’s general-purpose abilities
Maintaining these capabilities is essential for broad applicability to sequential decision-making tasks, including out-of-distribution tasks, and for supporting continued natural language interaction with users.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S6.p3.1.1">The reward modeling capabilities presented in this work offer potential solutions to challenges in RL.
First and foremost, LLM-derived reward models alleviate the need for human-designed reward functions, which are often complex and costly to develop.
Second, our empirical analysis reveals that AI-feedback based rewards produce dense functions which correlate positively with high-quality value functions.
Such reward functions can significantly reduce the difficulty of assigning credit by redistributing rewards across different steps within a trajectory.
Finally, distilling knowledge from LLMs into reward models opens new possibilities for applying RL in environments where simulators or symbolic features are unavailable—such as embodied AI agents interacting with humans.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p4">
<p class="ltx_p" id="S6.p4.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S6.p4.1.1">Some notable limitations and caveats exist. For example, interacting with LLMs through natural language requires experimenting with various prompting techniques and specifications. However, this flexibility also enables the shaping of reward functions to incorporate valuable strategies </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S6.p4.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Knox et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S6.p4.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib24" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2013</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S6.p4.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S6.p4.1.5">, such as promoting exploration, which can further enhance the performance of RL agents.</span></p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib1.5.5.1">Ahn et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib1.7.1">
Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, and Byron David et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib1.8.1">Do as i can, not as i say: Grounding language in robotic affordances.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib1.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib1.10.2">Conference on Robot Learning</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib1.11.3">, 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib1.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:247939706" title="">https://api.semanticscholar.org/CorpusID:247939706</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib1.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib2.5.5.1">Bai et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib2.7.1">
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib2.8.1">Constitutional ai: Harmlessness from ai feedback.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib2.9.1">arXiv preprint arXiv:2212.08073</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib2.10.2">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib3.5.5.1">Bellemare et al. (2016)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib3.7.1">
Marc G. Bellemare, Sriram Srinivasan, Georg Ostrovski, Tom Schaul, David Saxton, and Rémi Munos.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib3.8.1">Unifying count-based exploration and intrinsic motivation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib3.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib3.10.2">Neural Information Processing Systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib3.11.3">, 2016.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib3.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:8310565" title="">https://api.semanticscholar.org/CorpusID:8310565</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib3.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib4.5.5.1">Beyer et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib4.7.1">
Lucas Beyer, Andreas Steiner, André Susano Pinto, Alexander Kolesnikov, Xiao Wang, Daniel M. Salz, Maxim Neumann, Ibrahim M. Alabdulmohsin, Michael Tschannen, Emanuele Bugliarello, Thomas Unterthiner, Daniel Keysers, Skanda Koppula, Fangyu Liu, Adam Grycner, Alexey A. Gritsenko, Neil Houlsby, Manoj Kumar, Keran Rong, Julian Martin Eisenschlos, Rishabh Kabra, Matthias Bauer, Matko Bovsnjak, Xi Chen, Matthias Minderer, Paul Voigtlaender, Ioana Bica, Ivana Balazevic, Joan Puigcerver, Pinelopi Papalampidi, Olivier J. Hénaff, Xi Xiong, Radu Soricut, Jeremiah Harmsen, and Xiao-Qi Zhai.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib4.8.1">Paligemma: A versatile 3b vlm for transfer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib4.9.1">2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib4.10.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:271088378" title="">https://api.semanticscholar.org/CorpusID:271088378</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib4.11.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib5.5.5.1">Bradley &amp; Terry (1952)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib5.7.1">
Ralph Allan Bradley and Milton E. Terry.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib5.8.1">Rank analysis of incomplete block designs: I. the method of paired comparisons.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib5.9.1">Biometrika</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib5.10.2">, 39:324, 1952.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib5.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:125209808" title="">https://api.semanticscholar.org/CorpusID:125209808</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib5.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib6.5.5.1">Brohan et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib6.7.1">
Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi Chen, and Krzysztof Choromanski et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib6.8.1">Rt-2: Vision-language-action models transfer web knowledge to robotic control, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib6.9.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://arxiv.org/abs/2307.15818" title="">https://arxiv.org/abs/2307.15818</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib6.10.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib7.5.5.1">Brooks et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib7.7.1">
Ethan Brooks, Logan Walls, Richard L Lewis, and Satinder Singh.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib7.8.1">Large language models can implement policy iteration.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib7.9.1">Advances in Neural Information Processing Systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib7.10.2">, 36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib8.5.5.1">Brown et al. (2020)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib8.7.1">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Ma teusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib8.8.1">Language models are few-shot learners.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib8.9.1">ArXiv</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib8.10.2">, abs/2005.14165, 2020.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib8.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:218971783" title="">https://api.semanticscholar.org/CorpusID:218971783</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib8.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib9.5.5.1">Cheng et al. (2021)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib9.7.1">
Ching-An Cheng, Andrey Kolobov, and Adith Swaminathan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib9.8.1">Heuristic-guided reinforcement learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib9.9.1">Advances in Neural Information Processing Systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib9.10.2">, 34:13550–13563, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib10.5.5.1">Chevalier-Boisvert et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib10.7.1">
Maxime Chevalier-Boisvert, Bolun Dai, Mark Towers, Rodrigo de Lazcano, Lucas Willems, Salem Lahlou, Suman Pal, Pablo Samuel Castro, and Jordan Terry.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib10.8.1">Minigrid &amp; miniworld: Modular &amp; customizable reinforcement learning environments for goal-oriented tasks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib10.9.1">CoRR</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib10.10.2">, abs/2306.13831, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib11.5.5.1">Christiano et al. (2017)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib11.7.1">
Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib11.8.1">Deep reinforcement learning from human preferences.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib11.9.1">Advances in neural information processing systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib11.10.2">, 30, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib12.5.5.1">Devlin et al. (2019)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib12.7.1">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib12.8.1">Bert: Pre-training of deep bidirectional transformers for language understanding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib12.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib12.10.2">North American Chapter of the Association for Computational Linguistics</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib12.11.3">, 2019.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib12.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:52967399" title="">https://api.semanticscholar.org/CorpusID:52967399</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib12.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib13.5.5.1">Du et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib13.7.1">
Yuqing Du, Olivia Watkins, Zihan Wang, Cédric Colas, Trevor Darrell, P. Abbeel, Abhishek Gupta, and Jacob Andreas.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib13.8.1">Guiding pretraining in reinforcement learning with large language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib13.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib13.10.2">International Conference on Machine Learning</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib13.11.3">, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib13.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:256846700" title="">https://api.semanticscholar.org/CorpusID:256846700</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib13.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib14.5.5.1">Dubey et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib14.7.1">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, and Ahmad Al-Dahle et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib14.8.1">The llama 3 herd of models, 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib14.9.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://arxiv.org/abs/2407.21783" title="">https://arxiv.org/abs/2407.21783</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib14.10.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib15.5.5.1">Glaese et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib15.7.1">
Amelia Glaese, Nat McAleese, Maja Trębacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib15.8.1">Improving alignment of dialogue agents via targeted human judgements.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib15.9.1">arXiv preprint arXiv:2209.14375</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib15.10.2">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib16.5.5.1">Henaff et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib16.7.1">
Mikael Henaff, Roberta Raileanu, Minqi Jiang, and Tim Rocktäschel.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib16.8.1">Exploration via elliptical episodic bonuses.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib16.9.1">NeurIPS</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib16.10.2">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib17.5.5.1">Huang et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib17.7.1">
Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib17.8.1">Language models as zero-shot planners: Extracting actionable knowledge for embodied agents.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib17.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib17.10.2">International conference on machine learning</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib17.11.3">, pp.  9118–9147. PMLR, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib18.5.5.1">Hudson &amp; Manning (2019)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib18.7.1">
Drew A Hudson and Christopher D Manning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib18.8.1">Gqa: A new dataset for real-world visual reasoning and compositional question answering.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib18.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib18.10.2">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib18.11.3">, pp.  6700–6709, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib19.5.5.1">Imani et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib19.7.1">
Shima Imani, Liang Du, and Harsh Shrivastava.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib19.8.1">Mathprompter: Mathematical reasoning using large language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib19.9.1">arXiv preprint arXiv:2303.05398</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib19.10.2">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib20.5.5.1">Kakade &amp; Langford (2002)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib20.7.1">
Sham Kakade and John Langford.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib20.8.1">Approximately optimal approximate reinforcement learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib20.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib20.10.2">Proceedings of the Nineteenth International Conference on Machine Learning</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib20.11.3">, pp.  267–274, 2002.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib21.5.5.1">Kembhavi et al. (2016)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib21.7.1">
Aniruddha Kembhavi, Mike Salvato, Eric Kolve, Minjoon Seo, Hannaneh Hajishirzi, and Ali Farhadi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib21.8.1">A diagram is worth a dozen images.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib21.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib21.10.2">Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11–14, 2016, Proceedings, Part IV 14</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib21.11.3">, pp.  235–251. Springer, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib22.5.5.1">Kim et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib22.7.1">
Geunwoo Kim, Pierre Baldi, and Stephen McAleer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib22.8.1">Language models can solve computer tasks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib22.9.1">Advances in Neural Information Processing Systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib22.10.2">, 36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib23.5.5.1">Klissarov et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib23.7.1">
Martin Klissarov, Pierluca D’Oro, Shagun Sodhani, Roberta Raileanu, Pierre-Luc Bacon, Pascal Vincent, Amy Zhang, and Mikael Henaff.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib23.8.1">Motif: Intrinsic motivation from artificial intelligence feedback.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib23.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib23.10.2">The Twelfth International Conference on Learning Representations</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib23.11.3">, 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib23.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://openreview.net/forum?id=tmBKIecDE9" title="">https://openreview.net/forum?id=tmBKIecDE9</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib23.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib24.5.5.1">Knox et al. (2013)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib24.7.1">
W. B. Knox, Peter Stone, and Cynthia Breazeal.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib24.8.1">Training a robot via human feedback: A case study.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib24.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib24.10.2">International Conference on Software Reuse</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib24.11.3">, 2013.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib24.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:266033110" title="">https://api.semanticscholar.org/CorpusID:266033110</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib24.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib25.5.5.1">Kojima et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib25.7.1">
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib25.8.1">Large language models are zero-shot reasoners.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib25.9.1">Advances in neural information processing systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib25.10.2">, 35:22199–22213, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib26.5.5.1">Küttler et al. (2020)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib26.7.1">
Heinrich Küttler, Nantas Nardelli, Alexander H. Miller, Roberta Raileanu, Marco Selvatici, Edward Grefenstette, and Tim Rocktäschel.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib26.8.1">The NetHack Learning Environment.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib26.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib26.10.2">Proceedings of the Conference on Neural Information Processing Systems (NeurIPS)</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib26.11.3">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib27.5.5.1">Lee et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib27.7.1">
Harrison Lee, Samrat Phatale, Hassan Mansoor, Thomas Mesnard, Johan Ferret, Kellie Lu, Colton Bishop, Ethan Hall, Victor Carbune, Abhinav Rastogi, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib27.8.1">Rlaif: Scaling reinforcement learning from human feedback with ai feedback.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib27.9.1">arXiv preprint arXiv:2309.00267</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib27.10.2">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib28.5.5.1">Lightman et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib28.7.1">
Hunter Lightman, Vineet Kosaraju, Yura Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib28.8.1">Let’s verify step by step.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib28.9.1">ArXiv</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib28.10.2">, abs/2305.20050, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib28.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:258987659" title="">https://api.semanticscholar.org/CorpusID:258987659</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib28.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib29.5.5.1">Lin et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib29.7.1">
Jessy Lin, Yuqing Du, Olivia Watkins, Danijar Hafner, Pieter Abbeel, Dan Klein, and Anca Dragan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib29.8.1">Learning to model the world with language, 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib29.9.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://arxiv.org/abs/2308.01399" title="">https://arxiv.org/abs/2308.01399</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib29.10.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib30.5.5.1">Liu et al. (2018)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib30.7.1">
Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin Shi, and Percy Liang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib30.8.1">Reinforcement learning on web interfaces using workflow-guided exploration.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib30.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib30.10.2">International Conference on Learning Representations (ICLR)</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib30.11.3">, 2018.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib30.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://arxiv.org/abs/1802.08802" title="">https://arxiv.org/abs/1802.08802</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib30.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib31.5.5.1">Liu et al. (2024a)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib31.7.1">
Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib31.8.1">Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib31.9.1">Advances in Neural Information Processing Systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib31.10.2">, 36, 2024a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib32.5.5.1">Liu et al. (2024b)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib32.7.1">
Zeyuan Liu, Ziyu Huan, Xiyao Wang, Jiafei Lyu, Jian Tao, Xiu Li, Furong Huang, and Huazhe Xu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib32.8.1">World models with hints of large language models for goal achieving.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib32.9.1">arXiv preprint arXiv:2406.07381</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib32.10.2">, 2024b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib33.5.5.1">Lokshtanov &amp; Subercaseaux (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib33.7.1">
Daniel Lokshtanov and Bernardo Subercaseaux.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib33.8.1">Wordle is np-hard.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib33.9.1">ArXiv</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib33.10.2">, abs/2203.16713, 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib33.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:247839521" title="">https://api.semanticscholar.org/CorpusID:247839521</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib33.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib34.5.5.1">Ma et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib34.7.1">
Yecheng Jason Ma, William Liang, Guanzhi Wang, De-An Huang, Osbert Bastani, Dinesh Jayaraman, Yuke Zhu, Linxi Fan, and Anima Anandkumar.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib34.8.1">Eureka: Human-level reward design via coding large language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib34.9.1">ArXiv</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib34.10.2">, abs/2310.12931, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib34.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:264306288" title="">https://api.semanticscholar.org/CorpusID:264306288</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib34.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib35.5.5.1">Manigrasso et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib35.7.1">
Francesco Manigrasso, Stefan Schouten, Lia Morra, and Peter Bloem.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib35.8.1">Probing llms for logical reasoning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib35.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib35.10.2">International Conference on Neural-Symbolic Learning and Reasoning</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib35.11.3">, pp.  257–278. Springer, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib36.5.5.1">Mialon et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib36.7.1">
Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann LeCun, and Thomas Scialom.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib36.8.1">Augmented language models: a survey, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib36.9.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://arxiv.org/abs/2302.07842" title="">https://arxiv.org/abs/2302.07842</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib36.10.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib37.5.5.1">Mullen Jr &amp; Manocha (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib37.7.1">
James F Mullen Jr and Dinesh Manocha.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib37.8.1">Towards robots that know when they need help: Affordance-based uncertainty for large language model planners.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib37.9.1">arXiv preprint arXiv:2403.13198</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib37.10.2">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib38.5.5.1">Ouyang et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib38.7.1">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib38.8.1">Training language models to follow instructions with human feedback.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib38.9.1">Advances in neural information processing systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib38.10.2">, 35:27730–27744, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib39.5.5.1">Padalkar et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib39.7.1">
Abhishek Padalkar, Acorn Pooley, Ajinkya Jain, Alex Bewley, Alex Herzog, Alex Irpan, Alexander Khazatsky, Anant Rai, Anikait Singh, Anthony Brohan, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib39.8.1">Open x-embodiment: Robotic learning datasets and rt-x models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib39.9.1">arXiv preprint arXiv:2310.08864</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib39.10.2">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib40.4.4.1">Puterman (2014)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib40.6.1">
Martin L Puterman.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib40.7.1">Markov decision processes: discrete stochastic dynamic programming</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib40.8.2">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib40.9.1">John Wiley &amp; Sons, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib41.5.5.1">Radford et al. (2021)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib41.7.1">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib41.8.1">Learning transferable visual models from natural language supervision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib41.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib41.10.2">International Conference on Machine Learning</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib41.11.3">, 2021.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib41.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:231591445" title="">https://api.semanticscholar.org/CorpusID:231591445</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib41.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib42.5.5.1">Rafailov et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib42.7.1">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib42.8.1">Direct preference optimization: Your language model is secretly a reward model, 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib42.9.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://arxiv.org/abs/2305.18290" title="">https://arxiv.org/abs/2305.18290</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib42.10.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib43.5.5.1">Reid et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib43.7.1">
Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy Lillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib43.8.1">Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib43.9.1">arXiv preprint arXiv:2403.05530</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib43.10.2">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib44.5.5.1">Rocamonde et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib44.7.1">
Juan Rocamonde, Victoriano Montesinos, Elvis Nava, Ethan Perez, and David Lindner.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib44.8.1">Vision-language models are zero-shot reward models for reinforcement learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib44.9.1">arXiv preprint arXiv:2310.12921</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib44.10.2">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib45.5.5.1">Shaw et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib45.7.1">
Peter Shaw, Mandar Joshi, James Cohan, Jonathan Berant, Panupong Pasupat, Hexiang Hu, Urvashi Khandelwal, Kenton Lee, and Kristina Toutanova.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib45.8.1">From pixels to ui actions: Learning to follow instructions via graphical user interfaces.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib45.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib45.10.2">Advances in Neural Information Processing Systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib45.11.3">, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib45.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://arxiv.org/abs/2306.00245" title="">https://arxiv.org/abs/2306.00245</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib45.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib46.5.5.1">Shinn et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib46.7.1">
Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib46.8.1">Reflexion: Language agents with verbal reinforcement learning.(2023).
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib46.9.1">arXiv preprint cs.AI/2303.11366</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib46.10.2">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib47.5.5.1">Singhal et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib47.7.1">
Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib47.8.1">Large language models encode clinical knowledge.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib47.9.1">arXiv preprint arXiv:2212.13138</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib47.10.2">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib48.5.5.1">Snell et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib48.7.1">
Charles Burton Snell, Ilya Kostrikov, Yi Su, Mengjiao Yang, and Sergey Levine.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib48.8.1">Offline rl for natural language generation with implicit language q learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib48.9.1">ArXiv</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib48.10.2">, abs/2206.11871, 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib48.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:249954054" title="">https://api.semanticscholar.org/CorpusID:249954054</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib48.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib49.5.5.1">Stiennon et al. (2020)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib49.7.1">
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul F Christiano.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib49.8.1">Learning to summarize with human feedback.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib49.9.1">Advances in Neural Information Processing Systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib49.10.2">, 33:3008–3021, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib50.5.5.1">Sutton &amp; Barto (2018)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib50.7.1">
Richard S. Sutton and Andrew G. Barto.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib50.8.1">Reinforcement Learning: An Introduction</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib50.9.2">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib50.10.1">The MIT Press, second edition, 2018.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib50.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="http://incompleteideas.net/book/the-book-2nd.html" title="">http://incompleteideas.net/book/the-book-2nd.html</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib50.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib51.5.5.1">Sutton et al. (1999)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib51.7.1">
Richard S. Sutton, David A. McAllester, Satinder Singh, and Y. Mansour.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib51.8.1">Policy gradient methods for reinforcement learning with function approximation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib51.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib51.10.2">Neural Information Processing Systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib51.11.3">, 1999.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib51.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:1211821" title="">https://api.semanticscholar.org/CorpusID:1211821</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib51.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib52.5.5.1">Szot et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib52.7.1">
Andrew Szot, Max Schwarzer, Harsh Agrawal, Bogdan Mazoure, Rin Metcalf, Walter Talbott, Natalie Mackraz, R Devon Hjelm, and Alexander T Toshev.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib52.8.1">Large language models as generalizable policies for embodied tasks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib52.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib52.10.2">The Twelfth International Conference on Learning Representations</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib52.11.3">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib53.5.5.1">Szot et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib53.7.1">
Andrew Szot, Bogdan Mazoure, Harsh Agrawal, Devon Hjelm, Zsolt Kira, and Alexander Toshev.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib53.8.1">Grounding multimodal large language models in actions.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib53.9.1">arXiv preprint arXiv:2406.07904</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib53.10.2">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib54.5.5.1">Team et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib54.7.1">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib54.8.1">Gemini: a family of highly capable multimodal models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib54.9.1">arXiv preprint arXiv:2312.11805</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib54.10.2">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib55.5.5.1">Touvron et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib55.7.1">
Hugo Touvron, Louis Martin, Kevin R. Stone, Peter Albert, Amjad Almahairi, and Yasmine Babaei et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib55.8.1">Llama 2: Open foundation and fine-tuned chat models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib55.9.1">ArXiv</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib55.10.2">, abs/2307.09288, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib55.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:259950998" title="">https://api.semanticscholar.org/CorpusID:259950998</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib55.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib56.5.5.1">Uesato et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib56.7.1">
Jonathan Uesato, Nate Kushman, Ramana Kumar, H. Francis Song, Noah Yamamoto Siegel, Lisa Wang, Antonia Creswell, Geoffrey Irving, and Irina Higgins.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib56.8.1">Solving math word problems with process-based and outcome-based feedback, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib56.9.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://openreview.net/forum?id=MND1kmmNy0O" title="">https://openreview.net/forum?id=MND1kmmNy0O</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib56.10.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib57.5.5.1">Venuto et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib57.7.1">
David Venuto, Sami Nur Islam, Martin Klissarov, Doina Precup, Sherry Yang, and Ankit Anand.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib57.8.1">Code as reward: Empowering reinforcement learning with vlms.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib57.9.1">ArXiv</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib57.10.2">, abs/2402.04764, 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib57.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:267522976" title="">https://api.semanticscholar.org/CorpusID:267522976</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib57.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib58.5.5.1">Wang et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib58.7.1">
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib58.8.1">Voyager: An open-ended embodied agent with large language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib58.9.1">arXiv preprint arXiv:2305.16291</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib58.10.2">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib59.5.5.1">Wang et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib59.7.1">
Yufei Wang, Zhanyi Sun, Jesse Zhang, Zhou Xian, Erdem Biyik, David Held, and Zackory Erickson.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib59.8.1">Rl-vlm-f: Reinforcement learning from vision language foundation model feedback.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib59.9.1">arXiv preprint arXiv:2402.03681</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib59.10.2">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib60.5.5.1">Watkins &amp; Dayan (1992)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib60.7.1">
Christopher Watkins and Peter Dayan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib60.8.1">Q-learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib60.9.1">Machine Learning</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib60.10.2">, 8:279–292, 1992.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib60.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:208910339" title="">https://api.semanticscholar.org/CorpusID:208910339</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib60.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib61.5.5.1">Wei et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib61.7.1">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Huai hsin Chi, F. Xia, Quoc Le, and Denny Zhou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib61.8.1">Chain of thought prompting elicits reasoning in large language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib61.9.1">ArXiv</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib61.10.2">, abs/2201.11903, 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib61.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:246411621" title="">https://api.semanticscholar.org/CorpusID:246411621</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib61.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib62.5.5.1">Xu et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib62.7.1">
Derong Xu, Wei Chen, Wenjun Peng, Chao Zhang, Tong Xu, Xiangyu Zhao, Xian Wu, Yefeng Zheng, Yang Wang, and Enhong Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib62.8.1">Large language models for generative information extraction: A survey, 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib62.9.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://arxiv.org/abs/2312.17617" title="">https://arxiv.org/abs/2312.17617</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib62.10.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib63.5.5.1">Yao et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib63.7.1">
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib63.8.1">React: Synergizing reasoning and acting in language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib63.9.1">arXiv preprint arXiv:2210.03629</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib63.10.2">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib64.5.5.1">Yifan Li &amp; Wen (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib64.7.1">
Kun Zhou Jinpeng Wang Wayne Xin Zhao Yifan Li, Yifan Du and Ji-Rong Wen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib64.8.1">Evaluating object hallucination in large vision-language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib64.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib64.10.2">The 2023 Conference on Empirical Methods in Natural Language Processing</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib64.11.3">, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib64.12.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://openreview.net/forum?id=xozJw0kZXF" title="">https://openreview.net/forum?id=xozJw0kZXF</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib64.13.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib65.5.5.1">Yu et al. (2019)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib65.7.1">
Tianhe Yu, Deirdre Quillen, Zhanpeng He, Ryan Julian, Karol Hausman, Chelsea Finn, and Sergey Levine.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib65.8.1">Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib65.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib65.10.2">Conference on Robot Learning (CoRL)</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib65.11.3">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib66.5.5.1">Yu et al. (2023)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib66.7.1">
Wenhao Yu, Nimrod Gileadi, Chuyuan Fu, Sean Kirmani, Kuang-Huei Lee, Montse Gonzalez Arenas, Hao-Tien Lewis Chiang, Tom Erez, Leonard Hasenclever, Jan Humplik, Brian Ichter, Ted Xiao, Peng Xu, Andy Zeng, Tingnan Zhang, Nicolas Manfred Otto Heess, Dorsa Sadigh, Jie Tan, Yuval Tassa, and F. Xia.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib66.8.1">Language to rewards for robotic skill synthesis.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib66.9.1">ArXiv</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib66.10.2">, abs/2306.08647, 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib66.11.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://api.semanticscholar.org/CorpusID:259164906" title="">https://api.semanticscholar.org/CorpusID:259164906</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib66.12.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib67.5.5.1">Yue et al. (2024)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib67.7.1">
Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib67.8.1">Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib67.9.1">In </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib67.10.2">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib67.11.3">, pp.  9556–9567, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib68.5.5.1">Zelikman et al. (2022)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib68.7.1">
Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib68.8.1">Star: Bootstrapping reasoning with reasoning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib68.9.1">Advances in Neural Information Processing Systems</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib68.10.2">, 35:15476–15488, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib69.5.5.1">Zhang et al. (2024a)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib69.7.1">
Muru Zhang, Ofir Press, William Merrill, Alisa Liu, and Noah A. Smith.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib69.8.1">How language model hallucinations can snowball.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib69.9.1">In Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp (eds.), </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib69.10.2">Proceedings of the 41st International Conference on Machine Learning</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib69.11.3">, volume 235 of </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib69.12.4">Proceedings of Machine Learning Research</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib69.13.5">, pp.  59670–59684. PMLR, 21–27 Jul 2024a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib69.14.1">URL </span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://proceedings.mlr.press/v235/zhang24ay.html" title="">https://proceedings.mlr.press/v235/zhang24ay.html</a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib69.15.2">.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib70.5.5.1">Zhang et al. (2024b)</span></span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib70.7.1">
Shenao Zhang, Sirui Zheng, Shuqi Ke, Zhihan Liu, Wanxin Jin, Jianbo Yuan, Yingxiang Yang, Hongxia Yang, and Zhaoran Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib70.8.1">How can llm guide rl? a value-based approach.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="bib.bib70.9.1">arXiv preprint arXiv:2402.16181</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="bib.bib70.10.2">, 2024b.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.1.1.1">Appendix A</span> </span>Appendix</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.SS1.1.1.1">A.1</span> </span>Environment Details</h3>
<div class="ltx_para ltx_noindent" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.1">In our experiments, we investigate tasks from four different domains: MiniWob </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Liu et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib30" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2018</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.5">, NetHack </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.6.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Küttler et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.7.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib26" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2020</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.8.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.9">, and Wordle </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.10.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Lokshtanov &amp; Subercaseaux</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.11.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib33" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.12.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.13">, and MetaWorld </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.14.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yu et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.15.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib65" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2019</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.16.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p1.1.17">. The observation space for all these environments is text, except fro MetaWorld which consists of RGB pixels.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.1">In the MiniWob domain, we sample the subset of the five tasks on which state-of-the-art results are low. Specifically, we carry experiments on: </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS1.p2.1.2">click-tab-2-hard</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.3">, </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS1.p2.1.4">click-checkboxes-soft</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.5">, </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS1.p2.1.6">count-shape</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.7">, </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS1.p2.1.8">tic-tac-toe</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.9"> and </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS1.p2.1.10">use-autocomplete</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.11">. To learn RL policies from LLM-based rewards, we leverage the experimental setup of </span><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text ltx_font_sansserif ltx_font_bold">Shaw et al.</span> <span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.12.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib45" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.13.2.2.1">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.14">. In NetHack, we use the same environment and the same algorithmic setup as in </span><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text ltx_font_sansserif ltx_font_bold">Klissarov et al.</span> <span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.15.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib23" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.16.2.2.1">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.17">. In Wordle, we build on the code made available by </span><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text ltx_font_sansserif ltx_font_bold">Snell et al.</span> <span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.18.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib48" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.19.2.2.1">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.20"> and use their proposed subset of 200 words from the official list of the game. Finally, in MetaWorld we study the same subset of environments presented in </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.21.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Wang et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.22.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib59" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.23.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.24"> consisting of </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS1.p2.1.25">drawer-open-v2</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.26">, </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS1.p2.1.27">soccer-v2</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.28"> and </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS1.p2.1.29">sweep-into-v2</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS1.p2.1.30">. Across all experiments where RL policies are learned, we use the original hyperparameter values defined in the respective experimental setups we are building upon.</span></p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.SS2.1.1.1">A.2</span> </span>Details on Indirect Policy Modeling Through LLM-based Rewards</h3>
<div class="ltx_para ltx_noindent" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS2.p1.1.1">We use the following prompt templates to query the agent for AI feedback, Scalar Reward and Reward as Code across various environments. For the Embedding-based approach, we use calculate the cosine similarity between the representation, provided by a BERT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS2.p1.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Devlin et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS2.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib12" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2019</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS2.p1.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS2.p1.1.5"> sentence encoder (specifically the same </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS2.p1.1.6">paraphrase-MiniLM-L3-v2</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS2.p1.1.7"> model) when environments are text-based, and otherwise we use the CLIP encoder </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS2.p1.1.8.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Radford et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS2.p1.1.9.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib41" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2021</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS2.p1.1.10.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS2.p1.1.11">. The similarity is measured between the current observation and the same goal description contained in the each of the following prompts given for the other baselines.</span></p>
</div>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt1.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt1.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt1.2.1">[frametitle=MiniWob Prompt For Reward Modeling with AI feedback]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt1.2.2">I will present you with two HTML descriptions from a web interaction environment.
<br class="ltx_break"/>
<br class="ltx_break"/>{task_description}

<br class="ltx_break"/>Write an analysis describing the semantics of each description strictly using information from the descriptions.
<br class="ltx_break"/>Provide a comparative analysis based on first principles.
<br class="ltx_break"/>Finally, express a preference based on which description is the most likely to make some progress towards the goal,
writing either ("best_description": 1), ("best_description": 2).
<br class="ltx_break"/>You could also say ("best_description": None).
<br class="ltx_break"/>
<br class="ltx_break"/>html_description_1: {description_1} 
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt1.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt1.3.1">html_description_2: {description_2} 
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt1.5.1.1">List of Prompts 1</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt2.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt2.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt2.2.1">[frametitle=Wordle Prompt For Reward Modeling with AI feedback]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt2.2.2">I will present you with two short gameplay descriptions of Wordle.
<br class="ltx_break"/>
<br class="ltx_break"/>First, tell me about your knowledge of Wordle.
<br class="ltx_break"/>
<br class="ltx_break"/>Mention the goal of Wordle. Use the following information for Wordle states:
black means that the provided letter is not present anywhere in the hidden word.
yellow means that the provided letter is present somewhere in the hidden word, but not at the correct position.
green means that the provided letter is present in the hidden word exactly at the correct position.
<br class="ltx_break"/>
<br class="ltx_break"/>Then, write an analysis describing the semantics of each description strictly using information from the descriptions (which may be empty) and your knowledge of Wordle.
<br class="ltx_break"/>Provide a comparative analysis based on first principles.
<br class="ltx_break"/>Finally, express a preference based on which description is the most likely to make some progress towards the goal,
writing either ("best_description": 1), ("best_description": 2).
<br class="ltx_break"/>You could also say ("best_description": None).
<br class="ltx_break"/>
<br class="ltx_break"/>description_1: {description_1} 
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt2.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt2.3.1">description_2: {description_2} 
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt2.5.1.1">List of Prompts 2</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt3.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt3.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt3.2.1">[frametitle=NetHack Prompt For Reward Modeling with AI feedback]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt3.2.2">I will present you with two short gameplay descriptions of Nethack.
<br class="ltx_break"/>
<br class="ltx_break"/>First, tell me about your knowledge of NetHack.
<br class="ltx_break"/>
<br class="ltx_break"/>Mention the goal of NetHack. Prefer agents that maximize the score in the game, for instance by killing monsters, collecting gold or going down the stairs in the dungeon.
<br class="ltx_break"/>
<br class="ltx_break"/>Then, write an analysis describing the semantics of each description strictly using information from the descriptions (which may be empty) and your knowledge of NetHack.
<br class="ltx_break"/>Provide a comparative analysis based on first principles.
<br class="ltx_break"/>Finally, express a preference based on which description is the most likely to make some progress towards the goal,
writing either ("best_description": 1), ("best_description": 2).
<br class="ltx_break"/>You could also say ("best_description": None).
<br class="ltx_break"/>
<br class="ltx_break"/>description_1: {description_1} 
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt3.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt3.3.1">description_2: {description_2} 
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt3.5.1.1">List of Prompts 3</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt4.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt4.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt4.2.1">[frametitle=NetHack Prompt For Online Reward Modeling with AI feedback]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt4.2.2">I will present you with two short gameplay descriptions of Nethack.
<br class="ltx_break"/>
<br class="ltx_break"/>First, tell me about your knowledge of NetHack.
<br class="ltx_break"/>
<br class="ltx_break"/>Mention the goal of NetHack. Prefer agents that maximize the score in the game, for instance by killing monsters, collecting gold or going down the stairs in the dungeon.
<br class="ltx_break"/>
<br class="ltx_break"/>Then, write an analysis describing the semantics of each description strictly using information from the descriptions (which may be empty) and your knowledge of NetHack.
<br class="ltx_break"/>Provide a comparative analysis based on first principles.
<br class="ltx_break"/>Finally, express a preference based on which description is the most likely to make some progress towards the goal,
writing either ("best_description": 1), ("best_description": 2).
<br class="ltx_break"/>You could also say ("best_description": None).
<br class="ltx_break"/>
<br class="ltx_break"/>description_1: {description_1} 
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt4.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt4.3.1">description_2: {description_2} 
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt4.5.1.1">List of Prompts 4</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt5.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt5.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt5.2.1">[frametitle=MetaWorld Prompt For Reward Modeling with AI feedback]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt5.2.2">Does the image satisfy {current_task}?
<br class="ltx_break"/>image_1: {image_1} 
<br class="ltx_break"/><span class="ltx_text" id="none0.prompt5.2.2.1" style="color:#0000FF;">{llm_response}
<br class="ltx_break"/>
<br class="ltx_break"/></span>Does the image satisfy {current_task}?
<br class="ltx_break"/>image_2: {image_2} 
<br class="ltx_break"/><span class="ltx_text" id="none0.prompt5.2.2.2" style="color:#0000FF;">{llm_response}</span>
</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt5.2.3"></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt5.4.1.1">List of Prompts 5</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt6.3">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt6.4"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt6.4.1">[frametitle=MiniWob Prompt For Reward Modeling with Scalar Reward]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt6.4.2">I will present you with an HTML descriptions from a web interaction environment.
<br class="ltx_break"/>
<br class="ltx_break"/>{task_description}
<br class="ltx_break"/>
<br class="ltx_break"/>Write an analysis describing the semantics of the description strictly using information from the description.
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt6.2"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt6.2.2">Finally, output a scalar value between <math alttext="0" class="ltx_Math" display="inline" id="none0.prompt6.1.1.m1.1"><semantics id="none0.prompt6.1.1.m1.1a"><mn id="none0.prompt6.1.1.m1.1.1" xref="none0.prompt6.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="none0.prompt6.1.1.m1.1b"><cn id="none0.prompt6.1.1.m1.1.1.cmml" type="integer" xref="none0.prompt6.1.1.m1.1.1">0</cn></annotation-xml></semantics></math> and <math alttext="5" class="ltx_Math" display="inline" id="none0.prompt6.2.2.m2.1"><semantics id="none0.prompt6.2.2.m2.1a"><mn id="none0.prompt6.2.2.m2.1.1" xref="none0.prompt6.2.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="none0.prompt6.2.2.m2.1b"><cn id="none0.prompt6.2.2.m2.1.1.cmml" type="integer" xref="none0.prompt6.2.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="none0.prompt6.2.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="none0.prompt6.2.2.m2.1d">5</annotation></semantics></math>, with higher values correlation with progress towards the goal.
<br class="ltx_break"/>
<br class="ltx_break"/>html_description: {description} 
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt6.6.1.1">List of Prompts 6</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt7.3">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt7.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt7.2.3">[frametitle=Wordle Prompt For Reward Modeling with Scalar Reward]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt7.2.2">I will present you with a gameplay description of Wordle.
<br class="ltx_break"/>
<br class="ltx_break"/>First, tell me about your knowledge of Wordle.
<br class="ltx_break"/>
<br class="ltx_break"/>Mention the goal of Wordle. Use the following information for Wordle states:
black means that the provided letter is not present anywhere in the hidden word.
yellow means that the provided letter is present somewhere in the hidden word, but not at the correct position.
green means that the provided letter is present in the hidden word exactly at the correct position.
<br class="ltx_break"/>
<br class="ltx_break"/>Write an analysis describing the semantics of the description strictly using information from the description.
<br class="ltx_break"/>Finally, output a scalar value between <math alttext="0" class="ltx_Math" display="inline" id="none0.prompt7.1.1.m1.1"><semantics id="none0.prompt7.1.1.m1.1a"><mn id="none0.prompt7.1.1.m1.1.1" xref="none0.prompt7.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="none0.prompt7.1.1.m1.1b"><cn id="none0.prompt7.1.1.m1.1.1.cmml" type="integer" xref="none0.prompt7.1.1.m1.1.1">0</cn></annotation-xml></semantics></math> and <math alttext="5" class="ltx_Math" display="inline" id="none0.prompt7.2.2.m2.1"><semantics id="none0.prompt7.2.2.m2.1a"><mn id="none0.prompt7.2.2.m2.1.1" xref="none0.prompt7.2.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="none0.prompt7.2.2.m2.1b"><cn id="none0.prompt7.2.2.m2.1.1.cmml" type="integer" xref="none0.prompt7.2.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="none0.prompt7.2.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="none0.prompt7.2.2.m2.1d">5</annotation></semantics></math>, with higher values correlation with progress towards the goal.
<br class="ltx_break"/>description: {description} 
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt7.5.1.1">List of Prompts 7</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt8.3">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt8.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt8.2.3">[frametitle=NetHack Prompt For Reward Modeling with Scalar Reward]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt8.2.2">I will present you with a gameplay description of Nethack.
<br class="ltx_break"/>
<br class="ltx_break"/>First, tell me about your knowledge of NetHack.
<br class="ltx_break"/>
<br class="ltx_break"/>Mention the goal of NetHack. Prefer agents that maximize the score in the game, for instance by killing monsters, collecting gold or going down the stairs in the dungeon.
<br class="ltx_break"/>
<br class="ltx_break"/>Write an analysis describing the semantics of the description strictly using information from the description.
<br class="ltx_break"/>Finally, output a scalar value between <math alttext="0" class="ltx_Math" display="inline" id="none0.prompt8.1.1.m1.1"><semantics id="none0.prompt8.1.1.m1.1a"><mn id="none0.prompt8.1.1.m1.1.1" xref="none0.prompt8.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="none0.prompt8.1.1.m1.1b"><cn id="none0.prompt8.1.1.m1.1.1.cmml" type="integer" xref="none0.prompt8.1.1.m1.1.1">0</cn></annotation-xml></semantics></math> and <math alttext="5" class="ltx_Math" display="inline" id="none0.prompt8.2.2.m2.1"><semantics id="none0.prompt8.2.2.m2.1a"><mn id="none0.prompt8.2.2.m2.1.1" xref="none0.prompt8.2.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="none0.prompt8.2.2.m2.1b"><cn id="none0.prompt8.2.2.m2.1.1.cmml" type="integer" xref="none0.prompt8.2.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="none0.prompt8.2.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="none0.prompt8.2.2.m2.1d">5</annotation></semantics></math>, with higher values correlation with progress towards the goal.
<br class="ltx_break"/>description: {description} 
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt8.5.1.1">List of Prompts 8</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt9">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt9.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt9.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt9.2.1">[frametitle=MetaWorld Prompt For Reward Modeling with Scalar Reward]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt9.2.2">From 0 to 5, how much does the image achieve{current_task}?
<br class="ltx_break"/>image: {image}
</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt9.2.3"></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt9.4.1.1">List of Prompts 9</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt10.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt10.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt10.2.1">[frametitle=MiniWob Prompt For Reward Modeling with Reward as Code]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt10.2.2">I will present you with HTML descriptions from a web interaction environment.
<br class="ltx_break"/>
<br class="ltx_break"/>{task_description}
<br class="ltx_break"/>
<br class="ltx_break"/>Write an analysis describing the semantics of the descriptions strictly using information from the descriptions.
<br class="ltx_break"/></span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt10.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt10.3.1">Finally, write a code that, when executed, will help make progress towards the goal.
<br class="ltx_break"/>
<br class="ltx_break"/>html_descriptions: {descriptions} 
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt10.5.1.1">List of Prompts 10</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt11">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt11.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt11.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt11.2.1">[frametitle=Wordle Prompt For Reward Modeling with Reward as Code]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt11.2.2">I will present you with gameplay descriptions of Wordle.
<br class="ltx_break"/>
<br class="ltx_break"/>First, tell me about your knowledge of Wordle.
<br class="ltx_break"/>
<br class="ltx_break"/>Mention the goal of Wordle. Use the following information for Wordle states:
black means that the provided letter is not present anywhere in the hidden word.
yellow means that the provided letter is present somewhere in the hidden word, but not at the correct position.
green means that the provided letter is present in the hidden word exactly at the correct position.
<br class="ltx_break"/>
<br class="ltx_break"/>Write an analysis describing the semantics of the descriptions strictly using information from the description.
<br class="ltx_break"/>Finally, write a code that, when executed, will help make progress towards the goal.
<br class="ltx_break"/>descriptions: {descriptions} 
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt11.4.1.1">List of Prompts 11</span> </span></figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt12">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt12.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt12.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt12.2.1">[frametitle=NetHack Prompt For Reward Modeling with Reward as Code]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt12.2.2">I will present you with gameplay descriptions of Nethack.
<br class="ltx_break"/>
<br class="ltx_break"/>First, tell me about your knowledge of NetHack.
<br class="ltx_break"/>
<br class="ltx_break"/>Mention the goal of NetHack. Prefer agents that maximize the score in the game, for instance by killing monsters, collecting gold or going down the stairs in the dungeon.
<br class="ltx_break"/>
<br class="ltx_break"/>Write an analysis describing the semantics of the descriptions strictly using information from the descriptions.
<br class="ltx_break"/>Finally, write a code that, when executed, will help make progress towards the goal.
<br class="ltx_break"/>descriptions: {descriptions} 
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt12.4.1.1">List of Prompts 12</span> </span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.SS3.1.1.1">A.3</span> </span>Details on Direct Policy Modeling</h3>
<div class="ltx_para ltx_noindent" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS3.p1.1.1">We present the exact prompts used to query GPT-4o for each of the domains we have considered. These are presented through Prompt </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#none0.prompt13" title="List of Prompts 13 ‣ A.3 Details on Direct Policy Modeling ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">13</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS3.p1.1.2">, </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#none0.prompt15" title="List of Prompts 15 ‣ A.3 Details on Direct Policy Modeling ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">15</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS3.p1.1.3">, </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#none0.prompt14" title="List of Prompts 14 ‣ A.3 Details on Direct Policy Modeling ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">14</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS3.p1.1.4"> and </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#none0.prompt16" title="List of Prompts 16 ‣ A.3 Details on Direct Policy Modeling ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">16</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS3.p1.1.5">.</span></p>
</div>
<figure class="ltx_figure" id="A1.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="345" id="A1.F7.g1" src="x11.png" width="415"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.F7.3.1.1">Figure 7</span>: </span>Ablation on the set of prompting techniques used for direct policy modeling. The reported performance is averaged over all domains and tasks.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A1.SS3.p2">
<p class="ltx_p" id="A1.SS3.p2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS3.p2.1.1">Additionally, in Figure </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.F7" title="Figure 7 ‣ A.3 Details on Direct Policy Modeling ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">7</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS3.p2.1.2">, we ablate the prompting techniques used in our direct policy modeling approach. Results show that a combination of all prompting techniques presened in Section </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S2.SS1" title="2.1 Prompting ‣ 2 Using Language Models to Solve RL Tasks ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">2.1</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS3.p2.1.3"> works best.</span></p>
</div>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt13">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt13.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt13.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt13.2.1">[frametitle=MiniWob-Hard Prompt For Direct Policy Modeling]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt13.2.2">We have an autonomous computer control agent that can perform atomic instructions specified by natural language to control computers. There are two types of instructions it can execute. 
<br class="ltx_break"/>
<br class="ltx_break"/>First, given the instruction that matches the regular expression, <span class="ltx_text" id="none0.prompt13.2.2.1">"^type.{1,}$"</span>
<br class="ltx_break"/>Second, given the instruction that matches the regular expression, <span class="ltx_text" id="none0.prompt13.2.2.2">"^clickxpath\s.{1,}$"</span>
it can click an HTML element with an xpath that is visible on the webpage. The target of this instruction should be a valid xpath. 
<br class="ltx_break"/>
<br class="ltx_break"/>Below is the HTML code of the webpage where the agent should solve a task. 
<br class="ltx_break"/>
<br class="ltx_break"/>{html_observation} 
<br class="ltx_break"/>
<br class="ltx_break"/>Examples: 
<br class="ltx_break"/>task: {example_task}
<br class="ltx_break"/>plan: {example_plan}
<br class="ltx_break"/>
<br class="ltx_break"/>Current task: Enter an item that starts with Äntiänd ends with d̈a.̈ 
<br class="ltx_break"/>Think step-by-step before answering, what is the current plan? {<span class="ltx_text" id="none0.prompt13.2.2.3" style="color:#0000FF;">llm_plan</span>} 
<br class="ltx_break"/>
<br class="ltx_break"/>=============== 
<br class="ltx_break"/>Repeat N times: 
<br class="ltx_break"/>
<br class="ltx_break"/>Find problems with this plan for the given task compared to the example plans. 
<br class="ltx_break"/>
<br class="ltx_break"/>{<span class="ltx_text" id="none0.prompt13.2.2.4" style="color:#0000FF;">llm_criticism</span>} 
<br class="ltx_break"/>
<br class="ltx_break"/>Based on this, what is the plan for the agent to complete the task? 
<br class="ltx_break"/>
<br class="ltx_break"/>Below is the HTML code of the webpage where the agent should solve a task. 
<br class="ltx_break"/>{html_observation} 
<br class="ltx_break"/>
<br class="ltx_break"/>Current task: Enter an item that starts with Äntiänd ends with d̈a.̈ 
<br class="ltx_break"/>Think step-by-step before answering, what is the current plan? {<span class="ltx_text" id="none0.prompt13.2.2.5" style="color:#0000FF;">llm_plan</span>} 
<br class="ltx_break"/>=============== 
<br class="ltx_break"/></span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt13.2.3"></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt13.5.1.1">List of Prompts 13</span> </span>
</figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt14">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt14.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt14.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt14.2.1">[frametitle=Wordle Prompt for Direct Policy Modeling]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt14.2.2">Let’s play a game of Wordle. You will have to guess the words and I will give you the colors.
<br class="ltx_break"/>
<br class="ltx_break"/>Use the following information for Wordle colors:
<br class="ltx_break"/>black means that the provided letter is not present anywhere in the hidden word.
<br class="ltx_break"/>yellow means that the provided letter is present somewhere in the hidden word, but not at the correct position.
<br class="ltx_break"/>green means that the provided letter is present in the hidden word exactly at the correct position.
<br class="ltx_break"/>
<br class="ltx_break"/>You can choose among this list of words: {list_of_words}
<br class="ltx_break"/>
<br class="ltx_break"/>Here are examples trajectories, containing past observations and actions, together with an appropriate action.
<br class="ltx_break"/>
<br class="ltx_break"/>Example 1:
<br class="ltx_break"/>Trajectory: {example_trajectory}
<br class="ltx_break"/>Action: {example_action}
<br class="ltx_break"/>
<br class="ltx_break"/>Example 2:
<br class="ltx_break"/>Trajectory: {example_trajectory}
<br class="ltx_break"/>Action: {example_action}
<br class="ltx_break"/>
<br class="ltx_break"/>Current trajectory: {trajectory_so_far}
<br class="ltx_break"/>Think step-by-step before answering, what should be the current action? {<span class="ltx_text" id="none0.prompt14.2.2.1" style="color:#0000FF;">llm_action</span>}
<br class="ltx_break"/>
<br class="ltx_break"/>==============
<br class="ltx_break"/>Repeat N times:
<br class="ltx_break"/>
<br class="ltx_break"/>Find problems with this action for the given task compared to the example actions.
<br class="ltx_break"/>
<br class="ltx_break"/>{<span class="ltx_text" id="none0.prompt14.2.2.2" style="color:#0000FF;">llm_criticism</span>}
<br class="ltx_break"/>
<br class="ltx_break"/>Based on this, what is the action for the agent to make progress on the task?
<br class="ltx_break"/>
<br class="ltx_break"/>Current trajectory: {trajectory_so_far}
<br class="ltx_break"/>Think step-by-step before answering, what should be the current action? {<span class="ltx_text" id="none0.prompt14.2.2.3" style="color:#0000FF;">llm_action</span>}
<br class="ltx_break"/>==============
<br class="ltx_break"/></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt14.5.1.1">List of Prompts 14</span> </span>
</figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt15">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt15.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt15.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt15.2.1">[frametitle=NetHack Prompt for Direct Policy Modeling]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt15.2.2">Let’s play the game of NetHack.

<br class="ltx_break"/>
<br class="ltx_break"/>First, tell me about your knowledge of NetHack. Mention the goal of NetHack.

<br class="ltx_break"/>
<br class="ltx_break"/>Prefer maximizing the score in the game, for instance by killing monsters, collecting gold or going down the stairs in the dungeon.

<br class="ltx_break"/>
<br class="ltx_break"/>Here are examples sub-trajectories, containing past observations and actions, together with an appropriate action.

<br class="ltx_break"/>
<br class="ltx_break"/>Example 1:

<br class="ltx_break"/>sub-Trajectory: {example_sub-trajectory}

<br class="ltx_break"/>Action: {example_action}

<br class="ltx_break"/>
<br class="ltx_break"/>Example 2:

<br class="ltx_break"/>sub-Trajectory: {example_sub-trajectory}

<br class="ltx_break"/>Action: {example_action}

<br class="ltx_break"/>
<br class="ltx_break"/>Current sub-trajectory: {sub-trajectory_so_far}

<br class="ltx_break"/>Think step-by-step before answering, what should be the current action? {<span class="ltx_text" id="none0.prompt15.2.2.1" style="color:#0000FF;">llm_action</span>}

<br class="ltx_break"/>
<br class="ltx_break"/>==============

<br class="ltx_break"/>Repeat N times:

<br class="ltx_break"/>
<br class="ltx_break"/>Find problems with this action for the given task compared to the example actions.

<br class="ltx_break"/>
<br class="ltx_break"/>{<span class="ltx_text" id="none0.prompt15.2.2.2" style="color:#0000FF;">llm_criticism</span>}

<br class="ltx_break"/>
<br class="ltx_break"/>Based on this, what is the action for the agent to make progress on the task?

<br class="ltx_break"/>
<br class="ltx_break"/>Here is the current sub-trajectory, containing past observations and actions: {sub-trajectory_so_far}

<br class="ltx_break"/>Think step-by-step before answering, what should be the current action? {<span class="ltx_text" id="none0.prompt15.2.2.3" style="color:#0000FF;">llm_action</span>}

<br class="ltx_break"/>==============
</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt15.2.3"></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt15.5.1.1">List of Prompts 15</span> </span>
</figcaption>
</figure>
<figure class="ltx_float ltx_float_prompt" id="none0.prompt16">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="none0.prompt16.1">{mymessagebox}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="none0.prompt16.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="none0.prompt16.2.1">[frametitle=MetaWorld Prompt for Direct Policy Modeling]
</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="none0.prompt16.2.2">You are controlling a robot for the following task:

<br class="ltx_break"/>
<br class="ltx_break"/>{meta_world_task}

<br class="ltx_break"/>
<br class="ltx_break"/>Here are examples sub-trajectories, containing past observations and actions, together with an appropriate action.

<br class="ltx_break"/>
<br class="ltx_break"/>Example 1:

<br class="ltx_break"/>sub-Trajectory: {example_sub-trajectory}

<br class="ltx_break"/>Action: {example_action}

<br class="ltx_break"/>
<br class="ltx_break"/>Example 2:

<br class="ltx_break"/>sub-Trajectory: {example_sub-trajectory}

<br class="ltx_break"/>Action: {example_action}

<br class="ltx_break"/>
<br class="ltx_break"/>Current sub-trajectory: {sub-trajectory_so_far}

<br class="ltx_break"/>Think step-by-step before answering, what should be the current action? {<span class="ltx_text" id="none0.prompt16.2.2.1" style="color:#0000FF;">llm_action</span>}

<br class="ltx_break"/>
<br class="ltx_break"/>==============

<br class="ltx_break"/>Repeat N times:

<br class="ltx_break"/>
<br class="ltx_break"/>Find problems with this action for the given task compared to the example actions.

<br class="ltx_break"/>
<br class="ltx_break"/>{<span class="ltx_text" id="none0.prompt16.2.2.2" style="color:#0000FF;">llm_criticism</span>}

<br class="ltx_break"/>
<br class="ltx_break"/>Based on this, what is the action for the agent to make progress on the task?

<br class="ltx_break"/>
<br class="ltx_break"/>Here is the current sub-trajectory, containing past observations and actions: {sub-trajectory_so_far}

<br class="ltx_break"/>Think step-by-step before answering, what should be the current action? {<span class="ltx_text" id="none0.prompt16.2.2.3" style="color:#0000FF;">llm_action</span>}

<br class="ltx_break"/>==============</span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_serif ltx_font_medium" id="none0.prompt16.5.1.1">List of Prompts 16</span> </span>
</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.SS4.1.1.1">A.4</span> </span>Additional Indirect Policy Modeling Methods</h3>
<div class="ltx_para ltx_noindent" id="A1.SS4.p1">
<p class="ltx_p" id="A1.SS4.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS4.p1.1.1">There are a number of other prompting methods for extracting information or </span><em class="ltx_emph ltx_font_sansserif ltx_font_bold ltx_font_italic" id="A1.SS4.p1.1.2">knowledge</em><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS4.p1.1.3"> from an LLM that may be relevant to solving RL tasks.</span></p>
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.1">Direct State Generation</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.I1.i1.p1.1.2">. The model generates tokens that will represent next states (or other-future-time states). This is similar to world modeling. The next state prediction can be conditioned on an action, or marginalized over a policy distribution.</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i2.p1.1.1">Action Preference</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.I1.i2.p1.1.2">. Ask the LLM to select, among two choices, the most likely action given previous and future observations.</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i3.p1.1.1">State Preference</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.I1.i3.p1.1.2">. Ask the LLM to select, among two choices, the most likely next state or observation conditioned on prior history and/or actions.</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p2">
<p class="ltx_p" id="A1.SS4.p2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS4.p2.1.1">Many of the above could theoretically be used to construct a policy, yet a full implementation is out of scope from this paper due to the lack of available code-bases to build upon and we do not seek to build new algorithms from scratch. However, in Figure </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S3.F2.sf2" title="Figure 2(b) ‣ Figure 2 ‣ 3 Performance of Indirect and Direct Policy Models ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">2(b)</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS4.p2.1.2"> we perform investigations into the capabilities of LLMs to perform Action Preference and State Preference. The results show that current LLMs struggle to achieve strong performance on any of these tasks. Additionally, in Table </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.T1" title="Table 1 ‣ A.4 Additional Indirect Policy Modeling Methods ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS4.p2.1.3">, we report the accuracy with which LLMs directly predicts the next observation (Direct State Generation), providing a probe into their direct world modeling capabilities.
Results show limited performance, except on MiniWob-Hard tasks, which are fully observable and encode deterministic transitions.</span></p>
</div>
<figure class="ltx_table" id="A1.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T1.3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T1.3.3.4.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A1.T1.3.3.4.1.1"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A1.T1.3.3.4.1.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T1.3.3.4.1.2.1">Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t" id="A1.T1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.1.1.1.2.1">
<span class="ltx_p" id="A1.T1.1.1.1.2.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T1.1.1.1.2.1.1.1">MiniWob-Hard</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T1.1.1.1.1"><math alttext="65\pm 11.4\%" class="ltx_Math" display="inline" id="A1.T1.1.1.1.1.m1.1"><semantics id="A1.T1.1.1.1.1.m1.1a"><mrow id="A1.T1.1.1.1.1.m1.1.1" xref="A1.T1.1.1.1.1.m1.1.1.cmml"><mn id="A1.T1.1.1.1.1.m1.1.1.2" xref="A1.T1.1.1.1.1.m1.1.1.2.cmml">65</mn><mo id="A1.T1.1.1.1.1.m1.1.1.1" xref="A1.T1.1.1.1.1.m1.1.1.1.cmml">±</mo><mrow id="A1.T1.1.1.1.1.m1.1.1.3" xref="A1.T1.1.1.1.1.m1.1.1.3.cmml"><mn id="A1.T1.1.1.1.1.m1.1.1.3.2" xref="A1.T1.1.1.1.1.m1.1.1.3.2.cmml">11.4</mn><mo id="A1.T1.1.1.1.1.m1.1.1.3.1" xref="A1.T1.1.1.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T1.1.1.1.1.m1.1b"><apply id="A1.T1.1.1.1.1.m1.1.1.cmml" xref="A1.T1.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="A1.T1.1.1.1.1.m1.1.1.1.cmml" xref="A1.T1.1.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn id="A1.T1.1.1.1.1.m1.1.1.2.cmml" type="integer" xref="A1.T1.1.1.1.1.m1.1.1.2">65</cn><apply id="A1.T1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T1.1.1.1.1.m1.1.1.3"><csymbol cd="latexml" id="A1.T1.1.1.1.1.m1.1.1.3.1.cmml" xref="A1.T1.1.1.1.1.m1.1.1.3.1">percent</csymbol><cn id="A1.T1.1.1.1.1.m1.1.1.3.2.cmml" type="float" xref="A1.T1.1.1.1.1.m1.1.1.3.2">11.4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.1.1.1.1.m1.1c">65\pm 11.4\%</annotation><annotation encoding="application/x-llamapun" id="A1.T1.1.1.1.1.m1.1d">65 ± 11.4 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T1.2.2.2">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T1.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.2.2.2.2.1">
<span class="ltx_p" id="A1.T1.2.2.2.2.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T1.2.2.2.2.1.1.1">Wordle</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right" id="A1.T1.2.2.2.1"><math alttext="28\pm 8.3\%" class="ltx_Math" display="inline" id="A1.T1.2.2.2.1.m1.1"><semantics id="A1.T1.2.2.2.1.m1.1a"><mrow id="A1.T1.2.2.2.1.m1.1.1" xref="A1.T1.2.2.2.1.m1.1.1.cmml"><mn id="A1.T1.2.2.2.1.m1.1.1.2" xref="A1.T1.2.2.2.1.m1.1.1.2.cmml">28</mn><mo id="A1.T1.2.2.2.1.m1.1.1.1" xref="A1.T1.2.2.2.1.m1.1.1.1.cmml">±</mo><mrow id="A1.T1.2.2.2.1.m1.1.1.3" xref="A1.T1.2.2.2.1.m1.1.1.3.cmml"><mn id="A1.T1.2.2.2.1.m1.1.1.3.2" xref="A1.T1.2.2.2.1.m1.1.1.3.2.cmml">8.3</mn><mo id="A1.T1.2.2.2.1.m1.1.1.3.1" xref="A1.T1.2.2.2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T1.2.2.2.1.m1.1b"><apply id="A1.T1.2.2.2.1.m1.1.1.cmml" xref="A1.T1.2.2.2.1.m1.1.1"><csymbol cd="latexml" id="A1.T1.2.2.2.1.m1.1.1.1.cmml" xref="A1.T1.2.2.2.1.m1.1.1.1">plus-or-minus</csymbol><cn id="A1.T1.2.2.2.1.m1.1.1.2.cmml" type="integer" xref="A1.T1.2.2.2.1.m1.1.1.2">28</cn><apply id="A1.T1.2.2.2.1.m1.1.1.3.cmml" xref="A1.T1.2.2.2.1.m1.1.1.3"><csymbol cd="latexml" id="A1.T1.2.2.2.1.m1.1.1.3.1.cmml" xref="A1.T1.2.2.2.1.m1.1.1.3.1">percent</csymbol><cn id="A1.T1.2.2.2.1.m1.1.1.3.2.cmml" type="float" xref="A1.T1.2.2.2.1.m1.1.1.3.2">8.3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.2.2.2.1.m1.1c">28\pm 8.3\%</annotation><annotation encoding="application/x-llamapun" id="A1.T1.2.2.2.1.m1.1d">28 ± 8.3 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T1.3.3.3">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T1.3.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.3.3.3.2.1">
<span class="ltx_p" id="A1.T1.3.3.3.2.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T1.3.3.3.2.1.1.1">NetHack</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right" id="A1.T1.3.3.3.1"><math alttext="0.0\pm 0.0\%" class="ltx_Math" display="inline" id="A1.T1.3.3.3.1.m1.1"><semantics id="A1.T1.3.3.3.1.m1.1a"><mrow id="A1.T1.3.3.3.1.m1.1.1" xref="A1.T1.3.3.3.1.m1.1.1.cmml"><mn id="A1.T1.3.3.3.1.m1.1.1.2" xref="A1.T1.3.3.3.1.m1.1.1.2.cmml">0.0</mn><mo id="A1.T1.3.3.3.1.m1.1.1.1" xref="A1.T1.3.3.3.1.m1.1.1.1.cmml">±</mo><mrow id="A1.T1.3.3.3.1.m1.1.1.3" xref="A1.T1.3.3.3.1.m1.1.1.3.cmml"><mn id="A1.T1.3.3.3.1.m1.1.1.3.2" xref="A1.T1.3.3.3.1.m1.1.1.3.2.cmml">0.0</mn><mo id="A1.T1.3.3.3.1.m1.1.1.3.1" xref="A1.T1.3.3.3.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T1.3.3.3.1.m1.1b"><apply id="A1.T1.3.3.3.1.m1.1.1.cmml" xref="A1.T1.3.3.3.1.m1.1.1"><csymbol cd="latexml" id="A1.T1.3.3.3.1.m1.1.1.1.cmml" xref="A1.T1.3.3.3.1.m1.1.1.1">plus-or-minus</csymbol><cn id="A1.T1.3.3.3.1.m1.1.1.2.cmml" type="float" xref="A1.T1.3.3.3.1.m1.1.1.2">0.0</cn><apply id="A1.T1.3.3.3.1.m1.1.1.3.cmml" xref="A1.T1.3.3.3.1.m1.1.1.3"><csymbol cd="latexml" id="A1.T1.3.3.3.1.m1.1.1.3.1.cmml" xref="A1.T1.3.3.3.1.m1.1.1.3.1">percent</csymbol><cn id="A1.T1.3.3.3.1.m1.1.1.3.2.cmml" type="float" xref="A1.T1.3.3.3.1.m1.1.1.3.2">0.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.3.3.3.1.m1.1c">0.0\pm 0.0\%</annotation><annotation encoding="application/x-llamapun" id="A1.T1.3.3.3.1.m1.1d">0.0 ± 0.0 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T1.3.3.5.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_bb" id="A1.T1.3.3.5.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T1.3.3.5.1.1.1">
<span class="ltx_p" id="A1.T1.3.3.5.1.1.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T1.3.3.5.1.1.1.1.1">MetaWorld</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T1.3.3.5.1.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T1.3.3.5.1.2.1">N/A</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_table"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.T1.7.1.1">Table 1</span>: </span><span class="ltx_text ltx_font_serif" id="A1.T1.8.2">LLMs struggle to predict the next observation.</span> We show the decreasing accuracy of the LLM to predict the next observation with increasing task complexity. LLMs are unable to generate pixel observations, which are used in MetaWorld.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS5">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.SS5.1.1.1">A.5</span> </span>Ablating Reward as Code</h3>
<figure class="ltx_table" id="A1.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T2.7.7">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T2.7.7.8.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" colspan="2" id="A1.T2.7.7.8.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.7.7.8.1.1.1">Reward as Code - RGB Observations</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T2.7.7.9.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t" id="A1.T2.7.7.9.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.7.7.9.1.1.1">
<span class="ltx_p" id="A1.T2.7.7.9.1.1.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.7.7.9.1.1.1.1.1">GPT-4o</span></span>
</span>
</th>
<td class="ltx_td ltx_border_t" id="A1.T2.7.7.9.1.2"></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.1.1.1.2.1">
<span class="ltx_p" id="A1.T2.1.1.1.2.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.1.1.1.2.1.1.1">w/o expert demonstration</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.1.1"><math alttext="0\%\pm 1\%" class="ltx_Math" display="inline" id="A1.T2.1.1.1.1.m1.1"><semantics id="A1.T2.1.1.1.1.m1.1a"><mrow id="A1.T2.1.1.1.1.m1.1.1" xref="A1.T2.1.1.1.1.m1.1.1.cmml"><mrow id="A1.T2.1.1.1.1.m1.1.1.2" xref="A1.T2.1.1.1.1.m1.1.1.2.cmml"><mn id="A1.T2.1.1.1.1.m1.1.1.2.2" xref="A1.T2.1.1.1.1.m1.1.1.2.2.cmml">0</mn><mo id="A1.T2.1.1.1.1.m1.1.1.2.1" xref="A1.T2.1.1.1.1.m1.1.1.2.1.cmml">%</mo></mrow><mo id="A1.T2.1.1.1.1.m1.1.1.1" xref="A1.T2.1.1.1.1.m1.1.1.1.cmml">±</mo><mrow id="A1.T2.1.1.1.1.m1.1.1.3" xref="A1.T2.1.1.1.1.m1.1.1.3.cmml"><mn id="A1.T2.1.1.1.1.m1.1.1.3.2" xref="A1.T2.1.1.1.1.m1.1.1.3.2.cmml">1</mn><mo id="A1.T2.1.1.1.1.m1.1.1.3.1" xref="A1.T2.1.1.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T2.1.1.1.1.m1.1b"><apply id="A1.T2.1.1.1.1.m1.1.1.cmml" xref="A1.T2.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="A1.T2.1.1.1.1.m1.1.1.1.cmml" xref="A1.T2.1.1.1.1.m1.1.1.1">plus-or-minus</csymbol><apply id="A1.T2.1.1.1.1.m1.1.1.2.cmml" xref="A1.T2.1.1.1.1.m1.1.1.2"><csymbol cd="latexml" id="A1.T2.1.1.1.1.m1.1.1.2.1.cmml" xref="A1.T2.1.1.1.1.m1.1.1.2.1">percent</csymbol><cn id="A1.T2.1.1.1.1.m1.1.1.2.2.cmml" type="integer" xref="A1.T2.1.1.1.1.m1.1.1.2.2">0</cn></apply><apply id="A1.T2.1.1.1.1.m1.1.1.3.cmml" xref="A1.T2.1.1.1.1.m1.1.1.3"><csymbol cd="latexml" id="A1.T2.1.1.1.1.m1.1.1.3.1.cmml" xref="A1.T2.1.1.1.1.m1.1.1.3.1">percent</csymbol><cn id="A1.T2.1.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="A1.T2.1.1.1.1.m1.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.1.1.1.1.m1.1c">0\%\pm 1\%</annotation><annotation encoding="application/x-llamapun" id="A1.T2.1.1.1.1.m1.1d">0 % ± 1 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T2.2.2.2">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.2.2.2.2.1">
<span class="ltx_p" id="A1.T2.2.2.2.2.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.2.2.2.2.1.1.1">with expert demonstration</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right" id="A1.T2.2.2.2.1"><math alttext="79\%\pm 7\%" class="ltx_Math" display="inline" id="A1.T2.2.2.2.1.m1.1"><semantics id="A1.T2.2.2.2.1.m1.1a"><mrow id="A1.T2.2.2.2.1.m1.1.1" xref="A1.T2.2.2.2.1.m1.1.1.cmml"><mrow id="A1.T2.2.2.2.1.m1.1.1.2" xref="A1.T2.2.2.2.1.m1.1.1.2.cmml"><mn id="A1.T2.2.2.2.1.m1.1.1.2.2" xref="A1.T2.2.2.2.1.m1.1.1.2.2.cmml">79</mn><mo id="A1.T2.2.2.2.1.m1.1.1.2.1" xref="A1.T2.2.2.2.1.m1.1.1.2.1.cmml">%</mo></mrow><mo id="A1.T2.2.2.2.1.m1.1.1.1" xref="A1.T2.2.2.2.1.m1.1.1.1.cmml">±</mo><mrow id="A1.T2.2.2.2.1.m1.1.1.3" xref="A1.T2.2.2.2.1.m1.1.1.3.cmml"><mn id="A1.T2.2.2.2.1.m1.1.1.3.2" xref="A1.T2.2.2.2.1.m1.1.1.3.2.cmml">7</mn><mo id="A1.T2.2.2.2.1.m1.1.1.3.1" xref="A1.T2.2.2.2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T2.2.2.2.1.m1.1b"><apply id="A1.T2.2.2.2.1.m1.1.1.cmml" xref="A1.T2.2.2.2.1.m1.1.1"><csymbol cd="latexml" id="A1.T2.2.2.2.1.m1.1.1.1.cmml" xref="A1.T2.2.2.2.1.m1.1.1.1">plus-or-minus</csymbol><apply id="A1.T2.2.2.2.1.m1.1.1.2.cmml" xref="A1.T2.2.2.2.1.m1.1.1.2"><csymbol cd="latexml" id="A1.T2.2.2.2.1.m1.1.1.2.1.cmml" xref="A1.T2.2.2.2.1.m1.1.1.2.1">percent</csymbol><cn id="A1.T2.2.2.2.1.m1.1.1.2.2.cmml" type="integer" xref="A1.T2.2.2.2.1.m1.1.1.2.2">79</cn></apply><apply id="A1.T2.2.2.2.1.m1.1.1.3.cmml" xref="A1.T2.2.2.2.1.m1.1.1.3"><csymbol cd="latexml" id="A1.T2.2.2.2.1.m1.1.1.3.1.cmml" xref="A1.T2.2.2.2.1.m1.1.1.3.1">percent</csymbol><cn id="A1.T2.2.2.2.1.m1.1.1.3.2.cmml" type="integer" xref="A1.T2.2.2.2.1.m1.1.1.3.2">7</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.2.2.2.1.m1.1c">79\%\pm 7\%</annotation><annotation encoding="application/x-llamapun" id="A1.T2.2.2.2.1.m1.1d">79 % ± 7 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T2.7.7.10.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="2" id="A1.T2.7.7.10.2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.7.7.10.2.1.1">Reward as Code - Proprioceptive Observations</span></th>
</tr>
<tr class="ltx_tr" id="A1.T2.7.7.11.3">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_t" id="A1.T2.7.7.11.3.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.7.7.11.3.1.1">
<span class="ltx_p" id="A1.T2.7.7.11.3.1.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.7.7.11.3.1.1.1.1">Llama 3 70B</span></span>
</span>
</th>
<td class="ltx_td ltx_border_t" id="A1.T2.7.7.11.3.2"></td>
</tr>
<tr class="ltx_tr" id="A1.T2.3.3.3">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.3.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.3.3.3.2.1">
<span class="ltx_p" id="A1.T2.3.3.3.2.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.3.3.3.2.1.1.1">w/o background functional knowledge</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right" id="A1.T2.3.3.3.1"><math alttext="0\%\pm 1\%" class="ltx_Math" display="inline" id="A1.T2.3.3.3.1.m1.1"><semantics id="A1.T2.3.3.3.1.m1.1a"><mrow id="A1.T2.3.3.3.1.m1.1.1" xref="A1.T2.3.3.3.1.m1.1.1.cmml"><mrow id="A1.T2.3.3.3.1.m1.1.1.2" xref="A1.T2.3.3.3.1.m1.1.1.2.cmml"><mn id="A1.T2.3.3.3.1.m1.1.1.2.2" xref="A1.T2.3.3.3.1.m1.1.1.2.2.cmml">0</mn><mo id="A1.T2.3.3.3.1.m1.1.1.2.1" xref="A1.T2.3.3.3.1.m1.1.1.2.1.cmml">%</mo></mrow><mo id="A1.T2.3.3.3.1.m1.1.1.1" xref="A1.T2.3.3.3.1.m1.1.1.1.cmml">±</mo><mrow id="A1.T2.3.3.3.1.m1.1.1.3" xref="A1.T2.3.3.3.1.m1.1.1.3.cmml"><mn id="A1.T2.3.3.3.1.m1.1.1.3.2" xref="A1.T2.3.3.3.1.m1.1.1.3.2.cmml">1</mn><mo id="A1.T2.3.3.3.1.m1.1.1.3.1" xref="A1.T2.3.3.3.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T2.3.3.3.1.m1.1b"><apply id="A1.T2.3.3.3.1.m1.1.1.cmml" xref="A1.T2.3.3.3.1.m1.1.1"><csymbol cd="latexml" id="A1.T2.3.3.3.1.m1.1.1.1.cmml" xref="A1.T2.3.3.3.1.m1.1.1.1">plus-or-minus</csymbol><apply id="A1.T2.3.3.3.1.m1.1.1.2.cmml" xref="A1.T2.3.3.3.1.m1.1.1.2"><csymbol cd="latexml" id="A1.T2.3.3.3.1.m1.1.1.2.1.cmml" xref="A1.T2.3.3.3.1.m1.1.1.2.1">percent</csymbol><cn id="A1.T2.3.3.3.1.m1.1.1.2.2.cmml" type="integer" xref="A1.T2.3.3.3.1.m1.1.1.2.2">0</cn></apply><apply id="A1.T2.3.3.3.1.m1.1.1.3.cmml" xref="A1.T2.3.3.3.1.m1.1.1.3"><csymbol cd="latexml" id="A1.T2.3.3.3.1.m1.1.1.3.1.cmml" xref="A1.T2.3.3.3.1.m1.1.1.3.1">percent</csymbol><cn id="A1.T2.3.3.3.1.m1.1.1.3.2.cmml" type="integer" xref="A1.T2.3.3.3.1.m1.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.3.3.3.1.m1.1c">0\%\pm 1\%</annotation><annotation encoding="application/x-llamapun" id="A1.T2.3.3.3.1.m1.1d">0 % ± 1 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T2.4.4.4">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.4.4.4.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.4.4.4.2.1">
<span class="ltx_p" id="A1.T2.4.4.4.2.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.4.4.4.2.1.1.1">with background functional knowledge</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right" id="A1.T2.4.4.4.1"><math alttext="10\%\pm 3\%" class="ltx_Math" display="inline" id="A1.T2.4.4.4.1.m1.1"><semantics id="A1.T2.4.4.4.1.m1.1a"><mrow id="A1.T2.4.4.4.1.m1.1.1" xref="A1.T2.4.4.4.1.m1.1.1.cmml"><mrow id="A1.T2.4.4.4.1.m1.1.1.2" xref="A1.T2.4.4.4.1.m1.1.1.2.cmml"><mn id="A1.T2.4.4.4.1.m1.1.1.2.2" xref="A1.T2.4.4.4.1.m1.1.1.2.2.cmml">10</mn><mo id="A1.T2.4.4.4.1.m1.1.1.2.1" xref="A1.T2.4.4.4.1.m1.1.1.2.1.cmml">%</mo></mrow><mo id="A1.T2.4.4.4.1.m1.1.1.1" xref="A1.T2.4.4.4.1.m1.1.1.1.cmml">±</mo><mrow id="A1.T2.4.4.4.1.m1.1.1.3" xref="A1.T2.4.4.4.1.m1.1.1.3.cmml"><mn id="A1.T2.4.4.4.1.m1.1.1.3.2" xref="A1.T2.4.4.4.1.m1.1.1.3.2.cmml">3</mn><mo id="A1.T2.4.4.4.1.m1.1.1.3.1" xref="A1.T2.4.4.4.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T2.4.4.4.1.m1.1b"><apply id="A1.T2.4.4.4.1.m1.1.1.cmml" xref="A1.T2.4.4.4.1.m1.1.1"><csymbol cd="latexml" id="A1.T2.4.4.4.1.m1.1.1.1.cmml" xref="A1.T2.4.4.4.1.m1.1.1.1">plus-or-minus</csymbol><apply id="A1.T2.4.4.4.1.m1.1.1.2.cmml" xref="A1.T2.4.4.4.1.m1.1.1.2"><csymbol cd="latexml" id="A1.T2.4.4.4.1.m1.1.1.2.1.cmml" xref="A1.T2.4.4.4.1.m1.1.1.2.1">percent</csymbol><cn id="A1.T2.4.4.4.1.m1.1.1.2.2.cmml" type="integer" xref="A1.T2.4.4.4.1.m1.1.1.2.2">10</cn></apply><apply id="A1.T2.4.4.4.1.m1.1.1.3.cmml" xref="A1.T2.4.4.4.1.m1.1.1.3"><csymbol cd="latexml" id="A1.T2.4.4.4.1.m1.1.1.3.1.cmml" xref="A1.T2.4.4.4.1.m1.1.1.3.1">percent</csymbol><cn id="A1.T2.4.4.4.1.m1.1.1.3.2.cmml" type="integer" xref="A1.T2.4.4.4.1.m1.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.4.4.4.1.m1.1c">10\%\pm 3\%</annotation><annotation encoding="application/x-llamapun" id="A1.T2.4.4.4.1.m1.1d">10 % ± 3 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T2.7.7.12.4">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.7.7.12.4.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.7.7.12.4.1.1">
<span class="ltx_p" id="A1.T2.7.7.12.4.1.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.7.7.12.4.1.1.1.1">GPT-4o</span></span>
</span>
</th>
<td class="ltx_td" id="A1.T2.7.7.12.4.2"></td>
</tr>
<tr class="ltx_tr" id="A1.T2.5.5.5">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.5.5.5.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.5.5.5.2.1">
<span class="ltx_p" id="A1.T2.5.5.5.2.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.5.5.5.2.1.1.1">w/o background functional knowledge</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right" id="A1.T2.5.5.5.1"><math alttext="5\%\pm 3\%" class="ltx_Math" display="inline" id="A1.T2.5.5.5.1.m1.1"><semantics id="A1.T2.5.5.5.1.m1.1a"><mrow id="A1.T2.5.5.5.1.m1.1.1" xref="A1.T2.5.5.5.1.m1.1.1.cmml"><mrow id="A1.T2.5.5.5.1.m1.1.1.2" xref="A1.T2.5.5.5.1.m1.1.1.2.cmml"><mn id="A1.T2.5.5.5.1.m1.1.1.2.2" xref="A1.T2.5.5.5.1.m1.1.1.2.2.cmml">5</mn><mo id="A1.T2.5.5.5.1.m1.1.1.2.1" xref="A1.T2.5.5.5.1.m1.1.1.2.1.cmml">%</mo></mrow><mo id="A1.T2.5.5.5.1.m1.1.1.1" xref="A1.T2.5.5.5.1.m1.1.1.1.cmml">±</mo><mrow id="A1.T2.5.5.5.1.m1.1.1.3" xref="A1.T2.5.5.5.1.m1.1.1.3.cmml"><mn id="A1.T2.5.5.5.1.m1.1.1.3.2" xref="A1.T2.5.5.5.1.m1.1.1.3.2.cmml">3</mn><mo id="A1.T2.5.5.5.1.m1.1.1.3.1" xref="A1.T2.5.5.5.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T2.5.5.5.1.m1.1b"><apply id="A1.T2.5.5.5.1.m1.1.1.cmml" xref="A1.T2.5.5.5.1.m1.1.1"><csymbol cd="latexml" id="A1.T2.5.5.5.1.m1.1.1.1.cmml" xref="A1.T2.5.5.5.1.m1.1.1.1">plus-or-minus</csymbol><apply id="A1.T2.5.5.5.1.m1.1.1.2.cmml" xref="A1.T2.5.5.5.1.m1.1.1.2"><csymbol cd="latexml" id="A1.T2.5.5.5.1.m1.1.1.2.1.cmml" xref="A1.T2.5.5.5.1.m1.1.1.2.1">percent</csymbol><cn id="A1.T2.5.5.5.1.m1.1.1.2.2.cmml" type="integer" xref="A1.T2.5.5.5.1.m1.1.1.2.2">5</cn></apply><apply id="A1.T2.5.5.5.1.m1.1.1.3.cmml" xref="A1.T2.5.5.5.1.m1.1.1.3"><csymbol cd="latexml" id="A1.T2.5.5.5.1.m1.1.1.3.1.cmml" xref="A1.T2.5.5.5.1.m1.1.1.3.1">percent</csymbol><cn id="A1.T2.5.5.5.1.m1.1.1.3.2.cmml" type="integer" xref="A1.T2.5.5.5.1.m1.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.5.5.5.1.m1.1c">5\%\pm 3\%</annotation><annotation encoding="application/x-llamapun" id="A1.T2.5.5.5.1.m1.1d">5 % ± 3 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T2.6.6.6">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row" id="A1.T2.6.6.6.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.6.6.6.2.1">
<span class="ltx_p" id="A1.T2.6.6.6.2.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.6.6.6.2.1.1.1">with background functional knowledge</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right" id="A1.T2.6.6.6.1"><math alttext="76\%\pm 6\%" class="ltx_Math" display="inline" id="A1.T2.6.6.6.1.m1.1"><semantics id="A1.T2.6.6.6.1.m1.1a"><mrow id="A1.T2.6.6.6.1.m1.1.1" xref="A1.T2.6.6.6.1.m1.1.1.cmml"><mrow id="A1.T2.6.6.6.1.m1.1.1.2" xref="A1.T2.6.6.6.1.m1.1.1.2.cmml"><mn id="A1.T2.6.6.6.1.m1.1.1.2.2" xref="A1.T2.6.6.6.1.m1.1.1.2.2.cmml">76</mn><mo id="A1.T2.6.6.6.1.m1.1.1.2.1" xref="A1.T2.6.6.6.1.m1.1.1.2.1.cmml">%</mo></mrow><mo id="A1.T2.6.6.6.1.m1.1.1.1" xref="A1.T2.6.6.6.1.m1.1.1.1.cmml">±</mo><mrow id="A1.T2.6.6.6.1.m1.1.1.3" xref="A1.T2.6.6.6.1.m1.1.1.3.cmml"><mn id="A1.T2.6.6.6.1.m1.1.1.3.2" xref="A1.T2.6.6.6.1.m1.1.1.3.2.cmml">6</mn><mo id="A1.T2.6.6.6.1.m1.1.1.3.1" xref="A1.T2.6.6.6.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T2.6.6.6.1.m1.1b"><apply id="A1.T2.6.6.6.1.m1.1.1.cmml" xref="A1.T2.6.6.6.1.m1.1.1"><csymbol cd="latexml" id="A1.T2.6.6.6.1.m1.1.1.1.cmml" xref="A1.T2.6.6.6.1.m1.1.1.1">plus-or-minus</csymbol><apply id="A1.T2.6.6.6.1.m1.1.1.2.cmml" xref="A1.T2.6.6.6.1.m1.1.1.2"><csymbol cd="latexml" id="A1.T2.6.6.6.1.m1.1.1.2.1.cmml" xref="A1.T2.6.6.6.1.m1.1.1.2.1">percent</csymbol><cn id="A1.T2.6.6.6.1.m1.1.1.2.2.cmml" type="integer" xref="A1.T2.6.6.6.1.m1.1.1.2.2">76</cn></apply><apply id="A1.T2.6.6.6.1.m1.1.1.3.cmml" xref="A1.T2.6.6.6.1.m1.1.1.3"><csymbol cd="latexml" id="A1.T2.6.6.6.1.m1.1.1.3.1.cmml" xref="A1.T2.6.6.6.1.m1.1.1.3.1">percent</csymbol><cn id="A1.T2.6.6.6.1.m1.1.1.3.2.cmml" type="integer" xref="A1.T2.6.6.6.1.m1.1.1.3.2">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.6.6.6.1.m1.1c">76\%\pm 6\%</annotation><annotation encoding="application/x-llamapun" id="A1.T2.6.6.6.1.m1.1d">76 % ± 6 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T2.7.7.13.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="2" id="A1.T2.7.7.13.5.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.7.7.13.5.1.1">AI Feedback - RGB Observations</span></th>
</tr>
<tr class="ltx_tr" id="A1.T2.7.7.7">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="A1.T2.7.7.7.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T2.7.7.7.2.1">
<span class="ltx_p" id="A1.T2.7.7.7.2.1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.T2.7.7.7.2.1.1.1">PaliGemma</span></span>
</span>
</th>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A1.T2.7.7.7.1"><math alttext="72\%\pm 8\%" class="ltx_Math" display="inline" id="A1.T2.7.7.7.1.m1.1"><semantics id="A1.T2.7.7.7.1.m1.1a"><mrow id="A1.T2.7.7.7.1.m1.1.1" xref="A1.T2.7.7.7.1.m1.1.1.cmml"><mrow id="A1.T2.7.7.7.1.m1.1.1.2" xref="A1.T2.7.7.7.1.m1.1.1.2.cmml"><mn id="A1.T2.7.7.7.1.m1.1.1.2.2" xref="A1.T2.7.7.7.1.m1.1.1.2.2.cmml">72</mn><mo id="A1.T2.7.7.7.1.m1.1.1.2.1" xref="A1.T2.7.7.7.1.m1.1.1.2.1.cmml">%</mo></mrow><mo id="A1.T2.7.7.7.1.m1.1.1.1" xref="A1.T2.7.7.7.1.m1.1.1.1.cmml">±</mo><mrow id="A1.T2.7.7.7.1.m1.1.1.3" xref="A1.T2.7.7.7.1.m1.1.1.3.cmml"><mn id="A1.T2.7.7.7.1.m1.1.1.3.2" xref="A1.T2.7.7.7.1.m1.1.1.3.2.cmml">8</mn><mo id="A1.T2.7.7.7.1.m1.1.1.3.1" xref="A1.T2.7.7.7.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T2.7.7.7.1.m1.1b"><apply id="A1.T2.7.7.7.1.m1.1.1.cmml" xref="A1.T2.7.7.7.1.m1.1.1"><csymbol cd="latexml" id="A1.T2.7.7.7.1.m1.1.1.1.cmml" xref="A1.T2.7.7.7.1.m1.1.1.1">plus-or-minus</csymbol><apply id="A1.T2.7.7.7.1.m1.1.1.2.cmml" xref="A1.T2.7.7.7.1.m1.1.1.2"><csymbol cd="latexml" id="A1.T2.7.7.7.1.m1.1.1.2.1.cmml" xref="A1.T2.7.7.7.1.m1.1.1.2.1">percent</csymbol><cn id="A1.T2.7.7.7.1.m1.1.1.2.2.cmml" type="integer" xref="A1.T2.7.7.7.1.m1.1.1.2.2">72</cn></apply><apply id="A1.T2.7.7.7.1.m1.1.1.3.cmml" xref="A1.T2.7.7.7.1.m1.1.1.3"><csymbol cd="latexml" id="A1.T2.7.7.7.1.m1.1.1.3.1.cmml" xref="A1.T2.7.7.7.1.m1.1.1.3.1">percent</csymbol><cn id="A1.T2.7.7.7.1.m1.1.1.3.2.cmml" type="integer" xref="A1.T2.7.7.7.1.m1.1.1.3.2">8</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.7.7.7.1.m1.1c">72\%\pm 8\%</annotation><annotation encoding="application/x-llamapun" id="A1.T2.7.7.7.1.m1.1d">72 % ± 8 %</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_table"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.T2.10.1.1">Table 2</span>: </span>AI Feedback performs on par with Reward as Code, without proprioceptive observations or expert demonstrations. To match AI Feedback performance on Metaworld, Reward as Code requires GPT-4o level knowledge, augmented with either in-context expert demonstrations or proprioceptive observations.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A1.SS5.p1">
<p class="ltx_p" id="A1.SS5.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.1">In Table </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.T2" title="Table 2 ‣ A.5 Ablating Reward as Code ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.2">, we ablate the performance of the Reward as Code baseline across LLMs, observation spaces and additional assumptions. For pixel observations, we follow the methodology laid out in </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.3.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Venuto et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.4.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib57" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.5.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.6">, whereas for proprioceptive observations we follow the one from </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.7.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yu et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.8.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib66" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.9.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.10">. Both methods heavily depend on access to a state-of-the-art, closed-source model to achieve performance comparable to that of AI Feedback, which uses the smaller, open-source model of Paligemma </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.11.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Beyer et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.12.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib4" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.13.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS5.p1.1.14">. Additionally, each method requires expert demonstrations or specialized domain knowledge to guide the reward design process. While these assumptions may be viable in certain situations, such as in a controlled simulation environment, they can present significant practical challenges in more general contexts. In contrast, AI Feedback operates by simply comparing observations and reasoning using a chain-of-thought approach.</span></p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS6">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.SS6.1.1.1">A.6</span> </span>Learning from Environment Rewards</h3>
<div class="ltx_para ltx_noindent" id="A1.SS6.p1">
<p class="ltx_p" id="A1.SS6.p1.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS6.p1.2.1">In Figure </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.F8" title="Figure 8 ‣ A.6 Learning from Environment Rewards ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">8</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS6.p1.2.2">, we compare the performance of an RL agent trained using a reward function derived from AI feedback with that of an agent trained on human-designed rewards across different environments. We observe that AI feedback achieves comparable results, with an average score of </span><math alttext="89.93" class="ltx_Math" display="inline" id="A1.SS6.p1.1.m1.1"><semantics id="A1.SS6.p1.1.m1.1a"><mn id="A1.SS6.p1.1.m1.1.1" xref="A1.SS6.p1.1.m1.1.1.cmml">89.93</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.1.m1.1b"><cn id="A1.SS6.p1.1.m1.1.1.cmml" type="float" xref="A1.SS6.p1.1.m1.1.1">89.93</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.1.m1.1c">89.93</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.1.m1.1d">89.93</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS6.p1.2.3"> versus </span><math alttext="86.3" class="ltx_Math" display="inline" id="A1.SS6.p1.2.m2.1"><semantics id="A1.SS6.p1.2.m2.1a"><mn id="A1.SS6.p1.2.m2.1.1" xref="A1.SS6.p1.2.m2.1.1.cmml">86.3</mn><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.2.m2.1b"><cn id="A1.SS6.p1.2.m2.1.1.cmml" type="float" xref="A1.SS6.p1.2.m2.1.1">86.3</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.2.m2.1c">86.3</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.2.m2.1d">86.3</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS6.p1.2.4"> for the human-designed reward. The objective of this experiment is not to argue that LLM-based rewards consistently outperform human-crafted ones—since expert human knowledge can always be encoded into a reward function—but rather to contextualize the performance of LLM-based rewards. Notice that for MetaWorld we report the performance after fine-tuning the LLM as described in Section </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S5" title="5 Beyond Zero-Shot Reward Modeling ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS6.p1.2.5">.</span></p>
</div>
<figure class="ltx_figure" id="A1.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="326" id="A1.F8.g1" src="x12.png" width="664"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.F8.3.1.1">Figure 8</span>: </span>Comparison between the best performing LLM-based reward (AI Feedback) and human designed rewards for each domain.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS7">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.SS7.1.1.1">A.7</span> </span>AI feedback and heuristic functions</h3>
<div class="ltx_para ltx_noindent" id="A1.SS7.p1">
<p class="ltx_p" id="A1.SS7.p1.13"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.1">While prior works have shown that rewards can be extracted from a language model </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Brooks et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib7" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Klissarov et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib23" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.5">, it can be more generally thought of as encoding a heuristic function </span><math alttext="h" class="ltx_Math" display="inline" id="A1.SS7.p1.1.m1.1"><semantics id="A1.SS7.p1.1.m1.1a"><mi id="A1.SS7.p1.1.m1.1.1" xref="A1.SS7.p1.1.m1.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.1.m1.1b"><ci id="A1.SS7.p1.1.m1.1.1.cmml" xref="A1.SS7.p1.1.m1.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.1.m1.1c">h</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.1.m1.1d">italic_h</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.6">. The function </span><math alttext="h" class="ltx_Math" display="inline" id="A1.SS7.p1.2.m2.1"><semantics id="A1.SS7.p1.2.m2.1a"><mi id="A1.SS7.p1.2.m2.1.1" xref="A1.SS7.p1.2.m2.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.2.m2.1b"><ci id="A1.SS7.p1.2.m2.1.1.cmml" xref="A1.SS7.p1.2.m2.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.2.m2.1c">h</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.2.m2.1d">italic_h</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.7"> contains high-level, multi-step information about the MDP </span><math alttext="M" class="ltx_Math" display="inline" id="A1.SS7.p1.3.m3.1"><semantics id="A1.SS7.p1.3.m3.1a"><mi id="A1.SS7.p1.3.m3.1.1" xref="A1.SS7.p1.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.3.m3.1b"><ci id="A1.SS7.p1.3.m3.1.1.cmml" xref="A1.SS7.p1.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.3.m3.1c">M</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.3.m3.1d">italic_M</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.8">. To extract it, one can solve the re-shaped MDP </span><math alttext="\tilde{M}" class="ltx_Math" display="inline" id="A1.SS7.p1.4.m4.1"><semantics id="A1.SS7.p1.4.m4.1a"><mover accent="true" id="A1.SS7.p1.4.m4.1.1" xref="A1.SS7.p1.4.m4.1.1.cmml"><mi id="A1.SS7.p1.4.m4.1.1.2" xref="A1.SS7.p1.4.m4.1.1.2.cmml">M</mi><mo id="A1.SS7.p1.4.m4.1.1.1" xref="A1.SS7.p1.4.m4.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.4.m4.1b"><apply id="A1.SS7.p1.4.m4.1.1.cmml" xref="A1.SS7.p1.4.m4.1.1"><ci id="A1.SS7.p1.4.m4.1.1.1.cmml" xref="A1.SS7.p1.4.m4.1.1.1">~</ci><ci id="A1.SS7.p1.4.m4.1.1.2.cmml" xref="A1.SS7.p1.4.m4.1.1.2">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.4.m4.1c">\tilde{M}</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.4.m4.1d">over~ start_ARG italic_M end_ARG</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.9"> with </span><math alttext="\tilde{r}(s_{t},a_{t})=r(s_{t},a_{t})+(1-\lambda)\gamma\mathbb{E}_{s_{t+1}|s_{%
t},a_{t}}[h(s_{t+1})]" class="ltx_Math" display="inline" id="A1.SS7.p1.5.m5.8"><semantics id="A1.SS7.p1.5.m5.8a"><mrow id="A1.SS7.p1.5.m5.8.8" xref="A1.SS7.p1.5.m5.8.8.cmml"><mrow id="A1.SS7.p1.5.m5.4.4.2" xref="A1.SS7.p1.5.m5.4.4.2.cmml"><mover accent="true" id="A1.SS7.p1.5.m5.4.4.2.4" xref="A1.SS7.p1.5.m5.4.4.2.4.cmml"><mi id="A1.SS7.p1.5.m5.4.4.2.4.2" xref="A1.SS7.p1.5.m5.4.4.2.4.2.cmml">r</mi><mo id="A1.SS7.p1.5.m5.4.4.2.4.1" xref="A1.SS7.p1.5.m5.4.4.2.4.1.cmml">~</mo></mover><mo id="A1.SS7.p1.5.m5.4.4.2.3" xref="A1.SS7.p1.5.m5.4.4.2.3.cmml">⁢</mo><mrow id="A1.SS7.p1.5.m5.4.4.2.2.2" xref="A1.SS7.p1.5.m5.4.4.2.2.3.cmml"><mo id="A1.SS7.p1.5.m5.4.4.2.2.2.3" stretchy="false" xref="A1.SS7.p1.5.m5.4.4.2.2.3.cmml">(</mo><msub id="A1.SS7.p1.5.m5.3.3.1.1.1.1" xref="A1.SS7.p1.5.m5.3.3.1.1.1.1.cmml"><mi id="A1.SS7.p1.5.m5.3.3.1.1.1.1.2" xref="A1.SS7.p1.5.m5.3.3.1.1.1.1.2.cmml">s</mi><mi id="A1.SS7.p1.5.m5.3.3.1.1.1.1.3" xref="A1.SS7.p1.5.m5.3.3.1.1.1.1.3.cmml">t</mi></msub><mo id="A1.SS7.p1.5.m5.4.4.2.2.2.4" xref="A1.SS7.p1.5.m5.4.4.2.2.3.cmml">,</mo><msub id="A1.SS7.p1.5.m5.4.4.2.2.2.2" xref="A1.SS7.p1.5.m5.4.4.2.2.2.2.cmml"><mi id="A1.SS7.p1.5.m5.4.4.2.2.2.2.2" xref="A1.SS7.p1.5.m5.4.4.2.2.2.2.2.cmml">a</mi><mi id="A1.SS7.p1.5.m5.4.4.2.2.2.2.3" xref="A1.SS7.p1.5.m5.4.4.2.2.2.2.3.cmml">t</mi></msub><mo id="A1.SS7.p1.5.m5.4.4.2.2.2.5" stretchy="false" xref="A1.SS7.p1.5.m5.4.4.2.2.3.cmml">)</mo></mrow></mrow><mo id="A1.SS7.p1.5.m5.8.8.7" xref="A1.SS7.p1.5.m5.8.8.7.cmml">=</mo><mrow id="A1.SS7.p1.5.m5.8.8.6" xref="A1.SS7.p1.5.m5.8.8.6.cmml"><mrow id="A1.SS7.p1.5.m5.6.6.4.2" xref="A1.SS7.p1.5.m5.6.6.4.2.cmml"><mi id="A1.SS7.p1.5.m5.6.6.4.2.4" xref="A1.SS7.p1.5.m5.6.6.4.2.4.cmml">r</mi><mo id="A1.SS7.p1.5.m5.6.6.4.2.3" xref="A1.SS7.p1.5.m5.6.6.4.2.3.cmml">⁢</mo><mrow id="A1.SS7.p1.5.m5.6.6.4.2.2.2" xref="A1.SS7.p1.5.m5.6.6.4.2.2.3.cmml"><mo id="A1.SS7.p1.5.m5.6.6.4.2.2.2.3" stretchy="false" xref="A1.SS7.p1.5.m5.6.6.4.2.2.3.cmml">(</mo><msub id="A1.SS7.p1.5.m5.5.5.3.1.1.1.1" xref="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.cmml"><mi id="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.2" xref="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.2.cmml">s</mi><mi id="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.3" xref="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.3.cmml">t</mi></msub><mo id="A1.SS7.p1.5.m5.6.6.4.2.2.2.4" xref="A1.SS7.p1.5.m5.6.6.4.2.2.3.cmml">,</mo><msub id="A1.SS7.p1.5.m5.6.6.4.2.2.2.2" xref="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.cmml"><mi id="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.2" xref="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.2.cmml">a</mi><mi id="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.3" xref="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.3.cmml">t</mi></msub><mo id="A1.SS7.p1.5.m5.6.6.4.2.2.2.5" stretchy="false" xref="A1.SS7.p1.5.m5.6.6.4.2.2.3.cmml">)</mo></mrow></mrow><mo id="A1.SS7.p1.5.m5.8.8.6.5" xref="A1.SS7.p1.5.m5.8.8.6.5.cmml">+</mo><mrow id="A1.SS7.p1.5.m5.8.8.6.4" xref="A1.SS7.p1.5.m5.8.8.6.4.cmml"><mrow id="A1.SS7.p1.5.m5.7.7.5.3.1.1" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.cmml"><mo id="A1.SS7.p1.5.m5.7.7.5.3.1.1.2" stretchy="false" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.cmml">(</mo><mrow id="A1.SS7.p1.5.m5.7.7.5.3.1.1.1" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.cmml"><mn id="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.2" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.2.cmml">1</mn><mo id="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.1" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.1.cmml">−</mo><mi id="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.3" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.3.cmml">λ</mi></mrow><mo id="A1.SS7.p1.5.m5.7.7.5.3.1.1.3" stretchy="false" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.cmml">)</mo></mrow><mo id="A1.SS7.p1.5.m5.8.8.6.4.3" xref="A1.SS7.p1.5.m5.8.8.6.4.3.cmml">⁢</mo><mi id="A1.SS7.p1.5.m5.8.8.6.4.4" xref="A1.SS7.p1.5.m5.8.8.6.4.4.cmml">γ</mi><mo id="A1.SS7.p1.5.m5.8.8.6.4.3a" xref="A1.SS7.p1.5.m5.8.8.6.4.3.cmml">⁢</mo><msub id="A1.SS7.p1.5.m5.8.8.6.4.5" xref="A1.SS7.p1.5.m5.8.8.6.4.5.cmml"><mi id="A1.SS7.p1.5.m5.8.8.6.4.5.2" xref="A1.SS7.p1.5.m5.8.8.6.4.5.2.cmml">𝔼</mi><mrow id="A1.SS7.p1.5.m5.2.2.2" xref="A1.SS7.p1.5.m5.2.2.2.cmml"><msub id="A1.SS7.p1.5.m5.2.2.2.4" xref="A1.SS7.p1.5.m5.2.2.2.4.cmml"><mi id="A1.SS7.p1.5.m5.2.2.2.4.2" xref="A1.SS7.p1.5.m5.2.2.2.4.2.cmml">s</mi><mrow id="A1.SS7.p1.5.m5.2.2.2.4.3" xref="A1.SS7.p1.5.m5.2.2.2.4.3.cmml"><mi id="A1.SS7.p1.5.m5.2.2.2.4.3.2" xref="A1.SS7.p1.5.m5.2.2.2.4.3.2.cmml">t</mi><mo id="A1.SS7.p1.5.m5.2.2.2.4.3.1" xref="A1.SS7.p1.5.m5.2.2.2.4.3.1.cmml">+</mo><mn id="A1.SS7.p1.5.m5.2.2.2.4.3.3" xref="A1.SS7.p1.5.m5.2.2.2.4.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="A1.SS7.p1.5.m5.2.2.2.3" xref="A1.SS7.p1.5.m5.2.2.2.3.cmml">|</mo><mrow id="A1.SS7.p1.5.m5.2.2.2.2.2" xref="A1.SS7.p1.5.m5.2.2.2.2.3.cmml"><msub id="A1.SS7.p1.5.m5.1.1.1.1.1.1" xref="A1.SS7.p1.5.m5.1.1.1.1.1.1.cmml"><mi id="A1.SS7.p1.5.m5.1.1.1.1.1.1.2" xref="A1.SS7.p1.5.m5.1.1.1.1.1.1.2.cmml">s</mi><mi id="A1.SS7.p1.5.m5.1.1.1.1.1.1.3" xref="A1.SS7.p1.5.m5.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="A1.SS7.p1.5.m5.2.2.2.2.2.3" xref="A1.SS7.p1.5.m5.2.2.2.2.3.cmml">,</mo><msub id="A1.SS7.p1.5.m5.2.2.2.2.2.2" xref="A1.SS7.p1.5.m5.2.2.2.2.2.2.cmml"><mi id="A1.SS7.p1.5.m5.2.2.2.2.2.2.2" xref="A1.SS7.p1.5.m5.2.2.2.2.2.2.2.cmml">a</mi><mi id="A1.SS7.p1.5.m5.2.2.2.2.2.2.3" xref="A1.SS7.p1.5.m5.2.2.2.2.2.2.3.cmml">t</mi></msub></mrow></mrow></msub><mo id="A1.SS7.p1.5.m5.8.8.6.4.3b" xref="A1.SS7.p1.5.m5.8.8.6.4.3.cmml">⁢</mo><mrow id="A1.SS7.p1.5.m5.8.8.6.4.2.1" xref="A1.SS7.p1.5.m5.8.8.6.4.2.2.cmml"><mo id="A1.SS7.p1.5.m5.8.8.6.4.2.1.2" stretchy="false" xref="A1.SS7.p1.5.m5.8.8.6.4.2.2.1.cmml">[</mo><mrow id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.cmml"><mi id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.3" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.3.cmml">h</mi><mo id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.2" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.2.cmml">⁢</mo><mrow id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.cmml"><mo id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.2" stretchy="false" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.cmml">(</mo><msub id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.cmml"><mi id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.2" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.2.cmml">s</mi><mrow id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.cmml"><mi id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.2" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.2.cmml">t</mi><mo id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.1" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.1.cmml">+</mo><mn id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.3" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.3" stretchy="false" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.SS7.p1.5.m5.8.8.6.4.2.1.3" stretchy="false" xref="A1.SS7.p1.5.m5.8.8.6.4.2.2.1.cmml">]</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.5.m5.8b"><apply id="A1.SS7.p1.5.m5.8.8.cmml" xref="A1.SS7.p1.5.m5.8.8"><eq id="A1.SS7.p1.5.m5.8.8.7.cmml" xref="A1.SS7.p1.5.m5.8.8.7"></eq><apply id="A1.SS7.p1.5.m5.4.4.2.cmml" xref="A1.SS7.p1.5.m5.4.4.2"><times id="A1.SS7.p1.5.m5.4.4.2.3.cmml" xref="A1.SS7.p1.5.m5.4.4.2.3"></times><apply id="A1.SS7.p1.5.m5.4.4.2.4.cmml" xref="A1.SS7.p1.5.m5.4.4.2.4"><ci id="A1.SS7.p1.5.m5.4.4.2.4.1.cmml" xref="A1.SS7.p1.5.m5.4.4.2.4.1">~</ci><ci id="A1.SS7.p1.5.m5.4.4.2.4.2.cmml" xref="A1.SS7.p1.5.m5.4.4.2.4.2">𝑟</ci></apply><interval closure="open" id="A1.SS7.p1.5.m5.4.4.2.2.3.cmml" xref="A1.SS7.p1.5.m5.4.4.2.2.2"><apply id="A1.SS7.p1.5.m5.3.3.1.1.1.1.cmml" xref="A1.SS7.p1.5.m5.3.3.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS7.p1.5.m5.3.3.1.1.1.1.1.cmml" xref="A1.SS7.p1.5.m5.3.3.1.1.1.1">subscript</csymbol><ci id="A1.SS7.p1.5.m5.3.3.1.1.1.1.2.cmml" xref="A1.SS7.p1.5.m5.3.3.1.1.1.1.2">𝑠</ci><ci id="A1.SS7.p1.5.m5.3.3.1.1.1.1.3.cmml" xref="A1.SS7.p1.5.m5.3.3.1.1.1.1.3">𝑡</ci></apply><apply id="A1.SS7.p1.5.m5.4.4.2.2.2.2.cmml" xref="A1.SS7.p1.5.m5.4.4.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS7.p1.5.m5.4.4.2.2.2.2.1.cmml" xref="A1.SS7.p1.5.m5.4.4.2.2.2.2">subscript</csymbol><ci id="A1.SS7.p1.5.m5.4.4.2.2.2.2.2.cmml" xref="A1.SS7.p1.5.m5.4.4.2.2.2.2.2">𝑎</ci><ci id="A1.SS7.p1.5.m5.4.4.2.2.2.2.3.cmml" xref="A1.SS7.p1.5.m5.4.4.2.2.2.2.3">𝑡</ci></apply></interval></apply><apply id="A1.SS7.p1.5.m5.8.8.6.cmml" xref="A1.SS7.p1.5.m5.8.8.6"><plus id="A1.SS7.p1.5.m5.8.8.6.5.cmml" xref="A1.SS7.p1.5.m5.8.8.6.5"></plus><apply id="A1.SS7.p1.5.m5.6.6.4.2.cmml" xref="A1.SS7.p1.5.m5.6.6.4.2"><times id="A1.SS7.p1.5.m5.6.6.4.2.3.cmml" xref="A1.SS7.p1.5.m5.6.6.4.2.3"></times><ci id="A1.SS7.p1.5.m5.6.6.4.2.4.cmml" xref="A1.SS7.p1.5.m5.6.6.4.2.4">𝑟</ci><interval closure="open" id="A1.SS7.p1.5.m5.6.6.4.2.2.3.cmml" xref="A1.SS7.p1.5.m5.6.6.4.2.2.2"><apply id="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.cmml" xref="A1.SS7.p1.5.m5.5.5.3.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.1.cmml" xref="A1.SS7.p1.5.m5.5.5.3.1.1.1.1">subscript</csymbol><ci id="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.2.cmml" xref="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.2">𝑠</ci><ci id="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.3.cmml" xref="A1.SS7.p1.5.m5.5.5.3.1.1.1.1.3">𝑡</ci></apply><apply id="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.cmml" xref="A1.SS7.p1.5.m5.6.6.4.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.1.cmml" xref="A1.SS7.p1.5.m5.6.6.4.2.2.2.2">subscript</csymbol><ci id="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.2.cmml" xref="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.2">𝑎</ci><ci id="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.3.cmml" xref="A1.SS7.p1.5.m5.6.6.4.2.2.2.2.3">𝑡</ci></apply></interval></apply><apply id="A1.SS7.p1.5.m5.8.8.6.4.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4"><times id="A1.SS7.p1.5.m5.8.8.6.4.3.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.3"></times><apply id="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.cmml" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1"><minus id="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.1.cmml" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.1"></minus><cn id="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.2.cmml" type="integer" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.2">1</cn><ci id="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.3.cmml" xref="A1.SS7.p1.5.m5.7.7.5.3.1.1.1.3">𝜆</ci></apply><ci id="A1.SS7.p1.5.m5.8.8.6.4.4.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.4">𝛾</ci><apply id="A1.SS7.p1.5.m5.8.8.6.4.5.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.5"><csymbol cd="ambiguous" id="A1.SS7.p1.5.m5.8.8.6.4.5.1.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.5">subscript</csymbol><ci id="A1.SS7.p1.5.m5.8.8.6.4.5.2.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.5.2">𝔼</ci><apply id="A1.SS7.p1.5.m5.2.2.2.cmml" xref="A1.SS7.p1.5.m5.2.2.2"><csymbol cd="latexml" id="A1.SS7.p1.5.m5.2.2.2.3.cmml" xref="A1.SS7.p1.5.m5.2.2.2.3">conditional</csymbol><apply id="A1.SS7.p1.5.m5.2.2.2.4.cmml" xref="A1.SS7.p1.5.m5.2.2.2.4"><csymbol cd="ambiguous" id="A1.SS7.p1.5.m5.2.2.2.4.1.cmml" xref="A1.SS7.p1.5.m5.2.2.2.4">subscript</csymbol><ci id="A1.SS7.p1.5.m5.2.2.2.4.2.cmml" xref="A1.SS7.p1.5.m5.2.2.2.4.2">𝑠</ci><apply id="A1.SS7.p1.5.m5.2.2.2.4.3.cmml" xref="A1.SS7.p1.5.m5.2.2.2.4.3"><plus id="A1.SS7.p1.5.m5.2.2.2.4.3.1.cmml" xref="A1.SS7.p1.5.m5.2.2.2.4.3.1"></plus><ci id="A1.SS7.p1.5.m5.2.2.2.4.3.2.cmml" xref="A1.SS7.p1.5.m5.2.2.2.4.3.2">𝑡</ci><cn id="A1.SS7.p1.5.m5.2.2.2.4.3.3.cmml" type="integer" xref="A1.SS7.p1.5.m5.2.2.2.4.3.3">1</cn></apply></apply><list id="A1.SS7.p1.5.m5.2.2.2.2.3.cmml" xref="A1.SS7.p1.5.m5.2.2.2.2.2"><apply id="A1.SS7.p1.5.m5.1.1.1.1.1.1.cmml" xref="A1.SS7.p1.5.m5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS7.p1.5.m5.1.1.1.1.1.1.1.cmml" xref="A1.SS7.p1.5.m5.1.1.1.1.1.1">subscript</csymbol><ci id="A1.SS7.p1.5.m5.1.1.1.1.1.1.2.cmml" xref="A1.SS7.p1.5.m5.1.1.1.1.1.1.2">𝑠</ci><ci id="A1.SS7.p1.5.m5.1.1.1.1.1.1.3.cmml" xref="A1.SS7.p1.5.m5.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="A1.SS7.p1.5.m5.2.2.2.2.2.2.cmml" xref="A1.SS7.p1.5.m5.2.2.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS7.p1.5.m5.2.2.2.2.2.2.1.cmml" xref="A1.SS7.p1.5.m5.2.2.2.2.2.2">subscript</csymbol><ci id="A1.SS7.p1.5.m5.2.2.2.2.2.2.2.cmml" xref="A1.SS7.p1.5.m5.2.2.2.2.2.2.2">𝑎</ci><ci id="A1.SS7.p1.5.m5.2.2.2.2.2.2.3.cmml" xref="A1.SS7.p1.5.m5.2.2.2.2.2.2.3">𝑡</ci></apply></list></apply></apply><apply id="A1.SS7.p1.5.m5.8.8.6.4.2.2.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1"><csymbol cd="latexml" id="A1.SS7.p1.5.m5.8.8.6.4.2.2.1.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.2">delimited-[]</csymbol><apply id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1"><times id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.2.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.2"></times><ci id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.3.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.3">ℎ</ci><apply id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.1.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1">subscript</csymbol><ci id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.2.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.2">𝑠</ci><apply id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3"><plus id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.1.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.1"></plus><ci id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.2.cmml" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.2">𝑡</ci><cn id="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.3.cmml" type="integer" xref="A1.SS7.p1.5.m5.8.8.6.4.2.1.1.1.1.1.3.3">1</cn></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.5.m5.8c">\tilde{r}(s_{t},a_{t})=r(s_{t},a_{t})+(1-\lambda)\gamma\mathbb{E}_{s_{t+1}|s_{%
t},a_{t}}[h(s_{t+1})]</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.5.m5.8d">over~ start_ARG italic_r end_ARG ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = italic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) + ( 1 - italic_λ ) italic_γ blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_h ( italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) ]</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.10"> and </span><math alttext="\tilde{\gamma}=\lambda\gamma" class="ltx_Math" display="inline" id="A1.SS7.p1.6.m6.1"><semantics id="A1.SS7.p1.6.m6.1a"><mrow id="A1.SS7.p1.6.m6.1.1" xref="A1.SS7.p1.6.m6.1.1.cmml"><mover accent="true" id="A1.SS7.p1.6.m6.1.1.2" xref="A1.SS7.p1.6.m6.1.1.2.cmml"><mi id="A1.SS7.p1.6.m6.1.1.2.2" xref="A1.SS7.p1.6.m6.1.1.2.2.cmml">γ</mi><mo id="A1.SS7.p1.6.m6.1.1.2.1" xref="A1.SS7.p1.6.m6.1.1.2.1.cmml">~</mo></mover><mo id="A1.SS7.p1.6.m6.1.1.1" xref="A1.SS7.p1.6.m6.1.1.1.cmml">=</mo><mrow id="A1.SS7.p1.6.m6.1.1.3" xref="A1.SS7.p1.6.m6.1.1.3.cmml"><mi id="A1.SS7.p1.6.m6.1.1.3.2" xref="A1.SS7.p1.6.m6.1.1.3.2.cmml">λ</mi><mo id="A1.SS7.p1.6.m6.1.1.3.1" xref="A1.SS7.p1.6.m6.1.1.3.1.cmml">⁢</mo><mi id="A1.SS7.p1.6.m6.1.1.3.3" xref="A1.SS7.p1.6.m6.1.1.3.3.cmml">γ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.6.m6.1b"><apply id="A1.SS7.p1.6.m6.1.1.cmml" xref="A1.SS7.p1.6.m6.1.1"><eq id="A1.SS7.p1.6.m6.1.1.1.cmml" xref="A1.SS7.p1.6.m6.1.1.1"></eq><apply id="A1.SS7.p1.6.m6.1.1.2.cmml" xref="A1.SS7.p1.6.m6.1.1.2"><ci id="A1.SS7.p1.6.m6.1.1.2.1.cmml" xref="A1.SS7.p1.6.m6.1.1.2.1">~</ci><ci id="A1.SS7.p1.6.m6.1.1.2.2.cmml" xref="A1.SS7.p1.6.m6.1.1.2.2">𝛾</ci></apply><apply id="A1.SS7.p1.6.m6.1.1.3.cmml" xref="A1.SS7.p1.6.m6.1.1.3"><times id="A1.SS7.p1.6.m6.1.1.3.1.cmml" xref="A1.SS7.p1.6.m6.1.1.3.1"></times><ci id="A1.SS7.p1.6.m6.1.1.3.2.cmml" xref="A1.SS7.p1.6.m6.1.1.3.2">𝜆</ci><ci id="A1.SS7.p1.6.m6.1.1.3.3.cmml" xref="A1.SS7.p1.6.m6.1.1.3.3">𝛾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.6.m6.1c">\tilde{\gamma}=\lambda\gamma</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.6.m6.1d">over~ start_ARG italic_γ end_ARG = italic_λ italic_γ</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.11"> where </span><math alttext="\lambda\in[0,1]" class="ltx_Math" display="inline" id="A1.SS7.p1.7.m7.2"><semantics id="A1.SS7.p1.7.m7.2a"><mrow id="A1.SS7.p1.7.m7.2.3" xref="A1.SS7.p1.7.m7.2.3.cmml"><mi id="A1.SS7.p1.7.m7.2.3.2" xref="A1.SS7.p1.7.m7.2.3.2.cmml">λ</mi><mo id="A1.SS7.p1.7.m7.2.3.1" xref="A1.SS7.p1.7.m7.2.3.1.cmml">∈</mo><mrow id="A1.SS7.p1.7.m7.2.3.3.2" xref="A1.SS7.p1.7.m7.2.3.3.1.cmml"><mo id="A1.SS7.p1.7.m7.2.3.3.2.1" stretchy="false" xref="A1.SS7.p1.7.m7.2.3.3.1.cmml">[</mo><mn id="A1.SS7.p1.7.m7.1.1" xref="A1.SS7.p1.7.m7.1.1.cmml">0</mn><mo id="A1.SS7.p1.7.m7.2.3.3.2.2" xref="A1.SS7.p1.7.m7.2.3.3.1.cmml">,</mo><mn id="A1.SS7.p1.7.m7.2.2" xref="A1.SS7.p1.7.m7.2.2.cmml">1</mn><mo id="A1.SS7.p1.7.m7.2.3.3.2.3" stretchy="false" xref="A1.SS7.p1.7.m7.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.7.m7.2b"><apply id="A1.SS7.p1.7.m7.2.3.cmml" xref="A1.SS7.p1.7.m7.2.3"><in id="A1.SS7.p1.7.m7.2.3.1.cmml" xref="A1.SS7.p1.7.m7.2.3.1"></in><ci id="A1.SS7.p1.7.m7.2.3.2.cmml" xref="A1.SS7.p1.7.m7.2.3.2">𝜆</ci><interval closure="closed" id="A1.SS7.p1.7.m7.2.3.3.1.cmml" xref="A1.SS7.p1.7.m7.2.3.3.2"><cn id="A1.SS7.p1.7.m7.1.1.cmml" type="integer" xref="A1.SS7.p1.7.m7.1.1">0</cn><cn id="A1.SS7.p1.7.m7.2.2.cmml" type="integer" xref="A1.SS7.p1.7.m7.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.7.m7.2c">\lambda\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.7.m7.2d">italic_λ ∈ [ 0 , 1 ]</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.12"> </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_sansserif ltx_font_bold">Cheng et al.</span> <span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.13.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib9" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2021</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.14.2.2.1">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.15">. Solving </span><math alttext="\tilde{M}" class="ltx_Math" display="inline" id="A1.SS7.p1.8.m8.1"><semantics id="A1.SS7.p1.8.m8.1a"><mover accent="true" id="A1.SS7.p1.8.m8.1.1" xref="A1.SS7.p1.8.m8.1.1.cmml"><mi id="A1.SS7.p1.8.m8.1.1.2" xref="A1.SS7.p1.8.m8.1.1.2.cmml">M</mi><mo id="A1.SS7.p1.8.m8.1.1.1" xref="A1.SS7.p1.8.m8.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.8.m8.1b"><apply id="A1.SS7.p1.8.m8.1.1.cmml" xref="A1.SS7.p1.8.m8.1.1"><ci id="A1.SS7.p1.8.m8.1.1.1.cmml" xref="A1.SS7.p1.8.m8.1.1.1">~</ci><ci id="A1.SS7.p1.8.m8.1.1.2.cmml" xref="A1.SS7.p1.8.m8.1.1.2">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.8.m8.1c">\tilde{M}</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.8.m8.1d">over~ start_ARG italic_M end_ARG</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.16"> yields a policy </span><math alttext="\pi^{*}" class="ltx_Math" display="inline" id="A1.SS7.p1.9.m9.1"><semantics id="A1.SS7.p1.9.m9.1a"><msup id="A1.SS7.p1.9.m9.1.1" xref="A1.SS7.p1.9.m9.1.1.cmml"><mi id="A1.SS7.p1.9.m9.1.1.2" xref="A1.SS7.p1.9.m9.1.1.2.cmml">π</mi><mo id="A1.SS7.p1.9.m9.1.1.3" xref="A1.SS7.p1.9.m9.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.9.m9.1b"><apply id="A1.SS7.p1.9.m9.1.1.cmml" xref="A1.SS7.p1.9.m9.1.1"><csymbol cd="ambiguous" id="A1.SS7.p1.9.m9.1.1.1.cmml" xref="A1.SS7.p1.9.m9.1.1">superscript</csymbol><ci id="A1.SS7.p1.9.m9.1.1.2.cmml" xref="A1.SS7.p1.9.m9.1.1.2">𝜋</ci><times id="A1.SS7.p1.9.m9.1.1.3.cmml" xref="A1.SS7.p1.9.m9.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.9.m9.1c">\pi^{*}</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.9.m9.1d">italic_π start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.17"> that is also optimal in </span><math alttext="M" class="ltx_Math" display="inline" id="A1.SS7.p1.10.m10.1"><semantics id="A1.SS7.p1.10.m10.1a"><mi id="A1.SS7.p1.10.m10.1.1" xref="A1.SS7.p1.10.m10.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.10.m10.1b"><ci id="A1.SS7.p1.10.m10.1.1.cmml" xref="A1.SS7.p1.10.m10.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.10.m10.1c">M</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.10.m10.1d">italic_M</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.18"> - its value function’s bias can be shown to converge to </span><math alttext="V^{*}" class="ltx_Math" display="inline" id="A1.SS7.p1.11.m11.1"><semantics id="A1.SS7.p1.11.m11.1a"><msup id="A1.SS7.p1.11.m11.1.1" xref="A1.SS7.p1.11.m11.1.1.cmml"><mi id="A1.SS7.p1.11.m11.1.1.2" xref="A1.SS7.p1.11.m11.1.1.2.cmml">V</mi><mo id="A1.SS7.p1.11.m11.1.1.3" xref="A1.SS7.p1.11.m11.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.11.m11.1b"><apply id="A1.SS7.p1.11.m11.1.1.cmml" xref="A1.SS7.p1.11.m11.1.1"><csymbol cd="ambiguous" id="A1.SS7.p1.11.m11.1.1.1.cmml" xref="A1.SS7.p1.11.m11.1.1">superscript</csymbol><ci id="A1.SS7.p1.11.m11.1.1.2.cmml" xref="A1.SS7.p1.11.m11.1.1.2">𝑉</ci><times id="A1.SS7.p1.11.m11.1.1.3.cmml" xref="A1.SS7.p1.11.m11.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.11.m11.1c">V^{*}</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.11.m11.1d">italic_V start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.19"> in </span><math alttext="M" class="ltx_Math" display="inline" id="A1.SS7.p1.12.m12.1"><semantics id="A1.SS7.p1.12.m12.1a"><mi id="A1.SS7.p1.12.m12.1.1" xref="A1.SS7.p1.12.m12.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.12.m12.1b"><ci id="A1.SS7.p1.12.m12.1.1.cmml" xref="A1.SS7.p1.12.m12.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.12.m12.1c">M</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.12.m12.1d">italic_M</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.20"> as a function of </span><math alttext="||h-V^{*}||_{\infty}" class="ltx_Math" display="inline" id="A1.SS7.p1.13.m13.1"><semantics id="A1.SS7.p1.13.m13.1a"><msub id="A1.SS7.p1.13.m13.1.1" xref="A1.SS7.p1.13.m13.1.1.cmml"><mrow id="A1.SS7.p1.13.m13.1.1.1.1" xref="A1.SS7.p1.13.m13.1.1.1.2.cmml"><mo id="A1.SS7.p1.13.m13.1.1.1.1.2" stretchy="false" xref="A1.SS7.p1.13.m13.1.1.1.2.1.cmml">‖</mo><mrow id="A1.SS7.p1.13.m13.1.1.1.1.1" xref="A1.SS7.p1.13.m13.1.1.1.1.1.cmml"><mi id="A1.SS7.p1.13.m13.1.1.1.1.1.2" xref="A1.SS7.p1.13.m13.1.1.1.1.1.2.cmml">h</mi><mo id="A1.SS7.p1.13.m13.1.1.1.1.1.1" xref="A1.SS7.p1.13.m13.1.1.1.1.1.1.cmml">−</mo><msup id="A1.SS7.p1.13.m13.1.1.1.1.1.3" xref="A1.SS7.p1.13.m13.1.1.1.1.1.3.cmml"><mi id="A1.SS7.p1.13.m13.1.1.1.1.1.3.2" xref="A1.SS7.p1.13.m13.1.1.1.1.1.3.2.cmml">V</mi><mo id="A1.SS7.p1.13.m13.1.1.1.1.1.3.3" xref="A1.SS7.p1.13.m13.1.1.1.1.1.3.3.cmml">∗</mo></msup></mrow><mo id="A1.SS7.p1.13.m13.1.1.1.1.3" stretchy="false" xref="A1.SS7.p1.13.m13.1.1.1.2.1.cmml">‖</mo></mrow><mi id="A1.SS7.p1.13.m13.1.1.3" mathvariant="normal" xref="A1.SS7.p1.13.m13.1.1.3.cmml">∞</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS7.p1.13.m13.1b"><apply id="A1.SS7.p1.13.m13.1.1.cmml" xref="A1.SS7.p1.13.m13.1.1"><csymbol cd="ambiguous" id="A1.SS7.p1.13.m13.1.1.2.cmml" xref="A1.SS7.p1.13.m13.1.1">subscript</csymbol><apply id="A1.SS7.p1.13.m13.1.1.1.2.cmml" xref="A1.SS7.p1.13.m13.1.1.1.1"><csymbol cd="latexml" id="A1.SS7.p1.13.m13.1.1.1.2.1.cmml" xref="A1.SS7.p1.13.m13.1.1.1.1.2">norm</csymbol><apply id="A1.SS7.p1.13.m13.1.1.1.1.1.cmml" xref="A1.SS7.p1.13.m13.1.1.1.1.1"><minus id="A1.SS7.p1.13.m13.1.1.1.1.1.1.cmml" xref="A1.SS7.p1.13.m13.1.1.1.1.1.1"></minus><ci id="A1.SS7.p1.13.m13.1.1.1.1.1.2.cmml" xref="A1.SS7.p1.13.m13.1.1.1.1.1.2">ℎ</ci><apply id="A1.SS7.p1.13.m13.1.1.1.1.1.3.cmml" xref="A1.SS7.p1.13.m13.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A1.SS7.p1.13.m13.1.1.1.1.1.3.1.cmml" xref="A1.SS7.p1.13.m13.1.1.1.1.1.3">superscript</csymbol><ci id="A1.SS7.p1.13.m13.1.1.1.1.1.3.2.cmml" xref="A1.SS7.p1.13.m13.1.1.1.1.1.3.2">𝑉</ci><times id="A1.SS7.p1.13.m13.1.1.1.1.1.3.3.cmml" xref="A1.SS7.p1.13.m13.1.1.1.1.1.3.3"></times></apply></apply></apply><infinity id="A1.SS7.p1.13.m13.1.1.3.cmml" xref="A1.SS7.p1.13.m13.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p1.13.m13.1c">||h-V^{*}||_{\infty}</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p1.13.m13.1d">| | italic_h - italic_V start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT | | start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p1.13.21">.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS7.p2">
<p class="ltx_p" id="A1.SS7.p2.6"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.1">Specifically, assume access to an initial dataset </span><math alttext="\mathcal{D}_{0}" class="ltx_Math" display="inline" id="A1.SS7.p2.1.m1.1"><semantics id="A1.SS7.p2.1.m1.1a"><msub id="A1.SS7.p2.1.m1.1.1" xref="A1.SS7.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS7.p2.1.m1.1.1.2" xref="A1.SS7.p2.1.m1.1.1.2.cmml">𝒟</mi><mn id="A1.SS7.p2.1.m1.1.1.3" xref="A1.SS7.p2.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS7.p2.1.m1.1b"><apply id="A1.SS7.p2.1.m1.1.1.cmml" xref="A1.SS7.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS7.p2.1.m1.1.1.1.cmml" xref="A1.SS7.p2.1.m1.1.1">subscript</csymbol><ci id="A1.SS7.p2.1.m1.1.1.2.cmml" xref="A1.SS7.p2.1.m1.1.1.2">𝒟</ci><cn id="A1.SS7.p2.1.m1.1.1.3.cmml" type="integer" xref="A1.SS7.p2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p2.1.m1.1c">\mathcal{D}_{0}</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p2.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.2">, from which a heuristic </span><math alttext="h" class="ltx_Math" display="inline" id="A1.SS7.p2.2.m2.1"><semantics id="A1.SS7.p2.2.m2.1a"><mi id="A1.SS7.p2.2.m2.1.1" xref="A1.SS7.p2.2.m2.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p2.2.m2.1b"><ci id="A1.SS7.p2.2.m2.1.1.cmml" xref="A1.SS7.p2.2.m2.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p2.2.m2.1c">h</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p2.2.m2.1d">italic_h</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.3"> can be computed. In the reshaped MDP </span><math alttext="\tilde{M}" class="ltx_Math" display="inline" id="A1.SS7.p2.3.m3.1"><semantics id="A1.SS7.p2.3.m3.1a"><mover accent="true" id="A1.SS7.p2.3.m3.1.1" xref="A1.SS7.p2.3.m3.1.1.cmml"><mi id="A1.SS7.p2.3.m3.1.1.2" xref="A1.SS7.p2.3.m3.1.1.2.cmml">M</mi><mo id="A1.SS7.p2.3.m3.1.1.1" xref="A1.SS7.p2.3.m3.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="A1.SS7.p2.3.m3.1b"><apply id="A1.SS7.p2.3.m3.1.1.cmml" xref="A1.SS7.p2.3.m3.1.1"><ci id="A1.SS7.p2.3.m3.1.1.1.cmml" xref="A1.SS7.p2.3.m3.1.1.1">~</ci><ci id="A1.SS7.p2.3.m3.1.1.2.cmml" xref="A1.SS7.p2.3.m3.1.1.2">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p2.3.m3.1c">\tilde{M}</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p2.3.m3.1d">over~ start_ARG italic_M end_ARG</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.4">, one can learn a new policy </span><math alttext="\pi" class="ltx_Math" display="inline" id="A1.SS7.p2.4.m4.1"><semantics id="A1.SS7.p2.4.m4.1a"><mi id="A1.SS7.p2.4.m4.1.1" xref="A1.SS7.p2.4.m4.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p2.4.m4.1b"><ci id="A1.SS7.p2.4.m4.1.1.cmml" xref="A1.SS7.p2.4.m4.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p2.4.m4.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p2.4.m4.1d">italic_π</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.5"> which optimizes </span><math alttext="\tilde{r}" class="ltx_Math" display="inline" id="A1.SS7.p2.5.m5.1"><semantics id="A1.SS7.p2.5.m5.1a"><mover accent="true" id="A1.SS7.p2.5.m5.1.1" xref="A1.SS7.p2.5.m5.1.1.cmml"><mi id="A1.SS7.p2.5.m5.1.1.2" xref="A1.SS7.p2.5.m5.1.1.2.cmml">r</mi><mo id="A1.SS7.p2.5.m5.1.1.1" xref="A1.SS7.p2.5.m5.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="A1.SS7.p2.5.m5.1b"><apply id="A1.SS7.p2.5.m5.1.1.cmml" xref="A1.SS7.p2.5.m5.1.1"><ci id="A1.SS7.p2.5.m5.1.1.1.cmml" xref="A1.SS7.p2.5.m5.1.1.1">~</ci><ci id="A1.SS7.p2.5.m5.1.1.2.cmml" xref="A1.SS7.p2.5.m5.1.1.2">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p2.5.m5.1c">\tilde{r}</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p2.5.m5.1d">over~ start_ARG italic_r end_ARG</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.6"> with </span><math alttext="\lambda\in[0,1]" class="ltx_Math" display="inline" id="A1.SS7.p2.6.m6.2"><semantics id="A1.SS7.p2.6.m6.2a"><mrow id="A1.SS7.p2.6.m6.2.3" xref="A1.SS7.p2.6.m6.2.3.cmml"><mi id="A1.SS7.p2.6.m6.2.3.2" xref="A1.SS7.p2.6.m6.2.3.2.cmml">λ</mi><mo id="A1.SS7.p2.6.m6.2.3.1" xref="A1.SS7.p2.6.m6.2.3.1.cmml">∈</mo><mrow id="A1.SS7.p2.6.m6.2.3.3.2" xref="A1.SS7.p2.6.m6.2.3.3.1.cmml"><mo id="A1.SS7.p2.6.m6.2.3.3.2.1" stretchy="false" xref="A1.SS7.p2.6.m6.2.3.3.1.cmml">[</mo><mn id="A1.SS7.p2.6.m6.1.1" xref="A1.SS7.p2.6.m6.1.1.cmml">0</mn><mo id="A1.SS7.p2.6.m6.2.3.3.2.2" xref="A1.SS7.p2.6.m6.2.3.3.1.cmml">,</mo><mn id="A1.SS7.p2.6.m6.2.2" xref="A1.SS7.p2.6.m6.2.2.cmml">1</mn><mo id="A1.SS7.p2.6.m6.2.3.3.2.3" stretchy="false" xref="A1.SS7.p2.6.m6.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS7.p2.6.m6.2b"><apply id="A1.SS7.p2.6.m6.2.3.cmml" xref="A1.SS7.p2.6.m6.2.3"><in id="A1.SS7.p2.6.m6.2.3.1.cmml" xref="A1.SS7.p2.6.m6.2.3.1"></in><ci id="A1.SS7.p2.6.m6.2.3.2.cmml" xref="A1.SS7.p2.6.m6.2.3.2">𝜆</ci><interval closure="closed" id="A1.SS7.p2.6.m6.2.3.3.1.cmml" xref="A1.SS7.p2.6.m6.2.3.3.2"><cn id="A1.SS7.p2.6.m6.1.1.cmml" type="integer" xref="A1.SS7.p2.6.m6.1.1">0</cn><cn id="A1.SS7.p2.6.m6.2.2.cmml" type="integer" xref="A1.SS7.p2.6.m6.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p2.6.m6.2c">\lambda\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p2.6.m6.2d">italic_λ ∈ [ 0 , 1 ]</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.7">. </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.E5" title="In A.7 AI feedback and heuristic functions ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Equation</span> <span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.8"> shows the performance difference lemma </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_sansserif ltx_font_bold">Kakade &amp; Langford</span> <span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.9.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib20" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2002</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.10.2.2.1">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p2.6.11"> as a function of true and reshaped MDP quantities:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS7.p3">
<table class="ltx_equation ltx_eqn_table" id="A1.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\begin{split}\mathcal{L}(\pi,h)=&amp;\mathbb{E}_{\mathcal{D}_{0}}[V^{*}(s)-V^{\pi}%
(s)]\\
=&amp;c_{1}\color[rgb]{0,0.5,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.5,1}%
\pgfsys@color@cmyk@stroke{1}{0.50}{0}{0}\pgfsys@color@cmyk@fill{1}{0.50}{0}{0}%
\mathbb{E}_{\mathcal{D}_{0}}\bigg{[}\tilde{V}^{*}(s)-\tilde{V}^{\pi}(s)\bigg{]%
}\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}%
\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0}+c_{2}\color[rgb]{%
0,0.88,0}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.88,0}%
\pgfsys@color@cmyk@stroke{0.91}{0}{0.88}{0.12}\pgfsys@color@cmyk@fill{0.91}{0}%
{0.88}{0.12}\mathbb{E}_{\mathcal{D}^{\pi}}\bigg{[}\tilde{V}^{*}(s)-\tilde{V}^{%
\pi}(s)\bigg{]}\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0}+c_{3}\color[rgb]{%
1,0.04,0.61}\definecolor[named]{pgfstrokecolor}{rgb}{1,0.04,0.61}%
\pgfsys@color@cmyk@stroke{0}{0.96}{0.39}{0}\pgfsys@color@cmyk@fill{0}{0.96}{0.%
39}{0}\mathbb{E}_{\mathcal{D}^{\pi}}\bigg{[}h(s^{\prime})-\tilde{V}^{*}(s^{%
\prime})\bigg{]}\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0},\end{split}" class="ltx_Math" display="block" id="A1.E5.m1.81"><semantics id="A1.E5.m1.81a"><mtable columnspacing="0pt" displaystyle="true" id="A1.E5.m1.81.81.3" rowspacing="0pt"><mtr id="A1.E5.m1.81.81.3a"><mtd class="ltx_align_right" columnalign="right" id="A1.E5.m1.81.81.3b"><mrow id="A1.E5.m1.7.7.7.7.7"><mrow id="A1.E5.m1.7.7.7.7.7.8"><mi class="ltx_font_mathcaligraphic" id="A1.E5.m1.1.1.1.1.1.1" xref="A1.E5.m1.1.1.1.1.1.1.cmml">ℒ</mi><mo id="A1.E5.m1.7.7.7.7.7.8.1" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.7.7.7.7.7.8.2"><mo id="A1.E5.m1.2.2.2.2.2.2" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">(</mo><mi id="A1.E5.m1.3.3.3.3.3.3" xref="A1.E5.m1.3.3.3.3.3.3.cmml">π</mi><mo id="A1.E5.m1.4.4.4.4.4.4" xref="A1.E5.m1.79.79.1.1.1.cmml">,</mo><mi id="A1.E5.m1.5.5.5.5.5.5" xref="A1.E5.m1.5.5.5.5.5.5.cmml">h</mi><mo id="A1.E5.m1.6.6.6.6.6.6" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E5.m1.7.7.7.7.7.7" xref="A1.E5.m1.7.7.7.7.7.7.cmml">=</mo><mi id="A1.E5.m1.7.7.7.7.7.9" xref="A1.E5.m1.79.79.1.1.1.cmml"></mi></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="A1.E5.m1.81.81.3c"><mrow id="A1.E5.m1.80.80.2.79.23.16"><msub id="A1.E5.m1.80.80.2.79.23.16.18"><mi id="A1.E5.m1.8.8.8.8.1.1" xref="A1.E5.m1.8.8.8.8.1.1.cmml">𝔼</mi><msub id="A1.E5.m1.9.9.9.9.2.2.1" xref="A1.E5.m1.9.9.9.9.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.E5.m1.9.9.9.9.2.2.1.2" xref="A1.E5.m1.9.9.9.9.2.2.1.2.cmml">𝒟</mi><mn id="A1.E5.m1.9.9.9.9.2.2.1.3" xref="A1.E5.m1.9.9.9.9.2.2.1.3.cmml">0</mn></msub></msub><mo id="A1.E5.m1.80.80.2.79.23.16.17" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.80.80.2.79.23.16.16.1"><mo id="A1.E5.m1.10.10.10.10.3.3" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">[</mo><mrow id="A1.E5.m1.80.80.2.79.23.16.16.1.1"><mrow id="A1.E5.m1.80.80.2.79.23.16.16.1.1.1"><msup id="A1.E5.m1.80.80.2.79.23.16.16.1.1.1.2"><mi id="A1.E5.m1.11.11.11.11.4.4" xref="A1.E5.m1.11.11.11.11.4.4.cmml">V</mi><mo id="A1.E5.m1.12.12.12.12.5.5.1" xref="A1.E5.m1.12.12.12.12.5.5.1.cmml">∗</mo></msup><mo id="A1.E5.m1.80.80.2.79.23.16.16.1.1.1.1" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.80.80.2.79.23.16.16.1.1.1.3"><mo id="A1.E5.m1.13.13.13.13.6.6" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">(</mo><mi id="A1.E5.m1.14.14.14.14.7.7" xref="A1.E5.m1.14.14.14.14.7.7.cmml">s</mi><mo id="A1.E5.m1.15.15.15.15.8.8" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E5.m1.16.16.16.16.9.9" xref="A1.E5.m1.16.16.16.16.9.9.cmml">−</mo><mrow id="A1.E5.m1.80.80.2.79.23.16.16.1.1.2"><msup id="A1.E5.m1.80.80.2.79.23.16.16.1.1.2.2"><mi id="A1.E5.m1.17.17.17.17.10.10" xref="A1.E5.m1.17.17.17.17.10.10.cmml">V</mi><mi id="A1.E5.m1.18.18.18.18.11.11.1" xref="A1.E5.m1.18.18.18.18.11.11.1.cmml">π</mi></msup><mo id="A1.E5.m1.80.80.2.79.23.16.16.1.1.2.1" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.80.80.2.79.23.16.16.1.1.2.3"><mo id="A1.E5.m1.19.19.19.19.12.12" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">(</mo><mi id="A1.E5.m1.20.20.20.20.13.13" xref="A1.E5.m1.20.20.20.20.13.13.cmml">s</mi><mo id="A1.E5.m1.21.21.21.21.14.14" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A1.E5.m1.22.22.22.22.15.15" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">]</mo></mrow></mrow></mtd></mtr><mtr id="A1.E5.m1.81.81.3d"><mtd class="ltx_align_right" columnalign="right" id="A1.E5.m1.81.81.3e"><mo id="A1.E5.m1.23.23.23.1.1.1" xref="A1.E5.m1.23.23.23.1.1.1.cmml">=</mo></mtd><mtd class="ltx_align_left" columnalign="left" id="A1.E5.m1.81.81.3f"><mrow id="A1.E5.m1.81.81.3.80.57.56.56"><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1"><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.1"><msub id="A1.E5.m1.81.81.3.80.57.56.56.1.1.3"><mi id="A1.E5.m1.24.24.24.2.1.1" mathcolor="#000000" xref="A1.E5.m1.24.24.24.2.1.1.cmml">c</mi><mn id="A1.E5.m1.25.25.25.3.2.2.1" mathcolor="#000000" xref="A1.E5.m1.25.25.25.3.2.2.1.cmml">1</mn></msub><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.1.2" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><msub id="A1.E5.m1.81.81.3.80.57.56.56.1.1.4"><mi id="A1.E5.m1.26.26.26.4.3.3" mathcolor="#0080FF" xref="A1.E5.m1.26.26.26.4.3.3.cmml">𝔼</mi><msub id="A1.E5.m1.27.27.27.5.4.4.1" xref="A1.E5.m1.27.27.27.5.4.4.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.E5.m1.27.27.27.5.4.4.1.2" mathcolor="#0080FF" xref="A1.E5.m1.27.27.27.5.4.4.1.2.cmml">𝒟</mi><mn id="A1.E5.m1.27.27.27.5.4.4.1.3" mathcolor="#0080FF" xref="A1.E5.m1.27.27.27.5.4.4.1.3.cmml">0</mn></msub></msub><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.1.2a" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.1.1.1"><mo id="A1.E5.m1.28.28.28.6.5.5" mathcolor="#0080FF" maxsize="210%" minsize="210%" xref="A1.E5.m1.79.79.1.1.1.cmml">[</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.1.1.1.1"><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.1.1.1.1.1"><msup id="A1.E5.m1.81.81.3.80.57.56.56.1.1.1.1.1.1.2"><mover accent="true" id="A1.E5.m1.29.29.29.7.6.6" xref="A1.E5.m1.29.29.29.7.6.6.cmml"><mi id="A1.E5.m1.29.29.29.7.6.6.2" mathcolor="#0080FF" xref="A1.E5.m1.29.29.29.7.6.6.2.cmml">V</mi><mo id="A1.E5.m1.29.29.29.7.6.6.1" mathcolor="#0080FF" xref="A1.E5.m1.29.29.29.7.6.6.1.cmml">~</mo></mover><mo id="A1.E5.m1.30.30.30.8.7.7.1" mathcolor="#0080FF" xref="A1.E5.m1.30.30.30.8.7.7.1.cmml">∗</mo></msup><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.1.1.1.1.1.1" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.1.1.1.1.1.3"><mo id="A1.E5.m1.31.31.31.9.8.8" mathcolor="#0080FF" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">(</mo><mi id="A1.E5.m1.32.32.32.10.9.9" mathcolor="#0080FF" xref="A1.E5.m1.32.32.32.10.9.9.cmml">s</mi><mo id="A1.E5.m1.33.33.33.11.10.10" mathcolor="#0080FF" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E5.m1.34.34.34.12.11.11" mathcolor="#0080FF" xref="A1.E5.m1.34.34.34.12.11.11.cmml">−</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.1.1.1.1.2"><msup id="A1.E5.m1.81.81.3.80.57.56.56.1.1.1.1.1.2.2"><mover accent="true" id="A1.E5.m1.35.35.35.13.12.12" xref="A1.E5.m1.35.35.35.13.12.12.cmml"><mi id="A1.E5.m1.35.35.35.13.12.12.2" mathcolor="#0080FF" xref="A1.E5.m1.35.35.35.13.12.12.2.cmml">V</mi><mo id="A1.E5.m1.35.35.35.13.12.12.1" mathcolor="#0080FF" xref="A1.E5.m1.35.35.35.13.12.12.1.cmml">~</mo></mover><mi id="A1.E5.m1.36.36.36.14.13.13.1" mathcolor="#0080FF" xref="A1.E5.m1.36.36.36.14.13.13.1.cmml">π</mi></msup><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.1.1.1.1.2.1" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.1.1.1.1.2.3"><mo id="A1.E5.m1.37.37.37.15.14.14" mathcolor="#0080FF" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">(</mo><mi id="A1.E5.m1.38.38.38.16.15.15" mathcolor="#0080FF" xref="A1.E5.m1.38.38.38.16.15.15.cmml">s</mi><mo id="A1.E5.m1.39.39.39.17.16.16" mathcolor="#0080FF" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A1.E5.m1.40.40.40.18.17.17" mathcolor="#0080FF" maxsize="210%" minsize="210%" xref="A1.E5.m1.79.79.1.1.1.cmml">]</mo></mrow></mrow><mo id="A1.E5.m1.41.41.41.19.18.18" mathcolor="#000000" xref="A1.E5.m1.41.41.41.19.18.18.cmml">+</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.2"><msub id="A1.E5.m1.81.81.3.80.57.56.56.1.2.3"><mi id="A1.E5.m1.42.42.42.20.19.19" mathcolor="#000000" xref="A1.E5.m1.42.42.42.20.19.19.cmml">c</mi><mn id="A1.E5.m1.43.43.43.21.20.20.1" mathcolor="#000000" xref="A1.E5.m1.43.43.43.21.20.20.1.cmml">2</mn></msub><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.2.2" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><msub id="A1.E5.m1.81.81.3.80.57.56.56.1.2.4"><mi id="A1.E5.m1.44.44.44.22.21.21" mathcolor="#00E000" xref="A1.E5.m1.44.44.44.22.21.21.cmml">𝔼</mi><msup id="A1.E5.m1.45.45.45.23.22.22.1" xref="A1.E5.m1.45.45.45.23.22.22.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.E5.m1.45.45.45.23.22.22.1.2" mathcolor="#00E000" xref="A1.E5.m1.45.45.45.23.22.22.1.2.cmml">𝒟</mi><mi id="A1.E5.m1.45.45.45.23.22.22.1.3" mathcolor="#00E000" xref="A1.E5.m1.45.45.45.23.22.22.1.3.cmml">π</mi></msup></msub><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.2.2a" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.2.1.1"><mo id="A1.E5.m1.46.46.46.24.23.23" mathcolor="#00E000" maxsize="210%" minsize="210%" xref="A1.E5.m1.79.79.1.1.1.cmml">[</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.2.1.1.1"><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.2.1.1.1.1"><msup id="A1.E5.m1.81.81.3.80.57.56.56.1.2.1.1.1.1.2"><mover accent="true" id="A1.E5.m1.47.47.47.25.24.24" xref="A1.E5.m1.47.47.47.25.24.24.cmml"><mi id="A1.E5.m1.47.47.47.25.24.24.2" mathcolor="#00E000" xref="A1.E5.m1.47.47.47.25.24.24.2.cmml">V</mi><mo id="A1.E5.m1.47.47.47.25.24.24.1" mathcolor="#00E000" xref="A1.E5.m1.47.47.47.25.24.24.1.cmml">~</mo></mover><mo id="A1.E5.m1.48.48.48.26.25.25.1" mathcolor="#00E000" xref="A1.E5.m1.48.48.48.26.25.25.1.cmml">∗</mo></msup><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.2.1.1.1.1.1" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.2.1.1.1.1.3"><mo id="A1.E5.m1.49.49.49.27.26.26" mathcolor="#00E000" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">(</mo><mi id="A1.E5.m1.50.50.50.28.27.27" mathcolor="#00E000" xref="A1.E5.m1.50.50.50.28.27.27.cmml">s</mi><mo id="A1.E5.m1.51.51.51.29.28.28" mathcolor="#00E000" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E5.m1.52.52.52.30.29.29" mathcolor="#00E000" xref="A1.E5.m1.52.52.52.30.29.29.cmml">−</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.2.1.1.1.2"><msup id="A1.E5.m1.81.81.3.80.57.56.56.1.2.1.1.1.2.2"><mover accent="true" id="A1.E5.m1.53.53.53.31.30.30" xref="A1.E5.m1.53.53.53.31.30.30.cmml"><mi id="A1.E5.m1.53.53.53.31.30.30.2" mathcolor="#00E000" xref="A1.E5.m1.53.53.53.31.30.30.2.cmml">V</mi><mo id="A1.E5.m1.53.53.53.31.30.30.1" mathcolor="#00E000" xref="A1.E5.m1.53.53.53.31.30.30.1.cmml">~</mo></mover><mi id="A1.E5.m1.54.54.54.32.31.31.1" mathcolor="#00E000" xref="A1.E5.m1.54.54.54.32.31.31.1.cmml">π</mi></msup><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.2.1.1.1.2.1" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.2.1.1.1.2.3"><mo id="A1.E5.m1.55.55.55.33.32.32" mathcolor="#00E000" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">(</mo><mi id="A1.E5.m1.56.56.56.34.33.33" mathcolor="#00E000" xref="A1.E5.m1.56.56.56.34.33.33.cmml">s</mi><mo id="A1.E5.m1.57.57.57.35.34.34" mathcolor="#00E000" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A1.E5.m1.58.58.58.36.35.35" mathcolor="#00E000" maxsize="210%" minsize="210%" xref="A1.E5.m1.79.79.1.1.1.cmml">]</mo></mrow></mrow><mo id="A1.E5.m1.41.41.41.19.18.18a" mathcolor="#000000" xref="A1.E5.m1.41.41.41.19.18.18.cmml">+</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.3"><msub id="A1.E5.m1.81.81.3.80.57.56.56.1.3.3"><mi id="A1.E5.m1.60.60.60.38.37.37" mathcolor="#000000" xref="A1.E5.m1.60.60.60.38.37.37.cmml">c</mi><mn id="A1.E5.m1.61.61.61.39.38.38.1" mathcolor="#000000" xref="A1.E5.m1.61.61.61.39.38.38.1.cmml">3</mn></msub><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.3.2" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><msub id="A1.E5.m1.81.81.3.80.57.56.56.1.3.4"><mi id="A1.E5.m1.62.62.62.40.39.39" mathcolor="#FF0A9C" xref="A1.E5.m1.62.62.62.40.39.39.cmml">𝔼</mi><msup id="A1.E5.m1.63.63.63.41.40.40.1" xref="A1.E5.m1.63.63.63.41.40.40.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.E5.m1.63.63.63.41.40.40.1.2" mathcolor="#FF0A9C" xref="A1.E5.m1.63.63.63.41.40.40.1.2.cmml">𝒟</mi><mi id="A1.E5.m1.63.63.63.41.40.40.1.3" mathcolor="#FF0A9C" xref="A1.E5.m1.63.63.63.41.40.40.1.3.cmml">π</mi></msup></msub><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.3.2a" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1"><mo id="A1.E5.m1.64.64.64.42.41.41" mathcolor="#FF0A9C" maxsize="210%" minsize="210%" xref="A1.E5.m1.79.79.1.1.1.cmml">[</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1.1"><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1.1.1"><mi id="A1.E5.m1.65.65.65.43.42.42" mathcolor="#FF0A9C" xref="A1.E5.m1.65.65.65.43.42.42.cmml">h</mi><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1.1.1.2" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1.1.1.1.1"><mo id="A1.E5.m1.66.66.66.44.43.43" mathcolor="#FF0A9C" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">(</mo><msup id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1.1.1.1.1.1"><mi id="A1.E5.m1.67.67.67.45.44.44" mathcolor="#FF0A9C" xref="A1.E5.m1.67.67.67.45.44.44.cmml">s</mi><mo id="A1.E5.m1.68.68.68.46.45.45.1" mathcolor="#FF0A9C" xref="A1.E5.m1.68.68.68.46.45.45.1.cmml">′</mo></msup><mo id="A1.E5.m1.69.69.69.47.46.46" mathcolor="#FF0A9C" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E5.m1.70.70.70.48.47.47" mathcolor="#FF0A9C" xref="A1.E5.m1.70.70.70.48.47.47.cmml">−</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1.1.2"><msup id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1.1.2.3"><mover accent="true" id="A1.E5.m1.71.71.71.49.48.48" xref="A1.E5.m1.71.71.71.49.48.48.cmml"><mi id="A1.E5.m1.71.71.71.49.48.48.2" mathcolor="#FF0A9C" xref="A1.E5.m1.71.71.71.49.48.48.2.cmml">V</mi><mo id="A1.E5.m1.71.71.71.49.48.48.1" mathcolor="#FF0A9C" xref="A1.E5.m1.71.71.71.49.48.48.1.cmml">~</mo></mover><mo id="A1.E5.m1.72.72.72.50.49.49.1" mathcolor="#FF0A9C" xref="A1.E5.m1.72.72.72.50.49.49.1.cmml">∗</mo></msup><mo id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1.1.2.2" xref="A1.E5.m1.79.79.1.1.1.cmml">⁢</mo><mrow id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1.1.2.1.1"><mo id="A1.E5.m1.73.73.73.51.50.50" mathcolor="#FF0A9C" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">(</mo><msup id="A1.E5.m1.81.81.3.80.57.56.56.1.3.1.1.1.2.1.1.1"><mi id="A1.E5.m1.74.74.74.52.51.51" mathcolor="#FF0A9C" xref="A1.E5.m1.74.74.74.52.51.51.cmml">s</mi><mo id="A1.E5.m1.75.75.75.53.52.52.1" mathcolor="#FF0A9C" xref="A1.E5.m1.75.75.75.53.52.52.1.cmml">′</mo></msup><mo id="A1.E5.m1.76.76.76.54.53.53" mathcolor="#FF0A9C" stretchy="false" xref="A1.E5.m1.79.79.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A1.E5.m1.77.77.77.55.54.54" mathcolor="#FF0A9C" maxsize="210%" minsize="210%" xref="A1.E5.m1.79.79.1.1.1.cmml">]</mo></mrow></mrow></mrow><mo id="A1.E5.m1.78.78.78.56.55.55" mathcolor="#000000" xref="A1.E5.m1.79.79.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="A1.E5.m1.81b"><apply id="A1.E5.m1.79.79.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><and id="A1.E5.m1.79.79.1.1.1a.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></and><apply id="A1.E5.m1.79.79.1.1.1b.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><eq id="A1.E5.m1.7.7.7.7.7.7.cmml" xref="A1.E5.m1.7.7.7.7.7.7"></eq><apply id="A1.E5.m1.79.79.1.1.1.6.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.6.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><ci id="A1.E5.m1.1.1.1.1.1.1.cmml" xref="A1.E5.m1.1.1.1.1.1.1">ℒ</ci><interval closure="open" id="A1.E5.m1.79.79.1.1.1.6.3.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><ci id="A1.E5.m1.3.3.3.3.3.3.cmml" xref="A1.E5.m1.3.3.3.3.3.3">𝜋</ci><ci id="A1.E5.m1.5.5.5.5.5.5.cmml" xref="A1.E5.m1.5.5.5.5.5.5">ℎ</ci></interval></apply><apply id="A1.E5.m1.79.79.1.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.1.3.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.1.3.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">subscript</csymbol><ci id="A1.E5.m1.8.8.8.8.1.1.cmml" xref="A1.E5.m1.8.8.8.8.1.1">𝔼</ci><apply id="A1.E5.m1.9.9.9.9.2.2.1.cmml" xref="A1.E5.m1.9.9.9.9.2.2.1"><csymbol cd="ambiguous" id="A1.E5.m1.9.9.9.9.2.2.1.1.cmml" xref="A1.E5.m1.9.9.9.9.2.2.1">subscript</csymbol><ci id="A1.E5.m1.9.9.9.9.2.2.1.2.cmml" xref="A1.E5.m1.9.9.9.9.2.2.1.2">𝒟</ci><cn id="A1.E5.m1.9.9.9.9.2.2.1.3.cmml" type="integer" xref="A1.E5.m1.9.9.9.9.2.2.1.3">0</cn></apply></apply><apply id="A1.E5.m1.79.79.1.1.1.1.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="latexml" id="A1.E5.m1.79.79.1.1.1.1.1.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">delimited-[]</csymbol><apply id="A1.E5.m1.79.79.1.1.1.1.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><minus id="A1.E5.m1.16.16.16.16.9.9.cmml" xref="A1.E5.m1.16.16.16.16.9.9"></minus><apply id="A1.E5.m1.79.79.1.1.1.1.1.1.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.1.1.1.1.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.1.1.1.1.2.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.1.1.1.1.2.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">superscript</csymbol><ci id="A1.E5.m1.11.11.11.11.4.4.cmml" xref="A1.E5.m1.11.11.11.11.4.4">𝑉</ci><times id="A1.E5.m1.12.12.12.12.5.5.1.cmml" xref="A1.E5.m1.12.12.12.12.5.5.1"></times></apply><ci id="A1.E5.m1.14.14.14.14.7.7.cmml" xref="A1.E5.m1.14.14.14.14.7.7">𝑠</ci></apply><apply id="A1.E5.m1.79.79.1.1.1.1.1.1.1.3.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.1.1.1.1.3.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.1.1.1.1.3.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.1.1.1.1.3.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">superscript</csymbol><ci id="A1.E5.m1.17.17.17.17.10.10.cmml" xref="A1.E5.m1.17.17.17.17.10.10">𝑉</ci><ci id="A1.E5.m1.18.18.18.18.11.11.1.cmml" xref="A1.E5.m1.18.18.18.18.11.11.1">𝜋</ci></apply><ci id="A1.E5.m1.20.20.20.20.13.13.cmml" xref="A1.E5.m1.20.20.20.20.13.13">𝑠</ci></apply></apply></apply></apply></apply><apply id="A1.E5.m1.79.79.1.1.1c.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><eq id="A1.E5.m1.23.23.23.1.1.1.cmml" xref="A1.E5.m1.23.23.23.1.1.1"></eq><share href="https://arxiv.org/html/2410.05656v1#A1.E5.m1.79.79.1.1.1.1.cmml" id="A1.E5.m1.79.79.1.1.1d.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></share><apply id="A1.E5.m1.79.79.1.1.1.4.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><plus id="A1.E5.m1.41.41.41.19.18.18.cmml" xref="A1.E5.m1.41.41.41.19.18.18"></plus><apply id="A1.E5.m1.79.79.1.1.1.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.2.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.2.1.3.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.2.1.3.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">subscript</csymbol><ci id="A1.E5.m1.24.24.24.2.1.1.cmml" xref="A1.E5.m1.24.24.24.2.1.1">𝑐</ci><cn id="A1.E5.m1.25.25.25.3.2.2.1.cmml" type="integer" xref="A1.E5.m1.25.25.25.3.2.2.1">1</cn></apply><apply id="A1.E5.m1.79.79.1.1.1.2.1.4.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.2.1.4.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">subscript</csymbol><ci id="A1.E5.m1.26.26.26.4.3.3.cmml" xref="A1.E5.m1.26.26.26.4.3.3">𝔼</ci><apply id="A1.E5.m1.27.27.27.5.4.4.1.cmml" xref="A1.E5.m1.27.27.27.5.4.4.1"><csymbol cd="ambiguous" id="A1.E5.m1.27.27.27.5.4.4.1.1.cmml" xref="A1.E5.m1.27.27.27.5.4.4.1">subscript</csymbol><ci id="A1.E5.m1.27.27.27.5.4.4.1.2.cmml" xref="A1.E5.m1.27.27.27.5.4.4.1.2">𝒟</ci><cn id="A1.E5.m1.27.27.27.5.4.4.1.3.cmml" type="integer" xref="A1.E5.m1.27.27.27.5.4.4.1.3">0</cn></apply></apply><apply id="A1.E5.m1.79.79.1.1.1.2.1.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="latexml" id="A1.E5.m1.79.79.1.1.1.2.1.1.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">delimited-[]</csymbol><apply id="A1.E5.m1.79.79.1.1.1.2.1.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><minus id="A1.E5.m1.34.34.34.12.11.11.cmml" xref="A1.E5.m1.34.34.34.12.11.11"></minus><apply id="A1.E5.m1.79.79.1.1.1.2.1.1.1.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.2.1.1.1.1.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.2.1.1.1.1.2.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.2.1.1.1.1.2.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">superscript</csymbol><apply id="A1.E5.m1.29.29.29.7.6.6.cmml" xref="A1.E5.m1.29.29.29.7.6.6"><ci id="A1.E5.m1.29.29.29.7.6.6.1.cmml" xref="A1.E5.m1.29.29.29.7.6.6.1">~</ci><ci id="A1.E5.m1.29.29.29.7.6.6.2.cmml" xref="A1.E5.m1.29.29.29.7.6.6.2">𝑉</ci></apply><times id="A1.E5.m1.30.30.30.8.7.7.1.cmml" xref="A1.E5.m1.30.30.30.8.7.7.1"></times></apply><ci id="A1.E5.m1.32.32.32.10.9.9.cmml" xref="A1.E5.m1.32.32.32.10.9.9">𝑠</ci></apply><apply id="A1.E5.m1.79.79.1.1.1.2.1.1.1.1.3.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.2.1.1.1.1.3.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.2.1.1.1.1.3.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.2.1.1.1.1.3.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">superscript</csymbol><apply id="A1.E5.m1.35.35.35.13.12.12.cmml" xref="A1.E5.m1.35.35.35.13.12.12"><ci id="A1.E5.m1.35.35.35.13.12.12.1.cmml" xref="A1.E5.m1.35.35.35.13.12.12.1">~</ci><ci id="A1.E5.m1.35.35.35.13.12.12.2.cmml" xref="A1.E5.m1.35.35.35.13.12.12.2">𝑉</ci></apply><ci id="A1.E5.m1.36.36.36.14.13.13.1.cmml" xref="A1.E5.m1.36.36.36.14.13.13.1">𝜋</ci></apply><ci id="A1.E5.m1.38.38.38.16.15.15.cmml" xref="A1.E5.m1.38.38.38.16.15.15">𝑠</ci></apply></apply></apply></apply><apply id="A1.E5.m1.79.79.1.1.1.3.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.3.2.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.3.2.3.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.3.2.3.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">subscript</csymbol><ci id="A1.E5.m1.42.42.42.20.19.19.cmml" xref="A1.E5.m1.42.42.42.20.19.19">𝑐</ci><cn id="A1.E5.m1.43.43.43.21.20.20.1.cmml" type="integer" xref="A1.E5.m1.43.43.43.21.20.20.1">2</cn></apply><apply id="A1.E5.m1.79.79.1.1.1.3.2.4.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.3.2.4.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">subscript</csymbol><ci id="A1.E5.m1.44.44.44.22.21.21.cmml" xref="A1.E5.m1.44.44.44.22.21.21">𝔼</ci><apply id="A1.E5.m1.45.45.45.23.22.22.1.cmml" xref="A1.E5.m1.45.45.45.23.22.22.1"><csymbol cd="ambiguous" id="A1.E5.m1.45.45.45.23.22.22.1.1.cmml" xref="A1.E5.m1.45.45.45.23.22.22.1">superscript</csymbol><ci id="A1.E5.m1.45.45.45.23.22.22.1.2.cmml" xref="A1.E5.m1.45.45.45.23.22.22.1.2">𝒟</ci><ci id="A1.E5.m1.45.45.45.23.22.22.1.3.cmml" xref="A1.E5.m1.45.45.45.23.22.22.1.3">𝜋</ci></apply></apply><apply id="A1.E5.m1.79.79.1.1.1.3.2.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="latexml" id="A1.E5.m1.79.79.1.1.1.3.2.1.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">delimited-[]</csymbol><apply id="A1.E5.m1.79.79.1.1.1.3.2.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><minus id="A1.E5.m1.52.52.52.30.29.29.cmml" xref="A1.E5.m1.52.52.52.30.29.29"></minus><apply id="A1.E5.m1.79.79.1.1.1.3.2.1.1.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.3.2.1.1.1.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.3.2.1.1.1.2.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.3.2.1.1.1.2.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">superscript</csymbol><apply id="A1.E5.m1.47.47.47.25.24.24.cmml" xref="A1.E5.m1.47.47.47.25.24.24"><ci id="A1.E5.m1.47.47.47.25.24.24.1.cmml" xref="A1.E5.m1.47.47.47.25.24.24.1">~</ci><ci id="A1.E5.m1.47.47.47.25.24.24.2.cmml" xref="A1.E5.m1.47.47.47.25.24.24.2">𝑉</ci></apply><times id="A1.E5.m1.48.48.48.26.25.25.1.cmml" xref="A1.E5.m1.48.48.48.26.25.25.1"></times></apply><ci id="A1.E5.m1.50.50.50.28.27.27.cmml" xref="A1.E5.m1.50.50.50.28.27.27">𝑠</ci></apply><apply id="A1.E5.m1.79.79.1.1.1.3.2.1.1.1.3.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.3.2.1.1.1.3.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.3.2.1.1.1.3.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.3.2.1.1.1.3.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">superscript</csymbol><apply id="A1.E5.m1.53.53.53.31.30.30.cmml" xref="A1.E5.m1.53.53.53.31.30.30"><ci id="A1.E5.m1.53.53.53.31.30.30.1.cmml" xref="A1.E5.m1.53.53.53.31.30.30.1">~</ci><ci id="A1.E5.m1.53.53.53.31.30.30.2.cmml" xref="A1.E5.m1.53.53.53.31.30.30.2">𝑉</ci></apply><ci id="A1.E5.m1.54.54.54.32.31.31.1.cmml" xref="A1.E5.m1.54.54.54.32.31.31.1">𝜋</ci></apply><ci id="A1.E5.m1.56.56.56.34.33.33.cmml" xref="A1.E5.m1.56.56.56.34.33.33">𝑠</ci></apply></apply></apply></apply><apply id="A1.E5.m1.79.79.1.1.1.4.3.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.4.3.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.4.3.3.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.4.3.3.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">subscript</csymbol><ci id="A1.E5.m1.60.60.60.38.37.37.cmml" xref="A1.E5.m1.60.60.60.38.37.37">𝑐</ci><cn id="A1.E5.m1.61.61.61.39.38.38.1.cmml" type="integer" xref="A1.E5.m1.61.61.61.39.38.38.1">3</cn></apply><apply id="A1.E5.m1.79.79.1.1.1.4.3.4.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.4.3.4.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">subscript</csymbol><ci id="A1.E5.m1.62.62.62.40.39.39.cmml" xref="A1.E5.m1.62.62.62.40.39.39">𝔼</ci><apply id="A1.E5.m1.63.63.63.41.40.40.1.cmml" xref="A1.E5.m1.63.63.63.41.40.40.1"><csymbol cd="ambiguous" id="A1.E5.m1.63.63.63.41.40.40.1.1.cmml" xref="A1.E5.m1.63.63.63.41.40.40.1">superscript</csymbol><ci id="A1.E5.m1.63.63.63.41.40.40.1.2.cmml" xref="A1.E5.m1.63.63.63.41.40.40.1.2">𝒟</ci><ci id="A1.E5.m1.63.63.63.41.40.40.1.3.cmml" xref="A1.E5.m1.63.63.63.41.40.40.1.3">𝜋</ci></apply></apply><apply id="A1.E5.m1.79.79.1.1.1.4.3.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="latexml" id="A1.E5.m1.79.79.1.1.1.4.3.1.2.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">delimited-[]</csymbol><apply id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><minus id="A1.E5.m1.70.70.70.48.47.47.cmml" xref="A1.E5.m1.70.70.70.48.47.47"></minus><apply id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><ci id="A1.E5.m1.65.65.65.43.42.42.cmml" xref="A1.E5.m1.65.65.65.43.42.42">ℎ</ci><apply id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.1.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.1.1.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">superscript</csymbol><ci id="A1.E5.m1.67.67.67.45.44.44.cmml" xref="A1.E5.m1.67.67.67.45.44.44">𝑠</ci><ci id="A1.E5.m1.68.68.68.46.45.45.1.cmml" xref="A1.E5.m1.68.68.68.46.45.45.1">′</ci></apply></apply><apply id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><times id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.2.2.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"></times><apply id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.2.3.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.2.3.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">superscript</csymbol><apply id="A1.E5.m1.71.71.71.49.48.48.cmml" xref="A1.E5.m1.71.71.71.49.48.48"><ci id="A1.E5.m1.71.71.71.49.48.48.1.cmml" xref="A1.E5.m1.71.71.71.49.48.48.1">~</ci><ci id="A1.E5.m1.71.71.71.49.48.48.2.cmml" xref="A1.E5.m1.71.71.71.49.48.48.2">𝑉</ci></apply><times id="A1.E5.m1.72.72.72.50.49.49.1.cmml" xref="A1.E5.m1.72.72.72.50.49.49.1"></times></apply><apply id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.2.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1"><csymbol cd="ambiguous" id="A1.E5.m1.79.79.1.1.1.4.3.1.1.1.2.1.1.1.1.cmml" xref="A1.E5.m1.7.7.7.7.7.8.1">superscript</csymbol><ci id="A1.E5.m1.74.74.74.52.51.51.cmml" xref="A1.E5.m1.74.74.74.52.51.51">𝑠</ci><ci id="A1.E5.m1.75.75.75.53.52.52.1.cmml" xref="A1.E5.m1.75.75.75.53.52.52.1">′</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E5.m1.81c">\begin{split}\mathcal{L}(\pi,h)=&amp;\mathbb{E}_{\mathcal{D}_{0}}[V^{*}(s)-V^{\pi}%
(s)]\\
=&amp;c_{1}\color[rgb]{0,0.5,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.5,1}%
\pgfsys@color@cmyk@stroke{1}{0.50}{0}{0}\pgfsys@color@cmyk@fill{1}{0.50}{0}{0}%
\mathbb{E}_{\mathcal{D}_{0}}\bigg{[}\tilde{V}^{*}(s)-\tilde{V}^{\pi}(s)\bigg{]%
}\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}%
\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0}+c_{2}\color[rgb]{%
0,0.88,0}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.88,0}%
\pgfsys@color@cmyk@stroke{0.91}{0}{0.88}{0.12}\pgfsys@color@cmyk@fill{0.91}{0}%
{0.88}{0.12}\mathbb{E}_{\mathcal{D}^{\pi}}\bigg{[}\tilde{V}^{*}(s)-\tilde{V}^{%
\pi}(s)\bigg{]}\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0}+c_{3}\color[rgb]{%
1,0.04,0.61}\definecolor[named]{pgfstrokecolor}{rgb}{1,0.04,0.61}%
\pgfsys@color@cmyk@stroke{0}{0.96}{0.39}{0}\pgfsys@color@cmyk@fill{0}{0.96}{0.%
39}{0}\mathbb{E}_{\mathcal{D}^{\pi}}\bigg{[}h(s^{\prime})-\tilde{V}^{*}(s^{%
\prime})\bigg{]}\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0},\end{split}</annotation><annotation encoding="application/x-llamapun" id="A1.E5.m1.81d">start_ROW start_CELL caligraphic_L ( italic_π , italic_h ) = end_CELL start_CELL blackboard_E start_POSTSUBSCRIPT caligraphic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_V start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_s ) - italic_V start_POSTSUPERSCRIPT italic_π end_POSTSUPERSCRIPT ( italic_s ) ] end_CELL end_ROW start_ROW start_CELL = end_CELL start_CELL italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT caligraphic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ over~ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_s ) - over~ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT italic_π end_POSTSUPERSCRIPT ( italic_s ) ] + italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT caligraphic_D start_POSTSUPERSCRIPT italic_π end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ over~ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_s ) - over~ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT italic_π end_POSTSUPERSCRIPT ( italic_s ) ] + italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT caligraphic_D start_POSTSUPERSCRIPT italic_π end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_h ( italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) - over~ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ( italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ] , end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A1.SS7.p3.7"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.1">where </span><math alttext="c_{1},c_{2},c_{3}" class="ltx_Math" display="inline" id="A1.SS7.p3.1.m1.3"><semantics id="A1.SS7.p3.1.m1.3a"><mrow id="A1.SS7.p3.1.m1.3.3.3" xref="A1.SS7.p3.1.m1.3.3.4.cmml"><msub id="A1.SS7.p3.1.m1.1.1.1.1" xref="A1.SS7.p3.1.m1.1.1.1.1.cmml"><mi id="A1.SS7.p3.1.m1.1.1.1.1.2" xref="A1.SS7.p3.1.m1.1.1.1.1.2.cmml">c</mi><mn id="A1.SS7.p3.1.m1.1.1.1.1.3" xref="A1.SS7.p3.1.m1.1.1.1.1.3.cmml">1</mn></msub><mo id="A1.SS7.p3.1.m1.3.3.3.4" xref="A1.SS7.p3.1.m1.3.3.4.cmml">,</mo><msub id="A1.SS7.p3.1.m1.2.2.2.2" xref="A1.SS7.p3.1.m1.2.2.2.2.cmml"><mi id="A1.SS7.p3.1.m1.2.2.2.2.2" xref="A1.SS7.p3.1.m1.2.2.2.2.2.cmml">c</mi><mn id="A1.SS7.p3.1.m1.2.2.2.2.3" xref="A1.SS7.p3.1.m1.2.2.2.2.3.cmml">2</mn></msub><mo id="A1.SS7.p3.1.m1.3.3.3.5" xref="A1.SS7.p3.1.m1.3.3.4.cmml">,</mo><msub id="A1.SS7.p3.1.m1.3.3.3.3" xref="A1.SS7.p3.1.m1.3.3.3.3.cmml"><mi id="A1.SS7.p3.1.m1.3.3.3.3.2" xref="A1.SS7.p3.1.m1.3.3.3.3.2.cmml">c</mi><mn id="A1.SS7.p3.1.m1.3.3.3.3.3" xref="A1.SS7.p3.1.m1.3.3.3.3.3.cmml">3</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS7.p3.1.m1.3b"><list id="A1.SS7.p3.1.m1.3.3.4.cmml" xref="A1.SS7.p3.1.m1.3.3.3"><apply id="A1.SS7.p3.1.m1.1.1.1.1.cmml" xref="A1.SS7.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS7.p3.1.m1.1.1.1.1.1.cmml" xref="A1.SS7.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="A1.SS7.p3.1.m1.1.1.1.1.2.cmml" xref="A1.SS7.p3.1.m1.1.1.1.1.2">𝑐</ci><cn id="A1.SS7.p3.1.m1.1.1.1.1.3.cmml" type="integer" xref="A1.SS7.p3.1.m1.1.1.1.1.3">1</cn></apply><apply id="A1.SS7.p3.1.m1.2.2.2.2.cmml" xref="A1.SS7.p3.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS7.p3.1.m1.2.2.2.2.1.cmml" xref="A1.SS7.p3.1.m1.2.2.2.2">subscript</csymbol><ci id="A1.SS7.p3.1.m1.2.2.2.2.2.cmml" xref="A1.SS7.p3.1.m1.2.2.2.2.2">𝑐</ci><cn id="A1.SS7.p3.1.m1.2.2.2.2.3.cmml" type="integer" xref="A1.SS7.p3.1.m1.2.2.2.2.3">2</cn></apply><apply id="A1.SS7.p3.1.m1.3.3.3.3.cmml" xref="A1.SS7.p3.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="A1.SS7.p3.1.m1.3.3.3.3.1.cmml" xref="A1.SS7.p3.1.m1.3.3.3.3">subscript</csymbol><ci id="A1.SS7.p3.1.m1.3.3.3.3.2.cmml" xref="A1.SS7.p3.1.m1.3.3.3.3.2">𝑐</ci><cn id="A1.SS7.p3.1.m1.3.3.3.3.3.cmml" type="integer" xref="A1.SS7.p3.1.m1.3.3.3.3.3">3</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p3.1.m1.3c">c_{1},c_{2},c_{3}</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p3.1.m1.3d">italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.2"> are non-negative constants. Minimizing </span><math alttext="\mathcal{L}(\pi,h)" class="ltx_Math" display="inline" id="A1.SS7.p3.2.m2.2"><semantics id="A1.SS7.p3.2.m2.2a"><mrow id="A1.SS7.p3.2.m2.2.3" xref="A1.SS7.p3.2.m2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS7.p3.2.m2.2.3.2" xref="A1.SS7.p3.2.m2.2.3.2.cmml">ℒ</mi><mo id="A1.SS7.p3.2.m2.2.3.1" xref="A1.SS7.p3.2.m2.2.3.1.cmml">⁢</mo><mrow id="A1.SS7.p3.2.m2.2.3.3.2" xref="A1.SS7.p3.2.m2.2.3.3.1.cmml"><mo id="A1.SS7.p3.2.m2.2.3.3.2.1" stretchy="false" xref="A1.SS7.p3.2.m2.2.3.3.1.cmml">(</mo><mi id="A1.SS7.p3.2.m2.1.1" xref="A1.SS7.p3.2.m2.1.1.cmml">π</mi><mo id="A1.SS7.p3.2.m2.2.3.3.2.2" xref="A1.SS7.p3.2.m2.2.3.3.1.cmml">,</mo><mi id="A1.SS7.p3.2.m2.2.2" xref="A1.SS7.p3.2.m2.2.2.cmml">h</mi><mo id="A1.SS7.p3.2.m2.2.3.3.2.3" stretchy="false" xref="A1.SS7.p3.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS7.p3.2.m2.2b"><apply id="A1.SS7.p3.2.m2.2.3.cmml" xref="A1.SS7.p3.2.m2.2.3"><times id="A1.SS7.p3.2.m2.2.3.1.cmml" xref="A1.SS7.p3.2.m2.2.3.1"></times><ci id="A1.SS7.p3.2.m2.2.3.2.cmml" xref="A1.SS7.p3.2.m2.2.3.2">ℒ</ci><interval closure="open" id="A1.SS7.p3.2.m2.2.3.3.1.cmml" xref="A1.SS7.p3.2.m2.2.3.3.2"><ci id="A1.SS7.p3.2.m2.1.1.cmml" xref="A1.SS7.p3.2.m2.1.1">𝜋</ci><ci id="A1.SS7.p3.2.m2.2.2.cmml" xref="A1.SS7.p3.2.m2.2.2">ℎ</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p3.2.m2.2c">\mathcal{L}(\pi,h)</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p3.2.m2.2d">caligraphic_L ( italic_π , italic_h )</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.3"> with respect to </span><math alttext="\pi" class="ltx_Math" display="inline" id="A1.SS7.p3.3.m3.1"><semantics id="A1.SS7.p3.3.m3.1a"><mi id="A1.SS7.p3.3.m3.1.1" xref="A1.SS7.p3.3.m3.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p3.3.m3.1b"><ci id="A1.SS7.p3.3.m3.1.1.cmml" xref="A1.SS7.p3.3.m3.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p3.3.m3.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p3.3.m3.1d">italic_π</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.4"> and </span><math alttext="h" class="ltx_Math" display="inline" id="A1.SS7.p3.4.m4.1"><semantics id="A1.SS7.p3.4.m4.1a"><mi id="A1.SS7.p3.4.m4.1.1" xref="A1.SS7.p3.4.m4.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p3.4.m4.1b"><ci id="A1.SS7.p3.4.m4.1.1.cmml" xref="A1.SS7.p3.4.m4.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p3.4.m4.1c">h</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p3.4.m4.1d">italic_h</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.5"> can be achieved by minimizing each individual term. In particular, the red term suggests that the heuristic </span><math alttext="h" class="ltx_Math" display="inline" id="A1.SS7.p3.5.m5.1"><semantics id="A1.SS7.p3.5.m5.1a"><mi id="A1.SS7.p3.5.m5.1.1" xref="A1.SS7.p3.5.m5.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p3.5.m5.1b"><ci id="A1.SS7.p3.5.m5.1.1.cmml" xref="A1.SS7.p3.5.m5.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p3.5.m5.1c">h</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p3.5.m5.1d">italic_h</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.6"> has to be updated on data from </span><math alttext="\mathcal{D}^{\pi}" class="ltx_Math" display="inline" id="A1.SS7.p3.6.m6.1"><semantics id="A1.SS7.p3.6.m6.1a"><msup id="A1.SS7.p3.6.m6.1.1" xref="A1.SS7.p3.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.SS7.p3.6.m6.1.1.2" xref="A1.SS7.p3.6.m6.1.1.2.cmml">𝒟</mi><mi id="A1.SS7.p3.6.m6.1.1.3" xref="A1.SS7.p3.6.m6.1.1.3.cmml">π</mi></msup><annotation-xml encoding="MathML-Content" id="A1.SS7.p3.6.m6.1b"><apply id="A1.SS7.p3.6.m6.1.1.cmml" xref="A1.SS7.p3.6.m6.1.1"><csymbol cd="ambiguous" id="A1.SS7.p3.6.m6.1.1.1.cmml" xref="A1.SS7.p3.6.m6.1.1">superscript</csymbol><ci id="A1.SS7.p3.6.m6.1.1.2.cmml" xref="A1.SS7.p3.6.m6.1.1.2">𝒟</ci><ci id="A1.SS7.p3.6.m6.1.1.3.cmml" xref="A1.SS7.p3.6.m6.1.1.3">𝜋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p3.6.m6.1c">\mathcal{D}^{\pi}</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p3.6.m6.1d">caligraphic_D start_POSTSUPERSCRIPT italic_π end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.7"> in order to not become "stale". This points out a shortcoming of existing LLM-as-critic algorithms, which sometimes fix </span><math alttext="h" class="ltx_Math" display="inline" id="A1.SS7.p3.7.m7.1"><semantics id="A1.SS7.p3.7.m7.1a"><mi id="A1.SS7.p3.7.m7.1.1" xref="A1.SS7.p3.7.m7.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p3.7.m7.1b"><ci id="A1.SS7.p3.7.m7.1.1.cmml" xref="A1.SS7.p3.7.m7.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p3.7.m7.1c">h</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p3.7.m7.1d">italic_h</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.8"> after distilling the language model knowledge into it </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_sansserif ltx_font_bold">Klissarov et al.</span> <span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.9.1.1.1">(</span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib23" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.10.2.2.1">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p3.7.11"></span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS7.p4">
<p class="ltx_p" id="A1.SS7.p4.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p4.1.1">These theoretical findings suggest, in particular, that heuristic </span><math alttext="h" class="ltx_Math" display="inline" id="A1.SS7.p4.1.m1.1"><semantics id="A1.SS7.p4.1.m1.1a"><mi id="A1.SS7.p4.1.m1.1.1" xref="A1.SS7.p4.1.m1.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="A1.SS7.p4.1.m1.1b"><ci id="A1.SS7.p4.1.m1.1.1.cmml" xref="A1.SS7.p4.1.m1.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS7.p4.1.m1.1c">h</annotation><annotation encoding="application/x-llamapun" id="A1.SS7.p4.1.m1.1d">italic_h</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p4.1.2"> (in our case, the Bradley-Terry preference model), has to be updated with on-policy samples, similarly to empirical results from </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S4.F5" title="In 4.2 Exploration ‣ 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS7.p4.1.3">.</span></p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS8">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.SS8.1.1.1">A.8</span> </span>Additional Considerations for Preference-based Reward Modeling</h3>
<div class="ltx_para" id="A1.SS8.p1">
<p class="ltx_p" id="A1.SS8.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS8.p1.1.1">In Figure </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.F9" title="Figure 9 ‣ A.8 Additional Considerations for Preference-based Reward Modeling ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">9</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS8.p1.1.2">, we present the properties that were important to obtain effective exploration on NetHack, without the counting term shown in Equation </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S4.E4" title="Equation 4 ‣ 4.2 Exploration ‣ 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS8.p1.1.3">.</span></p>
</div>
<figure class="ltx_figure" id="A1.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="294" id="A1.F9.g1" src="x13.png" width="706"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.F9.3.1.1">Figure 9</span>: </span>Successful exploration on Nethack depends on both online preference elicitation and a non-Markovian reward function.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS9">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.SS9.1.1.1">A.9</span> </span>In-Context Learning for Reward Modeling</h3>
<div class="ltx_para ltx_noindent" id="A1.SS9.p1">
<p class="ltx_p" id="A1.SS9.p1.2"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS9.p1.2.1">In Figure </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.F10" title="Figure 10 ‣ A.9 In-Context Learning for Reward Modeling ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">10</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS9.p1.2.2">, we present a variation on the Wordle game where the color code has been altered, which we refer to as Eldrow (reverse Wordle). Under this transformation, the off-the-shelf model provides feedback that correlates very poorly with the optimal value function. When we measure the perplexity of the LLM on a natural language description of the new rule set of Eldrow (see Appendix </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1" title="Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">A</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS9.p1.2.3">) we obtain a value of </span><math alttext="6.97" class="ltx_Math" display="inline" id="A1.SS9.p1.1.m1.1"><semantics id="A1.SS9.p1.1.m1.1a"><mn id="A1.SS9.p1.1.m1.1.1" xref="A1.SS9.p1.1.m1.1.1.cmml">6.97</mn><annotation-xml encoding="MathML-Content" id="A1.SS9.p1.1.m1.1b"><cn id="A1.SS9.p1.1.m1.1.1.cmml" type="float" xref="A1.SS9.p1.1.m1.1.1">6.97</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS9.p1.1.m1.1c">6.97</annotation><annotation encoding="application/x-llamapun" id="A1.SS9.p1.1.m1.1d">6.97</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS9.p1.2.4"> which is higher than the one measured on the standard rule set of Wordle, with a value of </span><math alttext="5.06" class="ltx_Math" display="inline" id="A1.SS9.p1.2.m2.1"><semantics id="A1.SS9.p1.2.m2.1a"><mn id="A1.SS9.p1.2.m2.1.1" xref="A1.SS9.p1.2.m2.1.1.cmml">5.06</mn><annotation-xml encoding="MathML-Content" id="A1.SS9.p1.2.m2.1b"><cn id="A1.SS9.p1.2.m2.1.1.cmml" type="float" xref="A1.SS9.p1.2.m2.1.1">5.06</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS9.p1.2.m2.1c">5.06</annotation><annotation encoding="application/x-llamapun" id="A1.SS9.p1.2.m2.1d">5.06</annotation></semantics></math><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS9.p1.2.5">. Given that the difference in values is not very large, we leverage the simplest way for adapting the LLM: through in-context learning. As shown in Figure </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.F10.sf2" title="Figure 10(b) ‣ Figure 10 ‣ A.9 In-Context Learning for Reward Modeling ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">10(b)</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS9.p1.2.6">, by providing hints in the prompt about the new rule set, the LLM adapts its preferences and generates a Bradley-Terry model that recovers the correlation values we witnessed in </span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#S4.F4" title="Figure 4 ‣ Qualitative experiment ‣ 4.1 Credit Assignment ‣ 4 Analysis of AI Feedback for RL ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS9.p1.2.7">.</span></p>
</div>
<figure class="ltx_figure" id="A1.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A1.F10.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="623" id="A1.F10.sf1.g1" src="x14.png" width="830"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.F10.sf1.3.1.1">(a)</span> </span>Before in-context learning</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A1.F10.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="623" id="A1.F10.sf2.g1" src="x15.png" width="830"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.F10.sf2.3.1.1">(b)</span> </span>After in-context learning</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.F10.3.1.1">Figure 10</span>: </span>AI feedback can be adapted to novel settings through in-context learning. While the original LLM does poorly on Eldrow due to out-of-distribution, it manages to correct its feedback the task using in-context hints.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS10">
<h3 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.SS10.1.1.1">A.10</span> </span>LLMs as novelty detectors</h3>
<div class="ltx_para ltx_noindent" id="A1.SS10.p1">
<p class="ltx_p" id="A1.SS10.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS10.p1.1.1">We hypothesize that LLMs with long contexts can effectively act as novelty detectors. Within the scope of RL problems, this implies the ability to tell, for example, whether a sub-trajectory is contained in the replay buffer.</span></p>
</div>
<div class="ltx_para" id="A1.SS10.p2">
<p class="ltx_p" id="A1.SS10.p2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS10.p2.1.1">To test this, we query </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS10.p2.1.2">Gemini-1.5 Pro</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS10.p2.1.3"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS10.p2.1.4.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Team et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS10.p2.1.5.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib54" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS10.p2.1.6.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS10.p2.1.7"> with a context video containing 500 frames of an agent exploring the bottom-left room (</span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.F11" title="In A.10 LLMs as novelty detectors ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">11</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS10.p2.1.8">-left) and a single frame sampled uniformly at random from a query episode which covers in the top-right room, center and bottom of the maze (</span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.F11" title="In A.10 LLMs as novelty detectors ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">11</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS10.p2.1.9">-middle). We ask the LLM to identify novel query states, i.e. states which are not seen in the context episode. We then train a direct predictor (3-layer MLP) to estimate the probability of any state on the grid to be novel with respect to the context (</span><a class="ltx_ref ltx_font_sansserif ltx_font_bold" href="https://arxiv.org/html/2410.05656v1#A1.F11" title="In A.10 LLMs as novelty detectors ‣ Appendix A Appendix ‣ On the Modeling Capabilities of Large Language Models for Sequential Decision Making"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">11</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.SS10.p2.1.10">-right). The language model correctly identifies the top-right portion of the trajectory to be novel, knowledge which could then be used to construct an intrinsic reward function.</span></p>
</div>
<figure class="ltx_figure" id="A1.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="160" id="A1.F11.g1" src="extracted/5905056/figures/exploration_minigrid.png" width="503"/>
<figcaption class="ltx_caption ltx_centering ltx_font_sansserif ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A1.F11.3.1.1">Figure 11</span>: </span>LLMs can capture observation novelty. Given the context trajectory (red), and a single observation sampled uniformly at random from the query trajectory (blue), the LLM correctly identifies novel states that are seen in the query but not in the context (green).</figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix"><span class="ltx_text ltx_font_serif ltx_font_medium" id="A2.1.1.1">Appendix B</span> </span>Additional Related Works</h2>
<div class="ltx_para ltx_noindent" id="A2.p1">
<p class="ltx_p" id="A2.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.1">Large language models (LLMs) require additional adaptation for general-use language tasks </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Christiano et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib11" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2017</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Stiennon et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib49" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2020</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Ouyang et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib38" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Mialon et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib36" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.5">.
Without additional context and/or fine-tuning, LLMs can generate misleading, harmful, or even nonsensical answers to queries or conversations with humans </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.6.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Bai et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.7.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib2" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.8.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.p1.1.9">.
To modify their behavior, it is necessary to tune their prompts and/or fine-tune their outputs to ensure their output is desirable w.r.t. some set of linguistic tasks before deployment.
This at least if not more true in embodied settings, where real-world actions can have physical consequences, and methodologies for modifying LLM behavior in embodied settings more-or-less align with efforts in the language space.</span></p>
</div>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_font_sansserif ltx_font_bold ltx_title_paragraph">Prompt tuning</h4>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px1.p1.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.1">Arguably the most common theme among techniques that modify LLM behavior in general is to change the prompt such that the distribution of LLM outputs better-fits a given desiderata on behavior.
Prompt-engineering can greatly align or calibrate an LLM, pretrained or no, to desired beneficial behavior </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Christiano et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib11" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2017</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Glaese et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib15" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Bai et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib2" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.5">, or even expose harmful or other unexpected behaviors.
Chain-of-thought </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.6.1">(CoT,  </span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Wei et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.7.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib61" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.8.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.9"> is an in-context method to either few-shot or zero-shot </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.10.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Kojima et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.11.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib25" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.12.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.13"> adjust an LLM’s outputs to generate more correct responses to question-and-answering tasks.
Further modifications to the prompt such as providing feedback from an environment </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.14.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Yao et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.15.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib63" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.16.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.17">, self-critique </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.18.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Zelikman et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.19.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib68" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.20.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.21">, or self-reflection </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.22.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Shinn et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.23.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib46" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.24.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.25"> can improve LLM performance in language as well as tasks that have an environment.
The biggest promise of in-context-based methods in RL is that somewhere within the large language model’s conditional distribution is the optimal policy for any given task </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.26.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Brohan et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.27.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib6" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Szot et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.27.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib52" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.28.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.29">, an accurate world-explicit model </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.30.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Lin et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.31.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib29" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.32.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.33">, and/or a useful reward-model </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.34.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Klissarov et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.35.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib23" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.36.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.37">.
However, it is at best speculative as LLM’s are black box systems and prompt optimization is extremely difficult, and besides: systems built on this idea still must still overcome affordance mismatch </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.38.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Ahn et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.39.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib1" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.40.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.41"> and hallucinations </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.42.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Zhang et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.43.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib69" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024a</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.44.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p1.1.45"> to be useful for RL.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="A2.SS0.SSS0.Px1.p2.1"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.1">Querying model for feedback Another hypothesis is that LLMs contain knowledge relevant to tasks, and this knowledge can be extracted </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.2.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Xu et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.3.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib62" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.4.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.5"> in a way to train a policy that has desirable behavior </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.6.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Huang et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.7.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib17" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.8.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.9">.
RL AI Feedback </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.10.1">(RLAIF </span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Bai et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.11.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib2" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2022</span></a>; <span class="ltx_text ltx_font_sansserif ltx_font_bold">Lee et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.11.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib27" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2023</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.12.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.13"> is a scalable method akin to but without the practical issues that come paired with RL from Human Feedback </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.14.1">(RLHF </span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Christiano et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.15.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib11" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2017</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.16.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.17">, the goal of which is to fine-tune an existing LLM to be more specific, accurate, innocuous, etc.
RLAIF trains a reward model on a dataset collected from an LLM’s preferences given a dataset of language responses from an LLM and a given set of queries, and this reward model is used to train a policy using RL, for example using PPO.
This process of extracting knowledge using preference data can also be directly used to train a policy without a reward model </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.18.1">(</span><span class="ltx_text ltx_font_sansserif ltx_font_bold">Rafailov et al.</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.19.2.1.1">, </span><a class="ltx_ref" href="https://arxiv.org/html/2410.05656v1#bib.bib42" title=""><span class="ltx_text ltx_font_sansserif ltx_font_bold">2024</span></a><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.20.3">)</span></cite><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A2.SS0.SSS0.Px1.p2.1.21">.</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct  8 03:11:51 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
