<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1904.12577] Table understanding in structured documents</title><meta property="og:description" content="Table detection and extraction has been studied in the context of
documents like reports, where tables are clearly outlined and stand
out from the document structure visually. We study this topic in a
rather more chall…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Table understanding in structured documents">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Table understanding in structured documents">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1904.12577">

<!--Generated on Sat Mar  2 17:21:08 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
table detection; neural networks; invoices; graph convolution; attention
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Table understanding in structured documents</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Second author
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Left out for double blind review
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Third authorFourth author
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Left out for double blind review
</span>
<span class="ltx_contact ltx_role_affiliation">Left out for double blind review
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Table detection and extraction has been studied in the context of
documents like reports, where tables are clearly outlined and stand
out from the document structure visually. We study this topic in a
rather more challenging domain of layout-heavy business documents,
particularly invoices. Invoices present the novel challenges of tables
being often without outlines - either in the form of borders or surrounding
text flow - with ragged columns and widely varying data content. We
will also show, that we can extract specific information from structurally
different tables or table-like structures with one model. We present
a comprehensive representation of a page using graph over word boxes,
positional embeddings, trainable textual features and rephrase the
table detection as a text box labeling problem. We will work on our
newly presented dataset of pro forma invoices, invoices and debit
note documents using this representation and propose multiple baselines
to solve this labeling problem. We then propose a novel neural network
model that achieves strong, practical results on the presented dataset
and analyze the model performance and effects of graph convolutions
and self-attention in detail.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
table detection; neural networks; invoices; graph convolution; attention

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Table detection and table extraction problems were already introduced
in a competition ICDAR 2013, where the goal was to detect tables and
extract cell structures from a dataset of mostly scientific documents
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Table can be defined as a set of content cells
organized in a self-describing manner into such a structure, that
groups cells into rows and columns. This was reflected in the metric
defined in the competition, that scores tables based on the relations
successfully extracted. Similarly, structured documents do have a
self-describing structure, that often looks table-like.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">We have decided to investigate the problem on business documents such
as invoices, pro forma invoices and debit notes (referred for simplicity
as invoices or invoice-type documents later in this text), where the
aim is different. Namely - even table detection needs to be thought
of in the context of document understanding, because invoices are
inherently documents with textual information structured into more
tables. Graphical borders and edges are sometimes present, however,
they cannot be used for detection, because there is no general layout
and very often there are no borders at all. Another obstacle for traditional
methods is the fact, that the data can span over multiple lines of
text which holds true also for the table cells.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Moreover, we require our model to ’understand’ the document in a way
that it could classify tables and tabular structures based on their
content. In practice the goal is to detect the whole table with the
so-called ’line-items’ (detailed items of the total amount to pay)
and, at the same time, extract only a specific information from the
other tables (to find a ’field’). Simply said, not every table inside
an invoice should be detected and reported as whole (see example invoice
on figure <a href="#S3.F1" title="Figure 1 ‣ III-C Our approach ‣ III Methodology ‣ Table understanding in structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). Usually in commercial
applications this problem is tackled using a layout system that detects
the layout and extracts the table (or a field) from a position where
it usually happens to be; or employing another classification module,
which selects the right table from several proposals. That increases
the number of modules in the architecture and requires manual layout
setups, while our goal is to have a trainable system that could leverage
the commonalities present in the data without ongoing human support.
To verify that, we will ensure that proper generalization of models
predictions is evaluated on new layouts.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Previous Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The plethora of methods that have been previously used for the task
is hard to summarize or compare since all the algorithms have been
used/evaluated on different datasets and each have their strengths,
weak spots and quirks. However, we found none of them well suited
for working with structured documents (like invoices), since they
in general have no fixed layout, language, captions, delimiters, fonts…
For example, invoices vary in countries, companies and departments
and changes in time. In order to retrieve any information from a structured
document, you need to understand it.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">In literature there are examples of table detection using heuristics
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, using layouts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>,
regular expressions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, or leveraging the presence
of lines in tables <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>,
or using clustering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. A great survey can be
found in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Tables were searched for also in HTML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>,
free text <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> or scientific articles
with a method based on matching captions with content <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Machine learning methods and deep neural networks were also employed
in several papers. The work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> aims at scientific
documents using fine tailored methods stacked atop each other. Reference
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> uses Fast R-CNN architecture with a novel idea
of Euclidean distance feature to detect tables (which was compared
to Tesseract). Reference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> also uses (pretrained) Fast
R-CNN and FCN semantic segmentation model for table extraction problem.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> work has been done on detection problem
bottom up using the Hough transform, and extraction was solved with
Markov networks and features from the cell positions. Reference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>
uses convolutions over the number (and sizes) of spaces in a line.
A deep CNN approach was being investigated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>,
which combined CNNs for detecting row and columns, dilated convolutions,
CRFs and saliency maps, they have also developed a webcrawler to extend
their dataset. We tried and failed to get working results using the
YOLO architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> with textual datasets. (We have experimented
with YOLO because some works aimed at table detection do use the family
of R-CNNs, Fast R-CNNs and Mask R-CNNs, that preceded the development
of YOLO.)</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">For document understanding, a graph representation of a document was
examined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, finding similar documents
and reusing their goldstandards was done in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Methodology</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We would like to define our target as creating a model for tabular
or structured data understanding with relevant information detection
and classification. The basic unit of information will be a word in
a document’s page with its placement and possibly other features such
as style (see PDF format text data organization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>
for example). In this text, we will be calling them simply as <em id="S3.p1.1.1" class="ltx_emph ltx_font_italic">wordboxes</em>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">With table understanding we mean a joint task of line-item table detection
and information extraction from other tables. The information to be
extracted is defined by the document use-case or semantics, for line-item
table it is the whole table (’table detection’ task as defined in
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>), while for other structures it is just a specific
infomation (’information extraction’ task). No other constraints apply,
i.e. the data can span over multiple lines. So the model is required
to understand a type of table internally and we hope, that the two
tasks will boost the learning process for each other.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">With line-item table detection method, we will understand a model,
that could classify each wordbox in a document as being a part of
a line-item content or not (which basically identifies the table itself,
because all line-items tables happen to be well separated, so no instance
segmentation is needed). Same classification approach will be used
for other classes representing other types of content. The classes
are acquired from expert annotations and, as it turns out, we are
dealing with a multilabel problem, i.e. 35 classes in total, examples
being the total amount or recipient address. Also, not every document
contains instances of every class.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Metrics and evaluation</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We will observe the scores at validation and test splits, the test
being composed not only of different data, but also of different layouts
and invoice types, thus allowing us to observe the system scalability.
The scores are:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.2" class="ltx_p"><math id="S3.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S3.I1.i1.p1.1.m1.1a"><msub id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml"><mi id="S3.I1.i1.p1.1.m1.1.1.2" xref="S3.I1.i1.p1.1.m1.1.1.2.cmml">F</mi><mn id="S3.I1.i1.p1.1.m1.1.1.3" xref="S3.I1.i1.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><apply id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.1.m1.1.1.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S3.I1.i1.p1.1.m1.1.1.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">F_{1}</annotation></semantics></math> scores on line-item wordbox classification averaged from
both positive classes and negative classes. 
<br class="ltx_break">At <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> a content oriented metric was defined for
table detection on character level - each character being either in
the table or out of the table. For us the basic unit is a wordbox,
hence we will define our metric similarily to be the <math id="S3.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S3.I1.i1.p1.2.m2.1a"><msub id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml"><mi id="S3.I1.i1.p1.2.m2.1.1.2" xref="S3.I1.i1.p1.2.m2.1.1.2.cmml">F</mi><mn id="S3.I1.i1.p1.2.m2.1.1.3" xref="S3.I1.i1.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.1b"><apply id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.2.m2.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.2.m2.1.1.2.cmml" xref="S3.I1.i1.p1.2.m2.1.1.2">𝐹</ci><cn type="integer" id="S3.I1.i1.p1.2.m2.1.1.3.cmml" xref="S3.I1.i1.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.1c">F_{1}</annotation></semantics></math> score
of table body wordbox class classification.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.2" class="ltx_p">For other classes we will be looking at micro <math id="S3.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S3.I1.i2.p1.1.m1.1a"><msub id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.2" xref="S3.I1.i2.p1.1.m1.1.1.2.cmml">F</mi><mn id="S3.I1.i2.p1.1.m1.1.1.3" xref="S3.I1.i2.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I1.i2.p1.1.m1.1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S3.I1.i2.p1.1.m1.1.1.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">F_{1}</annotation></semantics></math> scores (only
from positive classes, because the counts of positive samples are
outnumbered by the negative samples - in total, the dataset contains
<math id="S3.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="1.2\,\%" display="inline"><semantics id="S3.I1.i2.p1.2.m2.1a"><mrow id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml"><mn id="S3.I1.i2.p1.2.m2.1.1.2" xref="S3.I1.i2.p1.2.m2.1.1.2.cmml">1.2</mn><mo lspace="0.170em" id="S3.I1.i2.p1.2.m2.1.1.1" xref="S3.I1.i2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><apply id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1"><csymbol cd="latexml" id="S3.I1.i2.p1.2.m2.1.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S3.I1.i2.p1.2.m2.1.1.2.cmml" xref="S3.I1.i2.p1.2.m2.1.1.2">1.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">1.2\,\%</annotation></semantics></math> positive classes).</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">We chose micro metric aggregation rule, because it gives higher importance
to bigger documents (in the number of wordboxes) which we consider
being more difficult for both human and machine.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">We present our research as a novel approach, because referenced papers
or commercial solutions cannot be customized to fit our aim. So we
will compare only against baseline logistic regression over the model
features.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">The data and their acquisition process</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">The data were acquired as a result of work of annotation and review
teams together with automated preprocessing and error-finding algorithms,
that reported errors in nearly <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="3\,\%" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mn id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">3</mn><mo lspace="0.170em" id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">3\,\%</annotation></semantics></math> of the annotation labels.
Classes were annotated in our annotation apps by drawing a rectangle
over the area with the target text. Manual inspection has revealed,
that the annotations can erroneously overlap portions of neighbouring
words, so for ground truth generation we have decided to select only
the wordboxes that are being overlapped by the annotation rectangle
by more than <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="20\,\%" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mn id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">20</mn><mo lspace="0.170em" id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="latexml" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">20\,\%</annotation></semantics></math> of their area.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Datasets</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.4" class="ltx_p">We have a dataset with <math id="S3.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="3554" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a"><mn id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">3554</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">3554</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">3554</annotation></semantics></math> PDF invoice files consisting of <math id="S3.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="4848" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a"><mn id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">4848</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b"><cn type="integer" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1">4848</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">4848</annotation></semantics></math>
pages in total. The documents are of various vendors, layouts and
languages, annotated with line-item table header and table body together
with other structural information. And we also have a bigger dataset
of <math id="S3.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="25071" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.3.m3.1a"><mn id="S3.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">25071</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.3.m3.1b"><cn type="integer" id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1">25071</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.3.m3.1c">25071</annotation></semantics></math> PDF files of <math id="S3.SS2.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="35880" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.4.m4.1a"><mn id="S3.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml">35880</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.4.m4.1b"><cn type="integer" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1">35880</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.4.m4.1c">35880</annotation></semantics></math> pages with just structural information
without line-items (datasets are noted as ’small’ and ’big’ in the
results).</p>
</div>
<div id="S3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p2.1" class="ltx_p">The documents are standard PDF files, not scanned documents or documents
captured by a digital camera. This decision will not impact the robustness
of our model - given a process to extract bounding boxes and text,
we can use our method in a straightforward manner.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p3.1" class="ltx_p">Validation split is chosen to be 1/4 the size. The validation set
measures adaptation, because it could contain similar invoice types
from similar vendors. So in addition, we have created another testing
set of <math id="S3.SS2.SSS0.Px1.p3.1.m1.1" class="ltx_Math" alttext="83" display="inline"><semantics id="S3.SS2.SSS0.Px1.p3.1.m1.1a"><mn id="S3.SS2.SSS0.Px1.p3.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p3.1.m1.1.1.cmml">83</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p3.1.m1.1b"><cn type="integer" id="S3.SS2.SSS0.Px1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.1.1">83</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p3.1.m1.1c">83</annotation></semantics></math> documents, that have different invoice layouts and types
to those in the training set to measure generalization.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p4" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p4.1" class="ltx_p">Since this newly compiled dataset was never explored and made accessible
before, we have published an anonymized version of the small dataset,
that contains only the positions and sizes of wordboxes and annotations,
no picture information and no readable text information –
only a subset of some textual features. The
dataset is to be found at <a target="_blank" href="https://github.com/rossumai/flying-rectangles" title="" class="ltx_ref ltx_href">https://github.com/rossumai/flying-rectangles</a></p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Our approach</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We want to operate based on the principle of reflecting the structure
of the data in the model’s architecture, as Machine learning algorithms
tend to perform better that way.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">What will be the structured information at the input? The number of
wordboxes per page can vary and so we have decided to perceive the
input as an ordered sequence (see below).</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">In addition we will teach the network to not only detect line-item
table in general, but also to detect a header in the table, because
that could provide a meaningful information - the headers are always
different from the contents.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.2" class="ltx_p">The features of each wordbox are:</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p">Geometrical:</p>
<ul id="S3.I2.i1.I1" class="ltx_itemize">
<li id="S3.I2.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I2.i1.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I2.i1.I1.i1.p1" class="ltx_para">
<p id="S3.I2.i1.I1.i1.p1.5" class="ltx_p">By geometrical algorithms we can construct a neighbourhood graph over
the boxes, which can then be used by a graph CNN if we bound the number
of neighbours on each edge of the box by a constant. 
<br class="ltx_break">Neighbours are generated for each wordbox (<math id="S3.I2.i1.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.I2.i1.I1.i1.p1.1.m1.1a"><mi id="S3.I2.i1.I1.i1.p1.1.m1.1.1" xref="S3.I2.i1.I1.i1.p1.1.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i1.I1.i1.p1.1.m1.1b"><ci id="S3.I2.i1.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I2.i1.I1.i1.p1.1.m1.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.I1.i1.p1.1.m1.1c">W</annotation></semantics></math>) as follows - every
other box is assigned to an edge of <math id="S3.I2.i1.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.I2.i1.I1.i1.p1.2.m2.1a"><mi id="S3.I2.i1.I1.i1.p1.2.m2.1.1" xref="S3.I2.i1.I1.i1.p1.2.m2.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i1.I1.i1.p1.2.m2.1b"><ci id="S3.I2.i1.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I2.i1.I1.i1.p1.2.m2.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.I1.i1.p1.2.m2.1c">W</annotation></semantics></math>, that has it in its field
of view (being fair <math id="S3.I2.i1.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="90\text{\textdegree}" display="inline"><semantics id="S3.I2.i1.I1.i1.p1.3.m3.1a"><mrow id="S3.I2.i1.I1.i1.p1.3.m3.1.1" xref="S3.I2.i1.I1.i1.p1.3.m3.1.1.cmml"><mn id="S3.I2.i1.I1.i1.p1.3.m3.1.1.2" xref="S3.I2.i1.I1.i1.p1.3.m3.1.1.2.cmml">90</mn><mo lspace="0em" rspace="0em" id="S3.I2.i1.I1.i1.p1.3.m3.1.1.1" xref="S3.I2.i1.I1.i1.p1.3.m3.1.1.1.cmml">​</mo><mtext id="S3.I2.i1.I1.i1.p1.3.m3.1.1.3" xref="S3.I2.i1.I1.i1.p1.3.m3.1.1.3a.cmml">°</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i1.I1.i1.p1.3.m3.1b"><apply id="S3.I2.i1.I1.i1.p1.3.m3.1.1.cmml" xref="S3.I2.i1.I1.i1.p1.3.m3.1.1"><times id="S3.I2.i1.I1.i1.p1.3.m3.1.1.1.cmml" xref="S3.I2.i1.I1.i1.p1.3.m3.1.1.1"></times><cn type="integer" id="S3.I2.i1.I1.i1.p1.3.m3.1.1.2.cmml" xref="S3.I2.i1.I1.i1.p1.3.m3.1.1.2">90</cn><ci id="S3.I2.i1.I1.i1.p1.3.m3.1.1.3a.cmml" xref="S3.I2.i1.I1.i1.p1.3.m3.1.1.3"><mtext id="S3.I2.i1.I1.i1.p1.3.m3.1.1.3.cmml" xref="S3.I2.i1.I1.i1.p1.3.m3.1.1.3">°</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.I1.i1.p1.3.m3.1c">90\text{\textdegree}</annotation></semantics></math>), then the closest (center
to center Euclidian distance) <math id="S3.I2.i1.I1.i1.p1.4.m4.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.I2.i1.I1.i1.p1.4.m4.1a"><mi id="S3.I2.i1.I1.i1.p1.4.m4.1.1" xref="S3.I2.i1.I1.i1.p1.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i1.I1.i1.p1.4.m4.1b"><ci id="S3.I2.i1.I1.i1.p1.4.m4.1.1.cmml" xref="S3.I2.i1.I1.i1.p1.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.I1.i1.p1.4.m4.1c">n</annotation></semantics></math> neighbours are chosen for that
edge. For example with <math id="S3.I2.i1.I1.i1.p1.5.m5.1" class="ltx_Math" alttext="n=1" display="inline"><semantics id="S3.I2.i1.I1.i1.p1.5.m5.1a"><mrow id="S3.I2.i1.I1.i1.p1.5.m5.1.1" xref="S3.I2.i1.I1.i1.p1.5.m5.1.1.cmml"><mi id="S3.I2.i1.I1.i1.p1.5.m5.1.1.2" xref="S3.I2.i1.I1.i1.p1.5.m5.1.1.2.cmml">n</mi><mo id="S3.I2.i1.I1.i1.p1.5.m5.1.1.1" xref="S3.I2.i1.I1.i1.p1.5.m5.1.1.1.cmml">=</mo><mn id="S3.I2.i1.I1.i1.p1.5.m5.1.1.3" xref="S3.I2.i1.I1.i1.p1.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i1.I1.i1.p1.5.m5.1b"><apply id="S3.I2.i1.I1.i1.p1.5.m5.1.1.cmml" xref="S3.I2.i1.I1.i1.p1.5.m5.1.1"><eq id="S3.I2.i1.I1.i1.p1.5.m5.1.1.1.cmml" xref="S3.I2.i1.I1.i1.p1.5.m5.1.1.1"></eq><ci id="S3.I2.i1.I1.i1.p1.5.m5.1.1.2.cmml" xref="S3.I2.i1.I1.i1.p1.5.m5.1.1.2">𝑛</ci><cn type="integer" id="S3.I2.i1.I1.i1.p1.5.m5.1.1.3.cmml" xref="S3.I2.i1.I1.i1.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.I1.i1.p1.5.m5.1c">n=1</annotation></semantics></math> see figure <a href="#S3.F1" title="Figure 1 ‣ III-C Our approach ‣ III Methodology ‣ Table understanding in structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
The relation does not need to be symmetrical, but when higher number
of closest neighbours will be used, the sets would have bigger overlap.</p>
</div>
</li>
<li id="S3.I2.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I2.i1.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I2.i1.I1.i2.p1" class="ltx_para">
<p id="S3.I2.i1.I1.i2.p1.3" class="ltx_p">We can define a ’reading order of wordboxes’. In particular, based
on the idea that if two boxes do overlap in a projection to <math id="S3.I2.i1.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.I2.i1.I1.i2.p1.1.m1.1a"><mi id="S3.I2.i1.I1.i2.p1.1.m1.1.1" xref="S3.I2.i1.I1.i2.p1.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i1.I1.i2.p1.1.m1.1b"><ci id="S3.I2.i1.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I2.i1.I1.i2.p1.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.I1.i2.p1.1.m1.1c">y</annotation></semantics></math> axis
by more than a given threshold, set to <math id="S3.I2.i1.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="50\,\%" display="inline"><semantics id="S3.I2.i1.I1.i2.p1.2.m2.1a"><mrow id="S3.I2.i1.I1.i2.p1.2.m2.1.1" xref="S3.I2.i1.I1.i2.p1.2.m2.1.1.cmml"><mn id="S3.I2.i1.I1.i2.p1.2.m2.1.1.2" xref="S3.I2.i1.I1.i2.p1.2.m2.1.1.2.cmml">50</mn><mo lspace="0.170em" id="S3.I2.i1.I1.i2.p1.2.m2.1.1.1" xref="S3.I2.i1.I1.i2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i1.I1.i2.p1.2.m2.1b"><apply id="S3.I2.i1.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I2.i1.I1.i2.p1.2.m2.1.1"><csymbol cd="latexml" id="S3.I2.i1.I1.i2.p1.2.m2.1.1.1.cmml" xref="S3.I2.i1.I1.i2.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S3.I2.i1.I1.i2.p1.2.m2.1.1.2.cmml" xref="S3.I2.i1.I1.i2.p1.2.m2.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.I1.i2.p1.2.m2.1c">50\,\%</annotation></semantics></math> in our experiments,
they should be regarded to be in the same line for a human reader.
This not only defines an order of the boxes in which they will be
given as sequence to the network, but also assigns a line number and
order-in-line number to each box. To get more information, we can
run this algorithm again on a <math id="S3.I2.i1.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="90\text{\textdegree}" display="inline"><semantics id="S3.I2.i1.I1.i2.p1.3.m3.1a"><mrow id="S3.I2.i1.I1.i2.p1.3.m3.1.1" xref="S3.I2.i1.I1.i2.p1.3.m3.1.1.cmml"><mn id="S3.I2.i1.I1.i2.p1.3.m3.1.1.2" xref="S3.I2.i1.I1.i2.p1.3.m3.1.1.2.cmml">90</mn><mo lspace="0em" rspace="0em" id="S3.I2.i1.I1.i2.p1.3.m3.1.1.1" xref="S3.I2.i1.I1.i2.p1.3.m3.1.1.1.cmml">​</mo><mtext id="S3.I2.i1.I1.i2.p1.3.m3.1.1.3" xref="S3.I2.i1.I1.i2.p1.3.m3.1.1.3a.cmml">°</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i1.I1.i2.p1.3.m3.1b"><apply id="S3.I2.i1.I1.i2.p1.3.m3.1.1.cmml" xref="S3.I2.i1.I1.i2.p1.3.m3.1.1"><times id="S3.I2.i1.I1.i2.p1.3.m3.1.1.1.cmml" xref="S3.I2.i1.I1.i2.p1.3.m3.1.1.1"></times><cn type="integer" id="S3.I2.i1.I1.i2.p1.3.m3.1.1.2.cmml" xref="S3.I2.i1.I1.i2.p1.3.m3.1.1.2">90</cn><ci id="S3.I2.i1.I1.i2.p1.3.m3.1.1.3a.cmml" xref="S3.I2.i1.I1.i2.p1.3.m3.1.1.3"><mtext id="S3.I2.i1.I1.i2.p1.3.m3.1.1.3.cmml" xref="S3.I2.i1.I1.i2.p1.3.m3.1.1.3">°</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.I1.i2.p1.3.m3.1c">90\text{\textdegree}</annotation></semantics></math> rotated version
of the document. These integers are then subject to a positional embedding.
Note, that the exact ordering/reading direction (left to right and
top to bottom or vice versa) should not matter in the neural network
design, thus giving us the freedom to process any language.</p>
</div>
</li>
<li id="S3.I2.i1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I2.i1.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I2.i1.I1.i3.p1" class="ltx_para">
<p id="S3.I2.i1.I1.i3.p1.1" class="ltx_p">Each box has 4 normalized coordinates (left, top, right, bottom) that
should be presented to the network also by positional embedding.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">Textual:</p>
<ul id="S3.I2.i2.I1" class="ltx_itemize">
<li id="S3.I2.i2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I2.i2.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I2.i2.I1.i1.p1" class="ltx_para">
<p id="S3.I2.i2.I1.i1.p1.1" class="ltx_p">Each word can be presented using any fixed size representation, in
our case we will use tailored features common in other NLP tasks (e.g.
authorship attribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, named
entity recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, and sentiment analysis
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>). The features per wordbox
are the counts of all characters, the counts of first two and last
two characters, length of a word, number of uppercase and lowercase
letters, number of text characters and number of digits. And finally,
if the word is in fact a number, then the number scaled and cropped
against different scales, zeroes for other text. The reason behind
these features is that in an invoice there would be a larger number
of named entities, ids and numbers, which are not easily embedded.</p>
</div>
</li>
<li id="S3.I2.i2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I2.i2.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I2.i2.I1.i2.p1" class="ltx_para">
<p id="S3.I2.i2.I1.i2.p1.1" class="ltx_p">Trainable word features are employed as well, using convolutional
architecture over sequence of one hot encoded, deaccented, lowercase
characters (only alphabet, numeric characters and special characters
“ ,.-+:/%?$£€#()&amp;”’, all others are discarded).</p>
</div>
</li>
</ul>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.1" class="ltx_p">Image features:</p>
<ul id="S3.I2.i3.I1" class="ltx_itemize">
<li id="S3.I2.i3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I2.i3.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I2.i3.I1.i1.p1" class="ltx_para">
<p id="S3.I2.i3.I1.i1.p1.1" class="ltx_p">Each wordbox has its corresponding crop in the original PDF file,
where it is rendered using some font settings and also background,
which could be crucial to line-item table (or header) detection, if
it contains lines, for example, or different background color or gradient.
So the network receives a crop from the original image, offsetted
outwards to be bigger than the text area to see also the surroundings.</p>
</div>
</li>
</ul>
</div>
</li>
</ul>
<p id="S3.SS3.p4.1" class="ltx_p">Each presented feature can be augmented, we have decided to do a random
<math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="1\,\%" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><mrow id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mn id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">1</mn><mo lspace="0.170em" id="S3.SS3.p4.1.m1.1.1.1" xref="S3.SS3.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="latexml" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">1\,\%</annotation></semantics></math> percent perturbation on coordinates and textual features
representation.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/1904.12577/assets/boxesgraph-arrowed-green.png" id="S3.F1.g1" class="ltx_graphics ltx_img_square" width="299" height="344" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Sample invoice with edges defining
neighbourhood wordboxes. Only the closest neighbour is connected for
each wordbox. Green area is the line-item table. Note that above it
lies a smaller table of payment terms and due date, from which only
some information should be extracted and the table should not be reported.
This invoice is artificially created for presentation and does not
represent the invoices in our dataset.</figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">The architecture</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">As can be seen in Figure <a href="#S3.F2" title="Figure 2 ‣ III-D The architecture ‣ III Methodology ‣ Table understanding in structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and as we have
stated before, the model uses 5 inputs - downsampled picture of the
whole document (<math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="620\times 877" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mrow id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mn id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">620</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p1.1.m1.1.1.1" xref="S3.SS4.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">877</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><times id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">620</cn><cn type="integer" id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">877</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">620\times 877</annotation></semantics></math>), grayscaled; features of the wordboxes,
including their boundingbox coordinates; on-hot characters with 40
one-hot encoded characters per each wordbox; neighbour ids - integers
that define the neighbouring wordboxes on each side of the wordbox;
and finally integer positions of each field defined by the geometrical
ordering.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.3" class="ltx_p">The positions are embedded by positional embeddings (defined and used
in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, we use embedding
size equal to 4 dimensions for <math id="S3.SS4.p2.1.m1.1" class="ltx_Math" alttext="sin" display="inline"><semantics id="S3.SS4.p2.1.m1.1a"><mrow id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml"><mi id="S3.SS4.p2.1.m1.1.1.2" xref="S3.SS4.p2.1.m1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.1.m1.1.1.1" xref="S3.SS4.p2.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS4.p2.1.m1.1.1.3" xref="S3.SS4.p2.1.m1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.1.m1.1.1.1a" xref="S3.SS4.p2.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS4.p2.1.m1.1.1.4" xref="S3.SS4.p2.1.m1.1.1.4.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><apply id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"><times id="S3.SS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1.1"></times><ci id="S3.SS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.1.1.2">𝑠</ci><ci id="S3.SS4.p2.1.m1.1.1.3.cmml" xref="S3.SS4.p2.1.m1.1.1.3">𝑖</ci><ci id="S3.SS4.p2.1.m1.1.1.4.cmml" xref="S3.SS4.p2.1.m1.1.1.4">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">sin</annotation></semantics></math> and 4 for <math id="S3.SS4.p2.2.m2.1" class="ltx_Math" alttext="cos" display="inline"><semantics id="S3.SS4.p2.2.m2.1a"><mrow id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml"><mi id="S3.SS4.p2.2.m2.1.1.2" xref="S3.SS4.p2.2.m2.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.2.m2.1.1.1" xref="S3.SS4.p2.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS4.p2.2.m2.1.1.3" xref="S3.SS4.p2.2.m2.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.2.m2.1.1.1a" xref="S3.SS4.p2.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS4.p2.2.m2.1.1.4" xref="S3.SS4.p2.2.m2.1.1.4.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><apply id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1"><times id="S3.SS4.p2.2.m2.1.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1.1"></times><ci id="S3.SS4.p2.2.m2.1.1.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2">𝑐</ci><ci id="S3.SS4.p2.2.m2.1.1.3.cmml" xref="S3.SS4.p2.2.m2.1.1.3">𝑜</ci><ci id="S3.SS4.p2.2.m2.1.1.4.cmml" xref="S3.SS4.p2.2.m2.1.1.4">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">cos</annotation></semantics></math>, with divisor
constant being <math id="S3.SS4.p2.3.m3.1" class="ltx_Math" alttext="10000" display="inline"><semantics id="S3.SS4.p2.3.m3.1a"><mn id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml">10000</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><cn type="integer" id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1">10000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">10000</annotation></semantics></math>) and then concatenated with other field features.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">The picture is reduced by classical stacked convolution and maxpooling
approach and then from its inner representation, field coordinates
(left, top, right, bottom) are used to get a crop of a slightly bigger
area (using morphological dilation) which is then appended to the
field. Finally we have decided to give the model a grasp of the image
as whole - a connection to the whole image flattened and then processed
to 32 float features, which are also appended to each field’s features.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p id="S3.SS4.p4.1" class="ltx_p">Before attention, dense, or graph convolution layers are used, all
the input features are concatenated.</p>
</div>
<div id="S3.SS4.p5" class="ltx_para">
<p id="S3.SS4.p5.1" class="ltx_p">Our implementation of the graph convolution mechanism gathers features
from the neighbouring wordboxes, concatenates them and feeds into
a Dense layer. To note, our graph has a regularity that allows us
to simplify the graph convolution - there does exist an upper bound
on the number of edges for each node, so we do not need to use any
general form graph convolutions as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.</p>
</div>
<div id="S3.SS4.p6" class="ltx_para">
<p id="S3.SS4.p6.1" class="ltx_p">We have also employed a convolution layer over the ordering dimension
(called <em id="S3.SS4.p6.1.1" class="ltx_emph ltx_font_italic">convolution over sequence</em> later in this text).</p>
</div>
<div id="S3.SS4.p7" class="ltx_para">
<p id="S3.SS4.p7.1" class="ltx_p">The rest of the network handles images and crops. The final output
branch has an attention transformer module (from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>)
to be able to compare pairwise all the fields in hope that denser
and regular areas (of texts in a table grid) can be detected better.
Our attention transformer unit does not use causality, nor query masking
and has 64 units and 8 heads.</p>
</div>
<div id="S3.SS4.p8" class="ltx_para">
<p id="S3.SS4.p8.1" class="ltx_p">Finally, the output is a multilabel problem, so sigmoidal layers are
deployed together with binary crossentropy as the loss function.</p>
</div>
<div id="S3.SS4.p9" class="ltx_para">
<p id="S3.SS4.p9.2" class="ltx_p">The optimizer was chosen to be Adam. Model selected in each experimental
run was always the one that performed best on the validation set (of
the <em id="S3.SS4.p9.2.1" class="ltx_emph ltx_font_italic">small</em> dataset) in terms of loss, while the <em id="S3.SS4.p9.2.2" class="ltx_emph ltx_font_italic">patience</em>
constant was <math id="S3.SS4.p9.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.SS4.p9.1.m1.1a"><mn id="S3.SS4.p9.1.m1.1.1" xref="S3.SS4.p9.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p9.1.m1.1b"><cn type="integer" id="S3.SS4.p9.1.m1.1.1.cmml" xref="S3.SS4.p9.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p9.1.m1.1c">10</annotation></semantics></math> epochs. Batched data were padded by zeros per batch
(with zero sample weights). Class weights in our multi-task classification
problem were chosen based on positive class occurrences. The network
has <math id="S3.SS4.p9.2.m2.1" class="ltx_Math" alttext="867k" display="inline"><semantics id="S3.SS4.p9.2.m2.1a"><mrow id="S3.SS4.p9.2.m2.1.1" xref="S3.SS4.p9.2.m2.1.1.cmml"><mn id="S3.SS4.p9.2.m2.1.1.2" xref="S3.SS4.p9.2.m2.1.1.2.cmml">867</mn><mo lspace="0em" rspace="0em" id="S3.SS4.p9.2.m2.1.1.1" xref="S3.SS4.p9.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS4.p9.2.m2.1.1.3" xref="S3.SS4.p9.2.m2.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p9.2.m2.1b"><apply id="S3.SS4.p9.2.m2.1.1.cmml" xref="S3.SS4.p9.2.m2.1.1"><times id="S3.SS4.p9.2.m2.1.1.1.cmml" xref="S3.SS4.p9.2.m2.1.1.1"></times><cn type="integer" id="S3.SS4.p9.2.m2.1.1.2.cmml" xref="S3.SS4.p9.2.m2.1.1.2">867</cn><ci id="S3.SS4.p9.2.m2.1.1.3.cmml" xref="S3.SS4.p9.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p9.2.m2.1c">867k</annotation></semantics></math> trainable parameters in total.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/1904.12577/assets/modeldetect4.png" id="S3.F2.g1" class="ltx_graphics ltx_img_portrait" width="329" height="498" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The model architecture. All features
are concatenated together before the self attention mechanism and
final layers. The cropping of the picture, embeddings and graph convolution
all happen inside the network. Note that <math id="S3.F2.2.m1.1" class="ltx_Math" alttext="Conv1D(1)" display="inline"><semantics id="S3.F2.2.m1.1b"><mrow id="S3.F2.2.m1.1.2" xref="S3.F2.2.m1.1.2.cmml"><mi id="S3.F2.2.m1.1.2.2" xref="S3.F2.2.m1.1.2.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.F2.2.m1.1.2.1" xref="S3.F2.2.m1.1.2.1.cmml">​</mo><mi id="S3.F2.2.m1.1.2.3" xref="S3.F2.2.m1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.F2.2.m1.1.2.1b" xref="S3.F2.2.m1.1.2.1.cmml">​</mo><mi id="S3.F2.2.m1.1.2.4" xref="S3.F2.2.m1.1.2.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.F2.2.m1.1.2.1c" xref="S3.F2.2.m1.1.2.1.cmml">​</mo><mi id="S3.F2.2.m1.1.2.5" xref="S3.F2.2.m1.1.2.5.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.F2.2.m1.1.2.1d" xref="S3.F2.2.m1.1.2.1.cmml">​</mo><mn id="S3.F2.2.m1.1.2.6" xref="S3.F2.2.m1.1.2.6.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.F2.2.m1.1.2.1e" xref="S3.F2.2.m1.1.2.1.cmml">​</mo><mi id="S3.F2.2.m1.1.2.7" xref="S3.F2.2.m1.1.2.7.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.F2.2.m1.1.2.1f" xref="S3.F2.2.m1.1.2.1.cmml">​</mo><mrow id="S3.F2.2.m1.1.2.8.2" xref="S3.F2.2.m1.1.2.cmml"><mo stretchy="false" id="S3.F2.2.m1.1.2.8.2.1" xref="S3.F2.2.m1.1.2.cmml">(</mo><mn id="S3.F2.2.m1.1.1" xref="S3.F2.2.m1.1.1.cmml">1</mn><mo stretchy="false" id="S3.F2.2.m1.1.2.8.2.2" xref="S3.F2.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.2.m1.1c"><apply id="S3.F2.2.m1.1.2.cmml" xref="S3.F2.2.m1.1.2"><times id="S3.F2.2.m1.1.2.1.cmml" xref="S3.F2.2.m1.1.2.1"></times><ci id="S3.F2.2.m1.1.2.2.cmml" xref="S3.F2.2.m1.1.2.2">𝐶</ci><ci id="S3.F2.2.m1.1.2.3.cmml" xref="S3.F2.2.m1.1.2.3">𝑜</ci><ci id="S3.F2.2.m1.1.2.4.cmml" xref="S3.F2.2.m1.1.2.4">𝑛</ci><ci id="S3.F2.2.m1.1.2.5.cmml" xref="S3.F2.2.m1.1.2.5">𝑣</ci><cn type="integer" id="S3.F2.2.m1.1.2.6.cmml" xref="S3.F2.2.m1.1.2.6">1</cn><ci id="S3.F2.2.m1.1.2.7.cmml" xref="S3.F2.2.m1.1.2.7">𝐷</ci><cn type="integer" id="S3.F2.2.m1.1.1.cmml" xref="S3.F2.2.m1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.m1.1d">Conv1D(1)</annotation></semantics></math> can be also
called a time distributed dense layer.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.3" class="ltx_p">The approach was tested on different data settings and different architectures.
There are 4 groups of experiments:</p>
<ol id="S4.I1" class="ltx_enumerate">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Comparing logistic regression baseline against the neural network.

<br class="ltx_break">To note, logistic regression baselines use all the inputs except the
picture and trainable word embeddings. To inspect the importance of
neighbouring boxes, we have compared the baseline without neighbours
and the baseline with included information about one or more neighbours
at each side (if present).</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">The importance and effect of each block of layers and each input and
other parameters.
<br class="ltx_break">The choice of modules to test was ’convolution with dropout after
attention’ to test the dropout layer, ’convolution over sequence’
for the importance of input ordering and attention. Experiments dropping
the graph convolution were done in variation of neighbours. Experiments
on anonymized dataset fall also into this category. We have also tested
the focal loss function <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, note that we
do not vary final activations in our experiments here and use only
sigmoidal, because they had best performance in earlier development
process.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">Specialization on a task where only line-items were classified and
specialization on a task with all but line-items.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p">Evaluating the model’s adaptation performance on the big dataset (without
line-items).</p>
</div>
</li>
</ol>
<p id="S4.p1.2" class="ltx_p">We will not be optimizing the number of neurons in the layers. The
training was done on a single GPU and ran approximately in <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="23" display="inline"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">23</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn type="integer" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">23</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">23</annotation></semantics></math> epochs
for <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn type="integer" id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">5</annotation></semantics></math> hours per experiment on small dataset.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Results</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Table <a href="#S4.T1" title="TABLE I ‣ IV-A Results ‣ IV Experiments ‣ Table understanding in structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> summarizes experiments
comparing the model against the logistic regression baseline, both
with varying number of neighbours (more than <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">2</annotation></semantics></math> not shown, because
the results were not improving with the number of neighbours). The
logistic regression baselines did improve with more neighbours, but
failed to generalize. We can notice the big difference between line-item
table detection and other classes coming from a possible observation
that sometimes the table is the biggest one. The results also do reflect
the nature of a specialized structured document, which invoices indeed
are - to classify all the structured information is not easy for a
person not working with invoices.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">On the other hand, the optimal number of neighbours for the final
architecture was 1, but we can notice, that 2 neighbours do help line-item
table body detections. We have designed the algorithm with more than
one neighbour in mind (with a single neighbour, the relation is not
symmetrical), so other positional features are possibly being exploited
more efficiently.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Table <a href="#S4.T2" title="TABLE II ‣ IV-A Results ‣ IV Experiments ‣ Table understanding in structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> shows, that the multihead attention
module helps with generalization to unseen layouts, omitting the module
makes the network prioritize adaptation on already seen layouts. Also
without attention, the number of training epochs was twice (27) as
much as with attention (13). Focal loss, prioritizing rare classes,
does help line-item header detection, but is a cause for the decrease
of the nonline-item score micro metric, as rare classes contribute
less.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">The importance of the convolutional layer over the sequence might
come from our initial guess that this would give more importance to
beginnings and endings of lines of words.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">Table <a href="#S4.T3" title="TABLE III ‣ IV-A Results ‣ IV Experiments ‣ Table understanding in structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> compares different inputs and
dataset choices. Although the architecture was optimized on the small
dataset, the results imply that the model has the capacity to adapt
and generalize also on bigger datasets. Looking at the anonymized
version of datasets, without some inputs, it can be concluded that
the network can learn to detect tight areas of evenly spaced words,
being the line-item table. Also even base text features help the model
generalize well. Overall the score on anonymized dataset means that
the positional information is passed correctly and embedded in a right
way for the network.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p">In table <a href="#S4.T4" title="TABLE IV ‣ IV-A Results ‣ IV Experiments ‣ Table understanding in structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> there can be seen that
the tasks of finding line-items and other structural information do
boost each other, with one exception being the header detection -
it does help adaptation, but when omitted, the generalization score
is higher.</p>
</div>
<div id="S4.SS1.p7" class="ltx_para">
<p id="S4.SS1.p7.3" class="ltx_p">The architecture provided on Figure <a href="#S3.F2" title="Figure 2 ‣ III-D The architecture ‣ III Methodology ‣ Table understanding in structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> is
the ’<span id="S4.SS1.p7.3.1" class="ltx_text ltx_font_bold">complete model</span>’, that uses binary crossentropy, all
inputs and all modules and a single neighbour at each side of each
box. Its generalization performance on unseen invoice types was <math id="S4.SS1.p7.1.m1.1" class="ltx_Math" alttext="93\,\%" display="inline"><semantics id="S4.SS1.p7.1.m1.1a"><mrow id="S4.SS1.p7.1.m1.1.1" xref="S4.SS1.p7.1.m1.1.1.cmml"><mn id="S4.SS1.p7.1.m1.1.1.2" xref="S4.SS1.p7.1.m1.1.1.2.cmml">93</mn><mo lspace="0.170em" id="S4.SS1.p7.1.m1.1.1.1" xref="S4.SS1.p7.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p7.1.m1.1b"><apply id="S4.SS1.p7.1.m1.1.1.cmml" xref="S4.SS1.p7.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p7.1.m1.1.1.1.cmml" xref="S4.SS1.p7.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS1.p7.1.m1.1.1.2.cmml" xref="S4.SS1.p7.1.m1.1.1.2">93</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p7.1.m1.1c">93\,\%</annotation></semantics></math>
on detecting line-items and <math id="S4.SS1.p7.2.m2.1" class="ltx_Math" alttext="66\,\%" display="inline"><semantics id="S4.SS1.p7.2.m2.1a"><mrow id="S4.SS1.p7.2.m2.1.1" xref="S4.SS1.p7.2.m2.1.1.cmml"><mn id="S4.SS1.p7.2.m2.1.1.2" xref="S4.SS1.p7.2.m2.1.1.2.cmml">66</mn><mo lspace="0.170em" id="S4.SS1.p7.2.m2.1.1.1" xref="S4.SS1.p7.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p7.2.m2.1b"><apply id="S4.SS1.p7.2.m2.1.1.cmml" xref="S4.SS1.p7.2.m2.1.1"><csymbol cd="latexml" id="S4.SS1.p7.2.m2.1.1.1.cmml" xref="S4.SS1.p7.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS1.p7.2.m2.1.1.2.cmml" xref="S4.SS1.p7.2.m2.1.1.2">66</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p7.2.m2.1c">66\,\%</annotation></semantics></math> for other classes (<math id="S4.SS1.p7.3.m3.1" class="ltx_Math" alttext="87\,\%" display="inline"><semantics id="S4.SS1.p7.3.m3.1a"><mrow id="S4.SS1.p7.3.m3.1.1" xref="S4.SS1.p7.3.m3.1.1.cmml"><mn id="S4.SS1.p7.3.m3.1.1.2" xref="S4.SS1.p7.3.m3.1.1.2.cmml">87</mn><mo lspace="0.170em" id="S4.SS1.p7.3.m3.1.1.1" xref="S4.SS1.p7.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p7.3.m3.1b"><apply id="S4.SS1.p7.3.m3.1.1.cmml" xref="S4.SS1.p7.3.m3.1.1"><csymbol cd="latexml" id="S4.SS1.p7.3.m3.1.1.1.cmml" xref="S4.SS1.p7.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS1.p7.3.m3.1.1.2.cmml" xref="S4.SS1.p7.3.m3.1.1.2">87</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p7.3.m3.1c">87\,\%</annotation></semantics></math>
on similar layouts). To verify what the line-item detection scores
mean in practice, we have run the prediction on the sample invoices
(Figure <a href="#S3.F1" title="Figure 1 ‣ III-C Our approach ‣ III Methodology ‣ Table understanding in structured documents" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), where our algorithm correctly
detected the line-item table up to 2 false positive words, which are
easily filtered out (heuristic filtering results are not reported).</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span> </figcaption>
<table id="S4.T1.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.6.7.1" class="ltx_tr">
<th id="S4.T1.6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T1.6.7.1.1.1" class="ltx_text">Experiments against the baseline</span></th>
<th id="S4.T1.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" colspan="3">Adaptation</th>
<th id="S4.T1.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3">Generalization</th>
</tr>
<tr id="S4.T1.6.8.2" class="ltx_tr">
<th id="S4.T1.6.8.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">line-items</th>
<th id="S4.T1.6.8.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">others</th>
<th id="S4.T1.6.8.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">line-items</th>
<th id="S4.T1.6.8.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">others</th>
</tr>
<tr id="S4.T1.6.6" class="ltx_tr">
<th id="S4.T1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">body <math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><msub id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml"><mi id="S4.T1.1.1.1.m1.1.1.2" xref="S4.T1.1.1.1.m1.1.1.2.cmml">F</mi><mn id="S4.T1.1.1.1.m1.1.1.3" xref="S4.T1.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><apply id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.1.1.1.m1.1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T1.1.1.1.m1.1.1.2.cmml" xref="S4.T1.1.1.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T1.1.1.1.m1.1.1.3.cmml" xref="S4.T1.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">header <math id="S4.T1.2.2.2.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T1.2.2.2.m1.1a"><msub id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml"><mi id="S4.T1.2.2.2.m1.1.1.2" xref="S4.T1.2.2.2.m1.1.1.2.cmml">F</mi><mn id="S4.T1.2.2.2.m1.1.1.3" xref="S4.T1.2.2.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><apply id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.2.2.2.m1.1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">subscript</csymbol><ci id="S4.T1.2.2.2.m1.1.1.2.cmml" xref="S4.T1.2.2.2.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T1.2.2.2.m1.1.1.3.cmml" xref="S4.T1.2.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">micro <math id="S4.T1.3.3.3.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T1.3.3.3.m1.1a"><msub id="S4.T1.3.3.3.m1.1.1" xref="S4.T1.3.3.3.m1.1.1.cmml"><mi id="S4.T1.3.3.3.m1.1.1.2" xref="S4.T1.3.3.3.m1.1.1.2.cmml">F</mi><mn id="S4.T1.3.3.3.m1.1.1.3" xref="S4.T1.3.3.3.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><apply id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.3.3.3.m1.1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1">subscript</csymbol><ci id="S4.T1.3.3.3.m1.1.1.2.cmml" xref="S4.T1.3.3.3.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T1.3.3.3.m1.1.1.3.cmml" xref="S4.T1.3.3.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T1.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">body <math id="S4.T1.4.4.4.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T1.4.4.4.m1.1a"><msub id="S4.T1.4.4.4.m1.1.1" xref="S4.T1.4.4.4.m1.1.1.cmml"><mi id="S4.T1.4.4.4.m1.1.1.2" xref="S4.T1.4.4.4.m1.1.1.2.cmml">F</mi><mn id="S4.T1.4.4.4.m1.1.1.3" xref="S4.T1.4.4.4.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.m1.1b"><apply id="S4.T1.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.4.4.4.m1.1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1">subscript</csymbol><ci id="S4.T1.4.4.4.m1.1.1.2.cmml" xref="S4.T1.4.4.4.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T1.4.4.4.m1.1.1.3.cmml" xref="S4.T1.4.4.4.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T1.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">header <math id="S4.T1.5.5.5.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T1.5.5.5.m1.1a"><msub id="S4.T1.5.5.5.m1.1.1" xref="S4.T1.5.5.5.m1.1.1.cmml"><mi id="S4.T1.5.5.5.m1.1.1.2" xref="S4.T1.5.5.5.m1.1.1.2.cmml">F</mi><mn id="S4.T1.5.5.5.m1.1.1.3" xref="S4.T1.5.5.5.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.m1.1b"><apply id="S4.T1.5.5.5.m1.1.1.cmml" xref="S4.T1.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.5.5.5.m1.1.1.1.cmml" xref="S4.T1.5.5.5.m1.1.1">subscript</csymbol><ci id="S4.T1.5.5.5.m1.1.1.2.cmml" xref="S4.T1.5.5.5.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T1.5.5.5.m1.1.1.3.cmml" xref="S4.T1.5.5.5.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T1.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">micro <math id="S4.T1.6.6.6.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T1.6.6.6.m1.1a"><msub id="S4.T1.6.6.6.m1.1.1" xref="S4.T1.6.6.6.m1.1.1.cmml"><mi id="S4.T1.6.6.6.m1.1.1.2" xref="S4.T1.6.6.6.m1.1.1.2.cmml">F</mi><mn id="S4.T1.6.6.6.m1.1.1.3" xref="S4.T1.6.6.6.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.m1.1b"><apply id="S4.T1.6.6.6.m1.1.1.cmml" xref="S4.T1.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.6.6.6.m1.1.1.1.cmml" xref="S4.T1.6.6.6.m1.1.1">subscript</csymbol><ci id="S4.T1.6.6.6.m1.1.1.2.cmml" xref="S4.T1.6.6.6.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T1.6.6.6.m1.1.1.3.cmml" xref="S4.T1.6.6.6.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.m1.1c">F_{1}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.6.9.1" class="ltx_tr">
<td id="S4.T1.6.9.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">complete model (without neighbours)</td>
<td id="S4.T1.6.9.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.9666</td>
<td id="S4.T1.6.9.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.9969</td>
<td id="S4.T1.6.9.1.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">0.8687</td>
<td id="S4.T1.6.9.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.9242</td>
<td id="S4.T1.6.9.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.9876</td>
<td id="S4.T1.6.9.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.6609</td>
</tr>
<tr id="S4.T1.6.10.2" class="ltx_tr">
<td id="S4.T1.6.10.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.6.10.2.1.1" class="ltx_text ltx_font_bold">complete model (1 neighbour)</span></td>
<td id="S4.T1.6.10.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9738</td>
<td id="S4.T1.6.10.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.10.2.3.1" class="ltx_text ltx_font_bold">0.9967</span></td>
<td id="S4.T1.6.10.2.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S4.T1.6.10.2.4.1" class="ltx_text ltx_font_bold">0.8790</span></td>
<td id="S4.T1.6.10.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9389</td>
<td id="S4.T1.6.10.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.10.2.6.1" class="ltx_text ltx_font_bold">0.9864</span></td>
<td id="S4.T1.6.10.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.10.2.7.1" class="ltx_text ltx_font_bold">0.6650</span></td>
</tr>
<tr id="S4.T1.6.11.3" class="ltx_tr">
<td id="S4.T1.6.11.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">complete model (with 2 neighbours)</td>
<td id="S4.T1.6.11.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.11.3.2.1" class="ltx_text ltx_font_bold">0.9762</span></td>
<td id="S4.T1.6.11.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9963</td>
<td id="S4.T1.6.11.3.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.8749</td>
<td id="S4.T1.6.11.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.11.3.5.1" class="ltx_text ltx_font_bold">0.9408</span></td>
<td id="S4.T1.6.11.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9860</td>
<td id="S4.T1.6.11.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6629</td>
</tr>
<tr id="S4.T1.6.12.4" class="ltx_tr">
<td id="S4.T1.6.12.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">logistic regression without neighbours</td>
<td id="S4.T1.6.12.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.7594</td>
<td id="S4.T1.6.12.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9477</td>
<td id="S4.T1.6.12.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.0004</td>
<td id="S4.T1.6.12.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.7560</td>
<td id="S4.T1.6.12.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9362</td>
<td id="S4.T1.6.12.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0000</td>
</tr>
<tr id="S4.T1.6.13.5" class="ltx_tr">
<td id="S4.T1.6.13.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">logistic regression with 1 neighbour</td>
<td id="S4.T1.6.13.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.8664</td>
<td id="S4.T1.6.13.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9663</td>
<td id="S4.T1.6.13.5.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.1482</td>
<td id="S4.T1.6.13.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.8071</td>
<td id="S4.T1.6.13.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9461</td>
<td id="S4.T1.6.13.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0327</td>
</tr>
<tr id="S4.T1.6.14.6" class="ltx_tr">
<td id="S4.T1.6.14.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">logistic regression with 2 neighbours</td>
<td id="S4.T1.6.14.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.8939</td>
<td id="S4.T1.6.14.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.9724</td>
<td id="S4.T1.6.14.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t">0.2276</td>
<td id="S4.T1.6.14.6.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.8284</td>
<td id="S4.T1.6.14.6.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.9493</td>
<td id="S4.T1.6.14.6.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.0525</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span> </figcaption>
<table id="S4.T2.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.6.7.1" class="ltx_tr">
<th id="S4.T2.6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T2.6.7.1.1.1" class="ltx_text">Experiments with ablation</span></th>
<th id="S4.T2.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" colspan="3">Adaptation</th>
<th id="S4.T2.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3">Generalization</th>
</tr>
<tr id="S4.T2.6.8.2" class="ltx_tr">
<th id="S4.T2.6.8.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">line-items</th>
<th id="S4.T2.6.8.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">others</th>
<th id="S4.T2.6.8.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">line-items</th>
<th id="S4.T2.6.8.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">others</th>
</tr>
<tr id="S4.T2.6.6" class="ltx_tr">
<th id="S4.T2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">body <math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><msub id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml"><mi id="S4.T2.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.m1.1.1.2.cmml">F</mi><mn id="S4.T2.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T2.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T2.1.1.1.m1.1.1.3.cmml" xref="S4.T2.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">header <math id="S4.T2.2.2.2.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T2.2.2.2.m1.1a"><msub id="S4.T2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.m1.1.1.cmml"><mi id="S4.T2.2.2.2.m1.1.1.2" xref="S4.T2.2.2.2.m1.1.1.2.cmml">F</mi><mn id="S4.T2.2.2.2.m1.1.1.3" xref="S4.T2.2.2.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m1.1b"><apply id="S4.T2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.2.2.2.m1.1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1">subscript</csymbol><ci id="S4.T2.2.2.2.m1.1.1.2.cmml" xref="S4.T2.2.2.2.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T2.2.2.2.m1.1.1.3.cmml" xref="S4.T2.2.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T2.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">micro <math id="S4.T2.3.3.3.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T2.3.3.3.m1.1a"><msub id="S4.T2.3.3.3.m1.1.1" xref="S4.T2.3.3.3.m1.1.1.cmml"><mi id="S4.T2.3.3.3.m1.1.1.2" xref="S4.T2.3.3.3.m1.1.1.2.cmml">F</mi><mn id="S4.T2.3.3.3.m1.1.1.3" xref="S4.T2.3.3.3.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1">subscript</csymbol><ci id="S4.T2.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T2.3.3.3.m1.1.1.3.cmml" xref="S4.T2.3.3.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T2.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">body <math id="S4.T2.4.4.4.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T2.4.4.4.m1.1a"><msub id="S4.T2.4.4.4.m1.1.1" xref="S4.T2.4.4.4.m1.1.1.cmml"><mi id="S4.T2.4.4.4.m1.1.1.2" xref="S4.T2.4.4.4.m1.1.1.2.cmml">F</mi><mn id="S4.T2.4.4.4.m1.1.1.3" xref="S4.T2.4.4.4.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.m1.1b"><apply id="S4.T2.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.4.4.4.m1.1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1">subscript</csymbol><ci id="S4.T2.4.4.4.m1.1.1.2.cmml" xref="S4.T2.4.4.4.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T2.4.4.4.m1.1.1.3.cmml" xref="S4.T2.4.4.4.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T2.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">header <math id="S4.T2.5.5.5.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T2.5.5.5.m1.1a"><msub id="S4.T2.5.5.5.m1.1.1" xref="S4.T2.5.5.5.m1.1.1.cmml"><mi id="S4.T2.5.5.5.m1.1.1.2" xref="S4.T2.5.5.5.m1.1.1.2.cmml">F</mi><mn id="S4.T2.5.5.5.m1.1.1.3" xref="S4.T2.5.5.5.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.m1.1b"><apply id="S4.T2.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.5.5.5.m1.1.1.1.cmml" xref="S4.T2.5.5.5.m1.1.1">subscript</csymbol><ci id="S4.T2.5.5.5.m1.1.1.2.cmml" xref="S4.T2.5.5.5.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T2.5.5.5.m1.1.1.3.cmml" xref="S4.T2.5.5.5.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T2.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">micro <math id="S4.T2.6.6.6.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T2.6.6.6.m1.1a"><msub id="S4.T2.6.6.6.m1.1.1" xref="S4.T2.6.6.6.m1.1.1.cmml"><mi id="S4.T2.6.6.6.m1.1.1.2" xref="S4.T2.6.6.6.m1.1.1.2.cmml">F</mi><mn id="S4.T2.6.6.6.m1.1.1.3" xref="S4.T2.6.6.6.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.m1.1b"><apply id="S4.T2.6.6.6.m1.1.1.cmml" xref="S4.T2.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.6.6.6.m1.1.1.1.cmml" xref="S4.T2.6.6.6.m1.1.1">subscript</csymbol><ci id="S4.T2.6.6.6.m1.1.1.2.cmml" xref="S4.T2.6.6.6.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T2.6.6.6.m1.1.1.3.cmml" xref="S4.T2.6.6.6.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.m1.1c">F_{1}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.6.9.1" class="ltx_tr">
<th id="S4.T2.6.9.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"><span id="S4.T2.6.9.1.1.1" class="ltx_text ltx_font_bold">complete model</span></th>
<td id="S4.T2.6.9.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.9738</td>
<td id="S4.T2.6.9.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.9967</td>
<td id="S4.T2.6.9.1.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">0.8790</td>
<td id="S4.T2.6.9.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T2.6.9.1.5.1" class="ltx_text ltx_font_bold">0.9389</span></td>
<td id="S4.T2.6.9.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.9864</td>
<td id="S4.T2.6.9.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T2.6.9.1.7.1" class="ltx_text ltx_font_bold">0.6650</span></td>
</tr>
<tr id="S4.T2.6.10.2" class="ltx_tr">
<th id="S4.T2.6.10.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">focal loss</th>
<td id="S4.T2.6.10.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9735</td>
<td id="S4.T2.6.10.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.6.10.2.3.1" class="ltx_text ltx_font_bold">0.9969</span></td>
<td id="S4.T2.6.10.2.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.8557</td>
<td id="S4.T2.6.10.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9383</td>
<td id="S4.T2.6.10.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.6.10.2.6.1" class="ltx_text ltx_font_bold">0.9878</span></td>
<td id="S4.T2.6.10.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6398</td>
</tr>
<tr id="S4.T2.6.11.3" class="ltx_tr">
<th id="S4.T2.6.11.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">no convolution over sequence</th>
<td id="S4.T2.6.11.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9670</td>
<td id="S4.T2.6.11.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9945</td>
<td id="S4.T2.6.11.3.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.8638</td>
<td id="S4.T2.6.11.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9101</td>
<td id="S4.T2.6.11.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9800</td>
<td id="S4.T2.6.11.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6237</td>
</tr>
<tr id="S4.T2.6.12.4" class="ltx_tr">
<th id="S4.T2.6.12.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">no attention</th>
<td id="S4.T2.6.12.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.6.12.4.2.1" class="ltx_text ltx_font_bold">0.9780</span></td>
<td id="S4.T2.6.12.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9967</td>
<td id="S4.T2.6.12.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S4.T2.6.12.4.4.1" class="ltx_text ltx_font_bold">0.8806</span></td>
<td id="S4.T2.6.12.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9348</td>
<td id="S4.T2.6.12.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9864</td>
<td id="S4.T2.6.12.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6487</td>
</tr>
<tr id="S4.T2.6.13.5" class="ltx_tr">
<th id="S4.T2.6.13.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">no convolution with dropout after attention</th>
<td id="S4.T2.6.13.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.9646</td>
<td id="S4.T2.6.13.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.9950</td>
<td id="S4.T2.6.13.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t">0.8435</td>
<td id="S4.T2.6.13.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.9168</td>
<td id="S4.T2.6.13.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.9807</td>
<td id="S4.T2.6.13.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.6050</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span></figcaption>
<table id="S4.T3.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.6.7.1" class="ltx_tr">
<th id="S4.T3.6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T3.6.7.1.1.1" class="ltx_text">Experiments with inputs variations</span></th>
<th id="S4.T3.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T3.6.7.1.2.1" class="ltx_text">dataset</span></th>
<th id="S4.T3.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" colspan="3">Adaptation</th>
<th id="S4.T3.6.7.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3">Generalization</th>
</tr>
<tr id="S4.T3.6.8.2" class="ltx_tr">
<th id="S4.T3.6.8.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">line-items</th>
<th id="S4.T3.6.8.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">others</th>
<th id="S4.T3.6.8.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">line-items</th>
<th id="S4.T3.6.8.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">others</th>
</tr>
<tr id="S4.T3.6.6" class="ltx_tr">
<th id="S4.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">body <math id="S4.T3.1.1.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T3.1.1.1.m1.1a"><msub id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml"><mi id="S4.T3.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.m1.1.1.2.cmml">F</mi><mn id="S4.T3.1.1.1.m1.1.1.3" xref="S4.T3.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T3.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T3.1.1.1.m1.1.1.3.cmml" xref="S4.T3.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">header <math id="S4.T3.2.2.2.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T3.2.2.2.m1.1a"><msub id="S4.T3.2.2.2.m1.1.1" xref="S4.T3.2.2.2.m1.1.1.cmml"><mi id="S4.T3.2.2.2.m1.1.1.2" xref="S4.T3.2.2.2.m1.1.1.2.cmml">F</mi><mn id="S4.T3.2.2.2.m1.1.1.3" xref="S4.T3.2.2.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.m1.1b"><apply id="S4.T3.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.2.2.2.m1.1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1">subscript</csymbol><ci id="S4.T3.2.2.2.m1.1.1.2.cmml" xref="S4.T3.2.2.2.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T3.2.2.2.m1.1.1.3.cmml" xref="S4.T3.2.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">micro <math id="S4.T3.3.3.3.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T3.3.3.3.m1.1a"><msub id="S4.T3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.m1.1.1.cmml"><mi id="S4.T3.3.3.3.m1.1.1.2" xref="S4.T3.3.3.3.m1.1.1.2.cmml">F</mi><mn id="S4.T3.3.3.3.m1.1.1.3" xref="S4.T3.3.3.3.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><apply id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.3.3.3.m1.1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1">subscript</csymbol><ci id="S4.T3.3.3.3.m1.1.1.2.cmml" xref="S4.T3.3.3.3.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T3.3.3.3.m1.1.1.3.cmml" xref="S4.T3.3.3.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T3.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">body <math id="S4.T3.4.4.4.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T3.4.4.4.m1.1a"><msub id="S4.T3.4.4.4.m1.1.1" xref="S4.T3.4.4.4.m1.1.1.cmml"><mi id="S4.T3.4.4.4.m1.1.1.2" xref="S4.T3.4.4.4.m1.1.1.2.cmml">F</mi><mn id="S4.T3.4.4.4.m1.1.1.3" xref="S4.T3.4.4.4.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m1.1b"><apply id="S4.T3.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.4.4.4.m1.1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1">subscript</csymbol><ci id="S4.T3.4.4.4.m1.1.1.2.cmml" xref="S4.T3.4.4.4.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T3.4.4.4.m1.1.1.3.cmml" xref="S4.T3.4.4.4.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T3.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">header <math id="S4.T3.5.5.5.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T3.5.5.5.m1.1a"><msub id="S4.T3.5.5.5.m1.1.1" xref="S4.T3.5.5.5.m1.1.1.cmml"><mi id="S4.T3.5.5.5.m1.1.1.2" xref="S4.T3.5.5.5.m1.1.1.2.cmml">F</mi><mn id="S4.T3.5.5.5.m1.1.1.3" xref="S4.T3.5.5.5.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.m1.1b"><apply id="S4.T3.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.5.5.5.m1.1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1">subscript</csymbol><ci id="S4.T3.5.5.5.m1.1.1.2.cmml" xref="S4.T3.5.5.5.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T3.5.5.5.m1.1.1.3.cmml" xref="S4.T3.5.5.5.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T3.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">micro <math id="S4.T3.6.6.6.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T3.6.6.6.m1.1a"><msub id="S4.T3.6.6.6.m1.1.1" xref="S4.T3.6.6.6.m1.1.1.cmml"><mi id="S4.T3.6.6.6.m1.1.1.2" xref="S4.T3.6.6.6.m1.1.1.2.cmml">F</mi><mn id="S4.T3.6.6.6.m1.1.1.3" xref="S4.T3.6.6.6.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.m1.1b"><apply id="S4.T3.6.6.6.m1.1.1.cmml" xref="S4.T3.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.6.6.6.m1.1.1.1.cmml" xref="S4.T3.6.6.6.m1.1.1">subscript</csymbol><ci id="S4.T3.6.6.6.m1.1.1.2.cmml" xref="S4.T3.6.6.6.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T3.6.6.6.m1.1.1.3.cmml" xref="S4.T3.6.6.6.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.m1.1c">F_{1}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.6.9.1" class="ltx_tr">
<th id="S4.T3.6.9.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"><span id="S4.T3.6.9.1.1.1" class="ltx_text ltx_font_bold">complete model (all inputs)</span></th>
<th id="S4.T3.6.9.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T3.6.9.1.2.1" class="ltx_text ltx_font_bold">small</span></th>
<td id="S4.T3.6.9.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T3.6.9.1.3.1" class="ltx_text ltx_font_bold">0.9738</span></td>
<td id="S4.T3.6.9.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T3.6.9.1.4.1" class="ltx_text ltx_font_bold">0.9967</span></td>
<td id="S4.T3.6.9.1.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S4.T3.6.9.1.5.1" class="ltx_text ltx_font_bold">0.8790</span></td>
<td id="S4.T3.6.9.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T3.6.9.1.6.1" class="ltx_text ltx_font_bold">0.9389</span></td>
<td id="S4.T3.6.9.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T3.6.9.1.7.1" class="ltx_text ltx_font_bold">0.9864</span></td>
<td id="S4.T3.6.9.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T3.6.9.1.8.1" class="ltx_text ltx_font_bold">0.6650</span></td>
</tr>
<tr id="S4.T3.6.10.2" class="ltx_tr">
<th id="S4.T3.6.10.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">no text embeddings</th>
<th id="S4.T3.6.10.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">small</th>
<td id="S4.T3.6.10.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9702</td>
<td id="S4.T3.6.10.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9921</td>
<td id="S4.T3.6.10.2.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.7772</td>
<td id="S4.T3.6.10.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9108</td>
<td id="S4.T3.6.10.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9771</td>
<td id="S4.T3.6.10.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.5118</td>
</tr>
<tr id="S4.T3.6.11.3" class="ltx_tr">
<th id="S4.T3.6.11.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">no picture, only some text features</th>
<th id="S4.T3.6.11.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">anonym</th>
<td id="S4.T3.6.11.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9694</td>
<td id="S4.T3.6.11.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9943</td>
<td id="S4.T3.6.11.3.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.4518</td>
<td id="S4.T3.6.11.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9185</td>
<td id="S4.T3.6.11.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9805</td>
<td id="S4.T3.6.11.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.4745</td>
</tr>
<tr id="S4.T3.6.12.4" class="ltx_tr">
<th id="S4.T3.6.12.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">no picture, no text features</th>
<th id="S4.T3.6.12.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">anonym</th>
<td id="S4.T3.6.12.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9588</td>
<td id="S4.T3.6.12.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9848</td>
<td id="S4.T3.6.12.4.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.6836</td>
<td id="S4.T3.6.12.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.8919</td>
<td id="S4.T3.6.12.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9549</td>
<td id="S4.T3.6.12.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.2152</td>
</tr>
<tr id="S4.T3.6.13.5" class="ltx_tr">
<th id="S4.T3.6.13.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">complete model (all inputs)</th>
<th id="S4.T3.6.13.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">big</th>
<td id="S4.T3.6.13.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T3.6.13.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T3.6.13.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t">0.8487</td>
<td id="S4.T3.6.13.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T3.6.13.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T3.6.13.5.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IV: </span></figcaption>
<table id="S4.T4.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.6.7.1" class="ltx_tr">
<th id="S4.T4.6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T4.6.7.1.1.1" class="ltx_text">Experiments with training target variations</span></th>
<th id="S4.T4.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T4.6.7.1.2.1" class="ltx_text">dataset</span></th>
<th id="S4.T4.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" colspan="3">Adaptation</th>
<th id="S4.T4.6.7.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3">Generalization</th>
</tr>
<tr id="S4.T4.6.8.2" class="ltx_tr">
<th id="S4.T4.6.8.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">line-items</th>
<th id="S4.T4.6.8.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">others</th>
<th id="S4.T4.6.8.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">line-items</th>
<th id="S4.T4.6.8.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">others</th>
</tr>
<tr id="S4.T4.6.6" class="ltx_tr">
<th id="S4.T4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">body <math id="S4.T4.1.1.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T4.1.1.1.m1.1a"><msub id="S4.T4.1.1.1.m1.1.1" xref="S4.T4.1.1.1.m1.1.1.cmml"><mi id="S4.T4.1.1.1.m1.1.1.2" xref="S4.T4.1.1.1.m1.1.1.2.cmml">F</mi><mn id="S4.T4.1.1.1.m1.1.1.3" xref="S4.T4.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.1.1.1.m1.1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T4.1.1.1.m1.1.1.2.cmml" xref="S4.T4.1.1.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T4.1.1.1.m1.1.1.3.cmml" xref="S4.T4.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T4.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">header <math id="S4.T4.2.2.2.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T4.2.2.2.m1.1a"><msub id="S4.T4.2.2.2.m1.1.1" xref="S4.T4.2.2.2.m1.1.1.cmml"><mi id="S4.T4.2.2.2.m1.1.1.2" xref="S4.T4.2.2.2.m1.1.1.2.cmml">F</mi><mn id="S4.T4.2.2.2.m1.1.1.3" xref="S4.T4.2.2.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.m1.1b"><apply id="S4.T4.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.2.2.2.m1.1.1.1.cmml" xref="S4.T4.2.2.2.m1.1.1">subscript</csymbol><ci id="S4.T4.2.2.2.m1.1.1.2.cmml" xref="S4.T4.2.2.2.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T4.2.2.2.m1.1.1.3.cmml" xref="S4.T4.2.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T4.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">micro <math id="S4.T4.3.3.3.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T4.3.3.3.m1.1a"><msub id="S4.T4.3.3.3.m1.1.1" xref="S4.T4.3.3.3.m1.1.1.cmml"><mi id="S4.T4.3.3.3.m1.1.1.2" xref="S4.T4.3.3.3.m1.1.1.2.cmml">F</mi><mn id="S4.T4.3.3.3.m1.1.1.3" xref="S4.T4.3.3.3.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.m1.1b"><apply id="S4.T4.3.3.3.m1.1.1.cmml" xref="S4.T4.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.3.3.3.m1.1.1.1.cmml" xref="S4.T4.3.3.3.m1.1.1">subscript</csymbol><ci id="S4.T4.3.3.3.m1.1.1.2.cmml" xref="S4.T4.3.3.3.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T4.3.3.3.m1.1.1.3.cmml" xref="S4.T4.3.3.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">body <math id="S4.T4.4.4.4.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T4.4.4.4.m1.1a"><msub id="S4.T4.4.4.4.m1.1.1" xref="S4.T4.4.4.4.m1.1.1.cmml"><mi id="S4.T4.4.4.4.m1.1.1.2" xref="S4.T4.4.4.4.m1.1.1.2.cmml">F</mi><mn id="S4.T4.4.4.4.m1.1.1.3" xref="S4.T4.4.4.4.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.m1.1b"><apply id="S4.T4.4.4.4.m1.1.1.cmml" xref="S4.T4.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.4.4.4.m1.1.1.1.cmml" xref="S4.T4.4.4.4.m1.1.1">subscript</csymbol><ci id="S4.T4.4.4.4.m1.1.1.2.cmml" xref="S4.T4.4.4.4.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T4.4.4.4.m1.1.1.3.cmml" xref="S4.T4.4.4.4.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T4.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">header <math id="S4.T4.5.5.5.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T4.5.5.5.m1.1a"><msub id="S4.T4.5.5.5.m1.1.1" xref="S4.T4.5.5.5.m1.1.1.cmml"><mi id="S4.T4.5.5.5.m1.1.1.2" xref="S4.T4.5.5.5.m1.1.1.2.cmml">F</mi><mn id="S4.T4.5.5.5.m1.1.1.3" xref="S4.T4.5.5.5.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.m1.1b"><apply id="S4.T4.5.5.5.m1.1.1.cmml" xref="S4.T4.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.5.5.5.m1.1.1.1.cmml" xref="S4.T4.5.5.5.m1.1.1">subscript</csymbol><ci id="S4.T4.5.5.5.m1.1.1.2.cmml" xref="S4.T4.5.5.5.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T4.5.5.5.m1.1.1.3.cmml" xref="S4.T4.5.5.5.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.m1.1c">F_{1}</annotation></semantics></math>
</th>
<th id="S4.T4.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">micro <math id="S4.T4.6.6.6.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S4.T4.6.6.6.m1.1a"><msub id="S4.T4.6.6.6.m1.1.1" xref="S4.T4.6.6.6.m1.1.1.cmml"><mi id="S4.T4.6.6.6.m1.1.1.2" xref="S4.T4.6.6.6.m1.1.1.2.cmml">F</mi><mn id="S4.T4.6.6.6.m1.1.1.3" xref="S4.T4.6.6.6.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.m1.1b"><apply id="S4.T4.6.6.6.m1.1.1.cmml" xref="S4.T4.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.6.6.6.m1.1.1.1.cmml" xref="S4.T4.6.6.6.m1.1.1">subscript</csymbol><ci id="S4.T4.6.6.6.m1.1.1.2.cmml" xref="S4.T4.6.6.6.m1.1.1.2">𝐹</ci><cn type="integer" id="S4.T4.6.6.6.m1.1.1.3.cmml" xref="S4.T4.6.6.6.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.m1.1c">F_{1}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.6.9.1" class="ltx_tr">
<td id="S4.T4.6.9.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt"><span id="S4.T4.6.9.1.1.1" class="ltx_text ltx_font_bold">complete model (all outputs)</span></td>
<td id="S4.T4.6.9.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T4.6.9.1.2.1" class="ltx_text ltx_font_bold">small</span></td>
<td id="S4.T4.6.9.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T4.6.9.1.3.1" class="ltx_text ltx_font_bold">0.9738</span></td>
<td id="S4.T4.6.9.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T4.6.9.1.4.1" class="ltx_text ltx_font_bold">0.9967</span></td>
<td id="S4.T4.6.9.1.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S4.T4.6.9.1.5.1" class="ltx_text ltx_font_bold">0.8790</span></td>
<td id="S4.T4.6.9.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.9389</td>
<td id="S4.T4.6.9.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T4.6.9.1.7.1" class="ltx_text ltx_font_bold">0.9864</span></td>
<td id="S4.T4.6.9.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.6650</td>
</tr>
<tr id="S4.T4.6.10.2" class="ltx_tr">
<td id="S4.T4.6.10.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">only line-items</td>
<td id="S4.T4.6.10.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">small</td>
<td id="S4.T4.6.10.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9027</td>
<td id="S4.T4.6.10.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9950</td>
<td id="S4.T4.6.10.2.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">N/A</td>
<td id="S4.T4.6.10.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.8762</td>
<td id="S4.T4.6.10.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9766</td>
<td id="S4.T4.6.10.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
</tr>
<tr id="S4.T4.6.11.3" class="ltx_tr">
<td id="S4.T4.6.11.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">no line-item header</td>
<td id="S4.T4.6.11.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">small</td>
<td id="S4.T4.6.11.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9736</td>
<td id="S4.T4.6.11.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T4.6.11.3.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.8777</td>
<td id="S4.T4.6.11.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.6.11.3.6.1" class="ltx_text ltx_font_bold">0.9394</span></td>
<td id="S4.T4.6.11.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T4.6.11.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.6.11.3.8.1" class="ltx_text ltx_font_bold">0.6731</span></td>
</tr>
<tr id="S4.T4.6.12.4" class="ltx_tr">
<td id="S4.T4.6.12.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">all but line-items</td>
<td id="S4.T4.6.12.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">small</td>
<td id="S4.T4.6.12.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T4.6.12.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T4.6.12.4.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.8632</td>
<td id="S4.T4.6.12.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T4.6.12.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T4.6.12.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.6247</td>
</tr>
<tr id="S4.T4.6.13.5" class="ltx_tr">
<td id="S4.T4.6.13.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">complete model (other than line-items targets)</td>
<td id="S4.T4.6.13.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">big</td>
<td id="S4.T4.6.13.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T4.6.13.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T4.6.13.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t">0.8487</td>
<td id="S4.T4.6.13.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T4.6.13.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T4.6.13.5.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We have found a fully trainable method for table detection and content
understanding in structured documents, that is able to detect a specific
line-item table and extract only some information from other tables
even in the presence of imbalanced classes and multiple layouts, languages
and invoice types. Anonymized version of our dataset was published,
as no similar dataset has been publicly available to date.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Trying to detect line-item headers in a single model did lead the
model to underperform, with a hint to use focal loss for such task.
Also, we have discovered, that attention module was important to generalization
for new invoice types, while using only close neighbours did lead
to better adaptation on already seen layouts.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">The system’s ability to correctly scale to completely new invoice
types is successfully verified for the line-item table detection task
at 93% and measured to be 66% on 35 ’other’ classes.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">Future work can include line-item table extractions, architecture
and hyperparameter tuning for bigger datasets, experiments with the
usage of different text features or embeddings and image augmentations.
It could be also measured how many annotations are needed for the
’other’ classes to adapt onto new invoice types.</p>
</div>
</section>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Acknowlegment</h2>

<div id="Ax1.p1" class="ltx_para">
<p id="Ax1.p1.1" class="ltx_p">The work was supported by the grant SVV-2017-260455. We would also like to thank to the annotation
team and the rest of the research team.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
M. Göbel, T. Hassan, E. Oro, and G. Orsi, “Icdar 2013 table competition,”
in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Document Analysis and Recognition (ICDAR), 2013 12th International
Conference on</em>.   IEEE, 2013, pp.
1449–1453.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Jahan Mac and R. G. Ragel, “Locating Tables in Scanned Documents for
Reconstructing and Republishing (ICIAfS14),” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, p.
arXiv:1412.7689, Dec. 2014.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
T. Dhiran and R. Sharma, “Table detection and extraction from image
document,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer &amp; Organization Trends</em>,
vol. 3, no. 7, pp. 275–278, 2013.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S. Mandal, S. Chowdhury, A. K. Das, and B. Chanda, “A very efficient table
detection system from document images.” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ICVGIP</em>, 2004, pp.
411–416.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
B. Gatos, D. Danatsas, I. Pratikakis, and S. J. Perantonis, “Automatic table
detection in document images,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">International Conference on Pattern
Recognition and Image Analysis</em>.   Springer, 2005, pp. 609–618.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
A. Gupta, D. Tiwari, T. Khurana, and S. Das, <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Table Detection and Metadata
Extraction in Document Images: Proceedings of ICSICCS-2018</em>, 01 2019, pp.
361–372.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Y. Liu, “Tableseer: automatic table extraction, search, and understanding,”
2009.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
W. Farrukh, A. Foncubierta, A.-N. Ciubotaru, G. Jaume, C. Bejas, O. Goksel, and
M. Gabrani, “Interpreting data from scanned tables,” 11 2017, pp. 5–6.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
N. Pether and T. Macdonald, “Robust pdf table locator,” 2016.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
N. Miloševic, “A multi-layered approach to information extraction from
tables in biomedical documents,” 2018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
A. Tengli, Y. Yang, and N. L. Ma, “Learning table extraction from examples,”
in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th international conference on Computational
Linguistics</em>.   Association for
Computational Linguistics, 2004, p. 987.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
X. Chu, Y. He, K. Chakrabarti, and K. Ganjam, “Tegra: Table extraction by
global record alignment,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2015 ACM SIGMOD
International Conference on Management of Data</em>, ser. SIGMOD ’15.   New York, NY, USA: ACM, 2015, pp. 1713–1728.
[Online]. Available: <a target="_blank" href="http://doi.acm.org/10.1145/2723372.2723725" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://doi.acm.org/10.1145/2723372.2723725</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
H. T. Ng, C. Y. Lim, and J. L. T. Koo, “Learning to recognize tables in free
text,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 37th Annual Meeting of the Association
for Computational Linguistics on Computational Linguistics</em>, ser. ACL
’99.   Stroudsburg, PA, USA: Association
for Computational Linguistics, 1999, pp. 443–450. [Online]. Available:
<a target="_blank" href="https://doi.org/10.3115/1034678.1034746" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.3115/1034678.1034746</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
C. A. Clark and S. K. Divvala, “Looking beyond text: Extracting figures,
tables and captions from computer science papers.” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">AAAI Workshop:
Scholarly Big Data</em>, 2015.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
M. Fan and D. S. Kim, “Detecting Table Region in PDF Documents Using
Distant Supervision,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, p. arXiv:1506.08891, Jun.
2015.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A. Gilani, S. Rukh Qasim, I. Malik, and F. Shafait, “Table detection using
deep learning,” 09 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
S. Schreiber, S. Agne, I. Wolf, A. Dengel, and S. Ahmed, “Deepdesrt: Deep
learning for detection and structure recognition of tables in document
images,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">2017 14th IAPR International Conference on Document
Analysis and Recognition (ICDAR)</em>, vol. 01, Nov 2017, pp. 1162–1167.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A. C. e Silva, A. Jorge, and L. Torgo, “Automatic selection of table areas in
documents for information extraction,” in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Progress in Artificial
Intelligence</em>, F. M. Pires and S. Abreu, Eds.   Berlin, Heidelberg: Springer Berlin Heidelberg, 2003, pp.
460–465.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
I. Kavasidis, S. Palazzo, C. Spampinato, C. Pino, D. Giordano, D. Giuffrida,
and P. Messina, “A saliency-based convolutional neural network for table and
chart detection in digitized documents.” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1804.06236,
2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
J. Redmon and A. Farhadi, “Yolov3: An incremental improvement,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv</em>,
2018.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
V. P. d’Andecy, E. Hartmann, and M. Rusinol, “Field extraction by hybrid
incremental and a-priori structural templates,” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">2018 13th IAPR
International Workshop on Document Analysis Systems (DAS)</em>, April 2018, pp.
251–256.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
B. Coüasnon and A. Lemaitre, <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Recognition of Tables and Forms</em>.   London: Springer London, 2014, pp. 647–677.
[Online]. Available: <a target="_blank" href="https://doi.org/10.1007/978-0-85729-859-1_20" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-0-85729-859-1_20</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
H. Hamza, Y. Belaïd, and A. Belaïd, “Case-based reasoning for invoice
analysis and recognition,” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Case-Based Reasoning Research and
Development</em>, R. O. Weber and M. M. Richter, Eds.   Berlin, Heidelberg: Springer Berlin Heidelberg, 2007, pp.
404–418.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
pdfparser. [Online]. Available: <a target="_blank" href="https://github.com/rossumai/pdfparser" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/rossumai/pdfparser</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Z. Chen, L. Huang, W. Yang, P. Meng, and H. Miao, “More than word frequencies:
Authorship attribution via natural frequency zoned word distribution
analysis,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1208.3001, 2012. [Online]. Available:
<a target="_blank" href="http://arxiv.org/abs/1208.3001" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1208.3001</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
D. Nadeau and S. Sekine, “A survey of named entity recognition and
classification,” <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Lingvisticae Investigationes</em>, vol. 30, no. 1, pp.
3–26, 2007.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A. Abbasi, H. Chen, and A. Salem, “Sentiment analysis in multiple languages:
Feature selection for opinion classification in web forums,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">ACM
Trans. Inf. Syst.</em>, vol. 26, no. 3, pp. 12:1–12:34, Jun. 2008. [Online].
Available: <a target="_blank" href="http://doi.acm.org/10.1145/1361684.1361685" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://doi.acm.org/10.1145/1361684.1361685</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
Gomez, L. Kaiser, and I. Polosukhin, “Attention Is All You Need,”
<em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, p. arXiv:1706.03762, Jun. 2017.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
R. Liu, J. Lehman, P. Molino, F. Petroski Such, E. Frank,
A. Sergeev, and J. Yosinski, “An Intriguing Failing of Convolutional
Neural Networks and the CoordConv Solution,” <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, p.
arXiv:1807.03247, Jul. 2018.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
M. Niepert, M. Ahmed, and K. Kutzkov, “Learning Convolutional Neural
Networks for Graphs,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, p. arXiv:1605.05273, May 2016.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
A. Jean-Pierre Tixier, G. Nikolentzos, P. Meladianos, and
M. Vazirgiannis, “Graph Classification with 2D Convolutional Neural
Networks,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, p. arXiv:1708.02218, Jul. 2017.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár, “Focal
Loss for Dense Object Detection,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, p.
arXiv:1708.02002, Aug. 2017.

</span>
</li>
</ul>
</section>
<figure id="tab1" class="ltx_float biography">
<table id="tab1.1" class="ltx_tabular">
<tr id="tab1.1.1" class="ltx_tr">
<td id="tab1.1.1.1" class="ltx_td">
<span id="tab1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_top ltx_framed ltx_framed_rectangle" style="width:72.3pt;">
<span id="tab1.1.1.1.1.1" class="ltx_p">Replace this box by an image with a width of 1 in and a height of
1.25 in!</span>
</span>
</td>
<td id="tab1.1.1.2" class="ltx_td">
<span id="tab1.1.1.2.1" class="ltx_inline-block">
<span id="tab1.1.1.2.1.1" class="ltx_p"><span id="tab1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Your Name</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab2" class="ltx_float biography">
<table id="tab2.1" class="ltx_tabular">
<tr id="tab2.1.1" class="ltx_tr">
<td id="tab2.1.1.1" class="ltx_td">
<span id="tab2.1.1.1.1" class="ltx_inline-block">
<span id="tab2.1.1.1.1.1" class="ltx_p"><span id="tab2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Coauthor</span> 
Same again for the co-author, but without photo</span>
</span>
</td>
</tr>
</table>
</figure><div class="ltx_rdf" about="" property="dcterms:creator" content="Your Name"></div>
<div class="ltx_rdf" about="" property="dcterms:title" content="Your Title"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/1904.12575" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1904.12577" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1904.12577">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1904.12577" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1904.12578" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 17:21:08 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
