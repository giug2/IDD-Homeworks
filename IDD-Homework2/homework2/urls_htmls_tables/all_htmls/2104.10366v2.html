<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2104.10366] Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables</title><meta property="og:description" content="Question answering from semi-structured tables can be seen as a semantic parsing task and is significant and practical for pushing the boundary of natural language understanding. Existing research mainly focuses on und…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2104.10366">

<!--Generated on Sun Mar 17 05:00:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaoyi Ruan, Meizhi Jin, Jian Ma, Haiqin Yang<sup id="id3.3.id1" class="ltx_sup"><span id="id3.3.id1.1" class="ltx_text ltx_font_italic">§</span></sup>, Lianxin Jiang, 
<br class="ltx_break"><span id="id4.4.id2" class="ltx_text ltx_font_bold">Yang Mo</span> and <span id="id5.5.id3" class="ltx_text ltx_font_bold">Mengyuan Zhou
<br class="ltx_break"></span>Ping An Life Insurance Co., Ltd. 
<br class="ltx_break">Shenzhen, Guangdong province, China 
<br class="ltx_break">{RUANXIAOYI687, EX-JINMEIZHI001, MAJIAN446, JIANGLIANXIN769, MOYANG853}@pingan.com.cn
<br class="ltx_break"><sup id="id6.6.id4" class="ltx_sup"><span id="id6.6.id4.1" class="ltx_text ltx_font_italic">§</span></sup> the corresponding author, email: hqyang@ieee.org
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">Question answering from semi-structured tables can be seen as a semantic parsing task and is significant and practical for pushing the boundary of natural language understanding. Existing research mainly focuses on understanding contents from unstructured evidence, e.g., news, natural language sentences, and documents. The task of verification from structured evidence, such as tables, charts, and databases, is still less explored. This paper describes sattiy team’s system in SemEval-2021 task 9: Statement Verification and Evidence Finding with Tables (SEM-TAB-FACT). This competition aims to verify statements and to find evidence from tables for scientific articles and to promote the proper interpretation of the surrounding article. In this paper, we exploited ensemble models of pre-trained language models over tables, TaPas and TaBERT, for Task A and adjust the result based on some rules extracted for Task B. Finally, in the leaderboard, we attain the F1 scores of 0.8496 and 0.7732 in Task A for the 2-way and 3-way evaluation, respectively, and the F1 score of 0.4856 in Task B.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Semantic parsing is one of the most important tasks in natural language processing. It not only needs to understand the meaning of natural language statements, but also needs to map them to meaningful executable queries, such as logical forms, SQL queries, and Python code <cite class="ltx_cite ltx_citemacro_cite">Pan et al. (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>); Lei et al. (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>); Zhu et al. (<a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>. Question answering from semi-structured tables is usually seen as a semantic parsing task <cite class="ltx_cite ltx_citemacro_citep">(Pasupat and Liang, <a href="#bib.bib14" title="" class="ltx_ref">2015</a>)</cite>, where questions are translated into logical forms that can be executed against the table to retrieve the correct denotation <cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a href="#bib.bib21" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Practically, it is significant in natural language understanding to verify whether a textual hypothesis is entailed or refuted by evidence <cite class="ltx_cite ltx_citemacro_cite">Benthem (<a href="#bib.bib1" title="" class="ltx_ref">2008</a>); D. et al. (<a href="#bib.bib4" title="" class="ltx_ref">1978</a>)</cite>. The verification problem has been extensively studied in different natural language tasks, such as natural language inference (NLI) <cite class="ltx_cite ltx_citemacro_cite">Bowman et al. (<a href="#bib.bib2" title="" class="ltx_ref">2015</a>)</cite>, claim verification <cite class="ltx_cite ltx_citemacro_citep">(Hanselowski et al., <a href="#bib.bib7" title="" class="ltx_ref">2018</a>)</cite>, recognizing of textual entailment (RTE) <cite class="ltx_cite ltx_citemacro_citep">(Dagan et al., <a href="#bib.bib5" title="" class="ltx_ref">2005</a>)</cite>, and multi-model language reasoning (NLVR/NLVR2) <cite class="ltx_cite ltx_citemacro_citep">(Suhr et al., <a href="#bib.bib15" title="" class="ltx_ref">2018</a>)</cite>. However, existing research mainly focuses on verifying hypothesis from unstructured evidence, e.g., news, natural language sentences and documents. Research of verification under structured evidence, such as tables, charts, and databases, is still in the exploratory stage.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">This year, SemEval-2021 Task 9: Statement Verification and Evidence Finding with Tables (SEM-TAB-FACT), aims to verify statements and find evidence from tables in scientific articles <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>. It is an important task targeting at promoting proper interpretation of the surrounding article.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The competition tries to explore table understanding from two tasks:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Task A - Table Statement Support: The task aims to determine whether a statement is fully supported, refuted, or unknown to a given table.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Task B - Relevant Cell Selection: given a statement and a table, the task is to determine which cells in the table provide evidence for supporting or refuting the statement.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The competition contains the following challenges:</p>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">In task A, there is no training data for the “Unknown” category and the number of tables is small in the training set.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">The lexical expression of the table may be different from that in the statement.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">The table structure is complex and diverse. A table may contain missing values while the the supporting evidence may be resided in cells across several rows or columns.</p>
</div>
</li>
<li id="S1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I2.i4.p1" class="ltx_para">
<p id="S1.I2.i4.p1.1" class="ltx_p">It is difficult to understand the statements. For example, some statements express totally different semantics meaning with only one different word. This difficulty makes it even harder to find the evidence cells from tables.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">To overcome these challenges, we incorporate several key technologies in our implementation:</p>
<ul id="S1.I3" class="ltx_itemize">
<li id="S1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I3.i1.p1" class="ltx_para">
<p id="S1.I3.i1.p1.1" class="ltx_p">developing a systematic way to generate data from the “Unknown” category;</p>
</div>
</li>
<li id="S1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I3.i2.p1" class="ltx_para">
<p id="S1.I3.i2.p1.1" class="ltx_p">including additional data corpus to enrich the training data;</p>
</div>
</li>
<li id="S1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I3.i3.p1" class="ltx_para">
<p id="S1.I3.i3.p1.1" class="ltx_p">exploiting existing state-of-the-art pre-trained language models over tables, TaBERT <cite class="ltx_cite ltx_citemacro_cite">Yin et al. (<a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite> and TaPas <cite class="ltx_cite ltx_citemacro_cite">Yin et al. (<a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>, and ensembling them into a powerful one;</p>
</div>
</li>
<li id="S1.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I3.i4.p1" class="ltx_para">
<p id="S1.I3.i4.p1.1" class="ltx_p">aligning contents in tables and statements while constructing manual rules for tackling Task B.</p>
</div>
</li>
</ul>
<p id="S1.p6.2" class="ltx_p">The test shows that our implementation can increase the performance according and finally, in the leadboard, we attain the F1 scores of 0.8496 and 0.7732 in Task A for the 2-way and 3-way evaluation, respectively, and the F1 score of 0.4856 in Task B.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The rest of this paper is organized as follows: In Sec. 2, we briefly depict related work to our implementation. In Sec. 3, we detail our proposed system. In Sec. 4, we present the experimental setup and analyze the results. Finally, we conclude our work in Sec. 5.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<table id="S1.T1.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S1.T1.3.4.1" class="ltx_tr">
<td id="S1.T1.3.4.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S1.T1.3.4.1.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S1.T1.3.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S1.T1.3.4.1.3.1" class="ltx_text">Tables</span></td>
<td id="S1.T1.3.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Label Distribution</td>
<td id="S1.T1.3.4.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Tokens in Statements</td>
<td id="S1.T1.3.4.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Tokens in Tables</td>
</tr>
<tr id="S1.T1.3.5.2" class="ltx_tr">
<td id="S1.T1.3.5.2.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S1.T1.3.5.2.2" class="ltx_td ltx_border_r"></td>
<td id="S1.T1.3.5.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Entailed/Refuted/Unknown</td>
<td id="S1.T1.3.5.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Max./Min./Avg.</td>
<td id="S1.T1.3.5.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Max./Min./Avg.</td>
</tr>
<tr id="S1.T1.3.6.3" class="ltx_tr">
<td id="S1.T1.3.6.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S1.T1.3.6.3.1.1" class="ltx_text">Train</span></td>
<td id="S1.T1.3.6.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Task 9</td>
<td id="S1.T1.3.6.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">981</td>
<td id="S1.T1.3.6.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2,818/1,688/0</td>
<td id="S1.T1.3.6.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88/3/11</td>
<td id="S1.T1.3.6.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">302/1/10</td>
</tr>
<tr id="S1.T1.3.7.4" class="ltx_tr">
<td id="S1.T1.3.7.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Tabfact</td>
<td id="S1.T1.3.7.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16,573</td>
<td id="S1.T1.3.7.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63,962/54,313/0</td>
<td id="S1.T1.3.7.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57/4/14</td>
<td id="S1.T1.3.7.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">127/5/13</td>
</tr>
<tr id="S1.T1.3.8.5" class="ltx_tr">
<td id="S1.T1.3.8.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Augm.</td>
<td id="S1.T1.3.8.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">17,554</td>
<td id="S1.T1.3.8.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">66,780/56,001/61,436</td>
<td id="S1.T1.3.8.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88/3/12</td>
<td id="S1.T1.3.8.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">302/1/11</td>
</tr>
<tr id="S1.T1.1.1" class="ltx_tr">
<td id="S1.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Dev.</td>
<td id="S1.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S1.T1.1.1.1.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S1.T1.1.1.1.m1.1a"><mo id="S1.T1.1.1.1.m1.1.1" xref="S1.T1.1.1.1.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.m1.1b"><minus id="S1.T1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.1.1.1.m1.1c">-</annotation></semantics></math></td>
<td id="S1.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">52</td>
<td id="S1.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">250/213/93</td>
<td id="S1.T1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">53/4/13</td>
<td id="S1.T1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">115/2/11</td>
</tr>
<tr id="S1.T1.3.3" class="ltx_tr">
<td id="S1.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Test</td>
<td id="S1.T1.2.2.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S1.T1.2.2.1.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S1.T1.2.2.1.m1.1a"><mo id="S1.T1.2.2.1.m1.1.1" xref="S1.T1.2.2.1.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S1.T1.2.2.1.m1.1b"><minus id="S1.T1.2.2.1.m1.1.1.cmml" xref="S1.T1.2.2.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.2.2.1.m1.1c">-</annotation></semantics></math></td>
<td id="S1.T1.3.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">52</td>
<td id="S1.T1.3.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S1.T1.3.3.2.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S1.T1.3.3.2.m1.1a"><mo id="S1.T1.3.3.2.m1.1.1" xref="S1.T1.3.3.2.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S1.T1.3.3.2.m1.1b"><minus id="S1.T1.3.3.2.m1.1.1.cmml" xref="S1.T1.3.3.2.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.3.3.2.m1.1c">-</annotation></semantics></math></td>
<td id="S1.T1.3.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">82/4/12</td>
<td id="S1.T1.3.3.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">69/2/11</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Data statistics.</figcaption>
</figure>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2104.10366/assets/figure1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="628" height="495" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Ensemble architecture</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Recently, pre-trained language models (PLMs), e.g., BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite>, XLNET <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib18" title="" class="ltx_ref">2019</a>)</cite>, and RoBERTa <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite>, have witnessed the burgeoning of promoting various downstream NLP tasks, such as reading comprehension, named entity recognition and text classification <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>); Lei et al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>. However, the current pretrained language models are basically trained on the general text. They are not fit for some tasks, e.g., Text-to-SQL, Table-to-Text, which need to encode the structured data, because the data in the structured table also needs to be encoded at the same time. Directly applying the existing PLMs may face the problem of inconsistency between the encoded text from the table and the pretrained text.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">TaBERT<cite class="ltx_cite ltx_citemacro_citep">(Yin et al., <a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite> is a newly proposed pretrained model built on top of BERT and jointly learns contextual representations for utterances and the structured schema of database (DB) tables. This model views the verification task completely as an NLI problem by linearizing a table as a premise sentence and applies PLMs to encode both the table and statements into distributed representation for classification. This model excels at linguistic reasoning like paraphrasing and inference but lacks symbolic reasoning skills. Intuitively, encoding more table contents, e.g., type information and content snapshots, relevant to the input utterance could potentially help answer questions that involve reasoning over information across multiple rows in the table because they can provide more hints about the meaning of a column. TaPas <cite class="ltx_cite ltx_citemacro_citep">(Herzig et al., <a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite> is another newly proposed pretrained question answering model over tables implemented on BERT to avoid generating the logical forms. The model can fine-tune on semantic parsing datasets, only using weak supervision, with an end-to-end differentiable recipe.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Another stream of work on evidence finding with table is the rule-based approaches. Most evidence cells can be extracted by rules. For example, if a row head or column head appears in the statement, we infer this row or col support this statement. Although rule-based approaches suffer from the low recall issue, they exhibit high precision and can be applied to adjust the result for ensemble.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>System Overview</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We elaborate the task and present our system in the following.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data Description and Tasks</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In Task A, the original dataset is a set of XML files, where each XML file represents a table and contains multiple sections:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">document</span> section represents the whole document;</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">table</span> section determines the unique ID of the document;</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">caption</span> section is a brief description of the table;</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">legend</span> section is a detailed description of the table;</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p"><span id="S3.I1.i5.p1.1.1" class="ltx_text ltx_font_italic">multiple row</span> sections describe the contents of each row of the table; and</p>
</div>
</li>
<li id="S3.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S3.I1.i6.p1" class="ltx_para">
<p id="S3.I1.i6.p1.1" class="ltx_p"><span id="S3.I1.i6.p1.1.1" class="ltx_text ltx_font_italic">statements</span> section provides several factual statements.</p>
</div>
</li>
</ul>
<p id="S3.SS1.p1.2" class="ltx_p">This task aims to determine if a statement is entailed or refuted by the given table, or whether, as is in some cases, this cannot be determined from the table. The competition also provides two kinds of evaluations for the task:</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p">3-way F1 score evaluation: a standard precision/recall evaluation (3-way) is computed to evaluates whether each table is correctly classified into one of the three types in {Entailed, Refuted, Unknown}. It is to test whether the classification algorithm understands cases where there is insufficient information to make a determination.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">2-way F1 score evaluation: the F1 score is computed to evaluate the performance when the statements with the “unknown” ground truth label are removed. The metric will also penalize misclassifying Refuted/Entailed statement as unknown.</p>
</div>
</li>
</ul>
<p id="S3.SS1.p1.3" class="ltx_p">In the evaluation, the score for all statements in each table is first averaged and then averaged across all tables to get the final F1 score.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">In Task B, the raw dataset is a subset of task A, where unknown statements are excluded. The goal is to determine for each cell and each statement, if the <span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_italic">cell is within the minimum set of cells</span> needed to provide evidence for the statement “relevant” or “irrelevant”. For some statements, there may be multiple minimal sets of cells that can be used to determine statement entailment or refusal. In such cases, the ground truth will contain all of the versions. The evaluation will calculate the recall and precision for each cell, with “relevant” cells as the positive category. The evaluation is conducted similarly as that in Task A.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data Augmentation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">There are mainly two critical issues in Task A. First, the number of the tables is small. We then include more external data, the TabFact dataset <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite> to improve the generalization of our proposed system. Second and more critically, “unknown” statements do not exist in the training set but may appear in the test set. To allow our system to output the “unknown” category, we construct additional “unknown” statements to enrich the training set. More specifically, we randomly select some statements from other tables and assign them to the “unknown” category for the current table. In order to keep balance on the labels, the number of selected statements from other tables is set to half of the statements in the current table. Details about the data statistics can be referred to Table <a href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Model Ensemble for Task A</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Figure 1 outlines the overall structure of our system, which is an ensemble of two main pretrained models on table-based data, TaBERT and TaPas, or two variants of TaBERT and four variants of TaPas. It is worth noting that the input of all models are the same. That is, given a statement and a table, the input is started with the sentence token, [CLS], followed by the sequence of the tokens in the statement, the segmentation token ([SEP]), and the sequence of the tokens in the flattened table. All the tokens in the statement and the table are extracted by wordpiece as in BERT and related NLP tasks <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib6" title="" class="ltx_ref">2019</a>); Yang (<a href="#bib.bib17" title="" class="ltx_ref">2019</a>); <span class="ltx_ref ltx_missing_citation ltx_ref_self">conf/ijcai/PHED21</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">conf/ijcnn/EDM21</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">conf/ijcnn/RefBERT21</span></cite>. The flattened table means that we borrow the implementation in TaBERT by only extracting the most likely content snapshot as detailed in Sec. 3.4. The obtained tokens’ embeddings are then fed into six strong baselines, i.e., two variants of TaBERT and four variants of TaPas, to attain the classification scores for the corresponding labels. The classification scores are then concatenated and fed into a vote layer, i.e., a fully-connected network, to yield the final prediction. 
</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Models</span></th>
<th id="S3.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Original data</span></th>
<th id="S3.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">+TabFact</span></th>
<th id="S3.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.4.1" class="ltx_text ltx_font_bold">+Augm.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.2.1" class="ltx_tr">
<td id="S3.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">TaBERT_1</td>
<td id="S3.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.7446/0.6580</td>
<td id="S3.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.7634/0.6837</td>
<td id="S3.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.8003/0.7502</td>
</tr>
<tr id="S3.T2.1.3.2" class="ltx_tr">
<td id="S3.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">TaBERT_3</td>
<td id="S3.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">0.7689/0.6792</td>
<td id="S3.T2.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">
<span id="S3.T2.1.3.2.3.1" class="ltx_text ltx_font_bold">0.7952</span>/0.7008</td>
<td id="S3.T2.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.1.3.2.4.1" class="ltx_text ltx_font_bold">0.8241/0.7653</span></td>
</tr>
<tr id="S3.T2.1.4.3" class="ltx_tr">
<td id="S3.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">TaPas_TFIMLR</td>
<td id="S3.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">0.7502/0.6637</td>
<td id="S3.T2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r">0.7859/0.6799</td>
<td id="S3.T2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r">0.8102/0.7649</td>
</tr>
<tr id="S3.T2.1.5.4" class="ltx_tr">
<td id="S3.T2.1.5.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">TaPas_WSIMLR</td>
<td id="S3.T2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r">0.7498/0.6522</td>
<td id="S3.T2.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r">0.7852/0.7005</td>
<td id="S3.T2.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r">0.8024/0.7577</td>
</tr>
<tr id="S3.T2.1.6.5" class="ltx_tr">
<td id="S3.T2.1.6.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">TaPas_IMLR</td>
<td id="S3.T2.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r">0.7538/0.6358</td>
<td id="S3.T2.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r">0.7799/0.6890</td>
<td id="S3.T2.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r">0.7908/0.7396</td>
</tr>
<tr id="S3.T2.1.7.6" class="ltx_tr">
<td id="S3.T2.1.7.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r">TaPas_WSMLR</td>
<td id="S3.T2.1.7.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T2.1.7.6.2.1" class="ltx_text ltx_font_bold">0.7695/0.6875</span></td>
<td id="S3.T2.1.7.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.7904/<span id="S3.T2.1.7.6.3.1" class="ltx_text ltx_font_bold">0.7058</span>
</td>
<td id="S3.T2.1.7.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.8156/0.7609</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of strong baselines in Task A for 2-way and 3-way evaluation.</figcaption>
</figure>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<th id="S3.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Models</span></th>
<th id="S3.T3.1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">+TabFact</span></th>
<th id="S3.T3.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">+Augm.</span></th>
<th id="S3.T3.1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T3.1.1.1.4.1" class="ltx_text ltx_font_bold">+Rule</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.1.2.1" class="ltx_tr">
<td id="S3.T3.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">TaBERT_1</td>
<td id="S3.T3.1.2.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">0.4025</td>
<td id="S3.T3.1.2.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">0.4159</td>
<td id="S3.T3.1.2.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">0.4605</td>
</tr>
<tr id="S3.T3.1.3.2" class="ltx_tr">
<td id="S3.T3.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">TaBERT_3</td>
<td id="S3.T3.1.3.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4158</td>
<td id="S3.T3.1.3.2.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4305</td>
<td id="S3.T3.1.3.2.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4685</td>
</tr>
<tr id="S3.T3.1.4.3" class="ltx_tr">
<td id="S3.T3.1.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">TaPas_TFIMLR</td>
<td id="S3.T3.1.4.3.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4253</td>
<td id="S3.T3.1.4.3.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4299</td>
<td id="S3.T3.1.4.3.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4597</td>
</tr>
<tr id="S3.T3.1.5.4" class="ltx_tr">
<td id="S3.T3.1.5.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">TaPas_WSIMLR</td>
<td id="S3.T3.1.5.4.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4199</td>
<td id="S3.T3.1.5.4.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4208</td>
<td id="S3.T3.1.5.4.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4682</td>
</tr>
<tr id="S3.T3.1.6.5" class="ltx_tr">
<td id="S3.T3.1.6.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">TaPas_IMLR</td>
<td id="S3.T3.1.6.5.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4006</td>
<td id="S3.T3.1.6.5.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4102</td>
<td id="S3.T3.1.6.5.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">0.4467</td>
</tr>
<tr id="S3.T3.1.7.6" class="ltx_tr">
<td id="S3.T3.1.7.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r">TaPas_WSMLR</td>
<td id="S3.T3.1.7.6.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T3.1.7.6.2.1" class="ltx_text ltx_font_bold">0.4258</span></td>
<td id="S3.T3.1.7.6.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T3.1.7.6.3.1" class="ltx_text ltx_font_bold">0.4386</span></td>
<td id="S3.T3.1.7.6.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T3.1.7.6.4.1" class="ltx_text ltx_font_bold">0.4708</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison of strong baselines in Task B.</figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Content Snapshot</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.8" class="ltx_p">In order to pin point the important rows and avoid excessively encode input from the table, we borrow the idea of content snapshot in TaBERT <cite class="ltx_cite ltx_citemacro_cite">Yin et al. (<a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite> to encode only a few rows that are most relevant to the statement. We create the content snapshot of <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mi id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">K</annotation></semantics></math> rows based on the following simple strategy. First, we count the number of rows of each table and find their median, say <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mi id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><ci id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">R</annotation></semantics></math>. If the number of rows in the current table is less than or equal to <math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><mi id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">R</annotation></semantics></math>, then <math id="S3.SS4.p1.4.m4.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p1.4.m4.1a"><mi id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><ci id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">K</annotation></semantics></math> is set to the total number of rows in the current table and the content snapshot is the entire content of the current table. If the number of rows in the current table is greater than <math id="S3.SS4.p1.5.m5.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS4.p1.5.m5.1a"><mi id="S3.SS4.p1.5.m5.1.1" xref="S3.SS4.p1.5.m5.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m5.1b"><ci id="S3.SS4.p1.5.m5.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m5.1c">R</annotation></semantics></math>, we set <math id="S3.SS4.p1.6.m6.1" class="ltx_Math" alttext="K=R" display="inline"><semantics id="S3.SS4.p1.6.m6.1a"><mrow id="S3.SS4.p1.6.m6.1.1" xref="S3.SS4.p1.6.m6.1.1.cmml"><mi id="S3.SS4.p1.6.m6.1.1.2" xref="S3.SS4.p1.6.m6.1.1.2.cmml">K</mi><mo id="S3.SS4.p1.6.m6.1.1.1" xref="S3.SS4.p1.6.m6.1.1.1.cmml">=</mo><mi id="S3.SS4.p1.6.m6.1.1.3" xref="S3.SS4.p1.6.m6.1.1.3.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.6.m6.1b"><apply id="S3.SS4.p1.6.m6.1.1.cmml" xref="S3.SS4.p1.6.m6.1.1"><eq id="S3.SS4.p1.6.m6.1.1.1.cmml" xref="S3.SS4.p1.6.m6.1.1.1"></eq><ci id="S3.SS4.p1.6.m6.1.1.2.cmml" xref="S3.SS4.p1.6.m6.1.1.2">𝐾</ci><ci id="S3.SS4.p1.6.m6.1.1.3.cmml" xref="S3.SS4.p1.6.m6.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.6.m6.1c">K=R</annotation></semantics></math> and select the top-<math id="S3.SS4.p1.7.m7.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS4.p1.7.m7.1a"><mi id="S3.SS4.p1.7.m7.1.1" xref="S3.SS4.p1.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.7.m7.1b"><ci id="S3.SS4.p1.7.m7.1.1.cmml" xref="S3.SS4.p1.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.7.m7.1c">K</annotation></semantics></math> row with the highest overlap rate between the statement and each row of <math id="S3.SS4.p1.8.m8.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS4.p1.8.m8.1a"><mi id="S3.SS4.p1.8.m8.1.1" xref="S3.SS4.p1.8.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.8.m8.1b"><ci id="S3.SS4.p1.8.m8.1.1.cmml" xref="S3.SS4.p1.8.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.8.m8.1c">n</annotation></semantics></math>-grams as the candidate rows.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Rule Construction for Task B</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">For Task B, we apply the same model trained in Task A to find whether the current table supports the statement. If yes, we label all cells as entailed. Otherwise, we first align the word expression in tables and statements while building the corresponding rules to adjust the model prediction. That is, we change uppercase to lowercase and transform all abbreviations into the full name in statements, cells, col heads and row heads. We also conduct stemming on all words. For example, “definition” and “defined” is transformed to “define”. After that, we collect all words in a statement into a word bag and determine the supporting relation based on the following rules: 1) If a word in the word bag appears in a row head, we then infer that cells in the whole column supports the statement; 2)If a word appears in the first column of the table, we then infer that cells in the whole row supports the statement; 3) If a word appears in both a row head and a cell in the first column of a table, we then infer that the cell corresponding to the row and column supports the statement; 4) If a word appears in a cell, we then infer that this cell supports the statement.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In the following, we present the strong baselines and the results with analysis.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.2" class="ltx_p">We have tried different combinations of TaBERT and TaPas pre-trained models and choose the following 6 best baselines: 1) TaBERT_1: the pre-trained TaBERT with <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="K=1" display="inline"><semantics id="S4.p2.1.m1.1a"><mrow id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml"><mi id="S4.p2.1.m1.1.1.2" xref="S4.p2.1.m1.1.1.2.cmml">K</mi><mo id="S4.p2.1.m1.1.1.1" xref="S4.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.p2.1.m1.1.1.3" xref="S4.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><apply id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1"><eq id="S4.p2.1.m1.1.1.1.cmml" xref="S4.p2.1.m1.1.1.1"></eq><ci id="S4.p2.1.m1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.2">𝐾</ci><cn type="integer" id="S4.p2.1.m1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">K=1</annotation></semantics></math>; 2) TaBERT_3: the pre-trained TaBERT with <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="K=3" display="inline"><semantics id="S4.p2.2.m2.1a"><mrow id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mi id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">K</mi><mo id="S4.p2.2.m2.1.1.1" xref="S4.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><eq id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1"></eq><ci id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">𝐾</ci><cn type="integer" id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">K=3</annotation></semantics></math>; 3) TaPas_TFIMLR: the pre-trained large TaPas downloaded from tapas_tabfact_inter_masklm_large_reset.zip; 4) TaPas_WSIMLR: the pre-trained large TaPas downloaded from tapas_wikisql_sqa_inter_masklm_large_reset.zip; 5) TaPas_IMLR: the pre-trained large TaPas downloaded from tapas_inter_masklm_large_reset.zip; 6) TaPas_WSMLR: the pre-trained large TaPas downloaded from tapas_wikisql_sqa_masklm_large_reset.zip.
Our proposed system is funetuned on the above models for the original training data, the original data with the TabFact data, and the augmentation data. We also tune the hyper parameters to fit a better result in the local test dataset.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Table <a href="#S3.T2" title="Table 2 ‣ 3.3 Model Ensemble for Task A ‣ 3 System Overview ‣ Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> reports the evaluation results of Task A on the development set when funetuning the above six strong baselines on different training data. The results show that the TaPas_WSMLR attains the best performance on the original data. The best performance is further improved from 0.7695 to 0.7952 for 2-way evaluation and from 0.6875 to 0.7058 for 3-way evaluation, respectively, by including the TabFact data. The performance is further improved to 0.8241 for 2-way evaluation and 0.7653 for 3-way evaluation, respectively, by adding the augmentation data. Finally, we apply the voting mechanism to ensemble the results and achieve the F1 scores of 0.8496 and 0.7732 on the test set, respectively.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">Table <a href="#S3.T3" title="Table 3 ‣ 3.3 Model Ensemble for Task A ‣ 3 System Overview ‣ Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> reports the results of Task B on the development set when funetuning the above six strong baselines on different training data. The results show that the TaPas_WSMLR attains the best performance among all six strong baselines and the perform increases from 0.4258 after adding the TabFact data, to 0.4386 after adding the augmentation data, and to 0.4708, additional 7.3% improvement after adding the manual rules. We conjecture that TaPas_WSMLR can provide more complementary information for solving the task. Finally, we ensemble the results by the voting mechanism and achieve the F1 score of 0.4856 on the test set.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">In sum, results in Table <a href="#S3.T2" title="Table 2 ‣ 3.3 Model Ensemble for Task A ‣ 3 System Overview ‣ Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and Table <a href="#S3.T3" title="Table 3 ‣ 3.3 Model Ensemble for Task A ‣ 3 System Overview ‣ Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> confirm the effectiveness of our proposed system by including more training data and the manual rules.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we present the implementation of our ensemble system to solve the problem of SemEval 2021 Task 9. To include more training data and resolve the issue of lacking data from the “Unknown” category in the training set, we include external corpus, the TabFact dataset, and specially construct the augmented data for the “Unknown” category. Content snapshot is also applied to reduce the encoding effort. Six pre-trained language models over tables are funetuned on the TabFact dataset and the augmented data with content snapshot tables to evaluate the corresponding performance. An ensemble mechanism is applied to get the final result. Moreover, data alignment and manual rule determination are applied to solve Task B. Finally, our system attains the F1 score of 0.8496 and 0.7732 in Task A for 2-way and 3-way evaluation, respectively, while getting the F1 score of 0.4856 in Task B.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benthem (2008)</span>
<span class="ltx_bibblock">
Jfak Van Benthem. 2008.

</span>
<span class="ltx_bibblock">A brief history of natural logic.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">London</em>, volume 55(2):339–346(8).

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowman et al. (2015)</span>
<span class="ltx_bibblock">
Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning.
2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1508.05326" title="" class="ltx_ref ltx_href">A large annotated corpus for
learning natural language inference</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1508.05326.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2020)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li,
Xiyou Zhou, and William Yang Wang. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=rkeJRhNYDH" title="" class="ltx_ref ltx_href">Tabfact: A
large-scale dataset for table-based fact verification</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">8th International Conference on Learning Representations,
ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">D. et al. (1978)</span>
<span class="ltx_bibblock">
D., C., P., Suppe, and Frederick. 1978.

</span>
<span class="ltx_bibblock">The structure of scientific theories.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">The American Journal of Psychology</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dagan et al. (2005)</span>
<span class="ltx_bibblock">
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005.

</span>
<span class="ltx_bibblock">The pascal recognising textual entailment challenge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Machine Learning Challenges, Evaluating Predictive
Uncertainty, Visual Object Classification and Recognizing Textual Entailment,
First PASCAL Machine Learning Challenges Workshop, MLCW 2005, Southampton,
UK, April 11-13, 2005, Revised Selected Papers</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/n19-1423" title="" class="ltx_ref ltx_href">BERT: pre-training of
deep bidirectional transformers for language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume
1 (Long and Short Papers)</em>, pages 4171–4186. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hanselowski et al. (2018)</span>
<span class="ltx_bibblock">
Andreas Hanselowski, Hao Zhang, Zile Li, Daniil Sorokin, Benjamin Schiller,
Claudia Schulz, and Iryna Gurevych. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1809.01479" title="" class="ltx_ref ltx_href">Ukp-athene: Multi-sentence
textual entailment for claim verification</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1809.01479.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig et al. (2020)</span>
<span class="ltx_bibblock">
Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Müller, Francesco
Piccinno, and Julian Martin Eisenschlos. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.398" title="" class="ltx_ref ltx_href">Tapas: Weakly
supervised table parsing via pre-training</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, pages
4320–4333. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et al. (2021)</span>
<span class="ltx_bibblock">
Wenqiang Lei, Yisong Miao, Runpeng Xie, Bonnie Webber, Meichun Liu, Tat-Seng
Chua, and Nancy F Chen. 2021.

</span>
<span class="ltx_bibblock">Have we solved the hard problem? it’s not easy! contextual lexical
contrast as a means to probe neural coherence.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et al. (2020)</span>
<span class="ltx_bibblock">
Wenqiang Lei, Weixin Wang, Zhixin Ma, Tian Gan, Wei Lu, Min-Yen Kan, and
Tat-Seng Chua. 2020.

</span>
<span class="ltx_bibblock">Re-examining the role of schema linking in text-to-sql.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 6943–6954.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020)</span>
<span class="ltx_bibblock">
Jiaqi Li, Ming Liu, Min-Yen Kan, Zihao Zheng, Zekun Wang, Wenqiang Lei, Ting
Liu, and Bing Qin. 2020.

</span>
<span class="ltx_bibblock">Molweni: A challenge multiparty dialogues-based machine reading
comprehension dataset with discourse structure.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on
Computational Linguistics</em>, pages 2642–2652.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2019)</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1907.11692" title="" class="ltx_ref ltx_href">Roberta: A robustly
optimized BERT pretraining approach</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1907.11692.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et al. (2019)</span>
<span class="ltx_bibblock">
Liangming Pan, Wenqiang Lei, Tat-Seng Chua, and Min-Yen Kan. 2019.

</span>
<span class="ltx_bibblock">Recent advances in neural question generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.08949</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasupat and Liang (2015)</span>
<span class="ltx_bibblock">
Panupong Pasupat and Percy Liang. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/v1/p15-1142" title="" class="ltx_ref ltx_href">Compositional semantic
parsing on semi-structured tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 53rd Annual Meeting of the Association
for Computational Linguistics and the 7th International Joint Conference on
Natural Language Processing of the Asian Federation of Natural Language
Processing, ACL 2015, July 26-31, 2015, Beijing, China, Volume 1: Long
Papers</em>, pages 1470–1480. The Association for Computer Linguistics.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suhr et al. (2018)</span>
<span class="ltx_bibblock">
Alane Suhr, Stephanie Zhou, Iris Zhang, Huajun Bai, and Yoav Artzi. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1811.00491" title="" class="ltx_ref ltx_href">A corpus for reasoning about
natural language grounded in photographs</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1811.00491.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
Nancy Xin Ru Wang, Diwakar Mahajan, Marina Danilevsky, and Sara Rosenthal.
2021.

</span>
<span class="ltx_bibblock">Semeval-2021 task 9: Fact verification and evidence finding for
tabular data in scientific documents (sem-tab-facts).

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th international workshop on semantic
evaluation (SemEval-2021)</em>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang (2019)</span>
<span class="ltx_bibblock">
Haiqin Yang. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1909.09292" title="" class="ltx_ref ltx_href">BERT meets chinese word
segmentation</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1909.09292.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2019)</span>
<span class="ltx_bibblock">
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov,
and Quoc V. Le. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1906.08237" title="" class="ltx_ref ltx_href">Xlnet: Generalized
autoregressive pretraining for language understanding</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1906.08237.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2020)</span>
<span class="ltx_bibblock">
Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.745" title="" class="ltx_ref ltx_href">Tabert:
Pretraining for joint understanding of textual and tabular data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, pages
8413–8426. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2020)</span>
<span class="ltx_bibblock">
Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2005.08314" title="" class="ltx_ref ltx_href">TaBERT: Pretraining for
Joint Understanding of Textual and Tabular Data</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, page arXiv:2005.08314.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. (2017)</span>
<span class="ltx_bibblock">
Victor Zhong, Caiming Xiong, and Richard Socher. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1709.00103" title="" class="ltx_ref ltx_href">Seq2sql: Generating
structured queries from natural language using reinforcement learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1709.00103.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2021)</span>
<span class="ltx_bibblock">
Fengbin Zhu, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria, and
Tat-Seng Chua. 2021.

</span>
<span class="ltx_bibblock">Retrieving and reading: A comprehensive survey on open-domain
question answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv: 2101.00774</em>.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2104.10365" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2104.10366" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2104.10366">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2104.10366" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2104.10367" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar 17 05:00:52 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
