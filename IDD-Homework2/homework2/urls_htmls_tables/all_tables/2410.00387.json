{
    "id_table_1": {
        "caption": "Table 1:  Comparison of all model performances for Uspanteko and Arapaho. Averaged over 5 runs. Highest scores for each model type (naive, modular) are in boldface; overall high scores underlined. Naive RAG retrieves up to 6 relevant chunks of context while Modular RAG restricts this to the top 3 chunks.",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": [
            "Over the last decade, language models have evolved rapidly, culminating in impressively domain-agnostic decoder-only models like GPT  Brown et al. ( 2020 )  and Llama 2  Touvron et al. ( 2023 ) . Although these models can be versatile in terms of being applicable to a wide variety of tasks and providing straightforward interfaces for quick inference, the fact remains that they are extremely parameter-heavy, making them difficult and expensive to train  Bender and Koller ( 2020 ) . LLMs, however, give us a unique descriptive power that can boost explainability when used in certain contexts. In this paper, we examine how LLMs can be used to make RAG-informed corrections for the task of morpheme glossing (Section  2.1 ), a crucial and time-intensive part of the workflow of documenting endangered languages. Retrieval augmented generation (RAG) incorporates an initial retrieval step, where LLMs query an external data source to gather relevant information before generating answers or text. This retrieval phase not only informs the subsequent generation process but also ensures that the responses are based on solid evidence, thereby improving the accuracy and relevance of the output. Figure  1  shows an example of one sentence from the Mayan language Uspanteko, its true and predicted morpheme glosses, and the explanations produced by our RAG pipeline.  We test and compare the efficacy of two popular LLMs - Claude 3.5 Sonnet  Anthropic ( 2024 )  and GPT-4  Achiam et al. ( 2023 ) . In our experiments, Claude-3.5-Sonnet gives the most promising outputs, with both word and morpheme-level accuracies improving significantly over baselines for Uspanteko and Arapaho.",
            "Furthermore, large language models can be prompted to explain their chain-of-thought  Wei et al. ( 2023 ) ,  an approach with immense benefits for model explainability.  Apart from correcting the output, we also generate a JSON object that contains descriptions of which  chunks were retrieved, how these chunks informed the final output, and the level of confidence the pipeline has in its final predictions.  As seen in figure  1 , the LLM-generated explanations of the results and how RAG was used to achieve them are (largely) coherent and contextually relevant.",
            "Table  1  shows results for all experimental settings, as well as the previous state-of-the-art for each language, as reported in  Ginn et al. ( 2023 ) .  The two LLM-only baselines perform well below the glossing baselines (RoBERTa and Bi-LSTM, see  3.4 ) and all other models.  For each of the two glossing baselines, we compare our naive and modular RAG models (see  3 ), separately in combination with Claude and GPT-4.  We aim to evaluate which LLM is most effective at correcting the glossing output of the smaller token classification network, given retrieved grammar excerpts. Before evaluation, we perform post-processing to correct some common punctuation errors in the LLM output.",
            "Category-type errors, where the model generates a tag instead of a lexical item, or vice versa, are most common, followed by content-type errors, which we consider true glossing errors. The error types form and specificity are those which we expect to be easily interpreted and corrected by human users; these account for roughly 19% of the errors. See Appendix  B.1  for error subtypes."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Error types and frequencies across 50 randomly-selected instances.",
        "table": "S6.T2.1",
        "footnotes": [],
        "references": [
            "Over the last decade, language models have evolved rapidly, culminating in impressively domain-agnostic decoder-only models like GPT  Brown et al. ( 2020 )  and Llama 2  Touvron et al. ( 2023 ) . Although these models can be versatile in terms of being applicable to a wide variety of tasks and providing straightforward interfaces for quick inference, the fact remains that they are extremely parameter-heavy, making them difficult and expensive to train  Bender and Koller ( 2020 ) . LLMs, however, give us a unique descriptive power that can boost explainability when used in certain contexts. In this paper, we examine how LLMs can be used to make RAG-informed corrections for the task of morpheme glossing (Section  2.1 ), a crucial and time-intensive part of the workflow of documenting endangered languages. Retrieval augmented generation (RAG) incorporates an initial retrieval step, where LLMs query an external data source to gather relevant information before generating answers or text. This retrieval phase not only informs the subsequent generation process but also ensures that the responses are based on solid evidence, thereby improving the accuracy and relevance of the output. Figure  1  shows an example of one sentence from the Mayan language Uspanteko, its true and predicted morpheme glosses, and the explanations produced by our RAG pipeline.  We test and compare the efficacy of two popular LLMs - Claude 3.5 Sonnet  Anthropic ( 2024 )  and GPT-4  Achiam et al. ( 2023 ) . In our experiments, Claude-3.5-Sonnet gives the most promising outputs, with both word and morpheme-level accuracies improving significantly over baselines for Uspanteko and Arapaho.",
            "Initial inspection of system outputs showed that, in some cases, the LLM proposes a corrected gloss that is close to the expected output without being identical, resulting in a ding to automatically-evaluated performance. For example, the model sometimes outputs  3S  when the expected tag is  3.S . We randomly select 50 instances across the two datasets and evaluate them for error types. Table  2  explains our error types and their frequency across this sample; we identify 103 errors across the 50 instances. Arapaho sentences have an average of 2.2 errors per sentence, with 1.9 for Uspanteko.",
            "We randomly select 30 instances. For each, we collect the original text, expected gloss, output of the initial glossing model, LLM-corrected output, and the complete set of explanations and retrieved grammar chunks from the RAG pipeline. A professional linguist then analyzes the number of pre-LLM errors, how many are addressed correctly/incorrectly/partially correctly, the percentage of correct morpheme explanations, the subjective quality of the RAG explanations, and the subjective quality of the retrieved grammar chunks, the latter two on a Likert scale (1-5). (Details in App.  B.2 .)"
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Manual analysis of model output, 14 Arapaho/16 Uspanteko examples. We count model corrections that are  correct ,  incorrect , and  partially correct , as well as  new errors  introduced by the corrective LLM. We also rate the average  explanation correctness  and quality of both  explanations  and  retrieved chunks . Details in Appendix C.",
        "table": "S6.T3.1",
        "footnotes": [],
        "references": [
            "Table  1  shows results for all experimental settings, as well as the previous state-of-the-art for each language, as reported in  Ginn et al. ( 2023 ) .  The two LLM-only baselines perform well below the glossing baselines (RoBERTa and Bi-LSTM, see  3.4 ) and all other models.  For each of the two glossing baselines, we compare our naive and modular RAG models (see  3 ), separately in combination with Claude and GPT-4.  We aim to evaluate which LLM is most effective at correcting the glossing output of the smaller token classification network, given retrieved grammar excerpts. Before evaluation, we perform post-processing to correct some common punctuation errors in the LLM output.",
            "The results appear in Table  3 . On average, the Uspanteko corrections are more accurate, with a similar number of new errors being introduced for both languages. Model explanations for individual morphemes are largely correct, and the chunks retrieved for Uspanteko are slightly higher quality. We note that there is a clear difference in the nature of the two grammars. The Arapaho grammar is a full and complex reference grammar, and the Uspanteko grammar is a sketch, using simpler explanations in a more compact presentation. This initial analysis suggests the need for a deeper exploration into linguistic reference materials of different types and their use in RAG.  Arapaho morphology is also significantly more complex than Uspanteko morphology, increasing the complexity of the task."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Likert scale used to score morpheme explanations provided by the corrective LLM.",
        "table": "A2.T4.1",
        "footnotes": [],
        "references": [
            "In this paper, we specifically focus on the low-resource Uspanteko and Arapaho languages (Section  4 ) as we have author-approved access to grammar resources and data for these languages. Our approach leverages the knowledge encapsulated in large models combined with these digitized grammars. In  Reid et al. ( 2024 ) , Googles Gemini team demonstrated that they could fit an entire grammar for a low-resource language (Kalamang) in a single prompt owing to the massive context window size of Gemini 1.5.",
            "Table  1  shows results for all experimental settings, as well as the previous state-of-the-art for each language, as reported in  Ginn et al. ( 2023 ) .  The two LLM-only baselines perform well below the glossing baselines (RoBERTa and Bi-LSTM, see  3.4 ) and all other models.  For each of the two glossing baselines, we compare our naive and modular RAG models (see  3 ), separately in combination with Claude and GPT-4.  We aim to evaluate which LLM is most effective at correcting the glossing output of the smaller token classification network, given retrieved grammar excerpts. Before evaluation, we perform post-processing to correct some common punctuation errors in the LLM output.",
            "We also recognize that we use sensitive language data and resources to obtain our results. All our data is part of the publicly available Sigmorphon 2023 shared task data as mentioned in section  4 , and we have permission from the producers of the two grammars to use them for research purposes. We will continue to seek express permission from communities and authors before using low-resource data and grammars for future experiments.",
            "Rate the set of explanations about how RAG was used according to their usefulness and/or correctness, using the scale in Table  4 ."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Likert scale used to score RAG explanations provided by the corrective LLM.",
        "table": "A2.T5.1",
        "footnotes": [],
        "references": [
            "For each retrieved grammar chunk, rate its quality/relevance for the example being glossed, using the scale in Table  5 . Compute the average score across all retrieved grammar chunks."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Glossing error analysis types and subtypes, together with frequencies across 50 sentences.",
        "table": "A2.T6.1",
        "footnotes": [],
        "references": [
            "In section  6  we present an analysis of the types of glossing errors made by our best model, across 50 randomly-selected sentences.  The figures presented there are for high-level error categories.  During the analysis, we consider a number of subtypes for each high-level error type.",
            "Table  6  (next page) shows the complete set of error types and subtypes, with frequencies, examples, and descriptions."
        ]
    },
    "global_footnotes": [
        "Code and data samples are available and will be released upon publication.",
        "https://sigmorphon.github.io/sharedtasks/2023/"
    ]
}