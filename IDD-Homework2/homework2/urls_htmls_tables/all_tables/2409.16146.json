{
    "id_table_1": {
        "caption": "Table 1:  Statistics of the full test sets and annotated results of answerable (A) and unanswerable (U) samples.",
        "table": "S3.T1.1",
        "footnotes": [],
        "references": [
            "However, directly applying existing RAG techniques, particularly for knowledge-intensive tasks  Thorne et al. ( 2018 ); Yang et al. ( 2018 ); Petroni et al. ( 2021 )  such as factoid question answering  Aghaebrahimian and Jurcicek ( 2016 ); Aghaebrahimian ( 2018 ) , introduces significant risks in practice.  When confronted with noisy search results, even the most advanced RAG models are prone to producing unreliable answers, often exhibiting overconfidence in these erroneous responses  Yang et al. ( 2023 ); Ren et al. ( 2023 ) .  Such unreliable answers may severely undermine the users question answering (QA) experience.  Therefore, for practical applications, especially in sensitive domains like healthcare and legal assistance, it is crucial that RAG systems confidently provide answers when they know and state I dont know when they do not, as illustrated in Figure  1 .  This calls for the investigation on the risk control issue of RAG, a core research problem we want to tackle in this work.  This approach reflects wisdom, as it involves RAG models proactively refusing to answer questions when predictions are uncertain.",
            "Answer generation.   Then, we prompt the LLM  f f f italic_f  to generate the answer  a ^ f superscript ^ a f \\hat{a}^{f} over^ start_ARG italic_a end_ARG start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT  for each question-passage pair  { q , p } q p \\{q,p\\} { italic_q , italic_p } , by feeding them as model input (prompts can be found in Appendix  C.1 ):",
            "Finally, we obtain two RC-RAG datasets, i.e., RC-TQ and RC-NQ.  The dataset statistics is shown in Table  1 .",
            "Risk control ability is dependent on the LLM ability.   We compare the performance of RC-RAG when using different LLMs as generators.  We find that risk control works better with ChatGPT than with Mistral.  Benchmark statistics (Table  1 ) show that Mistral outperforms ChatGPT on both datasets, particularly on RC-NQ.  This indicates that risk control is more effective with weaker LLMs, underscoring the necessity of risk control methods. The underlying reason is that more capable models are more confident in both their internal knowledge and retrieved results. Consequently, Mistral achieves higher coverage scores, demonstrating that stronger LLMs tend to retain answers, which is consistent with the reasons for the above results.",
            "Task difficulty has limited influence on risk control ability.   We compared the effect of RAG risk control methods on different tasks.  According to the risk and alignment scores, we find that the risk control methods perform worse in RC-NQ than in RC-TQ.  The statistics of the benchmark (Table  1 ) show that RC-NQ is significantly more difficult than RC-TQ, as both ChatGPT and Mistral have a lower percentage of answerable samples on the RC-NQ dataset.  We find that the more difficult the task to answer, the more difficult the risk control.  For coverage scores, the performance in RC-NQ is also weaker.  However, the performance in terms of carefulness scores was largely flat.  The conclusion drawn from the above phenomenon is that  the difficulty of the task has a limited effect on the ability of the risk control method to accurately identify unanswerable samples .  As the proportion of samples that cannot be answered is larger in tasks with higher difficulty, the proportion of samples (UK) that cannot be answered but are retained will also be larger, and the risk and coverage scores will be correspondingly increased."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Categorization of the RAG output.",
        "table": "S3.T2.1",
        "footnotes": [],
        "references": [
            "By combining above situations, the output of RAG would fall into one of the four folds, i.e., AK, AD, UD or UK, as shown in the Table  2 .  Specifically, AK/UK denotes the answerable/unanswerable samples with answers kept, while AD/UD denotes the answerable/unanswerable samples with answers discarded.  Noted that samples answered wrongly are labeled as unanswerable ones based on our annotation, thus there is no case of keeping the wrong answer in the answerable samples.",
            "Overview.   To achieve risk control for RAG, we propose a novel counterfactual (CF) prompting framework that assesses predictive uncertainty of RAG.  The overview is illustrated in Figure  2 , consisting of a prompting generation module, a judgment module, and a fusion module:        (i)   a prompting generation module, which utilizes counterfactual thinking to induce answer regeneration effected by two changing factors;      (ii)   a judgment module, which makes judgment based on uncertainty assessment by analyzing the effect of each changing factor on their answer; and      (iii)   a fusion module for the final judgment result.",
            "Prompting generation module.   In this work, we assume that two latent factors can affect RAG uncertainty, i.e., the quality and the usage of retrieved results.  Thus, we argue about each of them and ask for answer regeneration, respectively.  Specifically, we implement each prompt as shown in Figure  2 , where CF-quality prompt challenges the poor quality of retrieved results and CF-usage prompt challenges the improper usage.  By imagining two scenarios that challenge each factor, the model adjusts the way it gets answers depending on its confidence level."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Main results of RC-RAG on the test set of two datasets and two LLMs with dense retriever. Best results in bold and second best in underline.",
        "table": "S5.T3.8",
        "footnotes": [],
        "references": [
            "Fusion module.   We aggregate above judgment results as below.        (i)   If the two judgment results are consistent (both are  keep  or  discard ), we follow this judgment directly;      (ii)   Otherwise (one is  keep , the other is  discard ), make the final judgment according to following prompts-based strategies (prompts can be found in Appendix  C.3 ):",
            "Implementation details.   For LLMs, we call OpenAIs API 1 1 1 platform.openai.com  to achieve ChatGPT (version gpt-3.5-turbo-0301), while we choose Mistral-7b 2 2 2 huggingface.co/mistralai/Mistral-7B-Instruct-v0.2  to implement Mistral.  The max sequence length of LLM output is set to 256, and the temperature is set to 0.  All the others are set as default.  For the retrieved results, we conduct dense retrieval and sparse retrieval following  Ren et al. ( 2023 ) , and provide top-3 passages for each question following  Wang et al. ( 2023 ) .  Most of the experimental results of our method use the direct selection fusion strategy, unless otherwise stated.  More details refer to Appendix  B .  According to the analysis on the iteration number, as shown in Figure  3  in Appendix  B , we report all results derived from a single run.",
            "As shown in Table  3 , we present the performance of different RC-RAG methods on two datasets.  We have the following observations for  RQ1-3 .",
            "Details of iterative process.   The number of our iterative process  N N N italic_N  is chosen from [1,2,3,4,5].  Specifically, we explored the performance of risk control when the number of iterations increased from 1 to 5, and the experimental setting was the same as Sec.  6.3 .  The results are shown in the figure  3 , we can find that:  with the increase of iterations, risk and coverage score showed a downward trend, carefulness score increased, while the alignment index was basically flat.  In order to save the computational cost, we chose the number of iterations to be 1 to carry out the rest of our experiments."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Results of RC-RAG on the RC-NQ test set and Mistral with sparse retriever and dense retriever.",
        "table": "S5.T4.4",
        "footnotes": [],
        "references": [
            "To answer  RQ4 , we compared the performance of risk control of RAG with different retriever.  Results are shown in Table  4 , conducted on the RC-NQ test set using Mistral as a generator."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Ablation study results of RC-RAG on the subset of RC-TQ test set and ChatGPT with dense retriever.",
        "table": "S6.T5.4",
        "footnotes": [],
        "references": [
            "To answer  RQ5 , we conduct ablation study to investigate the effects of the two CF prompts separately.  The experiment was conducted on a subset of the RC-TQ test set using ChatGPT as a generator.  We used CF-quality and CF-usage separately in prompting generation module, followed by the judgement module.  The experimental results are shown in the Table  5 , from which we have the following observations."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  An example (No.135) from the RC-NQ test data, to analyze the generated answers and judgments of different risk control method for RAG.  We mark the correct judgments in red and wrong ones in blue.",
        "table": "S6.T6.1",
        "footnotes": [],
        "references": [
            "As shown in Table  6 , the RAG answer and its referred passages inaccurately address the question, yet no baseline methods reject to answer.  Our approach, while unable to detect errors when the usage of retrieved passages is challenged, recognizes their quality limitation and abstains from providing an answer.",
            "Details of iterative process.   The number of our iterative process  N N N italic_N  is chosen from [1,2,3,4,5].  Specifically, we explored the performance of risk control when the number of iterations increased from 1 to 5, and the experimental setting was the same as Sec.  6.3 .  The results are shown in the figure  3 , we can find that:  with the increase of iterations, risk and coverage score showed a downward trend, carefulness score increased, while the alignment index was basically flat.  In order to save the computational cost, we chose the number of iterations to be 1 to carry out the rest of our experiments."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  The statistics of the full test sets of RC-NQ and annotated results of answerable (A) and unanswerable (U) samples, utilizing Mistral as the generator with both sparse and dense retrievers.",
        "table": "A1.T7.1",
        "footnotes": [],
        "references": [
            "By comparing the results using different retrievers, we observe that the risk control method is more cautious with the sparse retriever in terms of carefulness.  However, the sparse retriever results in significantly more unanswerable samples than the dense retriever (Table  7  in Appendix  A ), leading to a higher risk score.  Additionally, the experimental results show that our method outperforms all baselines using both retrievers in terms of risk, carefulness, and alignment."
        ]
    },
    "id_table_8": {
        "caption": "Table 8:  Comparison results of our methods using two different fusion strategies, on the test set of two datasets and two LLMs with dense retriever. The subscripts  dir  and  pro  represent the use of direct selection strategy and probability comparison strategy, respectively.",
        "table": "A3.T8.12",
        "footnotes": [],
        "references": [
            "Fusion strategy.   The comparison results using two different fusion strategies are shown in Table  8  in Appendix  F .  Our complete approach with fusion module can effectively balance the two situations, considering both risk and coverage.  Specifically, the direct fusion strategy can identify the unanswerable samples more effectively.",
            "We show the comparison results of our methods using two different fusion strategies in Table  8 ."
        ]
    },
    "global_footnotes": [
        "platform.openai.com",
        "huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"
    ]
}