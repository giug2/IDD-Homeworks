{
    "PAPER'S NUMBER OF TABLES": 6,
    "S2.T1": {
        "caption": "Table 1: Examples of words used for filtering, based on fresh or trending terms at time of experimentation.",
        "table": "<table id=\"S2.T1.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S2.T1.2.1.1\" class=\"ltx_tr\">\n<th id=\"S2.T1.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S2.T1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Word</span></th>\n<th id=\"S2.T1.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S2.T1.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Source</span></th>\n<th id=\"S2.T1.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S2.T1.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Seen Count</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S2.T1.2.2.1\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S2.T1.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">warnock</span></td>\n<td id=\"S2.T1.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S2.T1.2.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">current events</span></td>\n<td id=\"S2.T1.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S2.T1.2.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">85</span></td>\n</tr>\n<tr id=\"S2.T1.2.3.2\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.3.2.1\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">webb</span></td>\n<td id=\"S2.T1.2.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">technology</span></td>\n<td id=\"S2.T1.2.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">48</span></td>\n</tr>\n<tr id=\"S2.T1.2.4.3\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.4.3.1\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">addams</span></td>\n<td id=\"S2.T1.2.4.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">media</span></td>\n<td id=\"S2.T1.2.4.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">38</span></td>\n</tr>\n<tr id=\"S2.T1.2.5.4\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.5.4.1\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">mbappe</span></td>\n<td id=\"S2.T1.2.5.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">sports</span></td>\n<td id=\"S2.T1.2.5.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.5.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">27</span></td>\n</tr>\n<tr id=\"S2.T1.2.6.5\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.6.5.1\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.6.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">salman</span></td>\n<td id=\"S2.T1.2.6.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">current events</span></td>\n<td id=\"S2.T1.2.6.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S2.T1.2.6.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">8</span></td>\n</tr>\n<tr id=\"S2.T1.2.7.6\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S2.T1.2.7.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">sumeru</span></td>\n<td id=\"S2.T1.2.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S2.T1.2.7.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">media</span></td>\n<td id=\"S2.T1.2.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S2.T1.2.7.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">8</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In order to target high-quality training examples, we generate a list of fresh words that are likely to be misrecognized by the model, and hence the target of legitimate user correction, rather than other edits. In the long term, this step should be automated, e.g., by aggregating over user corrections across devices through Federated Analytics [11]. Words that are corrected by a large number of users are likely to be true misrecognitions. For this work, we experiment with a manually-curated list of 241 words selected from sources such as pop culture, current events, and recent technologies. The terms vary greatly in how often they appear in on-device training examples (Fig 1), and some examples are shown in Table 1."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: In simulation, fine-tuning afforded improvement on the targeted testset (SF-LT), but degraded overall testset quality (MF + SF). Reintroducing SF + MF training data mitigated forgetting. When training was limited to the joint layer, the model was still able to improve on the targeted testset, while recovering the original WER for the overall testsets.",
        "table": "<table id=\"S4.T2.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T2.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Dataset</span></td>\n<td id=\"S4.T2.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T2.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">MF WER</span></td>\n<td id=\"S4.T2.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T2.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SF WER</span></td>\n<td id=\"S4.T2.2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T2.2.1.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SF-LT WER</span></td>\n</tr>\n<tr id=\"S4.T2.2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">MD (Baseline)</span></td>\n<td id=\"S4.T2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.7</span></td>\n<td id=\"S4.T2.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.3</span></td>\n<td id=\"S4.T2.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">45.5</span></td>\n</tr>\n<tr id=\"S4.T2.2.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"4\"><span id=\"S4.T2.2.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fine-tuning Whole Model</span></td>\n</tr>\n<tr id=\"S4.T2.2.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">SF-LT</span></td>\n<td id=\"S4.T2.2.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;color:#FF0000;\">7.8</span></td>\n<td id=\"S4.T2.2.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;color:#FF0000;\">9.3</span></td>\n<td id=\"S4.T2.2.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.4.4.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">31.4</span></td>\n</tr>\n<tr id=\"S4.T2.2.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.5.5.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.2.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">SF-LT + SF + MF</span></td>\n<td id=\"S4.T2.2.5.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.2.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;color:#FF0000;\">4.4</span></td>\n<td id=\"S4.T2.2.5.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.2.5.5.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">6.2</span></td>\n<td id=\"S4.T2.2.5.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.2.5.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">35.1</span></td>\n</tr>\n<tr id=\"S4.T2.2.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"4\"><span id=\"S4.T2.2.6.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fine-tuning Joint Layer</span></td>\n</tr>\n<tr id=\"S4.T2.2.7.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.7.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">SF-LT</span></td>\n<td id=\"S4.T2.2.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.7.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;color:#FF0000;\">6.4</span></td>\n<td id=\"S4.T2.2.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.7.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;color:#FF0000;\">8.4</span></td>\n<td id=\"S4.T2.2.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.2.7.7.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">38.1</span></td>\n</tr>\n<tr id=\"S4.T2.2.8.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.8.8.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.2.8.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">SF-LT + SF + MF</span></td>\n<td id=\"S4.T2.2.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.2.8.8.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.8</span></td>\n<td id=\"S4.T2.2.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.2.8.8.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.3</span></td>\n<td id=\"S4.T2.2.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.2.8.8.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">40.6</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As shown in Table 2, we started with a baseline trained on our multidomain dataset. By fine-tuning only on examples containing the long-tail words (SF-LT), we saw a 31% relative improvement over the baseline on the targeted testset, but observed catastrophic forgetting in the form of significant degradation on the testsets that represent the overall distribution, including over 100% regression on MF."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: In a production-like setting, both techniques were able to restore the baseline overall WER, but Static Checkpoint Averaging gave better results on the targeted testset.",
        "table": "<table id=\"S4.T3.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Setup</span></th>\n<th id=\"S4.T3.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Overall WER</span></th>\n<th id=\"S4.T3.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Targeted WER</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.2.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Baseline</span></td>\n<td id=\"S4.T3.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.2.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.4</span></td>\n<td id=\"S4.T3.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.2.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.5</span></td>\n</tr>\n<tr id=\"S4.T3.2.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.3.2.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.2.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Pure FL</span></td>\n<td id=\"S4.T3.2.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.2.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;color:#FF0000;\">4.6</span></td>\n<td id=\"S4.T3.2.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.2.3.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">16.1</span></td>\n</tr>\n<tr id=\"S4.T3.2.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.4.3.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.2.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Static Ckpt Avg</span></td>\n<td id=\"S4.T3.2.4.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.2.4.3.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4.4</span></td>\n<td id=\"S4.T3.2.4.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.2.4.3.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">16.1</span></td>\n</tr>\n<tr id=\"S4.T3.2.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.2.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Dynamic Ckpt Avg</span></td>\n<td id=\"S4.T3.2.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.2.5.4.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4.4</span></td>\n<td id=\"S4.T3.2.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.2.5.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.6</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As shown in Table 3, this approach was able improve model quality on the targeted testset, but we did observe the expected forgetting of the overall distribution. From the baseline, we saw that filtering on-device training examples to those containing targeted words allowed us to improve 8% relative on the targeted testset. However, we also saw a 4.5% regression on the overall WER, highlighting the necessity of techniques to mitigate catastrophic forgetting.",
            "Both Static Checkpoint Averaging and Dynamic Checkpoint Averaging were able to bring us back to parity on the overall distribution, while still affording improvement on the targeted distribution (Table 3). In particular, with Static Checkpoint Averaging, we were able to achieve the 8% improvement on the targeted testset from pure FL, while keeping the WER on the overall distribution from the baseline."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: After refreshing server-side training data, the baseline was much improved (3.5 WER), and regression from forgetting was much greater (20% relative). However, mixing federated and centralized training rounds restored the baseline Overall WER while keeping FL Targeted WER wins.",
        "table": "<table id=\"S4.T4.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T4.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Setup</span></th>\n<th id=\"S4.T4.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T4.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Overall WER</span></th>\n<th id=\"S4.T4.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T4.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Targeted WER</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.2.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Baseline</span></td>\n<td id=\"S4.T4.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.2.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.5</span></td>\n<td id=\"S4.T4.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.2.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.6</span></td>\n</tr>\n<tr id=\"S4.T4.2.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.3.2.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.2.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FL-only</span></td>\n<td id=\"S4.T4.2.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.2.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;color:#FF0000;\">4.4</span></td>\n<td id=\"S4.T4.2.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.2.3.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">16.1</span></td>\n</tr>\n<tr id=\"S4.T4.2.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.2.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FL + Centr. Mix</span></td>\n<td id=\"S4.T4.2.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.2.4.3.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.5</span></td>\n<td id=\"S4.T4.2.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.2.4.3.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">16.1</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "To test the technique of mixing centralized training in with the federated rounds, we first refreshed the model with more in-domain training data. This led to a much improved baseline, and a far greater regression after our targeted fine-tuning, as shown in Table 4. This 20% relative gap was greater than weight averaging techniques could address. However, once we mixed in centralized training simultaneously with the federated training rounds, we were able to achieve the best of both worlds: keep the wins on Targeted WER from targeted on-device training, while achieving the same best Overall WER from the server-only baseline."
        ]
    },
    "S4.T5": {
        "caption": "Table 5: Client Loss Weighting was able to slightly improve our already fine-tuned targeted WER from 16.1 to 16.0. Probabilistic Sampling did even better, improving our targeted WER to 15.8. The WER on the overall distribution can be restored by reintroducing checkpoint averaging.",
        "table": "<table id=\"S4.T5.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T5.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T5.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Setup</span></th>\n<th id=\"S4.T5.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T5.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Overall WER</span></th>\n<th id=\"S4.T5.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T5.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Tgt WER</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.2.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T5.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T5.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Baseline</span></td>\n<td id=\"S4.T5.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T5.2.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.4</span></td>\n<td id=\"S4.T5.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T5.2.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.5</span></td>\n</tr>\n<tr id=\"S4.T5.2.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T5.2.3.2.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Simple Fine-Tuning</span></td>\n<td id=\"S4.T5.2.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;color:#FF0000;\">4.6</span></td>\n<td id=\"S4.T5.2.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.1</span></td>\n</tr>\n<tr id=\"S4.T5.2.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T5.2.4.3.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Static Ckpt Avg</span></td>\n<td id=\"S4.T5.2.4.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.4.3.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4.4</span></td>\n<td id=\"S4.T5.2.4.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.1</span></td>\n</tr>\n<tr id=\"S4.T5.2.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T5.2.5.4.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Client Loss Weighting</span></td>\n<td id=\"S4.T5.2.5.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.5.4.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4.4</span></td>\n<td id=\"S4.T5.2.5.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.5.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.0</span></td>\n</tr>\n<tr id=\"S4.T5.2.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T5.2.6.5.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.6.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Probabilistic Sampling</span></td>\n<td id=\"S4.T5.2.6.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;color:#FF0000;\">4.6</span></td>\n<td id=\"S4.T5.2.6.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.2.6.5.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">15.8</span></td>\n</tr>\n<tr id=\"S4.T5.2.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T5.2.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.2.7.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Prob Samp + St Ckpt Avg</span></td>\n<td id=\"S4.T5.2.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.2.7.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.5</span></td>\n<td id=\"S4.T5.2.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.2.7.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.9</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As shown in Table 5, in comparison with our previous best fine-tuned result of 16.1, using Client Loss Weighting was able to give us a small improvement to 16.0. Probabilistic Sampling gave more significant wins, bringing our targeted WER down to 15.8."
        ]
    },
    "S4.T6": {
        "caption": "Table 6: Contact name recognition was improved by the above techniques. Using a names wordlist for filtering instead gave even better results, without harming the Overall WER.",
        "table": "<table id=\"S4.T6.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T6.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T6.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T6.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Setup</span></th>\n<th id=\"S4.T6.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T6.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Overall WER</span></th>\n<th id=\"S4.T6.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T6.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Contact Names WER</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T6.2.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T6.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Baseline</span></td>\n<td id=\"S4.T6.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.8</span></td>\n<td id=\"S4.T6.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.7</span></td>\n</tr>\n<tr id=\"S4.T6.2.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T6.2.3.2.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T6.2.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fresh Terms Filter</span></td>\n<td id=\"S4.T6.2.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T6.2.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.8</span></td>\n<td id=\"S4.T6.2.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T6.2.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.5</span></td>\n</tr>\n<tr id=\"S4.T6.2.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T6.2.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T6.2.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Names Filter</span></td>\n<td id=\"S4.T6.2.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T6.2.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.8</span></td>\n<td id=\"S4.T6.2.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T6.2.4.3.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">5.4</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Even using just the fresh wordlist filtering, training in FL was sufficient to improve the WER on our Contact Names testset from 5.7 to 5.5, as shown in Table 6. Though we did not target any names with our filtering, the general exposure to fresh training examples was able to improve the WER. We further improved this by replacing the wordlist with a list of the top 1000 baby names in each the US, China, and India. With this new setting, we reached 5.4 WER on the testset, a 5% relative improvement."
        ]
    }
}