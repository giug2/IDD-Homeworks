{
    "PAPER'S NUMBER OF TABLES": 3,
    "S6.T1": {
        "caption": "Table 1: Comparisons of communication rounds‚Äô while achieving differnet test accuracies results on CIFAR10 with LeNet5 model. Here, ‚Äù‚Ä¶‚Äù means that the algorithm can not be able to achieve the accuracy within FL iterations T = 100.",
        "table": "<table id=\"S6.T1.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T1.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T1.4.4.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Method</th>\n<th id=\"S6.T1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"30\\%\" display=\"inline\"><semantics id=\"S6.T1.1.1.1.m1.1a\"><mrow id=\"S6.T1.1.1.1.m1.1.1\" xref=\"S6.T1.1.1.1.m1.1.1.cmml\"><mn id=\"S6.T1.1.1.1.m1.1.1.2\" xref=\"S6.T1.1.1.1.m1.1.1.2.cmml\">30</mn><mo id=\"S6.T1.1.1.1.m1.1.1.1\" xref=\"S6.T1.1.1.1.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.1.1.1.m1.1b\"><apply id=\"S6.T1.1.1.1.m1.1.1.cmml\" xref=\"S6.T1.1.1.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T1.1.1.1.m1.1.1.1.cmml\" xref=\"S6.T1.1.1.1.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T1.1.1.1.m1.1.1.2.cmml\" xref=\"S6.T1.1.1.1.m1.1.1.2\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.1.1.1.m1.1c\">30\\%</annotation></semantics></math></th>\n<th id=\"S6.T1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"35\\%\" display=\"inline\"><semantics id=\"S6.T1.2.2.2.m1.1a\"><mrow id=\"S6.T1.2.2.2.m1.1.1\" xref=\"S6.T1.2.2.2.m1.1.1.cmml\"><mn id=\"S6.T1.2.2.2.m1.1.1.2\" xref=\"S6.T1.2.2.2.m1.1.1.2.cmml\">35</mn><mo id=\"S6.T1.2.2.2.m1.1.1.1\" xref=\"S6.T1.2.2.2.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.2.2.2.m1.1b\"><apply id=\"S6.T1.2.2.2.m1.1.1.cmml\" xref=\"S6.T1.2.2.2.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T1.2.2.2.m1.1.1.1.cmml\" xref=\"S6.T1.2.2.2.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T1.2.2.2.m1.1.1.2.cmml\" xref=\"S6.T1.2.2.2.m1.1.1.2\">35</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.2.2.2.m1.1c\">35\\%</annotation></semantics></math></th>\n<th id=\"S6.T1.3.3.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T1.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"40\\%\" display=\"inline\"><semantics id=\"S6.T1.3.3.3.m1.1a\"><mrow id=\"S6.T1.3.3.3.m1.1.1\" xref=\"S6.T1.3.3.3.m1.1.1.cmml\"><mn id=\"S6.T1.3.3.3.m1.1.1.2\" xref=\"S6.T1.3.3.3.m1.1.1.2.cmml\">40</mn><mo id=\"S6.T1.3.3.3.m1.1.1.1\" xref=\"S6.T1.3.3.3.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.3.3.3.m1.1b\"><apply id=\"S6.T1.3.3.3.m1.1.1.cmml\" xref=\"S6.T1.3.3.3.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T1.3.3.3.m1.1.1.1.cmml\" xref=\"S6.T1.3.3.3.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T1.3.3.3.m1.1.1.2.cmml\" xref=\"S6.T1.3.3.3.m1.1.1.2\">40</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.3.3.3.m1.1c\">40\\%</annotation></semantics></math></th>\n<th id=\"S6.T1.4.4.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T1.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"45\\%\" display=\"inline\"><semantics id=\"S6.T1.4.4.4.m1.1a\"><mrow id=\"S6.T1.4.4.4.m1.1.1\" xref=\"S6.T1.4.4.4.m1.1.1.cmml\"><mn id=\"S6.T1.4.4.4.m1.1.1.2\" xref=\"S6.T1.4.4.4.m1.1.1.2.cmml\">45</mn><mo id=\"S6.T1.4.4.4.m1.1.1.1\" xref=\"S6.T1.4.4.4.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.4.4.4.m1.1b\"><apply id=\"S6.T1.4.4.4.m1.1.1.cmml\" xref=\"S6.T1.4.4.4.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T1.4.4.4.m1.1.1.1.cmml\" xref=\"S6.T1.4.4.4.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T1.4.4.4.m1.1.1.2.cmml\" xref=\"S6.T1.4.4.4.m1.1.1.2\">45</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.4.4.4.m1.1c\">45\\%</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T1.4.5.1\" class=\"ltx_tr\">\n<td id=\"S6.T1.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S6.T1.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\">FAGH</span></td>\n<td id=\"S6.T1.4.5.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">18</td>\n<td id=\"S6.T1.4.5.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">29</td>\n<td id=\"S6.T1.4.5.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">43</td>\n<td id=\"S6.T1.4.5.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">78</td>\n</tr>\n<tr id=\"S6.T1.4.6.2\" class=\"ltx_tr\">\n<td id=\"S6.T1.4.6.2.1\" class=\"ltx_td ltx_align_left\">FedGA</td>\n<td id=\"S6.T1.4.6.2.2\" class=\"ltx_td ltx_align_left\">23</td>\n<td id=\"S6.T1.4.6.2.3\" class=\"ltx_td ltx_align_left\">54</td>\n<td id=\"S6.T1.4.6.2.4\" class=\"ltx_td ltx_align_left\">96</td>\n<td id=\"S6.T1.4.6.2.5\" class=\"ltx_td ltx_align_left\">‚Ä¶</td>\n</tr>\n<tr id=\"S6.T1.4.7.3\" class=\"ltx_tr\">\n<td id=\"S6.T1.4.7.3.1\" class=\"ltx_td ltx_align_left\">SCAFFOLD</td>\n<td id=\"S6.T1.4.7.3.2\" class=\"ltx_td ltx_align_left\">38</td>\n<td id=\"S6.T1.4.7.3.3\" class=\"ltx_td ltx_align_left\">66</td>\n<td id=\"S6.T1.4.7.3.4\" class=\"ltx_td ltx_align_left\">‚Ä¶</td>\n<td id=\"S6.T1.4.7.3.5\" class=\"ltx_td ltx_align_left\">‚Ä¶</td>\n</tr>\n<tr id=\"S6.T1.4.8.4\" class=\"ltx_tr\">\n<td id=\"S6.T1.4.8.4.1\" class=\"ltx_td ltx_align_left ltx_border_b\">FedExP</td>\n<td id=\"S6.T1.4.8.4.2\" class=\"ltx_td ltx_align_left ltx_border_b\">24</td>\n<td id=\"S6.T1.4.8.4.3\" class=\"ltx_td ltx_align_left ltx_border_b\">48</td>\n<td id=\"S6.T1.4.8.4.4\" class=\"ltx_td ltx_align_left ltx_border_b\">97</td>\n<td id=\"S6.T1.4.8.4.5\" class=\"ltx_td ltx_align_left ltx_border_b\">‚Ä¶</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To validate our proposed method, we conduct extensive experiments on heterogeneously partitioned CIFAR10 ",
                "Krizhevsky ",
                "et al.",
                " (",
                "2009",
                ")",
                ", FashionMNIST ",
                "Xiao ",
                "et al.",
                " (",
                "2017",
                ")",
                " and EMNIST-letters ",
                "Cohen ",
                "et al.",
                " (",
                "2017",
                ")",
                " datasets.\nCIFAR10 comprises color images (",
                "3",
                "√ó",
                "32",
                "√ó",
                "32",
                "3",
                "32",
                "32",
                "3\\times 32\\times 32",
                ") of 10 classes with total 60000 samples (50000 training samples and 10000 test sample). FashionMNIST comprises grayscale images (",
                "1",
                "√ó",
                "28",
                "√ó",
                "28",
                "1",
                "28",
                "28",
                "1\\times 28\\times 28",
                ") of 10 classes with total 60000 samples (50000 training samples and 10000 test sample). EMNIST-letters comprises grayscale images (",
                "1",
                "√ó",
                "28",
                "√ó",
                "28",
                "1",
                "28",
                "28",
                "1\\times 28\\times 28",
                " pixels) of handwritten uppercase and lowercase letters, divided into 26 classes. EMNIST-letters includes a total of 145,600 samples, with 124,800 for training and 20,800 for testing. To create heterogeneous data partitions for CIFAR10 and FashionMNIST datasets, we use the same Dirichlet distribution based heterogeneous and unbalanced partition strategy as mentioned in the papers of ",
                "Yurochkin ",
                "et al.",
                " and ",
                "Wang ",
                "et al.",
                ". We simulate ",
                "P",
                "i",
                "‚àº",
                "D",
                "‚Äã",
                "i",
                "‚Äã",
                "r",
                "K",
                "‚Äã",
                "(",
                "0.2",
                ")",
                "similar-to",
                "subscript",
                "ùëÉ",
                "ùëñ",
                "ùê∑",
                "ùëñ",
                "subscript",
                "ùëü",
                "ùêæ",
                "0.2",
                "P_{i}\\sim Dir_{K}(0.2)",
                " and find a heterogeneous partition by allocating a ",
                "P",
                "(",
                "i",
                ",",
                "j",
                ")",
                "subscript",
                "ùëÉ",
                "ùëñ",
                "ùëó",
                "P_{(i,j)}",
                " proportion of the samples of ",
                "i",
                "t",
                "‚Äã",
                "h",
                "superscript",
                "ùëñ",
                "ùë°",
                "‚Ñé",
                "i^{th}",
                " class to ",
                "j",
                "t",
                "‚Äã",
                "h",
                "superscript",
                "ùëó",
                "ùë°",
                "‚Ñé",
                "j^{th}",
                " client. As we use very small value of Dirichlet distribution‚Äôs concentration parameter (0.2), each client may not get samples of all the classes, which indicates a high degree of data heterogeneity across all the clients. For our experiments, we use K=200 clients. For EMNIST dataset, we utilizes similar partitioning strategy used in the paper of ",
                "McMahan ",
                "et al.",
                ", where the data has been sorted with the class label and then distributed. We create 400 shards of size 312 and assign 2 shards to each of the 200 clients.",
                "For CIFAR10 image classification, we use LeNet5 model ",
                "LeCun and others (",
                "2015",
                ")",
                ". For FashionMNIST, we use a custom convolutional neural network (CNN) model (total 1475338 trainable parameters) with two convolutional layers and three fully connected layers. After each convolutional layer, we use batch normalization, ReLU activation and max-pooling. After first fully connected layer, we use a dropout of 0.25. For EMNIST-letters, we use multinomial logistic regression (MLR) model. For all the federated image classification tasks, we use crossentropy loss function.",
                "We compare our algorithm with existing state-of-the-art federated learning algorithms such as SCAFFOLD, FedGA, FedExP, GIANT and DONE. To consider partial device participation in FL, we use ",
                "40",
                "%",
                "percent",
                "40",
                "40\\%",
                " of total client‚Äôs participation in each communication round. We do extensive experiments with a wide set of hyper-parameters for all the methods and find the best performing model for each method by considering minimum training ",
                "&",
                "\\&",
                " test losses and maximum test accuracy. We use FedGA ",
                "Œ≤",
                "ùõΩ",
                "\\beta",
                ", FAGH ",
                "œÅ",
                "ùúå",
                "\\rho",
                " and FedExP ",
                "œµ",
                "italic-œµ",
                "\\epsilon",
                " ",
                "‚àà",
                "{",
                "1",
                ",",
                "0.5",
                ",",
                "0.1",
                ",",
                "0.01",
                ",",
                "0.001",
                "}",
                "absent",
                "1",
                "0.5",
                "0.1",
                "0.01",
                "0.001",
                "\\in\\{1,0.5,0.1,0.01,0.001\\}",
                ", learning rate ",
                "Œ∑",
                "‚àà",
                "{",
                "1",
                ",",
                "0.5",
                ",",
                "0.1",
                ",",
                "0.01",
                ",",
                "0.001",
                ",",
                "0.0001",
                "}",
                "ùúÇ",
                "1",
                "0.5",
                "0.1",
                "0.01",
                "0.001",
                "0.0001",
                "\\eta\\in\\{1,0.5,0.1,0.01,0.001,0.0001\\}",
                ", FAGH ",
                "Œ≤",
                "1",
                "=",
                "0.9",
                "subscript",
                "ùõΩ",
                "1",
                "0.9",
                "\\beta_{1}=0.9",
                " ",
                "&",
                "\\&",
                " ",
                "Œ≤",
                "2",
                "=",
                "0.99",
                "subscript",
                "ùõΩ",
                "2",
                "0.99",
                "\\beta_{2}=0.99",
                ", number of Rechardson iterations for DONE=10, number of CG iterations for GIANT = 10 and ",
                "Œ±",
                "D",
                "‚Äã",
                "O",
                "‚Äã",
                "N",
                "‚Äã",
                "E",
                "‚àà",
                "{",
                "0.01",
                ",",
                "0.05",
                "}",
                "subscript",
                "ùõº",
                "ùê∑",
                "ùëÇ",
                "ùëÅ",
                "ùê∏",
                "0.01",
                "0.05",
                "\\alpha_{DONE}\\in\\{0.01,0.05\\}",
                ". For FedExP, we use SGD with momentum (0.9) optimizer for finding local updates.\nWe use total number of communication rounds T=100. We implement all the methods using Tesla V100 GPU and PyTorch1.12.1+cu102. we use seed=0 and batch size = 512. For each dataset, we use same initialization and same settings for all the existing and proposed methods.",
                "We compare our algorithm with DONE and GIANT in MLR based classification task. We tried to compare our algorithm with DONE and GIANT in CNN based classification tasks . But unfortunately, we did not find suitable hyperparameters for DONE and GIANT for this CNN based implementation. This may be due to their assumption of strongly convex loss function."
            ]
        ]
    },
    "S6.T2": {
        "caption": "Table 2: Comparisons of communication rounds‚Äô while achieving differnet test accuracies results on FashionMNIST with CNN model. Here, ‚Äù‚Ä¶‚Äù means that the algorithm can not be able to achieve the accuracy within FL iterations T = 100.",
        "table": "<table id=\"S6.T2.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T2.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T2.4.4.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Method</th>\n<th id=\"S6.T2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"60\\%\" display=\"inline\"><semantics id=\"S6.T2.1.1.1.m1.1a\"><mrow id=\"S6.T2.1.1.1.m1.1.1\" xref=\"S6.T2.1.1.1.m1.1.1.cmml\"><mn id=\"S6.T2.1.1.1.m1.1.1.2\" xref=\"S6.T2.1.1.1.m1.1.1.2.cmml\">60</mn><mo id=\"S6.T2.1.1.1.m1.1.1.1\" xref=\"S6.T2.1.1.1.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.1.1.1.m1.1b\"><apply id=\"S6.T2.1.1.1.m1.1.1.cmml\" xref=\"S6.T2.1.1.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T2.1.1.1.m1.1.1.1.cmml\" xref=\"S6.T2.1.1.1.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T2.1.1.1.m1.1.1.2.cmml\" xref=\"S6.T2.1.1.1.m1.1.1.2\">60</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.1.1.1.m1.1c\">60\\%</annotation></semantics></math></th>\n<th id=\"S6.T2.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"70\\%\" display=\"inline\"><semantics id=\"S6.T2.2.2.2.m1.1a\"><mrow id=\"S6.T2.2.2.2.m1.1.1\" xref=\"S6.T2.2.2.2.m1.1.1.cmml\"><mn id=\"S6.T2.2.2.2.m1.1.1.2\" xref=\"S6.T2.2.2.2.m1.1.1.2.cmml\">70</mn><mo id=\"S6.T2.2.2.2.m1.1.1.1\" xref=\"S6.T2.2.2.2.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.2.2.2.m1.1b\"><apply id=\"S6.T2.2.2.2.m1.1.1.cmml\" xref=\"S6.T2.2.2.2.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T2.2.2.2.m1.1.1.1.cmml\" xref=\"S6.T2.2.2.2.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T2.2.2.2.m1.1.1.2.cmml\" xref=\"S6.T2.2.2.2.m1.1.1.2\">70</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.2.2.2.m1.1c\">70\\%</annotation></semantics></math></th>\n<th id=\"S6.T2.3.3.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T2.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"80\\%\" display=\"inline\"><semantics id=\"S6.T2.3.3.3.m1.1a\"><mrow id=\"S6.T2.3.3.3.m1.1.1\" xref=\"S6.T2.3.3.3.m1.1.1.cmml\"><mn id=\"S6.T2.3.3.3.m1.1.1.2\" xref=\"S6.T2.3.3.3.m1.1.1.2.cmml\">80</mn><mo id=\"S6.T2.3.3.3.m1.1.1.1\" xref=\"S6.T2.3.3.3.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.3.3.3.m1.1b\"><apply id=\"S6.T2.3.3.3.m1.1.1.cmml\" xref=\"S6.T2.3.3.3.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T2.3.3.3.m1.1.1.1.cmml\" xref=\"S6.T2.3.3.3.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T2.3.3.3.m1.1.1.2.cmml\" xref=\"S6.T2.3.3.3.m1.1.1.2\">80</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.3.3.3.m1.1c\">80\\%</annotation></semantics></math></th>\n<th id=\"S6.T2.4.4.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T2.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"85\\%\" display=\"inline\"><semantics id=\"S6.T2.4.4.4.m1.1a\"><mrow id=\"S6.T2.4.4.4.m1.1.1\" xref=\"S6.T2.4.4.4.m1.1.1.cmml\"><mn id=\"S6.T2.4.4.4.m1.1.1.2\" xref=\"S6.T2.4.4.4.m1.1.1.2.cmml\">85</mn><mo id=\"S6.T2.4.4.4.m1.1.1.1\" xref=\"S6.T2.4.4.4.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.4.4.4.m1.1b\"><apply id=\"S6.T2.4.4.4.m1.1.1.cmml\" xref=\"S6.T2.4.4.4.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T2.4.4.4.m1.1.1.1.cmml\" xref=\"S6.T2.4.4.4.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T2.4.4.4.m1.1.1.2.cmml\" xref=\"S6.T2.4.4.4.m1.1.1.2\">85</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.4.4.4.m1.1c\">85\\%</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T2.4.5.1\" class=\"ltx_tr\">\n<td id=\"S6.T2.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S6.T2.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\">FAGH</span></td>\n<td id=\"S6.T2.4.5.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">7</td>\n<td id=\"S6.T2.4.5.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">14</td>\n<td id=\"S6.T2.4.5.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">36</td>\n<td id=\"S6.T2.4.5.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">71</td>\n</tr>\n<tr id=\"S6.T2.4.6.2\" class=\"ltx_tr\">\n<td id=\"S6.T2.4.6.2.1\" class=\"ltx_td ltx_align_left\">FedGA</td>\n<td id=\"S6.T2.4.6.2.2\" class=\"ltx_td ltx_align_left\">7</td>\n<td id=\"S6.T2.4.6.2.3\" class=\"ltx_td ltx_align_left\">12</td>\n<td id=\"S6.T2.4.6.2.4\" class=\"ltx_td ltx_align_left\">46</td>\n<td id=\"S6.T2.4.6.2.5\" class=\"ltx_td ltx_align_left\">‚Ä¶</td>\n</tr>\n<tr id=\"S6.T2.4.7.3\" class=\"ltx_tr\">\n<td id=\"S6.T2.4.7.3.1\" class=\"ltx_td ltx_align_left\">SCAFFOLD</td>\n<td id=\"S6.T2.4.7.3.2\" class=\"ltx_td ltx_align_left\">13</td>\n<td id=\"S6.T2.4.7.3.3\" class=\"ltx_td ltx_align_left\">35</td>\n<td id=\"S6.T2.4.7.3.4\" class=\"ltx_td ltx_align_left\">‚Ä¶</td>\n<td id=\"S6.T2.4.7.3.5\" class=\"ltx_td ltx_align_left\">‚Ä¶</td>\n</tr>\n<tr id=\"S6.T2.4.8.4\" class=\"ltx_tr\">\n<td id=\"S6.T2.4.8.4.1\" class=\"ltx_td ltx_align_left ltx_border_b\">FedExP</td>\n<td id=\"S6.T2.4.8.4.2\" class=\"ltx_td ltx_align_left ltx_border_b\">8</td>\n<td id=\"S6.T2.4.8.4.3\" class=\"ltx_td ltx_align_left ltx_border_b\">18</td>\n<td id=\"S6.T2.4.8.4.4\" class=\"ltx_td ltx_align_left ltx_border_b\">‚Ä¶</td>\n<td id=\"S6.T2.4.8.4.5\" class=\"ltx_td ltx_align_left ltx_border_b\">‚Ä¶</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To validate our proposed method, we conduct extensive experiments on heterogeneously partitioned CIFAR10 ",
                "Krizhevsky ",
                "et al.",
                " (",
                "2009",
                ")",
                ", FashionMNIST ",
                "Xiao ",
                "et al.",
                " (",
                "2017",
                ")",
                " and EMNIST-letters ",
                "Cohen ",
                "et al.",
                " (",
                "2017",
                ")",
                " datasets.\nCIFAR10 comprises color images (",
                "3",
                "√ó",
                "32",
                "√ó",
                "32",
                "3",
                "32",
                "32",
                "3\\times 32\\times 32",
                ") of 10 classes with total 60000 samples (50000 training samples and 10000 test sample). FashionMNIST comprises grayscale images (",
                "1",
                "√ó",
                "28",
                "√ó",
                "28",
                "1",
                "28",
                "28",
                "1\\times 28\\times 28",
                ") of 10 classes with total 60000 samples (50000 training samples and 10000 test sample). EMNIST-letters comprises grayscale images (",
                "1",
                "√ó",
                "28",
                "√ó",
                "28",
                "1",
                "28",
                "28",
                "1\\times 28\\times 28",
                " pixels) of handwritten uppercase and lowercase letters, divided into 26 classes. EMNIST-letters includes a total of 145,600 samples, with 124,800 for training and 20,800 for testing. To create heterogeneous data partitions for CIFAR10 and FashionMNIST datasets, we use the same Dirichlet distribution based heterogeneous and unbalanced partition strategy as mentioned in the papers of ",
                "Yurochkin ",
                "et al.",
                " and ",
                "Wang ",
                "et al.",
                ". We simulate ",
                "P",
                "i",
                "‚àº",
                "D",
                "‚Äã",
                "i",
                "‚Äã",
                "r",
                "K",
                "‚Äã",
                "(",
                "0.2",
                ")",
                "similar-to",
                "subscript",
                "ùëÉ",
                "ùëñ",
                "ùê∑",
                "ùëñ",
                "subscript",
                "ùëü",
                "ùêæ",
                "0.2",
                "P_{i}\\sim Dir_{K}(0.2)",
                " and find a heterogeneous partition by allocating a ",
                "P",
                "(",
                "i",
                ",",
                "j",
                ")",
                "subscript",
                "ùëÉ",
                "ùëñ",
                "ùëó",
                "P_{(i,j)}",
                " proportion of the samples of ",
                "i",
                "t",
                "‚Äã",
                "h",
                "superscript",
                "ùëñ",
                "ùë°",
                "‚Ñé",
                "i^{th}",
                " class to ",
                "j",
                "t",
                "‚Äã",
                "h",
                "superscript",
                "ùëó",
                "ùë°",
                "‚Ñé",
                "j^{th}",
                " client. As we use very small value of Dirichlet distribution‚Äôs concentration parameter (0.2), each client may not get samples of all the classes, which indicates a high degree of data heterogeneity across all the clients. For our experiments, we use K=200 clients. For EMNIST dataset, we utilizes similar partitioning strategy used in the paper of ",
                "McMahan ",
                "et al.",
                ", where the data has been sorted with the class label and then distributed. We create 400 shards of size 312 and assign 2 shards to each of the 200 clients.",
                "For CIFAR10 image classification, we use LeNet5 model ",
                "LeCun and others (",
                "2015",
                ")",
                ". For FashionMNIST, we use a custom convolutional neural network (CNN) model (total 1475338 trainable parameters) with two convolutional layers and three fully connected layers. After each convolutional layer, we use batch normalization, ReLU activation and max-pooling. After first fully connected layer, we use a dropout of 0.25. For EMNIST-letters, we use multinomial logistic regression (MLR) model. For all the federated image classification tasks, we use crossentropy loss function.",
                "We compare our algorithm with existing state-of-the-art federated learning algorithms such as SCAFFOLD, FedGA, FedExP, GIANT and DONE. To consider partial device participation in FL, we use ",
                "40",
                "%",
                "percent",
                "40",
                "40\\%",
                " of total client‚Äôs participation in each communication round. We do extensive experiments with a wide set of hyper-parameters for all the methods and find the best performing model for each method by considering minimum training ",
                "&",
                "\\&",
                " test losses and maximum test accuracy. We use FedGA ",
                "Œ≤",
                "ùõΩ",
                "\\beta",
                ", FAGH ",
                "œÅ",
                "ùúå",
                "\\rho",
                " and FedExP ",
                "œµ",
                "italic-œµ",
                "\\epsilon",
                " ",
                "‚àà",
                "{",
                "1",
                ",",
                "0.5",
                ",",
                "0.1",
                ",",
                "0.01",
                ",",
                "0.001",
                "}",
                "absent",
                "1",
                "0.5",
                "0.1",
                "0.01",
                "0.001",
                "\\in\\{1,0.5,0.1,0.01,0.001\\}",
                ", learning rate ",
                "Œ∑",
                "‚àà",
                "{",
                "1",
                ",",
                "0.5",
                ",",
                "0.1",
                ",",
                "0.01",
                ",",
                "0.001",
                ",",
                "0.0001",
                "}",
                "ùúÇ",
                "1",
                "0.5",
                "0.1",
                "0.01",
                "0.001",
                "0.0001",
                "\\eta\\in\\{1,0.5,0.1,0.01,0.001,0.0001\\}",
                ", FAGH ",
                "Œ≤",
                "1",
                "=",
                "0.9",
                "subscript",
                "ùõΩ",
                "1",
                "0.9",
                "\\beta_{1}=0.9",
                " ",
                "&",
                "\\&",
                " ",
                "Œ≤",
                "2",
                "=",
                "0.99",
                "subscript",
                "ùõΩ",
                "2",
                "0.99",
                "\\beta_{2}=0.99",
                ", number of Rechardson iterations for DONE=10, number of CG iterations for GIANT = 10 and ",
                "Œ±",
                "D",
                "‚Äã",
                "O",
                "‚Äã",
                "N",
                "‚Äã",
                "E",
                "‚àà",
                "{",
                "0.01",
                ",",
                "0.05",
                "}",
                "subscript",
                "ùõº",
                "ùê∑",
                "ùëÇ",
                "ùëÅ",
                "ùê∏",
                "0.01",
                "0.05",
                "\\alpha_{DONE}\\in\\{0.01,0.05\\}",
                ". For FedExP, we use SGD with momentum (0.9) optimizer for finding local updates.\nWe use total number of communication rounds T=100. We implement all the methods using Tesla V100 GPU and PyTorch1.12.1+cu102. we use seed=0 and batch size = 512. For each dataset, we use same initialization and same settings for all the existing and proposed methods.",
                "We compare our algorithm with DONE and GIANT in MLR based classification task. We tried to compare our algorithm with DONE and GIANT in CNN based classification tasks . But unfortunately, we did not find suitable hyperparameters for DONE and GIANT for this CNN based implementation. This may be due to their assumption of strongly convex loss function."
            ]
        ]
    },
    "S6.T3": {
        "caption": "Table 3: Comparisons of communication rounds‚Äô while achieving differnet test accuracies results on EMNIST with MLR model. Here, ‚Äù‚Ä¶‚Äù means that the algorithm can not be able to achieve the accuracy within FL iterations T = 100.",
        "table": "<table id=\"S6.T3.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T3.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T3.4.4.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Method</th>\n<th id=\"S6.T3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"40\\%\" display=\"inline\"><semantics id=\"S6.T3.1.1.1.m1.1a\"><mrow id=\"S6.T3.1.1.1.m1.1.1\" xref=\"S6.T3.1.1.1.m1.1.1.cmml\"><mn id=\"S6.T3.1.1.1.m1.1.1.2\" xref=\"S6.T3.1.1.1.m1.1.1.2.cmml\">40</mn><mo id=\"S6.T3.1.1.1.m1.1.1.1\" xref=\"S6.T3.1.1.1.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.1.1.1.m1.1b\"><apply id=\"S6.T3.1.1.1.m1.1.1.cmml\" xref=\"S6.T3.1.1.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T3.1.1.1.m1.1.1.1.cmml\" xref=\"S6.T3.1.1.1.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T3.1.1.1.m1.1.1.2.cmml\" xref=\"S6.T3.1.1.1.m1.1.1.2\">40</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.1.1.1.m1.1c\">40\\%</annotation></semantics></math></th>\n<th id=\"S6.T3.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T3.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"50\\%\" display=\"inline\"><semantics id=\"S6.T3.2.2.2.m1.1a\"><mrow id=\"S6.T3.2.2.2.m1.1.1\" xref=\"S6.T3.2.2.2.m1.1.1.cmml\"><mn id=\"S6.T3.2.2.2.m1.1.1.2\" xref=\"S6.T3.2.2.2.m1.1.1.2.cmml\">50</mn><mo id=\"S6.T3.2.2.2.m1.1.1.1\" xref=\"S6.T3.2.2.2.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.2.2.2.m1.1b\"><apply id=\"S6.T3.2.2.2.m1.1.1.cmml\" xref=\"S6.T3.2.2.2.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T3.2.2.2.m1.1.1.1.cmml\" xref=\"S6.T3.2.2.2.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T3.2.2.2.m1.1.1.2.cmml\" xref=\"S6.T3.2.2.2.m1.1.1.2\">50</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.2.2.2.m1.1c\">50\\%</annotation></semantics></math></th>\n<th id=\"S6.T3.3.3.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"60\\%\" display=\"inline\"><semantics id=\"S6.T3.3.3.3.m1.1a\"><mrow id=\"S6.T3.3.3.3.m1.1.1\" xref=\"S6.T3.3.3.3.m1.1.1.cmml\"><mn id=\"S6.T3.3.3.3.m1.1.1.2\" xref=\"S6.T3.3.3.3.m1.1.1.2.cmml\">60</mn><mo id=\"S6.T3.3.3.3.m1.1.1.1\" xref=\"S6.T3.3.3.3.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.3.3.3.m1.1b\"><apply id=\"S6.T3.3.3.3.m1.1.1.cmml\" xref=\"S6.T3.3.3.3.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T3.3.3.3.m1.1.1.1.cmml\" xref=\"S6.T3.3.3.3.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T3.3.3.3.m1.1.1.2.cmml\" xref=\"S6.T3.3.3.3.m1.1.1.2\">60</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.3.3.3.m1.1c\">60\\%</annotation></semantics></math></th>\n<th id=\"S6.T3.4.4.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T3.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"65\\%\" display=\"inline\"><semantics id=\"S6.T3.4.4.4.m1.1a\"><mrow id=\"S6.T3.4.4.4.m1.1.1\" xref=\"S6.T3.4.4.4.m1.1.1.cmml\"><mn id=\"S6.T3.4.4.4.m1.1.1.2\" xref=\"S6.T3.4.4.4.m1.1.1.2.cmml\">65</mn><mo id=\"S6.T3.4.4.4.m1.1.1.1\" xref=\"S6.T3.4.4.4.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.4.4.4.m1.1b\"><apply id=\"S6.T3.4.4.4.m1.1.1.cmml\" xref=\"S6.T3.4.4.4.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T3.4.4.4.m1.1.1.1.cmml\" xref=\"S6.T3.4.4.4.m1.1.1.1\">percent</csymbol><cn type=\"integer\" id=\"S6.T3.4.4.4.m1.1.1.2.cmml\" xref=\"S6.T3.4.4.4.m1.1.1.2\">65</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.4.4.4.m1.1c\">65\\%</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T3.4.5.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S6.T3.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\">FAGH</span></td>\n<td id=\"S6.T3.4.5.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">6</td>\n<td id=\"S6.T3.4.5.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">11</td>\n<td id=\"S6.T3.4.5.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">25</td>\n<td id=\"S6.T3.4.5.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">58</td>\n</tr>\n<tr id=\"S6.T3.4.6.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.6.2.1\" class=\"ltx_td ltx_align_left\">FedGA</td>\n<td id=\"S6.T3.4.6.2.2\" class=\"ltx_td ltx_align_left\">11</td>\n<td id=\"S6.T3.4.6.2.3\" class=\"ltx_td ltx_align_left\">21</td>\n<td id=\"S6.T3.4.6.2.4\" class=\"ltx_td ltx_align_left\">46</td>\n<td id=\"S6.T3.4.6.2.5\" class=\"ltx_td ltx_align_left\">‚Ä¶</td>\n</tr>\n<tr id=\"S6.T3.4.7.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.7.3.1\" class=\"ltx_td ltx_align_left\">SCAFFOLD</td>\n<td id=\"S6.T3.4.7.3.2\" class=\"ltx_td ltx_align_left\">13</td>\n<td id=\"S6.T3.4.7.3.3\" class=\"ltx_td ltx_align_left\">23</td>\n<td id=\"S6.T3.4.7.3.4\" class=\"ltx_td ltx_align_left\">61</td>\n<td id=\"S6.T3.4.7.3.5\" class=\"ltx_td ltx_align_left\">‚Ä¶</td>\n</tr>\n<tr id=\"S6.T3.4.8.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.8.4.1\" class=\"ltx_td ltx_align_left\">FedExP</td>\n<td id=\"S6.T3.4.8.4.2\" class=\"ltx_td ltx_align_left\">11</td>\n<td id=\"S6.T3.4.8.4.3\" class=\"ltx_td ltx_align_left\">19</td>\n<td id=\"S6.T3.4.8.4.4\" class=\"ltx_td ltx_align_left\">55</td>\n<td id=\"S6.T3.4.8.4.5\" class=\"ltx_td ltx_align_left\">‚Ä¶</td>\n</tr>\n<tr id=\"S6.T3.4.9.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.9.5.1\" class=\"ltx_td ltx_align_left\">DONE</td>\n<td id=\"S6.T3.4.9.5.2\" class=\"ltx_td ltx_align_left\">7</td>\n<td id=\"S6.T3.4.9.5.3\" class=\"ltx_td ltx_align_left\">12</td>\n<td id=\"S6.T3.4.9.5.4\" class=\"ltx_td ltx_align_left\">34</td>\n<td id=\"S6.T3.4.9.5.5\" class=\"ltx_td ltx_align_left\">96</td>\n</tr>\n<tr id=\"S6.T3.4.10.6\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.10.6.1\" class=\"ltx_td ltx_align_left ltx_border_b\">GIANT</td>\n<td id=\"S6.T3.4.10.6.2\" class=\"ltx_td ltx_align_left ltx_border_b\">8</td>\n<td id=\"S6.T3.4.10.6.3\" class=\"ltx_td ltx_align_left ltx_border_b\">12</td>\n<td id=\"S6.T3.4.10.6.4\" class=\"ltx_td ltx_align_left ltx_border_b\">33</td>\n<td id=\"S6.T3.4.10.6.5\" class=\"ltx_td ltx_align_left ltx_border_b\">79</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To validate our proposed method, we conduct extensive experiments on heterogeneously partitioned CIFAR10 ",
                "Krizhevsky ",
                "et al.",
                " (",
                "2009",
                ")",
                ", FashionMNIST ",
                "Xiao ",
                "et al.",
                " (",
                "2017",
                ")",
                " and EMNIST-letters ",
                "Cohen ",
                "et al.",
                " (",
                "2017",
                ")",
                " datasets.\nCIFAR10 comprises color images (",
                "3",
                "√ó",
                "32",
                "√ó",
                "32",
                "3",
                "32",
                "32",
                "3\\times 32\\times 32",
                ") of 10 classes with total 60000 samples (50000 training samples and 10000 test sample). FashionMNIST comprises grayscale images (",
                "1",
                "√ó",
                "28",
                "√ó",
                "28",
                "1",
                "28",
                "28",
                "1\\times 28\\times 28",
                ") of 10 classes with total 60000 samples (50000 training samples and 10000 test sample). EMNIST-letters comprises grayscale images (",
                "1",
                "√ó",
                "28",
                "√ó",
                "28",
                "1",
                "28",
                "28",
                "1\\times 28\\times 28",
                " pixels) of handwritten uppercase and lowercase letters, divided into 26 classes. EMNIST-letters includes a total of 145,600 samples, with 124,800 for training and 20,800 for testing. To create heterogeneous data partitions for CIFAR10 and FashionMNIST datasets, we use the same Dirichlet distribution based heterogeneous and unbalanced partition strategy as mentioned in the papers of ",
                "Yurochkin ",
                "et al.",
                " and ",
                "Wang ",
                "et al.",
                ". We simulate ",
                "P",
                "i",
                "‚àº",
                "D",
                "‚Äã",
                "i",
                "‚Äã",
                "r",
                "K",
                "‚Äã",
                "(",
                "0.2",
                ")",
                "similar-to",
                "subscript",
                "ùëÉ",
                "ùëñ",
                "ùê∑",
                "ùëñ",
                "subscript",
                "ùëü",
                "ùêæ",
                "0.2",
                "P_{i}\\sim Dir_{K}(0.2)",
                " and find a heterogeneous partition by allocating a ",
                "P",
                "(",
                "i",
                ",",
                "j",
                ")",
                "subscript",
                "ùëÉ",
                "ùëñ",
                "ùëó",
                "P_{(i,j)}",
                " proportion of the samples of ",
                "i",
                "t",
                "‚Äã",
                "h",
                "superscript",
                "ùëñ",
                "ùë°",
                "‚Ñé",
                "i^{th}",
                " class to ",
                "j",
                "t",
                "‚Äã",
                "h",
                "superscript",
                "ùëó",
                "ùë°",
                "‚Ñé",
                "j^{th}",
                " client. As we use very small value of Dirichlet distribution‚Äôs concentration parameter (0.2), each client may not get samples of all the classes, which indicates a high degree of data heterogeneity across all the clients. For our experiments, we use K=200 clients. For EMNIST dataset, we utilizes similar partitioning strategy used in the paper of ",
                "McMahan ",
                "et al.",
                ", where the data has been sorted with the class label and then distributed. We create 400 shards of size 312 and assign 2 shards to each of the 200 clients.",
                "For CIFAR10 image classification, we use LeNet5 model ",
                "LeCun and others (",
                "2015",
                ")",
                ". For FashionMNIST, we use a custom convolutional neural network (CNN) model (total 1475338 trainable parameters) with two convolutional layers and three fully connected layers. After each convolutional layer, we use batch normalization, ReLU activation and max-pooling. After first fully connected layer, we use a dropout of 0.25. For EMNIST-letters, we use multinomial logistic regression (MLR) model. For all the federated image classification tasks, we use crossentropy loss function.",
                "We compare our algorithm with existing state-of-the-art federated learning algorithms such as SCAFFOLD, FedGA, FedExP, GIANT and DONE. To consider partial device participation in FL, we use ",
                "40",
                "%",
                "percent",
                "40",
                "40\\%",
                " of total client‚Äôs participation in each communication round. We do extensive experiments with a wide set of hyper-parameters for all the methods and find the best performing model for each method by considering minimum training ",
                "&",
                "\\&",
                " test losses and maximum test accuracy. We use FedGA ",
                "Œ≤",
                "ùõΩ",
                "\\beta",
                ", FAGH ",
                "œÅ",
                "ùúå",
                "\\rho",
                " and FedExP ",
                "œµ",
                "italic-œµ",
                "\\epsilon",
                " ",
                "‚àà",
                "{",
                "1",
                ",",
                "0.5",
                ",",
                "0.1",
                ",",
                "0.01",
                ",",
                "0.001",
                "}",
                "absent",
                "1",
                "0.5",
                "0.1",
                "0.01",
                "0.001",
                "\\in\\{1,0.5,0.1,0.01,0.001\\}",
                ", learning rate ",
                "Œ∑",
                "‚àà",
                "{",
                "1",
                ",",
                "0.5",
                ",",
                "0.1",
                ",",
                "0.01",
                ",",
                "0.001",
                ",",
                "0.0001",
                "}",
                "ùúÇ",
                "1",
                "0.5",
                "0.1",
                "0.01",
                "0.001",
                "0.0001",
                "\\eta\\in\\{1,0.5,0.1,0.01,0.001,0.0001\\}",
                ", FAGH ",
                "Œ≤",
                "1",
                "=",
                "0.9",
                "subscript",
                "ùõΩ",
                "1",
                "0.9",
                "\\beta_{1}=0.9",
                " ",
                "&",
                "\\&",
                " ",
                "Œ≤",
                "2",
                "=",
                "0.99",
                "subscript",
                "ùõΩ",
                "2",
                "0.99",
                "\\beta_{2}=0.99",
                ", number of Rechardson iterations for DONE=10, number of CG iterations for GIANT = 10 and ",
                "Œ±",
                "D",
                "‚Äã",
                "O",
                "‚Äã",
                "N",
                "‚Äã",
                "E",
                "‚àà",
                "{",
                "0.01",
                ",",
                "0.05",
                "}",
                "subscript",
                "ùõº",
                "ùê∑",
                "ùëÇ",
                "ùëÅ",
                "ùê∏",
                "0.01",
                "0.05",
                "\\alpha_{DONE}\\in\\{0.01,0.05\\}",
                ". For FedExP, we use SGD with momentum (0.9) optimizer for finding local updates.\nWe use total number of communication rounds T=100. We implement all the methods using Tesla V100 GPU and PyTorch1.12.1+cu102. we use seed=0 and batch size = 512. For each dataset, we use same initialization and same settings for all the existing and proposed methods.",
                "We compare our algorithm with DONE and GIANT in MLR based classification task. We tried to compare our algorithm with DONE and GIANT in CNN based classification tasks . But unfortunately, we did not find suitable hyperparameters for DONE and GIANT for this CNN based implementation. This may be due to their assumption of strongly convex loss function."
            ]
        ]
    }
}