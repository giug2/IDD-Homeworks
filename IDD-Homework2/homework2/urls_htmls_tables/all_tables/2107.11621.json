{
    "PAPER'S NUMBER OF TABLES": 1,
    "S1.T1": {
        "caption": "Table 1: The investigation results of recently published FL algorithms.",
        "table": "<table id=\"S1.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S1.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\">Method</th>\n<th id=\"S1.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Step <a href=\"#S1.I1.i1\" title=\"item i) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\"><span class=\"ltx_text ltx_font_italic\">i</span>)</span></a>\n</th>\n<th id=\"S1.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Step <a href=\"#S1.I1.i2\" title=\"item ii) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\"><span class=\"ltx_text ltx_font_italic\">ii</span>)</span></a>\n</th>\n<th id=\"S1.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Step <a href=\"#S1.I1.i3\" title=\"item iii) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\"><span class=\"ltx_text ltx_font_italic\">iii</span>)</span></a>\n</th>\n<th id=\"S1.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Step <a href=\"#S1.I1.i4\" title=\"item iv) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\"><span class=\"ltx_text ltx_font_italic\">iv</span>)</span></a>\n</th>\n<th id=\"S1.T1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Platform</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S1.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">15</a>]</cite></th>\n<td id=\"S1.T1.1.2.1.2\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S1.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">✓</td>\n<td id=\"S1.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">✓</td>\n<td id=\"S1.T1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">✓</td>\n<td id=\"S1.T1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">PyTorch<span id=\"footnote1\" class=\"ltx_note ltx_role_footnote\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>Official code: <a target=\"_blank\" href=\"https://github.com/IBM/FedMA\" title=\"\" class=\"ltx_ref ltx_url ltx_font_typewriter\">https://github.com/IBM/FedMA</a>.</span></span></span>\n</td>\n</tr>\n<tr id=\"S1.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib16\" title=\"\" class=\"ltx_ref\">16</a>]</cite></th>\n<td id=\"S1.T1.1.3.2.2\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.3.2.3\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.3.2.4\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.3.2.5\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.3.2.6\" class=\"ltx_td ltx_align_center\">TensorFlow<span id=\"footnote2\" class=\"ltx_note ltx_role_footnote\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>Official code: <a target=\"_blank\" href=\"https://github.com/jichan3751/ifca\" title=\"\" class=\"ltx_ref ltx_url ltx_font_typewriter\">https://github.com/jichan3751/ifca</a>.</span></span></span>\n</td>\n</tr>\n<tr id=\"S1.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib17\" title=\"\" class=\"ltx_ref\">17</a>]</cite></th>\n<td id=\"S1.T1.1.4.3.2\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.4.3.3\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.4.3.4\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.4.3.5\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.4.3.6\" class=\"ltx_td ltx_align_center\">PyTorch<span id=\"footnote3\" class=\"ltx_note ltx_role_footnote\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span>Official code: <a target=\"_blank\" href=\"https://github.com/CharlieDinh/pFedMe\" title=\"\" class=\"ltx_ref ltx_url ltx_font_typewriter\">https://github.com/CharlieDinh/pFedMe</a>.</span></span></span>\n</td>\n</tr>\n<tr id=\"S1.T1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib18\" title=\"\" class=\"ltx_ref\">18</a>]</cite></th>\n<td id=\"S1.T1.1.5.4.2\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.5.4.3\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.5.4.4\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.5.4.5\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.5.4.6\" class=\"ltx_td ltx_align_center\">PyTorch<span id=\"footnote4\" class=\"ltx_note ltx_role_footnote\"><sup class=\"ltx_note_mark\">4</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">4</sup><span class=\"ltx_tag ltx_tag_note\">4</span>Official code: <a target=\"_blank\" href=\"https://github.com/med-air/FedBN\" title=\"\" class=\"ltx_ref ltx_url ltx_font_typewriter\">https://github.com/med-air/FedBN</a>.</span></span></span>\n</td>\n</tr>\n<tr id=\"S1.T1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a>]</cite></th>\n<td id=\"S1.T1.1.6.5.2\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.6.5.3\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.6.5.4\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.6.5.5\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.6.5.6\" class=\"ltx_td ltx_align_center\">PyTorch<span id=\"footnote5\" class=\"ltx_note ltx_role_footnote\"><sup class=\"ltx_note_mark\">5</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">5</sup><span class=\"ltx_tag ltx_tag_note\">5</span>Official code: <a target=\"_blank\" href=\"https://github.com/alpemreacar/FedDyn\" title=\"\" class=\"ltx_ref ltx_url ltx_font_typewriter\">https://github.com/alpemreacar/FedDyn</a>.</span></span></span>\n</td>\n</tr>\n<tr id=\"S1.T1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib20\" title=\"\" class=\"ltx_ref\">20</a>]</cite></th>\n<td id=\"S1.T1.1.7.6.2\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.7.6.3\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.7.6.4\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.7.6.5\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.7.6.6\" class=\"ltx_td ltx_align_center\">PyTorch<span id=\"footnote6\" class=\"ltx_note ltx_role_footnote\"><sup class=\"ltx_note_mark\">6</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">6</sup><span class=\"ltx_tag ltx_tag_note\">6</span>Official code: <a target=\"_blank\" href=\"https://github.com/hmgxr128/MIFA_code\" title=\"\" class=\"ltx_ref ltx_url ltx_font_typewriter\">https://github.com/hmgxr128/MIFA_code</a></span></span></span>\n</td>\n</tr>\n<tr id=\"S1.T1.1.8.7\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.8.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib21\" title=\"\" class=\"ltx_ref\">21</a>]</cite></th>\n<td id=\"S1.T1.1.8.7.2\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.8.7.3\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.8.7.4\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.1.8.7.5\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S1.T1.1.8.7.6\" class=\"ltx_td ltx_align_center\">Sklearn<span id=\"footnote7\" class=\"ltx_note ltx_role_footnote\"><sup class=\"ltx_note_mark\">7</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">7</sup><span class=\"ltx_tag ltx_tag_note\">7</span>Official code: <a target=\"_blank\" href=\"https://github.com/daizhongxiang/Differentially-Private-Federated-Bayesian-Optimization\" title=\"\" class=\"ltx_ref ltx_url ltx_font_typewriter\">https://github.com/daizhongxiang/Differentially-Private-Federated-Bayesian-Optimization</a>.</span></span></span>\n</td>\n</tr>\n<tr id=\"S1.T1.1.9.8\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.9.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite></th>\n<td id=\"S1.T1.1.9.8.2\" class=\"ltx_td ltx_border_b\"></td>\n<td id=\"S1.T1.1.9.8.3\" class=\"ltx_td ltx_align_center ltx_border_b\">✓</td>\n<td id=\"S1.T1.1.9.8.4\" class=\"ltx_td ltx_align_center ltx_border_b\">✓</td>\n<td id=\"S1.T1.1.9.8.5\" class=\"ltx_td ltx_align_center ltx_border_b\">✓</td>\n<td id=\"S1.T1.1.9.8.6\" class=\"ltx_td ltx_align_center ltx_border_b\">PyTorch<span id=\"footnote8\" class=\"ltx_note ltx_role_footnote\"><sup class=\"ltx_note_mark\">8</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">8</sup><span class=\"ltx_tag ltx_tag_note\">8</span>Official code: <a target=\"_blank\" href=\"https://github.com/jhoon-oh/fedbabu\" title=\"\" class=\"ltx_ref ltx_url ltx_font_typewriter\">https://github.com/jhoon-oh/fedbabu</a>.</span></span></span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Federated learning (FL), proposed by Google at the very beginning ",
                "[",
                "1",
                "]",
                ", is recently a burgeoning research area of machine learning, which aims to protect individual data privacy in distributed machine learning process, especially in finance ",
                "[",
                "2",
                "]",
                ", smart healthcare ",
                "[",
                "3",
                ", ",
                "4",
                "]",
                " and edge computing ",
                "[",
                "5",
                ", ",
                "6",
                "]",
                ". Different from traditional data-centered distributed machine learning, participants in FL setting utilize localized data to train local model, then leverages specific strategies with other participants to acquire the final model collaboratively, avoiding direct data sharing behavior.",
                "Though it might differ in specific methodologies, current FL schemes can be summarized as repetition of training rounds, with each integrated by several basic steps:\n\n",
                "\n",
                "i",
                ")",
                " ",
                "local update on client’s model using their own localized data;\n",
                "\n",
                "ii",
                ")",
                " ",
                "clients upload their local trained model parameters to server;\n",
                "\n",
                "iii",
                ")",
                " ",
                "server performs aggregation strategy on collected clients’ model parameters to obtain global model;\n",
                "\n",
                "iv",
                ")",
                " ",
                "server selects a subset of clients and distributes the latest global model to them.\n",
                "\n",
                "\nMany FL researches try to improve algorithm effectiveness or efficiency on only one or more steps in this workflow with different scenarios: ",
                "[",
                "7",
                "]",
                " suggests to add regularization term in step ",
                "i",
                ")",
                " to achieve more robust convergence in heterogeneous settings; ",
                "[",
                "8",
                "]",
                " applies gradient compression method in step ",
                "ii",
                ")",
                " to reduce communication bandwidth; ",
                "[",
                "9",
                "]",
                " tries to modify in step ",
                "i",
                ")",
                ", ",
                "ii",
                ")",
                " and ",
                "iii",
                ")",
                " for privacy-preserving purpose; ",
                "[",
                "10",
                "]",
                " proposes better sample strategy in step ",
                "iv",
                ")",
                " to address suboptimal result problem in Federated Multi-Task Learning. These indicate that the implementation of many FL algorithms only requires modification on several components of common workflow, without the necessity of repetitive implementation on basic FL workflow. The paradigm of FL and related research points are as depicted in figure ",
                "1",
                ".",
                "However, though with several FL related frameworks or platforms available, researchers still prefer to implement FL algorithms using PyTorch ",
                "[",
                "11",
                "]",
                " or TensorFlow ",
                "[",
                "12",
                "]",
                " from scratch ",
                "[",
                "13",
                ", ",
                "14",
                "]",
                ". This inefficient modus operandi in FL community can hamper researchers’ enthusiasm in both procedures of reproducing previous work and fast verification of new ideas.",
                "To relieve the burden of researchers in implementing FL algorithms and emancipate FL scientists from repetitive implementation of basic FL setting, we introduce highly customizable framework ",
                "FedLab",
                " in this paper. ",
                "FedLab",
                " provides the necessary modules for FL simulation, including communication, compression, model optimization, data partition and other functional modules. ",
                "FedLab",
                " users can build FL simulation environment with custom modules like playing with LEGO bricks. In all, we make the following contributions to FL community:",
                "A flexible FL framework ",
                "FedLab",
                " is proposed, in which the flexibility is given by highly customizable interfaces and scalability in FL system. ",
                "FedLab",
                " allows users focus on interested components design while keeping other part default. What’s more, ",
                "FedLab",
                " also supports ",
                "standalone",
                ", ",
                "cross machine",
                " and ",
                "hierarchical",
                " simulation paradigms.",
                "Various data partition tools for comprehensive data distribution scenarios in FL. ",
                "FedLab",
                " provides a series of data partition functions as well as built-in data partition schemes for different data distributions over federation.",
                "Standardized FL implementation schemes are presented through ",
                "FedLab",
                ". For instance, standard synchronous and asynchronous FL system are available. Besides, we also provides FL datasets benchmarks and functional modules for standard FL simulation.",
                "An open-source group is founded in GitHub repository for ",
                "FedLab",
                "’s continuous\nmaintenance. Elaborate document is published as well."
            ]
        ]
    }
}