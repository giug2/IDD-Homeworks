{
    "PAPER'S NUMBER OF TABLES": 1,
    "S4.T1": {
        "caption": "TABLE I: Fairness values J​(𝐰¯(T))𝐽superscript¯𝐰𝑇J(\\overline{\\mathbf{w}}^{(T)}), where T𝑇T is the last communication round, for the scenarios in Fig. 1.",
        "table": "<table id=\"S4.T1.23\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.7.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.7.3.4\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<th id=\"S4.T1.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><math id=\"S4.T1.5.1.1.m1.1\" class=\"ltx_Math\" alttext=\"m=1\" display=\"inline\"><semantics id=\"S4.T1.5.1.1.m1.1a\"><mrow id=\"S4.T1.5.1.1.m1.1.1\" xref=\"S4.T1.5.1.1.m1.1.1.cmml\"><mi mathsize=\"90%\" id=\"S4.T1.5.1.1.m1.1.1.2\" xref=\"S4.T1.5.1.1.m1.1.1.2.cmml\">m</mi><mo mathsize=\"90%\" id=\"S4.T1.5.1.1.m1.1.1.1\" xref=\"S4.T1.5.1.1.m1.1.1.1.cmml\">=</mo><mn mathsize=\"90%\" id=\"S4.T1.5.1.1.m1.1.1.3\" xref=\"S4.T1.5.1.1.m1.1.1.3.cmml\">1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.5.1.1.m1.1b\"><apply id=\"S4.T1.5.1.1.m1.1.1.cmml\" xref=\"S4.T1.5.1.1.m1.1.1\"><eq id=\"S4.T1.5.1.1.m1.1.1.1.cmml\" xref=\"S4.T1.5.1.1.m1.1.1.1\"></eq><ci id=\"S4.T1.5.1.1.m1.1.1.2.cmml\" xref=\"S4.T1.5.1.1.m1.1.1.2\">𝑚</ci><cn type=\"integer\" id=\"S4.T1.5.1.1.m1.1.1.3.cmml\" xref=\"S4.T1.5.1.1.m1.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.5.1.1.m1.1c\">m=1</annotation></semantics></math></th>\n<th id=\"S4.T1.6.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><math id=\"S4.T1.6.2.2.m1.1\" class=\"ltx_Math\" alttext=\"m=2\" display=\"inline\"><semantics id=\"S4.T1.6.2.2.m1.1a\"><mrow id=\"S4.T1.6.2.2.m1.1.1\" xref=\"S4.T1.6.2.2.m1.1.1.cmml\"><mi mathsize=\"90%\" id=\"S4.T1.6.2.2.m1.1.1.2\" xref=\"S4.T1.6.2.2.m1.1.1.2.cmml\">m</mi><mo mathsize=\"90%\" id=\"S4.T1.6.2.2.m1.1.1.1\" xref=\"S4.T1.6.2.2.m1.1.1.1.cmml\">=</mo><mn mathsize=\"90%\" id=\"S4.T1.6.2.2.m1.1.1.3\" xref=\"S4.T1.6.2.2.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.6.2.2.m1.1b\"><apply id=\"S4.T1.6.2.2.m1.1.1.cmml\" xref=\"S4.T1.6.2.2.m1.1.1\"><eq id=\"S4.T1.6.2.2.m1.1.1.1.cmml\" xref=\"S4.T1.6.2.2.m1.1.1.1\"></eq><ci id=\"S4.T1.6.2.2.m1.1.1.2.cmml\" xref=\"S4.T1.6.2.2.m1.1.1.2\">𝑚</ci><cn type=\"integer\" id=\"S4.T1.6.2.2.m1.1.1.3.cmml\" xref=\"S4.T1.6.2.2.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.6.2.2.m1.1c\">m=2</annotation></semantics></math></th>\n<th id=\"S4.T1.7.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><math id=\"S4.T1.7.3.3.m1.1\" class=\"ltx_Math\" alttext=\"m=3\" display=\"inline\"><semantics id=\"S4.T1.7.3.3.m1.1a\"><mrow id=\"S4.T1.7.3.3.m1.1.1\" xref=\"S4.T1.7.3.3.m1.1.1.cmml\"><mi mathsize=\"90%\" id=\"S4.T1.7.3.3.m1.1.1.2\" xref=\"S4.T1.7.3.3.m1.1.1.2.cmml\">m</mi><mo mathsize=\"90%\" id=\"S4.T1.7.3.3.m1.1.1.1\" xref=\"S4.T1.7.3.3.m1.1.1.1.cmml\">=</mo><mn mathsize=\"90%\" id=\"S4.T1.7.3.3.m1.1.1.3\" xref=\"S4.T1.7.3.3.m1.1.1.3.cmml\">3</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.7.3.3.m1.1b\"><apply id=\"S4.T1.7.3.3.m1.1.1.cmml\" xref=\"S4.T1.7.3.3.m1.1.1\"><eq id=\"S4.T1.7.3.3.m1.1.1.1.cmml\" xref=\"S4.T1.7.3.3.m1.1.1.1\"></eq><ci id=\"S4.T1.7.3.3.m1.1.1.2.cmml\" xref=\"S4.T1.7.3.3.m1.1.1.2\">𝑚</ci><cn type=\"integer\" id=\"S4.T1.7.3.3.m1.1.1.3.cmml\" xref=\"S4.T1.7.3.3.m1.1.1.3\">3</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.7.3.3.m1.1c\">m=3</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.11.7\" class=\"ltx_tr\">\n<th id=\"S4.T1.8.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><math id=\"S4.T1.8.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pi_{\\text{rand}}\" display=\"inline\"><semantics id=\"S4.T1.8.4.1.m1.1a\"><msub id=\"S4.T1.8.4.1.m1.1.1\" xref=\"S4.T1.8.4.1.m1.1.1.cmml\"><mi mathsize=\"90%\" id=\"S4.T1.8.4.1.m1.1.1.2\" xref=\"S4.T1.8.4.1.m1.1.1.2.cmml\">π</mi><mtext mathsize=\"90%\" id=\"S4.T1.8.4.1.m1.1.1.3\" xref=\"S4.T1.8.4.1.m1.1.1.3a.cmml\">rand</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.8.4.1.m1.1b\"><apply id=\"S4.T1.8.4.1.m1.1.1.cmml\" xref=\"S4.T1.8.4.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T1.8.4.1.m1.1.1.1.cmml\" xref=\"S4.T1.8.4.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T1.8.4.1.m1.1.1.2.cmml\" xref=\"S4.T1.8.4.1.m1.1.1.2\">𝜋</ci><ci id=\"S4.T1.8.4.1.m1.1.1.3a.cmml\" xref=\"S4.T1.8.4.1.m1.1.1.3\"><mtext mathsize=\"63%\" id=\"S4.T1.8.4.1.m1.1.1.3.cmml\" xref=\"S4.T1.8.4.1.m1.1.1.3\">rand</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.8.4.1.m1.1c\">\\pi_{\\text{rand}}</annotation></semantics></math></th>\n<td id=\"S4.T1.9.5.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"S4.T1.9.5.2.m1.1\" class=\"ltx_Math\" alttext=\"0.43\" display=\"inline\"><semantics id=\"S4.T1.9.5.2.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.9.5.2.m1.1.1\" xref=\"S4.T1.9.5.2.m1.1.1.cmml\">0.43</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.9.5.2.m1.1b\"><cn type=\"float\" id=\"S4.T1.9.5.2.m1.1.1.cmml\" xref=\"S4.T1.9.5.2.m1.1.1\">0.43</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.9.5.2.m1.1c\">0.43</annotation></semantics></math></td>\n<td id=\"S4.T1.10.6.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"S4.T1.10.6.3.m1.1\" class=\"ltx_Math\" alttext=\"0.29\" display=\"inline\"><semantics id=\"S4.T1.10.6.3.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.10.6.3.m1.1.1\" xref=\"S4.T1.10.6.3.m1.1.1.cmml\">0.29</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.10.6.3.m1.1b\"><cn type=\"float\" id=\"S4.T1.10.6.3.m1.1.1.cmml\" xref=\"S4.T1.10.6.3.m1.1.1\">0.29</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.10.6.3.m1.1c\">0.29</annotation></semantics></math></td>\n<td id=\"S4.T1.11.7.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\"><math id=\"S4.T1.11.7.4.m1.1\" class=\"ltx_Math\" alttext=\"0.66\" display=\"inline\"><semantics id=\"S4.T1.11.7.4.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.11.7.4.m1.1.1\" xref=\"S4.T1.11.7.4.m1.1.1.cmml\">0.66</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.11.7.4.m1.1b\"><cn type=\"float\" id=\"S4.T1.11.7.4.m1.1.1.cmml\" xref=\"S4.T1.11.7.4.m1.1.1\">0.66</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.11.7.4.m1.1c\">0.66</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T1.15.11\" class=\"ltx_tr\">\n<th id=\"S4.T1.12.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><math id=\"S4.T1.12.8.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pi_{\\text{pow-d}}\" display=\"inline\"><semantics id=\"S4.T1.12.8.1.m1.1a\"><msub id=\"S4.T1.12.8.1.m1.1.1\" xref=\"S4.T1.12.8.1.m1.1.1.cmml\"><mi mathsize=\"90%\" id=\"S4.T1.12.8.1.m1.1.1.2\" xref=\"S4.T1.12.8.1.m1.1.1.2.cmml\">π</mi><mtext mathsize=\"90%\" id=\"S4.T1.12.8.1.m1.1.1.3\" xref=\"S4.T1.12.8.1.m1.1.1.3a.cmml\">pow-d</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.12.8.1.m1.1b\"><apply id=\"S4.T1.12.8.1.m1.1.1.cmml\" xref=\"S4.T1.12.8.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T1.12.8.1.m1.1.1.1.cmml\" xref=\"S4.T1.12.8.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T1.12.8.1.m1.1.1.2.cmml\" xref=\"S4.T1.12.8.1.m1.1.1.2\">𝜋</ci><ci id=\"S4.T1.12.8.1.m1.1.1.3a.cmml\" xref=\"S4.T1.12.8.1.m1.1.1.3\"><mtext mathsize=\"63%\" id=\"S4.T1.12.8.1.m1.1.1.3.cmml\" xref=\"S4.T1.12.8.1.m1.1.1.3\">pow-d</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.12.8.1.m1.1c\">\\pi_{\\text{pow-d}}</annotation></semantics></math></th>\n<td id=\"S4.T1.13.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T1.13.9.2.m1.1\" class=\"ltx_Math\" alttext=\"0.75\" display=\"inline\"><semantics id=\"S4.T1.13.9.2.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.13.9.2.m1.1.1\" xref=\"S4.T1.13.9.2.m1.1.1.cmml\">0.75</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.13.9.2.m1.1b\"><cn type=\"float\" id=\"S4.T1.13.9.2.m1.1.1.cmml\" xref=\"S4.T1.13.9.2.m1.1.1\">0.75</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.13.9.2.m1.1c\">0.75</annotation></semantics></math></td>\n<td id=\"S4.T1.14.10.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T1.14.10.3.m1.1\" class=\"ltx_Math\" alttext=\"0.89\" display=\"inline\"><semantics id=\"S4.T1.14.10.3.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.14.10.3.m1.1.1\" xref=\"S4.T1.14.10.3.m1.1.1.cmml\">0.89</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.14.10.3.m1.1b\"><cn type=\"float\" id=\"S4.T1.14.10.3.m1.1.1.cmml\" xref=\"S4.T1.14.10.3.m1.1.1\">0.89</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.14.10.3.m1.1c\">0.89</annotation></semantics></math></td>\n<td id=\"S4.T1.15.11.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><math id=\"S4.T1.15.11.4.m1.1\" class=\"ltx_Math\" alttext=\"0.91\" display=\"inline\"><semantics id=\"S4.T1.15.11.4.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.15.11.4.m1.1.1\" xref=\"S4.T1.15.11.4.m1.1.1.cmml\">0.91</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.15.11.4.m1.1b\"><cn type=\"float\" id=\"S4.T1.15.11.4.m1.1.1.cmml\" xref=\"S4.T1.15.11.4.m1.1.1\">0.91</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.15.11.4.m1.1c\">0.91</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T1.19.15\" class=\"ltx_tr\">\n<th id=\"S4.T1.16.12.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><math id=\"S4.T1.16.12.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pi_{\\text{ucb-cs}}\" display=\"inline\"><semantics id=\"S4.T1.16.12.1.m1.1a\"><msub id=\"S4.T1.16.12.1.m1.1.1\" xref=\"S4.T1.16.12.1.m1.1.1.cmml\"><mi mathsize=\"90%\" id=\"S4.T1.16.12.1.m1.1.1.2\" xref=\"S4.T1.16.12.1.m1.1.1.2.cmml\">π</mi><mtext mathsize=\"90%\" id=\"S4.T1.16.12.1.m1.1.1.3\" xref=\"S4.T1.16.12.1.m1.1.1.3a.cmml\">ucb-cs</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.16.12.1.m1.1b\"><apply id=\"S4.T1.16.12.1.m1.1.1.cmml\" xref=\"S4.T1.16.12.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T1.16.12.1.m1.1.1.1.cmml\" xref=\"S4.T1.16.12.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T1.16.12.1.m1.1.1.2.cmml\" xref=\"S4.T1.16.12.1.m1.1.1.2\">𝜋</ci><ci id=\"S4.T1.16.12.1.m1.1.1.3a.cmml\" xref=\"S4.T1.16.12.1.m1.1.1.3\"><mtext mathsize=\"63%\" id=\"S4.T1.16.12.1.m1.1.1.3.cmml\" xref=\"S4.T1.16.12.1.m1.1.1.3\">ucb-cs</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.16.12.1.m1.1c\">\\pi_{\\text{ucb-cs}}</annotation></semantics></math></th>\n<td id=\"S4.T1.17.13.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T1.17.13.2.m1.1\" class=\"ltx_Math\" alttext=\"0.61\" display=\"inline\"><semantics id=\"S4.T1.17.13.2.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.17.13.2.m1.1.1\" xref=\"S4.T1.17.13.2.m1.1.1.cmml\">0.61</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.17.13.2.m1.1b\"><cn type=\"float\" id=\"S4.T1.17.13.2.m1.1.1.cmml\" xref=\"S4.T1.17.13.2.m1.1.1\">0.61</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.17.13.2.m1.1c\">0.61</annotation></semantics></math></td>\n<td id=\"S4.T1.18.14.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T1.18.14.3.m1.1\" class=\"ltx_Math\" alttext=\"0.61\" display=\"inline\"><semantics id=\"S4.T1.18.14.3.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.18.14.3.m1.1.1\" xref=\"S4.T1.18.14.3.m1.1.1.cmml\">0.61</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.18.14.3.m1.1b\"><cn type=\"float\" id=\"S4.T1.18.14.3.m1.1.1.cmml\" xref=\"S4.T1.18.14.3.m1.1.1\">0.61</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.18.14.3.m1.1c\">0.61</annotation></semantics></math></td>\n<td id=\"S4.T1.19.15.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><math id=\"S4.T1.19.15.4.m1.1\" class=\"ltx_Math\" alttext=\"0.65\" display=\"inline\"><semantics id=\"S4.T1.19.15.4.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.19.15.4.m1.1.1\" xref=\"S4.T1.19.15.4.m1.1.1.cmml\">0.65</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.19.15.4.m1.1b\"><cn type=\"float\" id=\"S4.T1.19.15.4.m1.1.1.cmml\" xref=\"S4.T1.19.15.4.m1.1.1\">0.65</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.19.15.4.m1.1c\">0.65</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T1.23.19\" class=\"ltx_tr\">\n<th id=\"S4.T1.20.16.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\"><math id=\"S4.T1.20.16.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pi_{\\text{rpow-d}}\" display=\"inline\"><semantics id=\"S4.T1.20.16.1.m1.1a\"><msub id=\"S4.T1.20.16.1.m1.1.1\" xref=\"S4.T1.20.16.1.m1.1.1.cmml\"><mi mathsize=\"90%\" id=\"S4.T1.20.16.1.m1.1.1.2\" xref=\"S4.T1.20.16.1.m1.1.1.2.cmml\">π</mi><mtext mathsize=\"90%\" id=\"S4.T1.20.16.1.m1.1.1.3\" xref=\"S4.T1.20.16.1.m1.1.1.3a.cmml\">rpow-d</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.20.16.1.m1.1b\"><apply id=\"S4.T1.20.16.1.m1.1.1.cmml\" xref=\"S4.T1.20.16.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T1.20.16.1.m1.1.1.1.cmml\" xref=\"S4.T1.20.16.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T1.20.16.1.m1.1.1.2.cmml\" xref=\"S4.T1.20.16.1.m1.1.1.2\">𝜋</ci><ci id=\"S4.T1.20.16.1.m1.1.1.3a.cmml\" xref=\"S4.T1.20.16.1.m1.1.1.3\"><mtext mathsize=\"63%\" id=\"S4.T1.20.16.1.m1.1.1.3.cmml\" xref=\"S4.T1.20.16.1.m1.1.1.3\">rpow-d</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.20.16.1.m1.1c\">\\pi_{\\text{rpow-d}}</annotation></semantics></math></th>\n<td id=\"S4.T1.21.17.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><math id=\"S4.T1.21.17.2.m1.1\" class=\"ltx_Math\" alttext=\"0.32\" display=\"inline\"><semantics id=\"S4.T1.21.17.2.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.21.17.2.m1.1.1\" xref=\"S4.T1.21.17.2.m1.1.1.cmml\">0.32</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.21.17.2.m1.1b\"><cn type=\"float\" id=\"S4.T1.21.17.2.m1.1.1.cmml\" xref=\"S4.T1.21.17.2.m1.1.1\">0.32</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.21.17.2.m1.1c\">0.32</annotation></semantics></math></td>\n<td id=\"S4.T1.22.18.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><math id=\"S4.T1.22.18.3.m1.1\" class=\"ltx_Math\" alttext=\"0.52\" display=\"inline\"><semantics id=\"S4.T1.22.18.3.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.22.18.3.m1.1.1\" xref=\"S4.T1.22.18.3.m1.1.1.cmml\">0.52</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.22.18.3.m1.1b\"><cn type=\"float\" id=\"S4.T1.22.18.3.m1.1.1.cmml\" xref=\"S4.T1.22.18.3.m1.1.1\">0.52</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.22.18.3.m1.1c\">0.52</annotation></semantics></math></td>\n<td id=\"S4.T1.23.19.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\"><math id=\"S4.T1.23.19.4.m1.1\" class=\"ltx_Math\" alttext=\"0.39\" display=\"inline\"><semantics id=\"S4.T1.23.19.4.m1.1a\"><mn mathsize=\"90%\" id=\"S4.T1.23.19.4.m1.1.1\" xref=\"S4.T1.23.19.4.m1.1.1.cmml\">0.39</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.23.19.4.m1.1b\"><cn type=\"float\" id=\"S4.T1.23.19.4.m1.1.1.cmml\" xref=\"S4.T1.23.19.4.m1.1.1\">0.39</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.23.19.4.m1.1c\">0.39</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We evaluate the proposed ",
                "UCB-CS",
                " with logistic regression on a heterogeneous synthetic federated dataset, ",
                "Synthetic",
                "(1,1) ",
                "[",
                "15",
                "]",
                ", and DNN trained on a non-iid partitioned FMNIST dataset ",
                "[",
                "16",
                "]",
                ". For logistic regression, we assume in ",
                "K",
                "=",
                "30",
                "𝐾",
                "30",
                "K=30",
                " where the local dataset sizes follow the power law distribution. We set ",
                "b",
                "=",
                "50",
                ",",
                "τ",
                "=",
                "30",
                "formulae-sequence",
                "𝑏",
                "50",
                "𝜏",
                "30",
                "b=50,~{}\\tau=30",
                ", and ",
                "η",
                "=",
                "0.05",
                "𝜂",
                "0.05",
                "\\eta=0.05",
                ", where ",
                "η",
                "𝜂",
                "\\eta",
                " is decayed to ",
                "η",
                "/",
                "2",
                "𝜂",
                "2",
                "\\eta/2",
                " every 300 and 600 rounds. For DNN, we train a deep multi-layer perceptron network with two hidden layers on the FMNIST dataset. We construct the heterogeneous data partition amongst clients using the Dirichlet distribution ",
                "Dir",
                "K",
                "​",
                "(",
                "α",
                ")",
                "subscript",
                "Dir",
                "𝐾",
                "𝛼",
                "\\text{Dir}_{K}(\\alpha)",
                " ",
                "[",
                "17",
                "]",
                ", where ",
                "α",
                "𝛼",
                "\\alpha",
                " determines the degree of the data heterogeneity across clients. Smaller ",
                "α",
                "𝛼",
                "\\alpha",
                " indicates larger data heterogeneity. For all experiments we use ",
                "b",
                "=",
                "64",
                ",",
                "τ",
                "=",
                "100",
                "formulae-sequence",
                "𝑏",
                "64",
                "𝜏",
                "100",
                "b=64,~{}\\tau=100",
                ", and ",
                "η",
                "=",
                "0.005",
                "𝜂",
                "0.005",
                "\\eta=0.005",
                ", where ",
                "η",
                "𝜂",
                "\\eta",
                " is decayed by half for round 150. All experiments are conducted with clusters equipped with one NVIDIA TitanX GPU. The machines communicate amongst each other through Ethernet. The algorithms are implemented by PyTorch. For all results, the hyper-parameters ",
                "d",
                "𝑑",
                "d",
                " and ",
                "γ",
                "𝛾",
                "\\gamma",
                " are tuned for the best performance via grid search.",
                "The training loss performance for the synthetic dataset simulation is presented in Fig. ",
                "1",
                ". The ",
                "UCB-CS",
                " algorithm, ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                ", converges even faster than ",
                "π",
                "pow-d",
                "subscript",
                "𝜋",
                "pow-d",
                "\\pi_{\\text{pow-d}}",
                " without any error floor, and performs significantly better than ",
                "π",
                "rand",
                "subscript",
                "𝜋",
                "rand",
                "\\pi_{\\text{rand}}",
                " and ",
                "π",
                "rpow-d",
                "subscript",
                "𝜋",
                "rpow-d",
                "\\pi_{\\text{rpow-d}}",
                ". The ",
                "π",
                "rpow-d",
                "subscript",
                "𝜋",
                "rpow-d",
                "\\pi_{\\text{rpow-d}}",
                " selection policy performs worse than ",
                "π",
                "rand",
                "subscript",
                "𝜋",
                "rand",
                "\\pi_{\\text{rand}}",
                ", showing that using stale local losses for biased client selection can make the performance worse than the unbiased selection strategies. Additionally, in Table ",
                "LABEL:tab:fair",
                ", we show that the biased client selection strategies achieve notable higher fairness than the random selection strategy. While ",
                "π",
                "pow-d",
                "subscript",
                "𝜋",
                "pow-d",
                "\\pi_{\\text{pow-d}}",
                " is able to achieve higher fairness than ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                ", ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                " shows a significant improvement in fairness even with low communication cost and robustness to the error floor in the training curve. Hence we show that ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                " is efficient in the three important factors in FL: loss performance, fairness, and communication-efficiency.",
                "To dive deeper into the difference between ",
                "π",
                "pow-d",
                "subscript",
                "𝜋",
                "pow-d",
                "\\pi_{\\text{pow-d}}",
                " and ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                ", in Fig, ",
                "2",
                " we present the local loss distribution across the clients at the end of training for the simulation in Fig. ",
                "1",
                "(a). We show that both ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                " and ",
                "π",
                "pow-d",
                "subscript",
                "𝜋",
                "pow-d",
                "\\pi_{\\text{pow-d}}",
                " is able to improve the worst performing client’s local loss performance for ",
                "π",
                "rand",
                "subscript",
                "𝜋",
                "rand",
                "\\pi_{\\text{rand}}",
                ". While ",
                "π",
                "pow-d",
                "subscript",
                "𝜋",
                "pow-d",
                "\\pi_{\\text{pow-d}}",
                " is able to keep most of the clients in the approximately average range of performance of the local loss, ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                " allows most of the clients to perform with the lowest local loss, skewing the local loss distribution across clients towards lower loss values. Hence from Fig. ",
                "2",
                " we can see that ",
                "π",
                "pow-d",
                "subscript",
                "𝜋",
                "pow-d",
                "\\pi_{\\text{pow-d}}",
                " is valuing fairness over performance, whereas ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                " is valuing performance slightly over fairness.",
                "In Fig. ",
                "3",
                ", the test accuracy and training loss for image classification on the FMNIST dataset via DNN are presented. For less data heterogeneity (",
                "α",
                "=",
                "2",
                "𝛼",
                "2",
                "\\alpha=2",
                "), both ",
                "π",
                "rpow-d",
                "subscript",
                "𝜋",
                "rpow-d",
                "\\pi_{\\text{rpow-d}}",
                " and ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                " perform similarly with higher test accuracy and lower training loss than ",
                "π",
                "rand",
                "subscript",
                "𝜋",
                "rand",
                "\\pi_{\\text{rand}}",
                ". However, for larger data heterogeneity (",
                "α",
                "=",
                "0.3",
                "𝛼",
                "0.3",
                "\\alpha=0.3",
                "), ",
                "π",
                "rpow-d",
                "subscript",
                "𝜋",
                "rpow-d",
                "\\pi_{\\text{rpow-d}}",
                " performs worse than ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                ", showing that with large ",
                "τ",
                "𝜏",
                "\\tau",
                " the estimated local loss values that ",
                "π",
                "rpow-d",
                "subscript",
                "𝜋",
                "rpow-d",
                "\\pi_{\\text{rpow-d}}",
                " use becomes very stale, worsening the performance in the presence of large data heterogeneity. On the other hand, ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                " and ",
                "π",
                "pow-d",
                "subscript",
                "𝜋",
                "pow-d",
                "\\pi_{\\text{pow-d}}",
                " have similar empirical performance, which shows that ",
                "π",
                "ucb-cs",
                "subscript",
                "𝜋",
                "ucb-cs",
                "\\pi_{\\text{ucb-cs}}",
                "’s use of discounted and accumulated local losses give an accurate representation of the client’s actual local loss value."
            ]
        ]
    }
}