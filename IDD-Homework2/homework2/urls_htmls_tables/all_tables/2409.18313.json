{
    "id_table_1": {
        "caption": "TABLE I:  Comparison of related tasks and datasets.",
        "table": "S3.T1.3",
        "footnotes": [],
        "references": [
            "Task  We introduce the general task of  Embodied-RAG benchmark , formulating semantic navigation and question answering under a single paradigm (Table  I , Figure  1 ).",
            "Example tasks are shown in Fig.  4 , with instances of explicit, implicit, and global queries in Fig.  1 . Spatially, the queries range from specific regions small enough to contain certain objects to global regions encompassing the entire scene. Linguistically, global queries are closer to retrieval-augmented generation tasks, while explicit/implicit ones are more retrieval-focused.  Explicit  and  implicit  queries are  navigational  tasks that expect navigation actions and text descriptions of the retrieved location.  Global  queries are  explanation  tasks requiring text generation at a more holistic level; there are no global navigation tasks since they pertain to large areas, sometimes the entire environment. who carefully went through the simulated or real environment."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Comparison of Methods on different Embodied-RAG Benchmarks. Explicit and Implicit queries are evaluated using Success Rate (SR), while Global queries use a Likert Scale of 1 to 5.",
        "table": "S6.T2.3",
        "footnotes": [],
        "references": [
            "To bridge this gap, we present Embodied-RAG. Embodied-RAG has two components,  Memory Construction  (Fig.  2 (a)) and  Retrieval and Generation  (Fig.  2 (b c)). During  Memory Construction , the system autonomously builds a topological map for low-level navigation and a hierarchical  semantic forest  without relying on hand-crafted constraints or features. This forest is organized based on spatial correlations between hierarchical nodes, each containing language descriptions of observations, and can be expanded to handle temporal or multi-modal inputs. Root nodes represent global explanations, leaf nodes capture specific object arrangements, and intermediate nodes reflect various mid-level scales. Embodied-RAG allows retrieval at various levels of  abstraction  in the language query (explicit, implicit, global), matching it with the  spatial/semantic  resolution (local, intermediate, global) of the memory (Fig.  2 (b)/(c), Fig.  3 ). In the  Retrieval and Generation  process, to mitigate perceptual hallucinations from semantic similarity searches, Embodied-RAG incorporates a robust reasoning component. This involves parallelized tree traversals scored by a language model, with retrieved results structured and used as context for generating explanations or navigational actions via an LLM.",
            "Output : The expected output can be both navigation actions with language descriptions (Fig  4  top, Fig.  2  c-1), or language explanations (Fig  4  bottom, Fig.  2  c-2).",
            "The nodes form a topological map (blue nodes in Fig.  2 ), eliminating the need for specific control parameters like velocity and yaw, which often vary across different drive systems. This abstraction enables compatibility with any local planner, regardless of the robots embodiment. Furthermore, the topological structure is far more memory-efficient than traditional metric maps  [ 2 ,  32 ,  30 ] , allowing for efficient scaling in both large outdoor and complex indoor environments. Our experiments show that this approach successfully navigates kilometer-scale simulated environments.",
            "To address perception hallucinations and improve reasoning capabilities over hierarchies of abstraction constructed for a given environment, we modified RAGs relevancy scoring mechanism from semantic similarity to LLM selections at each level, following a strategy similar to Tree-of-Thoughts  [ 50 ] . The input to this retrieval process consists of  N N N italic_N  semantic trees, and the output is the top  k k k italic_k   chains , which represent node paths from selected leaf nodes to the root (e.g., the concatenation of green, yellow, and red nodes in Fig.  2 (c)).",
            "Text Answers  As depicted in Figure  2  (c), we concatenate the  k k k italic_k  chains as part of the prompt to the LLM. We ask it to generate an answer to the query based on the  k k k italic_k  retrieved chains. The spatial scale of attention in each node of the chain facilitate the LLM to generate responses at any semantic scale (explicit, implicit, general) based on the retrieved result."
        ]
    },
    "global_footnotes": [
        "Equal contribution."
    ]
}