{
    "PAPER'S NUMBER OF TABLES": 1,
    "S4.T1": {
        "caption": "Table 1: Deployed Model Descriptions",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<td id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"4\"><span id=\"S4.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Model Parameters</span></td>\n</tr>\n<tr id=\"S4.T1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Name</span></th>\n<td id=\"S4.T1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.2.2.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Total</span></td>\n<td id=\"S4.T1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.2.3.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Trainable</span></td>\n<td id=\"S4.T1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.2.4.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Trainable</span></td>\n<td id=\"S4.T1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.2.5.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Trained on</span></td>\n</tr>\n<tr id=\"S4.T1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">tf-mobilenet</th>\n<td id=\"S4.T1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">412,770</td>\n<td id=\"S4.T1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2,562</td>\n<td id=\"S4.T1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">410,208</td>\n<td id=\"S4.T1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ImageNet</td>\n</tr>\n<tr id=\"S4.T1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\">perf-mobilenet</th>\n<td id=\"S4.T1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">221,794</td>\n<td id=\"S4.T1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">514</td>\n<td id=\"S4.T1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">221,280</td>\n<td id=\"S4.T1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Visual Wake Words</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We implemented two versions of MobileNetV2 for our task: the Tensorflow built-in MobileNet compressed with a factor of ",
                "a",
                "‚Äã",
                "l",
                "‚Äã",
                "p",
                "‚Äã",
                "h",
                "‚Äã",
                "a",
                "=",
                "0.35",
                "ùëé",
                "ùëô",
                "ùëù",
                "‚Ñé",
                "ùëé",
                "0.35",
                "alpha=0.35",
                " (hereby referenced as tf-mobilenet) pretrained on ImageNet and the MobileNet from the TinyML Perf Benchmark (hereby referenced as perf-mobilenet) ",
                "[",
                "10",
                ", ",
                "12",
                "]",
                ". The compressed tf-mobilenet has more parameters than perf-mobilenet has x parameters. Both models were frozen and the input and outputs were quantized using post-training 8-bit quantization to interface correctly with the microcontroller.",
                "We ran into issues with transfer learning on the perf-mobilenet model. Specifically, the embeddings generated from the network were incredibly sparse, where only 16 of the 256 outputs were ever non-zero. This may be as a result of encouraging sparsity during training via methods such as L2 weight regularization so the embeddings generated are highly specific to the task it was initially trained on (person detection through the visual wake words dataset). If given more time, we would have re-trained the perf-mobilenet to get more meaningful embeddings.",
                "In our simulations, tf-mobilenet performed much better and successfully learned the task of cat identification. However, it was too large to fit on-device for our microcontroller. Since we were using an Arduino Nano 33 BLE Sense with 1MB of flash memory and 256KB of SRAM, we believe that other microcontrollers could have fit the tf-mobilenet model. Therefore, we used the perf-mobilenet for memory and time benchmarking on our arduino and the tf-mobilenet model in our simulations to understand performance."
            ]
        ]
    }
}