{
    "PAPER'S NUMBER OF TABLES": 1,
    "S5.T2": {
        "caption": "TABLE I: Comparison of all models based on COCO metrics and mAP on test dataset which was captured in the same environment as the training datasetTABLE II: Comparison of all models based on COCO metrics and mAP on test dataset which was captured in an entirely different environment than the training dataset",
        "table": "<table id=\"S5.T2.1\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\">Algorithm</th>\n<th id=\"S5.T2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">AP</th>\n<th id=\"S5.T2.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">AP50</th>\n<th id=\"S5.T2.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">AP75</th>\n<th id=\"S5.T2.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">APsmall</th>\n<th id=\"S5.T2.1.1.1.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">APmedium</th>\n<th id=\"S5.T2.1.1.1.7\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">APlarge</th>\n<th id=\"S5.T2.1.1.1.8\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">mAP</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt\">FedEnsemble model</td>\n<td id=\"S5.T2.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">0.6530</td>\n<td id=\"S5.T2.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">0.9718</td>\n<td id=\"S5.T2.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">0.7643</td>\n<td id=\"S5.T2.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">0.6212</td>\n<td id=\"S5.T2.1.2.1.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">0.6349</td>\n<td id=\"S5.T2.1.2.1.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">0.4101</td>\n<td id=\"S5.T2.1.2.1.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">0.9749</td>\n</tr>\n<tr id=\"S5.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Federated learning</td>\n<td id=\"S5.T2.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.5723</td>\n<td id=\"S5.T2.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.9586</td>\n<td id=\"S5.T2.1.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.5825</td>\n<td id=\"S5.T2.1.3.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.5011</td>\n<td id=\"S5.T2.1.3.2.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.5702</td>\n<td id=\"S5.T2.1.3.2.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.3945</td>\n<td id=\"S5.T2.1.3.2.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.9660</td>\n</tr>\n<tr id=\"S5.T2.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Transferlearning</td>\n<td id=\"S5.T2.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.6635</td>\n<td id=\"S5.T2.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.9725</td>\n<td id=\"S5.T2.1.4.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.7763</td>\n<td id=\"S5.T2.1.4.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.6092</td>\n<td id=\"S5.T2.1.4.3.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.6453</td>\n<td id=\"S5.T2.1.4.3.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.4142</td>\n<td id=\"S5.T2.1.4.3.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.9755</td>\n</tr>\n<tr id=\"S5.T2.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Fine-tune model</td>\n<td id=\"S5.T2.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.5.4.2.1\" class=\"ltx_text ltx_font_bold\">0.6680</span></td>\n<td id=\"S5.T2.1.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.5.4.3.1\" class=\"ltx_text ltx_font_bold\">0.9743</span></td>\n<td id=\"S5.T2.1.5.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.7124</td>\n<td id=\"S5.T2.1.5.4.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\">0.6671</span></td>\n<td id=\"S5.T2.1.5.4.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.5.4.6.1\" class=\"ltx_text ltx_font_bold\">0.6561</span></td>\n<td id=\"S5.T2.1.5.4.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.5.4.7.1\" class=\"ltx_text ltx_font_bold\">0.4247</span></td>\n<td id=\"S5.T2.1.5.4.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.9774</td>\n</tr>\n<tr id=\"S5.T2.1.6.5\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Hybrid Centralized learning</td>\n<td id=\"S5.T2.1.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.6643</td>\n<td id=\"S5.T2.1.6.5.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.9702</td>\n<td id=\"S5.T2.1.6.5.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.7455</td>\n<td id=\"S5.T2.1.6.5.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.6318</td>\n<td id=\"S5.T2.1.6.5.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.6399</td>\n<td id=\"S5.T2.1.6.5.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.4240</td>\n<td id=\"S5.T2.1.6.5.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.6.5.8.1\" class=\"ltx_text ltx_font_bold\">0.9783</span></td>\n</tr>\n<tr id=\"S5.T2.1.7.6\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Real Centralized learning</td>\n<td id=\"S5.T2.1.7.6.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.6676</td>\n<td id=\"S5.T2.1.7.6.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.9663</td>\n<td id=\"S5.T2.1.7.6.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.7.6.4.1\" class=\"ltx_text ltx_font_bold\">0.7820</span></td>\n<td id=\"S5.T2.1.7.6.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.6598</td>\n<td id=\"S5.T2.1.7.6.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.6472</td>\n<td id=\"S5.T2.1.7.6.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.4107</td>\n<td id=\"S5.T2.1.7.6.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.9743</td>\n</tr>\n<tr id=\"S5.T2.1.8.7\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Synthetic Centralized learning</td>\n<td id=\"S5.T2.1.8.7.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.1509</td>\n<td id=\"S5.T2.1.8.7.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.3595</td>\n<td id=\"S5.T2.1.8.7.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.1025</td>\n<td id=\"S5.T2.1.8.7.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.0902</td>\n<td id=\"S5.T2.1.8.7.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.1890</td>\n<td id=\"S5.T2.1.8.7.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.0946</td>\n<td id=\"S5.T2.1.8.7.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.3663</td>\n</tr>\n<tr id=\"S5.T2.1.9.8\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">YOLO Ensemble</td>\n<td id=\"S5.T2.1.9.8.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.5314</td>\n<td id=\"S5.T2.1.9.8.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.9171</td>\n<td id=\"S5.T2.1.9.8.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.5470</td>\n<td id=\"S5.T2.1.9.8.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.5731</td>\n<td id=\"S5.T2.1.9.8.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.5232</td>\n<td id=\"S5.T2.1.9.8.7\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.3036</td>\n<td id=\"S5.T2.1.9.8.8\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.9188</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "This section showcases a comparison of results from all the algorithms on two test datasets. The first dataset (referred to as Testset1) is similar to the background and setup shown in image ",
                "2",
                ", and the second dataset (referred to as Testset2) features unseen environment parameters, as shown in figure ",
                "3",
                ".\nTable ",
                "II",
                " presents results based on Testset1, while Table ",
                "II",
                " presents results based on Testset2 in COCO metrics ",
                "[",
                "30",
                "]",
                ", which includes IoU-Aware (Intersection over Union) and object size-relevant metrics. The last column denotes mAP (mean Average Precision) at an IoU threshold of 0.5 in terms of PASCAL metrics, which is a single IoU threshold metric. Tables ",
                "II",
                " and ",
                "II",
                " include two additional tests beyond those mentioned in section ",
                "IV",
                ".\nThe ’Real Centralized learning’ test uses only the 300 real images dataset to train the YOLOv5 model for 200 epochs, and the resulting best model weights are used to test both Testset1 and Testset2. Similarly, the ’Synthetic Centralized learning’ model is trained using only the 300 synthetic images from the hybrid dataset and is tested on both datasets.",
                "Starting with Table ",
                "II",
                ", we observe that most models achieve an mAP of more than 95%, except for the model trained using only the synthetic dataset and the YOLOv5 ensemble model (which uses this synthetic dataset model as one of its two models). These two models exhibit a lower mAP, and the average precision for small objects is also lower. The model trained solely on the real dataset of 300 images performs well in all AP metrics.\nFederated learning and FedEnsemble learning techniques perform on par with the centrally trained model but do not achieve better results. Transfer learning, fine-tune learning, and the model trained directly on the hybrid dataset also perform well on the test dataset, achieving APsmall greater than 60% and mAP above 97%. The fine-tune model stands out among all the algorithms, performing well in terms of all AP metrics. However, it’s important to note that the test images are from the same sample set distribution as the training dataset (500 images were captured, of which 300 were used for training, 100 for validation, and 100 for testing, as shown in figure ",
                "2",
                "). Hence, it is yet to be confirmed if the models really perform well or are overfitted to the training dataset samples.",
                "To test the real accuracy of the models, all the models were tested on a newly created test dataset (as mentioned in section ",
                "III-A",
                ", figure ",
                "3",
                ").\nTable ",
                "II",
                " reveals that the ’Real Centralized learning’ model and the transfer learning model achieve an mAP of around 76%, with APsmall at 25% and 23%, respectively. The fine-tuned model and hybrid dataset model only slightly outperform them, achieving around 75% mAP and 28% APsmall metrics. This strongly suggests that the centrally trained dataset models tend to overfit to the training dataset, especially the model trained only using 300 real images. The synthetic dataset model underperforms here, as does the YOLOv5 ensemble model.",
                "The results for federated learning from Table ",
                "II",
                " show that federated learning used to create a hybrid model by training two clients, each having only real and synthetic datasets respectively, produced the best results. The results are followed by the FedEnsemble learning, which also succeeded in producing a robust model that performs well on unseen environment datasets by using the same dataset used for centralized training but divided into different subsets as clients’ datasets.\nThe results of the global federated model are 8% better in terms of PASCAL metrics mAP (mean Average Precision) when compared to the baseline centrally trained model. In terms of COCO metrics ",
                "[",
                "30",
                "]",
                ", federated learning outperforms the baseline model in all AP (Average Precision) types, as seen in the Table. Federated learning is seen to be performing better than all the other algorithms, followed by the FedEnsemble technique, which also performs better on unseen test data within a different environment (As shown in Figure ",
                "13",
                " and ",
                "17",
                " for centralized and FedEnsemble model respectively).",
                "The idea of testing models trained with only synthetic or real datasets is to showcase that clients’ models trained with local datasets performed subpar when similar objects were placed in a new unseen environment condition. However, using similar datasets with the help of federated learning, clients can achieve a robust global federated model without sharing any raw private data (Refer Appendix for further details)."
            ]
        ]
    }
}