{
    "PAPER'S NUMBER OF TABLES": 5,
    "S4.T1": {
        "caption": "Table 1: Datasets Statistics",
        "table": "<table id=\"S4.T1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></td>\n<td id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Clients</span></td>\n<td id=\"S4.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Total samples</span></td>\n<td id=\"S4.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span id=\"S4.T1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Samples per client</span></td>\n<td id=\"S4.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Classes</span></td>\n</tr>\n<tr id=\"S4.T1.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.2.1\" class=\"ltx_td\"></td>\n<td id=\"S4.T1.1.1.2.2\" class=\"ltx_td\"></td>\n<td id=\"S4.T1.1.1.2.3\" class=\"ltx_td\"></td>\n<td id=\"S4.T1.1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Mean</td>\n<td id=\"S4.T1.1.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Stdev</td>\n<td id=\"S4.T1.1.1.2.6\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.T1.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">CelebA</td>\n<td id=\"S4.T1.1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">9,343</td>\n<td id=\"S4.T1.1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">200,288</td>\n<td id=\"S4.T1.1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">21.44</td>\n<td id=\"S4.T1.1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">7.63</td>\n<td id=\"S4.T1.1.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">2</td>\n</tr>\n<tr id=\"S4.T1.1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_b\">FEMNIST</td>\n<td id=\"S4.T1.1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_b\">3,550</td>\n<td id=\"S4.T1.1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_b\">805,263</td>\n<td id=\"S4.T1.1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_b\">226.83</td>\n<td id=\"S4.T1.1.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_b\">88.94</td>\n<td id=\"S4.T1.1.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_b\">62</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We evaluate the proposed model on image classification tasks on the LEAF benchmarkÂ [2], testing both on the CelebAÂ [25] and Federated Extended MNIST (FEMNIST)Â [20, 6] datasets. Table 1 details each setting."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Accuracy of FedAvg in TensorFlow [2] and our version implemented in PyTorch. ",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></td>\n<td id=\"S4.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.1.2.1\" class=\"ltx_text ltx_font_bold\">TensorFlow</span></td>\n<td id=\"S4.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.1.3.1\" class=\"ltx_text ltx_font_bold\">PyTorch</span></td>\n</tr>\n<tr id=\"S4.T2.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">CelebA</td>\n<td id=\"S4.T2.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">89.46</td>\n<td id=\"S4.T2.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">86.88</td>\n</tr>\n<tr id=\"S4.T2.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_b\">FEMNIST</td>\n<td id=\"S4.T2.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\">74.72</td>\n<td id=\"S4.T2.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_b\">77.81</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In all datasets, the domain classifiers are CNNs made of two convolutional layers of 323232 and 646464 features and kernel size 3Ã—3333\\times 3, followed by an average pooling and a linear layer whose output dimension is the number of domains. We train the domain classifiers through an SGD optimizer without weight decay and a learning rate of 10âˆ’4superscript10410^{-4}. We implement FedCGÂ on PyTorchÂ [35], running the experiments on NVIDIA GeForce 1070 GTX GPUs. We chose PytTorch due to its higher flexibility for prototyping and experimenting the components of our model. To ensure a fair comparison, we implemented the FedAvg baseline using the same framework, architectures, hyperparameters and training protocols of [3].TableÂ 2 compares our results with the performance of the TensorflowÂ [1] implementation from the LEAF repositoryÂ [3]:\nour FedAvg baseline outperforms the original one by almost 3% in accuracy on FEMNIST, while performing almost 2.5% less on CelebA. Nevertheless, our main interest is to evaluate the relative improvement of the proposed model with respect to a baseline that does not exploit domain information, using the same aggregation strategy of FedAvg for federated learning. For these reasons, in the following we will take as reference the FedAvg results of the PyTorch framework, to ensure a comparison with the baseline under the exact conditions. We evaluate our results in terms of global accuracy on the test set, \\ieon the union of the images of all test devices. All experiments on the same dataset were run with the same configuration to perform a fair comparison between the considered approaches."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Ablation studies on CelebA dataset with N=32ğ‘32N=32 domains extracted from images meta-data. A is the adjacency matrix that weights the domains contributions: the symbols (eye,U,H) respectively stand for identity, uniform and weighted (with inverse Hamming distance) matrices. W is the weight projection matrix and ReLU the chosen non-linear activation.",
        "table": "<table id=\"S4.T3.2.2.2\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T3.2.2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r\">Model</td>\n<td id=\"S4.T3.1.1.1.1.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.1.1.1.1.1\" class=\"ltx_text ltx_markedasmath ltx_font_bold\">A</span></td>\n<td id=\"S4.T3.2.2.2.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.2.2.2.2.2.1\" class=\"ltx_text ltx_markedasmath ltx_font_bold\">W</span></td>\n<td id=\"S4.T3.2.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">ReLU</td>\n<td id=\"S4.T3.2.2.2.2.5\" class=\"ltx_td ltx_align_center\">Acc(%)</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">Domain-specific models</td>\n<td id=\"S4.T3.2.2.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">-</td>\n<td id=\"S4.T3.2.2.2.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">-</td>\n<td id=\"S4.T3.2.2.2.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">-</td>\n<td id=\"S4.T3.2.2.2.3.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">33.61</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.T3.2.2.2.4.1.1\" class=\"ltx_text\">GCN</span></td>\n<td id=\"S4.T3.2.2.2.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">U</td>\n<td id=\"S4.T3.2.2.2.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">âœ—</td>\n<td id=\"S4.T3.2.2.2.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ—</td>\n<td id=\"S4.T3.2.2.2.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">84.39</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.5.1\" class=\"ltx_td ltx_align_center\">H</td>\n<td id=\"S4.T3.2.2.2.5.2\" class=\"ltx_td ltx_align_center\">âœ—</td>\n<td id=\"S4.T3.2.2.2.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ—</td>\n<td id=\"S4.T3.2.2.2.5.4\" class=\"ltx_td ltx_align_center\">82.10</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.6.1\" class=\"ltx_td ltx_align_center\">U</td>\n<td id=\"S4.T3.2.2.2.6.2\" class=\"ltx_td ltx_align_center\">âœ“</td>\n<td id=\"S4.T3.2.2.2.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ—</td>\n<td id=\"S4.T3.2.2.2.6.4\" class=\"ltx_td ltx_align_center\">87.92</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.7\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.7.1\" class=\"ltx_td ltx_align_center\">H</td>\n<td id=\"S4.T3.2.2.2.7.2\" class=\"ltx_td ltx_align_center\">âœ“</td>\n<td id=\"S4.T3.2.2.2.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ—</td>\n<td id=\"S4.T3.2.2.2.7.4\" class=\"ltx_td ltx_align_center\">84.25</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.8\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.8.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.T3.2.2.2.8.1.1\" class=\"ltx_text\">FedCG</span></td>\n<td id=\"S4.T3.2.2.2.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">U</td>\n<td id=\"S4.T3.2.2.2.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">âœ“</td>\n<td id=\"S4.T3.2.2.2.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ—</td>\n<td id=\"S4.T3.2.2.2.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\">86.96</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.9\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.9.1\" class=\"ltx_td ltx_align_center\">H</td>\n<td id=\"S4.T3.2.2.2.9.2\" class=\"ltx_td ltx_align_center\">âœ“</td>\n<td id=\"S4.T3.2.2.2.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ—</td>\n<td id=\"S4.T3.2.2.2.9.4\" class=\"ltx_td ltx_align_center\">88.65</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.10\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.10.1\" class=\"ltx_td ltx_align_center\">U</td>\n<td id=\"S4.T3.2.2.2.10.2\" class=\"ltx_td ltx_align_center\">âœ“</td>\n<td id=\"S4.T3.2.2.2.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ“</td>\n<td id=\"S4.T3.2.2.2.10.4\" class=\"ltx_td ltx_align_center\">87.97</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.11\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.11.1\" class=\"ltx_td ltx_align_center ltx_border_b\">H</td>\n<td id=\"S4.T3.2.2.2.11.2\" class=\"ltx_td ltx_align_center ltx_border_b\">âœ“</td>\n<td id=\"S4.T3.2.2.2.11.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">âœ“</td>\n<td id=\"S4.T3.2.2.2.11.4\" class=\"ltx_td ltx_align_center ltx_border_b\">89.57</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In this section, we focus our analysis on testing the performance of the proposed model on the CelebA dataset, analyzing the various components of our approach. All referred studies and results can be found in Table 3 and 4.",
            "To create a sanity-check for our model, we first define the domains manually, exploiting the a priori knowledge given from the images meta-data, \\iethe 40 attributes of the dataset (Table 3). This allows us to isolate the choice of how to include domain-specific information within the model, without any influence from the clustering procedure. From the 40 attributes, we select the combination of nğ‘›n attributes leading to the most balanced subdivisions of the dataset and having a low correlation with the target feature. Since each attribute can only assume the values {0,1}01\\{0,1\\}, the number of possible domains is given by all the 2nsuperscript2ğ‘›2^{n} combinations of the nğ‘›n features. We choose n=5ğ‘›5n=5, having N=32ğ‘32N=32 domains. The selected features are attractive, heavy makeup, high cheekbones, mouth slightly open and wavy hair.",
            "We start by replacing the standard single server model with Nğ‘N separate domain-specific models, trained and tested only on the images of their specific domains. As shown in Table 3, the performance drops significantly (33.6133.6133.61% vs 86.8886.8886.88% of FedAvg), since the insufficient amount of data seen by each model leads to poor generalization. This shows that learning a single full model per each domain is not a viable strategy in this scenario.",
            "In order to account for the relations existing among the different domains, we introduce the graph, modeled as a 1-layer GCN. To study the impact of introducing a GCN, we also test a simpler version of the model without the weight transformation matrix Wğ‘ŠW.\nWe analyze different choices of ğ€ğ€\\mathbf{A}, considering the cases where i) they are uniformly weighted (U) and ii) the domains are weighted according to a similarity criterion (H), specifically the normalized inverse of the Hamming distanceÂ [34] between the numerical representation of the domains (\\ietheir binary metadata).\nAs TableÂ 3 shows, using a GCN consistently improves the final performance over the domain-specific models. The uniform adjacency matrix performs slightly better than the weighted one in this case, with both their performance improving when the projection matrix ğ–ğ–\\mathbf{W} is introduced. These results confirm the importance of making the domain-specific nodes interact. However, the results are not satisfactory, being either below or just 1% above (GCN-H with ğ–ğ–\\mathbf{W}) FedAvg. This means that domain information is still dully exploited within the model.",
            "Finally, we analyze the usage of\ndomain-specific parameters to produce residual activations (\\ieEq.Â (4)), as in FedCG, comparing it with the GCN when not using any domain-agnostic component. As TableÂ 3 shows, while the model with uniform adjacency matrix (U) sees a decrease in performance from GCN to FedCGÂ (\\ie87.92% vs 86.96%), the model with weighted adjacency matrix (H) sees a large boost, going from the 84.25% accuracy of GCN to the 88.65% of FedCG. We can draw two conclusions. First, using residual layers to refine the domain agnostic activations (FedCG) performs better than using only domain-specific components (GCN). Second, when domain-specific components are integrated as residuals, they are much more effective when connected in a weighted (H) rather than a uniform (U) fashion. This is proved by the results of FedCG-H, surpassing FedCG-U by 1.7% in accuracy. Finally, we test the importance of the ReLU non-linearity applied to the output of the residual GCN. The non-linearity improves FedCG, both when the domains are connected uniformly (+1%) and in a weighted fashion (+0.9%). The final FedCGÂ model with 1-layer GCN filtered with a ReLU and a weighted adjacency matrix outperforms the baseline FedAvg by 2.6% accuracy, showing the effectiveness of our choices."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Ablation studies on CelebA dataset with domains given by a priori knowledge or online clustering procedures. In the A init column, â€œeyeâ€ stands for identity matrix and â€œrandâ€ for random. The third column specifies the clustering, \\ieclusters generated with K-means or the teacher-student classifier (â€œClfâ€).",
        "table": "<table id=\"S4.T4.2.2.2\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T4.2.2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedCGÂ layers</td>\n<td id=\"S4.T4.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<span id=\"S4.T4.1.1.1.1.1.1\" class=\"ltx_text ltx_markedasmath ltx_font_bold\">A</span> init</td>\n<td id=\"S4.T4.2.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Clusters</td>\n<td id=\"S4.T4.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T4.2.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"D\" display=\"inline\"><semantics id=\"S4.T4.2.2.2.2.2.m1.1a\"><mi id=\"S4.T4.2.2.2.2.2.m1.1.1\" xref=\"S4.T4.2.2.2.2.2.m1.1.1.cmml\">D</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.2.2.2.2.2.m1.1b\"><ci id=\"S4.T4.2.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T4.2.2.2.2.2.m1.1.1\">ğ·</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.2.2.2.2.2.m1.1c\">D</annotation></semantics></math></td>\n<td id=\"S4.T4.2.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Soft domains</td>\n<td id=\"S4.T4.2.2.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">Acc(%)</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"12\"><span id=\"S4.T4.2.2.2.3.1.1\" class=\"ltx_text\">all</span></td>\n<td id=\"S4.T4.2.2.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">eye</td>\n<td id=\"S4.T4.2.2.2.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">K-means</td>\n<td id=\"S4.T4.2.2.2.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">2</td>\n<td id=\"S4.T4.2.2.2.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">âœ—</td>\n<td id=\"S4.T4.2.2.2.3.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">88.36</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.4\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.4.1\" class=\"ltx_td ltx_align_center\">eye</td>\n<td id=\"S4.T4.2.2.2.4.2\" class=\"ltx_td ltx_align_center\">K-means</td>\n<td id=\"S4.T4.2.2.2.4.3\" class=\"ltx_td ltx_align_center\">3</td>\n<td id=\"S4.T4.2.2.2.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ—</td>\n<td id=\"S4.T4.2.2.2.4.5\" class=\"ltx_td ltx_align_center\">87.97</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.5\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.5.1\" class=\"ltx_td ltx_align_center\">eye</td>\n<td id=\"S4.T4.2.2.2.5.2\" class=\"ltx_td ltx_align_center\">K-means</td>\n<td id=\"S4.T4.2.2.2.5.3\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"S4.T4.2.2.2.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ—</td>\n<td id=\"S4.T4.2.2.2.5.5\" class=\"ltx_td ltx_align_center\">87.21</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.6\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.6.1\" class=\"ltx_td ltx_align_center ltx_border_t\">eye</td>\n<td id=\"S4.T4.2.2.2.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Clf</td>\n<td id=\"S4.T4.2.2.2.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">2</td>\n<td id=\"S4.T4.2.2.2.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ—</td>\n<td id=\"S4.T4.2.2.2.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\">88.03</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.7\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.7.1\" class=\"ltx_td ltx_align_center\">eye</td>\n<td id=\"S4.T4.2.2.2.7.2\" class=\"ltx_td ltx_align_center\">Clf</td>\n<td id=\"S4.T4.2.2.2.7.3\" class=\"ltx_td ltx_align_center\">3</td>\n<td id=\"S4.T4.2.2.2.7.4\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ—</td>\n<td id=\"S4.T4.2.2.2.7.5\" class=\"ltx_td ltx_align_center\">88.59</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.8\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.8.1\" class=\"ltx_td ltx_align_center\">eye</td>\n<td id=\"S4.T4.2.2.2.8.2\" class=\"ltx_td ltx_align_center\">Clf</td>\n<td id=\"S4.T4.2.2.2.8.3\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"S4.T4.2.2.2.8.4\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ—</td>\n<td id=\"S4.T4.2.2.2.8.5\" class=\"ltx_td ltx_align_center\">88.74</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.9\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.9.1\" class=\"ltx_td ltx_align_center ltx_border_t\">rand</td>\n<td id=\"S4.T4.2.2.2.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Clf</td>\n<td id=\"S4.T4.2.2.2.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\">2</td>\n<td id=\"S4.T4.2.2.2.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ—</td>\n<td id=\"S4.T4.2.2.2.9.5\" class=\"ltx_td ltx_align_center ltx_border_t\">88.73</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.10\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.10.1\" class=\"ltx_td ltx_align_center\">rand</td>\n<td id=\"S4.T4.2.2.2.10.2\" class=\"ltx_td ltx_align_center\">Clf</td>\n<td id=\"S4.T4.2.2.2.10.3\" class=\"ltx_td ltx_align_center\">3</td>\n<td id=\"S4.T4.2.2.2.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ—</td>\n<td id=\"S4.T4.2.2.2.10.5\" class=\"ltx_td ltx_align_center\">88.24</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.11\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.11.1\" class=\"ltx_td ltx_align_center\">rand</td>\n<td id=\"S4.T4.2.2.2.11.2\" class=\"ltx_td ltx_align_center\">Clf</td>\n<td id=\"S4.T4.2.2.2.11.3\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"S4.T4.2.2.2.11.4\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ—</td>\n<td id=\"S4.T4.2.2.2.11.5\" class=\"ltx_td ltx_align_center\">88.55</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.12\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.12.1\" class=\"ltx_td ltx_align_center ltx_border_t\">eye</td>\n<td id=\"S4.T4.2.2.2.12.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Clf</td>\n<td id=\"S4.T4.2.2.2.12.3\" class=\"ltx_td ltx_align_center ltx_border_t\">2</td>\n<td id=\"S4.T4.2.2.2.12.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T4.2.2.2.12.5\" class=\"ltx_td ltx_align_center ltx_border_t\">87.88</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.13\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.13.1\" class=\"ltx_td ltx_align_center\">eye</td>\n<td id=\"S4.T4.2.2.2.13.2\" class=\"ltx_td ltx_align_center\">Clf</td>\n<td id=\"S4.T4.2.2.2.13.3\" class=\"ltx_td ltx_align_center\">3</td>\n<td id=\"S4.T4.2.2.2.13.4\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ“</td>\n<td id=\"S4.T4.2.2.2.13.5\" class=\"ltx_td ltx_align_center\">88.74</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.14\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.14.1\" class=\"ltx_td ltx_align_center\">eye</td>\n<td id=\"S4.T4.2.2.2.14.2\" class=\"ltx_td ltx_align_center\">Clf</td>\n<td id=\"S4.T4.2.2.2.14.3\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"S4.T4.2.2.2.14.4\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ“</td>\n<td id=\"S4.T4.2.2.2.14.5\" class=\"ltx_td ltx_align_center\">88.67</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.15\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.15.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.T4.2.2.2.15.1.1\" class=\"ltx_text\">last</span></td>\n<td id=\"S4.T4.2.2.2.15.2\" class=\"ltx_td ltx_align_center ltx_border_t\">eye</td>\n<td id=\"S4.T4.2.2.2.15.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Clf</td>\n<td id=\"S4.T4.2.2.2.15.4\" class=\"ltx_td ltx_align_center ltx_border_t\">2</td>\n<td id=\"S4.T4.2.2.2.15.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T4.2.2.2.15.6\" class=\"ltx_td ltx_align_center ltx_border_t\">88.31</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.16\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.16.1\" class=\"ltx_td ltx_align_center\">eye</td>\n<td id=\"S4.T4.2.2.2.16.2\" class=\"ltx_td ltx_align_center\">Clf</td>\n<td id=\"S4.T4.2.2.2.16.3\" class=\"ltx_td ltx_align_center\">3</td>\n<td id=\"S4.T4.2.2.2.16.4\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ“</td>\n<td id=\"S4.T4.2.2.2.16.5\" class=\"ltx_td ltx_align_center\">88.13</td>\n</tr>\n<tr id=\"S4.T4.2.2.2.17\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.17.1\" class=\"ltx_td ltx_align_center\">eye</td>\n<td id=\"S4.T4.2.2.2.17.2\" class=\"ltx_td ltx_align_center\">Clf</td>\n<td id=\"S4.T4.2.2.2.17.3\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"S4.T4.2.2.2.17.4\" class=\"ltx_td ltx_align_center ltx_border_r\">âœ“</td>\n<td id=\"S4.T4.2.2.2.17.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.2.2.2.17.5.1\" class=\"ltx_text ltx_font_bold\">89.18</span></td>\n</tr>\n<tr id=\"S4.T4.2.2.2.18\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.18.1\" class=\"ltx_td ltx_align_center ltx_border_b\">eye</td>\n<td id=\"S4.T4.2.2.2.18.2\" class=\"ltx_td ltx_align_center ltx_border_b\">Clf</td>\n<td id=\"S4.T4.2.2.2.18.3\" class=\"ltx_td ltx_align_center ltx_border_b\">32</td>\n<td id=\"S4.T4.2.2.2.18.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">âœ“</td>\n<td id=\"S4.T4.2.2.2.18.5\" class=\"ltx_td ltx_align_center ltx_border_b\">88.40</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In the previous section, we analyzed how to integrate domain-specific components given oracle domain information. In this section, we drop the assumption of having such information and we study the effectiveness of the domains discovered through our clustering procedure on FedCGâ€‰ held out through the teacher-student domain classifier\n(cf.Â Sec. 3.1). We report the results of our analysis in Table 4.",
            "We start by comparing our domain classifier with the K-means algorithmÂ [26] applied to the parameters of the models trained separately on each client. FedCGÂ performs clustering locally instead, accessing only a subset of the clients at each round. As Table 4 shows, the performance of our clustering procedure is either on par (D=2ğ·2D=2) or superior (D=3ğ·3D=3,444) to K-means clustering. In particular, as the number of clusters grows, the performance of K-means drops (\\iefrom 88.36% with D=2ğ·2D=2 to 87.21 with D=4ğ·4D=4), while our method - with the same residual GCN - shows performance improvements (\\iefrom 88.03% with D=2ğ·2D=2 to 88.74 with D=4ğ·4D=4). This indicates the effectiveness of our local clustering procedure that, differently from K-means, captures the presence of different domains within each client, without requiring one specific model per client.",
            "Then, we analyze the effect of different initialization strategies for the adjacency matrix of the GCN, considering two choices, \\iedomains either disconnected (identity matrix, eye) or randomly connected (random adjacency matrix, rand). From Table 4, it is easy to see our method performances are not dependent on the particular initialization strategy, achieving over 88.5% for all choices with D=4ğ·4D=4. With random initialization though, the performance does not grow with the number of domains, which may indicate the importance of carefully initializing ğ€ğ€\\mathbf{A} as the number of domains grows. For this reason, in the following we always consider a uniform initialization strategy. Note that such a strategy allows the model to refine the domain-specific components separately before merging them based on their distance (see Eq.Â (3.3))."
        ]
    },
    "S4.T5": {
        "caption": "Table 5: Comparison with the state of the art on CelebA and FEMNIST. We separate the methods according to their setting.",
        "table": "<table id=\"S4.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T5.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T5.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></td>\n<td id=\"S4.T5.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T5.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S4.T5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T5.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Accuracy (%)</span></td>\n</tr>\n<tr id=\"S4.T5.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"2\"><span id=\"S4.T5.1.2.1.1\" class=\"ltx_text\">CelebA</span></td>\n<td id=\"S4.T5.1.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">FedAvg</td>\n<td id=\"S4.T5.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">86.88</td>\n</tr>\n<tr id=\"S4.T5.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.3.1\" class=\"ltx_td ltx_align_left\">FedCG</td>\n<td id=\"S4.T5.1.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.1.3.2.1\" class=\"ltx_text ltx_font_bold\">89.18</span></td>\n</tr>\n<tr id=\"S4.T5.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"2\"><span id=\"S4.T5.1.4.1.1\" class=\"ltx_text\">FEMNIST</span></td>\n<td id=\"S4.T5.1.4.2\" class=\"ltx_td ltx_align_left ltx_border_t\">FedAvg</td>\n<td id=\"S4.T5.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">77.81</td>\n</tr>\n<tr id=\"S4.T5.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.5.1\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T5.1.5.1.1\" class=\"ltx_text ltx_font_bold\">FedCG</span></td>\n<td id=\"S4.T5.1.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.1.5.2.1\" class=\"ltx_text ltx_font_bold\">83.41</span></td>\n</tr>\n<tr id=\"S4.T5.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.6.1\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.1.6.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-3</td>\n<td id=\"S4.T5.1.6.2\" class=\"ltx_td ltx_align_left\">FedProx</td>\n<td id=\"S4.T5.1.6.3\" class=\"ltx_td ltx_align_center\">75.00</td>\n</tr>\n<tr id=\"S4.T5.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_b\">\n<span id=\"S4.T5.1.7.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-3</td>\n<td id=\"S4.T5.1.7.2\" class=\"ltx_td ltx_align_left ltx_border_b\">SCAFFOLD</td>\n<td id=\"S4.T5.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_b\">84.20</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The experimental comparison is reported in Table 5. FedCGÂ largely outperforms FedAvg in both scenarios. It achieves 89.18%percent89.1889.18\\% accuracy compared to 86.88% of FedAvg on CelebA, and 83.41%percent83.4183.41\\% accuracy compared to 77.81% of FedAvg on FEMNIST. This latter improvement (+5.6%) is remarkable given the higher complexity of the classification task in FEMNIST. Comparing FedCGÂ with FedProx and SCAFFOLD on FEMNIST, we can see that FedCGÂ outperforms FedProx by a large margin (+8.41%) while being slightly inferior to SCAFFOLD (\\ie-0.79%). However, both FedProx and SCAFFOLD present results under different federated protocols, \\egFedProx runs the algorithm for 200 rounds of 10 clients while SCAFFOLD performs 1000 rounds with 20 clients each. Despite that, our comparisons demonstrate that FedCGÂ is far superior to the standard FedAvg baselines, due to its better ability to address the statistical heterogeneity across clients, while showing either superior (\\wrtFedProx) or competitive (\\wrtSCAFFOLD) results with other state-of-the-art algorithms trained on different settings."
        ]
    }
}