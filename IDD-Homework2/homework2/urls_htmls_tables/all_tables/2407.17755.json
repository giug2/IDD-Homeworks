{
    "S3.T1": {
        "caption": "Table 1: Hyperparameters",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Hyper parameters</th>\n<td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Specification</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Loss Function :</th>\n<td id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Binary Cross-Entropy</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Optimizer :</th>\n<td id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_left\">Adam with a learning rate of 0.00005</td>\n</tr>\n<tr id=\"S3.T1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Batch Size :</th>\n<td id=\"S3.T1.1.5.4.2\" class=\"ltx_td ltx_align_left\">32</td>\n</tr>\n<tr id=\"S3.T1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Regularization:</th>\n<td id=\"S3.T1.1.6.5.2\" class=\"ltx_td ltx_align_left\">L2 (0.001) on Dense layers</td>\n</tr>\n<tr id=\"S3.T1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Dropout Rate:</th>\n<td id=\"S3.T1.1.7.6.2\" class=\"ltx_td ltx_align_left\">0.5</td>\n</tr>\n<tr id=\"S3.T1.1.8.7\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Data Augmentation:</th>\n<td id=\"S3.T1.1.8.7.2\" class=\"ltx_td ltx_align_left\">Random zoom(0.15), horizontal flip, and vertical flip</td>\n</tr>\n<tr id=\"S3.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">Epochs:</th>\n<td id=\"S3.T1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_b\">\n<math id=\"S3.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"15\" display=\"inline\"><semantics id=\"S3.T1.1.1.1.m1.1a\"><mn id=\"S3.T1.1.1.1.m1.1.1\" xref=\"S3.T1.1.1.1.m1.1.1.cmml\">15</mn><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.1.1.1.m1.1b\"><cn type=\"integer\" id=\"S3.T1.1.1.1.m1.1.1.cmml\" xref=\"S3.T1.1.1.1.m1.1.1\">15</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.1.1.1.m1.1c\">15</annotation></semantics></math> epochs for DenseNet121 and InceptionV3 models</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "The model training and evaluation process involved the multiple steps. In the data Preprocessing, the images were resized to 224\u00d7224224224224\\times 224 pixels and preprocessed using the OpenCV and PIL libraries. A balanced dataset was created by oversampling the minority classes to a desired number of samples (500 per class) to handle class imbalance. The specification for the hyperparameters are provided in Table 1."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Comparative analysis among the proposed model and existing models across evaluation metrics including Precision, Recall, Accuracy, Cohen\u2019s Kappa Score, and F1 Score.",
        "table": "<table id=\"S4.T2.4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Model</th>\n<th id=\"S4.T2.4.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Precision</th>\n<th id=\"S4.T2.4.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Recall</th>\n<th id=\"S4.T2.4.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Accuracy</th>\n<th id=\"S4.T2.4.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Cohen&#8217;s</th>\n<th id=\"S4.T2.4.1.1.1.6\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\">F1</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.4.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.1.2.1.1\" class=\"ltx_td\"></td>\n<th id=\"S4.T2.4.1.2.1.2\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S4.T2.4.1.2.1.3\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S4.T2.4.1.2.1.4\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S4.T2.4.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Kappa Score</th>\n<td id=\"S4.T2.4.1.2.1.6\" class=\"ltx_td ltx_nopad_r\"></td>\n</tr>\n<tr id=\"S4.T2.4.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Vgg16<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a>]</cite>\n</td>\n<td id=\"S4.T2.4.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.95</td>\n<td id=\"S4.T2.4.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.99</td>\n<td id=\"S4.T2.4.1.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.96</td>\n<td id=\"S4.T2.4.1.3.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.92</td>\n<td id=\"S4.T2.4.1.3.2.6\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\">0.97</td>\n</tr>\n<tr id=\"S4.T2.4.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.1.4.3.1\" class=\"ltx_td ltx_align_left\">Resnet50</td>\n<td id=\"S4.T2.4.1.4.3.2\" class=\"ltx_td ltx_align_left\">0.98</td>\n<td id=\"S4.T2.4.1.4.3.3\" class=\"ltx_td ltx_align_left\">0.97</td>\n<td id=\"S4.T2.4.1.4.3.4\" class=\"ltx_td ltx_align_left\">0.97</td>\n<td id=\"S4.T2.4.1.4.3.5\" class=\"ltx_td ltx_align_left\">0.94</td>\n<td id=\"S4.T2.4.1.4.3.6\" class=\"ltx_td ltx_nopad_r ltx_align_left\">0.97</td>\n</tr>\n<tr id=\"S4.T2.4.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.1.5.4.1\" class=\"ltx_td ltx_align_left\">Xception<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">7</a>]</cite>\n</td>\n<td id=\"S4.T2.4.1.5.4.2\" class=\"ltx_td ltx_align_left\">0.97</td>\n<td id=\"S4.T2.4.1.5.4.3\" class=\"ltx_td ltx_align_left\">0.99</td>\n<td id=\"S4.T2.4.1.5.4.4\" class=\"ltx_td ltx_align_left\">0.98</td>\n<td id=\"S4.T2.4.1.5.4.5\" class=\"ltx_td ltx_align_left\">0.95</td>\n<td id=\"S4.T2.4.1.5.4.6\" class=\"ltx_td ltx_nopad_r ltx_align_left\">0.97</td>\n</tr>\n<tr id=\"S4.T2.4.1.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.1.6.5.1\" class=\"ltx_td ltx_align_left\">InceptionV3<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite>\n</td>\n<td id=\"S4.T2.4.1.6.5.2\" class=\"ltx_td ltx_align_left\">0.98</td>\n<td id=\"S4.T2.4.1.6.5.3\" class=\"ltx_td ltx_align_left\">0.98</td>\n<td id=\"S4.T2.4.1.6.5.4\" class=\"ltx_td ltx_align_left\">0.98</td>\n<td id=\"S4.T2.4.1.6.5.5\" class=\"ltx_td ltx_align_left\">0.96</td>\n<td id=\"S4.T2.4.1.6.5.6\" class=\"ltx_td ltx_nopad_r ltx_align_left\">0.98</td>\n</tr>\n<tr id=\"S4.T2.4.1.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.1.7.6.1\" class=\"ltx_td ltx_align_left\">Densenet121<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">28</a>]</cite>\n</td>\n<td id=\"S4.T2.4.1.7.6.2\" class=\"ltx_td ltx_align_left\">0.98</td>\n<td id=\"S4.T2.4.1.7.6.3\" class=\"ltx_td ltx_align_left\">0.97</td>\n<td id=\"S4.T2.4.1.7.6.4\" class=\"ltx_td ltx_align_left\">0.97</td>\n<td id=\"S4.T2.4.1.7.6.5\" class=\"ltx_td ltx_align_left\">0.94</td>\n<td id=\"S4.T2.4.1.7.6.6\" class=\"ltx_td ltx_nopad_r ltx_align_left\">0.97</td>\n</tr>\n<tr id=\"S4.T2.4.1.8.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.4.1.8.7.1.1\" class=\"ltx_text ltx_font_bold\">Proposed Model</span></td>\n<td id=\"S4.T2.4.1.8.7.2\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.4.1.8.7.2.1\" class=\"ltx_text ltx_font_bold\">0.99</span></td>\n<td id=\"S4.T2.4.1.8.7.3\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.4.1.8.7.3.1\" class=\"ltx_text ltx_font_bold\">0.99</span></td>\n<td id=\"S4.T2.4.1.8.7.4\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.4.1.8.7.4.1\" class=\"ltx_text ltx_font_bold\">0.99</span></td>\n<td id=\"S4.T2.4.1.8.7.5\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.4.1.8.7.5.1\" class=\"ltx_text ltx_font_bold\">0.98</span></td>\n<td id=\"S4.T2.4.1.8.7.6\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\"><span id=\"S4.T2.4.1.8.7.6.1\" class=\"ltx_text ltx_font_bold\">0.99</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Tabel 2 and Fig. 6 illustrate the superior performance of the proposed hybrid model against other well-known deep learning architectures in detecting diabetic retinopathy. Our model demonstrates higher accuracy and recall, showcasing its effectiveness in this task. Specifically, our ensemble model, leveraging InceptionV3 and Densenet121, achieves outstanding results across all metrics. Notably, it achieves a specificity and precision of 0.99, an accuracy rate of 0.99, and a Cohen\u2019s Kappa Score of 0.98. These outcomes underscore the capability of our model to capture both local and global features in retinal images, thereby significantly enhancing diabetic retinopathy detection. Consequently, our ensemble model emerges as a promising tool to support clinicians in diagnosis."
        ]
    }
}