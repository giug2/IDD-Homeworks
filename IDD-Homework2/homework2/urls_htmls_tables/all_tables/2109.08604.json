{
    "PAPER'S NUMBER OF TABLES": 5,
    "S4.T1": {
        "caption": "Table 1: Performance in the central (i.e. non-federated) setting on the Adult dataset.\nThe fairness metric optimized is FNR parity.\nThe tolerance for BMDM and MMDM is α=0.02𝛼0.02\\alpha=0.02.\n",
        "table": "<table id=\"S4.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Algorithm</span></th>\n<th id=\"S4.T1.3.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S4.T1.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n<th id=\"S4.T1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\">FNR gap</span></th>\n<th id=\"S4.T1.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.3.1.1.4.1\" class=\"ltx_text ltx_font_bold\">EO gap</span></th>\n<th id=\"S4.T1.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.3.1.1.5.1\" class=\"ltx_text ltx_font_bold\">DemP gap</span></th>\n<th id=\"S4.T1.3.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.3.1.1.6.1\" class=\"ltx_text ltx_font_bold\">PP gap</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.3.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">SGD</th>\n<th id=\"S4.T1.3.2.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.857</th>\n<td id=\"S4.T1.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.071</td>\n<td id=\"S4.T1.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.071</td>\n<td id=\"S4.T1.3.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.113</td>\n<td id=\"S4.T1.3.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.016</td>\n</tr>\n<tr id=\"S4.T1.3.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">\n<cite class=\"ltx_cite ltx_citemacro_citet\">Tran et al. [<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">2021</a>]</cite> without privacy</th>\n<th id=\"S4.T1.3.3.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">0.856</th>\n<td id=\"S4.T1.3.3.2.3\" class=\"ltx_td ltx_align_center\">0.048</td>\n<td id=\"S4.T1.3.3.2.4\" class=\"ltx_td ltx_align_center\">0.048</td>\n<td id=\"S4.T1.3.3.2.5\" class=\"ltx_td ltx_align_center\">0.108</td>\n<td id=\"S4.T1.3.3.2.6\" class=\"ltx_td ltx_align_center\">0.036</td>\n</tr>\n<tr id=\"S4.T1.3.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">BMDM</th>\n<th id=\"S4.T1.3.4.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">0.857</th>\n<td id=\"S4.T1.3.4.3.3\" class=\"ltx_td ltx_align_center\">0.001</td>\n<td id=\"S4.T1.3.4.3.4\" class=\"ltx_td ltx_align_center\">0.030</td>\n<td id=\"S4.T1.3.4.3.5\" class=\"ltx_td ltx_align_center\">0.094</td>\n<td id=\"S4.T1.3.4.3.6\" class=\"ltx_td ltx_align_center\">0.046</td>\n</tr>\n<tr id=\"S4.T1.3.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">MMDM (this paper)</th>\n<th id=\"S4.T1.3.5.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">0.856</th>\n<td id=\"S4.T1.3.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.005</td>\n<td id=\"S4.T1.3.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.028</td>\n<td id=\"S4.T1.3.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.091</td>\n<td id=\"S4.T1.3.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.063</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We start our experiments comparing the performance and fairness in the central, non-federated, non-private setting. We trained a shallow network (consisting of one hidden layer with 10 hidden units and a ReLU activation function) with these algorithms, where we tried to enforce FNR parity with a tolerance ",
                "α",
                "=",
                "0.02",
                "𝛼",
                "0.02",
                "\\alpha=0.02",
                ". For MMDM, the damping parameter is ",
                "c",
                "=",
                "2",
                "𝑐",
                "2",
                "c=2",
                ". For ",
                "Tran et al. [",
                "2021",
                "]",
                ", the multiplier threshold is ",
                "λ",
                "max",
                "=",
                "0.05",
                "subscript",
                "𝜆",
                "max",
                "0.05",
                "\\lambda_{\\textnormal{max}}=0.05",
                ". The results after 1,000 iterations are displayed in ",
                "Table",
                " ",
                "1",
                ", which also shows the gap in other common measures of fairness such as the equalized odds, the demographic parity, or the predictive parity, see e.g. ",
                "Castelnovo et al. [",
                "2021",
                "]",
                ".",
                "Compared to Federated SGD, the MMDM algorithm reduces the FNR gap from 7% to 0.5%, while hardly reducing the accuracy of the model.\nSimilarly, the gap in the equalized odds (EO), which is a stronger fairness notion than the FNR parity, also decreases from around 7% to 3%. Moreover, the demographic parity (DemP) gap, which considers the probability of predicting one or the other target class, also improves. In terms of predictive parity (PP), which uses the precision as the performance function, the MMDM algorithm did not improve the parity among groups.\nThe BMDM algorithm, which lacks a quadratic term of the fairness function, performs even slightly better in the central scenario.\nHowever, the algorithm from ",
                "Tran et al. [",
                "2021",
                "]",
                ", an approximation to BMDM as discussed in ",
                "Section",
                " ",
                "3.1",
                ", gives only a small improvement. Therefore, we continue our analysis to the federated and private settings only with the BMDM and MMDM algorithms.",
                "The second experiment is to study how federated learning, clipping, and DP decrease the performance for the under-represented groups, thus increasing the fairness gap on the different fairness metrics. For that, we trained the same network with ",
                "FederatedSGD",
                " and versions of this algorithm where only clipping was performed and where both clipping and DP where included. They were trained with a cohort size of ",
                "m",
                "=",
                "200",
                "𝑚",
                "200",
                "m=200",
                " for ",
                "T",
                "=",
                "1",
                ",",
                "000",
                "𝑇",
                "1",
                "000",
                "T=1,000",
                " iterations and the model with best training cohort accuracy was selected. The privacy parameters are ",
                "(",
                "ϵ",
                ",",
                "δ",
                ")",
                "=",
                "(",
                "2",
                ",",
                "5",
                "⋅",
                "10",
                "−",
                "5",
                ")",
                "italic-ϵ",
                "𝛿",
                "2",
                "⋅",
                "5",
                "superscript",
                "10",
                "5",
                "(\\epsilon,\\delta)=(2,5\\cdot 10^{-5})",
                ".\nThe results are displayed in ",
                "Table",
                " ",
                "2",
                ". The network becomes less fair under all the metrics considered, compared with the central setting. Moreover, the introduction of clipping largely increases the unfairness of the models reaching more than a 16% gap in FNR. The addition of DP requires an increase in cohort size from 200 to ",
                "1",
                ",",
                "000",
                "1",
                "000",
                "1,000",
                ", but does not have a larger effect on the unfairness of the models (see ",
                "Table",
                " ",
                "5",
                " in ",
                "Section",
                " ",
                "B.1",
                " for the details). These observations are in line with ",
                "[Bagdasaryan et al., ",
                "2019",
                "]",
                ", where they note that the under-represented groups usually have the higher loss gradients and thus clipping affects them more than the majority groups.",
                "After that, we repeated the above experiment with ",
                "FPFL",
                " and BMDM with DP. ",
                "FPFL",
                " and BMDM with DP converged to a solution faster than ",
                "FederatedSGD",
                ", and thus the models were trained for only ",
                "T",
                "=",
                "250",
                "𝑇",
                "250",
                "T=250",
                " iterations. Here the model with the best training cohort accuracy while respecting the fairness condition on the training cohort data was selected.\nNote that the fairness condition is evaluated with noisy statistics, so a model may be deemed as fair while slightly violating the desired constraints. The results are also included in ",
                "Table",
                " ",
                "2",
                " to aid the comparison. We note how, similarly to the central case, the model trained with ",
                "FPFL",
                " manages to enforce the fairness constraints while keeping a similar accuracy. In contrast, BMDM seems to not be able to find network weights that respect the fairness conditions, as expected by the less favorable (“less convex”) loss surface around these solutions. Moreover, clipping does not seem to affect largely the performance of ",
                "FPFL",
                " since it compensates the gradient loss clipping with the fairness enforcement."
            ]
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Performance of a neural network on the Adult dataset when trained with FL.\nThe fairness metric considered for BMDM-FL and FPFL is FNR parity and the tolerance is α=0.02𝛼0.02\\alpha=0.02.",
        "table": "<table id=\"S4.T2.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.5.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T2.5.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Algorithm</span></th>\n<th id=\"S4.T2.5.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S4.T2.5.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n<th id=\"S4.T2.5.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.5.1.1.3.1\" class=\"ltx_text ltx_font_bold\">FNR gap</span></th>\n<th id=\"S4.T2.5.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.5.1.1.4.1\" class=\"ltx_text ltx_font_bold\">EO gap</span></th>\n<th id=\"S4.T2.5.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.5.1.1.5.1\" class=\"ltx_text ltx_font_bold\">DemP gap</span></th>\n<th id=\"S4.T2.5.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.5.1.1.6.1\" class=\"ltx_text ltx_font_bold\">PP gap</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.5.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FL</th>\n<th id=\"S4.T2.5.2.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.851</th>\n<td id=\"S4.T2.5.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.121</td>\n<td id=\"S4.T2.5.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.121</td>\n<td id=\"S4.T2.5.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.122</td>\n<td id=\"S4.T2.5.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.037</td>\n</tr>\n<tr id=\"S4.T2.5.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">BMDM-FL</th>\n<th id=\"S4.T2.5.3.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">0.854</th>\n<td id=\"S4.T2.5.3.2.3\" class=\"ltx_td ltx_align_center\">0.043</td>\n<td id=\"S4.T2.5.3.2.4\" class=\"ltx_td ltx_align_center\">0.043</td>\n<td id=\"S4.T2.5.3.2.5\" class=\"ltx_td ltx_align_center\">0.101</td>\n<td id=\"S4.T2.5.3.2.6\" class=\"ltx_td ltx_align_center\">0.016</td>\n</tr>\n<tr id=\"S4.T2.5.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Fair FL</th>\n<th id=\"S4.T2.5.4.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">0.855</th>\n<td id=\"S4.T2.5.4.3.3\" class=\"ltx_td ltx_align_center\">0.036</td>\n<td id=\"S4.T2.5.4.3.4\" class=\"ltx_td ltx_align_center\">0.039</td>\n<td id=\"S4.T2.5.4.3.5\" class=\"ltx_td ltx_align_center\">0.108</td>\n<td id=\"S4.T2.5.4.3.6\" class=\"ltx_td ltx_align_center\">0.033</td>\n</tr>\n<tr id=\"S4.T2.5.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FL + Clip</th>\n<th id=\"S4.T2.5.5.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.844</th>\n<td id=\"S4.T2.5.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.169</td>\n<td id=\"S4.T2.5.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.169</td>\n<td id=\"S4.T2.5.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.129</td>\n<td id=\"S4.T2.5.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.051</td>\n</tr>\n<tr id=\"S4.T2.5.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">BMDM-FL + Clip</th>\n<th id=\"S4.T2.5.6.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">0.851</th>\n<td id=\"S4.T2.5.6.5.3\" class=\"ltx_td ltx_align_center\">0.052</td>\n<td id=\"S4.T2.5.6.5.4\" class=\"ltx_td ltx_align_center\">0.052</td>\n<td id=\"S4.T2.5.6.5.5\" class=\"ltx_td ltx_align_center\">0.105</td>\n<td id=\"S4.T2.5.6.5.6\" class=\"ltx_td ltx_align_center\">0.008</td>\n</tr>\n<tr id=\"S4.T2.5.7.6\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Fair FL + Clip</th>\n<th id=\"S4.T2.5.7.6.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">0.853</th>\n<td id=\"S4.T2.5.7.6.3\" class=\"ltx_td ltx_align_center\">0.018</td>\n<td id=\"S4.T2.5.7.6.4\" class=\"ltx_td ltx_align_center\">0.029</td>\n<td id=\"S4.T2.5.7.6.5\" class=\"ltx_td ltx_align_center\">0.090</td>\n<td id=\"S4.T2.5.7.6.6\" class=\"ltx_td ltx_align_center\">0.016</td>\n</tr>\n<tr id=\"S4.T2.5.8.7\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Private FL</th>\n<th id=\"S4.T2.5.8.7.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.847</th>\n<td id=\"S4.T2.5.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.148</td>\n<td id=\"S4.T2.5.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.148</td>\n<td id=\"S4.T2.5.8.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.126</td>\n<td id=\"S4.T2.5.8.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.041</td>\n</tr>\n<tr id=\"S4.T2.5.9.8\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">BMDM-PFL</th>\n<th id=\"S4.T2.5.9.8.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">0.850</th>\n<td id=\"S4.T2.5.9.8.3\" class=\"ltx_td ltx_align_center\">0.023</td>\n<td id=\"S4.T2.5.9.8.4\" class=\"ltx_td ltx_align_center\">0.035</td>\n<td id=\"S4.T2.5.9.8.5\" class=\"ltx_td ltx_align_center\">0.097</td>\n<td id=\"S4.T2.5.9.8.6\" class=\"ltx_td ltx_align_center\">0.009</td>\n</tr>\n<tr id=\"S4.T2.5.10.9\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Fair Private FL</th>\n<th id=\"S4.T2.5.10.9.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">0.851</th>\n<td id=\"S4.T2.5.10.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.001</td>\n<td id=\"S4.T2.5.10.9.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.027</td>\n<td id=\"S4.T2.5.10.9.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.087</td>\n<td id=\"S4.T2.5.10.9.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.042</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We start our experiments comparing the performance and fairness in the central, non-federated, non-private setting. We trained a shallow network (consisting of one hidden layer with 10 hidden units and a ReLU activation function) with these algorithms, where we tried to enforce FNR parity with a tolerance ",
                "α",
                "=",
                "0.02",
                "𝛼",
                "0.02",
                "\\alpha=0.02",
                ". For MMDM, the damping parameter is ",
                "c",
                "=",
                "2",
                "𝑐",
                "2",
                "c=2",
                ". For ",
                "Tran et al. [",
                "2021",
                "]",
                ", the multiplier threshold is ",
                "λ",
                "max",
                "=",
                "0.05",
                "subscript",
                "𝜆",
                "max",
                "0.05",
                "\\lambda_{\\textnormal{max}}=0.05",
                ". The results after 1,000 iterations are displayed in ",
                "Table",
                " ",
                "1",
                ", which also shows the gap in other common measures of fairness such as the equalized odds, the demographic parity, or the predictive parity, see e.g. ",
                "Castelnovo et al. [",
                "2021",
                "]",
                ".",
                "Compared to Federated SGD, the MMDM algorithm reduces the FNR gap from 7% to 0.5%, while hardly reducing the accuracy of the model.\nSimilarly, the gap in the equalized odds (EO), which is a stronger fairness notion than the FNR parity, also decreases from around 7% to 3%. Moreover, the demographic parity (DemP) gap, which considers the probability of predicting one or the other target class, also improves. In terms of predictive parity (PP), which uses the precision as the performance function, the MMDM algorithm did not improve the parity among groups.\nThe BMDM algorithm, which lacks a quadratic term of the fairness function, performs even slightly better in the central scenario.\nHowever, the algorithm from ",
                "Tran et al. [",
                "2021",
                "]",
                ", an approximation to BMDM as discussed in ",
                "Section",
                " ",
                "3.1",
                ", gives only a small improvement. Therefore, we continue our analysis to the federated and private settings only with the BMDM and MMDM algorithms.",
                "The second experiment is to study how federated learning, clipping, and DP decrease the performance for the under-represented groups, thus increasing the fairness gap on the different fairness metrics. For that, we trained the same network with ",
                "FederatedSGD",
                " and versions of this algorithm where only clipping was performed and where both clipping and DP where included. They were trained with a cohort size of ",
                "m",
                "=",
                "200",
                "𝑚",
                "200",
                "m=200",
                " for ",
                "T",
                "=",
                "1",
                ",",
                "000",
                "𝑇",
                "1",
                "000",
                "T=1,000",
                " iterations and the model with best training cohort accuracy was selected. The privacy parameters are ",
                "(",
                "ϵ",
                ",",
                "δ",
                ")",
                "=",
                "(",
                "2",
                ",",
                "5",
                "⋅",
                "10",
                "−",
                "5",
                ")",
                "italic-ϵ",
                "𝛿",
                "2",
                "⋅",
                "5",
                "superscript",
                "10",
                "5",
                "(\\epsilon,\\delta)=(2,5\\cdot 10^{-5})",
                ".\nThe results are displayed in ",
                "Table",
                " ",
                "2",
                ". The network becomes less fair under all the metrics considered, compared with the central setting. Moreover, the introduction of clipping largely increases the unfairness of the models reaching more than a 16% gap in FNR. The addition of DP requires an increase in cohort size from 200 to ",
                "1",
                ",",
                "000",
                "1",
                "000",
                "1,000",
                ", but does not have a larger effect on the unfairness of the models (see ",
                "Table",
                " ",
                "5",
                " in ",
                "Section",
                " ",
                "B.1",
                " for the details). These observations are in line with ",
                "[Bagdasaryan et al., ",
                "2019",
                "]",
                ", where they note that the under-represented groups usually have the higher loss gradients and thus clipping affects them more than the majority groups.",
                "After that, we repeated the above experiment with ",
                "FPFL",
                " and BMDM with DP. ",
                "FPFL",
                " and BMDM with DP converged to a solution faster than ",
                "FederatedSGD",
                ", and thus the models were trained for only ",
                "T",
                "=",
                "250",
                "𝑇",
                "250",
                "T=250",
                " iterations. Here the model with the best training cohort accuracy while respecting the fairness condition on the training cohort data was selected.\nNote that the fairness condition is evaluated with noisy statistics, so a model may be deemed as fair while slightly violating the desired constraints. The results are also included in ",
                "Table",
                " ",
                "2",
                " to aid the comparison. We note how, similarly to the central case, the model trained with ",
                "FPFL",
                " manages to enforce the fairness constraints while keeping a similar accuracy. In contrast, BMDM seems to not be able to find network weights that respect the fairness conditions, as expected by the less favorable (“less convex”) loss surface around these solutions. Moreover, clipping does not seem to affect largely the performance of ",
                "FPFL",
                " since it compensates the gradient loss clipping with the fairness enforcement."
            ]
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Performance of a convolutional network on the Unfair FEMNIST when trained with different algorithms: like Table 2, starting with FederatedSGD and ending with FPFL.\nThe fairness metric considered for FPFL is accuracy parity and the tolerance is α=0.04𝛼0.04\\alpha=0.04.",
        "table": "<table id=\"S4.T3.14\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.14.13.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.14.13.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"S4.T3.14.13.1.1.1\" class=\"ltx_text ltx_font_bold\">Algo.</span></th>\n<td id=\"S4.T3.14.13.1.2\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T3.14.13.1.2.1\" class=\"ltx_text ltx_font_bold\">Population</span></td>\n<th id=\"S4.T3.14.13.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_tt\">\n<span id=\"S4.T3.14.13.1.3.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span>\n</th>\n<td id=\"S4.T3.14.13.1.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_tt\"><span id=\"S4.T3.14.13.1.4.1\" class=\"ltx_text ltx_font_bold\">Acc. gap</span></td>\n</tr>\n<tr id=\"S4.T3.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"4\"><math id=\"S4.T3.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"m=100\" display=\"inline\"><semantics id=\"S4.T3.3.1.1.m1.1a\"><mrow id=\"S4.T3.3.1.1.m1.1.1\" xref=\"S4.T3.3.1.1.m1.1.1.cmml\"><mi id=\"S4.T3.3.1.1.m1.1.1.2\" xref=\"S4.T3.3.1.1.m1.1.1.2.cmml\">m</mi><mo id=\"S4.T3.3.1.1.m1.1.1.1\" xref=\"S4.T3.3.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T3.3.1.1.m1.1.1.3\" xref=\"S4.T3.3.1.1.m1.1.1.3.cmml\">100</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.3.1.1.m1.1b\"><apply id=\"S4.T3.3.1.1.m1.1.1.cmml\" xref=\"S4.T3.3.1.1.m1.1.1\"><eq id=\"S4.T3.3.1.1.m1.1.1.1.cmml\" xref=\"S4.T3.3.1.1.m1.1.1.1\"></eq><ci id=\"S4.T3.3.1.1.m1.1.1.2.cmml\" xref=\"S4.T3.3.1.1.m1.1.1.2\">𝑚</ci><cn type=\"integer\" id=\"S4.T3.3.1.1.m1.1.1.3.cmml\" xref=\"S4.T3.3.1.1.m1.1.1.3\">100</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.3.1.1.m1.1c\">m=100</annotation></semantics></math></th>\n</tr>\n<tr id=\"S4.T3.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.2.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\">FL</th>\n<td id=\"S4.T3.4.2.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S4.T3.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S4.T3.4.2.1.m1.1a\"><mi id=\"S4.T3.4.2.1.m1.1.1\" xref=\"S4.T3.4.2.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.4.2.1.m1.1b\"><ci id=\"S4.T3.4.2.1.m1.1.1.cmml\" xref=\"S4.T3.4.2.1.m1.1.1\">𝐾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.4.2.1.m1.1c\">K</annotation></semantics></math></td>\n<th id=\"S4.T3.4.2.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t\">0.960</th>\n<td id=\"S4.T3.4.2.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\">0.134</td>\n</tr>\n<tr id=\"S4.T3.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row\">FFL</th>\n<td id=\"S4.T3.5.3.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r\"><math id=\"S4.T3.5.3.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S4.T3.5.3.1.m1.1a\"><mi id=\"S4.T3.5.3.1.m1.1.1\" xref=\"S4.T3.5.3.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.5.3.1.m1.1b\"><ci id=\"S4.T3.5.3.1.m1.1.1.cmml\" xref=\"S4.T3.5.3.1.m1.1.1\">𝐾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.5.3.1.m1.1c\">K</annotation></semantics></math></td>\n<th id=\"S4.T3.5.3.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">0.950</th>\n<td id=\"S4.T3.5.3.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">0.047</td>\n</tr>\n<tr id=\"S4.T3.6.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.6.4.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\">FL + Clip</th>\n<td id=\"S4.T3.6.4.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S4.T3.6.4.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S4.T3.6.4.1.m1.1a\"><mi id=\"S4.T3.6.4.1.m1.1.1\" xref=\"S4.T3.6.4.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.6.4.1.m1.1b\"><ci id=\"S4.T3.6.4.1.m1.1.1.cmml\" xref=\"S4.T3.6.4.1.m1.1.1\">𝐾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.6.4.1.m1.1c\">K</annotation></semantics></math></td>\n<th id=\"S4.T3.6.4.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t\">0.946</th>\n<td id=\"S4.T3.6.4.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\">0.166</td>\n</tr>\n<tr id=\"S4.T3.7.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.7.5.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row\">FFL + Clip</th>\n<td id=\"S4.T3.7.5.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r\"><math id=\"S4.T3.7.5.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S4.T3.7.5.1.m1.1a\"><mi id=\"S4.T3.7.5.1.m1.1.1\" xref=\"S4.T3.7.5.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.7.5.1.m1.1b\"><ci id=\"S4.T3.7.5.1.m1.1.1.cmml\" xref=\"S4.T3.7.5.1.m1.1.1\">𝐾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.7.5.1.m1.1c\">K</annotation></semantics></math></td>\n<th id=\"S4.T3.7.5.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">0.954</th>\n<td id=\"S4.T3.7.5.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">0.053</td>\n</tr>\n<tr id=\"S4.T3.8.6\" class=\"ltx_tr\">\n<th id=\"S4.T3.8.6.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\">PFL</th>\n<td id=\"S4.T3.8.6.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S4.T3.8.6.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S4.T3.8.6.1.m1.1a\"><mi id=\"S4.T3.8.6.1.m1.1.1\" xref=\"S4.T3.8.6.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.8.6.1.m1.1b\"><ci id=\"S4.T3.8.6.1.m1.1.1.cmml\" xref=\"S4.T3.8.6.1.m1.1.1\">𝐾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.8.6.1.m1.1c\">K</annotation></semantics></math></td>\n<th id=\"S4.T3.8.6.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t\">0.807</th>\n<td id=\"S4.T3.8.6.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\">0.409</td>\n</tr>\n<tr id=\"S4.T3.9.7\" class=\"ltx_tr\">\n<th id=\"S4.T3.9.7.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row\">FPFL</th>\n<td id=\"S4.T3.9.7.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r\"><math id=\"S4.T3.9.7.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S4.T3.9.7.1.m1.1a\"><mi id=\"S4.T3.9.7.1.m1.1.1\" xref=\"S4.T3.9.7.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.9.7.1.m1.1b\"><ci id=\"S4.T3.9.7.1.m1.1.1.cmml\" xref=\"S4.T3.9.7.1.m1.1.1\">𝐾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.9.7.1.m1.1c\">K</annotation></semantics></math></td>\n<th id=\"S4.T3.9.7.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">0.093</th>\n<td id=\"S4.T3.9.7.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">0.015</td>\n</tr>\n<tr id=\"S4.T3.10.8\" class=\"ltx_tr\">\n<th id=\"S4.T3.10.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"4\"><math id=\"S4.T3.10.8.1.m1.2\" class=\"ltx_Math\" alttext=\"m=2,000\" display=\"inline\"><semantics id=\"S4.T3.10.8.1.m1.2a\"><mrow id=\"S4.T3.10.8.1.m1.2.3\" xref=\"S4.T3.10.8.1.m1.2.3.cmml\"><mi id=\"S4.T3.10.8.1.m1.2.3.2\" xref=\"S4.T3.10.8.1.m1.2.3.2.cmml\">m</mi><mo id=\"S4.T3.10.8.1.m1.2.3.1\" xref=\"S4.T3.10.8.1.m1.2.3.1.cmml\">=</mo><mrow id=\"S4.T3.10.8.1.m1.2.3.3.2\" xref=\"S4.T3.10.8.1.m1.2.3.3.1.cmml\"><mn id=\"S4.T3.10.8.1.m1.1.1\" xref=\"S4.T3.10.8.1.m1.1.1.cmml\">2</mn><mo id=\"S4.T3.10.8.1.m1.2.3.3.2.1\" xref=\"S4.T3.10.8.1.m1.2.3.3.1.cmml\">,</mo><mn id=\"S4.T3.10.8.1.m1.2.2\" xref=\"S4.T3.10.8.1.m1.2.2.cmml\">000</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.10.8.1.m1.2b\"><apply id=\"S4.T3.10.8.1.m1.2.3.cmml\" xref=\"S4.T3.10.8.1.m1.2.3\"><eq id=\"S4.T3.10.8.1.m1.2.3.1.cmml\" xref=\"S4.T3.10.8.1.m1.2.3.1\"></eq><ci id=\"S4.T3.10.8.1.m1.2.3.2.cmml\" xref=\"S4.T3.10.8.1.m1.2.3.2\">𝑚</ci><list id=\"S4.T3.10.8.1.m1.2.3.3.1.cmml\" xref=\"S4.T3.10.8.1.m1.2.3.3.2\"><cn type=\"integer\" id=\"S4.T3.10.8.1.m1.1.1.cmml\" xref=\"S4.T3.10.8.1.m1.1.1\">2</cn><cn type=\"integer\" id=\"S4.T3.10.8.1.m1.2.2.cmml\" xref=\"S4.T3.10.8.1.m1.2.2\">000</cn></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.10.8.1.m1.2c\">m=2,000</annotation></semantics></math></th>\n</tr>\n<tr id=\"S4.T3.11.9\" class=\"ltx_tr\">\n<th id=\"S4.T3.11.9.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\">PFL</th>\n<td id=\"S4.T3.11.9.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S4.T3.11.9.1.m1.1\" class=\"ltx_Math\" alttext=\"100K\" display=\"inline\"><semantics id=\"S4.T3.11.9.1.m1.1a\"><mrow id=\"S4.T3.11.9.1.m1.1.1\" xref=\"S4.T3.11.9.1.m1.1.1.cmml\"><mn id=\"S4.T3.11.9.1.m1.1.1.2\" xref=\"S4.T3.11.9.1.m1.1.1.2.cmml\">100</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.11.9.1.m1.1.1.1\" xref=\"S4.T3.11.9.1.m1.1.1.1.cmml\">​</mo><mi id=\"S4.T3.11.9.1.m1.1.1.3\" xref=\"S4.T3.11.9.1.m1.1.1.3.cmml\">K</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.11.9.1.m1.1b\"><apply id=\"S4.T3.11.9.1.m1.1.1.cmml\" xref=\"S4.T3.11.9.1.m1.1.1\"><times id=\"S4.T3.11.9.1.m1.1.1.1.cmml\" xref=\"S4.T3.11.9.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"S4.T3.11.9.1.m1.1.1.2.cmml\" xref=\"S4.T3.11.9.1.m1.1.1.2\">100</cn><ci id=\"S4.T3.11.9.1.m1.1.1.3.cmml\" xref=\"S4.T3.11.9.1.m1.1.1.3\">𝐾</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.11.9.1.m1.1c\">100K</annotation></semantics></math></td>\n<th id=\"S4.T3.11.9.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t\">0.951</th>\n<td id=\"S4.T3.11.9.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\">0.157</td>\n</tr>\n<tr id=\"S4.T3.12.10\" class=\"ltx_tr\">\n<th id=\"S4.T3.12.10.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row\">FPFL</th>\n<td id=\"S4.T3.12.10.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r\"><math id=\"S4.T3.12.10.1.m1.1\" class=\"ltx_Math\" alttext=\"100K\" display=\"inline\"><semantics id=\"S4.T3.12.10.1.m1.1a\"><mrow id=\"S4.T3.12.10.1.m1.1.1\" xref=\"S4.T3.12.10.1.m1.1.1.cmml\"><mn id=\"S4.T3.12.10.1.m1.1.1.2\" xref=\"S4.T3.12.10.1.m1.1.1.2.cmml\">100</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.12.10.1.m1.1.1.1\" xref=\"S4.T3.12.10.1.m1.1.1.1.cmml\">​</mo><mi id=\"S4.T3.12.10.1.m1.1.1.3\" xref=\"S4.T3.12.10.1.m1.1.1.3.cmml\">K</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.12.10.1.m1.1b\"><apply id=\"S4.T3.12.10.1.m1.1.1.cmml\" xref=\"S4.T3.12.10.1.m1.1.1\"><times id=\"S4.T3.12.10.1.m1.1.1.1.cmml\" xref=\"S4.T3.12.10.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"S4.T3.12.10.1.m1.1.1.2.cmml\" xref=\"S4.T3.12.10.1.m1.1.1.2\">100</cn><ci id=\"S4.T3.12.10.1.m1.1.1.3.cmml\" xref=\"S4.T3.12.10.1.m1.1.1.3\">𝐾</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.12.10.1.m1.1c\">100K</annotation></semantics></math></td>\n<th id=\"S4.T3.12.10.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">0.903</th>\n<td id=\"S4.T3.12.10.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">0.074</td>\n</tr>\n<tr id=\"S4.T3.13.11\" class=\"ltx_tr\">\n<th id=\"S4.T3.13.11.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row\">PFL</th>\n<td id=\"S4.T3.13.11.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r\"><math id=\"S4.T3.13.11.1.m1.2\" class=\"ltx_Math\" alttext=\"1,000K\" display=\"inline\"><semantics id=\"S4.T3.13.11.1.m1.2a\"><mrow id=\"S4.T3.13.11.1.m1.2.2.1\" xref=\"S4.T3.13.11.1.m1.2.2.2.cmml\"><mn id=\"S4.T3.13.11.1.m1.1.1\" xref=\"S4.T3.13.11.1.m1.1.1.cmml\">1</mn><mo id=\"S4.T3.13.11.1.m1.2.2.1.2\" xref=\"S4.T3.13.11.1.m1.2.2.2.cmml\">,</mo><mrow id=\"S4.T3.13.11.1.m1.2.2.1.1\" xref=\"S4.T3.13.11.1.m1.2.2.1.1.cmml\"><mn id=\"S4.T3.13.11.1.m1.2.2.1.1.2\" xref=\"S4.T3.13.11.1.m1.2.2.1.1.2.cmml\">000</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.13.11.1.m1.2.2.1.1.1\" xref=\"S4.T3.13.11.1.m1.2.2.1.1.1.cmml\">​</mo><mi id=\"S4.T3.13.11.1.m1.2.2.1.1.3\" xref=\"S4.T3.13.11.1.m1.2.2.1.1.3.cmml\">K</mi></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.13.11.1.m1.2b\"><list id=\"S4.T3.13.11.1.m1.2.2.2.cmml\" xref=\"S4.T3.13.11.1.m1.2.2.1\"><cn type=\"integer\" id=\"S4.T3.13.11.1.m1.1.1.cmml\" xref=\"S4.T3.13.11.1.m1.1.1\">1</cn><apply id=\"S4.T3.13.11.1.m1.2.2.1.1.cmml\" xref=\"S4.T3.13.11.1.m1.2.2.1.1\"><times id=\"S4.T3.13.11.1.m1.2.2.1.1.1.cmml\" xref=\"S4.T3.13.11.1.m1.2.2.1.1.1\"></times><cn type=\"integer\" id=\"S4.T3.13.11.1.m1.2.2.1.1.2.cmml\" xref=\"S4.T3.13.11.1.m1.2.2.1.1.2\">000</cn><ci id=\"S4.T3.13.11.1.m1.2.2.1.1.3.cmml\" xref=\"S4.T3.13.11.1.m1.2.2.1.1.3\">𝐾</ci></apply></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.13.11.1.m1.2c\">1,000K</annotation></semantics></math></td>\n<th id=\"S4.T3.13.11.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">0.951</th>\n<td id=\"S4.T3.13.11.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">0.153</td>\n</tr>\n<tr id=\"S4.T3.14.12\" class=\"ltx_tr\">\n<th id=\"S4.T3.14.12.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb\">FPFL</th>\n<td id=\"S4.T3.14.12.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r\"><math id=\"S4.T3.14.12.1.m1.2\" class=\"ltx_Math\" alttext=\"1,000K\" display=\"inline\"><semantics id=\"S4.T3.14.12.1.m1.2a\"><mrow id=\"S4.T3.14.12.1.m1.2.2.1\" xref=\"S4.T3.14.12.1.m1.2.2.2.cmml\"><mn id=\"S4.T3.14.12.1.m1.1.1\" xref=\"S4.T3.14.12.1.m1.1.1.cmml\">1</mn><mo id=\"S4.T3.14.12.1.m1.2.2.1.2\" xref=\"S4.T3.14.12.1.m1.2.2.2.cmml\">,</mo><mrow id=\"S4.T3.14.12.1.m1.2.2.1.1\" xref=\"S4.T3.14.12.1.m1.2.2.1.1.cmml\"><mn id=\"S4.T3.14.12.1.m1.2.2.1.1.2\" xref=\"S4.T3.14.12.1.m1.2.2.1.1.2.cmml\">000</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.14.12.1.m1.2.2.1.1.1\" xref=\"S4.T3.14.12.1.m1.2.2.1.1.1.cmml\">​</mo><mi id=\"S4.T3.14.12.1.m1.2.2.1.1.3\" xref=\"S4.T3.14.12.1.m1.2.2.1.1.3.cmml\">K</mi></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.14.12.1.m1.2b\"><list id=\"S4.T3.14.12.1.m1.2.2.2.cmml\" xref=\"S4.T3.14.12.1.m1.2.2.1\"><cn type=\"integer\" id=\"S4.T3.14.12.1.m1.1.1.cmml\" xref=\"S4.T3.14.12.1.m1.1.1\">1</cn><apply id=\"S4.T3.14.12.1.m1.2.2.1.1.cmml\" xref=\"S4.T3.14.12.1.m1.2.2.1.1\"><times id=\"S4.T3.14.12.1.m1.2.2.1.1.1.cmml\" xref=\"S4.T3.14.12.1.m1.2.2.1.1.1\"></times><cn type=\"integer\" id=\"S4.T3.14.12.1.m1.2.2.1.1.2.cmml\" xref=\"S4.T3.14.12.1.m1.2.2.1.1.2\">000</cn><ci id=\"S4.T3.14.12.1.m1.2.2.1.1.3.cmml\" xref=\"S4.T3.14.12.1.m1.2.2.1.1.3\">𝐾</ci></apply></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.14.12.1.m1.2c\">1,000K</annotation></semantics></math></td>\n<th id=\"S4.T3.14.12.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb\">0.927</th>\n<td id=\"S4.T3.14.12.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_bb\">0.073</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We start our experiments confirming again the hypothesis and findings from ",
                "Bagdasaryan et al. [",
                "2019",
                "]",
                " that clipping and DP disproportionately affect under-represented groups. For that, we trained a convolutional network (consisting of 2 convolution layers with kernel of size ",
                "5",
                "×",
                "5",
                "5",
                "5",
                "5\\times 5",
                ", stride of 2, ReLU activation function, and 32 and 64 filters respectively) with ",
                "FederatedSGD",
                " and versions of this algorithm where only clipping was performed and where both clipping and DP were included. For the FEMNIST experiments, the privacy parameters are ",
                "(",
                "ϵ",
                ",",
                "δ",
                ")",
                "=",
                "(",
                "2",
                ",",
                "2.5",
                "⋅",
                "10",
                "−",
                "4",
                ")",
                "italic-ϵ",
                "𝛿",
                "2",
                "⋅",
                "2.5",
                "superscript",
                "10",
                "4",
                "(\\epsilon,\\delta)=(2,2.5\\cdot 10^{-4})",
                " and the damping parameter is ",
                "c",
                "=",
                "20",
                "𝑐",
                "20",
                "c=20",
                ". They were trained with a cohort size of ",
                "m",
                "=",
                "100",
                "𝑚",
                "100",
                "m=100",
                " for ",
                "T",
                "=",
                "2",
                ",",
                "000",
                "𝑇",
                "2",
                "000",
                "T=2,000",
                " iterations and the model with best training cohort accuracy was selected. The results are displayed in ",
                "Table",
                " ",
                "3",
                ". Similarly to before, clipping increases the accuracy gap from 13% to almost 17%. In this case, since the number of users ",
                "K",
                "𝐾",
                "K",
                " is small, the DP noise is large compared to the users’ statistics.\nTherefore, the accuracy drops from more than 94% with clipping to 80.7% when DP is also used, and the accuracy gap increases to more than 40%.",
                "The second experiment tests whether ",
                "FPFL",
                " can remedy the unfairness without decreasing accuracy too much. We trained the same convolutional network, again for ",
                "T",
                "=",
                "2",
                ",",
                "000",
                "𝑇",
                "2",
                "000",
                "T=2,000",
                " iterations, and selected the model with the best training cohort accuracy that respected the fairness condition on the training cohort. When DP noise is not included, ",
                "FPFL",
                " reduces the accuracy gap with ",
                "FederatedSGD",
                " by around 9% while keeping the accuracy within 1%. We note how, as before, clipping largely does not affect the ability of ",
                "FPFL",
                " to enforce fairness. However, note that since the data is more non-i.i.d. than before (i.e. there are more differences between the distribution of each user) the models that are deemed fair in the training cohort may not be as fair in the general population, and now we see a larger gap between the desired tolerance ",
                "α",
                "=",
                "0.04",
                "𝛼",
                "0.04",
                "\\alpha=0.04",
                " and the obtained accuracy gap from ",
                "FPFL",
                " without noise (0.047 and 0.053 without and with clipping).",
                "When DP is used, the noise is too large for ",
                "FPFL",
                " to function properly and often the sign of the constraints’ gradient, see (",
                "9",
                "), flips. Note that in the estimation of the performance function, i.e. ",
                "F",
                "​",
                "(",
                "d",
                "a",
                ",",
                "𝒘",
                ")",
                "/",
                "n",
                "a",
                "𝐹",
                "subscript",
                "𝑑",
                "𝑎",
                "𝒘",
                "subscript",
                "𝑛",
                "𝑎",
                "F(d_{a},\\bm{w})/n_{a}",
                ", both the numerator and denominator are obtained from a noisy vector, thus making the estimators more sensitive to noise than the estimators for plain ",
                "FederatedSGD",
                ". This is due to two main factors: (i) the larger the model, the larger the aggregation of the gradients for each weight, and thus more noise needs to be added; and (ii) the smaller the amount of users, the larger the noise that needs to be added.",
                "For this reason, we considered the hypothetical scenario where the population, used for calculating the DP noise, is 100 and 1,000 times larger, which is a conservative assumption for federated learning deployments ",
                "[Apple, ",
                "2017",
                "]",
                ". Then, we repeated the experiment with DP ",
                "FederatedSGD",
                " and ",
                "FPFL",
                " and increased the cohort size to ",
                "m",
                "=",
                "2",
                ",",
                "000",
                "𝑚",
                "2",
                "000",
                "m=2,000",
                ". In this scenario, DP ",
                "FederatedSGD",
                " maintained an accuracy gap of more than 15% while ",
                "FPFL",
                " reduced this gap to less than a half in both cases. Nonetheless, the accuracy still decreases slightly, with a reduction of around 5% and 2% respectively compared with DP ",
                "FederatedSGD",
                "."
            ]
        ]
    },
    "A2.T4": {
        "caption": "Table 4: Performance of a deep and a shallow network on the Adult dataset when trained with SGD and the MMDM algorithm. The fairness metric considered for MMDM is FNR parity and the tolerance is α=0.02𝛼0.02\\alpha=0.02.\nTran et al. [2021] without privacy, and with λmax=0.05subscript𝜆max0.05\\lambda_{\\textnormal{max}}=0.05.",
        "table": "<table id=\"A2.T4.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T4.5.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T4.5.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"A2.T4.5.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th id=\"A2.T4.5.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"A2.T4.5.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Algorithm</span></th>\n<th id=\"A2.T4.5.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T4.5.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n<th id=\"A2.T4.5.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T4.5.1.1.4.1\" class=\"ltx_text ltx_font_bold\">FNR gap</span></th>\n<th id=\"A2.T4.5.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T4.5.1.1.5.1\" class=\"ltx_text ltx_font_bold\">EO gap</span></th>\n<th id=\"A2.T4.5.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T4.5.1.1.6.1\" class=\"ltx_text ltx_font_bold\">DemP gap</span></th>\n<th id=\"A2.T4.5.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T4.5.1.1.7.1\" class=\"ltx_text ltx_font_bold\">PP gap</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T4.5.2.1\" class=\"ltx_tr\">\n<th id=\"A2.T4.5.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Shallow</th>\n<th id=\"A2.T4.5.2.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">SGD</th>\n<td id=\"A2.T4.5.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.857</td>\n<td id=\"A2.T4.5.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.071</td>\n<td id=\"A2.T4.5.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.071</td>\n<td id=\"A2.T4.5.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.113</td>\n<td id=\"A2.T4.5.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.016</td>\n</tr>\n<tr id=\"A2.T4.5.3.2\" class=\"ltx_tr\">\n<th id=\"A2.T4.5.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T4.5.3.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">\n<cite class=\"ltx_cite ltx_citemacro_citet\">Tran et al. [<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">2021</a>]</cite>*</th>\n<td id=\"A2.T4.5.3.2.3\" class=\"ltx_td ltx_align_center\">0.856</td>\n<td id=\"A2.T4.5.3.2.4\" class=\"ltx_td ltx_align_center\">0.048</td>\n<td id=\"A2.T4.5.3.2.5\" class=\"ltx_td ltx_align_center\">0.048</td>\n<td id=\"A2.T4.5.3.2.6\" class=\"ltx_td ltx_align_center\">0.108</td>\n<td id=\"A2.T4.5.3.2.7\" class=\"ltx_td ltx_align_center\">0.036</td>\n</tr>\n<tr id=\"A2.T4.5.4.3\" class=\"ltx_tr\">\n<th id=\"A2.T4.5.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T4.5.4.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BMDM</th>\n<td id=\"A2.T4.5.4.3.3\" class=\"ltx_td ltx_align_center\">0.857</td>\n<td id=\"A2.T4.5.4.3.4\" class=\"ltx_td ltx_align_center\">0.001</td>\n<td id=\"A2.T4.5.4.3.5\" class=\"ltx_td ltx_align_center\">0.030</td>\n<td id=\"A2.T4.5.4.3.6\" class=\"ltx_td ltx_align_center\">0.094</td>\n<td id=\"A2.T4.5.4.3.7\" class=\"ltx_td ltx_align_center\">0.046</td>\n</tr>\n<tr id=\"A2.T4.5.5.4\" class=\"ltx_tr\">\n<th id=\"A2.T4.5.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T4.5.5.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">MMDM</th>\n<td id=\"A2.T4.5.5.4.3\" class=\"ltx_td ltx_align_center\">0.856</td>\n<td id=\"A2.T4.5.5.4.4\" class=\"ltx_td ltx_align_center\">0.005</td>\n<td id=\"A2.T4.5.5.4.5\" class=\"ltx_td ltx_align_center\">0.028</td>\n<td id=\"A2.T4.5.5.4.6\" class=\"ltx_td ltx_align_center\">0.091</td>\n<td id=\"A2.T4.5.5.4.7\" class=\"ltx_td ltx_align_center\">0.063</td>\n</tr>\n<tr id=\"A2.T4.5.6.5\" class=\"ltx_tr\">\n<th id=\"A2.T4.5.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Deep</th>\n<th id=\"A2.T4.5.6.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">SGD</th>\n<td id=\"A2.T4.5.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.858</td>\n<td id=\"A2.T4.5.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.070</td>\n<td id=\"A2.T4.5.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.070</td>\n<td id=\"A2.T4.5.6.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.117</td>\n<td id=\"A2.T4.5.6.5.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.006</td>\n</tr>\n<tr id=\"A2.T4.5.7.6\" class=\"ltx_tr\">\n<th id=\"A2.T4.5.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T4.5.7.6.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">\n<cite class=\"ltx_cite ltx_citemacro_citet\">Tran et al. [<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">2021</a>]</cite>*</th>\n<td id=\"A2.T4.5.7.6.3\" class=\"ltx_td ltx_align_center\">0.853</td>\n<td id=\"A2.T4.5.7.6.4\" class=\"ltx_td ltx_align_center\">0.054</td>\n<td id=\"A2.T4.5.7.6.5\" class=\"ltx_td ltx_align_center\">0.054</td>\n<td id=\"A2.T4.5.7.6.6\" class=\"ltx_td ltx_align_center\">0.111</td>\n<td id=\"A2.T4.5.7.6.7\" class=\"ltx_td ltx_align_center\">0.035</td>\n</tr>\n<tr id=\"A2.T4.5.8.7\" class=\"ltx_tr\">\n<th id=\"A2.T4.5.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T4.5.8.7.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BMDM</th>\n<td id=\"A2.T4.5.8.7.3\" class=\"ltx_td ltx_align_center\">0.853</td>\n<td id=\"A2.T4.5.8.7.4\" class=\"ltx_td ltx_align_center\">0.000</td>\n<td id=\"A2.T4.5.8.7.5\" class=\"ltx_td ltx_align_center\">0.027</td>\n<td id=\"A2.T4.5.8.7.6\" class=\"ltx_td ltx_align_center\">0.088</td>\n<td id=\"A2.T4.5.8.7.7\" class=\"ltx_td ltx_align_center\">0.050</td>\n</tr>\n<tr id=\"A2.T4.5.9.8\" class=\"ltx_tr\">\n<th id=\"A2.T4.5.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Deep</th>\n<th id=\"A2.T4.5.9.8.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">MMDM</th>\n<td id=\"A2.T4.5.9.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.855</td>\n<td id=\"A2.T4.5.9.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.003</td>\n<td id=\"A2.T4.5.9.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.027</td>\n<td id=\"A2.T4.5.9.8.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.090</td>\n<td id=\"A2.T4.5.9.8.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.066</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We replicated all the experiments with the shallow network from ",
                "Section",
                " ",
                "4.1",
                " with the deep network instead. The results for these experiments on the central and federated setting are displayed in ",
                "Table",
                " ",
                "4",
                " and ",
                "Table",
                " ",
                "5",
                ", respectively.",
                "The results obtained with the deep network are almost identical to those of the shallow network in the central setting without DP noise.",
                "The first difference with the results for the shallow network is that the performance and fairness of the deep network does not change much when going from the central to the federated setting without DP noise nor clipping. The shallow network, however, becomes less fair under all the metrics considered.",
                "The results for federated learning with clipping do not differ much between the shallow and deep networks. In both cases we see how ",
                "FederatedAveraging",
                " with clipping deteriorates the fairness of the model with all the measures considered. Moreover, they also suggest how ",
                "FPFL",
                " can mitigate this problem, maintaining similar levels of accuracy (in this case, even higher) while keeping the fairness below the fairness tolerance.",
                "Another contrast with the shallow network appears in the comparison of algorithms with and without differential privacy.\nWith DP, training does not reliably converge.\nThis is partly due to the fact that the noise is large enough so that sign of the constraints’ gradient, see (",
                "9",
                "), is sometimes mistaken.",
                "For this reason, we repeat the experiments with PFL and ",
                "FPFL",
                " with a larger cohort size, ",
                "m",
                "=",
                "1",
                ",",
                "000",
                "𝑚",
                "1",
                "000",
                "m=1,000",
                ", to see if a smaller relative noise would aid the training with PFL or with ",
                "FPFL",
                ". The results with PFL were almost identical, with similar levels of accuracy and unfairness. On the other hand, the larger signal-to-DP noise ratio helped the models trained with ",
                "FPFL",
                " to keep models with the desired levels of FNR gap and lower unfairness measured with any other metric. Moreover, the accuracy of the models, that now work better for the under-represented group, is in fact slightly higher than for the models trained with PFL."
            ]
        ]
    },
    "A2.T5": {
        "caption": "Table 5: Performance of a deep and a shallow network on the Adult dataset when trained with different algorithms: FederatedSGD without privacy, with norm clipping, and with DP, denoted as FL, FL + Clip, and PFL respectively; and FPFL without privacy nor norm clipping, with norm clipping only, and with DP, denoted as FFL, FFL + Clip, and FPFL respectively. The fairness metric considered for FPFL is FNR parity and the tolerance is α=0.02𝛼0.02\\alpha=0.02.",
        "table": "<table id=\"A2.T5.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T5.4.3.1\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"A2.T5.4.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th id=\"A2.T5.4.3.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"A2.T5.4.3.1.2.1\" class=\"ltx_text ltx_font_bold\">Algorithm</span></th>\n<td id=\"A2.T5.4.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A2.T5.4.3.1.3.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"A2.T5.4.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A2.T5.4.3.1.4.1\" class=\"ltx_text ltx_font_bold\">FNR gap</span></td>\n<td id=\"A2.T5.4.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A2.T5.4.3.1.5.1\" class=\"ltx_text ltx_font_bold\">EO gap</span></td>\n<td id=\"A2.T5.4.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A2.T5.4.3.1.6.1\" class=\"ltx_text ltx_font_bold\">DemP gap</span></td>\n<td id=\"A2.T5.4.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A2.T5.4.3.1.7.1\" class=\"ltx_text ltx_font_bold\">PP gap</span></td>\n</tr>\n<tr id=\"A2.T5.3.1\" class=\"ltx_tr\">\n<th id=\"A2.T5.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"7\"><math id=\"A2.T5.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"m=200\" display=\"inline\"><semantics id=\"A2.T5.3.1.1.m1.1a\"><mrow id=\"A2.T5.3.1.1.m1.1.1\" xref=\"A2.T5.3.1.1.m1.1.1.cmml\"><mi id=\"A2.T5.3.1.1.m1.1.1.2\" xref=\"A2.T5.3.1.1.m1.1.1.2.cmml\">m</mi><mo id=\"A2.T5.3.1.1.m1.1.1.1\" xref=\"A2.T5.3.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"A2.T5.3.1.1.m1.1.1.3\" xref=\"A2.T5.3.1.1.m1.1.1.3.cmml\">200</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A2.T5.3.1.1.m1.1b\"><apply id=\"A2.T5.3.1.1.m1.1.1.cmml\" xref=\"A2.T5.3.1.1.m1.1.1\"><eq id=\"A2.T5.3.1.1.m1.1.1.1.cmml\" xref=\"A2.T5.3.1.1.m1.1.1.1\"></eq><ci id=\"A2.T5.3.1.1.m1.1.1.2.cmml\" xref=\"A2.T5.3.1.1.m1.1.1.2\">𝑚</ci><cn type=\"integer\" id=\"A2.T5.3.1.1.m1.1.1.3.cmml\" xref=\"A2.T5.3.1.1.m1.1.1.3\">200</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T5.3.1.1.m1.1c\">m=200</annotation></semantics></math></th>\n</tr>\n<tr id=\"A2.T5.4.4.2\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Shallow</th>\n<th id=\"A2.T5.4.4.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">FL</th>\n<td id=\"A2.T5.4.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.851</td>\n<td id=\"A2.T5.4.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.121</td>\n<td id=\"A2.T5.4.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.121</td>\n<td id=\"A2.T5.4.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.122</td>\n<td id=\"A2.T5.4.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.037</td>\n</tr>\n<tr id=\"A2.T5.4.5.3\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T5.4.5.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BMDM-FL</th>\n<td id=\"A2.T5.4.5.3.3\" class=\"ltx_td ltx_align_center\">0.854</td>\n<td id=\"A2.T5.4.5.3.4\" class=\"ltx_td ltx_align_center\">0.043</td>\n<td id=\"A2.T5.4.5.3.5\" class=\"ltx_td ltx_align_center\">0.043</td>\n<td id=\"A2.T5.4.5.3.6\" class=\"ltx_td ltx_align_center\">0.101</td>\n<td id=\"A2.T5.4.5.3.7\" class=\"ltx_td ltx_align_center\">0.016</td>\n</tr>\n<tr id=\"A2.T5.4.6.4\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T5.4.6.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">FFL</th>\n<td id=\"A2.T5.4.6.4.3\" class=\"ltx_td ltx_align_center\">0.855</td>\n<td id=\"A2.T5.4.6.4.4\" class=\"ltx_td ltx_align_center\">0.036</td>\n<td id=\"A2.T5.4.6.4.5\" class=\"ltx_td ltx_align_center\">0.039</td>\n<td id=\"A2.T5.4.6.4.6\" class=\"ltx_td ltx_align_center\">0.108</td>\n<td id=\"A2.T5.4.6.4.7\" class=\"ltx_td ltx_align_center\">0.033</td>\n</tr>\n<tr id=\"A2.T5.4.7.5\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.7.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">FL</th>\n<td id=\"A2.T5.4.7.5.3\" class=\"ltx_td ltx_align_center\">0.853</td>\n<td id=\"A2.T5.4.7.5.4\" class=\"ltx_td ltx_align_center\">0.078</td>\n<td id=\"A2.T5.4.7.5.5\" class=\"ltx_td ltx_align_center\">0.078</td>\n<td id=\"A2.T5.4.7.5.6\" class=\"ltx_td ltx_align_center\">0.125</td>\n<td id=\"A2.T5.4.7.5.7\" class=\"ltx_td ltx_align_center\">0.015</td>\n</tr>\n<tr id=\"A2.T5.4.8.6\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.8.6.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BMDM-FL</th>\n<td id=\"A2.T5.4.8.6.3\" class=\"ltx_td ltx_align_center\">0.850</td>\n<td id=\"A2.T5.4.8.6.4\" class=\"ltx_td ltx_align_center\">0.051</td>\n<td id=\"A2.T5.4.8.6.5\" class=\"ltx_td ltx_align_center\">0.051</td>\n<td id=\"A2.T5.4.8.6.6\" class=\"ltx_td ltx_align_center\">0.116</td>\n<td id=\"A2.T5.4.8.6.7\" class=\"ltx_td ltx_align_center\">0.012</td>\n</tr>\n<tr id=\"A2.T5.4.9.7\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.9.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.9.7.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">FFL</th>\n<td id=\"A2.T5.4.9.7.3\" class=\"ltx_td ltx_align_center\">0.854</td>\n<td id=\"A2.T5.4.9.7.4\" class=\"ltx_td ltx_align_center\">0.009</td>\n<td id=\"A2.T5.4.9.7.5\" class=\"ltx_td ltx_align_center\">0.030</td>\n<td id=\"A2.T5.4.9.7.6\" class=\"ltx_td ltx_align_center\">0.093</td>\n<td id=\"A2.T5.4.9.7.7\" class=\"ltx_td ltx_align_center\">0.049</td>\n</tr>\n<tr id=\"A2.T5.4.10.8\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.10.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Shallow</th>\n<th id=\"A2.T5.4.10.8.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">FL + Clip</th>\n<td id=\"A2.T5.4.10.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.844</td>\n<td id=\"A2.T5.4.10.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.169</td>\n<td id=\"A2.T5.4.10.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.169</td>\n<td id=\"A2.T5.4.10.8.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.129</td>\n<td id=\"A2.T5.4.10.8.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.051</td>\n</tr>\n<tr id=\"A2.T5.4.11.9\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.11.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T5.4.11.9.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BMDM-FL + Clip</th>\n<td id=\"A2.T5.4.11.9.3\" class=\"ltx_td ltx_align_center\">0.851</td>\n<td id=\"A2.T5.4.11.9.4\" class=\"ltx_td ltx_align_center\">0.052</td>\n<td id=\"A2.T5.4.11.9.5\" class=\"ltx_td ltx_align_center\">0.052</td>\n<td id=\"A2.T5.4.11.9.6\" class=\"ltx_td ltx_align_center\">0.105</td>\n<td id=\"A2.T5.4.11.9.7\" class=\"ltx_td ltx_align_center\">0.008</td>\n</tr>\n<tr id=\"A2.T5.4.12.10\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.12.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T5.4.12.10.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">FFL + Clip</th>\n<td id=\"A2.T5.4.12.10.3\" class=\"ltx_td ltx_align_center\">0.853</td>\n<td id=\"A2.T5.4.12.10.4\" class=\"ltx_td ltx_align_center\">0.018</td>\n<td id=\"A2.T5.4.12.10.5\" class=\"ltx_td ltx_align_center\">0.029</td>\n<td id=\"A2.T5.4.12.10.6\" class=\"ltx_td ltx_align_center\">0.090</td>\n<td id=\"A2.T5.4.12.10.7\" class=\"ltx_td ltx_align_center\">0.016</td>\n</tr>\n<tr id=\"A2.T5.4.13.11\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.13.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.13.11.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">FL + Clip</th>\n<td id=\"A2.T5.4.13.11.3\" class=\"ltx_td ltx_align_center\">0.848</td>\n<td id=\"A2.T5.4.13.11.4\" class=\"ltx_td ltx_align_center\">0.160</td>\n<td id=\"A2.T5.4.13.11.5\" class=\"ltx_td ltx_align_center\">0.160</td>\n<td id=\"A2.T5.4.13.11.6\" class=\"ltx_td ltx_align_center\">0.131</td>\n<td id=\"A2.T5.4.13.11.7\" class=\"ltx_td ltx_align_center\">0.056</td>\n</tr>\n<tr id=\"A2.T5.4.14.12\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.14.12.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.14.12.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BMDM-FL + Clip</th>\n<td id=\"A2.T5.4.14.12.3\" class=\"ltx_td ltx_align_center\">0.844</td>\n<td id=\"A2.T5.4.14.12.4\" class=\"ltx_td ltx_align_center\">0.130</td>\n<td id=\"A2.T5.4.14.12.5\" class=\"ltx_td ltx_align_center\">0.130</td>\n<td id=\"A2.T5.4.14.12.6\" class=\"ltx_td ltx_align_center\">0.112</td>\n<td id=\"A2.T5.4.14.12.7\" class=\"ltx_td ltx_align_center\">0.041</td>\n</tr>\n<tr id=\"A2.T5.4.15.13\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.15.13.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.15.13.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">FFL + Clip</th>\n<td id=\"A2.T5.4.15.13.3\" class=\"ltx_td ltx_align_center\">0.852</td>\n<td id=\"A2.T5.4.15.13.4\" class=\"ltx_td ltx_align_center\">0.008</td>\n<td id=\"A2.T5.4.15.13.5\" class=\"ltx_td ltx_align_center\">0.023</td>\n<td id=\"A2.T5.4.15.13.6\" class=\"ltx_td ltx_align_center\">0.081</td>\n<td id=\"A2.T5.4.15.13.7\" class=\"ltx_td ltx_align_center\">0.031</td>\n</tr>\n<tr id=\"A2.T5.4.16.14\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.16.14.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Shallow</th>\n<th id=\"A2.T5.4.16.14.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">PFL</th>\n<td id=\"A2.T5.4.16.14.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.828</td>\n<td id=\"A2.T5.4.16.14.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.171</td>\n<td id=\"A2.T5.4.16.14.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.171</td>\n<td id=\"A2.T5.4.16.14.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.093</td>\n<td id=\"A2.T5.4.16.14.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.038</td>\n</tr>\n<tr id=\"A2.T5.4.17.15\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.17.15.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T5.4.17.15.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BMDM-PFL</th>\n<td id=\"A2.T5.4.17.15.3\" class=\"ltx_td ltx_align_center\">0.803</td>\n<td id=\"A2.T5.4.17.15.4\" class=\"ltx_td ltx_align_center\">0.002</td>\n<td id=\"A2.T5.4.17.15.5\" class=\"ltx_td ltx_align_center\">0.005</td>\n<td id=\"A2.T5.4.17.15.6\" class=\"ltx_td ltx_align_center\">0.044</td>\n<td id=\"A2.T5.4.17.15.7\" class=\"ltx_td ltx_align_center\">0.209</td>\n</tr>\n<tr id=\"A2.T5.4.18.16\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.18.16.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T5.4.18.16.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">FPFL</th>\n<td id=\"A2.T5.4.18.16.3\" class=\"ltx_td ltx_align_center\">0.793</td>\n<td id=\"A2.T5.4.18.16.4\" class=\"ltx_td ltx_align_center\">0.060</td>\n<td id=\"A2.T5.4.18.16.5\" class=\"ltx_td ltx_align_center\">0.060</td>\n<td id=\"A2.T5.4.18.16.6\" class=\"ltx_td ltx_align_center\">0.051</td>\n<td id=\"A2.T5.4.18.16.7\" class=\"ltx_td ltx_align_center\">0.167</td>\n</tr>\n<tr id=\"A2.T5.4.19.17\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.19.17.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.19.17.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">PFL</th>\n<td id=\"A2.T5.4.19.17.3\" class=\"ltx_td ltx_align_center\">0.804</td>\n<td id=\"A2.T5.4.19.17.4\" class=\"ltx_td ltx_align_center\">0.174</td>\n<td id=\"A2.T5.4.19.17.5\" class=\"ltx_td ltx_align_center\">0.174</td>\n<td id=\"A2.T5.4.19.17.6\" class=\"ltx_td ltx_align_center\">0.073</td>\n<td id=\"A2.T5.4.19.17.7\" class=\"ltx_td ltx_align_center\">0.031</td>\n</tr>\n<tr id=\"A2.T5.4.20.18\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.20.18.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.20.18.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BMDM-PFL</th>\n<td id=\"A2.T5.4.20.18.3\" class=\"ltx_td ltx_align_center\">0.792</td>\n<td id=\"A2.T5.4.20.18.4\" class=\"ltx_td ltx_align_center\">0.303</td>\n<td id=\"A2.T5.4.20.18.5\" class=\"ltx_td ltx_align_center\">0.303</td>\n<td id=\"A2.T5.4.20.18.6\" class=\"ltx_td ltx_align_center\">0.164</td>\n<td id=\"A2.T5.4.20.18.7\" class=\"ltx_td ltx_align_center\">0.067</td>\n</tr>\n<tr id=\"A2.T5.4.21.19\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.21.19.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.21.19.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">FPFL</th>\n<td id=\"A2.T5.4.21.19.3\" class=\"ltx_td ltx_align_center\">0.281</td>\n<td id=\"A2.T5.4.21.19.4\" class=\"ltx_td ltx_align_center\">0.036</td>\n<td id=\"A2.T5.4.21.19.5\" class=\"ltx_td ltx_align_center\">0.036</td>\n<td id=\"A2.T5.4.21.19.6\" class=\"ltx_td ltx_align_center\">0.014</td>\n<td id=\"A2.T5.4.21.19.7\" class=\"ltx_td ltx_align_center\">0.127</td>\n</tr>\n<tr id=\"A2.T5.4.2\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"7\"><math id=\"A2.T5.4.2.1.m1.2\" class=\"ltx_Math\" alttext=\"m=1,000\" display=\"inline\"><semantics id=\"A2.T5.4.2.1.m1.2a\"><mrow id=\"A2.T5.4.2.1.m1.2.3\" xref=\"A2.T5.4.2.1.m1.2.3.cmml\"><mi id=\"A2.T5.4.2.1.m1.2.3.2\" xref=\"A2.T5.4.2.1.m1.2.3.2.cmml\">m</mi><mo id=\"A2.T5.4.2.1.m1.2.3.1\" xref=\"A2.T5.4.2.1.m1.2.3.1.cmml\">=</mo><mrow id=\"A2.T5.4.2.1.m1.2.3.3.2\" xref=\"A2.T5.4.2.1.m1.2.3.3.1.cmml\"><mn id=\"A2.T5.4.2.1.m1.1.1\" xref=\"A2.T5.4.2.1.m1.1.1.cmml\">1</mn><mo id=\"A2.T5.4.2.1.m1.2.3.3.2.1\" xref=\"A2.T5.4.2.1.m1.2.3.3.1.cmml\">,</mo><mn id=\"A2.T5.4.2.1.m1.2.2\" xref=\"A2.T5.4.2.1.m1.2.2.cmml\">000</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A2.T5.4.2.1.m1.2b\"><apply id=\"A2.T5.4.2.1.m1.2.3.cmml\" xref=\"A2.T5.4.2.1.m1.2.3\"><eq id=\"A2.T5.4.2.1.m1.2.3.1.cmml\" xref=\"A2.T5.4.2.1.m1.2.3.1\"></eq><ci id=\"A2.T5.4.2.1.m1.2.3.2.cmml\" xref=\"A2.T5.4.2.1.m1.2.3.2\">𝑚</ci><list id=\"A2.T5.4.2.1.m1.2.3.3.1.cmml\" xref=\"A2.T5.4.2.1.m1.2.3.3.2\"><cn type=\"integer\" id=\"A2.T5.4.2.1.m1.1.1.cmml\" xref=\"A2.T5.4.2.1.m1.1.1\">1</cn><cn type=\"integer\" id=\"A2.T5.4.2.1.m1.2.2.cmml\" xref=\"A2.T5.4.2.1.m1.2.2\">000</cn></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T5.4.2.1.m1.2c\">m=1,000</annotation></semantics></math></th>\n</tr>\n<tr id=\"A2.T5.4.22.20\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.22.20.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Shallow</th>\n<th id=\"A2.T5.4.22.20.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">PFL</th>\n<td id=\"A2.T5.4.22.20.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.847</td>\n<td id=\"A2.T5.4.22.20.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.148</td>\n<td id=\"A2.T5.4.22.20.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.148</td>\n<td id=\"A2.T5.4.22.20.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.126</td>\n<td id=\"A2.T5.4.22.20.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.041</td>\n</tr>\n<tr id=\"A2.T5.4.23.21\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.23.21.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T5.4.23.21.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BMDM-PFL</th>\n<td id=\"A2.T5.4.23.21.3\" class=\"ltx_td ltx_align_center\">0.850</td>\n<td id=\"A2.T5.4.23.21.4\" class=\"ltx_td ltx_align_center\">0.023</td>\n<td id=\"A2.T5.4.23.21.5\" class=\"ltx_td ltx_align_center\">0.035</td>\n<td id=\"A2.T5.4.23.21.6\" class=\"ltx_td ltx_align_center\">0.097</td>\n<td id=\"A2.T5.4.23.21.7\" class=\"ltx_td ltx_align_center\">0.009</td>\n</tr>\n<tr id=\"A2.T5.4.24.22\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.24.22.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Shallow</th>\n<th id=\"A2.T5.4.24.22.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">FPFL</th>\n<td id=\"A2.T5.4.24.22.3\" class=\"ltx_td ltx_align_center\">0.851</td>\n<td id=\"A2.T5.4.24.22.4\" class=\"ltx_td ltx_align_center\">0.001</td>\n<td id=\"A2.T5.4.24.22.5\" class=\"ltx_td ltx_align_center\">0.027</td>\n<td id=\"A2.T5.4.24.22.6\" class=\"ltx_td ltx_align_center\">0.087</td>\n<td id=\"A2.T5.4.24.22.7\" class=\"ltx_td ltx_align_center\">0.042</td>\n</tr>\n<tr id=\"A2.T5.4.25.23\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.25.23.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.25.23.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">PFL</th>\n<td id=\"A2.T5.4.25.23.3\" class=\"ltx_td ltx_align_center\">0.847</td>\n<td id=\"A2.T5.4.25.23.4\" class=\"ltx_td ltx_align_center\">0.167</td>\n<td id=\"A2.T5.4.25.23.5\" class=\"ltx_td ltx_align_center\">0.167</td>\n<td id=\"A2.T5.4.25.23.6\" class=\"ltx_td ltx_align_center\">0.132</td>\n<td id=\"A2.T5.4.25.23.7\" class=\"ltx_td ltx_align_center\">0.043</td>\n</tr>\n<tr id=\"A2.T5.4.26.24\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.26.24.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep</th>\n<th id=\"A2.T5.4.26.24.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BMDM-PFL</th>\n<td id=\"A2.T5.4.26.24.3\" class=\"ltx_td ltx_align_center\">0.837</td>\n<td id=\"A2.T5.4.26.24.4\" class=\"ltx_td ltx_align_center\">0.167</td>\n<td id=\"A2.T5.4.26.24.5\" class=\"ltx_td ltx_align_center\">0.167</td>\n<td id=\"A2.T5.4.26.24.6\" class=\"ltx_td ltx_align_center\">0.115</td>\n<td id=\"A2.T5.4.26.24.7\" class=\"ltx_td ltx_align_center\">0.085</td>\n</tr>\n<tr id=\"A2.T5.4.27.25\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.27.25.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Deep</th>\n<th id=\"A2.T5.4.27.25.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">FPFL</th>\n<td id=\"A2.T5.4.27.25.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.848</td>\n<td id=\"A2.T5.4.27.25.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.027</td>\n<td id=\"A2.T5.4.27.25.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.027</td>\n<td id=\"A2.T5.4.27.25.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.080</td>\n<td id=\"A2.T5.4.27.25.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.026</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We replicated all the experiments with the shallow network from ",
                "Section",
                " ",
                "4.1",
                " with the deep network instead. The results for these experiments on the central and federated setting are displayed in ",
                "Table",
                " ",
                "4",
                " and ",
                "Table",
                " ",
                "5",
                ", respectively.",
                "The results obtained with the deep network are almost identical to those of the shallow network in the central setting without DP noise.",
                "The first difference with the results for the shallow network is that the performance and fairness of the deep network does not change much when going from the central to the federated setting without DP noise nor clipping. The shallow network, however, becomes less fair under all the metrics considered.",
                "The results for federated learning with clipping do not differ much between the shallow and deep networks. In both cases we see how ",
                "FederatedAveraging",
                " with clipping deteriorates the fairness of the model with all the measures considered. Moreover, they also suggest how ",
                "FPFL",
                " can mitigate this problem, maintaining similar levels of accuracy (in this case, even higher) while keeping the fairness below the fairness tolerance.",
                "Another contrast with the shallow network appears in the comparison of algorithms with and without differential privacy.\nWith DP, training does not reliably converge.\nThis is partly due to the fact that the noise is large enough so that sign of the constraints’ gradient, see (",
                "9",
                "), is sometimes mistaken.",
                "For this reason, we repeat the experiments with PFL and ",
                "FPFL",
                " with a larger cohort size, ",
                "m",
                "=",
                "1",
                ",",
                "000",
                "𝑚",
                "1",
                "000",
                "m=1,000",
                ", to see if a smaller relative noise would aid the training with PFL or with ",
                "FPFL",
                ". The results with PFL were almost identical, with similar levels of accuracy and unfairness. On the other hand, the larger signal-to-DP noise ratio helped the models trained with ",
                "FPFL",
                " to keep models with the desired levels of FNR gap and lower unfairness measured with any other metric. Moreover, the accuracy of the models, that now work better for the under-represented group, is in fact slightly higher than for the models trained with PFL."
            ]
        ]
    }
}