{
    "id_table_1": {
        "caption": "Table 1.  We study 4 ablations of our method on 4 different pieces. We show that the F1 score of our method is significantly higher than all the variants.",
        "table": "S5.T1.3",
        "footnotes": [],
        "references": [
            "In summary, this paper makes two major contributions toward physics-based synthesis of elite-level piano performance, as illustrated in Figure  1 :",
            "The performance of each model is listed in Table  1 . The training curve is shown in Figure  9 .  The full model outperforms the ablative models by a large margin in all the tested cases. We show qualitative comparisons visually of the studied ablative models in Figure  10 .  As we can see, the  RL  only case performs the worst and behaves in a manner not human-like, which highlights the necessity of using motion imitation to ensure the motion naturalness and to help better key-pressing task execution.  When the policies are trained without diffusion-generated motions ( RL+Retr  and  RL+Whole ), they yield unnatural hand poses due to the lack of fingering information. The policies also tend to have redundant motions during playing in this case because during training they could try to imitate some unrelated motions that may not strictly apply to the input music piece. When the model is only trained with diffusion-generated motions ( RL+Diff ), the policy tends to overfit the erroneous finger placements existing in the diffusion-generated motions and thus has lower accuracy of key pressing. Those results demonstrate that the diffusion model and motion retrieval are complimentary  and both of them are crucial to the final performance of our pipeline. Additionally, in supplementary materials, we qualitatively compare the motions generated by our control policies to those in our dataset when facing the same target notes.",
            "The hyperparameters used for diffusion model training and reinforcement learning are listed in Table  S1 .  We employ PPO  (Schulman et al . ,  2017 )  as our backbone reinforcement learning algorithm.",
            "Here, we include a qualitative comparison between  the motions generated by our control policies and those in our dataset when facing the same target notes in Figure  S1 . There are often multiple ways to perform the same target notes. Our pipeline enables the policy to either imitate motions generated by the diffusion model or from the captured dataset, resulting in diverse piano-playing patterns. The synthesized motions can be distinct from human pianists as shown in Figure  S1 a. Figure  S1 b shows an example where the synthesized motion largely resembles human motion in terms of fingering and hand poses. Finally, we show an example where the control policy yields results with similar hand poses but different fingering compared with the human pianist."
        ]
    },
    "id_table_2": {
        "caption": "Table S1.  Hyperparameters for Model Training",
        "table": "A2.T1.17",
        "footnotes": [],
        "references": [
            "Figure  2  summarizes the motion reconstruction process. We first use the state-of-the-art pose estimation model HaMeR  (Pavlakos et al . ,  2024 )  to predict the hand pose  K 2D  R N  5  2  21  2 subscript K 2D superscript R N 5 2 21 2 \\bm{K}_{\\textrm{2D}}\\in\\mathbb{R}^{N\\times 5\\times 2\\times 21\\times 2} bold_italic_K start_POSTSUBSCRIPT 2D end_POSTSUBSCRIPT  blackboard_R start_POSTSUPERSCRIPT italic_N  5  2  21  2 end_POSTSUPERSCRIPT , which are the 2D locations of 21 joints on each hand from all 5 camera views for a sequence of  N N N italic_N  frames. While HaMeR can generate 3D meshes of MANO hands  (Romero et al . ,  2017 )  in the camera space, we found that the predicted depths are not usable due to severe inaccuracy. As such, we only leverage the projected 2D keypoints from HaMeR and compute 3D locations of each joint  K 3  D  R N  2  21  3 subscript K 3 D superscript R N 2 21 3 \\bm{K}_{3D}\\in\\mathbb{R}^{N\\times 2\\times 21\\times 3} bold_italic_K start_POSTSUBSCRIPT 3 italic_D end_POSTSUBSCRIPT  blackboard_R start_POSTSUPERSCRIPT italic_N  2  21  3 end_POSTSUPERSCRIPT  via triangulation. RANSAC is used to filter out occluded keypoints, while a Butterworth filter is applied to every joint to enhance temporal smoothness, since HaMeR only considers one frame at a time. Next, we fit MANO hand parameters   = {  ,  , t }    t \\Theta=\\{\\theta,\\beta,t\\} roman_ = { italic_ , italic_ , italic_t }  to obtain 3D hand meshes for every frame, where    R N  2  16  3  superscript R N 2 16 3 \\theta\\in\\mathbb{R}^{N\\times 2\\times 16\\times 3} italic_  blackboard_R start_POSTSUPERSCRIPT italic_N  2  16  3 end_POSTSUPERSCRIPT ,    R 2  45  superscript R 2 45 \\beta\\in\\mathbb{R}^{2\\times 45} italic_  blackboard_R start_POSTSUPERSCRIPT 2  45 end_POSTSUPERSCRIPT ,  t  t N  2  3 t superscript t N 2 3 t\\in t^{N\\times 2\\times 3} italic_t  italic_t start_POSTSUPERSCRIPT italic_N  2  3 end_POSTSUPERSCRIPT  are the joint rotations, shape parameters and global translations of the two hands. The shape parameters are computed with extra hand calibration videos. Other parameters are optimized by minimizing the mean-squared error between the triangulated joint locations and MANO hand joint locations."
        ]
    },
    "id_table_3": {
        "caption": "Table S2.  List of compositions in FurElise.",
        "table": "A4.T2.1",
        "footnotes": [],
        "references": [
            "We record the data in a typical piano studio familiar to the performers, as shown in Figure  3 . To minimize the influence of capture device, we design a markerless setup using multiview RGB cameras. Five calibrated GoPro cameras are placed around a grand piano to record synchronized videos and audio with  59.94 59.94 59.94 59.94  FPS. All the videos have a resolution of  3840  2160 3840 2160 3840\\times 2160 3840  2160 . The grand piano is a Yamaha Disklavier DS7X ENPRO, which has a built-in recorder to record the key and pedal pressing events during the performance with high precision in MIDI format, from which the original audio with high fidelity can be reproduced."
        ]
    },
    "global_footnotes": []
}