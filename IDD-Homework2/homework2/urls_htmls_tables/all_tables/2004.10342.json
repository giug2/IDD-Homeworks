{
    "PAPER'S NUMBER OF TABLES": 4,
    "S5.T1": {
        "caption": "Table 1: Precision@1 (%) on CIFAR-10 and CIFAR-100.",
        "table": "<table id=\"S5.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Dataset</span></th>\n<th id=\"S5.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></th>\n<td id=\"S5.T1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Baseline-1</span></td>\n<td id=\"S5.T1.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Baseline-2</span></td>\n<td id=\"S5.T1.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedAwS</span></td>\n<td id=\"S5.T1.1.1.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T1.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Softmax (Oracle)</span></td>\n</tr>\n<tr id=\"S5.T1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.2.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">CIFAR-10</span></th>\n<th id=\"S5.T1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">\n<span id=\"S5.T1.1.2.2.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">ResNet</span><span id=\"S5.T1.1.2.2.2.2\" class=\"ltx_text\" style=\"font-size:90%;\">-8</span>\n</th>\n<td id=\"S5.T1.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">10.7</span></td>\n<td id=\"S5.T1.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">83.3</span></td>\n<td id=\"S5.T1.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">86.3</span></td>\n<td id=\"S5.T1.1.2.2.6\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T1.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">88.4</span></td>\n</tr>\n<tr id=\"S5.T1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.3.3.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">CIFAR-10</span></th>\n<th id=\"S5.T1.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">\n<span id=\"S5.T1.1.3.3.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">ResNet</span><span id=\"S5.T1.1.3.3.2.2\" class=\"ltx_text\" style=\"font-size:90%;\">-32</span>\n</th>\n<td id=\"S5.T1.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">9.8</span></td>\n<td id=\"S5.T1.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">92.1</span></td>\n<td id=\"S5.T1.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">92.4</span></td>\n<td id=\"S5.T1.1.3.3.6\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T1.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">92.4</span></td>\n</tr>\n<tr id=\"S5.T1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.4.4.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">CIFAR-100</span></th>\n<th id=\"S5.T1.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">\n<span id=\"S5.T1.1.4.4.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">ResNet</span><span id=\"S5.T1.1.4.4.2.2\" class=\"ltx_text\" style=\"font-size:90%;\">-32</span>\n</th>\n<td id=\"S5.T1.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">1.0</span></td>\n<td id=\"S5.T1.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">65.1</span></td>\n<td id=\"S5.T1.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">67.9</span></td>\n<td id=\"S5.T1.1.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T1.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">68.0</span></td>\n</tr>\n<tr id=\"S5.T1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.5.5.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">CIFAR-100</span></th>\n<th id=\"S5.T1.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\">\n<span id=\"S5.T1.1.5.5.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">ResNet</span><span id=\"S5.T1.1.5.5.2.2\" class=\"ltx_text\" style=\"font-size:90%;\">-56</span>\n</th>\n<td id=\"S5.T1.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">1.1</span></td>\n<td id=\"S5.T1.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.5.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">67.5</span></td>\n<td id=\"S5.T1.1.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.5.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">69.6</span></td>\n<td id=\"S5.T1.1.5.5.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\"><span id=\"S5.T1.1.5.5.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">70.0</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "From Table 1,\nwe see that\non both CIFAR-10 and CIFAR-100, FedAwS almost matches or comes very close to the performance of the oracle method which has access to all labels.\nThe first baseline method, training with only positive squared hinge loss does not lead to any meaningful precision values. In this case, as discussed above the model collapses into a degenerate solution."
        ]
    },
    "S6.T2": {
        "caption": "Table 2: Summary of the datasets used in the paper. #I/L is the number of instances per label, and #L/I is the number of labels per instance.",
        "table": "<table id=\"S6.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Dataset</span></td>\n<td id=\"S6.T2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">#Features</span></td>\n<td id=\"S6.T2.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">#Labels</span></td>\n<td id=\"S6.T2.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">#TrainPoints</span></td>\n<td id=\"S6.T2.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">#TestPoints</span></td>\n<td id=\"S6.T2.1.1.1.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Avg. #I/L</span></td>\n<td id=\"S6.T2.1.1.1.7\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S6.T2.1.1.1.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">Avg. #L/I</span></td>\n</tr>\n<tr id=\"S6.T2.1.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T2.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.2.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">AmazonCat</span></td>\n<td id=\"S6.T2.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">203,882</span></td>\n<td id=\"S6.T2.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">13,330</span></td>\n<td id=\"S6.T2.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">1,186,239</span></td>\n<td id=\"S6.T2.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">306,782</span></td>\n<td id=\"S6.T2.1.2.2.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">448.57</span></td>\n<td id=\"S6.T2.1.2.2.7\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S6.T2.1.2.2.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.04</span></td>\n</tr>\n<tr id=\"S6.T2.1.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T2.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.3.3.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">WikiLSHTC</span></td>\n<td id=\"S6.T2.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">1,617,899</span></td>\n<td id=\"S6.T2.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">325,056</span></td>\n<td id=\"S6.T2.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">1,778,351</span></td>\n<td id=\"S6.T2.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">587,084</span></td>\n<td id=\"S6.T2.1.3.3.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.46</span></td>\n<td id=\"S6.T2.1.3.3.7\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S6.T2.1.3.3.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.19</span></td>\n</tr>\n<tr id=\"S6.T2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S6.T2.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.4.4.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Amazon670K</span></td>\n<td id=\"S6.T2.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">135,909</span></td>\n<td id=\"S6.T2.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">670,091</span></td>\n<td id=\"S6.T2.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">490,449</span></td>\n<td id=\"S6.T2.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">153,025</span></td>\n<td id=\"S6.T2.1.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.99</span></td>\n<td id=\"S6.T2.1.4.4.7\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\"><span id=\"S6.T2.1.4.4.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.45</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Datasets.\nWe test the proposed approach on standard extreme multilabel classification datasets (Varma, 2018). These datasets have a large number of classes, and therefore are a good representatives of the applications of federated learning with only positive labels. Similar to (Reddi et al., 2019), because these datasets are multi-label, we uniformly sample positive labels to obtain datasets corresponding to multi-class classification problems. The datasets and their statistics are summarized in Table 2."
        ]
    },
    "S6.T3": {
        "caption": "Table 3: P@1,3,5 (%) of different methods on AmazonCat, Amazon670K  and WikiLSHTC.",
        "table": "<table id=\"S6.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.1.1.1\" class=\"ltx_td\" colspan=\"2\"></td>\n<td id=\"S6.T3.1.1.1.2\" class=\"ltx_td ltx_align_center\" colspan=\"3\"><span id=\"S6.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Federated Learning with Only Positives</span></td>\n<td id=\"S6.T3.1.1.1.3\" class=\"ltx_td ltx_align_center\" colspan=\"2\"><span id=\"S6.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Oracle</span></td>\n</tr>\n<tr id=\"S6.T3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.2.2.1\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S6.T3.1.2.2.2\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S6.T3.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Baseline-1</td>\n<td id=\"S6.T3.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Baseline-2</td>\n<td id=\"S6.T3.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedAwS</td>\n<td id=\"S6.T3.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">Softmax</td>\n<td id=\"S6.T3.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">SLEEC</td>\n</tr>\n<tr id=\"S6.T3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.3.3.1\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S6.T3.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">P@1</td>\n<td id=\"S6.T3.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">3.4</td>\n<td id=\"S6.T3.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">64.1</td>\n<td id=\"S6.T3.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">92.1</td>\n<td id=\"S6.T3.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">92.1</td>\n<td id=\"S6.T3.1.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\">90.5</td>\n</tr>\n<tr id=\"S6.T3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.4.4.1\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T3.1.4.4.1.1\" class=\"ltx_text ltx_font_smallcaps\">AmazonCat</span></td>\n<td id=\"S6.T3.1.4.4.2\" class=\"ltx_td ltx_align_center\">P@3</td>\n<td id=\"S6.T3.1.4.4.3\" class=\"ltx_td ltx_align_center\">3.2</td>\n<td id=\"S6.T3.1.4.4.4\" class=\"ltx_td ltx_align_center\">46.8</td>\n<td id=\"S6.T3.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\">70.8</td>\n<td id=\"S6.T3.1.4.4.6\" class=\"ltx_td ltx_align_center\">77.9</td>\n<td id=\"S6.T3.1.4.4.7\" class=\"ltx_td ltx_align_center\">76.3</td>\n</tr>\n<tr id=\"S6.T3.1.5.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.5.5.1\" class=\"ltx_td\"></td>\n<td id=\"S6.T3.1.5.5.2\" class=\"ltx_td ltx_align_center\">P@5</td>\n<td id=\"S6.T3.1.5.5.3\" class=\"ltx_td ltx_align_center\">3.1</td>\n<td id=\"S6.T3.1.5.5.4\" class=\"ltx_td ltx_align_center\">32.6</td>\n<td id=\"S6.T3.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r\">58.7</td>\n<td id=\"S6.T3.1.5.5.6\" class=\"ltx_td ltx_align_center\">62.3</td>\n<td id=\"S6.T3.1.5.5.7\" class=\"ltx_td ltx_align_center\">61.5</td>\n</tr>\n<tr id=\"S6.T3.1.6.6\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.6.6.1\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S6.T3.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">P@1</td>\n<td id=\"S6.T3.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n<td id=\"S6.T3.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4.3</td>\n<td id=\"S6.T3.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.1</td>\n<td id=\"S6.T3.1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_t\">35.2</td>\n<td id=\"S6.T3.1.6.6.7\" class=\"ltx_td ltx_align_center ltx_border_t\">35.1</td>\n</tr>\n<tr id=\"S6.T3.1.7.7\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.7.7.1\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T3.1.7.7.1.1\" class=\"ltx_text ltx_font_smallcaps\">Amazon670K</span></td>\n<td id=\"S6.T3.1.7.7.2\" class=\"ltx_td ltx_align_center\">P@3</td>\n<td id=\"S6.T3.1.7.7.3\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S6.T3.1.7.7.4\" class=\"ltx_td ltx_align_center\">2.8</td>\n<td id=\"S6.T3.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_r\">29.6</td>\n<td id=\"S6.T3.1.7.7.6\" class=\"ltx_td ltx_align_center\">31.6</td>\n<td id=\"S6.T3.1.7.7.7\" class=\"ltx_td ltx_align_center\">31.3</td>\n</tr>\n<tr id=\"S6.T3.1.8.8\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.8.8.1\" class=\"ltx_td\"></td>\n<td id=\"S6.T3.1.8.8.2\" class=\"ltx_td ltx_align_center\">P@5</td>\n<td id=\"S6.T3.1.8.8.3\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S6.T3.1.8.8.4\" class=\"ltx_td ltx_align_center\">2.2</td>\n<td id=\"S6.T3.1.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_r\">27.4</td>\n<td id=\"S6.T3.1.8.8.6\" class=\"ltx_td ltx_align_center\">29.5</td>\n<td id=\"S6.T3.1.8.8.7\" class=\"ltx_td ltx_align_center\">28.6</td>\n</tr>\n<tr id=\"S6.T3.1.9.9\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.9.9.1\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S6.T3.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\">P@1</td>\n<td id=\"S6.T3.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\">7.6</td>\n<td id=\"S6.T3.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">7.9</td>\n<td id=\"S6.T3.1.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">37.2</td>\n<td id=\"S6.T3.1.9.9.6\" class=\"ltx_td ltx_align_center ltx_border_t\">54.1</td>\n<td id=\"S6.T3.1.9.9.7\" class=\"ltx_td ltx_align_center ltx_border_t\">54.8</td>\n</tr>\n<tr id=\"S6.T3.1.10.10\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.10.10.1\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T3.1.10.10.1.1\" class=\"ltx_text ltx_font_smallcaps\">WikiLSHTC</span></td>\n<td id=\"S6.T3.1.10.10.2\" class=\"ltx_td ltx_align_center\">P@3</td>\n<td id=\"S6.T3.1.10.10.3\" class=\"ltx_td ltx_align_center\">4.5</td>\n<td id=\"S6.T3.1.10.10.4\" class=\"ltx_td ltx_align_center\">3.4</td>\n<td id=\"S6.T3.1.10.10.5\" class=\"ltx_td ltx_align_center ltx_border_r\">22.6</td>\n<td id=\"S6.T3.1.10.10.6\" class=\"ltx_td ltx_align_center\">38.8</td>\n<td id=\"S6.T3.1.10.10.7\" class=\"ltx_td ltx_align_center\">33.4</td>\n</tr>\n<tr id=\"S6.T3.1.11.11\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.11.11.1\" class=\"ltx_td ltx_border_b\"></td>\n<td id=\"S6.T3.1.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_b\">P@5</td>\n<td id=\"S6.T3.1.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_b\">2.8</td>\n<td id=\"S6.T3.1.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_b\">2.6</td>\n<td id=\"S6.T3.1.11.11.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">16.2</td>\n<td id=\"S6.T3.1.11.11.6\" class=\"ltx_td ltx_align_center ltx_border_b\">29.9</td>\n<td id=\"S6.T3.1.11.11.7\" class=\"ltx_td ltx_align_center ltx_border_b\">23.9</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Results.\nWe report precision@k𝑘k for k∈{1,3,4}𝑘134k\\in\\{1,3,4\\}\nin Table 3.\nOn all the datasets, FedAwS largely outperforms the two baseline methods of training with only positive labels. On both AmazonCat and Amazon670K, it matches or comes very close to the performance of Softmax and SLEEC. Baseline-2 gives reasonable (although quite sub-optimal) performance on AmazonCat; but does not work on Amazon670K and WikiLSHTC which have larger number of classes. Thus, randomly initialized class embeddings are not ideal in the situation of many classes, and it is crucial to train the class embeddings with the rest of the model.",
            "Meta parameters. There are two meta parameters in the proposed method: the learning rate multiplier of the spreadout loss λ𝜆\\lambda (cf. Algorithm 1), and the number top confusing labels considered in each round k𝑘k (cf. (8)).\nTo make a fair comparison with other methods which do not have these meta parameters, in all of our other experiments in Table 3, we simply use k=10𝑘10k=10 and λ=10𝜆10\\lambda=10."
        ]
    },
    "S6.T4": {
        "caption": "Table 4: P@1,3,5 (%) of different meta parameters on AmazonCat.",
        "table": "<table id=\"S6.T4.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T4.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T4.3.3.4\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_t\"></th>\n<th id=\"S6.T4.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Baseline-1</th>\n<th id=\"S6.T4.3.3.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Baseline-2</th>\n<th id=\"S6.T4.3.3.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">k = 10</th>\n<th id=\"S6.T4.3.3.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">k = 100</th>\n<th id=\"S6.T4.3.3.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">k = 500</th>\n<th id=\"S6.T4.3.3.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">k = all</th>\n<th id=\"S6.T4.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\">\n<math id=\"S6.T4.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\lambda\" display=\"inline\"><semantics id=\"S6.T4.1.1.1.m1.1a\"><mi id=\"S6.T4.1.1.1.m1.1.1\" xref=\"S6.T4.1.1.1.m1.1.1.cmml\">λ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T4.1.1.1.m1.1b\"><ci id=\"S6.T4.1.1.1.m1.1.1.cmml\" xref=\"S6.T4.1.1.1.m1.1.1\">𝜆</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T4.1.1.1.m1.1c\">\\lambda</annotation></semantics></math> = 1</th>\n<th id=\"S6.T4.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">\n<math id=\"S6.T4.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\lambda\" display=\"inline\"><semantics id=\"S6.T4.2.2.2.m1.1a\"><mi id=\"S6.T4.2.2.2.m1.1.1\" xref=\"S6.T4.2.2.2.m1.1.1.cmml\">λ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T4.2.2.2.m1.1b\"><ci id=\"S6.T4.2.2.2.m1.1.1.cmml\" xref=\"S6.T4.2.2.2.m1.1.1\">𝜆</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T4.2.2.2.m1.1c\">\\lambda</annotation></semantics></math> = 10</th>\n<th id=\"S6.T4.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><math id=\"S6.T4.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\lambda=100\" display=\"inline\"><semantics id=\"S6.T4.3.3.3.m1.1a\"><mrow id=\"S6.T4.3.3.3.m1.1.1\" xref=\"S6.T4.3.3.3.m1.1.1.cmml\"><mi id=\"S6.T4.3.3.3.m1.1.1.2\" xref=\"S6.T4.3.3.3.m1.1.1.2.cmml\">λ</mi><mo id=\"S6.T4.3.3.3.m1.1.1.1\" xref=\"S6.T4.3.3.3.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T4.3.3.3.m1.1.1.3\" xref=\"S6.T4.3.3.3.m1.1.1.3.cmml\">100</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T4.3.3.3.m1.1b\"><apply id=\"S6.T4.3.3.3.m1.1.1.cmml\" xref=\"S6.T4.3.3.3.m1.1.1\"><eq id=\"S6.T4.3.3.3.m1.1.1.1.cmml\" xref=\"S6.T4.3.3.3.m1.1.1.1\"></eq><ci id=\"S6.T4.3.3.3.m1.1.1.2.cmml\" xref=\"S6.T4.3.3.3.m1.1.1.2\">𝜆</ci><cn type=\"integer\" id=\"S6.T4.3.3.3.m1.1.1.3.cmml\" xref=\"S6.T4.3.3.3.m1.1.1.3\">100</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T4.3.3.3.m1.1c\">\\lambda=100</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T4.3.4.1\" class=\"ltx_tr\">\n<th id=\"S6.T4.3.4.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">P@1</th>\n<td id=\"S6.T4.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">3.4</td>\n<td id=\"S6.T4.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64.1</td>\n<td id=\"S6.T4.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">26.3</td>\n<td id=\"S6.T4.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">92.1</td>\n<td id=\"S6.T4.3.4.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">86.9</td>\n<td id=\"S6.T4.3.4.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">87.7</td>\n<th id=\"S6.T4.3.4.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">73.2</th>\n<td id=\"S6.T4.3.4.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">92.1</td>\n<td id=\"S6.T4.3.4.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\">92.2</td>\n</tr>\n<tr id=\"S6.T4.3.5.2\" class=\"ltx_tr\">\n<th id=\"S6.T4.3.5.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">P@3</th>\n<td id=\"S6.T4.3.5.2.2\" class=\"ltx_td ltx_align_center\">3.2</td>\n<td id=\"S6.T4.3.5.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">46.8</td>\n<td id=\"S6.T4.3.5.2.4\" class=\"ltx_td ltx_align_center\">21.5</td>\n<td id=\"S6.T4.3.5.2.5\" class=\"ltx_td ltx_align_center\">70.8</td>\n<td id=\"S6.T4.3.5.2.6\" class=\"ltx_td ltx_align_center\">66.1</td>\n<td id=\"S6.T4.3.5.2.7\" class=\"ltx_td ltx_align_center ltx_border_r\">69.7</td>\n<th id=\"S6.T4.3.5.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">50.2</th>\n<td id=\"S6.T4.3.5.2.9\" class=\"ltx_td ltx_align_center\">70.8</td>\n<td id=\"S6.T4.3.5.2.10\" class=\"ltx_td ltx_align_center\">71.7</td>\n</tr>\n<tr id=\"S6.T4.3.6.3\" class=\"ltx_tr\">\n<th id=\"S6.T4.3.6.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b\">P@5</th>\n<td id=\"S6.T4.3.6.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\">3.1</td>\n<td id=\"S6.T4.3.6.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">32.6</td>\n<td id=\"S6.T4.3.6.3.4\" class=\"ltx_td ltx_align_center ltx_border_b\">18.2</td>\n<td id=\"S6.T4.3.6.3.5\" class=\"ltx_td ltx_align_center ltx_border_b\">58.7</td>\n<td id=\"S6.T4.3.6.3.6\" class=\"ltx_td ltx_align_center ltx_border_b\">49.3</td>\n<td id=\"S6.T4.3.6.3.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">52.2</td>\n<th id=\"S6.T4.3.6.3.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b\">40.4</th>\n<td id=\"S6.T4.3.6.3.9\" class=\"ltx_td ltx_align_center ltx_border_b\">58.7</td>\n<td id=\"S6.T4.3.6.3.10\" class=\"ltx_td ltx_align_center ltx_border_b\">57.9</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We perform an analysis of these two parameters in Table 4 on the AmazonCat dataset. A very large k𝑘k leads to worse performance, verifying the benefit and requirement of stochastic negative mining. The reason for the bad performance for a small k𝑘k is that most of the picked labels are in fact positives in this setting (due to the inherent multi-label nature of the dataset), and over spreading the positive classes is not desirable. Regarding λ𝜆\\lambda, a relatively large value such as 10 or 100 is necessary to ensure that the class embeddings are sufficiently spreadout."
        ]
    }
}