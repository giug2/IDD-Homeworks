{
    "PAPER'S NUMBER OF TABLES": 13,
    "S4.T1": {
        "caption": "",
        "table": "",
        "footnotes": "\n\n\n\n\nDataset\nK=10ğ¾10K=10, C=10ğ¶10C=10\nK=20ğ¾20K=20, C=20ğ¶20C=20\nK=30ğ¾30K=30, C=30ğ¶30C=30\n\nCifar-10\n92.86%percent\\%\n92.93%percent\\%\n92.12%percent\\%\n\nSVHN\n95.49%percent\\%\n94.99%percent\\%\n78.77%percent\\% (94.93%âˆ—)\n\n\nK=10ğ¾10K=10, C=10ğ¶10C=10\nK=20ğ¾20K=20, C=10ğ¶10C=10\nK=30ğ¾30K=30, C=10ğ¶10C=10\n\nCifar-10\n92.86%percent\\%\n93.19%percent\\%\n92.84%percent\\%\n\nSVHN\n95.49%percent\\%\n95.43%percent\\%\n93.56%percent\\%\n\n",
        "references": [
            "As can be seen from the top ofÂ Tab.Â 1, increasing the number of users Kğ¾K has a marginal effect (<<1%) on the accuracy, from K=10ğ¾10K=10 to K=30ğ¾30K=30.\nOne notable thing here is that with K=30ğ¾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10ğ¾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30ğ¾30K=30 on SVHN, the final accuracy is 94.93%. One can refer toÂ Fig.Â C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000, K=100ğ¾100K=100, C=5ğ¶5C=5, and R=0ğ‘…0R=0 (which is the iid case) or R=1ğ‘…1R=1 (which is the most difficult non-iid case).\nFrom Tab.Â 3, one can see that our grouping-based solution outperforms the method proposed inÂ [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5ğ¶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatchÂ [11] inÂ Â§Â G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL)Â [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent workÂ [32] shows this may not be the case).\nFederated Averaging (FedAvg)Â [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FLÂ [16, 28, 33].\nInÂ [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is â€œrelatively ignoredâ€ and has â€œlittle prior arts,â€ as mentioned in a recent survey paperÂ [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users Kâˆˆ{47,20,10}ğ¾472010K\\in\\{47,20,10\\}. In these three settings, we let C=Kğ¶ğ¾C=K.\nThe other environmental factors are shown in rows 32-34 ofÂ Tab.Â A.2.\nWe set the group number S=5ğ‘†5S=5, S=2ğ‘†2S=2 and S=2ğ‘†2S=2 for the setting of K=47ğ¾47K=47, K=20ğ¾20K=20 and K=10ğ¾10K=10, respectively.\nSee TableÂ F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in TableÂ J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users Cğ¶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed inÂ Â§Â 4.2."
        ]
    },
    "S4.T2": {
        "caption": "",
        "table": "",
        "footnotes": "\n\n\n\n\nDataset\n\n\n\nK=47ğ¾47K=47\n\nC=10ğ¶10C=10\n\n\n\n\nK=47ğ¾47K=47\n\nC=30ğ¶30C=30\n\n\n\n\nK=47ğ¾47K=47\n\nC=47ğ¶47C=47\n\n\nEMNIST (FedAvg)\n83.07%percent\\%\n79.05%percent\\%\n65.48%percent\\%\n\nEMNIST (Grouping-based)\n84.43%percent\\%\n83.12%percent\\%\n82.95%percent\\%\n\n",
        "references": [
            "As can be seen from the top ofÂ Tab.Â 1, increasing the number of users Kğ¾K has a marginal effect (<<1%) on the accuracy, from K=10ğ¾10K=10 to K=30ğ¾30K=30.\nOne notable thing here is that with K=30ğ¾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10ğ¾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30ğ¾30K=30 on SVHN, the final accuracy is 94.93%. One can refer toÂ Fig.Â C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000, K=100ğ¾100K=100, C=5ğ¶5C=5, and R=0ğ‘…0R=0 (which is the iid case) or R=1ğ‘…1R=1 (which is the most difficult non-iid case).\nFrom Tab.Â 3, one can see that our grouping-based solution outperforms the method proposed inÂ [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5ğ¶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatchÂ [11] inÂ Â§Â G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL)Â [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent workÂ [32] shows this may not be the case).\nFederated Averaging (FedAvg)Â [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FLÂ [16, 28, 33].\nInÂ [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is â€œrelatively ignoredâ€ and has â€œlittle prior arts,â€ as mentioned in a recent survey paperÂ [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users Kâˆˆ{47,20,10}ğ¾472010K\\in\\{47,20,10\\}. In these three settings, we let C=Kğ¶ğ¾C=K.\nThe other environmental factors are shown in rows 32-34 ofÂ Tab.Â A.2.\nWe set the group number S=5ğ‘†5S=5, S=2ğ‘†2S=2 and S=2ğ‘†2S=2 for the setting of K=47ğ¾47K=47, K=20ğ¾20K=20 and K=10ğ¾10K=10, respectively.\nSee TableÂ F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in TableÂ J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users Cğ¶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed inÂ Â§Â 4.2."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Comparing with [9] in exactly the same setting on Cifar-10. The model in [9] is ResNet-9.\n",
        "table": "<table id=\"S4.T3.3\" class=\"ltx_tabular ltx_centering ltx_align_top\">\n<tr id=\"S4.T3.3.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S4.T3.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedMatch</td>\n<td id=\"S4.T3.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Ours</td>\n</tr>\n<tr id=\"S4.T3.3.2\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"S4.T3.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T3.3.2.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">Labels-at-client (iid)</span></td>\n<td id=\"S4.T3.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.3.2.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">53.51%</span></td>\n<td id=\"S4.T3.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.3.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#FFCC99;\">71.61%</span></td>\n</tr>\n<tr id=\"S4.T3.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.3.1\" class=\"ltx_td ltx_align_left\">Labels-at-client (non-iid)</td>\n<td id=\"S4.T3.3.3.2\" class=\"ltx_td ltx_align_center\">54.26%</td>\n<td id=\"S4.T3.3.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">69.05%</span></td>\n</tr>\n<tr id=\"S4.T3.3.4\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"S4.T3.3.4.1\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T3.3.4.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">Labels-at-server (iid)</span></td>\n<td id=\"S4.T3.3.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.3.4.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">46.81%</span></td>\n<td id=\"S4.T3.3.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.3.4.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#FFCC99;\">63.32%</span></td>\n</tr>\n<tr id=\"S4.T3.3.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Labels-at-server (non-iid)</td>\n<td id=\"S4.T3.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">47.11%</td>\n<td id=\"S4.T3.3.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.3.5.3.1\" class=\"ltx_text ltx_font_bold\">63.24%</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper ",
                "[",
                "9",
                "]",
                ".\nFor the Cifar-10 data, according to Table 1 in ",
                "[",
                "9",
                "]",
                ", we set ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "5000",
                "N_{s}=5000",
                ", ",
                "K",
                "=",
                "100",
                "ğ¾",
                "100",
                "K=100",
                ", ",
                "C",
                "=",
                "5",
                "ğ¶",
                "5",
                "C=5",
                ", and ",
                "R",
                "=",
                "0",
                "ğ‘…",
                "0",
                "R=0",
                " (which is the iid case) or ",
                "R",
                "=",
                "1",
                "ğ‘…",
                "1",
                "R=1",
                " (which is the most difficult non-iid case).\nFrom Tab.Â ",
                "3",
                ", one can see that our grouping-based solution outperforms the method proposed inÂ ",
                "[",
                "9",
                "]",
                " by a large margin.\nWe notice that the results in ",
                "[",
                "9",
                "]",
                " are presented in two different settings including the ",
                "labels-at-server",
                " setting and the ",
                "labels-at-client",
                " setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "5000",
                "N_{s}=5000",
                " labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "5000",
                "N_{s}=5000",
                " labeled data are distributed to 100 users. In each round, ",
                "C",
                "=",
                "5",
                "ğ¶",
                "5",
                "C=5",
                " users are random selected to communicate with the server.\nSee Appendix ",
                "H",
                " for the details of adapting our solution to the label-at-the-client setting.",
                "We also compare our solution with supervised FL methods inÂ Tab.Â ",
                "4",
                ".\nWe choose two supervised FL methods for comparison: Supervised FedAvgÂ ",
                "[",
                "2",
                "]",
                " and DataSharingÂ ",
                "[",
                "16",
                "]",
                ".\nWe set ",
                "K",
                "=",
                "10",
                "ğ¾",
                "10",
                "K=10",
                ", ",
                "C",
                "=",
                "10",
                "ğ¶",
                "10",
                "C=10",
                " and ",
                "T",
                "=",
                "32",
                "ğ‘‡",
                "32",
                "T=32",
                ", and we use ResNet-18 to be the model for training.\nThe non-iid setting of DataSharingÂ ",
                "[",
                "16",
                "]",
                " corresponds to the scenario where we set ",
                "R",
                "=",
                "0.29",
                "ğ‘…",
                "0.29",
                "R=0.29",
                ".\nFor our solutions, we set ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "1000",
                "N_{s}=1000",
                " and ",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                ". The detailed experimental parameters of different methods can be seen from rows 22-25 ofÂ Tab.Â ",
                "A.2",
                ".\nLarger ",
                "R",
                "ğ‘…",
                "R",
                " means a higher non-iid level and thus a more difficult scenario (which we have experimentally demonstrated in Fig.Â ",
                "5",
                "). FromÂ Tab.Â ",
                "4",
                " we see that the performance of our method (",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                ") on Cifar-10 is still better than Supervised FedAvg (",
                "R",
                "=",
                "0.29",
                "ğ‘…",
                "0.29",
                "R=0.29",
                ") and DataSharing methods (",
                "R",
                "=",
                "0.29",
                "ğ‘…",
                "0.29",
                "R=0.29",
                ") even when the scenario of ",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                " is more difficult.",
                "We also compare our method with EASGDÂ ",
                "[",
                "14",
                "]",
                " and OverlapSGDÂ ",
                "[",
                "15",
                "]",
                " which are communication efficient algorithms under supervised settings.\nWe use the same parameters in their papers, i.e., ",
                "K",
                "=",
                "16",
                "ğ¾",
                "16",
                "K=16",
                ", ",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                ", ",
                "C",
                "=",
                "16",
                "ğ¶",
                "16",
                "C=16",
                " and ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "1000",
                "N_{s}=1000",
                " on Cifar-10. See rows 26-29 ofÂ Tab.Â ",
                "A.2",
                " for the details.\nThe results are shown inÂ Tab.Â ",
                "5",
                ".\nWe see that our result has better accuracy than both EASGD and OverlapSGD.\nParticularly, even with ",
                "T",
                "=",
                "32",
                "ğ‘‡",
                "32",
                "T=32",
                " (larger ",
                "T",
                "ğ‘‡",
                "T",
                " means a harder scenario; see Fig.Â ",
                "5",
                "), our method has 0.80% or 0.29% better performance, as compared to EASGD or OverlapSGD in the setting of ",
                "T",
                "=",
                "2",
                "ğ‘‡",
                "2",
                "T=2",
                ", respectively.\nNote that both EASGD and OverlapSGD are supervised algorithms, which means they have all the data labels.",
                "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â ",
                "F",
                ", and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the ",
                "SSFL",
                " setting.\nWe also compare our grouping-based solution with FixMatchÂ ",
                "[",
                "11",
                "]",
                " inÂ Â§Â ",
                "G",
                ").\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â ",
                "H",
                ", i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â ",
                "I",
                ".\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â ",
                "J",
                ". We show that the grouping-based method outperforms FedAvg in this setting as well."
            ]
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Comparison with supervised FL. Here, â€œâˆ—â€ is calculated according to the setting in DataSharing.\n",
        "table": "<div id=\"S4.T4.8\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:211.4pt;height:72pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<p id=\"S4.T4.8.6\" class=\"ltx_p\"><span id=\"S4.T4.8.6.6\" class=\"ltx_text\">\n<span id=\"S4.T4.8.6.6.6\" class=\"ltx_tabular ltx_align_top\">\n<span id=\"S4.T4.8.6.6.6.7\" class=\"ltx_tr\">\n<span id=\"S4.T4.8.6.6.6.7.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">Method</span>\n<span id=\"S4.T4.8.6.6.6.7.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Test accuracy</span></span>\n<span id=\"S4.T4.4.2.2.2.2\" class=\"ltx_tr\">\n<span id=\"S4.T4.4.2.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Supervised FedAvg</span>\n<span id=\"S4.T4.4.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">78.52<math id=\"S4.T4.3.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T4.3.1.1.1.1.1.m1.1a\"><mo id=\"S4.T4.3.1.1.1.1.1.m1.1.1\" xref=\"S4.T4.3.1.1.1.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.3.1.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T4.3.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T4.3.1.1.1.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.3.1.1.1.1.1.m1.1c\">\\%</annotation></semantics></math> (<math id=\"S4.T4.4.2.2.2.2.2.m2.1\" class=\"ltx_Math\" alttext=\"R=0.29\" display=\"inline\"><semantics id=\"S4.T4.4.2.2.2.2.2.m2.1a\"><mrow id=\"S4.T4.4.2.2.2.2.2.m2.1.1\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.cmml\"><mi id=\"S4.T4.4.2.2.2.2.2.m2.1.1.2\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.2.cmml\">R</mi><mo id=\"S4.T4.4.2.2.2.2.2.m2.1.1.1\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.1.cmml\">=</mo><mn id=\"S4.T4.4.2.2.2.2.2.m2.1.1.3\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.3.cmml\">0.29</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.4.2.2.2.2.2.m2.1b\"><apply id=\"S4.T4.4.2.2.2.2.2.m2.1.1.cmml\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1\"><eq id=\"S4.T4.4.2.2.2.2.2.m2.1.1.1.cmml\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.1\"></eq><ci id=\"S4.T4.4.2.2.2.2.2.m2.1.1.2.cmml\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.2\">ğ‘…</ci><cn type=\"float\" id=\"S4.T4.4.2.2.2.2.2.m2.1.1.3.cmml\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.3\">0.29</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.4.2.2.2.2.2.m2.1c\">R=0.29</annotation></semantics></math>)</span></span>\n<span id=\"S4.T4.6.4.4.4.4\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<span id=\"S4.T4.6.4.4.4.4.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T4.6.4.4.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">DataSharing</span></span>\n<span id=\"S4.T4.6.4.4.4.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.6.4.4.4.4.2.2\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">81.82<math id=\"S4.T4.5.3.3.3.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T4.5.3.3.3.3.1.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"S4.T4.5.3.3.3.3.1.1.m1.1.1\" xref=\"S4.T4.5.3.3.3.3.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.5.3.3.3.3.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T4.5.3.3.3.3.1.1.m1.1.1.cmml\" xref=\"S4.T4.5.3.3.3.3.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.5.3.3.3.3.1.1.m1.1c\">\\%</annotation></semantics></math> (<math id=\"S4.T4.6.4.4.4.4.2.2.m2.1\" class=\"ltx_Math\" alttext=\"R=0.29^{*}\" display=\"inline\"><semantics id=\"S4.T4.6.4.4.4.4.2.2.m2.1a\"><mrow id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.cmml\"><mi mathbackground=\"#FFCC99\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.2\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.2.cmml\">R</mi><mo mathbackground=\"#FFCC99\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.1\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.1.cmml\">=</mo><msup id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.cmml\"><mn mathbackground=\"#FFCC99\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.2\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.2.cmml\">0.29</mn><mo mathbackground=\"#FFCC99\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.3\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.3.cmml\">âˆ—</mo></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1b\"><apply id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1\"><eq id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.1.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.1\"></eq><ci id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.2.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.2\">ğ‘…</ci><apply id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.1.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3\">superscript</csymbol><cn type=\"float\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.2.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.2\">0.29</cn><times id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.3.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.3\"></times></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1c\">R=0.29^{*}</annotation></semantics></math>)</span></span></span>\n<span id=\"S4.T4.8.6.6.6.6\" class=\"ltx_tr\">\n<span id=\"S4.T4.8.6.6.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">Grouping-based (ours)</span>\n<span id=\"S4.T4.8.6.6.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.8.6.6.6.6.2.2\" class=\"ltx_text ltx_font_bold\">92.96<math id=\"S4.T4.7.5.5.5.5.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T4.7.5.5.5.5.1.1.m1.1a\"><mo id=\"S4.T4.7.5.5.5.5.1.1.m1.1.1\" xref=\"S4.T4.7.5.5.5.5.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.7.5.5.5.5.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T4.7.5.5.5.5.1.1.m1.1.1.cmml\" xref=\"S4.T4.7.5.5.5.5.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.7.5.5.5.5.1.1.m1.1c\">\\%</annotation></semantics></math> (<math id=\"S4.T4.8.6.6.6.6.2.2.m2.1\" class=\"ltx_Math\" alttext=\"R=0.4\" display=\"inline\"><semantics id=\"S4.T4.8.6.6.6.6.2.2.m2.1a\"><mrow id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.cmml\"><mi id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.2\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.2.cmml\">R</mi><mo id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.1\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.1.cmml\">=</mo><mn id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.3\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.3.cmml\">0.4</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.8.6.6.6.6.2.2.m2.1b\"><apply id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.cmml\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1\"><eq id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.1.cmml\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.1\"></eq><ci id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.2.cmml\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.2\">ğ‘…</ci><cn type=\"float\" id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.3.cmml\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.3\">0.4</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.8.6.6.6.6.2.2.m2.1c\">R=0.4</annotation></semantics></math>)</span></span></span>\n</span></span></p>\n</span></div>\n\n",
        "footnotes": "\n\n\nMethod\nTest accuracy\n\nSupervised FedAvg\n78.52%percent\\% (R=0.29ğ‘…0.29R=0.29)\n\nDataSharing\n81.82%percent\\% (R=0.29âˆ—ğ‘…superscript0.29R=0.29^{*})\n\nGrouping-based (ours)\n92.96%percent\\% (R=0.4ğ‘…0.4R=0.4)\n",
        "references": [
            [
                "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper ",
                "[",
                "9",
                "]",
                ".\nFor the Cifar-10 data, according to Table 1 in ",
                "[",
                "9",
                "]",
                ", we set ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "5000",
                "N_{s}=5000",
                ", ",
                "K",
                "=",
                "100",
                "ğ¾",
                "100",
                "K=100",
                ", ",
                "C",
                "=",
                "5",
                "ğ¶",
                "5",
                "C=5",
                ", and ",
                "R",
                "=",
                "0",
                "ğ‘…",
                "0",
                "R=0",
                " (which is the iid case) or ",
                "R",
                "=",
                "1",
                "ğ‘…",
                "1",
                "R=1",
                " (which is the most difficult non-iid case).\nFrom Tab.Â ",
                "3",
                ", one can see that our grouping-based solution outperforms the method proposed inÂ ",
                "[",
                "9",
                "]",
                " by a large margin.\nWe notice that the results in ",
                "[",
                "9",
                "]",
                " are presented in two different settings including the ",
                "labels-at-server",
                " setting and the ",
                "labels-at-client",
                " setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "5000",
                "N_{s}=5000",
                " labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "5000",
                "N_{s}=5000",
                " labeled data are distributed to 100 users. In each round, ",
                "C",
                "=",
                "5",
                "ğ¶",
                "5",
                "C=5",
                " users are random selected to communicate with the server.\nSee Appendix ",
                "H",
                " for the details of adapting our solution to the label-at-the-client setting.",
                "We also compare our solution with supervised FL methods inÂ Tab.Â ",
                "4",
                ".\nWe choose two supervised FL methods for comparison: Supervised FedAvgÂ ",
                "[",
                "2",
                "]",
                " and DataSharingÂ ",
                "[",
                "16",
                "]",
                ".\nWe set ",
                "K",
                "=",
                "10",
                "ğ¾",
                "10",
                "K=10",
                ", ",
                "C",
                "=",
                "10",
                "ğ¶",
                "10",
                "C=10",
                " and ",
                "T",
                "=",
                "32",
                "ğ‘‡",
                "32",
                "T=32",
                ", and we use ResNet-18 to be the model for training.\nThe non-iid setting of DataSharingÂ ",
                "[",
                "16",
                "]",
                " corresponds to the scenario where we set ",
                "R",
                "=",
                "0.29",
                "ğ‘…",
                "0.29",
                "R=0.29",
                ".\nFor our solutions, we set ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "1000",
                "N_{s}=1000",
                " and ",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                ". The detailed experimental parameters of different methods can be seen from rows 22-25 ofÂ Tab.Â ",
                "A.2",
                ".\nLarger ",
                "R",
                "ğ‘…",
                "R",
                " means a higher non-iid level and thus a more difficult scenario (which we have experimentally demonstrated in Fig.Â ",
                "5",
                "). FromÂ Tab.Â ",
                "4",
                " we see that the performance of our method (",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                ") on Cifar-10 is still better than Supervised FedAvg (",
                "R",
                "=",
                "0.29",
                "ğ‘…",
                "0.29",
                "R=0.29",
                ") and DataSharing methods (",
                "R",
                "=",
                "0.29",
                "ğ‘…",
                "0.29",
                "R=0.29",
                ") even when the scenario of ",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                " is more difficult.",
                "We also compare our method with EASGDÂ ",
                "[",
                "14",
                "]",
                " and OverlapSGDÂ ",
                "[",
                "15",
                "]",
                " which are communication efficient algorithms under supervised settings.\nWe use the same parameters in their papers, i.e., ",
                "K",
                "=",
                "16",
                "ğ¾",
                "16",
                "K=16",
                ", ",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                ", ",
                "C",
                "=",
                "16",
                "ğ¶",
                "16",
                "C=16",
                " and ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "1000",
                "N_{s}=1000",
                " on Cifar-10. See rows 26-29 ofÂ Tab.Â ",
                "A.2",
                " for the details.\nThe results are shown inÂ Tab.Â ",
                "5",
                ".\nWe see that our result has better accuracy than both EASGD and OverlapSGD.\nParticularly, even with ",
                "T",
                "=",
                "32",
                "ğ‘‡",
                "32",
                "T=32",
                " (larger ",
                "T",
                "ğ‘‡",
                "T",
                " means a harder scenario; see Fig.Â ",
                "5",
                "), our method has 0.80% or 0.29% better performance, as compared to EASGD or OverlapSGD in the setting of ",
                "T",
                "=",
                "2",
                "ğ‘‡",
                "2",
                "T=2",
                ", respectively.\nNote that both EASGD and OverlapSGD are supervised algorithms, which means they have all the data labels.",
                "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â ",
                "F",
                ", and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the ",
                "SSFL",
                " setting.\nWe also compare our grouping-based solution with FixMatchÂ ",
                "[",
                "11",
                "]",
                " inÂ Â§Â ",
                "G",
                ").\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â ",
                "H",
                ", i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â ",
                "I",
                ".\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â ",
                "J",
                ". We show that the grouping-based method outperforms FedAvg in this setting as well."
            ]
        ]
    },
    "S4.T5": {
        "caption": "Table 5: Comparison with two other supervised FL algorithms EASGD and OverlapSGD on Cifar-10.\n",
        "table": "<div id=\"S4.T5.12\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:243.2pt;height:72pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<p id=\"S4.T5.12.12\" class=\"ltx_p\"><span id=\"S4.T5.12.12.12\" class=\"ltx_text\">\n<span id=\"S4.T5.12.12.12.12\" class=\"ltx_tabular ltx_align_top\">\n<span id=\"S4.T5.3.3.3.3.3\" class=\"ltx_tr\">\n<span id=\"S4.T5.3.3.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_tt\">Method</span>\n<span id=\"S4.T5.1.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"S4.T5.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"T=2\" display=\"inline\"><semantics id=\"S4.T5.1.1.1.1.1.1.m1.1a\"><mrow id=\"S4.T5.1.1.1.1.1.1.m1.1.1\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T5.1.1.1.1.1.1.m1.1.1.2\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.2.cmml\">T</mi><mo id=\"S4.T5.1.1.1.1.1.1.m1.1.1.1\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T5.1.1.1.1.1.1.m1.1.1.3\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.1.1.1.1.1.1.m1.1b\"><apply id=\"S4.T5.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1\"><eq id=\"S4.T5.1.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.1\"></eq><ci id=\"S4.T5.1.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.2\">ğ‘‡</ci><cn type=\"integer\" id=\"S4.T5.1.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.1.1.1.1.1.1.m1.1c\">T=2</annotation></semantics></math></span>\n<span id=\"S4.T5.2.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"S4.T5.2.2.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"T=8\" display=\"inline\"><semantics id=\"S4.T5.2.2.2.2.2.2.m1.1a\"><mrow id=\"S4.T5.2.2.2.2.2.2.m1.1.1\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.cmml\"><mi id=\"S4.T5.2.2.2.2.2.2.m1.1.1.2\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.2.cmml\">T</mi><mo id=\"S4.T5.2.2.2.2.2.2.m1.1.1.1\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T5.2.2.2.2.2.2.m1.1.1.3\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.3.cmml\">8</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.2.2.2.2.2.2.m1.1b\"><apply id=\"S4.T5.2.2.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1\"><eq id=\"S4.T5.2.2.2.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.1\"></eq><ci id=\"S4.T5.2.2.2.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.2\">ğ‘‡</ci><cn type=\"integer\" id=\"S4.T5.2.2.2.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.3\">8</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.2.2.2.2.2.2.m1.1c\">T=8</annotation></semantics></math></span>\n<span id=\"S4.T5.3.3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"S4.T5.3.3.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"T=32\" display=\"inline\"><semantics id=\"S4.T5.3.3.3.3.3.3.m1.1a\"><mrow id=\"S4.T5.3.3.3.3.3.3.m1.1.1\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.cmml\"><mi id=\"S4.T5.3.3.3.3.3.3.m1.1.1.2\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.2.cmml\">T</mi><mo id=\"S4.T5.3.3.3.3.3.3.m1.1.1.1\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T5.3.3.3.3.3.3.m1.1.1.3\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.3.cmml\">32</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.3.3.3.3.3.3.m1.1b\"><apply id=\"S4.T5.3.3.3.3.3.3.m1.1.1.cmml\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1\"><eq id=\"S4.T5.3.3.3.3.3.3.m1.1.1.1.cmml\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.1\"></eq><ci id=\"S4.T5.3.3.3.3.3.3.m1.1.1.2.cmml\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.2\">ğ‘‡</ci><cn type=\"integer\" id=\"S4.T5.3.3.3.3.3.3.m1.1.1.3.cmml\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.3\">32</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.3.3.3.3.3.3.m1.1c\">T=32</annotation></semantics></math></span></span>\n<span id=\"S4.T5.6.6.6.6.6\" class=\"ltx_tr\">\n<span id=\"S4.T5.6.6.6.6.6.4\" class=\"ltx_td ltx_align_left ltx_border_t\">EASGD</span>\n<span id=\"S4.T5.4.4.4.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\">91.12<math id=\"S4.T5.4.4.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.4.4.4.4.4.1.m1.1a\"><mo id=\"S4.T5.4.4.4.4.4.1.m1.1.1\" xref=\"S4.T5.4.4.4.4.4.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.4.4.4.4.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.4.4.4.4.4.1.m1.1.1.cmml\" xref=\"S4.T5.4.4.4.4.4.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.4.4.4.4.4.1.m1.1c\">\\%</annotation></semantics></math></span>\n<span id=\"S4.T5.5.5.5.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">88.88<math id=\"S4.T5.5.5.5.5.5.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.5.5.5.5.5.2.m1.1a\"><mo id=\"S4.T5.5.5.5.5.5.2.m1.1.1\" xref=\"S4.T5.5.5.5.5.5.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.5.5.5.5.5.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.5.5.5.5.5.2.m1.1.1.cmml\" xref=\"S4.T5.5.5.5.5.5.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.5.5.5.5.5.2.m1.1c\">\\%</annotation></semantics></math></span>\n<span id=\"S4.T5.6.6.6.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T5.6.6.6.6.6.3.m1.1\" class=\"ltx_Math\" alttext=\"-\" display=\"inline\"><semantics id=\"S4.T5.6.6.6.6.6.3.m1.1a\"><mo id=\"S4.T5.6.6.6.6.6.3.m1.1.1\" xref=\"S4.T5.6.6.6.6.6.3.m1.1.1.cmml\">âˆ’</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.6.6.6.6.6.3.m1.1b\"><minus id=\"S4.T5.6.6.6.6.6.3.m1.1.1.cmml\" xref=\"S4.T5.6.6.6.6.6.3.m1.1.1\"></minus></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.6.6.6.6.6.3.m1.1c\">-</annotation></semantics></math></span></span>\n<span id=\"S4.T5.9.9.9.9.9\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<span id=\"S4.T5.9.9.9.9.9.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T5.9.9.9.9.9.4.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">OverlapSGD</span></span>\n<span id=\"S4.T5.7.7.7.7.7.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.7.7.7.7.7.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">91.63<math id=\"S4.T5.7.7.7.7.7.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.7.7.7.7.7.1.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"S4.T5.7.7.7.7.7.1.1.m1.1.1\" xref=\"S4.T5.7.7.7.7.7.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.7.7.7.7.7.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.7.7.7.7.7.1.1.m1.1.1.cmml\" xref=\"S4.T5.7.7.7.7.7.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.7.7.7.7.7.1.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"S4.T5.8.8.8.8.8.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.8.8.8.8.8.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">91.45<math id=\"S4.T5.8.8.8.8.8.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.8.8.8.8.8.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"S4.T5.8.8.8.8.8.2.1.m1.1.1\" xref=\"S4.T5.8.8.8.8.8.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.8.8.8.8.8.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.8.8.8.8.8.2.1.m1.1.1.cmml\" xref=\"S4.T5.8.8.8.8.8.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.8.8.8.8.8.2.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"S4.T5.9.9.9.9.9.3\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T5.9.9.9.9.9.3.m1.1\" class=\"ltx_Math\" style=\"background-color:#FFCC99;\" alttext=\"-\" display=\"inline\"><semantics id=\"S4.T5.9.9.9.9.9.3.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"S4.T5.9.9.9.9.9.3.m1.1.1\" xref=\"S4.T5.9.9.9.9.9.3.m1.1.1.cmml\">âˆ’</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.9.9.9.9.9.3.m1.1b\"><minus id=\"S4.T5.9.9.9.9.9.3.m1.1.1.cmml\" xref=\"S4.T5.9.9.9.9.9.3.m1.1.1\"></minus></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.9.9.9.9.9.3.m1.1c\">-</annotation></semantics></math></span></span>\n<span id=\"S4.T5.12.12.12.12.12\" class=\"ltx_tr\">\n<span id=\"S4.T5.12.12.12.12.12.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">Grouping-based (ours)</span>\n<span id=\"S4.T5.10.10.10.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.10.10.10.10.10.1.1\" class=\"ltx_text ltx_font_bold\">94.22<math id=\"S4.T5.10.10.10.10.10.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.10.10.10.10.10.1.1.m1.1a\"><mo id=\"S4.T5.10.10.10.10.10.1.1.m1.1.1\" xref=\"S4.T5.10.10.10.10.10.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.10.10.10.10.10.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.10.10.10.10.10.1.1.m1.1.1.cmml\" xref=\"S4.T5.10.10.10.10.10.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.10.10.10.10.10.1.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"S4.T5.11.11.11.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.11.11.11.11.11.2.1\" class=\"ltx_text ltx_font_bold\">93.58<math id=\"S4.T5.11.11.11.11.11.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.11.11.11.11.11.2.1.m1.1a\"><mo id=\"S4.T5.11.11.11.11.11.2.1.m1.1.1\" xref=\"S4.T5.11.11.11.11.11.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.11.11.11.11.11.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.11.11.11.11.11.2.1.m1.1.1.cmml\" xref=\"S4.T5.11.11.11.11.11.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.11.11.11.11.11.2.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"S4.T5.12.12.12.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.12.12.12.12.12.3.1\" class=\"ltx_text ltx_font_bold\">91.92<math id=\"S4.T5.12.12.12.12.12.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.12.12.12.12.12.3.1.m1.1a\"><mo id=\"S4.T5.12.12.12.12.12.3.1.m1.1.1\" xref=\"S4.T5.12.12.12.12.12.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.12.12.12.12.12.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.12.12.12.12.12.3.1.m1.1.1.cmml\" xref=\"S4.T5.12.12.12.12.12.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.12.12.12.12.12.3.1.m1.1c\">\\%</annotation></semantics></math></span></span></span>\n</span></span></p>\n</span></div>\n\n",
        "footnotes": "\n\n\nMethod\nT=2ğ‘‡2T=2\nT=8ğ‘‡8T=8\nT=32ğ‘‡32T=32\n\nEASGD\n91.12%percent\\%\n88.88%percent\\%\nâˆ’-\n\nOverlapSGD\n91.63%percent\\%\n91.45%percent\\%\nâˆ’-\n\nGrouping-based (ours)\n94.22%percent\\%\n93.58%percent\\%\n91.92%percent\\%\n",
        "references": [
            [
                "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper ",
                "[",
                "9",
                "]",
                ".\nFor the Cifar-10 data, according to Table 1 in ",
                "[",
                "9",
                "]",
                ", we set ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "5000",
                "N_{s}=5000",
                ", ",
                "K",
                "=",
                "100",
                "ğ¾",
                "100",
                "K=100",
                ", ",
                "C",
                "=",
                "5",
                "ğ¶",
                "5",
                "C=5",
                ", and ",
                "R",
                "=",
                "0",
                "ğ‘…",
                "0",
                "R=0",
                " (which is the iid case) or ",
                "R",
                "=",
                "1",
                "ğ‘…",
                "1",
                "R=1",
                " (which is the most difficult non-iid case).\nFrom Tab.Â ",
                "3",
                ", one can see that our grouping-based solution outperforms the method proposed inÂ ",
                "[",
                "9",
                "]",
                " by a large margin.\nWe notice that the results in ",
                "[",
                "9",
                "]",
                " are presented in two different settings including the ",
                "labels-at-server",
                " setting and the ",
                "labels-at-client",
                " setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "5000",
                "N_{s}=5000",
                " labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "5000",
                "N_{s}=5000",
                " labeled data are distributed to 100 users. In each round, ",
                "C",
                "=",
                "5",
                "ğ¶",
                "5",
                "C=5",
                " users are random selected to communicate with the server.\nSee Appendix ",
                "H",
                " for the details of adapting our solution to the label-at-the-client setting.",
                "We also compare our solution with supervised FL methods inÂ Tab.Â ",
                "4",
                ".\nWe choose two supervised FL methods for comparison: Supervised FedAvgÂ ",
                "[",
                "2",
                "]",
                " and DataSharingÂ ",
                "[",
                "16",
                "]",
                ".\nWe set ",
                "K",
                "=",
                "10",
                "ğ¾",
                "10",
                "K=10",
                ", ",
                "C",
                "=",
                "10",
                "ğ¶",
                "10",
                "C=10",
                " and ",
                "T",
                "=",
                "32",
                "ğ‘‡",
                "32",
                "T=32",
                ", and we use ResNet-18 to be the model for training.\nThe non-iid setting of DataSharingÂ ",
                "[",
                "16",
                "]",
                " corresponds to the scenario where we set ",
                "R",
                "=",
                "0.29",
                "ğ‘…",
                "0.29",
                "R=0.29",
                ".\nFor our solutions, we set ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "1000",
                "N_{s}=1000",
                " and ",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                ". The detailed experimental parameters of different methods can be seen from rows 22-25 ofÂ Tab.Â ",
                "A.2",
                ".\nLarger ",
                "R",
                "ğ‘…",
                "R",
                " means a higher non-iid level and thus a more difficult scenario (which we have experimentally demonstrated in Fig.Â ",
                "5",
                "). FromÂ Tab.Â ",
                "4",
                " we see that the performance of our method (",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                ") on Cifar-10 is still better than Supervised FedAvg (",
                "R",
                "=",
                "0.29",
                "ğ‘…",
                "0.29",
                "R=0.29",
                ") and DataSharing methods (",
                "R",
                "=",
                "0.29",
                "ğ‘…",
                "0.29",
                "R=0.29",
                ") even when the scenario of ",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                " is more difficult.",
                "We also compare our method with EASGDÂ ",
                "[",
                "14",
                "]",
                " and OverlapSGDÂ ",
                "[",
                "15",
                "]",
                " which are communication efficient algorithms under supervised settings.\nWe use the same parameters in their papers, i.e., ",
                "K",
                "=",
                "16",
                "ğ¾",
                "16",
                "K=16",
                ", ",
                "R",
                "=",
                "0.4",
                "ğ‘…",
                "0.4",
                "R=0.4",
                ", ",
                "C",
                "=",
                "16",
                "ğ¶",
                "16",
                "C=16",
                " and ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "ğ‘",
                "ğ‘ ",
                "1000",
                "N_{s}=1000",
                " on Cifar-10. See rows 26-29 ofÂ Tab.Â ",
                "A.2",
                " for the details.\nThe results are shown inÂ Tab.Â ",
                "5",
                ".\nWe see that our result has better accuracy than both EASGD and OverlapSGD.\nParticularly, even with ",
                "T",
                "=",
                "32",
                "ğ‘‡",
                "32",
                "T=32",
                " (larger ",
                "T",
                "ğ‘‡",
                "T",
                " means a harder scenario; see Fig.Â ",
                "5",
                "), our method has 0.80% or 0.29% better performance, as compared to EASGD or OverlapSGD in the setting of ",
                "T",
                "=",
                "2",
                "ğ‘‡",
                "2",
                "T=2",
                ", respectively.\nNote that both EASGD and OverlapSGD are supervised algorithms, which means they have all the data labels.",
                "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â ",
                "F",
                ", and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the ",
                "SSFL",
                " setting.\nWe also compare our grouping-based solution with FixMatchÂ ",
                "[",
                "11",
                "]",
                " inÂ Â§Â ",
                "G",
                ").\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â ",
                "H",
                ", i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â ",
                "I",
                ".\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â ",
                "J",
                ". We show that the grouping-based method outperforms FedAvg in this setting as well."
            ]
        ]
    },
    "A1.T1": {
        "caption": "Table A.1: Optimizer hyperparameters used on different datasets. ",
        "table": "<table id=\"A1.T1.7\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T1.7.7\" class=\"ltx_tr\">\n<td id=\"A1.T1.7.7.8\" class=\"ltx_td ltx_align_left ltx_border_tt\">Dataset</td>\n<td id=\"A1.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"E\" display=\"inline\"><semantics id=\"A1.T1.1.1.1.m1.1a\"><mi id=\"A1.T1.1.1.1.m1.1.1\" xref=\"A1.T1.1.1.1.m1.1.1.cmml\">E</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.1.1.1.m1.1b\"><ci id=\"A1.T1.1.1.1.m1.1.1.cmml\" xref=\"A1.T1.1.1.1.m1.1.1\">ğ¸</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.1.1.1.m1.1c\">E</annotation></semantics></math></td>\n<td id=\"A1.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"M\" display=\"inline\"><semantics id=\"A1.T1.2.2.2.m1.1a\"><mi id=\"A1.T1.2.2.2.m1.1.1\" xref=\"A1.T1.2.2.2.m1.1.1.cmml\">M</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.2.2.2.m1.1b\"><ci id=\"A1.T1.2.2.2.m1.1.1.cmml\" xref=\"A1.T1.2.2.2.m1.1.1\">ğ‘€</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.2.2.2.m1.1c\">M</annotation></semantics></math></td>\n<td id=\"A1.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma\" display=\"inline\"><semantics id=\"A1.T1.3.3.3.m1.1a\"><mi id=\"A1.T1.3.3.3.m1.1.1\" xref=\"A1.T1.3.3.3.m1.1.1.cmml\">Î³</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.3.3.3.m1.1b\"><ci id=\"A1.T1.3.3.3.m1.1.1.cmml\" xref=\"A1.T1.3.3.3.m1.1.1\">ğ›¾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.3.3.3.m1.1c\">\\gamma</annotation></semantics></math></td>\n<td id=\"A1.T1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"e\" display=\"inline\"><semantics id=\"A1.T1.4.4.4.m1.1a\"><mi id=\"A1.T1.4.4.4.m1.1.1\" xref=\"A1.T1.4.4.4.m1.1.1.cmml\">e</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.4.4.4.m1.1b\"><ci id=\"A1.T1.4.4.4.m1.1.1.cmml\" xref=\"A1.T1.4.4.4.m1.1.1\">ğ‘’</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.4.4.4.m1.1c\">e</annotation></semantics></math></td>\n<td id=\"A1.T1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\varepsilon\" display=\"inline\"><semantics id=\"A1.T1.5.5.5.m1.1a\"><mi id=\"A1.T1.5.5.5.m1.1.1\" xref=\"A1.T1.5.5.5.m1.1.1.cmml\">Îµ</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.5.5.5.m1.1b\"><ci id=\"A1.T1.5.5.5.m1.1.1.cmml\" xref=\"A1.T1.5.5.5.m1.1.1\">ğœ€</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.5.5.5.m1.1c\">\\varepsilon</annotation></semantics></math></td>\n<td id=\"A1.T1.7.7.9\" class=\"ltx_td ltx_align_center ltx_border_tt\">weight decay</td>\n<td id=\"A1.T1.7.7.10\" class=\"ltx_td ltx_align_center ltx_border_tt\">momentum</td>\n<td id=\"A1.T1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.6.6.6.m1.1\" class=\"ltx_Math\" alttext=\"c\" display=\"inline\"><semantics id=\"A1.T1.6.6.6.m1.1a\"><mi id=\"A1.T1.6.6.6.m1.1.1\" xref=\"A1.T1.6.6.6.m1.1.1.cmml\">c</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.6.6.6.m1.1b\"><ci id=\"A1.T1.6.6.6.m1.1.1.cmml\" xref=\"A1.T1.6.6.6.m1.1.1\">ğ‘</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.6.6.6.m1.1c\">c</annotation></semantics></math></td>\n<td id=\"A1.T1.7.7.7\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.7.7.7.m1.1\" class=\"ltx_Math\" alttext=\"B\" display=\"inline\"><semantics id=\"A1.T1.7.7.7.m1.1a\"><mi id=\"A1.T1.7.7.7.m1.1.1\" xref=\"A1.T1.7.7.7.m1.1.1.cmml\">B</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.7.7.7.m1.1b\"><ci id=\"A1.T1.7.7.7.m1.1.1.cmml\" xref=\"A1.T1.7.7.7.m1.1.1\">ğµ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.7.7.7.m1.1c\">B</annotation></semantics></math></td>\n</tr>\n<tr id=\"A1.T1.7.8\" class=\"ltx_tr\">\n<td id=\"A1.T1.7.8.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Cifar-10</td>\n<td id=\"A1.T1.7.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">300</td>\n<td id=\"A1.T1.7.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">65536</td>\n<td id=\"A1.T1.7.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.146</td>\n<td id=\"A1.T1.7.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\">5</td>\n<td id=\"A1.T1.7.8.6\" class=\"ltx_td ltx_align_center ltx_border_t\">1e-4</td>\n<td id=\"A1.T1.7.8.7\" class=\"ltx_td ltx_align_center ltx_border_t\">1e-4</td>\n<td id=\"A1.T1.7.8.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9</td>\n<td id=\"A1.T1.7.8.9\" class=\"ltx_td ltx_align_center ltx_border_t\">2.3</td>\n<td id=\"A1.T1.7.8.10\" class=\"ltx_td ltx_align_center ltx_border_t\">64</td>\n</tr>\n<tr id=\"A1.T1.7.9\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"A1.T1.7.9.1\" class=\"ltx_td ltx_align_left\"><span id=\"A1.T1.7.9.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">SVHN</span></td>\n<td id=\"A1.T1.7.9.2\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">40</span></td>\n<td id=\"A1.T1.7.9.3\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.3.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">65536</span></td>\n<td id=\"A1.T1.7.9.4\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.4.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">0.146</span></td>\n<td id=\"A1.T1.7.9.5\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.5.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">5</span></td>\n<td id=\"A1.T1.7.9.6\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.6.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">1e-4</span></td>\n<td id=\"A1.T1.7.9.7\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.7.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">1e-4</span></td>\n<td id=\"A1.T1.7.9.8\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.8.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">0.9</span></td>\n<td id=\"A1.T1.7.9.9\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.9.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">2.3</span></td>\n<td id=\"A1.T1.7.9.10\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.10.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">64</span></td>\n</tr>\n<tr id=\"A1.T1.7.10\" class=\"ltx_tr\">\n<td id=\"A1.T1.7.10.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">EMNIST</td>\n<td id=\"A1.T1.7.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">100</td>\n<td id=\"A1.T1.7.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">65536</td>\n<td id=\"A1.T1.7.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.03</td>\n<td id=\"A1.T1.7.10.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0</td>\n<td id=\"A1.T1.7.10.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">1e-4</td>\n<td id=\"A1.T1.7.10.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">1e-4</td>\n<td id=\"A1.T1.7.10.8\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.9</td>\n<td id=\"A1.T1.7.10.9\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.4375</td>\n<td id=\"A1.T1.7.10.10\" class=\"ltx_td ltx_align_center ltx_border_bb\">64</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As can be seen from the top ofÂ Tab.Â 1, increasing the number of users Kğ¾K has a marginal effect (<<1%) on the accuracy, from K=10ğ¾10K=10 to K=30ğ¾30K=30.\nOne notable thing here is that with K=30ğ¾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10ğ¾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30ğ¾30K=30 on SVHN, the final accuracy is 94.93%. One can refer toÂ Fig.Â C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000, K=100ğ¾100K=100, C=5ğ¶5C=5, and R=0ğ‘…0R=0 (which is the iid case) or R=1ğ‘…1R=1 (which is the most difficult non-iid case).\nFrom Tab.Â 3, one can see that our grouping-based solution outperforms the method proposed inÂ [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5ğ¶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatchÂ [11] inÂ Â§Â G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL)Â [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent workÂ [32] shows this may not be the case).\nFederated Averaging (FedAvg)Â [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FLÂ [16, 28, 33].\nInÂ [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is â€œrelatively ignoredâ€ and has â€œlittle prior arts,â€ as mentioned in a recent survey paperÂ [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users Kâˆˆ{47,20,10}ğ¾472010K\\in\\{47,20,10\\}. In these three settings, we let C=Kğ¶ğ¾C=K.\nThe other environmental factors are shown in rows 32-34 ofÂ Tab.Â A.2.\nWe set the group number S=5ğ‘†5S=5, S=2ğ‘†2S=2 and S=2ğ‘†2S=2 for the setting of K=47ğ¾47K=47, K=20ğ¾20K=20 and K=10ğ¾10K=10, respectively.\nSee TableÂ F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in TableÂ J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users Cğ¶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed inÂ Â§Â 4.2."
        ]
    },
    "A1.T2": {
        "caption": "",
        "table": "",
        "footnotes": "\n\n\n\n\n\nExperiment title\nRow-id\nDataset\nMethod\nRğ‘…R\nTğ‘‡T\nNssubscriptğ‘ğ‘ N_{s}\nCğ¶C\nKğ¾K\nSğ‘†S\n\n \n\n\nImpact of Rğ‘…R\n\nÂ Fig.Â 5 (left)\n \n1\nCifar10\nGrouping-based\n{0.0,0.1,â‹¯,1.0}0.00.1â‹¯1.0\\{0.0,0.1,\\cdots,1.0\\}\n16\n103superscript10310^{3}\n101010\n101010\nâˆ’-\n\n2\nSVHN\nGrouping-based\n{0.0,0.1,â‹¯,1.0}0.00.1â‹¯1.0\\{0.0,0.1,\\cdots,1.0\\}\n16\n103superscript10310^{3}\n101010\n101010\nâˆ’-\n\n3\nEMNIST\nGrouping-based\n{0.0,0.1,â‹¯,1.0}0.00.1â‹¯1.0\\{0.0,0.1,\\cdots,1.0\\}\n16\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n101010\n474747\nâˆ’-\n\n \n\n\nImpact of Tğ‘‡T\n\nÂ Fig.Â 5 (middle)\n \n4\nCifar10\nGrouping-based\n0.40.40.4\n{2,22,â‹¯,25}2superscript22â‹¯superscript25\\{2,2^{2},\\cdots,2^{5}\\}\n103superscript10310^{3}\n101010\n101010\nâˆ’-\n\n5\nSVHN\nGrouping-based\n0.40.40.4\n{2,22,â‹¯,25}2superscript22â‹¯superscript25\\{2,2^{2},\\cdots,2^{5}\\}\n103superscript10310^{3}\n101010\n101010\nâˆ’-\n\n6\nEMNIST\nGrouping-based\n0.40.40.4\n{2,22,â‹¯,25}2superscript22â‹¯superscript25\\{2,2^{2},\\cdots,2^{5}\\}\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n101010\n474747\nâˆ’-\n\n \n\n\nImpact of Nssubscriptğ‘ğ‘ N_{s}\n\nÂ Fig.Â 5 (right)\n \n7\nCifar10\nGrouping-based\n0.40.40.4\n161616\n{103,2Ã—103,â‹¯,5Ã—103}superscript1032superscript103â‹¯5superscript103\\{10^{3},2\\times 10^{3},\\cdots,5\\times 10^{3}\\}\n101010\n101010\nâˆ’-\n\n8\nSVHN\nGrouping-based\n0.40.40.4\n161616\n{103,2Ã—103,â‹¯,5Ã—103}superscript1032superscript103â‹¯5superscript103\\{10^{3},2\\times 10^{3},\\cdots,5\\times 10^{3}\\}\n101010\n101010\nâˆ’-\n\n9\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n{103,2Ã—103,â‹¯,5Ã—103}superscript1032superscript103â‹¯5superscript103\\{10^{3},2\\times 10^{3},\\cdots,5\\times 10^{3}\\}\n101010\n474747\nâˆ’-\n\n \n\n\nImpact of Cğ¶C\n\nÂ Tab.Â 1 andÂ Tab.Â 2\n \n10\nCifar10\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n101010\n101010\nâˆ’-\n\n11\nCifar10\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{10,20}1020\\{10,20\\}\n202020\nâˆ’-\n\n\n12\nCifar10\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{10,30}1030\\{10,30\\}\n303030\nâˆ’-\n\n\n13\nSVHN\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n101010\n101010\nâˆ’-\n\n\n14\nSVHN\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{10,20}1020\\{10,20\\}\n202020\nâˆ’-\n\n\n15\nSVHN\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{10,30}1030\\{10,30\\}\n303030\nâˆ’-\n\n\n16\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n{10,30,47}103047\\{10,30,47\\}\n474747\nâˆ’-\n\n \n\n\nImpact of Kğ¾K\n\nÂ Tab.Â 1\n \n17\nCifar10\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n101010\n{10,20,30}102030\\{10,20,30\\}\nâˆ’-\n\n18\nSVHN\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n101010\n{10,20,30}102030\\{10,20,30\\}\nâˆ’-\n\n \n\n\nFedAvg vs.\n\nGrouping-based\n\nÂ Tab.Â D.1\n \n19\nCifar10\nFedAvg/Grouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n101010\n101010\nâˆ’-/222\n\n20\nSVHN\nFedAvg/Grouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n202020\n202020\nâˆ’-/222\n\n21\nEMNIST\nFedAvg/Grouping-based\n0.40.40.4\n161616\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n474747\n474747\nâˆ’-/555\n\n \n\n\nComparison with\n\nsupervised\nFL\n\nÂ Tab.Â 4\n \n22\nCifar10\nSupervised FedAvg\n0.290.290.29\n323232\nâˆ’-\n101010\n101010\nâˆ’-\n\n23\nCifar10\nDataSharing\n0.290.290.29\n323232\nâˆ’-\n101010\n101010\nâˆ’-\n\n24\nCifar10\nFedAvg\n0.40.40.4\n323232\n103superscript10310^{3}\n101010\n101010\nâˆ’-\n\n25\nCifar10\nGrouping-based\n0.40.40.4\n323232\n103superscript10310^{3}\n101010\n101010\n222\n\n \n\n\nComparison with\n\nEASGD and\n\nOverlapSGD\n\nÂ Tab.Â 5\n \n26\nCifar10\nEASGD\n0.40.40.4\n{2,8}28\\{2,8\\}\nâˆ’-\n161616\n161616\nâˆ’-\n\n27\nCifar10\nOverlapSGD\n0.40.40.4\n{2,8}28\\{2,8\\}\nâˆ’-\n161616\n161616\nâˆ’-\n\n28\nCifar10\nFedAvg\n0.40.40.4\n{2,8,32}2832\\{2,8,32\\}\n103superscript10310^{3}\n161616\n161616\nâˆ’-\n\n29\nCifar10\nGrouping-based\n0.40.40.4\n{2,8,32}2832\\{2,8,32\\}\n103superscript10310^{3}\n161616\n161616\n222\n\n \n\n\nImpact of the ratio Î·ğœ‚\\eta\n\nÂ Tab.Â E.1\n \n30\nCifar10\nFedAvg/Grouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{3,6,10,30}361030\\{3,6,10,30\\}\n303030\nâˆ’-\n\n31\nSVHN\nFedAvg/Grouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{3,6,10,30}361030\\{3,6,10,30\\}\n303030\nâˆ’-\n\n \n\n\nFully supervised\n\nFLÂ Tab.Â F.1\n \n32\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n101010\n101010\n222\n\n33\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n202020\n202020\n222\n\n34\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n474747\n474747\n555\n\n \n\n\nGrouping-based vs.\n\nFixMatchÂ Tab.Â G.1\n \n35\nCifar10\nGrouping-based\n0.40.40.4\n161616\n4Ã—1034superscript1034\\times 10^{3}\n101010\n101010\n222\n\n36\nSVHN\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n202020\n202020\n222\n\n37\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n474747\n474747\n555\n\n\n38\nCifar10\nFixMatch\n0.00.00.0\n111\n4Ã—1034superscript1034\\times 10^{3}\n111\n111\nâˆ’-\n\n\n39\nSVHN\nFixMatch\n0.00.00.0\n111\n103superscript10310^{3}\n111\n111\nâˆ’-\n\n\n40\nEMNIST\nFixMatch\n0.00.00.0\n111\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n111\n111\nâˆ’-\n\n \n\n\nUsers have labeled samplesÂ Tab.Â H.1\n \n41\nEMNIST\nFedAvg\n{0.4,0.6}0.40.6\\{0.4,0.6\\}\n161616\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n474747\n474747\nâˆ’-\n\n \n\n\nPerformance on STL-10\n\nÂ Tab.Â I.1\n \n42\nSTL-10\nSelf-training\n0.00.00.0\n161616\n103superscript10310^{3}\n222\n101010\nâˆ’-\n\n43\nSTL-10\nCRL with BN\n0.00.00.0\n161616\n103superscript10310^{3}\n222\n101010\nâˆ’-\n\n44\nSTL-10\nFedAvg\n0.00.00.0\n161616\n103superscript10310^{3}\n222\n101010\nâˆ’-\n\n45\nSTL-10\nGrouping-based\n0.00.00.0\n161616\n103superscript10310^{3}\n222\n101010\n222\n\n \n\n\nPerformance on EMNIST with\n\nlarge user numberÂ Tab.Â J.1\n \n46\nEMNIST\nFedAvg/Grouping-based\n0.40.40.4\n161616\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n101010\n474747\nâˆ’-/222\n\n47\nEMNIST\nFedAvg/Grouping-based\n0.40.40.4\n161616\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n202020\n474747\nâˆ’-/222\n\n48\nEMNIST\nFedAvg/Grouping-based\n0.40.40.4\n161616\n4.7Ã—1034.7superscript1034.7\\times 10^{3}\n303030\n474747\nâˆ’-/222\n\n \n\n\nComparison withÂ [9] on\n\nCifar10 Tab. 3\n \n49\nCifar10\nFedMatch\n{0,1}01\\{0,1\\}\n100100100\n5Ã—1035superscript1035\\times 10^{3}\n555\n100100100\nâˆ’-\n\n50\nCifar10\nGrouping-based\n{0,1}01\\{0,1\\}\n100100100\n5Ã—1035superscript1035\\times 10^{3}\n555\n100100100\n222\n\n",
        "references": [
            "As can be seen from the top ofÂ Tab.Â 1, increasing the number of users Kğ¾K has a marginal effect (<<1%) on the accuracy, from K=10ğ¾10K=10 to K=30ğ¾30K=30.\nOne notable thing here is that with K=30ğ¾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10ğ¾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30ğ¾30K=30 on SVHN, the final accuracy is 94.93%. One can refer toÂ Fig.Â C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000, K=100ğ¾100K=100, C=5ğ¶5C=5, and R=0ğ‘…0R=0 (which is the iid case) or R=1ğ‘…1R=1 (which is the most difficult non-iid case).\nFrom Tab.Â 3, one can see that our grouping-based solution outperforms the method proposed inÂ [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5ğ¶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatchÂ [11] inÂ Â§Â G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL)Â [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent workÂ [32] shows this may not be the case).\nFederated Averaging (FedAvg)Â [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FLÂ [16, 28, 33].\nInÂ [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is â€œrelatively ignoredâ€ and has â€œlittle prior arts,â€ as mentioned in a recent survey paperÂ [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users Kâˆˆ{47,20,10}ğ¾472010K\\in\\{47,20,10\\}. In these three settings, we let C=Kğ¶ğ¾C=K.\nThe other environmental factors are shown in rows 32-34 ofÂ Tab.Â A.2.\nWe set the group number S=5ğ‘†5S=5, S=2ğ‘†2S=2 and S=2ğ‘†2S=2 for the setting of K=47ğ¾47K=47, K=20ğ¾20K=20 and K=10ğ¾10K=10, respectively.\nSee TableÂ F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in TableÂ J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users Cğ¶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed inÂ Â§Â 4.2."
        ]
    },
    "A5.T1": {
        "caption": "Table E.1: Test accuracy versus the ratio of communicating users Î·=C/Kğœ‚ğ¶ğ¾\\eta=C/K on Cifar-10 and SVHN",
        "table": "<table id=\"A5.T1.22\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A5.T1.14.12\" class=\"ltx_tr\">\n<td id=\"A5.T1.14.12.13\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A5.T1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<table id=\"A5.T1.5.3.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A5.T1.3.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"A5.T1.3.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"A5.T1.3.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\eta=1/10\" display=\"inline\"><semantics id=\"A5.T1.3.1.1.1.1.1.m1.1a\"><mrow id=\"A5.T1.3.1.1.1.1.1.m1.1.1\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"A5.T1.3.1.1.1.1.1.m1.1.1.2\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.2.cmml\">Î·</mi><mo id=\"A5.T1.3.1.1.1.1.1.m1.1.1.1\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.1.cmml\">=</mo><mrow id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.cmml\"><mn id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.2\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.2.cmml\">1</mn><mo id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.1\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.1.cmml\">/</mo><mn id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.3\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.3.cmml\">10</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.3.1.1.1.1.1.m1.1b\"><apply id=\"A5.T1.3.1.1.1.1.1.m1.1.1.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1\"><eq id=\"A5.T1.3.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.1\"></eq><ci id=\"A5.T1.3.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.2\">ğœ‚</ci><apply id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3\"><divide id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.1.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.1\"></divide><cn type=\"integer\" id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.2.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.2\">1</cn><cn type=\"integer\" id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.3.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.3\">10</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.3.1.1.1.1.1.m1.1c\">\\eta=1/10</annotation></semantics></math></td>\n</tr>\n<tr id=\"A5.T1.5.3.3.3.3\" class=\"ltx_tr\">\n<td id=\"A5.T1.5.3.3.3.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(<math id=\"A5.T1.4.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K=30\" display=\"inline\"><semantics id=\"A5.T1.4.2.2.2.2.1.m1.1a\"><mrow id=\"A5.T1.4.2.2.2.2.1.m1.1.1\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.cmml\"><mi id=\"A5.T1.4.2.2.2.2.1.m1.1.1.2\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.2.cmml\">K</mi><mo id=\"A5.T1.4.2.2.2.2.1.m1.1.1.1\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.1.cmml\">=</mo><mn id=\"A5.T1.4.2.2.2.2.1.m1.1.1.3\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.3.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.4.2.2.2.2.1.m1.1b\"><apply id=\"A5.T1.4.2.2.2.2.1.m1.1.1.cmml\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1\"><eq id=\"A5.T1.4.2.2.2.2.1.m1.1.1.1.cmml\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.1\"></eq><ci id=\"A5.T1.4.2.2.2.2.1.m1.1.1.2.cmml\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.2\">ğ¾</ci><cn type=\"integer\" id=\"A5.T1.4.2.2.2.2.1.m1.1.1.3.cmml\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.3\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.4.2.2.2.2.1.m1.1c\">K=30</annotation></semantics></math>, <math id=\"A5.T1.5.3.3.3.3.2.m2.1\" class=\"ltx_Math\" alttext=\"C=3\" display=\"inline\"><semantics id=\"A5.T1.5.3.3.3.3.2.m2.1a\"><mrow id=\"A5.T1.5.3.3.3.3.2.m2.1.1\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.cmml\"><mi id=\"A5.T1.5.3.3.3.3.2.m2.1.1.2\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.2.cmml\">C</mi><mo id=\"A5.T1.5.3.3.3.3.2.m2.1.1.1\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.1.cmml\">=</mo><mn id=\"A5.T1.5.3.3.3.3.2.m2.1.1.3\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.3.cmml\">3</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.5.3.3.3.3.2.m2.1b\"><apply id=\"A5.T1.5.3.3.3.3.2.m2.1.1.cmml\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1\"><eq id=\"A5.T1.5.3.3.3.3.2.m2.1.1.1.cmml\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.1\"></eq><ci id=\"A5.T1.5.3.3.3.3.2.m2.1.1.2.cmml\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.2\">ğ¶</ci><cn type=\"integer\" id=\"A5.T1.5.3.3.3.3.2.m2.1.1.3.cmml\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.3\">3</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.5.3.3.3.3.2.m2.1c\">C=3</annotation></semantics></math>)</td>\n</tr>\n</table>\n</td>\n<td id=\"A5.T1.8.6.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<table id=\"A5.T1.8.6.6.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A5.T1.6.4.4.1.1\" class=\"ltx_tr\">\n<td id=\"A5.T1.6.4.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"A5.T1.6.4.4.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\eta=1/5\" display=\"inline\"><semantics id=\"A5.T1.6.4.4.1.1.1.m1.1a\"><mrow id=\"A5.T1.6.4.4.1.1.1.m1.1.1\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.cmml\"><mi id=\"A5.T1.6.4.4.1.1.1.m1.1.1.2\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.2.cmml\">Î·</mi><mo id=\"A5.T1.6.4.4.1.1.1.m1.1.1.1\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.1.cmml\">=</mo><mrow id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.cmml\"><mn id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.2\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.2.cmml\">1</mn><mo id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.1\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.1.cmml\">/</mo><mn id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.3\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.3.cmml\">5</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.6.4.4.1.1.1.m1.1b\"><apply id=\"A5.T1.6.4.4.1.1.1.m1.1.1.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1\"><eq id=\"A5.T1.6.4.4.1.1.1.m1.1.1.1.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.1\"></eq><ci id=\"A5.T1.6.4.4.1.1.1.m1.1.1.2.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.2\">ğœ‚</ci><apply id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3\"><divide id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.1.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.1\"></divide><cn type=\"integer\" id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.2.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.2\">1</cn><cn type=\"integer\" id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.3.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.3\">5</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.6.4.4.1.1.1.m1.1c\">\\eta=1/5</annotation></semantics></math></td>\n</tr>\n<tr id=\"A5.T1.8.6.6.3.3\" class=\"ltx_tr\">\n<td id=\"A5.T1.8.6.6.3.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(<math id=\"A5.T1.7.5.5.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K=30\" display=\"inline\"><semantics id=\"A5.T1.7.5.5.2.2.1.m1.1a\"><mrow id=\"A5.T1.7.5.5.2.2.1.m1.1.1\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.cmml\"><mi id=\"A5.T1.7.5.5.2.2.1.m1.1.1.2\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.2.cmml\">K</mi><mo id=\"A5.T1.7.5.5.2.2.1.m1.1.1.1\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.1.cmml\">=</mo><mn id=\"A5.T1.7.5.5.2.2.1.m1.1.1.3\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.3.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.7.5.5.2.2.1.m1.1b\"><apply id=\"A5.T1.7.5.5.2.2.1.m1.1.1.cmml\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1\"><eq id=\"A5.T1.7.5.5.2.2.1.m1.1.1.1.cmml\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.1\"></eq><ci id=\"A5.T1.7.5.5.2.2.1.m1.1.1.2.cmml\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.2\">ğ¾</ci><cn type=\"integer\" id=\"A5.T1.7.5.5.2.2.1.m1.1.1.3.cmml\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.3\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.7.5.5.2.2.1.m1.1c\">K=30</annotation></semantics></math>, <math id=\"A5.T1.8.6.6.3.3.2.m2.1\" class=\"ltx_Math\" alttext=\"C=6\" display=\"inline\"><semantics id=\"A5.T1.8.6.6.3.3.2.m2.1a\"><mrow id=\"A5.T1.8.6.6.3.3.2.m2.1.1\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.cmml\"><mi id=\"A5.T1.8.6.6.3.3.2.m2.1.1.2\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.2.cmml\">C</mi><mo id=\"A5.T1.8.6.6.3.3.2.m2.1.1.1\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.1.cmml\">=</mo><mn id=\"A5.T1.8.6.6.3.3.2.m2.1.1.3\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.3.cmml\">6</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.8.6.6.3.3.2.m2.1b\"><apply id=\"A5.T1.8.6.6.3.3.2.m2.1.1.cmml\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1\"><eq id=\"A5.T1.8.6.6.3.3.2.m2.1.1.1.cmml\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.1\"></eq><ci id=\"A5.T1.8.6.6.3.3.2.m2.1.1.2.cmml\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.2\">ğ¶</ci><cn type=\"integer\" id=\"A5.T1.8.6.6.3.3.2.m2.1.1.3.cmml\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.3\">6</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.8.6.6.3.3.2.m2.1c\">C=6</annotation></semantics></math>)</td>\n</tr>\n</table>\n</td>\n<td id=\"A5.T1.11.9.9\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<table id=\"A5.T1.11.9.9.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A5.T1.9.7.7.1.1\" class=\"ltx_tr\">\n<td id=\"A5.T1.9.7.7.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"A5.T1.9.7.7.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\eta=1/3\" display=\"inline\"><semantics id=\"A5.T1.9.7.7.1.1.1.m1.1a\"><mrow id=\"A5.T1.9.7.7.1.1.1.m1.1.1\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.cmml\"><mi id=\"A5.T1.9.7.7.1.1.1.m1.1.1.2\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.2.cmml\">Î·</mi><mo id=\"A5.T1.9.7.7.1.1.1.m1.1.1.1\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.1.cmml\">=</mo><mrow id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.cmml\"><mn id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.2\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.2.cmml\">1</mn><mo id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.1\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.1.cmml\">/</mo><mn id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.3\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.3.cmml\">3</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.9.7.7.1.1.1.m1.1b\"><apply id=\"A5.T1.9.7.7.1.1.1.m1.1.1.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1\"><eq id=\"A5.T1.9.7.7.1.1.1.m1.1.1.1.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.1\"></eq><ci id=\"A5.T1.9.7.7.1.1.1.m1.1.1.2.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.2\">ğœ‚</ci><apply id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3\"><divide id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.1.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.1\"></divide><cn type=\"integer\" id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.2.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.2\">1</cn><cn type=\"integer\" id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.3.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.3\">3</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.9.7.7.1.1.1.m1.1c\">\\eta=1/3</annotation></semantics></math></td>\n</tr>\n<tr id=\"A5.T1.11.9.9.3.3\" class=\"ltx_tr\">\n<td id=\"A5.T1.11.9.9.3.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(<math id=\"A5.T1.10.8.8.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K=30\" display=\"inline\"><semantics id=\"A5.T1.10.8.8.2.2.1.m1.1a\"><mrow id=\"A5.T1.10.8.8.2.2.1.m1.1.1\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.cmml\"><mi id=\"A5.T1.10.8.8.2.2.1.m1.1.1.2\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.2.cmml\">K</mi><mo id=\"A5.T1.10.8.8.2.2.1.m1.1.1.1\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.1.cmml\">=</mo><mn id=\"A5.T1.10.8.8.2.2.1.m1.1.1.3\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.3.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.10.8.8.2.2.1.m1.1b\"><apply id=\"A5.T1.10.8.8.2.2.1.m1.1.1.cmml\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1\"><eq id=\"A5.T1.10.8.8.2.2.1.m1.1.1.1.cmml\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.1\"></eq><ci id=\"A5.T1.10.8.8.2.2.1.m1.1.1.2.cmml\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.2\">ğ¾</ci><cn type=\"integer\" id=\"A5.T1.10.8.8.2.2.1.m1.1.1.3.cmml\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.3\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.10.8.8.2.2.1.m1.1c\">K=30</annotation></semantics></math>, <math id=\"A5.T1.11.9.9.3.3.2.m2.1\" class=\"ltx_Math\" alttext=\"C=10\" display=\"inline\"><semantics id=\"A5.T1.11.9.9.3.3.2.m2.1a\"><mrow id=\"A5.T1.11.9.9.3.3.2.m2.1.1\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.cmml\"><mi id=\"A5.T1.11.9.9.3.3.2.m2.1.1.2\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.2.cmml\">C</mi><mo id=\"A5.T1.11.9.9.3.3.2.m2.1.1.1\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.1.cmml\">=</mo><mn id=\"A5.T1.11.9.9.3.3.2.m2.1.1.3\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.3.cmml\">10</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.11.9.9.3.3.2.m2.1b\"><apply id=\"A5.T1.11.9.9.3.3.2.m2.1.1.cmml\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1\"><eq id=\"A5.T1.11.9.9.3.3.2.m2.1.1.1.cmml\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.1\"></eq><ci id=\"A5.T1.11.9.9.3.3.2.m2.1.1.2.cmml\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.2\">ğ¶</ci><cn type=\"integer\" id=\"A5.T1.11.9.9.3.3.2.m2.1.1.3.cmml\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.3\">10</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.11.9.9.3.3.2.m2.1c\">C=10</annotation></semantics></math>)</td>\n</tr>\n</table>\n</td>\n<td id=\"A5.T1.14.12.12\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<table id=\"A5.T1.14.12.12.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A5.T1.12.10.10.1.1\" class=\"ltx_tr\">\n<td id=\"A5.T1.12.10.10.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"A5.T1.12.10.10.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\eta=1\" display=\"inline\"><semantics id=\"A5.T1.12.10.10.1.1.1.m1.1a\"><mrow id=\"A5.T1.12.10.10.1.1.1.m1.1.1\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.cmml\"><mi id=\"A5.T1.12.10.10.1.1.1.m1.1.1.2\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.2.cmml\">Î·</mi><mo id=\"A5.T1.12.10.10.1.1.1.m1.1.1.1\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"A5.T1.12.10.10.1.1.1.m1.1.1.3\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.3.cmml\">1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.12.10.10.1.1.1.m1.1b\"><apply id=\"A5.T1.12.10.10.1.1.1.m1.1.1.cmml\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1\"><eq id=\"A5.T1.12.10.10.1.1.1.m1.1.1.1.cmml\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.1\"></eq><ci id=\"A5.T1.12.10.10.1.1.1.m1.1.1.2.cmml\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.2\">ğœ‚</ci><cn type=\"integer\" id=\"A5.T1.12.10.10.1.1.1.m1.1.1.3.cmml\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.12.10.10.1.1.1.m1.1c\">\\eta=1</annotation></semantics></math></td>\n</tr>\n<tr id=\"A5.T1.14.12.12.3.3\" class=\"ltx_tr\">\n<td id=\"A5.T1.14.12.12.3.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(<math id=\"A5.T1.13.11.11.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K=30\" display=\"inline\"><semantics id=\"A5.T1.13.11.11.2.2.1.m1.1a\"><mrow id=\"A5.T1.13.11.11.2.2.1.m1.1.1\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.cmml\"><mi id=\"A5.T1.13.11.11.2.2.1.m1.1.1.2\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.2.cmml\">K</mi><mo id=\"A5.T1.13.11.11.2.2.1.m1.1.1.1\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.1.cmml\">=</mo><mn id=\"A5.T1.13.11.11.2.2.1.m1.1.1.3\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.3.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.13.11.11.2.2.1.m1.1b\"><apply id=\"A5.T1.13.11.11.2.2.1.m1.1.1.cmml\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1\"><eq id=\"A5.T1.13.11.11.2.2.1.m1.1.1.1.cmml\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.1\"></eq><ci id=\"A5.T1.13.11.11.2.2.1.m1.1.1.2.cmml\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.2\">ğ¾</ci><cn type=\"integer\" id=\"A5.T1.13.11.11.2.2.1.m1.1.1.3.cmml\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.3\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.13.11.11.2.2.1.m1.1c\">K=30</annotation></semantics></math>, <math id=\"A5.T1.14.12.12.3.3.2.m2.1\" class=\"ltx_Math\" alttext=\"C=30\" display=\"inline\"><semantics id=\"A5.T1.14.12.12.3.3.2.m2.1a\"><mrow id=\"A5.T1.14.12.12.3.3.2.m2.1.1\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.cmml\"><mi id=\"A5.T1.14.12.12.3.3.2.m2.1.1.2\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.2.cmml\">C</mi><mo id=\"A5.T1.14.12.12.3.3.2.m2.1.1.1\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.1.cmml\">=</mo><mn id=\"A5.T1.14.12.12.3.3.2.m2.1.1.3\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.3.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.14.12.12.3.3.2.m2.1b\"><apply id=\"A5.T1.14.12.12.3.3.2.m2.1.1.cmml\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1\"><eq id=\"A5.T1.14.12.12.3.3.2.m2.1.1.1.cmml\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.1\"></eq><ci id=\"A5.T1.14.12.12.3.3.2.m2.1.1.2.cmml\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.2\">ğ¶</ci><cn type=\"integer\" id=\"A5.T1.14.12.12.3.3.2.m2.1.1.3.cmml\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.3\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.14.12.12.3.3.2.m2.1c\">C=30</annotation></semantics></math>)</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"A5.T1.18.16\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"A5.T1.18.16.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A5.T1.18.16.5.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">Cifar-10 (Grouping-based)</span></td>\n<td id=\"A5.T1.15.13.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A5.T1.15.13.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">82.48<math id=\"A5.T1.15.13.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.15.13.1.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A5.T1.15.13.1.1.m1.1.1\" xref=\"A5.T1.15.13.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.15.13.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.15.13.1.1.m1.1.1.cmml\" xref=\"A5.T1.15.13.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.15.13.1.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A5.T1.16.14.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A5.T1.16.14.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">92.08<math id=\"A5.T1.16.14.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.16.14.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A5.T1.16.14.2.1.m1.1.1\" xref=\"A5.T1.16.14.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.16.14.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.16.14.2.1.m1.1.1.cmml\" xref=\"A5.T1.16.14.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.16.14.2.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A5.T1.17.15.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A5.T1.17.15.3.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">92.84<math id=\"A5.T1.17.15.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.17.15.3.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A5.T1.17.15.3.1.m1.1.1\" xref=\"A5.T1.17.15.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.17.15.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.17.15.3.1.m1.1.1.cmml\" xref=\"A5.T1.17.15.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.17.15.3.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A5.T1.18.16.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A5.T1.18.16.4.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">92.12<math id=\"A5.T1.18.16.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.18.16.4.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A5.T1.18.16.4.1.m1.1.1\" xref=\"A5.T1.18.16.4.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.18.16.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.18.16.4.1.m1.1.1.cmml\" xref=\"A5.T1.18.16.4.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.18.16.4.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"A5.T1.22.20\" class=\"ltx_tr\">\n<td id=\"A5.T1.22.20.5\" class=\"ltx_td ltx_align_left ltx_border_bb\">SVHN (Grouping-based)</td>\n<td id=\"A5.T1.19.17.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">92.83<math id=\"A5.T1.19.17.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.19.17.1.m1.1a\"><mo id=\"A5.T1.19.17.1.m1.1.1\" xref=\"A5.T1.19.17.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.19.17.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.19.17.1.m1.1.1.cmml\" xref=\"A5.T1.19.17.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.19.17.1.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A5.T1.20.18.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">93.42<math id=\"A5.T1.20.18.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.20.18.2.m1.1a\"><mo id=\"A5.T1.20.18.2.m1.1.1\" xref=\"A5.T1.20.18.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.20.18.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.20.18.2.m1.1.1.cmml\" xref=\"A5.T1.20.18.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.20.18.2.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A5.T1.21.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">93.56<math id=\"A5.T1.21.19.3.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.21.19.3.m1.1a\"><mo id=\"A5.T1.21.19.3.m1.1.1\" xref=\"A5.T1.21.19.3.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.21.19.3.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.21.19.3.m1.1.1.cmml\" xref=\"A5.T1.21.19.3.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.21.19.3.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A5.T1.22.20.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">78.77<math id=\"A5.T1.22.20.4.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.22.20.4.m1.1a\"><mo id=\"A5.T1.22.20.4.m1.1.1\" xref=\"A5.T1.22.20.4.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.22.20.4.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.22.20.4.m1.1.1.cmml\" xref=\"A5.T1.22.20.4.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.22.20.4.m1.1c\">\\%</annotation></semantics></math>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As can be seen from the top ofÂ Tab.Â 1, increasing the number of users Kğ¾K has a marginal effect (<<1%) on the accuracy, from K=10ğ¾10K=10 to K=30ğ¾30K=30.\nOne notable thing here is that with K=30ğ¾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10ğ¾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30ğ¾30K=30 on SVHN, the final accuracy is 94.93%. One can refer toÂ Fig.Â C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000, K=100ğ¾100K=100, C=5ğ¶5C=5, and R=0ğ‘…0R=0 (which is the iid case) or R=1ğ‘…1R=1 (which is the most difficult non-iid case).\nFrom Tab.Â 3, one can see that our grouping-based solution outperforms the method proposed inÂ [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5ğ¶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatchÂ [11] inÂ Â§Â G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL)Â [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent workÂ [32] shows this may not be the case).\nFederated Averaging (FedAvg)Â [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FLÂ [16, 28, 33].\nInÂ [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is â€œrelatively ignoredâ€ and has â€œlittle prior arts,â€ as mentioned in a recent survey paperÂ [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users Kâˆˆ{47,20,10}ğ¾472010K\\in\\{47,20,10\\}. In these three settings, we let C=Kğ¶ğ¾C=K.\nThe other environmental factors are shown in rows 32-34 ofÂ Tab.Â A.2.\nWe set the group number S=5ğ‘†5S=5, S=2ğ‘†2S=2 and S=2ğ‘†2S=2 for the setting of K=47ğ¾47K=47, K=20ğ¾20K=20 and K=10ğ¾10K=10, respectively.\nSee TableÂ F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in TableÂ J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users Cğ¶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed inÂ Â§Â 4.2."
        ]
    },
    "A6.T1": {
        "caption": "Table F.1: The accuracy comparison of FedAvg and the grouping-based average for supervised FL on EMNSIT.\n",
        "table": "<div id=\"A6.T1.9\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:284.0pt;height:73.9pt;vertical-align:-1.9pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<p id=\"A6.T1.9.9\" class=\"ltx_p\"><span id=\"A6.T1.9.9.9\" class=\"ltx_text\">\n<span id=\"A6.T1.9.9.9.9\" class=\"ltx_tabular ltx_align_top\">\n<span id=\"A6.T1.9.9.9.9.10\" class=\"ltx_tr\">\n<span id=\"A6.T1.9.9.9.9.10.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">User number</span>\n<span id=\"A6.T1.9.9.9.9.10.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</span>\n<span id=\"A6.T1.9.9.9.9.10.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Grouping-based</span>\n<span id=\"A6.T1.9.9.9.9.10.4\" class=\"ltx_td ltx_border_tt\"></span></span>\n<span id=\"A6.T1.3.3.3.3.3\" class=\"ltx_tr\">\n<span id=\"A6.T1.1.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><math id=\"A6.T1.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"K=47\" display=\"inline\"><semantics id=\"A6.T1.1.1.1.1.1.1.m1.1a\"><mrow id=\"A6.T1.1.1.1.1.1.1.m1.1.1\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T1.1.1.1.1.1.1.m1.1.1.2\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.2.cmml\">K</mi><mo id=\"A6.T1.1.1.1.1.1.1.m1.1.1.1\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"A6.T1.1.1.1.1.1.1.m1.1.1.3\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.3.cmml\">47</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.1.1.1.1.1.1.m1.1b\"><apply id=\"A6.T1.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1\"><eq id=\"A6.T1.1.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.1\"></eq><ci id=\"A6.T1.1.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.2\">ğ¾</ci><cn type=\"integer\" id=\"A6.T1.1.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.3\">47</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.1.1.1.1.1.1.m1.1c\">K=47</annotation></semantics></math></span>\n<span id=\"A6.T1.2.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">84.71<math id=\"A6.T1.2.2.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.2.2.2.2.2.2.m1.1a\"><mo id=\"A6.T1.2.2.2.2.2.2.m1.1.1\" xref=\"A6.T1.2.2.2.2.2.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.2.2.2.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.2.2.2.2.2.2.m1.1.1.cmml\" xref=\"A6.T1.2.2.2.2.2.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.2.2.2.2.2.2.m1.1c\">\\%</annotation></semantics></math></span>\n<span id=\"A6.T1.3.3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T1.3.3.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">84.97<math id=\"A6.T1.3.3.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.3.3.3.3.3.3.1.m1.1a\"><mo id=\"A6.T1.3.3.3.3.3.3.1.m1.1.1\" xref=\"A6.T1.3.3.3.3.3.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.3.3.3.3.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.3.3.3.3.3.3.1.m1.1.1.cmml\" xref=\"A6.T1.3.3.3.3.3.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.3.3.3.3.3.3.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"A6.T1.3.3.3.3.3.4\" class=\"ltx_td ltx_border_t\"></span></span>\n<span id=\"A6.T1.6.6.6.6.6\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<span id=\"A6.T1.4.4.4.4.4.1\" class=\"ltx_td ltx_align_left\"><math id=\"A6.T1.4.4.4.4.4.1.m1.1\" class=\"ltx_Math\" style=\"background-color:#FFCC99;\" alttext=\"K=20\" display=\"inline\"><semantics id=\"A6.T1.4.4.4.4.4.1.m1.1a\"><mrow id=\"A6.T1.4.4.4.4.4.1.m1.1.1\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.cmml\"><mi mathbackground=\"#FFCC99\" id=\"A6.T1.4.4.4.4.4.1.m1.1.1.2\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.2.cmml\">K</mi><mo mathbackground=\"#FFCC99\" id=\"A6.T1.4.4.4.4.4.1.m1.1.1.1\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.1.cmml\">=</mo><mn mathbackground=\"#FFCC99\" id=\"A6.T1.4.4.4.4.4.1.m1.1.1.3\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.3.cmml\">20</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.4.4.4.4.4.1.m1.1b\"><apply id=\"A6.T1.4.4.4.4.4.1.m1.1.1.cmml\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1\"><eq id=\"A6.T1.4.4.4.4.4.1.m1.1.1.1.cmml\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.1\"></eq><ci id=\"A6.T1.4.4.4.4.4.1.m1.1.1.2.cmml\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.2\">ğ¾</ci><cn type=\"integer\" id=\"A6.T1.4.4.4.4.4.1.m1.1.1.3.cmml\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.3\">20</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.4.4.4.4.4.1.m1.1c\">K=20</annotation></semantics></math></span>\n<span id=\"A6.T1.5.5.5.5.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T1.5.5.5.5.5.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">86.14<math id=\"A6.T1.5.5.5.5.5.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.5.5.5.5.5.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A6.T1.5.5.5.5.5.2.1.m1.1.1\" xref=\"A6.T1.5.5.5.5.5.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.5.5.5.5.5.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.5.5.5.5.5.2.1.m1.1.1.cmml\" xref=\"A6.T1.5.5.5.5.5.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.5.5.5.5.5.2.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"A6.T1.6.6.6.6.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T1.6.6.6.6.6.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#FFCC99;\">86.27<math id=\"A6.T1.6.6.6.6.6.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.6.6.6.6.6.3.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A6.T1.6.6.6.6.6.3.1.m1.1.1\" xref=\"A6.T1.6.6.6.6.6.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.6.6.6.6.6.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.6.6.6.6.6.3.1.m1.1.1.cmml\" xref=\"A6.T1.6.6.6.6.6.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.6.6.6.6.6.3.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"A6.T1.6.6.6.6.6.4\" class=\"ltx_td\"></span></span>\n<span id=\"A6.T1.9.9.9.9.9\" class=\"ltx_tr\">\n<span id=\"A6.T1.7.7.7.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb\"><math id=\"A6.T1.7.7.7.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"K=10\" display=\"inline\"><semantics id=\"A6.T1.7.7.7.7.7.1.m1.1a\"><mrow id=\"A6.T1.7.7.7.7.7.1.m1.1.1\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.cmml\"><mi id=\"A6.T1.7.7.7.7.7.1.m1.1.1.2\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.2.cmml\">K</mi><mo id=\"A6.T1.7.7.7.7.7.1.m1.1.1.1\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.1.cmml\">=</mo><mn id=\"A6.T1.7.7.7.7.7.1.m1.1.1.3\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.3.cmml\">10</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.7.7.7.7.7.1.m1.1b\"><apply id=\"A6.T1.7.7.7.7.7.1.m1.1.1.cmml\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1\"><eq id=\"A6.T1.7.7.7.7.7.1.m1.1.1.1.cmml\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.1\"></eq><ci id=\"A6.T1.7.7.7.7.7.1.m1.1.1.2.cmml\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.2\">ğ¾</ci><cn type=\"integer\" id=\"A6.T1.7.7.7.7.7.1.m1.1.1.3.cmml\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.3\">10</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.7.7.7.7.7.1.m1.1c\">K=10</annotation></semantics></math></span>\n<span id=\"A6.T1.8.8.8.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">86.19<math id=\"A6.T1.8.8.8.8.8.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.8.8.8.8.8.2.m1.1a\"><mo id=\"A6.T1.8.8.8.8.8.2.m1.1.1\" xref=\"A6.T1.8.8.8.8.8.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.8.8.8.8.8.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.8.8.8.8.8.2.m1.1.1.cmml\" xref=\"A6.T1.8.8.8.8.8.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.8.8.8.8.8.2.m1.1c\">\\%</annotation></semantics></math></span>\n<span id=\"A6.T1.9.9.9.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T1.9.9.9.9.9.3.1\" class=\"ltx_text ltx_font_bold\">86.29<math id=\"A6.T1.9.9.9.9.9.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.9.9.9.9.9.3.1.m1.1a\"><mo id=\"A6.T1.9.9.9.9.9.3.1.m1.1.1\" xref=\"A6.T1.9.9.9.9.9.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.9.9.9.9.9.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.9.9.9.9.9.3.1.m1.1.1.cmml\" xref=\"A6.T1.9.9.9.9.9.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.9.9.9.9.9.3.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"A6.T1.9.9.9.9.9.4\" class=\"ltx_td ltx_border_bb\"></span></span>\n</span></span></p>\n</span></div>\n\n",
        "footnotes": "\n\n\nUser number\nFedAvg\nGrouping-based\n\n\nK=47ğ¾47K=47\n84.71%percent\\%\n84.97%percent\\%\n\n\nK=20ğ¾20K=20\n86.14%percent\\%\n86.27%percent\\%\n\n\nK=10ğ¾10K=10\n86.19%percent\\%\n86.29%percent\\%\n\n",
        "references": [
            "As can be seen from the top ofÂ Tab.Â 1, increasing the number of users Kğ¾K has a marginal effect (<<1%) on the accuracy, from K=10ğ¾10K=10 to K=30ğ¾30K=30.\nOne notable thing here is that with K=30ğ¾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10ğ¾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30ğ¾30K=30 on SVHN, the final accuracy is 94.93%. One can refer toÂ Fig.Â C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000, K=100ğ¾100K=100, C=5ğ¶5C=5, and R=0ğ‘…0R=0 (which is the iid case) or R=1ğ‘…1R=1 (which is the most difficult non-iid case).\nFrom Tab.Â 3, one can see that our grouping-based solution outperforms the method proposed inÂ [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5ğ¶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatchÂ [11] inÂ Â§Â G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL)Â [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent workÂ [32] shows this may not be the case).\nFederated Averaging (FedAvg)Â [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FLÂ [16, 28, 33].\nInÂ [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is â€œrelatively ignoredâ€ and has â€œlittle prior arts,â€ as mentioned in a recent survey paperÂ [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users Kâˆˆ{47,20,10}ğ¾472010K\\in\\{47,20,10\\}. In these three settings, we let C=Kğ¶ğ¾C=K.\nThe other environmental factors are shown in rows 32-34 ofÂ Tab.Â A.2.\nWe set the group number S=5ğ‘†5S=5, S=2ğ‘†2S=2 and S=2ğ‘†2S=2 for the setting of K=47ğ¾47K=47, K=20ğ¾20K=20 and K=10ğ¾10K=10, respectively.\nSee TableÂ F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in TableÂ J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users Cğ¶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed inÂ Â§Â 4.2."
        ]
    },
    "A7.T1": {
        "caption": "Table G.1: Comparison with FixMatch.\n",
        "table": "<table id=\"A7.T1.6\" class=\"ltx_tabular ltx_centering ltx_align_top\">\n<tr id=\"A7.T1.6.7\" class=\"ltx_tr\">\n<td id=\"A7.T1.6.7.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">Dataset</td>\n<td id=\"A7.T1.6.7.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FixMatch</td>\n<td id=\"A7.T1.6.7.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Grouping-based</td>\n<td id=\"A7.T1.6.7.4\" class=\"ltx_td ltx_border_tt\"></td>\n</tr>\n<tr id=\"A7.T1.2.2\" class=\"ltx_tr\">\n<td id=\"A7.T1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Cifar10</td>\n<td id=\"A7.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">95.74<math id=\"A7.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.1.1.1.m1.1a\"><mo id=\"A7.T1.1.1.1.m1.1.1\" xref=\"A7.T1.1.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.1.1.1.m1.1.1.cmml\" xref=\"A7.T1.1.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.1.1.1.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A7.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">92.86<math id=\"A7.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.2.2.2.m1.1a\"><mo id=\"A7.T1.2.2.2.m1.1.1\" xref=\"A7.T1.2.2.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.2.2.2.m1.1.1.cmml\" xref=\"A7.T1.2.2.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.2.2.2.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A7.T1.2.2.4\" class=\"ltx_td ltx_border_t\"></td>\n</tr>\n<tr id=\"A7.T1.4.4\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"A7.T1.4.4.3\" class=\"ltx_td ltx_align_left\"><span id=\"A7.T1.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">SVHN</span></td>\n<td id=\"A7.T1.3.3.1\" class=\"ltx_td ltx_align_center\"><span id=\"A7.T1.3.3.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">97.72<math id=\"A7.T1.3.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.3.3.1.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A7.T1.3.3.1.1.m1.1.1\" xref=\"A7.T1.3.3.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.3.3.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.3.3.1.1.m1.1.1.cmml\" xref=\"A7.T1.3.3.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.3.3.1.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A7.T1.4.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"A7.T1.4.4.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">95.49<math id=\"A7.T1.4.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.4.4.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A7.T1.4.4.2.1.m1.1.1\" xref=\"A7.T1.4.4.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.4.4.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.4.4.2.1.m1.1.1.cmml\" xref=\"A7.T1.4.4.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.4.4.2.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A7.T1.4.4.4\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"A7.T1.6.6\" class=\"ltx_tr\">\n<td id=\"A7.T1.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">EMNSIT</td>\n<td id=\"A7.T1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">83.70<math id=\"A7.T1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.5.5.1.m1.1a\"><mo id=\"A7.T1.5.5.1.m1.1.1\" xref=\"A7.T1.5.5.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.5.5.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.5.5.1.m1.1.1.cmml\" xref=\"A7.T1.5.5.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.5.5.1.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A7.T1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">81.63<math id=\"A7.T1.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.6.6.2.m1.1a\"><mo id=\"A7.T1.6.6.2.m1.1.1\" xref=\"A7.T1.6.6.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.6.6.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.6.6.2.m1.1.1.cmml\" xref=\"A7.T1.6.6.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.6.6.2.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A7.T1.6.6.4\" class=\"ltx_td ltx_border_bb\"></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As can be seen from the top ofÂ Tab.Â 1, increasing the number of users Kğ¾K has a marginal effect (<<1%) on the accuracy, from K=10ğ¾10K=10 to K=30ğ¾30K=30.\nOne notable thing here is that with K=30ğ¾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10ğ¾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30ğ¾30K=30 on SVHN, the final accuracy is 94.93%. One can refer toÂ Fig.Â C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000, K=100ğ¾100K=100, C=5ğ¶5C=5, and R=0ğ‘…0R=0 (which is the iid case) or R=1ğ‘…1R=1 (which is the most difficult non-iid case).\nFrom Tab.Â 3, one can see that our grouping-based solution outperforms the method proposed inÂ [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5ğ¶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatchÂ [11] inÂ Â§Â G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL)Â [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent workÂ [32] shows this may not be the case).\nFederated Averaging (FedAvg)Â [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FLÂ [16, 28, 33].\nInÂ [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is â€œrelatively ignoredâ€ and has â€œlittle prior arts,â€ as mentioned in a recent survey paperÂ [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users Kâˆˆ{47,20,10}ğ¾472010K\\in\\{47,20,10\\}. In these three settings, we let C=Kğ¶ğ¾C=K.\nThe other environmental factors are shown in rows 32-34 ofÂ Tab.Â A.2.\nWe set the group number S=5ğ‘†5S=5, S=2ğ‘†2S=2 and S=2ğ‘†2S=2 for the setting of K=47ğ¾47K=47, K=20ğ¾20K=20 and K=10ğ¾10K=10, respectively.\nSee TableÂ F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in TableÂ J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users Cğ¶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed inÂ Â§Â 4.2."
        ]
    },
    "A8.T1": {
        "caption": "Table H.1: Performance of the label-at-client setting.\n",
        "table": "<table id=\"A8.T1.4\" class=\"ltx_tabular ltx_centering ltx_align_top\">\n<tr id=\"A8.T1.2.2\" class=\"ltx_tr\">\n<td id=\"A8.T1.2.2.3\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A8.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A8.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"R=0.4\" display=\"inline\"><semantics id=\"A8.T1.1.1.1.m1.1a\"><mrow id=\"A8.T1.1.1.1.m1.1.1\" xref=\"A8.T1.1.1.1.m1.1.1.cmml\"><mi id=\"A8.T1.1.1.1.m1.1.1.2\" xref=\"A8.T1.1.1.1.m1.1.1.2.cmml\">R</mi><mo id=\"A8.T1.1.1.1.m1.1.1.1\" xref=\"A8.T1.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"A8.T1.1.1.1.m1.1.1.3\" xref=\"A8.T1.1.1.1.m1.1.1.3.cmml\">0.4</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A8.T1.1.1.1.m1.1b\"><apply id=\"A8.T1.1.1.1.m1.1.1.cmml\" xref=\"A8.T1.1.1.1.m1.1.1\"><eq id=\"A8.T1.1.1.1.m1.1.1.1.cmml\" xref=\"A8.T1.1.1.1.m1.1.1.1\"></eq><ci id=\"A8.T1.1.1.1.m1.1.1.2.cmml\" xref=\"A8.T1.1.1.1.m1.1.1.2\">ğ‘…</ci><cn type=\"float\" id=\"A8.T1.1.1.1.m1.1.1.3.cmml\" xref=\"A8.T1.1.1.1.m1.1.1.3\">0.4</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A8.T1.1.1.1.m1.1c\">R=0.4</annotation></semantics></math></td>\n<td id=\"A8.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A8.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"R=0.6\" display=\"inline\"><semantics id=\"A8.T1.2.2.2.m1.1a\"><mrow id=\"A8.T1.2.2.2.m1.1.1\" xref=\"A8.T1.2.2.2.m1.1.1.cmml\"><mi id=\"A8.T1.2.2.2.m1.1.1.2\" xref=\"A8.T1.2.2.2.m1.1.1.2.cmml\">R</mi><mo id=\"A8.T1.2.2.2.m1.1.1.1\" xref=\"A8.T1.2.2.2.m1.1.1.1.cmml\">=</mo><mn id=\"A8.T1.2.2.2.m1.1.1.3\" xref=\"A8.T1.2.2.2.m1.1.1.3.cmml\">0.6</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A8.T1.2.2.2.m1.1b\"><apply id=\"A8.T1.2.2.2.m1.1.1.cmml\" xref=\"A8.T1.2.2.2.m1.1.1\"><eq id=\"A8.T1.2.2.2.m1.1.1.1.cmml\" xref=\"A8.T1.2.2.2.m1.1.1.1\"></eq><ci id=\"A8.T1.2.2.2.m1.1.1.2.cmml\" xref=\"A8.T1.2.2.2.m1.1.1.2\">ğ‘…</ci><cn type=\"float\" id=\"A8.T1.2.2.2.m1.1.1.3.cmml\" xref=\"A8.T1.2.2.2.m1.1.1.3\">0.6</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A8.T1.2.2.2.m1.1c\">R=0.6</annotation></semantics></math></td>\n</tr>\n<tr id=\"A8.T1.4.4\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"A8.T1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span id=\"A8.T1.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">EMNSIT</span></td>\n<td id=\"A8.T1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A8.T1.3.3.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">81.88<math id=\"A8.T1.3.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A8.T1.3.3.1.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A8.T1.3.3.1.1.m1.1.1\" xref=\"A8.T1.3.3.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A8.T1.3.3.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A8.T1.3.3.1.1.m1.1.1.cmml\" xref=\"A8.T1.3.3.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A8.T1.3.3.1.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A8.T1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A8.T1.4.4.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">81.40<math id=\"A8.T1.4.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A8.T1.4.4.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A8.T1.4.4.2.1.m1.1.1\" xref=\"A8.T1.4.4.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A8.T1.4.4.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A8.T1.4.4.2.1.m1.1.1.cmml\" xref=\"A8.T1.4.4.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A8.T1.4.4.2.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As can be seen from the top ofÂ Tab.Â 1, increasing the number of users Kğ¾K has a marginal effect (<<1%) on the accuracy, from K=10ğ¾10K=10 to K=30ğ¾30K=30.\nOne notable thing here is that with K=30ğ¾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10ğ¾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30ğ¾30K=30 on SVHN, the final accuracy is 94.93%. One can refer toÂ Fig.Â C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000, K=100ğ¾100K=100, C=5ğ¶5C=5, and R=0ğ‘…0R=0 (which is the iid case) or R=1ğ‘…1R=1 (which is the most difficult non-iid case).\nFrom Tab.Â 3, one can see that our grouping-based solution outperforms the method proposed inÂ [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5ğ¶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatchÂ [11] inÂ Â§Â G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL)Â [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent workÂ [32] shows this may not be the case).\nFederated Averaging (FedAvg)Â [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FLÂ [16, 28, 33].\nInÂ [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is â€œrelatively ignoredâ€ and has â€œlittle prior arts,â€ as mentioned in a recent survey paperÂ [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users Kâˆˆ{47,20,10}ğ¾472010K\\in\\{47,20,10\\}. In these three settings, we let C=Kğ¶ğ¾C=K.\nThe other environmental factors are shown in rows 32-34 ofÂ Tab.Â A.2.\nWe set the group number S=5ğ‘†5S=5, S=2ğ‘†2S=2 and S=2ğ‘†2S=2 for the setting of K=47ğ¾47K=47, K=20ğ¾20K=20 and K=10ğ¾10K=10, respectively.\nSee TableÂ F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in TableÂ J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users Cğ¶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed inÂ Â§Â 4.2."
        ]
    },
    "A9.T1": {
        "caption": "",
        "table": "",
        "footnotes": "\n\n\n\n\nSelf-training\nCRL with BN\nCRL with GN\nGrouping-based\n\n74.25%\n78.96%\n81.71%\n82.81%\n\n",
        "references": [
            "As can be seen from the top ofÂ Tab.Â 1, increasing the number of users Kğ¾K has a marginal effect (<<1%) on the accuracy, from K=10ğ¾10K=10 to K=30ğ¾30K=30.\nOne notable thing here is that with K=30ğ¾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10ğ¾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30ğ¾30K=30 on SVHN, the final accuracy is 94.93%. One can refer toÂ Fig.Â C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000, K=100ğ¾100K=100, C=5ğ¶5C=5, and R=0ğ‘…0R=0 (which is the iid case) or R=1ğ‘…1R=1 (which is the most difficult non-iid case).\nFrom Tab.Â 3, one can see that our grouping-based solution outperforms the method proposed inÂ [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5ğ¶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatchÂ [11] inÂ Â§Â G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL)Â [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent workÂ [32] shows this may not be the case).\nFederated Averaging (FedAvg)Â [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FLÂ [16, 28, 33].\nInÂ [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is â€œrelatively ignoredâ€ and has â€œlittle prior arts,â€ as mentioned in a recent survey paperÂ [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users Kâˆˆ{47,20,10}ğ¾472010K\\in\\{47,20,10\\}. In these three settings, we let C=Kğ¶ğ¾C=K.\nThe other environmental factors are shown in rows 32-34 ofÂ Tab.Â A.2.\nWe set the group number S=5ğ‘†5S=5, S=2ğ‘†2S=2 and S=2ğ‘†2S=2 for the setting of K=47ğ¾47K=47, K=20ğ¾20K=20 and K=10ğ¾10K=10, respectively.\nSee TableÂ F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in TableÂ J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users Cğ¶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed inÂ Â§Â 4.2."
        ]
    },
    "A10.T1": {
        "caption": "Table J.1: The accuracy comparison of FedAvg and grouping-based average with large user number on EMNIST.\n",
        "table": "<table id=\"A10.T1.9\" class=\"ltx_tabular ltx_centering ltx_align_top\">\n<tr id=\"A10.T1.9.10\" class=\"ltx_tr\">\n<td id=\"A10.T1.9.10.1\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A10.T1.9.10.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</td>\n<td id=\"A10.T1.9.10.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Grouping-based</td>\n<td id=\"A10.T1.9.10.4\" class=\"ltx_td ltx_border_tt\"></td>\n</tr>\n<tr id=\"A10.T1.3.3\" class=\"ltx_tr\">\n<td id=\"A10.T1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><math id=\"A10.T1.1.1.1.m1.2\" class=\"ltx_Math\" alttext=\"K=470,C=10\" display=\"inline\"><semantics id=\"A10.T1.1.1.1.m1.2a\"><mrow id=\"A10.T1.1.1.1.m1.2.2.2\" xref=\"A10.T1.1.1.1.m1.2.2.3.cmml\"><mrow id=\"A10.T1.1.1.1.m1.1.1.1.1\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.cmml\"><mi id=\"A10.T1.1.1.1.m1.1.1.1.1.2\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.2.cmml\">K</mi><mo id=\"A10.T1.1.1.1.m1.1.1.1.1.1\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.1.cmml\">=</mo><mn id=\"A10.T1.1.1.1.m1.1.1.1.1.3\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.3.cmml\">470</mn></mrow><mo id=\"A10.T1.1.1.1.m1.2.2.2.3\" xref=\"A10.T1.1.1.1.m1.2.2.3a.cmml\">,</mo><mrow id=\"A10.T1.1.1.1.m1.2.2.2.2\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.cmml\"><mi id=\"A10.T1.1.1.1.m1.2.2.2.2.2\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.2.cmml\">C</mi><mo id=\"A10.T1.1.1.1.m1.2.2.2.2.1\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.1.cmml\">=</mo><mn id=\"A10.T1.1.1.1.m1.2.2.2.2.3\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.3.cmml\">10</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.1.1.1.m1.2b\"><apply id=\"A10.T1.1.1.1.m1.2.2.3.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2\"><csymbol cd=\"ambiguous\" id=\"A10.T1.1.1.1.m1.2.2.3a.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2.3\">formulae-sequence</csymbol><apply id=\"A10.T1.1.1.1.m1.1.1.1.1.cmml\" xref=\"A10.T1.1.1.1.m1.1.1.1.1\"><eq id=\"A10.T1.1.1.1.m1.1.1.1.1.1.cmml\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.1\"></eq><ci id=\"A10.T1.1.1.1.m1.1.1.1.1.2.cmml\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.2\">ğ¾</ci><cn type=\"integer\" id=\"A10.T1.1.1.1.m1.1.1.1.1.3.cmml\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.3\">470</cn></apply><apply id=\"A10.T1.1.1.1.m1.2.2.2.2.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2.2\"><eq id=\"A10.T1.1.1.1.m1.2.2.2.2.1.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.1\"></eq><ci id=\"A10.T1.1.1.1.m1.2.2.2.2.2.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.2\">ğ¶</ci><cn type=\"integer\" id=\"A10.T1.1.1.1.m1.2.2.2.2.3.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.3\">10</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.1.1.1.m1.2c\">K=470,C=10</annotation></semantics></math></td>\n<td id=\"A10.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">83.69<math id=\"A10.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.2.2.2.m1.1a\"><mo id=\"A10.T1.2.2.2.m1.1.1\" xref=\"A10.T1.2.2.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.2.2.2.m1.1.1.cmml\" xref=\"A10.T1.2.2.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.2.2.2.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A10.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A10.T1.3.3.3.1\" class=\"ltx_text ltx_font_bold\">83.94<math id=\"A10.T1.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.3.3.3.1.m1.1a\"><mo id=\"A10.T1.3.3.3.1.m1.1.1\" xref=\"A10.T1.3.3.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.3.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.3.3.3.1.m1.1.1.cmml\" xref=\"A10.T1.3.3.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.3.3.3.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A10.T1.3.3.4\" class=\"ltx_td ltx_border_t\"></td>\n</tr>\n<tr id=\"A10.T1.6.6\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"A10.T1.4.4.1\" class=\"ltx_td ltx_align_left\"><math id=\"A10.T1.4.4.1.m1.2\" class=\"ltx_Math\" style=\"background-color:#FFCC99;\" alttext=\"K=470,C=20\" display=\"inline\"><semantics id=\"A10.T1.4.4.1.m1.2a\"><mrow id=\"A10.T1.4.4.1.m1.2.2.2\" xref=\"A10.T1.4.4.1.m1.2.2.3.cmml\"><mrow id=\"A10.T1.4.4.1.m1.1.1.1.1\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.cmml\"><mi mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.1.1.1.1.2\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.2.cmml\">K</mi><mo mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.1.1.1.1.1\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.1.cmml\">=</mo><mn mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.1.1.1.1.3\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.3.cmml\">470</mn></mrow><mo mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.2.2.2.3\" xref=\"A10.T1.4.4.1.m1.2.2.3a.cmml\">,</mo><mrow id=\"A10.T1.4.4.1.m1.2.2.2.2\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.cmml\"><mi mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.2.2.2.2.2\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.2.cmml\">C</mi><mo mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.2.2.2.2.1\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.1.cmml\">=</mo><mn mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.2.2.2.2.3\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.3.cmml\">20</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.4.4.1.m1.2b\"><apply id=\"A10.T1.4.4.1.m1.2.2.3.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2\"><csymbol cd=\"ambiguous\" id=\"A10.T1.4.4.1.m1.2.2.3a.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2.3\">formulae-sequence</csymbol><apply id=\"A10.T1.4.4.1.m1.1.1.1.1.cmml\" xref=\"A10.T1.4.4.1.m1.1.1.1.1\"><eq id=\"A10.T1.4.4.1.m1.1.1.1.1.1.cmml\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.1\"></eq><ci id=\"A10.T1.4.4.1.m1.1.1.1.1.2.cmml\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.2\">ğ¾</ci><cn type=\"integer\" id=\"A10.T1.4.4.1.m1.1.1.1.1.3.cmml\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.3\">470</cn></apply><apply id=\"A10.T1.4.4.1.m1.2.2.2.2.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2.2\"><eq id=\"A10.T1.4.4.1.m1.2.2.2.2.1.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.1\"></eq><ci id=\"A10.T1.4.4.1.m1.2.2.2.2.2.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.2\">ğ¶</ci><cn type=\"integer\" id=\"A10.T1.4.4.1.m1.2.2.2.2.3.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.3\">20</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.4.4.1.m1.2c\">K=470,C=20</annotation></semantics></math></td>\n<td id=\"A10.T1.5.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"A10.T1.5.5.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">82.36<math id=\"A10.T1.5.5.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.5.5.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A10.T1.5.5.2.1.m1.1.1\" xref=\"A10.T1.5.5.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.5.5.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.5.5.2.1.m1.1.1.cmml\" xref=\"A10.T1.5.5.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.5.5.2.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A10.T1.6.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"A10.T1.6.6.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#FFCC99;\">83.66<math id=\"A10.T1.6.6.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.6.6.3.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A10.T1.6.6.3.1.m1.1.1\" xref=\"A10.T1.6.6.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.6.6.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.6.6.3.1.m1.1.1.cmml\" xref=\"A10.T1.6.6.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.6.6.3.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A10.T1.6.6.4\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"A10.T1.9.9\" class=\"ltx_tr\">\n<td id=\"A10.T1.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb\"><math id=\"A10.T1.7.7.1.m1.2\" class=\"ltx_Math\" alttext=\"K=470,C=30\" display=\"inline\"><semantics id=\"A10.T1.7.7.1.m1.2a\"><mrow id=\"A10.T1.7.7.1.m1.2.2.2\" xref=\"A10.T1.7.7.1.m1.2.2.3.cmml\"><mrow id=\"A10.T1.7.7.1.m1.1.1.1.1\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.cmml\"><mi id=\"A10.T1.7.7.1.m1.1.1.1.1.2\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.2.cmml\">K</mi><mo id=\"A10.T1.7.7.1.m1.1.1.1.1.1\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.1.cmml\">=</mo><mn id=\"A10.T1.7.7.1.m1.1.1.1.1.3\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.3.cmml\">470</mn></mrow><mo id=\"A10.T1.7.7.1.m1.2.2.2.3\" xref=\"A10.T1.7.7.1.m1.2.2.3a.cmml\">,</mo><mrow id=\"A10.T1.7.7.1.m1.2.2.2.2\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.cmml\"><mi id=\"A10.T1.7.7.1.m1.2.2.2.2.2\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.2.cmml\">C</mi><mo id=\"A10.T1.7.7.1.m1.2.2.2.2.1\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.1.cmml\">=</mo><mn id=\"A10.T1.7.7.1.m1.2.2.2.2.3\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.3.cmml\">30</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.7.7.1.m1.2b\"><apply id=\"A10.T1.7.7.1.m1.2.2.3.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2\"><csymbol cd=\"ambiguous\" id=\"A10.T1.7.7.1.m1.2.2.3a.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2.3\">formulae-sequence</csymbol><apply id=\"A10.T1.7.7.1.m1.1.1.1.1.cmml\" xref=\"A10.T1.7.7.1.m1.1.1.1.1\"><eq id=\"A10.T1.7.7.1.m1.1.1.1.1.1.cmml\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.1\"></eq><ci id=\"A10.T1.7.7.1.m1.1.1.1.1.2.cmml\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.2\">ğ¾</ci><cn type=\"integer\" id=\"A10.T1.7.7.1.m1.1.1.1.1.3.cmml\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.3\">470</cn></apply><apply id=\"A10.T1.7.7.1.m1.2.2.2.2.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2.2\"><eq id=\"A10.T1.7.7.1.m1.2.2.2.2.1.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.1\"></eq><ci id=\"A10.T1.7.7.1.m1.2.2.2.2.2.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.2\">ğ¶</ci><cn type=\"integer\" id=\"A10.T1.7.7.1.m1.2.2.2.2.3.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.3\">30</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.7.7.1.m1.2c\">K=470,C=30</annotation></semantics></math></td>\n<td id=\"A10.T1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">79.41<math id=\"A10.T1.8.8.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.8.8.2.m1.1a\"><mo id=\"A10.T1.8.8.2.m1.1.1\" xref=\"A10.T1.8.8.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.8.8.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.8.8.2.m1.1.1.cmml\" xref=\"A10.T1.8.8.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.8.8.2.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A10.T1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A10.T1.9.9.3.1\" class=\"ltx_text ltx_font_bold\">81.31<math id=\"A10.T1.9.9.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.9.9.3.1.m1.1a\"><mo id=\"A10.T1.9.9.3.1.m1.1.1\" xref=\"A10.T1.9.9.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.9.9.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.9.9.3.1.m1.1.1.cmml\" xref=\"A10.T1.9.9.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.9.9.3.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A10.T1.9.9.4\" class=\"ltx_td ltx_border_bb\"></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As can be seen from the top ofÂ Tab.Â 1, increasing the number of users Kğ¾K has a marginal effect (<<1%) on the accuracy, from K=10ğ¾10K=10 to K=30ğ¾30K=30.\nOne notable thing here is that with K=30ğ¾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10ğ¾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30ğ¾30K=30 on SVHN, the final accuracy is 94.93%. One can refer toÂ Fig.Â C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000, K=100ğ¾100K=100, C=5ğ¶5C=5, and R=0ğ‘…0R=0 (which is the iid case) or R=1ğ‘…1R=1 (which is the most difficult non-iid case).\nFrom Tab.Â 3, one can see that our grouping-based solution outperforms the method proposed inÂ [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscriptğ‘ğ‘ 5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5ğ¶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL inÂ Â§Â F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatchÂ [11] inÂ Â§Â G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples inÂ Â§Â H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, seeÂ Â§Â I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 inÂ Â§Â J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL)Â [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent workÂ [32] shows this may not be the case).\nFederated Averaging (FedAvg)Â [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FLÂ [16, 28, 33].\nInÂ [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is â€œrelatively ignoredâ€ and has â€œlittle prior arts,â€ as mentioned in a recent survey paperÂ [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users Kâˆˆ{47,20,10}ğ¾472010K\\in\\{47,20,10\\}. In these three settings, we let C=Kğ¶ğ¾C=K.\nThe other environmental factors are shown in rows 32-34 ofÂ Tab.Â A.2.\nWe set the group number S=5ğ‘†5S=5, S=2ğ‘†2S=2 and S=2ğ‘†2S=2 for the setting of K=47ğ¾47K=47, K=20ğ¾20K=20 and K=10ğ¾10K=10, respectively.\nSee TableÂ F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in TableÂ J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users Cğ¶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed inÂ Â§Â 4.2."
        ]
    }
}