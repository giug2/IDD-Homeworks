{
    "id_table_1": {
        "caption": "Table 1.  Replacing structural token embeddings by other query token embeddings (TREC 2019-2020, RQ1).  Maximum values are in bold; significant differences from None are shown with a dagger ( p < 0.05 p 0.05 p<0.05 italic_p < 0.05 , Bonferroni-corrected  t t t italic_t -tests).",
        "table": "S4.T1.20.16",
        "footnotes": [],
        "references": [
            "ColBERT  (Khattab and Zaharia,  2020 ) s use of multiple token embedding vectors supports fine-grained matching between queries and documents. The model ranks documents by adding the maximum similarity of a document token embedding  to each query token embedding, as shown in Equation  1 . This greedy alignment of query to document token embeddings has been dubbed  MaxSim .",
            "As shown in Figure  1 , when extending the maximum length of a query past the 32 token window it was trained with, we see a repeating pattern of cosine similarities between  [MASK]  and non- [MASK]  tokens.  It appears that BERT keeps outputting the same weighting pattern for longer query lengths.  A natural question then, is how ColBERT fares when the maximum query length is increased, and  [MASK] -based term weighting dominates document scoring.  One may be wary of the unintentional effects of changing  [MASK]  counts this way. For instance, could adding an extra  [MASK]  to the end of a query cause the previous  [MASK] s, or even the query text tokens, to change their representations in response?",
            "For the  [MASK]  remapping experiment, we see that on ColBERTv2, remapping  [MASK] s causes a consistent decrease in performance (see Table  1 ). For nDCG@1000, all conditions are significantly worse than the baseline. The All [X]    \\rightarrow   Text condition performs worse than any other condition, many times being significantly worse than the baseline. The  [MASK]     \\rightarrow   Str. & Text condition performs best of the three conditions. This is both consistent with the ColBERTv1 results from  Giacalone et al .  ( 2024 ) , and provides more evidence for that  [MASK]  embeddings simply select all non- [MASK] s as candidates for term weighting.",
            "This would also explain the pattern demonstrated by the  [Q]  token in Figure  1 , where  [MASK] s that are very similar to the  [Q]  token are always also very similar to some other token. When we visualized several different queries using the same visualization shown in Figure  1 , we saw that  [Q]  was the only non- [MASK]  structural token consistently very similar to query text tokens."
        ]
    },
    "id_table_2": {
        "caption": "Table 2.  Changing the maximum length of queries from 32 to 128 with  [MASK]  padding.  Maximum values are in bold; significant differences from 32 are shown with a dagger ( p < 0.05 p 0.05 p<0.05 italic_p < 0.05 , Bonferroni-corrected  t t t italic_t -tests).",
        "table": "S4.T2.5.1",
        "footnotes": [],
        "references": [
            "In Khattab and Zaharias original ColBERT paper  (Khattab and Zaharia,  2020 ) , they show using augmentation with  [MASK]  tokens increases  MRR@10 on MS MARCO  (Nguyen et al . ,  2016 ) .  Their rationale is that  [MASK]  tokens help  introduce new terms to the query, and reweight other query terms.  However, later work suggests that  [MASK]  tokens primarily weight other tokens in the query, as summarized in Section  2 . In this paper we present new experiments to obtain additional insight into how query augmentation maps  [MASK] s into the contextualized token embedding space.  We consider two main research questions:",
            "For the query shift experiment shown in Figure  2 , we see the same pattern reported in  Giacalone et al .  ( 2024 ) :  [Q]  and  [MASK]  tokens vary greatly after what is is swapped and moved, while  [CLS] ,  [SEP] , and query text tokens do not change nearly as much. In fact, with ColBERTv2, this difference is even starker. Given that this is a pattern that has now manifested itself across two separately trained checkpoints, with two different training objectives, we suspect that the  [Q]  token performs a similar function to  [MASK]  tokens  adding weight to certain tokens to influence scoring.",
            "In Table  2 , we see nDCG@/@1000 on both TREC 2019-2020 and TREC COVID as we vary the maximum query length.  We first focus on the results from the TREC 2019-2020 dataset. Modifying only set retrieval causes a minor increase in nDCG@1000, but appears to have no effect on nDCG@10, likely due to baseline set retrieval already retrieving most relevant documents.  Modifying only reranking on TREC 2019-2020 causes both nDCG@10/@1000 to decrease. When modifying both phases, nDCG@10 very slightly increases, but nDCG@1000 does not change, likely due to the increase from set retrieval and the decrease from reranking negating each other.  Ultimately, all changes observed on TREC 2019-2020 are small, and we never saw an increase or decrease greater than 1%, nor did we observe any statistically significant  p p p italic_p -values when performing Bonferroni-corrected  t t t italic_t -tests."
        ]
    },
    "global_footnotes": [
        "To our knowledge, this has not been reported in the ColBERT papers."
    ]
}