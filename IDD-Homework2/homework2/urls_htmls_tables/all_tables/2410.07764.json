{
    "id_table_1": {
        "caption": "Table 1:  Quantitative evaluation of hyperGNN explainers on the synthetic benchmarks.  We compare explanation faithfulness, measured by generalized fidelity metrics, and concision, measured by subhypergraph size and density. Our method consistently outputs more faithful explanations than all baselines, which are given comparable or more generous size budgets ( n = 20 n 20 n=20 italic_n = 20  for  H-TreeGrid ,  n = 10 n 10 n=10 italic_n = 10  for all other datasets).",
        "table": "S5.T1.14",
        "footnotes": [],
        "references": [
            "Given a trained hyperGNN  f f f italic_f , a hypergraph  G G G italic_G , and a node instance  v v v italic_v  in  G G G italic_G , our goal is to produce an explanation subhypergraph that is both faithful and concise. To achieve this, we formulate these desiderata as a joint objective and optimize the explanation subhypergraph against this objective by discrete sampling. Figure  1 (top) gives an overview of the local explainer.",
            "where  | c | c |c| | italic_c |  is the number of nodes belonging to that concept. We then produce as the explanation for concept  c c c italic_c  the instance-level explanation subhypergraph for  v c  superscript subscript v c v_{c}^{*} italic_v start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , which we denote  G expl  ( v ) subscript G expl v G_{\\textrm{expl}}(v) italic_G start_POSTSUBSCRIPT expl end_POSTSUBSCRIPT ( italic_v ) . This explanation is computed using our instance-level explainer described in Section  4.1 .",
            "Figure  1 (bottom) illustrates the overall pipeline. Whereas GCExplainer visualizes each concept by the  n n n italic_n -hop graph neighborhood of  v c  superscript subscript v c v_{c}^{*} italic_v start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , where  n n n italic_n  is a hyperparameter, the integration with our local explainer produces more legible explanation artefacts appropriate to the users desired faithfulness-concision tradeoff (see Appendix  D  for a visual comparison between the two approaches).",
            "We show that our hypergraph explainer produces high quality explanations through extensive evaluations. We test on real hypergraphs  Cora ,  CoauthorCora ,  CoauthorDBLP , and  Zoo  from the benchmark of  Chien et al. ( 2021 ) . 1 1 1 We selected the latter three hypergraphs because here the hyperGNNs outperform MLP by an appreciable margin; these are expected to be the relatively discriminating test cases for explainability, as discussed in Section  5.1  For comparison, we also selected  Cora , where this is not the case.  In Section  5.1 , we discuss why existing hypergraph datasets may not provide a sufficiently challenging setting for finding subhypergraph explanations, and design challenging synthetic hypergraph datasets to complement our evaluations. In Section  5.2 , we highlight some shortcomings of the fidelity metric used to quantitatively evaluate explanations, and propose alternatives to address them.",
            "Synthetic hypergraphs.  Our method, SHypX, significantly outperforms all baselines across all four synthetic datasets (Table  1 ). While Gradient and Attention show substantial improvements from Random (e.g. on  H-RandHouse ,  Fid  Acc superscript subscript Fid Acc \\textrm{Fid}_{-}^{\\textrm{Acc}} Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT Acc end_POSTSUPERSCRIPT  is 0.36 and 0.61 respectively, compared to Randoms 0.81), they dont consistently produce faithful explanations. On synthetic hypergraphs, HyperEX performs on par with Random. We hypothesize that this is because it mean-aggregates nodes to produce hyperedge representations, which constitutes a homophily assumption that is violated in the synthetic case. In comparison, the explanations produced by our method reliably achieves near zero fidelity metrics.",
            "Comparing explanation methods across different concision budget.  In Table  1  and Table  2 , for each dataset, we fixed the same hyperparameter  n n n italic_n  across all baselines (to obtain the top- n n n italic_n  node-hyperedge links) such that at least one baseline produces explanations of comparable concision to SHypX; this ensures a fair comparison between the fidelity results. We observe that the baseline explainers  often do not even select components that are connected  to the node being explained. Note that, since post-processing discards these disconnected components (see Section  4.1  ),  | G expl |  n subscript G expl n |G_{\\mathrm{expl}}|\\leq n | italic_G start_POSTSUBSCRIPT roman_expl end_POSTSUBSCRIPT |  italic_n  the explanation size can vary across baselines despite their identical choice of  n n n italic_n . To understand how the quality of explanation varies when allowing larger subhypergraphs as explanation, we designed an experiment in which we directly control for the size of the final explanation and compare  Fid  KL superscript subscript Fid KL \\textrm{Fid}_{-}^{\\textrm{KL}} Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT KL end_POSTSUPERSCRIPT  (see Figure  3 ). The outperformance of our method is robust across the curve, whereas the baseline methods buy limited gains in fidelity with increasing size budget.",
            "For consistency, all explanation methods operate over the same AllSetTransformer model for each dataset. This models task performance is reported in Table  5 . All explanation methods benefit from identical pre-processing, which reduces the search space to the computational subhypergraph. They are also subject to the same post-processing, which retain only the connected component containing the node being explained (as described in Section  4.1 ). This means the mean explanation size obtained is generally less than  n n n italic_n .",
            "For the main results of Table  1  and Table  2 , we choose our explanation concision budget by setting   pred = 1 subscript  pred 1 \\lambda_{\\textrm{pred}}=1 italic_ start_POSTSUBSCRIPT pred end_POSTSUBSCRIPT = 1 , and   size = 0.05 subscript  size 0.05 \\lambda_{\\textrm{size}}=0.05 italic_ start_POSTSUBSCRIPT size end_POSTSUBSCRIPT = 0.05  for the synthetic datasets and   size = 0.005 subscript  size 0.005 \\lambda_{\\textrm{size}}=0.005 italic_ start_POSTSUBSCRIPT size end_POSTSUBSCRIPT = 0.005  for the real world datasets. Alternative choices of    \\lambda italic_  for two select datasets are reported in Figure  3 . The explanation subhypergraph is sampled with Gumbel-Softmax at temperature 1.0, and optimized with Adam for 400 epochs at learning rate 0.01. The probability of sampling each node-hyperedge link (  v , e ( 1 ) superscript subscript  v e 1 \\pi_{v,e}^{(1)} italic_ start_POSTSUBSCRIPT italic_v , italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT ) is initialized uniformly to   95 % absent percent 95 \\approx 95\\%  95 %  across the computational subhypergraph.",
            "The  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  metric has been used to measure whether an explanation is sufficient, that is, whether it is free of superfluous information. A large  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  indicates that the explanations complement  does not contain  useful information for the hyperGNNs prediction. This has been thought to suggest that the explanation has successfully isolated the useful information. However, this reasoning is flawed  a successful explanation (achieving the user-desired balance of faithfulness and concision) could nonetheless induce a complement subhypergraph that can also reproduce the hyperGNNs prediction. This can be seen with a simple intuition: when the explanation subhypergraph is concise  that is, all of its parts are necessary, as desired  the complement is large. The complement is therefore likely to include a large number of hyperedges and neighbors directly incident to the node being explained. This allows the complement to reproduce the hyperGNNs prediction with high fidelity, producing low  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  scores. See Figure  10  for an illustrative example.",
            "To concretely illustrate some of these failure modes, we expose the  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  scores of  H-TreeGrid  and  Coauthor-DBLP  in Table  6 . For  H-TreeGrid , the similar  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  for Gradient and our method suggest that they are comparably successful at isolating relevant information to the explanation subhypergraph. However, this does not align with our natural understanding of which explanations are more sufficient  whereas Table  1  shows that our method achieves an extremely low fidelity at mean explanation size of 15.1 and mean explanation density of 0.45, Gradient produces explanations with  Fid  A  c  c = 0.40 superscript subscript Fid A c c 0.40 \\textrm{Fid}_{-}^{Acc}=0.40 Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A italic_c italic_c end_POSTSUPERSCRIPT = 0.40  while being almost 3 links larger and 10 percentage points denser. For  CoauthorDBLP , our method yields the most faithful and most concise explanations (average size 2.3 and average density 0.15) of all baselines (Table  2 ). However, the small size of these explanations induces a large complement, contributing to its unfavorable  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  scores."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Quantitative evaluation on four real world datasets.  Our method consistently produces explanations that are both more faithful (as measured by  Fid   superscript subscript Fid \\textrm{Fid}_{-}^{*} Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  metrics) and more concise (as measured by Size and Density) than all baselines.",
        "table": "S5.T2.12",
        "footnotes": [],
        "references": [
            "We pass the resultant subhypergraph through the hyperGNN to evaluate  f  ( G sub , X , v ) f subscript G sub X v f(G_{\\textrm{sub}},\\bm{X},v) italic_f ( italic_G start_POSTSUBSCRIPT sub end_POSTSUBSCRIPT , bold_italic_X , italic_v ) . By ensuring this entire subhypergraph sampling is differentiable, we are able to optimize the underlying probabilities  {  v , e } subscript  v e \\{\\pi_{v,e}\\} { italic_ start_POSTSUBSCRIPT italic_v , italic_e end_POSTSUBSCRIPT } , using backpropagation on the loss  L  ( f , G sub , G comp , X , v ) L f subscript G sub subscript G comp X v \\mathcal{L}(f,G_{\\textrm{sub}},G_{\\textrm{comp}},\\bm{X},v) caligraphic_L ( italic_f , italic_G start_POSTSUBSCRIPT sub end_POSTSUBSCRIPT , italic_G start_POSTSUBSCRIPT comp end_POSTSUBSCRIPT , bold_italic_X , italic_v )  defined in Equation  2 .",
            "We show that our hypergraph explainer produces high quality explanations through extensive evaluations. We test on real hypergraphs  Cora ,  CoauthorCora ,  CoauthorDBLP , and  Zoo  from the benchmark of  Chien et al. ( 2021 ) . 1 1 1 We selected the latter three hypergraphs because here the hyperGNNs outperform MLP by an appreciable margin; these are expected to be the relatively discriminating test cases for explainability, as discussed in Section  5.1  For comparison, we also selected  Cora , where this is not the case.  In Section  5.1 , we discuss why existing hypergraph datasets may not provide a sufficiently challenging setting for finding subhypergraph explanations, and design challenging synthetic hypergraph datasets to complement our evaluations. In Section  5.2 , we highlight some shortcomings of the fidelity metric used to quantitatively evaluate explanations, and propose alternatives to address them.",
            "Our synthetic hypergraphs are inspired by the synthetic graphs of  Ying et al. ( 2019 ) , which have served as a core benchmark in graph explainability. Each hypergraph comprises a base component that is either random or a deterministic hyper-binary-tree (Figure  2 a-b), to which various motifs (Figure  2 c-e) are attached using a single hyperedge. Additionally, we randomly add degree-2 hyperedges as perturbations. Figure  2 e shows an example of a hypergraph constructed in this manner. The task is to classify nodes based on their positions in the base or motif. See Appendix  B  for details.",
            "Real hypergraphs.  On the real world hypergraphs, SHypX also outperforms all baselines. For example, in  Coauthor-Cora , we achieve  Fid  KL superscript subscript Fid KL \\textrm{Fid}_{-}^{\\textrm{KL}} Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT KL end_POSTSUPERSCRIPT  of  3  e   4 3E-4 310-4 start_ARG 3 end_ARG start_ARG  end_ARG start_ARG roman_e start_ARG - 4 end_ARG end_ARG , compared to  0.03 , 0.05 , 0.08 , 0.25 0.03 0.05 0.08 0.25 0.03,0.05,0.08,0.25 0.03 , 0.05 , 0.08 , 0.25  for HyperEX, Gradient, Attention, and Random respectively. While producing more faithful explanations, our model does not sacrifice concision: it achieves this superior fidelity with the best concision on this dataset, at average size 2.1 and density 0.28. This relative ranking between methods is consistent across all four real hypergraphs. We also observe that the simple baselines Random, Gradient, and Attention already attain competitive performance on several real hypergraphs.  Cora  is the most extreme example of this, where even Random produces faithful explanations at  Fid  KL = 0.01 superscript subscript Fid KL 0.01 \\textrm{Fid}_{-}^{\\textrm{KL}}=0.01 Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT KL end_POSTSUPERSCRIPT = 0.01 . Indeed, SHypXs mean explanation size of 1.4 suggests that oftentimes, just the nodes features, without neighborhood structure, suffice to achieve perfect predictions over  Cora . This structural degeneracy is also observed to some extent for  CoauthorCora  and  CoauthorDBLP . These results support Section  5.2 s discussion about complementing evaluations on real hypergraphs with our challenging synthetic ones, and leveraging generalized fidelity as a more discriminating metric.",
            "Comparing explanation methods across different concision budget.  In Table  1  and Table  2 , for each dataset, we fixed the same hyperparameter  n n n italic_n  across all baselines (to obtain the top- n n n italic_n  node-hyperedge links) such that at least one baseline produces explanations of comparable concision to SHypX; this ensures a fair comparison between the fidelity results. We observe that the baseline explainers  often do not even select components that are connected  to the node being explained. Note that, since post-processing discards these disconnected components (see Section  4.1  ),  | G expl |  n subscript G expl n |G_{\\mathrm{expl}}|\\leq n | italic_G start_POSTSUBSCRIPT roman_expl end_POSTSUBSCRIPT |  italic_n  the explanation size can vary across baselines despite their identical choice of  n n n italic_n . To understand how the quality of explanation varies when allowing larger subhypergraphs as explanation, we designed an experiment in which we directly control for the size of the final explanation and compare  Fid  KL superscript subscript Fid KL \\textrm{Fid}_{-}^{\\textrm{KL}} Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT KL end_POSTSUPERSCRIPT  (see Figure  3 ). The outperformance of our method is robust across the curve, whereas the baseline methods buy limited gains in fidelity with increasing size budget.",
            "Our synthetic hypergraphs are designed with a base-and-motif construction , inspired by  Ying et al. ( 2019 ) . For the random base, we sample a random bipartite graph with  n , m n m n,m italic_n , italic_m  nodes in each of the bipartite sets respectively, and  k k k italic_k  edges between them uniformly at random. We take the largest connected component of this bipartite graph and apply the inverse star expansion to obtain a random base hypergraph (Figure  2 a). For the tree base, we enclose each triplet of a parent node and its two child nodes in a hyperedge. This produces a tree base hypergraph that is deterministic and 3-uniform (Figure  2 b). The house, cycle, and grid motifs from  Ying et al. ( 2019 )  are also lifted to hypergraph motifs (Figure  2 c-e). In designing these, we were motivated by preserving the natural symmetries of each motif, without rendering the classification task trivial (for example, allowing motifs to be immediately distinguishable from a tree base by hyperedge degree). In the example visualized in Figure  2 e, the hypergraph consists of a random base of 13 nodes (blue nodes and grey hyperedges), 2 house motifs, and 3 edge perturbations (pink hyperedges).",
            "The benchmark task over our synthetic hypergraphs is node classification, where the node labels depend on the nodes position in the base or motif. Each class is denoted by a distinct color in Figure  2 . In particular, all base nodes are Class 0, and all nodes in the cycle and grid motif are Class 1. The house motif is further sub-divided into top-of-the-house (Class 1), middle-of-the-house (Class 2), and bottom-of-the-house (Class 3).",
            "For the main results of Table  1  and Table  2 , we choose our explanation concision budget by setting   pred = 1 subscript  pred 1 \\lambda_{\\textrm{pred}}=1 italic_ start_POSTSUBSCRIPT pred end_POSTSUBSCRIPT = 1 , and   size = 0.05 subscript  size 0.05 \\lambda_{\\textrm{size}}=0.05 italic_ start_POSTSUBSCRIPT size end_POSTSUBSCRIPT = 0.05  for the synthetic datasets and   size = 0.005 subscript  size 0.005 \\lambda_{\\textrm{size}}=0.005 italic_ start_POSTSUBSCRIPT size end_POSTSUBSCRIPT = 0.005  for the real world datasets. Alternative choices of    \\lambda italic_  for two select datasets are reported in Figure  3 . The explanation subhypergraph is sampled with Gumbel-Softmax at temperature 1.0, and optimized with Adam for 400 epochs at learning rate 0.01. The probability of sampling each node-hyperedge link (  v , e ( 1 ) superscript subscript  v e 1 \\pi_{v,e}^{(1)} italic_ start_POSTSUBSCRIPT italic_v , italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT ) is initialized uniformly to   95 % absent percent 95 \\approx 95\\%  95 %  across the computational subhypergraph.",
            "We extract concepts by k-means clustering, as described in Section  4.2 . The quality of concept extraction is quantified by concept completeness, the accuracy of a decision tree classifier that optimally maps the set of concepts onto the set of class labels  (Magister et al.,  2021 ) . Optimal is defined such that each node instance, featurized only by its concept label, is mapped to a class label with high accuracy. Since the concept label is a discrete class, the decision tree classifier is optimized by performing majority vote within each concept, as proposed in Section  4.2 . We consider the concept extraction successful if its concept completeness is close to the task accuracy, since this overall procedure relies on the latent representations learned by the hyperGNN.",
            "To concretely illustrate some of these failure modes, we expose the  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  scores of  H-TreeGrid  and  Coauthor-DBLP  in Table  6 . For  H-TreeGrid , the similar  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  for Gradient and our method suggest that they are comparably successful at isolating relevant information to the explanation subhypergraph. However, this does not align with our natural understanding of which explanations are more sufficient  whereas Table  1  shows that our method achieves an extremely low fidelity at mean explanation size of 15.1 and mean explanation density of 0.45, Gradient produces explanations with  Fid  A  c  c = 0.40 superscript subscript Fid A c c 0.40 \\textrm{Fid}_{-}^{Acc}=0.40 Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A italic_c italic_c end_POSTSUPERSCRIPT = 0.40  while being almost 3 links larger and 10 percentage points denser. For  CoauthorDBLP , our method yields the most faithful and most concise explanations (average size 2.3 and average density 0.15) of all baselines (Table  2 ). However, the small size of these explanations induces a large complement, contributing to its unfavorable  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  scores.",
            "Based on these observations, we opt for hypergraph size  | G | 1 subscript G 1 |G|_{1} | italic_G | start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  (Section  5.2 ) as a cheaper and less artefact-prone measure of explanation minimality.",
            "In this section, we investigate the choice of sampling technique. Since this choice pertains to the optimization, we are primarily interested in which sampler achieves the lowest loss given a fixed objective function (Equation  2 ). Table  7  compares the loss attained by the Gumbel-Softmax sampler (our choice) against two alternatives, as well as reporting their respective fidelity and size metrics for reference."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Construction of novel synthetic hypergraphs. Upper section reports fundamental properties of each hypergraph dataset, such as its base and type of attached motif. Lower section reports, for each family, the default parameters used to instantiate the hypergraph used in our evaluations.",
        "table": "A6.EGx1",
        "footnotes": [],
        "references": [
            "Different combinations of these base and motif components give rise to four synthetic hypergraphs:  H-RandHouse ,  H-CommHouse ,  H-TreeCycle , and  H-TreeGrid . Table  3  shows their statistics and Table  4  benchmarks several hyperGNN architectures on these hypergraphs. Compared to benchmarks on real hypergraphs  (Chien et al.,  2021 ) , our proposed datasets exhibits a clear gap between hyperGNNs and models that disregard structural information, such as MLPs. This indicates that the datasets represent challenging, structure-dependent tasks well-suited for evaluating hypergraph explainability.",
            "Comparing explanation methods across different concision budget.  In Table  1  and Table  2 , for each dataset, we fixed the same hyperparameter  n n n italic_n  across all baselines (to obtain the top- n n n italic_n  node-hyperedge links) such that at least one baseline produces explanations of comparable concision to SHypX; this ensures a fair comparison between the fidelity results. We observe that the baseline explainers  often do not even select components that are connected  to the node being explained. Note that, since post-processing discards these disconnected components (see Section  4.1  ),  | G expl |  n subscript G expl n |G_{\\mathrm{expl}}|\\leq n | italic_G start_POSTSUBSCRIPT roman_expl end_POSTSUBSCRIPT |  italic_n  the explanation size can vary across baselines despite their identical choice of  n n n italic_n . To understand how the quality of explanation varies when allowing larger subhypergraphs as explanation, we designed an experiment in which we directly control for the size of the final explanation and compare  Fid  KL superscript subscript Fid KL \\textrm{Fid}_{-}^{\\textrm{KL}} Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT KL end_POSTSUPERSCRIPT  (see Figure  3 ). The outperformance of our method is robust across the curve, whereas the baseline methods buy limited gains in fidelity with increasing size budget.",
            "By adjusting the relative strengths of the   pred subscript  pred \\lambda_{\\mathrm{pred}} italic_ start_POSTSUBSCRIPT roman_pred end_POSTSUBSCRIPT  and   size subscript  size \\lambda_{\\mathrm{size}} italic_ start_POSTSUBSCRIPT roman_size end_POSTSUBSCRIPT  coefficients, our model allows the users to effectively trade off between explanation faithfulness and concision. Figure  3 a shows  H-RandHouse  explanations obtained with   pred /  size  { 0.2 , 0.1 , 0.05 , 0.02 , 0.01 , 0.005 } subscript  pred subscript  size 0.2 0.1 0.05 0.02 0.01 0.005 \\lambda_{\\mathrm{pred}}/\\lambda_{\\mathrm{size}}\\in\\{0.2,0.1,0.05,0.02,0.01,0.0% 05\\} italic_ start_POSTSUBSCRIPT roman_pred end_POSTSUBSCRIPT / italic_ start_POSTSUBSCRIPT roman_size end_POSTSUBSCRIPT  { 0.2 , 0.1 , 0.05 , 0.02 , 0.01 , 0.005 } . As this ratio shrinks, the extracted explanations interpolate smoothly from concise-but-less-faithful (0.36  Fid  KL . superscript subscript Fid KL \\mathrm{Fid}_{-}^{\\mathrm{KL.}} roman_Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_KL . end_POSTSUPERSCRIPT , mean size 4) to verbose-and-highly-faithful ( 3  e   3 3E-3 310-3 start_ARG 3 end_ARG start_ARG  end_ARG start_ARG roman_e start_ARG - 3 end_ARG end_ARG   Fid  KL . superscript subscript Fid KL \\textrm{Fid}_{-}^{\\mathrm{KL.}} Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_KL . end_POSTSUPERSCRIPT , mean size 22). Similarly, for  Zoo , explanations obtained with   pred /  size  { 1  e   2 , 5  e   3 , 2  e   3 , 1  e   3 , 5  e   4 } subscript  pred subscript  size 1E-2 5E-3 2E-3 1E-3 5E-4 \\lambda_{\\mathrm{pred}}/\\lambda_{\\mathrm{size}}\\in\\{$110-2$,$510-3$,$210-3$,$1% 10-3$,$510-4$\\} italic_ start_POSTSUBSCRIPT roman_pred end_POSTSUBSCRIPT / italic_ start_POSTSUBSCRIPT roman_size end_POSTSUBSCRIPT  { start_ARG 1 end_ARG start_ARG  end_ARG start_ARG roman_e start_ARG - 2 end_ARG end_ARG , start_ARG 5 end_ARG start_ARG  end_ARG start_ARG roman_e start_ARG - 3 end_ARG end_ARG , start_ARG 2 end_ARG start_ARG  end_ARG start_ARG roman_e start_ARG - 3 end_ARG end_ARG , start_ARG 1 end_ARG start_ARG  end_ARG start_ARG roman_e start_ARG - 3 end_ARG end_ARG , start_ARG 5 end_ARG start_ARG  end_ARG start_ARG roman_e start_ARG - 4 end_ARG end_ARG }  form a smooth decaying curve from higher to near-zero fidelity. Interestingly, Figure  3  suggests that for  H-RandHouse , all baselines perform similarly once adjusted for final explanation size, and that for  Zoo , no baseline method reliably improves in fidelity with increasing size budget. Finally, we note that specifying the trade-off via   pred /  size subscript  pred subscript  size \\lambda_{\\mathrm{pred}}/\\lambda_{\\mathrm{size}} italic_ start_POSTSUBSCRIPT roman_pred end_POSTSUBSCRIPT / italic_ start_POSTSUBSCRIPT roman_size end_POSTSUBSCRIPT  confers our method an additional benefit: it can dynamically adapt the explanation size for each node, according to the relevance of a nodes neighborhood in the local hyperGNN prediction. In contrast, the baselines explainers inflexibly apply top- n n n italic_n  thresholding across all node instances.",
            "Different combinations of these base and motif components give rise to the synthetic hypergraphs  H-RandHouse ,  H-CommHouse ,  H-TreeCycle , and  H-TreeGrid  (Table  3 ).  H-CommHouse  comprises two  H-RandHouse  graphs, i.e. communities, stitched together with random edges. Each node has features drawn from a normal distribution, whose mean and variance depend on the community membership. The other three synthetic graphs have trivial features, which we choose to be all ones. (We observed similar performance for all zeros or standard random normal features.) Perturbations, in the form of degree-2 hyperedges, are then added randomly to simulate structural noise, increasing the difficulty of the task. A train-validation split at 80% train nodes is applied to each hypergraph.",
            "For the baselines in each dataset, we choose  n n n italic_n  such that the density of the gradient or attention explanations is comparable to, or greater than, the density of our explanations. This ensures our method does not have an unfair advantage. We find that  n = 10 n 10 n=10 italic_n = 10  for all datasets except  n = 20 n 20 n=20 italic_n = 20  for  H-TreeGrid  suffices to achieve this comparison. Note that these size budgets are greater than the mean size of explanations produced by our method on their respective datasets. Alternatively, Figure  3  compares all methods across the entire curve of varying explanation size budgets.",
            "For the main results of Table  1  and Table  2 , we choose our explanation concision budget by setting   pred = 1 subscript  pred 1 \\lambda_{\\textrm{pred}}=1 italic_ start_POSTSUBSCRIPT pred end_POSTSUBSCRIPT = 1 , and   size = 0.05 subscript  size 0.05 \\lambda_{\\textrm{size}}=0.05 italic_ start_POSTSUBSCRIPT size end_POSTSUBSCRIPT = 0.05  for the synthetic datasets and   size = 0.005 subscript  size 0.005 \\lambda_{\\textrm{size}}=0.005 italic_ start_POSTSUBSCRIPT size end_POSTSUBSCRIPT = 0.005  for the real world datasets. Alternative choices of    \\lambda italic_  for two select datasets are reported in Figure  3 . The explanation subhypergraph is sampled with Gumbel-Softmax at temperature 1.0, and optimized with Adam for 400 epochs at learning rate 0.01. The probability of sampling each node-hyperedge link (  v , e ( 1 ) superscript subscript  v e 1 \\pi_{v,e}^{(1)} italic_ start_POSTSUBSCRIPT italic_v , italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT ) is initialized uniformly to   95 % absent percent 95 \\approx 95\\%  95 %  across the computational subhypergraph."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:   Benchmarking hypergraph neural networks on the synthetic hypergraphs. Each number denotes the mean final validation accuracy, in %, over 5 random seeds. All models are three layers deep, use sum aggregation, and no dropout. AllDeepSets and AllSetTransformer have dimension-16 message passing and classifier layers; MLP, HGNN, HCHA have dimension-80 hidden layers, which ensures all models have comparable parameter count. All models are trained with the Adam optimizer at 0.001 learning rate, for 2000 epochs (MLP, HGNN, HCHA) or 500 epochs (AllDeepSets and AllSetTransformer), which we observed sufficed to achieve convergence. Other hyperparameters are per  Chien et al. ( 2021 ) s defaults. Boldface indicates the best model.",
        "table": "A2.T3.1",
        "footnotes": [
            ""
        ],
        "references": [
            "where  | c | c |c| | italic_c |  is the number of nodes belonging to that concept. We then produce as the explanation for concept  c c c italic_c  the instance-level explanation subhypergraph for  v c  superscript subscript v c v_{c}^{*} italic_v start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , which we denote  G expl  ( v ) subscript G expl v G_{\\textrm{expl}}(v) italic_G start_POSTSUBSCRIPT expl end_POSTSUBSCRIPT ( italic_v ) . This explanation is computed using our instance-level explainer described in Section  4.1 .",
            "Different combinations of these base and motif components give rise to four synthetic hypergraphs:  H-RandHouse ,  H-CommHouse ,  H-TreeCycle , and  H-TreeGrid . Table  3  shows their statistics and Table  4  benchmarks several hyperGNN architectures on these hypergraphs. Compared to benchmarks on real hypergraphs  (Chien et al.,  2021 ) , our proposed datasets exhibits a clear gap between hyperGNNs and models that disregard structural information, such as MLPs. This indicates that the datasets represent challenging, structure-dependent tasks well-suited for evaluating hypergraph explainability.",
            "Comparing explanation methods across different concision budget.  In Table  1  and Table  2 , for each dataset, we fixed the same hyperparameter  n n n italic_n  across all baselines (to obtain the top- n n n italic_n  node-hyperedge links) such that at least one baseline produces explanations of comparable concision to SHypX; this ensures a fair comparison between the fidelity results. We observe that the baseline explainers  often do not even select components that are connected  to the node being explained. Note that, since post-processing discards these disconnected components (see Section  4.1  ),  | G expl |  n subscript G expl n |G_{\\mathrm{expl}}|\\leq n | italic_G start_POSTSUBSCRIPT roman_expl end_POSTSUBSCRIPT |  italic_n  the explanation size can vary across baselines despite their identical choice of  n n n italic_n . To understand how the quality of explanation varies when allowing larger subhypergraphs as explanation, we designed an experiment in which we directly control for the size of the final explanation and compare  Fid  KL superscript subscript Fid KL \\textrm{Fid}_{-}^{\\textrm{KL}} Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT KL end_POSTSUPERSCRIPT  (see Figure  3 ). The outperformance of our method is robust across the curve, whereas the baseline methods buy limited gains in fidelity with increasing size budget.",
            "Figure  4  shows the concept-level explanation subhypergraphs provided by our explainer for  H-RandHouse  (for more datasets see Appendix  D ). We find that  H-RandHouse s concept explanations are readily interpretable: the Class 1, 2, and 3 concepts clearly show each respective top-of-house, middle-of-house, and bottom-of-house node situated within a house-like motif. Particularly interesting is the subdivision of Class 2 into two distinct concepts: one for the anchor node that is attached to the base hypergraph (includes the attaching hyperedge), and one for the non-anchor node. This reveals that the hyperGNN implicitly represents and reasons about two types of Class 2 nodes. Furthermore, the Class 3 concept is visualized as a fragment of the house motif, suggesting that this hyperGNN does not rely on the top-of-house node to make Class 3 predictions. This mechanism is not a priori obvious, and such information could be leveraged to debug the hyperGNN. The remaining concepts corresponding to Class 0 reflect an eclectic variety, representative of the diverse neighborhoods of nodes in the random base graph.",
            "We benchmark several hyperGNN architectures on our synthetic tasks. As claimed, the synthetic hypergraphs are challenging. Table  4  shows that performance improves with stronger models, and the structure-agnostic MLP does no better than random.",
            "For consistency, all explanation methods operate over the same AllSetTransformer model for each dataset. This models task performance is reported in Table  5 . All explanation methods benefit from identical pre-processing, which reduces the search space to the computational subhypergraph. They are also subject to the same post-processing, which retain only the connected component containing the node being explained (as described in Section  4.1 ). This means the mean explanation size obtained is generally less than  n n n italic_n .",
            "We extract concepts by k-means clustering, as described in Section  4.2 . The quality of concept extraction is quantified by concept completeness, the accuracy of a decision tree classifier that optimally maps the set of concepts onto the set of class labels  (Magister et al.,  2021 ) . Optimal is defined such that each node instance, featurized only by its concept label, is mapped to a class label with high accuracy. Since the concept label is a discrete class, the decision tree classifier is optimized by performing majority vote within each concept, as proposed in Section  4.2 . We consider the concept extraction successful if its concept completeness is close to the task accuracy, since this overall procedure relies on the latent representations learned by the hyperGNN.",
            "We report concept visualizations for  H-CommHouse  (Figure  5 ),  H-TreeCycle  (Figure  6 ), and  H-TreeGrid  (Figure  7 ), analogous to Figure  4  for  H-RandHouse ."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:   Task performance (accuracy on train, validation, and test splits) for each dataset, and the concept completeness of extracted concepts. (Note we did not use a separate test split for the synthetic datasets in our experiments.) The decision tree classifier used to compute concept completeness uses the same train/validation split as the base task.",
        "table": "A2.T4.20",
        "footnotes": [],
        "references": [
            "We show that our hypergraph explainer produces high quality explanations through extensive evaluations. We test on real hypergraphs  Cora ,  CoauthorCora ,  CoauthorDBLP , and  Zoo  from the benchmark of  Chien et al. ( 2021 ) . 1 1 1 We selected the latter three hypergraphs because here the hyperGNNs outperform MLP by an appreciable margin; these are expected to be the relatively discriminating test cases for explainability, as discussed in Section  5.1  For comparison, we also selected  Cora , where this is not the case.  In Section  5.1 , we discuss why existing hypergraph datasets may not provide a sufficiently challenging setting for finding subhypergraph explanations, and design challenging synthetic hypergraph datasets to complement our evaluations. In Section  5.2 , we highlight some shortcomings of the fidelity metric used to quantitatively evaluate explanations, and propose alternatives to address them.",
            "Real hypergraphs.  On the real world hypergraphs, SHypX also outperforms all baselines. For example, in  Coauthor-Cora , we achieve  Fid  KL superscript subscript Fid KL \\textrm{Fid}_{-}^{\\textrm{KL}} Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT KL end_POSTSUPERSCRIPT  of  3  e   4 3E-4 310-4 start_ARG 3 end_ARG start_ARG  end_ARG start_ARG roman_e start_ARG - 4 end_ARG end_ARG , compared to  0.03 , 0.05 , 0.08 , 0.25 0.03 0.05 0.08 0.25 0.03,0.05,0.08,0.25 0.03 , 0.05 , 0.08 , 0.25  for HyperEX, Gradient, Attention, and Random respectively. While producing more faithful explanations, our model does not sacrifice concision: it achieves this superior fidelity with the best concision on this dataset, at average size 2.1 and density 0.28. This relative ranking between methods is consistent across all four real hypergraphs. We also observe that the simple baselines Random, Gradient, and Attention already attain competitive performance on several real hypergraphs.  Cora  is the most extreme example of this, where even Random produces faithful explanations at  Fid  KL = 0.01 superscript subscript Fid KL 0.01 \\textrm{Fid}_{-}^{\\textrm{KL}}=0.01 Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT KL end_POSTSUPERSCRIPT = 0.01 . Indeed, SHypXs mean explanation size of 1.4 suggests that oftentimes, just the nodes features, without neighborhood structure, suffice to achieve perfect predictions over  Cora . This structural degeneracy is also observed to some extent for  CoauthorCora  and  CoauthorDBLP . These results support Section  5.2 s discussion about complementing evaluations on real hypergraphs with our challenging synthetic ones, and leveraging generalized fidelity as a more discriminating metric.",
            "For consistency, all explanation methods operate over the same AllSetTransformer model for each dataset. This models task performance is reported in Table  5 . All explanation methods benefit from identical pre-processing, which reduces the search space to the computational subhypergraph. They are also subject to the same post-processing, which retain only the connected component containing the node being explained (as described in Section  4.1 ). This means the mean explanation size obtained is generally less than  n n n italic_n .",
            "Table  5  shows that across all datasets, the latents are indeed such that we can successfully extract meaningful concepts that score well on concept completeness (i.e. within a few percentage points of the task accuracy). We find that  k = 10 k 10 k=10 italic_k = 10  suffices to achieve this condition on all datasets, but that it is beneficial to increase to  k = 15 k 15 k=15 italic_k = 15  for  H-CommHouse .",
            "We report concept visualizations for  H-CommHouse  (Figure  5 ),  H-TreeCycle  (Figure  6 ), and  H-TreeGrid  (Figure  7 ), analogous to Figure  4  for  H-RandHouse .",
            "Based on these observations, we opt for hypergraph size  | G | 1 subscript G 1 |G|_{1} | italic_G | start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  (Section  5.2 ) as a cheaper and less artefact-prone measure of explanation minimality."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Fidelity and size metrics on the explanation complement, for two select datasets. We find that this can be a misleading metric.",
        "table": "A3.T5.1",
        "footnotes": [],
        "references": [
            "We report concept visualizations for  H-CommHouse  (Figure  5 ),  H-TreeCycle  (Figure  6 ), and  H-TreeGrid  (Figure  7 ), analogous to Figure  4  for  H-RandHouse .",
            "To concretely illustrate some of these failure modes, we expose the  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  scores of  H-TreeGrid  and  Coauthor-DBLP  in Table  6 . For  H-TreeGrid , the similar  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  for Gradient and our method suggest that they are comparably successful at isolating relevant information to the explanation subhypergraph. However, this does not align with our natural understanding of which explanations are more sufficient  whereas Table  1  shows that our method achieves an extremely low fidelity at mean explanation size of 15.1 and mean explanation density of 0.45, Gradient produces explanations with  Fid  A  c  c = 0.40 superscript subscript Fid A c c 0.40 \\textrm{Fid}_{-}^{Acc}=0.40 Fid start_POSTSUBSCRIPT - end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A italic_c italic_c end_POSTSUPERSCRIPT = 0.40  while being almost 3 links larger and 10 percentage points denser. For  CoauthorDBLP , our method yields the most faithful and most concise explanations (average size 2.3 and average density 0.15) of all baselines (Table  2 ). However, the small size of these explanations induces a large complement, contributing to its unfavorable  Fid + subscript Fid \\textrm{Fid}_{+} Fid start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  scores."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Ablating the choice of Gumbel-Softmax sampler to two alternatives: relax-and-thresh  (Ying et al.,  2019 )  and sparsemax  (Martins & Astudillo,  2016 ) . Here, the loss function has coefficients   pred = 1 subscript  pred 1 \\lambda_{\\textrm{pred}}=1 italic_ start_POSTSUBSCRIPT pred end_POSTSUBSCRIPT = 1  and   size = 0.005 subscript  size 0.005 \\lambda_{\\textrm{size}}=0.005 italic_ start_POSTSUBSCRIPT size end_POSTSUBSCRIPT = 0.005 . Lowest losses are in boldface.",
        "table": "A5.T6.10",
        "footnotes": [
            "",
            ""
        ],
        "references": [
            "We report concept visualizations for  H-CommHouse  (Figure  5 ),  H-TreeCycle  (Figure  6 ), and  H-TreeGrid  (Figure  7 ), analogous to Figure  4  for  H-RandHouse .",
            "In this section, we investigate the choice of sampling technique. Since this choice pertains to the optimization, we are primarily interested in which sampler achieves the lowest loss given a fixed objective function (Equation  2 ). Table  7  compares the loss attained by the Gumbel-Softmax sampler (our choice) against two alternatives, as well as reporting their respective fidelity and size metrics for reference.",
            "We performed this ablation for one synthetic ( H-RandHouse ) and one real ( zoo ) dataset. Table  7  shows that Gumbel-Softmax achieves better losses than both relax-and-thresh and sparsemax: 0.10 (vs 0.15 and 0.58) on  H-RandHouse , and 0.04 (vs 0.14 and 0.08) on  Zoo . Even without reference to the quantitative results, we know that relax-and-thresh and (to a lesser extent) sparsemax suffer from the so-called introduced evidence problem  (Dabkowski & Gal,  2017 ; Yuan et al.,  2022 ) . Because the weighted subhypergraph seen during optimization differs from the final explanation subhypergraph obtained upon binarization, these samplers can lead to highly unfaithful explanations. Though relax-and-thresh attempts to mitigate this effect with entropy loss, we find that it is insufficient to avoid this problem, particularly for hypergraphs. The sparsity properties of sparsemax make it less prone to this failure mode (it achieves a much higher rate of zero entropy loss), but does not eliminate the problem completely. Note that HyperEX  (Maleki et al.,  2023 )  is also prone to the introduced evidence problem, since it also thresholds attention weights to obtain the final explanation subhypergraph."
        ]
    },
    "id_table_8": {
        "caption": "",
        "table": "A6.T7.13",
        "footnotes": [],
        "references": [
            "Visualizing concepts by the  n n n italic_n -hop neighborhood of their representative nodes, as suggested by directly generalizing the GNN explainer of  Magister et al. ( 2021 ) , can produce crowded hypergraphs that obscure the crucial neighborhood important to that node instance. In Figure  8  and Figure  9  for  H-RandHouse  and  CoauthorCora  respectively, we demonstrate with a few examples of concepts extracted from each hypergraph. For  H-RandHouse , we see that our method (bottom row) more clearly reveals the house motif when explaining nodes located in the motif. For  CoauthorCora , the frequent appearance of the trivial subhypergraph (i.e., comprising only the node being explained) in our explanations reveals that class labels depend more strongly on features than local structure. This observation is not apparent from visualising  n n n italic_n -hop neighborhoods (top row)."
        ]
    }
}