{
    "id_table_1": {
        "caption": "Table 1:  Functions of logical form.",
        "table": "S2.T1.8",
        "footnotes": [],
        "references": [
            "To address the above challenges and meet the requirements of professional domain knowledge services, we propose  Knowledge Augmented Generation(KAG) , which fully leverages the complementary characteristics of KG and RAG techniques. More than merely integrating graph structures into the knowledge base process, it incorporates the semantic types and relationships of knowledge graph and the commonly used Logical Forms from KGQA (Knowledge Graph Question Answering) into the retrieval and generation process. As shown in Figure  1 , this framework involves the optimization of the following five modules:",
            "In this section, we will first introduce the overall framework of KAG, and then discuss five key enhancements in sections 2.1 to 2.5. As shown in Figure  1 , the KAG framework consists of three parts: KAG-Builder, KAG-Solver, and KAG-Model. The KAG-Builder is designed for building offline indexes, in this module, we proposed a  LLM Friendly Knowledge Representation framework  and  mutual-indexing between knowledge structure and text chunk . In the module KAG-Solver we introduced a  Logical-form-guided hybrid reasoning solver  that integrates LLM reasoning, knowledge reasoning, and mathematical logic reasoning. Additionally,  knowledge alignment by semantic reasoning  is used to enhance the accuracy of knowledge representation and retrieval in both KAG-Builder and KAG-Solver. The KAG-Model optimizes the capabilities needed by each module based on a general language model, thereby improving the performance of all modules.",
            "Since interactions between different modules in traditional RAG are based on vector representations of natural language, inaccuracies often arise. Inspired by the logical forms commonly used in KGQA, we designed an executable language with reasoning and retrieval capabilities. This language breaks down a question into multiple logical expressions, each of which may include functions for retrieval or logical operations. The mutual indexing described in Section 2.2 makes this process possible. Meanwhile, we designed a multi-turn solving mechanism based on reflection and global memory, inspired by ReSP [ 26 ] . The KAG solving process, as referenced in Figure  6  and Algorithm  17 , first decomposes the current question  q  u  e  r  y c  u  r q u e r subscript y c u r query_{cur} italic_q italic_u italic_e italic_r italic_y start_POSTSUBSCRIPT italic_c italic_u italic_r end_POSTSUBSCRIPT  into a list of subquestions  l  f l  i  s  t l subscript f l i s t lf_{list} italic_l italic_f start_POSTSUBSCRIPT italic_l italic_i italic_s italic_t end_POSTSUBSCRIPT  represented in logical form, and performs hybrid reasoning to solve them. If an exact answer can be obtained through multi-hop reasoning over structured knowledge, it returns the answer directly. Otherwise, it reflects on the solution results: storing the answers and retrieval results corresponding to  l  f l  i  s  t l subscript f l i s t lf_{list} italic_l italic_f start_POSTSUBSCRIPT italic_l italic_i italic_s italic_t end_POSTSUBSCRIPT  in global memory and determining whether the question is resolved. If not, it generates supplementary questions and proceeds to the next iteration. Section 2.3.1, 2.3.2 and 2.3.3 introduce logical form function for planning, logical form for reasoning and logical form for retrieval respectively. In general, the proposed logical form language has the following three advantages:",
            "Table  13  illustrates a multi-round scenario consistent with pseudocode  17 . Although first round the exact number of  plague occurrences  couldnt be determined, but we can extracted information indicates:  \"Venice, the birthplace of Antonio Vivaldi, experienced the devastating Black Death, also known as the Great Plague. This pandemic caused by Yersinia pestis led to 75 to 200 million deaths in Eurasia, peaking in Europe from 1347 to 1351. The plague brought significant upheavals in Europe. Although specific occurrence records in Venice arent detailed, its clear the city was impacted during the mid-14th century.\" . As is shown in Table  13 ,After two iterations, the answer determined is:  22 times .",
            "Logical Functions are defined as Table  1 , with each function representing an execution action. Complex problems are decomposed by planning a combination of these expressions, enabling reasoning about intricate issues.",
            "When the query statement represented by natural language is applied to the search, the logic is often fuzzy, such as  \"find a picture containing vegetables or fruits\"  and  \"find a picture containing vegetables and fruits\" . Whether text search or vector search is used, the similarity between the two queries is very high, but the corresponding answers are quite different. The same is true for problems involving logical reasoning processes such as  and  or  not , and  intersection  differences. To this end, we use logical form to express the question, so that it can express explicit semantic relations.  Similar to IRCOT, we decompose complex original problem and plan out various execution actions such as multi-step retrieval, numerical reasoning, logical reasoning, and semantic deduce. Each sub-problem is expressed using logical form functions, and dependencies between sub-questions are established through variable references. The inference resolution process for each sub-question is illustrated as Algorithm  11 . In this process, the  GraphRetrieval  module performs KG structure retrieval according to the logical form clause to obtain structured graph results. Another key module,  HybridRetrieval , combining natural language expressed sub-problems and logical functions for comprehensive retrieval of documents and sub-graph information. To understand how logical functions can be utilized to reason about complex problems, refer to the following examples as Table  14 .",
            "1) Knowledge Graph Indexing.  As is shown in Table  11 , after incorporation Knowledge Alignment into the KG mutual-indexing, the top-5 recall rates of  C  R r  e  f 3 C subscript R r e subscript f 3 CR_{ref_{3}} italic_C italic_R start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  improved by 9.2%, 28.4%, and 9.5% respectively, with an average improvement of 15.7%. As shown in Figure  9 , after enhancing knowledge alignment, the relation density is significantly increased, and the frequency-outdegree graph is shifted to the right as a whole",
            "For analyze the impact of the maximum number of iterations parameter  n n n italic_n  on the results,  L  F  S r  e  f 1 L F subscript S r e subscript f 1 LFS_{ref_{1}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  compared to  L  F  S r  e  f 3 L F subscript S r e subscript f 3 LFS_{ref_{3}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  , the F1 scores decreased by 0.6%, 1.6%, and 4.8%, respectively. Based on the experiments of  L  F  S r  e  f 3 L F subscript S r e subscript f 3 LFS_{ref_{3}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , the proportions for an iteration count of 1 were analyzed to be 97.2%, 94.8%, and 87.9%;  L  F  S  H r  e  f 1 L F S subscript H r e subscript f 1 LFSH_{ref_{1}} italic_L italic_F italic_S italic_H start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  compared to  L  F  S  H r  e  f 3 L F S subscript H r e subscript f 3 LFSH_{ref_{3}} italic_L italic_F italic_S italic_H start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  , the F1 scores decreased by 0.2%, 1.2%, and 4.4%, respectively. Based on the experiments of  L  F  S  H r  e  f 3 L F S subscript H r e subscript f 3 LFSH_{ref_{3}} italic_L italic_F italic_S italic_H start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , the proportions for an iteration count of 1 were analyzed to be 98.3%, 95.2%, and 84.1%; showing a positive correlation with the F1 score reduction. Table  13  provides a detailed analysis of the effect of iteration rounds on the solution of the final answer. Increasing the maximum number of iterations parameter facilitates the re-planning of existing information when  L  F  S r  e  f n L F subscript S r e subscript f n LFS_{ref_{n}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT  is unable to complete the solution, thereby addressing some unsolvable case.",
            "Implementing our framework requires multiple LLM calls during the construction and solving phases.  A substantial number of intermediate tokens required to be generated during the planning stage to facilitate the breakdown of sub-problems and symbolic representation, this leads to computational and economic overhead, as illustrated in Table  14 , where the problem decomposition not only outputs sub-problems but also logical functions, resulting in approximately twice as many generated tokens compared to merely decomposing the sub-problems. Meanwhile, currently, all model invocations within the KAG framework, including entity recognition, relation extraction, relation recall, and standardization, rely on large models. This multitude of models significantly increases the overall runtime. In future domain-specific implementations, tasks like relation recall, entity recognition, and standardization could be substituted with smaller, domain-specific models to enhance operational efficiency."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Commonly used semantic relations.",
        "table": "S2.T1.2.2.2.2",
        "footnotes": [],
        "references": [
            "where,  M M \\mathcal{M} caligraphic_M  represents all types defined in LLMFriSPG,  T T \\mathcal{T} caligraphic_T  represents all  EntityType (e.g., Person in Figure  2 ),  EventType  classes and all pre-defined properties that are compatible with LPG syntax declarations.  C C \\mathcal{C} caligraphic_C  represents all  ConceptType  classes, concepts and concept relations, it is worth noting that the root node of each concept tree is a  ConceptType  class that is compatible with LPG syntax(e.g., TaxoOfPerson in Figure  2 .), each concept node has a unique  ConceptType  class.    \\mathcal{\\rho} italic_  represents the inductive relations from instances to conecepts.  L L \\mathcal{L} caligraphic_L  represents all executable rules defined on logical relations and logical concepts. For   t  T for-all t T \\mathcal{\\forall}{t}\\in\\mathcal{T}  italic_t  caligraphic_T :",
            "As is show in Figure  2 , where,  p t subscript p t p_{t} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  represents all properties and relations of type  t t t italic_t , and  p t c superscript subscript p t c p_{t}^{c} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT  represents the domain experts pre-defined part,  p t f superscript subscript p t f p_{t}^{f} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT  represents the part added in an ad-hoc manner,  p t b superscript subscript p t b p_{t}^{b} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT  represents the system built-in properties, such as  supporting_chunks, descripiton, summary  and  belongTo .  For any instance  e i subscript e i e_{i} italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , denote  t  y  p  e  o  f  ( e i ) t y p e o f subscript e i typeof(e_{i}) italic_t italic_y italic_p italic_e italic_o italic_f ( italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  as  t k subscript t k t_{k} italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , and  supporting_chunks  represents the set of all text chunks containing instance  e i subscript e i {e_{i}} italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , the user defines the chunk generation strategy and the maximum length of the chunk in KAG builder phase,  description  represents the general descriptive information specific to class  t k subscript t k {t_{k}} italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT . It is worth noting that the meaning of  description  added to the type  t k subscript t k {t_{k}} italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT  and the instance  e i subscript e i {e_{i}} italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is different, when  description  is attached to  t k subscript t k {t_{k}} italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , it signifies the global description for that type. Conversely, when it is associated with an instance  e i subscript e i {e_{i}} italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , it represents the general descriptive information for  e i subscript e i {e_{i}} italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  consistent with the orignal document context,  description  can effectively assist LLM in understanding the precise meaning of a specific instance or type, and can be used in tasks such as information extraction, entity linking, and summary generation.  summary  represents the summary of  e i subscript e i {e_{i}} italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  or  r j subscript r j {r_{j}} italic_r start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT  in the original document context.  belongTo  represents the inductive semantics from instance to concept. Each  EntityType  or  EventType  can be associated with a  ConceptType  through  belongTo . It is worth noting that,  1)   T T \\mathcal{T} caligraphic_T  and  C C \\mathcal{C} caligraphic_C   have different functions.  The statement  t t {t} italic_t  adopts the object-oriented principle to better match the representation of the LPG [ 21 ] , and  C C \\mathcal{C} caligraphic_C  is managed by a text-based concept tree. This article will not introduce the SPG semantics in detail.  2)  p t c superscript subscript p t c p_{t}^{c} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT  and  p t f superscript subscript p t f p_{t}^{f} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT  can be instantiated separately . That is, they share the same class declaration, but in the instance storage space, pre-defined static properties and realtime-added dynamic properties can coexist, and we also support instantiating only one of them. This approach can better balance the application scenarios of professional decision-making and information retrieval. General information retrieval scenarios mainly instantiate dynamic properties, while professional decision-making application scenarios mainly instantiate static properties. Users can strike a balance between ease of use and professionalism based on business scenario requirements.  3)  p t c superscript subscript p t c p_{t}^{c} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT  and  p t f superscript subscript p t f p_{t}^{f} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT  share the same conceptual terminology . Concepts are general common sense knowledge that is independent of specific documents or instances. Different instances are linked to the same concept node to achieve the purpose of classifying the instances. We can achieve semantic alignment between LLM and instances through concept graphs, and concepts can also be used as navigation for knowledge retrieval. the details are shown in section 2.4 and 2.3.",
            "Given a dataset, we use fine-tuning-free LLM(such as GPT-3.5, DeepSeek, QWen, etc,.) or our fine-tuned model Hum to extract entities, events, concepts and relations to construct  K  G f  r K subscript G f r KG_{fr} italic_K italic_G start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT , subsequently, construct the mutual-indexing structure between  K  G f  r K subscript G f r KG_{fr} italic_K italic_G start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT  and  R  C R C RC italic_R italic_C , enabling cross-document links through entities and relations. This process includes three steps. First, it extracts the entity set  E = { e 1 , e 2 , e 3 , ... } E subscript e 1 subscript e 2 subscript e 3 ... E=\\{e_{1},e_{2},e_{3},...\\} italic_E = { italic_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_e start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_e start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , ... }  chunk by chunk, second, extracts the event set  E  V = { e  v 1 , e  v 2 , e  v 3 , ... } E V e subscript v 1 e subscript v 2 e subscript v 3 ... {EV}=\\{{ev}_{1},{ev}_{2},{ev}_{3},...\\} italic_E italic_V = { italic_e italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_e italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_e italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , ... }  associated to all entities and iteratively extracts the relation set  R = { r 1 , r 2 , r 3 , ... } R subscript r 1 subscript r 2 subscript r 3 ... R=\\{r_{1},r_{2},r_{3},...\\} italic_R = { italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , ... }  between all entities in  E E E italic_E , finally, completes all hypernym relations between the instance and its  spgClass . To provide more convenience for the subsequent Knowledge Alignment phase, and overcome the problem of low discrimination of knowledge phrases such as Wikidata [ 22 ]  and ConceptNet [ 23 ] , in the entity extraction phase, we use LLMs to generate built-in properties  description, summary, semanticType, spgClass, descripitonOfSemanticType  by default for each instance  e  at one time, as shown in Figure  2 , we store them in the  e  instance storage according to the structure of  e.description,e.summary, <e, belongTo, semanticType> and <e, hasClass, spgClass> .",
            "When openIE is applied to professional domains, irrelevant noise will be introduced. Previous researches [ 3 ,  5 ,  24 ]  have shown that noisy and irrelevant corpora can significantly undermine the performance of LLMs. It is a challenge to align the granularity of extracted information and domain knowledge. The domain knowledge alignment capabilities in KAG include:  1) Domain term and concept injection . We use an iterative extraction approach, First, we store domain concepts and terms with  description  in KG storage. Second, we extract all instances in the document through openIE, then we perform vector retrieval to obtain all possible concept and term sets  E d subscript E d E_{d} italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT . Finally, we add  E d subscript E d E_{d} italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT  to the extraction prompt and perform another extraction to obtain a set  E d a superscript subscript E d a E_{d}^{a} italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT  that is mostly aligned with the domain knowledge.  2) Schema-constraint Extraction . In the vertical professional domains, the data structure between multiple documents in each data source such as drug instructions, physical examination reports, government affairs, online order data, structured data tables, etc. has strong consistency, and is more suitable for information extraction with schema-constraint, structured Extraction also makes it easier to do knowledge management and quality improvement. For detailed information about knowledge construction based on Schema-constraint, please refer to the SPG 1 1 1 Official site of SPG: https://spg.openkg.cn/en-US  and OneKE [ 25 ] . This article will not introduce it in detail. It is worth noting that, as shown in figure  2 , for the same entity type, such as  Person , we can pre-define properties and relations such as  name, gender, placeOfBirth, (Person, hasFather, Person), (Person, hasFriend, Person) , and can also extract tripples directly such as  (Jay Chou, spgClass, Person), (Jay Chou, constellation, Capricorn), (Jay Chou, record company, Universal Music Group)  through openIE.  3) Pre-defined Knowledge Structures By Document Type . Professional documents such as drug instructions, government affairs documents, and legal definitions generally have a relatively standardized document structure. Each type of document can be defined as an entity type, and different paragraphs are different properties of the entity. Taking government affairs as an example, we can pre-define the GovernmentAffair EntityType and properites such as  administrative divisions, service procedures, required materials, service locations, and target groups . The divided chunks are the values of different properties. If the user asks  \"What materials are needed to apply for housing provident fund in Xihu District?\" , you can directly take out the chunk corresponding to property  required materials  to answer the question, avoiding the possible hallucinations caused by LLM re-generation.",
            "To solve these problems, we propose a solution that leverages concept graphs to enhance offline indexing and online retrieval through semantic reasoning. This involves tasks such as  knowledge instance standardization, instance-to-concept linking, semantic relation completion, and domain knowledge injection . As described in section 2.2.2, we added descriptive text information to each instance, concept or relation in the extraction phase to enhance its interpretability and contextual relevance. Meanwhile, as described in section 2.2.3, KAG supports the injection of domain concepts and terminology knowledge to reduce the noise problem caused by the mismatch of knowledge granularity in vertical domains. The goal of concept reasoning is to make full use of vector retrieval and concept reasoning to complete concept relations based on the aforementioned knowledge structure to enhance the accuracy and connectivity of the domain KG. Refer to the definition of SPG concept semantics 2 2 2 Semantic Classification of Concept: https://openspg.yuque.com/ndx6g9/ps5q6b/fe5p4nh1zhk6p1d8 , as is shown in Table  2 , we have summarized six semantic relations commonly required for retrieval and reasoning. Additional semantic relations can be added based on the specific requirements of the actual scenario.",
            "Complete concepts and relations between concepts . During the extraction process, we use concept reasoning to complete all  hypernym  and  isA relation s between semanticType and spgClass. As is shown in Figure  5  and Table  2 , we can obtain the semanticType of  Chamber  is  Legislative Body , and its  spgClass  is  Organization  in the extraction phase. Through semantic completion, we can get  <Legislative Body, isA, Government Agency>, <Government Agency, isA, Organization> . Through semantic completion, the triple information of  K  G f  r K subscript G f r KG_{fr} italic_K italic_G start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT  space is more complete and the connectivity of nodes is stronger."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Enhancement of natural language understanding capabilities in different LLMs by KAG. The experimental results are based on the open-compass framework and tested using the gen mode. The evaluation metrics for C3, WSC, Lambda, and Race are ACC. XSum and Lcsts are measured using ROUGE-1. Race includes Race-middle and Race-high, and their average is taken.",
        "table": "S2.T1.3.3.1.1",
        "footnotes": [],
        "references": [
            "In order to more accurately define the hierarchical representation of information and knowledge, as shown in  3 , we denote  K  G c  s K subscript G c s KG_{cs} italic_K italic_G start_POSTSUBSCRIPT italic_c italic_s end_POSTSUBSCRIPT  as  knowledge layer , which represents the domain knowledge that complies with the domain schema constraints and has been summarized, integrated, and evaluated. denote  K  G f  r K subscript G f r KG_{fr} italic_K italic_G start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT  as  graph information layer , which represents the graph data such as entities and relations obtained through information extraction. denote  R  C R C RC italic_R italic_C  as  raw chunks layer , which represents the original document chunks after semantic segmentation. the  K  G c  s K subscript G c s KG_{cs} italic_K italic_G start_POSTSUBSCRIPT italic_c italic_s end_POSTSUBSCRIPT  layer fully complies with the SPG semantic specification and supports knowledge construction and logical rule definition with strict schema constraints, SPG requires that domain knowledge must have pre-defined schema constraints. It has high knowledge accuracy and logical rigor. However, due to its heavy reliance on manual annotation, the labor cost of construction is relatively high and the information completeness is insufficient.  K  G f  r K subscript G f r KG_{fr} italic_K italic_G start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT  shares the same EntityTypes, Eventtypes and Conceptual system with  K  G c  s K subscript G c s KG_{cs} italic_K italic_G start_POSTSUBSCRIPT italic_c italic_s end_POSTSUBSCRIPT , and provides effective information supplement for  K  G c  s K subscript G c s KG_{cs} italic_K italic_G start_POSTSUBSCRIPT italic_c italic_s end_POSTSUBSCRIPT . Meanwhile, the  supporting_chunks, summary , and  description  edges built between  K  G f  r K subscript G f r KG_{fr} italic_K italic_G start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT  and  R  C R C RC italic_R italic_C  form an inverted index based on graph structure, making  R  C R C RC italic_R italic_C  an effective original-text-context supplement for  K  G f  r K subscript G f r KG_{fr} italic_K italic_G start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT  and with high information completeness. As is show in the right part of figure  3 , in a specific domain application,  R  ( K  G c  s ) R K subscript G c s R(KG_{cs}) italic_R ( italic_K italic_G start_POSTSUBSCRIPT italic_c italic_s end_POSTSUBSCRIPT ) ,  R  ( K  G f  r ) R K subscript G f r R(KG_{fr}) italic_R ( italic_K italic_G start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT ) , and  R  ( R  C ) R R C R(RC) italic_R ( italic_R italic_C )  respectively represent their knowledge coverage in solving the target domain problems. If the application has higher requirements for knowledge accuracy and logic rigorousness, it is necessary to  build more domain structured knowledge and consume more expert manpower to increase the coverage of  R  ( K  G c  s ) R K subscript G c s R(KG_{cs}) italic_R ( italic_K italic_G start_POSTSUBSCRIPT italic_c italic_s end_POSTSUBSCRIPT ) . On the contrary, if the application has higher requirements for retrieval efficiency and a certain degree of information loss or error tolerance, it is necessary to increase the coverage of  R  ( K  G f  r ) R K subscript G f r R(KG_{fr}) italic_R ( italic_K italic_G start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT )  to fully utilize KAGs automated knowledge construction capabilities and reduce expert manpower consumption.",
            "Table  13  illustrates a multi-round scenario consistent with pseudocode  17 . Although first round the exact number of  plague occurrences  couldnt be determined, but we can extracted information indicates:  \"Venice, the birthplace of Antonio Vivaldi, experienced the devastating Black Death, also known as the Great Plague. This pandemic caused by Yersinia pestis led to 75 to 200 million deaths in Eurasia, peaking in Europe from 1347 to 1351. The plague brought significant upheavals in Europe. Although specific occurrence records in Venice arent detailed, its clear the city was impacted during the mid-14th century.\" . As is shown in Table  13 ,After two iterations, the answer determined is:  22 times .",
            "We fine-tuned six foundational models: qwen2, llama2, baichuan2, llama3, mistral, phi3, and used six understanding benchmarks recorded on OpenCompass for performance validation. The table  3  shows that the KAG-Model has a significant improvement in NLU tasks.",
            "For analyze the impact of the maximum number of iterations parameter  n n n italic_n  on the results,  L  F  S r  e  f 1 L F subscript S r e subscript f 1 LFS_{ref_{1}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  compared to  L  F  S r  e  f 3 L F subscript S r e subscript f 3 LFS_{ref_{3}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  , the F1 scores decreased by 0.6%, 1.6%, and 4.8%, respectively. Based on the experiments of  L  F  S r  e  f 3 L F subscript S r e subscript f 3 LFS_{ref_{3}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , the proportions for an iteration count of 1 were analyzed to be 97.2%, 94.8%, and 87.9%;  L  F  S  H r  e  f 1 L F S subscript H r e subscript f 1 LFSH_{ref_{1}} italic_L italic_F italic_S italic_H start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  compared to  L  F  S  H r  e  f 3 L F S subscript H r e subscript f 3 LFSH_{ref_{3}} italic_L italic_F italic_S italic_H start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  , the F1 scores decreased by 0.2%, 1.2%, and 4.4%, respectively. Based on the experiments of  L  F  S  H r  e  f 3 L F S subscript H r e subscript f 3 LFSH_{ref_{3}} italic_L italic_F italic_S italic_H start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , the proportions for an iteration count of 1 were analyzed to be 98.3%, 95.2%, and 84.1%; showing a positive correlation with the F1 score reduction. Table  13  provides a detailed analysis of the effect of iteration rounds on the solution of the final answer. Increasing the maximum number of iterations parameter facilitates the re-planning of existing information when  L  F  S r  e  f n L F subscript S r e subscript f n LFS_{ref_{n}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT  is unable to complete the solution, thereby addressing some unsolvable case."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Enhancement of natural language Inference capabilities in different LLMs by KAG. The evaluation metrics for CMNLI, OCNLI, SIQA are measured with accuracy.",
        "table": "S2.T1.6.6.3.3",
        "footnotes": [],
        "references": [
            "As illustrated in Figure  4 , KAG-Builder consists of three coherent processes: structured information acquisition, knowledge semantic alignment and graph storage writer. The main goals of this module include: 1) building a mutual-indexing between the graph structure and the text chunk to add more descriptive context to the graph structure, 2) using the concept semantic graph to align different knowledge granularities to reduce noise and increase graph connectivity.",
            "When the query statement represented by natural language is applied to the search, the logic is often fuzzy, such as  \"find a picture containing vegetables or fruits\"  and  \"find a picture containing vegetables and fruits\" . Whether text search or vector search is used, the similarity between the two queries is very high, but the corresponding answers are quite different. The same is true for problems involving logical reasoning processes such as  and  or  not , and  intersection  differences. To this end, we use logical form to express the question, so that it can express explicit semantic relations.  Similar to IRCOT, we decompose complex original problem and plan out various execution actions such as multi-step retrieval, numerical reasoning, logical reasoning, and semantic deduce. Each sub-problem is expressed using logical form functions, and dependencies between sub-questions are established through variable references. The inference resolution process for each sub-question is illustrated as Algorithm  11 . In this process, the  GraphRetrieval  module performs KG structure retrieval according to the logical form clause to obtain structured graph results. Another key module,  HybridRetrieval , combining natural language expressed sub-problems and logical functions for comprehensive retrieval of documents and sub-graph information. To understand how logical functions can be utilized to reason about complex problems, refer to the following examples as Table  14 .",
            "Semantic reasoning is one of the core ability required in KAG process, we use NLI tasks and general reasoning Q&A tasks to evaluate the ability of our model, the results are as shown in Table  4  and Table  5 . The evaluation results indicates that our KAG-Model demonstrates a significant improvement in tasks related with semantic reasoning: First, Table  5  shows that on the Hypernym Discovery task(which is consistent in form with the reasoning required in semantic enhanced indexing and retrieval.), our fine-tuned KAG-llama model outperforms Llama3 and ChatGPT-3.5 significantly. In addition, the better performance of our model on CMNLI, OCNLI and SIQA compared with Llama3 in Table  4  shows that our model has good capabilities in general logical reasoning.",
            "Implementing our framework requires multiple LLM calls during the construction and solving phases.  A substantial number of intermediate tokens required to be generated during the planning stage to facilitate the breakdown of sub-problems and symbolic representation, this leads to computational and economic overhead, as illustrated in Table  14 , where the problem decomposition not only outputs sub-problems but also logical functions, resulting in approximately twice as many generated tokens compared to merely decomposing the sub-problems. Meanwhile, currently, all model invocations within the KAG framework, including entity recognition, relation extraction, relation recall, and standardization, rely on large models. This multitude of models significantly increases the overall runtime. In future domain-specific implementations, tasks like relation recall, entity recognition, and standardization could be substituted with smaller, domain-specific models to enhance operational efficiency."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Hypernym Discovery performance comparison on SemEval2018-Task9 dataset, measured in MRR.",
        "table": "S2.T1.7.7.1.1",
        "footnotes": [],
        "references": [
            "The process of enhancing indexing through semantic reasoning, as shown in Figure  5  , specifically implemented as predicting semantic relations or related knowledge elements among index items using LLM, encompassing four strategies:",
            "Predict relations between instances and concepts . For each knowledge instance (such as event, entity), predict its corresponding concept and add the derived triple  < e i , b e l o n g T o , c j > <e_{i},\\ belongTo,\\ c_{j}> < italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b italic_e italic_l italic_o italic_n italic_g italic_T italic_o , italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT >  to the knowledge index. As is shown in Figure  5 , < Chamber, belongTo, Legislative Body > means that the Chamber belongs to Legislative Body in classification.",
            "Complete concepts and relations between concepts . During the extraction process, we use concept reasoning to complete all  hypernym  and  isA relation s between semanticType and spgClass. As is shown in Figure  5  and Table  2 , we can obtain the semanticType of  Chamber  is  Legislative Body , and its  spgClass  is  Organization  in the extraction phase. Through semantic completion, we can get  <Legislative Body, isA, Government Agency>, <Government Agency, isA, Organization> . Through semantic completion, the triple information of  K  G f  r K subscript G f r KG_{fr} italic_K italic_G start_POSTSUBSCRIPT italic_f italic_r end_POSTSUBSCRIPT  space is more complete and the connectivity of nodes is stronger.",
            "Semantic reasoning is one of the core ability required in KAG process, we use NLI tasks and general reasoning Q&A tasks to evaluate the ability of our model, the results are as shown in Table  4  and Table  5 . The evaluation results indicates that our KAG-Model demonstrates a significant improvement in tasks related with semantic reasoning: First, Table  5  shows that on the Hypernym Discovery task(which is consistent in form with the reasoning required in semantic enhanced indexing and retrieval.), our fine-tuned KAG-llama model outperforms Llama3 and ChatGPT-3.5 significantly. In addition, the better performance of our model on CMNLI, OCNLI and SIQA compared with Llama3 in Table  4  shows that our model has good capabilities in general logical reasoning."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Performance comparison on CMedQA & BioASQ. \"CP\" indicates \"continual pre-trained\". We consider continual pre-training as a basic method of domain knowledge infusion, on par with other retrieval-based methods. Consequently, we do not report on the outcomes of hybrid approaches.",
        "table": "S2.T1.8.8.1.1",
        "footnotes": [],
        "references": [
            "Since interactions between different modules in traditional RAG are based on vector representations of natural language, inaccuracies often arise. Inspired by the logical forms commonly used in KGQA, we designed an executable language with reasoning and retrieval capabilities. This language breaks down a question into multiple logical expressions, each of which may include functions for retrieval or logical operations. The mutual indexing described in Section 2.2 makes this process possible. Meanwhile, we designed a multi-turn solving mechanism based on reflection and global memory, inspired by ReSP [ 26 ] . The KAG solving process, as referenced in Figure  6  and Algorithm  17 , first decomposes the current question  q  u  e  r  y c  u  r q u e r subscript y c u r query_{cur} italic_q italic_u italic_e italic_r italic_y start_POSTSUBSCRIPT italic_c italic_u italic_r end_POSTSUBSCRIPT  into a list of subquestions  l  f l  i  s  t l subscript f l i s t lf_{list} italic_l italic_f start_POSTSUBSCRIPT italic_l italic_i italic_s italic_t end_POSTSUBSCRIPT  represented in logical form, and performs hybrid reasoning to solve them. If an exact answer can be obtained through multi-hop reasoning over structured knowledge, it returns the answer directly. Otherwise, it reflects on the solution results: storing the answers and retrieval results corresponding to  l  f l  i  s  t l subscript f l i s t lf_{list} italic_l italic_f start_POSTSUBSCRIPT italic_l italic_i italic_s italic_t end_POSTSUBSCRIPT  in global memory and determining whether the question is resolved. If not, it generates supplementary questions and proceeds to the next iteration. Section 2.3.1, 2.3.2 and 2.3.3 introduce logical form function for planning, logical form for reasoning and logical form for retrieval respectively. In general, the proposed logical form language has the following three advantages:",
            "In the retrieval phase, we utilize semantic relation reasoning to search the KG index based on the phrases and types in the logical form. For the types, mentions or relations in the logical form, we employ the method of combining semantic relation reasoning with similarity retrieval to replace the traditional similarity retrieval method. This retrieval method makes the retrieval path professional and logical, so as to obtain the correct answer. First, the hybrid reasoning performs precise type matching and entity linking. If the type matching fails, then, semantic reasoning is performed. As shown in Figure  6 , if the type  Political Party  fails to match, semantic reasoning is used to predict that  Political Party  contains  Political Faction , and reasoning or path calculation is performed starting from  Political Faction .       Take another example. If the user query  q 1 subscript q 1 q_{1} italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  is  \"Which public places can cataract patients go for leisure?\"  and the document content  d 2 subscript d 2 d_{2} italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  is  \"The museum is equipped with facilities to provide barrier-free visiting experience services such as touch, voice interpretation, and fully automatic guided tours for the visually impaired.\" , It is almost impossible to retrieve  d 2 subscript d 2 d_{2} italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  based on the vector similarity with  q 1 subscript q 1 q_{1} italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT . However, it is easier to retrieve  d 2 subscript d 2 d_{2} italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  through the semantic relation of  <cataract patient, isA, visually impaired> .",
            "We select two biomedical question-answering datasets, CMedQA [ 29 ]  and BioASQ [ 30 ] , for evaluating our model. CMedQA is a comprehensive dataset of Chinese medical questions and answers, while BioASQ is an English biomedical dataset. We randomly choose 1,000 instances from each for testing. For CMedQA, we employ the answer texts from the non-selected Q&A pairs as corpora to construct a KG in a weakly supervised manner. Similarly, with BioASQ, we use all the provided reference passages as the domain-specific corpora. Experimental results, as shown in Table  6 , demonstrate significant enhancement in generation performance. For more details on the specific implementation process, please refer to our paper [ 31 ]"
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  In RAG for Multi-Hop QA settings, performance comparison across different datasets using different LLMs.",
        "table": "S2.T2.1",
        "footnotes": [],
        "references": [
            "Since interactions between different modules in traditional RAG are based on vector representations of natural language, inaccuracies often arise. Inspired by the logical forms commonly used in KGQA, we designed an executable language with reasoning and retrieval capabilities. This language breaks down a question into multiple logical expressions, each of which may include functions for retrieval or logical operations. The mutual indexing described in Section 2.2 makes this process possible. Meanwhile, we designed a multi-turn solving mechanism based on reflection and global memory, inspired by ReSP [ 26 ] . The KAG solving process, as referenced in Figure  6  and Algorithm  17 , first decomposes the current question  q  u  e  r  y c  u  r q u e r subscript y c u r query_{cur} italic_q italic_u italic_e italic_r italic_y start_POSTSUBSCRIPT italic_c italic_u italic_r end_POSTSUBSCRIPT  into a list of subquestions  l  f l  i  s  t l subscript f l i s t lf_{list} italic_l italic_f start_POSTSUBSCRIPT italic_l italic_i italic_s italic_t end_POSTSUBSCRIPT  represented in logical form, and performs hybrid reasoning to solve them. If an exact answer can be obtained through multi-hop reasoning over structured knowledge, it returns the answer directly. Otherwise, it reflects on the solution results: storing the answers and retrieval results corresponding to  l  f l  i  s  t l subscript f l i s t lf_{list} italic_l italic_f start_POSTSUBSCRIPT italic_l italic_i italic_s italic_t end_POSTSUBSCRIPT  in global memory and determining whether the question is resolved. If not, it generates supplementary questions and proceeds to the next iteration. Section 2.3.1, 2.3.2 and 2.3.3 introduce logical form function for planning, logical form for reasoning and logical form for retrieval respectively. In general, the proposed logical form language has the following three advantages:",
            "Table  13  illustrates a multi-round scenario consistent with pseudocode  17 . Although first round the exact number of  plague occurrences  couldnt be determined, but we can extracted information indicates:  \"Venice, the birthplace of Antonio Vivaldi, experienced the devastating Black Death, also known as the Great Plague. This pandemic caused by Yersinia pestis led to 75 to 200 million deaths in Eurasia, peaking in Europe from 1347 to 1351. The plague brought significant upheavals in Europe. Although specific occurrence records in Venice arent detailed, its clear the city was impacted during the mid-14th century.\" . As is shown in Table  13 ,After two iterations, the answer determined is:  22 times .",
            "As shown in Figure  7 , the processes of indexing and QA each consist of similar steps. Both of the two pipelines can be abstracted as  classify, mention detection, mention relation detection, semantic alignment, embedding , and  chunk, instance, or query-focused summary . Among these,  classify, mention detection , and  mention relation detection  can be categorized as NLU, while  semantic alignment  and  embedding  can be grouped under NLI. Finally, the  chunk, instance or query-focused summary  can be classified under NLG. Thus, we can conclude that the three fundamental capabilities of natural language processing that a RAG system relies on are NLU, NLI, and NLG.",
            "As shown in experiment results in Table  7 , we draw the following conclusions:  (1) OneGen demonstrates efficacy in  R  G  R G {R\\rightarrow G} italic_R  italic_G  task, and joint training of retrieval and generation yields performance gains on the RAG task. The Self-RAG endows LLMs with self-assessment and adaptive retrieval, while OneGen adds self-retrieval. Our method outperforms the original Self-RAG across all datasets, especially achieving improvements of 3.1pt on Pub dataset and 2.8pt on ARC dataset, validating the benefits of joint training.  (2) OneGen is highly efficient in training, with instruction-finetuned LLMs showing strong retrieval capabilities with minimal additional tuning. It requires less and lower-quality retrieval data, achieving comparable performance with just 60K noisy samples and incomplete documents, without synthetic data. For more details on the specific implementation process, please refer to paper [ 32 ]"
        ]
    },
    "id_table_8": {
        "caption": "Table 8:  The end-to-end generation performance of different RAG models on three multi-hop Q&A datasets. The values in  bold  and  underline  are the best and second best indicators respectively.",
        "table": "S2.T2.1.2.1.2.1",
        "footnotes": [],
        "references": [
            "The end-to-end Q&A performance is shown in Table  8 . Within the RAG frameworks leveraging ChatGPT-3.5 as backbone model, HippoRAG demonstrates superior performance compared to NativeRAG. HippoRAG employs a human long-term memory strategy that facilitates the continuous integration of knowledge from external documents into LLMs, thereby significantly enhancing Q&A capabilities. However, given the substantial economic costs associated with utilizing ChatGPT-3.5, we opted to use the DeepSeek-V2 API as a viable alternative. On average, the performance of the IRCoT + HippoRAG configuration utilizing the DeepSeek-V2 API slightly surpasses that of ChatGPT-3.5. Our constructed framework KAG shows significant performance improvement compared to IRCoT + HippoRAG, with EM increases of 11.5%, 19.8%, and 10.5% on HotpotQA, 2WikiMultiHopQA, and MuSiQue respectively, and F1 improvements of 12.5%, 19.1%, and 12.2%. These advancements in end-to-end performance can largely be attributed to the development of more effective indexing, knowledge alignment and hybrid solving libraries within our framework.  We evaluate the effectiveness of the single-step retriever and multi-step retriever, with the retrieval performance shown in Table  9 . From the experimental results, it is evident that the multi-step retriever generally outperforms the single-step retriever. Analysis reveals that the content retrieved by the single-step retriever exhibits very high similarity, resulting in an inability to use the single-step retrieval outcomes to derive answers for certain data that require reasoning. The multi-step retriever alleviates this issue. Our proposed KAG framework directly utilizes the multi-step retriever and significantly enhances retrieval performance through strategies such as mutual-indexing, logical form solving, and knowledge alignment."
        ]
    },
    "id_table_9": {
        "caption": "Table 9:  The performance of different retrieval models on three multi-hop Q&A datasets",
        "table": "S2.T2.1.3.2.2.1",
        "footnotes": [],
        "references": [
            "The end-to-end Q&A performance is shown in Table  8 . Within the RAG frameworks leveraging ChatGPT-3.5 as backbone model, HippoRAG demonstrates superior performance compared to NativeRAG. HippoRAG employs a human long-term memory strategy that facilitates the continuous integration of knowledge from external documents into LLMs, thereby significantly enhancing Q&A capabilities. However, given the substantial economic costs associated with utilizing ChatGPT-3.5, we opted to use the DeepSeek-V2 API as a viable alternative. On average, the performance of the IRCoT + HippoRAG configuration utilizing the DeepSeek-V2 API slightly surpasses that of ChatGPT-3.5. Our constructed framework KAG shows significant performance improvement compared to IRCoT + HippoRAG, with EM increases of 11.5%, 19.8%, and 10.5% on HotpotQA, 2WikiMultiHopQA, and MuSiQue respectively, and F1 improvements of 12.5%, 19.1%, and 12.2%. These advancements in end-to-end performance can largely be attributed to the development of more effective indexing, knowledge alignment and hybrid solving libraries within our framework.  We evaluate the effectiveness of the single-step retriever and multi-step retriever, with the retrieval performance shown in Table  9 . From the experimental results, it is evident that the multi-step retriever generally outperforms the single-step retriever. Analysis reveals that the content retrieved by the single-step retriever exhibits very high similarity, resulting in an inability to use the single-step retrieval outcomes to derive answers for certain data that require reasoning. The multi-step retriever alleviates this issue. Our proposed KAG framework directly utilizes the multi-step retriever and significantly enhances retrieval performance through strategies such as mutual-indexing, logical form solving, and knowledge alignment.",
            "1) Knowledge Graph Indexing.  As is shown in Table  11 , after incorporation Knowledge Alignment into the KG mutual-indexing, the top-5 recall rates of  C  R r  e  f 3 C subscript R r e subscript f 3 CR_{ref_{3}} italic_C italic_R start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  improved by 9.2%, 28.4%, and 9.5% respectively, with an average improvement of 15.7%. As shown in Figure  9 , after enhancing knowledge alignment, the relation density is significantly increased, and the frequency-outdegree graph is shifted to the right as a whole"
        ]
    },
    "id_table_10": {
        "caption": "Table 10:  The end-to-end generation performance of different model methods on three multi-hop Q&A datasets. The backbone model is DeepSeek-V2 API. As is described in Algorithm  17 ,  r  e  f 3 r e subscript f 3 ref_{3} italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT  represents a maximum of 3 rounds of reflection, and  r  e  f 1 r e subscript f 1 ref_{1} italic_r italic_e italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  represents a maximum of 1 round, which means that no reflection is introduced.",
        "table": "S2.T2.1.4.3.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_11": {
        "caption": "Table 11:  The recall performance of different methods across three datasets is presented. The answers to some sub-questions in the  L  F  S r  e  f n L F subscript S r e subscript f n LFS_{ref_{n}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT  method use KG reasoning without recalling supporting chunks, which is not comparable to other methods in terms of recall rate. BackBone model is DeepSeek-V2 API.",
        "table": "S2.T2.1.5.4.2.1",
        "footnotes": [],
        "references": [
            "When the query statement represented by natural language is applied to the search, the logic is often fuzzy, such as  \"find a picture containing vegetables or fruits\"  and  \"find a picture containing vegetables and fruits\" . Whether text search or vector search is used, the similarity between the two queries is very high, but the corresponding answers are quite different. The same is true for problems involving logical reasoning processes such as  and  or  not , and  intersection  differences. To this end, we use logical form to express the question, so that it can express explicit semantic relations.  Similar to IRCOT, we decompose complex original problem and plan out various execution actions such as multi-step retrieval, numerical reasoning, logical reasoning, and semantic deduce. Each sub-problem is expressed using logical form functions, and dependencies between sub-questions are established through variable references. The inference resolution process for each sub-question is illustrated as Algorithm  11 . In this process, the  GraphRetrieval  module performs KG structure retrieval according to the logical form clause to obtain structured graph results. Another key module,  HybridRetrieval , combining natural language expressed sub-problems and logical functions for comprehensive retrieval of documents and sub-graph information. To understand how logical functions can be utilized to reason about complex problems, refer to the following examples as Table  14 .",
            "1) Knowledge Graph Indexing.  As is shown in Table  11 , after incorporation Knowledge Alignment into the KG mutual-indexing, the top-5 recall rates of  C  R r  e  f 3 C subscript R r e subscript f 3 CR_{ref_{3}} italic_C italic_R start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  improved by 9.2%, 28.4%, and 9.5% respectively, with an average improvement of 15.7%. As shown in Figure  9 , after enhancing knowledge alignment, the relation density is significantly increased, and the frequency-outdegree graph is shifted to the right as a whole"
        ]
    },
    "id_table_12": {
        "caption": "Table 12:  Ablation Experiments of KAG in E-Goverment Q&A.",
        "table": "S2.T2.1.6.5.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_13": {
        "caption": "Table 13:  An example of using logical-from to guide question planning, reasoning, retrieval, and answer generation, and using multiple rounds of reflection to rephrase questions.",
        "table": "S2.T2.1.7.6.2.1",
        "footnotes": [],
        "references": [
            "Table  13  illustrates a multi-round scenario consistent with pseudocode  17 . Although first round the exact number of  plague occurrences  couldnt be determined, but we can extracted information indicates:  \"Venice, the birthplace of Antonio Vivaldi, experienced the devastating Black Death, also known as the Great Plague. This pandemic caused by Yersinia pestis led to 75 to 200 million deaths in Eurasia, peaking in Europe from 1347 to 1351. The plague brought significant upheavals in Europe. Although specific occurrence records in Venice arent detailed, its clear the city was impacted during the mid-14th century.\" . As is shown in Table  13 ,After two iterations, the answer determined is:  22 times .",
            "For analyze the impact of the maximum number of iterations parameter  n n n italic_n  on the results,  L  F  S r  e  f 1 L F subscript S r e subscript f 1 LFS_{ref_{1}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  compared to  L  F  S r  e  f 3 L F subscript S r e subscript f 3 LFS_{ref_{3}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  , the F1 scores decreased by 0.6%, 1.6%, and 4.8%, respectively. Based on the experiments of  L  F  S r  e  f 3 L F subscript S r e subscript f 3 LFS_{ref_{3}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , the proportions for an iteration count of 1 were analyzed to be 97.2%, 94.8%, and 87.9%;  L  F  S  H r  e  f 1 L F S subscript H r e subscript f 1 LFSH_{ref_{1}} italic_L italic_F italic_S italic_H start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  compared to  L  F  S  H r  e  f 3 L F S subscript H r e subscript f 3 LFSH_{ref_{3}} italic_L italic_F italic_S italic_H start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT  , the F1 scores decreased by 0.2%, 1.2%, and 4.4%, respectively. Based on the experiments of  L  F  S  H r  e  f 3 L F S subscript H r e subscript f 3 LFSH_{ref_{3}} italic_L italic_F italic_S italic_H start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , the proportions for an iteration count of 1 were analyzed to be 98.3%, 95.2%, and 84.1%; showing a positive correlation with the F1 score reduction. Table  13  provides a detailed analysis of the effect of iteration rounds on the solution of the final answer. Increasing the maximum number of iterations parameter facilitates the re-planning of existing information when  L  F  S r  e  f n L F subscript S r e subscript f n LFS_{ref_{n}} italic_L italic_F italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT  is unable to complete the solution, thereby addressing some unsolvable case."
        ]
    },
    "id_table_14": {
        "caption": "Table 14:  The cases of reasoning with logical form",
        "table": "S2.T3.6",
        "footnotes": [],
        "references": [
            "When the query statement represented by natural language is applied to the search, the logic is often fuzzy, such as  \"find a picture containing vegetables or fruits\"  and  \"find a picture containing vegetables and fruits\" . Whether text search or vector search is used, the similarity between the two queries is very high, but the corresponding answers are quite different. The same is true for problems involving logical reasoning processes such as  and  or  not , and  intersection  differences. To this end, we use logical form to express the question, so that it can express explicit semantic relations.  Similar to IRCOT, we decompose complex original problem and plan out various execution actions such as multi-step retrieval, numerical reasoning, logical reasoning, and semantic deduce. Each sub-problem is expressed using logical form functions, and dependencies between sub-questions are established through variable references. The inference resolution process for each sub-question is illustrated as Algorithm  11 . In this process, the  GraphRetrieval  module performs KG structure retrieval according to the logical form clause to obtain structured graph results. Another key module,  HybridRetrieval , combining natural language expressed sub-problems and logical functions for comprehensive retrieval of documents and sub-graph information. To understand how logical functions can be utilized to reason about complex problems, refer to the following examples as Table  14 .",
            "Implementing our framework requires multiple LLM calls during the construction and solving phases.  A substantial number of intermediate tokens required to be generated during the planning stage to facilitate the breakdown of sub-problems and symbolic representation, this leads to computational and economic overhead, as illustrated in Table  14 , where the problem decomposition not only outputs sub-problems but also logical functions, resulting in approximately twice as many generated tokens compared to merely decomposing the sub-problems. Meanwhile, currently, all model invocations within the KAG framework, including entity recognition, relation extraction, relation recall, and standardization, rely on large models. This multitude of models significantly increases the overall runtime. In future domain-specific implementations, tasks like relation recall, entity recognition, and standardization could be substituted with smaller, domain-specific models to enhance operational efficiency."
        ]
    },
    "id_table_15": {
        "caption": "",
        "table": "S2.T4.1",
        "footnotes": [],
        "references": []
    },
    "id_table_16": {
        "caption": "",
        "table": "S2.T5.1",
        "footnotes": [],
        "references": []
    },
    "id_table_17": {
        "caption": "",
        "table": "S2.T6.1",
        "footnotes": [],
        "references": [
            "Since interactions between different modules in traditional RAG are based on vector representations of natural language, inaccuracies often arise. Inspired by the logical forms commonly used in KGQA, we designed an executable language with reasoning and retrieval capabilities. This language breaks down a question into multiple logical expressions, each of which may include functions for retrieval or logical operations. The mutual indexing described in Section 2.2 makes this process possible. Meanwhile, we designed a multi-turn solving mechanism based on reflection and global memory, inspired by ReSP [ 26 ] . The KAG solving process, as referenced in Figure  6  and Algorithm  17 , first decomposes the current question  q  u  e  r  y c  u  r q u e r subscript y c u r query_{cur} italic_q italic_u italic_e italic_r italic_y start_POSTSUBSCRIPT italic_c italic_u italic_r end_POSTSUBSCRIPT  into a list of subquestions  l  f l  i  s  t l subscript f l i s t lf_{list} italic_l italic_f start_POSTSUBSCRIPT italic_l italic_i italic_s italic_t end_POSTSUBSCRIPT  represented in logical form, and performs hybrid reasoning to solve them. If an exact answer can be obtained through multi-hop reasoning over structured knowledge, it returns the answer directly. Otherwise, it reflects on the solution results: storing the answers and retrieval results corresponding to  l  f l  i  s  t l subscript f l i s t lf_{list} italic_l italic_f start_POSTSUBSCRIPT italic_l italic_i italic_s italic_t end_POSTSUBSCRIPT  in global memory and determining whether the question is resolved. If not, it generates supplementary questions and proceeds to the next iteration. Section 2.3.1, 2.3.2 and 2.3.3 introduce logical form function for planning, logical form for reasoning and logical form for retrieval respectively. In general, the proposed logical form language has the following three advantages:",
            "Table  13  illustrates a multi-round scenario consistent with pseudocode  17 . Although first round the exact number of  plague occurrences  couldnt be determined, but we can extracted information indicates:  \"Venice, the birthplace of Antonio Vivaldi, experienced the devastating Black Death, also known as the Great Plague. This pandemic caused by Yersinia pestis led to 75 to 200 million deaths in Eurasia, peaking in Europe from 1347 to 1351. The plague brought significant upheavals in Europe. Although specific occurrence records in Venice arent detailed, its clear the city was impacted during the mid-14th century.\" . As is shown in Table  13 ,After two iterations, the answer determined is:  22 times ."
        ]
    },
    "id_table_18": {
        "caption": "",
        "table": "S2.T7.1",
        "footnotes": [],
        "references": []
    },
    "id_table_19": {
        "caption": "",
        "table": "S3.T8.2",
        "footnotes": [],
        "references": []
    },
    "id_table_20": {
        "caption": "",
        "table": "S3.T9.1",
        "footnotes": [],
        "references": []
    },
    "id_table_21": {
        "caption": "",
        "table": "S3.T10.6",
        "footnotes": [],
        "references": []
    },
    "id_table_22": {
        "caption": "",
        "table": "S3.T11.6",
        "footnotes": [],
        "references": []
    },
    "id_table_23": {
        "caption": "",
        "table": "S4.T12.1",
        "footnotes": [],
        "references": []
    },
    "id_table_24": {
        "caption": "",
        "table": "A1.T13.1",
        "footnotes": [],
        "references": []
    },
    "id_table_25": {
        "caption": "",
        "table": "A1.T13.1.1.1.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_26": {
        "caption": "",
        "table": "A1.T13.1.2.1.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_27": {
        "caption": "",
        "table": "A1.T13.1.3.2.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_28": {
        "caption": "",
        "table": "A1.T13.1.4.3.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_29": {
        "caption": "",
        "table": "A1.T13.1.5.4.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_30": {
        "caption": "",
        "table": "A1.T13.1.6.5.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_31": {
        "caption": "",
        "table": "A2.T14.1",
        "footnotes": [],
        "references": []
    },
    "id_table_32": {
        "caption": "",
        "table": "A2.T14.1.1.1.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_33": {
        "caption": "",
        "table": "A2.T14.1.2.1.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_34": {
        "caption": "",
        "table": "A2.T14.1.3.2.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_35": {
        "caption": "",
        "table": "A2.T14.1.4.3.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_36": {
        "caption": "",
        "table": "A2.T14.1.5.4.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_37": {
        "caption": "",
        "table": "A2.T14.1.6.5.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_38": {
        "caption": "",
        "table": "A2.T14.1.7.6.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_39": {
        "caption": "",
        "table": "A2.T14.1.8.7.1.1",
        "footnotes": [],
        "references": []
    },
    "global_footnotes": [
        ", *: These authors contributed equally to this work.",
        ",",
        ": Corresponding author.",
        "Official site of SPG: https://spg.openkg.cn/en-US",
        "Semantic Classification of Concept: https://openspg.yuque.com/ndx6g9/ps5q6b/fe5p4nh1zhk6p1d8",
        "DSL: https://openspg.yuque.com/ndx6g9/ooil9x/sdtg4q3bw4ka5wmz",
        "Official site of SPG: https://spg.openkg.cn/en-US",
        "DSL: https://openspg.yuque.com/ndx6g9/ooil9x/sdtg4q3bw4ka5wmz"
    ]
}