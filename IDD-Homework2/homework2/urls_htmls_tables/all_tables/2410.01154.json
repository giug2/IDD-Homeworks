{
    "id_table_1": {
        "caption": "Table 1:  Main results on Wiki-ZSL. We mark the best results in  bold , the second-best  underlined . The results of the baselines are retrieved from  Li et al. ( 2023a )  and  Zhao et al. ( 2023a ) .",
        "table": "S2.T1.3.3",
        "footnotes": [
            "",
            ""
        ],
        "references": [
            "Our methodologys initial phase generates relation synonyms to broaden relation synonym coverage. This strategy recognizes that a datasets relation often represents a broad concept, covering various synonymous or semantically related terms. As detailed in Figure  1 , Step 1, we utilize LLMs to generate  k k k italic_k  synonyms for each targeted relation. To ensure the generated synonyms align with the relations meaning, we provide the description of the relation to the LLMs. We then integrate the original relation with these synonyms to form a comprehensive semantic group. This process ensures the group encompasses the original relation alongside its synonyms, enhancing the relations contextual comprehension.",
            "After establishing semantic groups for each relation, we then prompt LLMs to create synthetic samples (as shown in Step 2 of Figure  1 ). However, these directly generated samples often lack sufficient entity coverage, reflecting the real worlds complexity and variability in sentence structures. Such reliance on LLMs may result in a skewed distribution of entities, favoring those frequently found in pretraining and Supervised Fine-Tuning (SFT) data  Li et al. ( 2023b ); Xu et al. ( 2023 ) . This issue is not unique to our approach but has also been observed in other LLM-based domain-specific data generation efforts (e.g.,  Li et al. ( 2023b ); Xu et al. ( 2023 ) ).",
            "To address this, we use LLMs to rephrase each sentence in the synthetic samples, creating  r r r italic_r  variants with similar meanings (as shown in Figure  1 , Step 4). These rephrased versions differ in structure but maintain the original relation, whether explicit or implicit. This method enhances the range of linguistic expressions in our dataset while ensuring consistent portrayal of the relationship across different semantic representations.",
            "Error propagation is a critical concern in complex pipelines like ours, where early inaccuracies can accumulate and adversely impact downstream tasks. For instance, if incorrect or imprecise synonyms are generated during the Relation Synonyms Generation step, these errors may cascade through subsequent stages, resulting in further inaccuracies in relation extraction and other tasks that rely on these synonyms. To mitigate this risk, we incorporate relation descriptions (as detailed in Section  2.1  and Table  14  in the appendix). This enables the language model to better grasp the context of the relations, thereby enhancing the accuracy of synonym generation, as demonstrated in Table  4 .",
            "Our evaluation of zero-shot prompting in LLMs, conducted on the FewRel and Wiki-ZSL datasets (as detailed in Tables  1  and  2 ), shows competitive performance against existing zero-shot RE methods. Notably, our Self-Prompting technique significantly enhances ChatGPTs performance over Vanilla prompting, outperforming the RE-Prompt method in most scenarios and markedly surpassing the SumAsk prompt strategy.",
            "Generation:  Tables  10  and  11  showcase examples of the generation process for the  location  and  operator  relations, respectively.   Inference:  Table  12  presents a successful instance of Self-Prompting, while Table  13  illustrates a failure. The success case demonstrates how synthetic in-context samples, when closely related to the test sample, can offer a nuanced guide, aiding the model in distinguishing between  location  and  located on terrain feature . Conversely, in the failure case, Self-Prompting did not yield an accurate prediction due to the in-context samples being less relevant, thereby introducing noise during inference.",
            "We listed each stages prompts used in the synthetic data generation process in Table  14 ."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Main results on FewRel. We mark the best results in  bold , the second-best  underlined . The results of the baselines are retrieved from  Li et al. ( 2023a )  and  Zhao et al. ( 2023a ) .",
        "table": "S2.T2.3.3",
        "footnotes": [
            "",
            ""
        ],
        "references": [
            "Error propagation is a critical concern in complex pipelines like ours, where early inaccuracies can accumulate and adversely impact downstream tasks. For instance, if incorrect or imprecise synonyms are generated during the Relation Synonyms Generation step, these errors may cascade through subsequent stages, resulting in further inaccuracies in relation extraction and other tasks that rely on these synonyms. To mitigate this risk, we incorporate relation descriptions (as detailed in Section  2.1  and Table  14  in the appendix). This enables the language model to better grasp the context of the relations, thereby enhancing the accuracy of synonym generation, as demonstrated in Table  4 .",
            "Our evaluation of zero-shot prompting in LLMs, conducted on the FewRel and Wiki-ZSL datasets (as detailed in Tables  1  and  2 ), shows competitive performance against existing zero-shot RE methods. Notably, our Self-Prompting technique significantly enhances ChatGPTs performance over Vanilla prompting, outperforming the RE-Prompt method in most scenarios and markedly surpassing the SumAsk prompt strategy.",
            "Generation:  Tables  10  and  11  showcase examples of the generation process for the  location  and  operator  relations, respectively.   Inference:  Table  12  presents a successful instance of Self-Prompting, while Table  13  illustrates a failure. The success case demonstrates how synthetic in-context samples, when closely related to the test sample, can offer a nuanced guide, aiding the model in distinguishing between  location  and  located on terrain feature . Conversely, in the failure case, Self-Prompting did not yield an accurate prediction due to the in-context samples being less relevant, thereby introducing noise during inference."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Main results on TACRED and SemEval. We mark the best results in  bold , the second-best  underlined . The results of the baselines are retrieved from  Zhang et al. ( 2023b )",
        "table": "S4.T3.2.2",
        "footnotes": [
            ""
        ],
        "references": [
            "Further validation is demonstrated through the application of our method on the TACRED and SemEval datasets. As shown in Table  3 , our Self-Prompting technique achieved the highest F1 score on the SemEval dataset and the second-highest on TACRED, outperforming other zero-shot methods and significantly exceeding the performance of the QA4RE prompt strategy. This highlights the effectiveness of our approach, particularly given QA4REs established performance.",
            "To identify the optimal number of in-context samples  d d d italic_d , we analyzed how varying the number of examples in the input affects performance, as illustrated in Figure  3 . These experiments, aimed at assessing cost-effectiveness, were limited to a single subset of relations with  m = 10 m 10 m=10 italic_m = 10 . Analyzing F1 scores across two datasets revealed a pattern of performance improvement as the number of examples increased from 1 to 12. Yet, we found that utilizing more than 10 examples did not offer substantial benefits and, notably for Wiki-ZSL, resulted in diminished performance. Therefore, balancing performance efficiency with cost considerations, we determined that 10 demonstrations ( d = 10 d 10 d=10 italic_d = 10 ) were optimal for our experiments.",
            "Evaluating the impact of synthetic sample size on experimental outcomes, our comprehensive analysis, shown in Figure  3 , focuses on a relation subset with  m = 10 m 10 m=10 italic_m = 10 , exploring synthetic sample sizes from 100 to approximately 6,000.",
            "Generation:  Tables  10  and  11  showcase examples of the generation process for the  location  and  operator  relations, respectively.   Inference:  Table  12  presents a successful instance of Self-Prompting, while Table  13  illustrates a failure. The success case demonstrates how synthetic in-context samples, when closely related to the test sample, can offer a nuanced guide, aiding the model in distinguishing between  location  and  located on terrain feature . Conversely, in the failure case, Self-Prompting did not yield an accurate prediction due to the in-context samples being less relevant, thereby introducing noise during inference."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Performance comparison of different strategies on FewRel and Wiki-ZSL datasets ( m = 10 m 10 m=10 italic_m = 10 ).",
        "table": "S4.T4.3.1",
        "footnotes": [],
        "references": [
            "Error propagation is a critical concern in complex pipelines like ours, where early inaccuracies can accumulate and adversely impact downstream tasks. For instance, if incorrect or imprecise synonyms are generated during the Relation Synonyms Generation step, these errors may cascade through subsequent stages, resulting in further inaccuracies in relation extraction and other tasks that rely on these synonyms. To mitigate this risk, we incorporate relation descriptions (as detailed in Section  2.1  and Table  14  in the appendix). This enables the language model to better grasp the context of the relations, thereby enhancing the accuracy of synonym generation, as demonstrated in Table  4 .",
            "As we can see in Table  4 , the findings emphasize the importance of each component. Removing sentence rephrasing slightly decreases Precision and F1 scores. Excluding relation synonym generation results in a more substantial drop across all metrics, highlighting the importance of synonyms for capturing semantic breadth. Omitting entity frequency filtering significantly impacts Recall, indicating that entity variety is crucial for comprehensive relation extraction.",
            "Figure  4  shows that our generated samples more accurately encapsulate the targeted relations compared to those generated by the RE-Prompt method. This close alignment with real data benchmarks demonstrates the effectiveness of our generation methodology, validating our samples utility for in-context learning in RE tasks.",
            "We listed each stages prompts used in the synthetic data generation process in Table  14 ."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Statistics of FewRel and Wiki-ZSL",
        "table": "A2.T5.1.1",
        "footnotes": [],
        "references": [
            "The statistics of the datasets are shown in Table  5  and Table  6 . Following previous works  Zhang et al. ( 2023b ); Li et al. ( 2023a ) , for the FewRel and Wiki-ZSL datasets, we randomly selected 5 relations for validation and selected a varying number of unseen relations ( m m m italic_m ) for testing, where  m m m italic_m  could be 5, 10, or 15. To ascertain the robustness of our results, this classification process was repeated five times, and we report the average macro-F1 scores from these iterations. For TACRED and SemEval, we conduct experiments using only the test samples and present the micro-averaged F1 scores. All relations are included except for  none-of-the-above ."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Statistics of TACRED and SemEval",
        "table": "A2.T6.1.1",
        "footnotes": [],
        "references": [
            "The statistics of the datasets are shown in Table  5  and Table  6 . Following previous works  Zhang et al. ( 2023b ); Li et al. ( 2023a ) , for the FewRel and Wiki-ZSL datasets, we randomly selected 5 relations for validation and selected a varying number of unseen relations ( m m m italic_m ) for testing, where  m m m italic_m  could be 5, 10, or 15. To ascertain the robustness of our results, this classification process was repeated five times, and we report the average macro-F1 scores from these iterations. For TACRED and SemEval, we conduct experiments using only the test samples and present the micro-averaged F1 scores. All relations are included except for  none-of-the-above ."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Performance on FewRel and Wiki-ZSL datasets using varied synthetic demonstrations with  m = 10 m 10 m=10 italic_m = 10  unseen relations",
        "table": "A7.T7.3.1",
        "footnotes": [],
        "references": [
            "To further compare the quality of synthetic data from our method against RE-Prompt, we utilized RE-Prompts synthetic data as demonstration samples in our inference framework. We documented the experimental outcomes on the FewRel and Wiki-ZSL datasets, with  m = 10 m 10 m=10 italic_m = 10 , in Table  7 . These outcomes uniformly demonstrate that our method surpasses RE-Prompt in all instances, highlighting the superior data quality generated by our approach. This advantage is attained without task-specific fine-tuning, showcasing our data generation processs ability to produce high-quality synthetic samples for RE tasks effectively."
        ]
    },
    "id_table_8": {
        "caption": "Table 8:  Performance of our method for LLMs with different size",
        "table": "A7.T8.3.3",
        "footnotes": [],
        "references": []
    },
    "id_table_9": {
        "caption": "Table 9:  Average number of token usage (k) and cost ($) for a single relation samples generation",
        "table": "A8.T9.1.1",
        "footnotes": [],
        "references": [
            "For synthetic data generation, we employed  gpt-3.5-turbo , an economical choice at $0.001 per 1K tokens for prompts and $0.002 per 1K tokens for completions 1 1 1 https://openai.com/pricing . The synthesis involves three phases: generating relation synonyms, creating samples, and rephrasing sentences. The costs for each relations data generation are itemized in Table  9 , totaling approximately $0.264 for around 600 samples per relation. Considering the Wiki-ZSL dataset includes up to 113 relations, the full data generation cost is estimated at $30. This is cost-effective compared to manual annotation expenses, such as in machine translation tasks, which can reach around $0.1 per word  Neubig and He ( 2023 ) . Thus, using  gpt-3.5-turbo  for synthetic data generation in RE tasks is validated as an economically viable method."
        ]
    },
    "id_table_10": {
        "caption": "Table 10:  Case of sample generation for relation  Location",
        "table": "A10.T10.1.1",
        "footnotes": [],
        "references": [
            "Generation:  Tables  10  and  11  showcase examples of the generation process for the  location  and  operator  relations, respectively.   Inference:  Table  12  presents a successful instance of Self-Prompting, while Table  13  illustrates a failure. The success case demonstrates how synthetic in-context samples, when closely related to the test sample, can offer a nuanced guide, aiding the model in distinguishing between  location  and  located on terrain feature . Conversely, in the failure case, Self-Prompting did not yield an accurate prediction due to the in-context samples being less relevant, thereby introducing noise during inference."
        ]
    },
    "id_table_11": {
        "caption": "Table 11:  Case of sample generation for relation  Operator",
        "table": "A10.T11.1.1",
        "footnotes": [],
        "references": [
            "Generation:  Tables  10  and  11  showcase examples of the generation process for the  location  and  operator  relations, respectively.   Inference:  Table  12  presents a successful instance of Self-Prompting, while Table  13  illustrates a failure. The success case demonstrates how synthetic in-context samples, when closely related to the test sample, can offer a nuanced guide, aiding the model in distinguishing between  location  and  located on terrain feature . Conversely, in the failure case, Self-Prompting did not yield an accurate prediction due to the in-context samples being less relevant, thereby introducing noise during inference."
        ]
    },
    "id_table_12": {
        "caption": "Table 12:  Case of successful test sample inference",
        "table": "A10.T12.1.1",
        "footnotes": [],
        "references": [
            "Generation:  Tables  10  and  11  showcase examples of the generation process for the  location  and  operator  relations, respectively.   Inference:  Table  12  presents a successful instance of Self-Prompting, while Table  13  illustrates a failure. The success case demonstrates how synthetic in-context samples, when closely related to the test sample, can offer a nuanced guide, aiding the model in distinguishing between  location  and  located on terrain feature . Conversely, in the failure case, Self-Prompting did not yield an accurate prediction due to the in-context samples being less relevant, thereby introducing noise during inference."
        ]
    },
    "id_table_13": {
        "caption": "Table 13:  Case of failed test sample inference",
        "table": "A10.T13.1.1",
        "footnotes": [],
        "references": [
            "Generation:  Tables  10  and  11  showcase examples of the generation process for the  location  and  operator  relations, respectively.   Inference:  Table  12  presents a successful instance of Self-Prompting, while Table  13  illustrates a failure. The success case demonstrates how synthetic in-context samples, when closely related to the test sample, can offer a nuanced guide, aiding the model in distinguishing between  location  and  located on terrain feature . Conversely, in the failure case, Self-Prompting did not yield an accurate prediction due to the in-context samples being less relevant, thereby introducing noise during inference."
        ]
    },
    "id_table_14": {
        "caption": "Table 14:  Prompts used for synthetic data generation and test sample inference",
        "table": "A11.T14.1.1",
        "footnotes": [],
        "references": [
            "Error propagation is a critical concern in complex pipelines like ours, where early inaccuracies can accumulate and adversely impact downstream tasks. For instance, if incorrect or imprecise synonyms are generated during the Relation Synonyms Generation step, these errors may cascade through subsequent stages, resulting in further inaccuracies in relation extraction and other tasks that rely on these synonyms. To mitigate this risk, we incorporate relation descriptions (as detailed in Section  2.1  and Table  14  in the appendix). This enables the language model to better grasp the context of the relations, thereby enhancing the accuracy of synonym generation, as demonstrated in Table  4 .",
            "We listed each stages prompts used in the synthetic data generation process in Table  14 ."
        ]
    }
}