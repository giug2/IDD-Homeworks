{
    "PAPER'S NUMBER OF TABLES": 4,
    "S3.T1": {
        "caption": "TABLE I: Overview of the models used in the experiments.",
        "table": "<table id=\"S3.T1.4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.4.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.4.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S3.T1.4.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Model Type</th>\n<th id=\"S3.T1.4.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Size</th>\n<th id=\"S3.T1.4.1.1.1.4\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Parameters</th>\n</tr>\n<tr id=\"S3.T1.4.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.4.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Sine-wave example</td>\n<td id=\"S3.T1.4.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Fully connected</td>\n<td id=\"S3.T1.4.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">19.4 KB</td>\n<td id=\"S3.T1.4.1.2.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\">1153</td>\n</tr>\n<tr id=\"S3.T1.4.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.4.1.3.3.1\" class=\"ltx_td ltx_align_left\">Keywords spotting (4 Classes)</td>\n<td id=\"S3.T1.4.1.3.3.2\" class=\"ltx_td ltx_align_left\">Convolutional</td>\n<td id=\"S3.T1.4.1.3.3.3\" class=\"ltx_td ltx_align_left\">95.7 KB</td>\n<td id=\"S3.T1.4.1.3.3.4\" class=\"ltx_td ltx_nopad_r ltx_align_left\">19812</td>\n</tr>\n<tr id=\"S3.T1.4.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.4.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Omniglot (5 Classes)</td>\n<td id=\"S3.T1.4.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">Convolutional</td>\n<td id=\"S3.T1.4.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">485.1 KB</td>\n<td id=\"S3.T1.4.1.4.4.4\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\">113733</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We evaluate the performance of Reptile and TinyReptile on Raspberry Pi 4 and Arduino Nano BLE 33 MCU. We do not consider other FL algorithms because they are ineffective for meta-learning problems. As mentioned, the NNs we considered in the experiments are described in TableÂ I. We attempted the following ranges of different hyperparameters and found possible combinations that work well for the problems: the client learning rate Î²ğ›½\\beta (0.001â€“0.02), training steps kğ‘˜k (1â€“32), and support set size Sğ‘†S (1â€“32). However, we did not fine-tune the hyperparameters to optimize the final results."
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Comparison of memory requirement (the results are measured under the support set size S=32ğ‘†32S=32).",
        "table": "<table id=\"S4.T2.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.5.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S4.T2.5.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S4.T2.5.1.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T2.5.1.1.1.2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">Reptile</td>\n</tr>\n<tr id=\"S4.T2.5.1.1.1.2.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">(batched &amp; serial)</td>\n</tr>\n</table>\n</th>\n<th id=\"S4.T2.5.1.1.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S4.T2.5.1.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T2.5.1.1.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">TinyReptile</td>\n</tr>\n<tr id=\"S4.T2.5.1.1.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">(ours)</td>\n</tr>\n</table>\n</th>\n</tr>\n<tr id=\"S4.T2.5.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Sine-wave example</td>\n<td id=\"S4.T2.5.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">10.7 KB</td>\n<td id=\"S4.T2.5.1.2.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\">4.8 KB</td>\n</tr>\n<tr id=\"S4.T2.5.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.3.3.1\" class=\"ltx_td ltx_align_left\">Keywords spotting (4 Classes)</td>\n<td id=\"S4.T2.5.1.3.3.2\" class=\"ltx_td ltx_align_left\">5816.4 KB</td>\n<td id=\"S4.T2.5.1.3.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_left\">437.2 KB</td>\n</tr>\n<tr id=\"S4.T2.5.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Omniglot (5 Classes)</td>\n<td id=\"S4.T2.5.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">3778.1 KB</td>\n<td id=\"S4.T2.5.1.4.4.3\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\">667.2 KB</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To run the algorithms on hardware, we need to measure their memory usage for the considered NNs. Notable outcomes are presented in Table.Â ",
                "II",
                ". Owing to online learning, TinyReptile provides a significant reduction in memory consumption by a factor of at least two across all tasks compared with Reptile. The results also show that only the Sine-wave example can be used for experiments on the Arduino Nano 33 BLE Sense board because this MCU is equipped with only 256 KB of memory."
            ]
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: Comparison of time consumption of one training round on the Sine-wave example on Arduino Nano 33 BLE Sense (the results are measured under the support set size S=32ğ‘†32S=32).",
        "table": "<table id=\"S4.T3.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.5.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.5.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S4.T3.5.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Sending</th>\n<th id=\"S4.T3.5.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Local Training</th>\n<th id=\"S4.T3.5.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Receiving</th>\n<th id=\"S4.T3.5.1.1.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Total</th>\n</tr>\n<tr id=\"S4.T3.5.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.5.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Reptile</td>\n<td id=\"S4.T3.5.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1.58 s</td>\n<td id=\"S4.T3.5.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">8.32 s</td>\n<td id=\"S4.T3.5.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">1.65 s</td>\n<td id=\"S4.T3.5.1.2.2.5\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\">11.55 s</td>\n</tr>\n<tr id=\"S4.T3.5.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.5.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">TinyReptile (ours)</td>\n<td id=\"S4.T3.5.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">1.58 s</td>\n<td id=\"S4.T3.5.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">0.44 s</td>\n<td id=\"S4.T3.5.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">1.65 s</td>\n<td id=\"S4.T3.5.1.3.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\">3.67 s</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In Fig.Â ",
                "3",
                ", we present the convergence performance of Reptile (serial) and TinyReptile on the Sine-wave example, where we also demonstrate the feasibility of running TinyReptile on the Arduino MCU. Arduino Nano 33 BLE Sense MCU is equipped with a 64-MHz Cortex-M4 CPU, 256-KB memory, and 1-MB flash, whose specification is within the typical range of TinyML devices. We choose the following hyperparameters in the experiments: ",
                "S",
                "t",
                "â€‹",
                "r",
                "â€‹",
                "a",
                "â€‹",
                "i",
                "â€‹",
                "n",
                "â€‹",
                "i",
                "â€‹",
                "n",
                "â€‹",
                "g",
                "=",
                "32",
                "subscript",
                "ğ‘†",
                "ğ‘¡",
                "ğ‘Ÿ",
                "ğ‘",
                "ğ‘–",
                "ğ‘›",
                "ğ‘–",
                "ğ‘›",
                "ğ‘”",
                "32",
                "S_{training}=32",
                ", ",
                "Î²",
                "=",
                "0.01",
                "ğ›½",
                "0.01",
                "\\beta=0.01",
                ", and local epoch ",
                "E",
                "=",
                "8",
                "ğ¸",
                "8",
                "E=8",
                " (for training with Reptile). We observe a slower convergence, more fluctuations, and slightly worse results on the Arduino MCU than on the Raspberry Pi 4, which may be due to the limited numerical precision of the hardware. Nevertheless, given a sufficient number of training rounds, the model can still achieve reasonable performance on the MCU. In particular, Reptile (serial) performs worse than TinyReptile on the MCU. Our explanation is that because of the limited numerical precision of the MCU, the effect of the gradient calculated over the batch data may be canceled out and make the already less precise gradient even less precise.",
                "Because the Arduino board is constrained for the Omniglot task and Keywords spotting task, we compare the training progress of Reptile and TinyReptile on these two datasets only on Raspberry Pi 4 in Fig.Â ",
                "4",
                ". Here, we choose the following hyperparameters in the experiments: ",
                "S",
                "t",
                "â€‹",
                "r",
                "â€‹",
                "a",
                "â€‹",
                "i",
                "â€‹",
                "n",
                "â€‹",
                "i",
                "â€‹",
                "n",
                "â€‹",
                "g",
                "=",
                "16",
                "subscript",
                "ğ‘†",
                "ğ‘¡",
                "ğ‘Ÿ",
                "ğ‘",
                "ğ‘–",
                "ğ‘›",
                "ğ‘–",
                "ğ‘›",
                "ğ‘”",
                "16",
                "S_{training}=16",
                ", ",
                "Î²",
                "=",
                "0.002",
                "ğ›½",
                "0.002",
                "\\beta=0.002",
                ", local epoch ",
                "E",
                "=",
                "8",
                "ğ¸",
                "8",
                "E=8",
                " (for training with Reptile), and the number of sampled clients in each round ",
                "T",
                "=",
                "32",
                "ğ‘‡",
                "32",
                "T=32",
                " (for training with the batched version of Reptile). The results confirm that TinyReptile requires slightly more training rounds to obtain the same accuracy as Reptile, which is reasonable because TinyReptile updates on only one data point at a time, whereas Reptile trains on the entire support set in a batch."
            ]
        ]
    },
    "S4.T4": {
        "caption": "TABLE IV: Comparison of time consumption of one training round on Raspberry Pi 4 (the results are measured under the support set size S=32ğ‘†32S=32).",
        "table": "<table id=\"S4.T4.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.5.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.5.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S4.T4.5.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S4.T4.5.1.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T4.5.1.1.1.2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.5.1.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">Reptile</td>\n</tr>\n<tr id=\"S4.T4.5.1.1.1.2.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.5.1.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">(batched &amp; serial)</td>\n</tr>\n</table>\n</th>\n<th id=\"S4.T4.5.1.1.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S4.T4.5.1.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T4.5.1.1.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.5.1.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">TinyReptile</td>\n</tr>\n<tr id=\"S4.T4.5.1.1.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.5.1.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">(ours)</td>\n</tr>\n</table>\n</th>\n</tr>\n<tr id=\"S4.T4.5.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.5.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Sine-wave example</td>\n<td id=\"S4.T4.5.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.56 s</td>\n<td id=\"S4.T4.5.1.2.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\">0.24 s</td>\n</tr>\n<tr id=\"S4.T4.5.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.5.1.3.3.1\" class=\"ltx_td ltx_align_left\">Keywords spotting (4 Classes)</td>\n<td id=\"S4.T4.5.1.3.3.2\" class=\"ltx_td ltx_align_left\">11.96 s</td>\n<td id=\"S4.T4.5.1.3.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_left\">3.45 s</td>\n</tr>\n<tr id=\"S4.T4.5.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T4.5.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Omniglot (5 Classes)</td>\n<td id=\"S4.T4.5.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">22.53 s</td>\n<td id=\"S4.T4.5.1.4.4.3\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\">10.11 s</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In Fig.Â ",
                "3",
                ", we present the convergence performance of Reptile (serial) and TinyReptile on the Sine-wave example, where we also demonstrate the feasibility of running TinyReptile on the Arduino MCU. Arduino Nano 33 BLE Sense MCU is equipped with a 64-MHz Cortex-M4 CPU, 256-KB memory, and 1-MB flash, whose specification is within the typical range of TinyML devices. We choose the following hyperparameters in the experiments: ",
                "S",
                "t",
                "â€‹",
                "r",
                "â€‹",
                "a",
                "â€‹",
                "i",
                "â€‹",
                "n",
                "â€‹",
                "i",
                "â€‹",
                "n",
                "â€‹",
                "g",
                "=",
                "32",
                "subscript",
                "ğ‘†",
                "ğ‘¡",
                "ğ‘Ÿ",
                "ğ‘",
                "ğ‘–",
                "ğ‘›",
                "ğ‘–",
                "ğ‘›",
                "ğ‘”",
                "32",
                "S_{training}=32",
                ", ",
                "Î²",
                "=",
                "0.01",
                "ğ›½",
                "0.01",
                "\\beta=0.01",
                ", and local epoch ",
                "E",
                "=",
                "8",
                "ğ¸",
                "8",
                "E=8",
                " (for training with Reptile). We observe a slower convergence, more fluctuations, and slightly worse results on the Arduino MCU than on the Raspberry Pi 4, which may be due to the limited numerical precision of the hardware. Nevertheless, given a sufficient number of training rounds, the model can still achieve reasonable performance on the MCU. In particular, Reptile (serial) performs worse than TinyReptile on the MCU. Our explanation is that because of the limited numerical precision of the MCU, the effect of the gradient calculated over the batch data may be canceled out and make the already less precise gradient even less precise.",
                "Because the Arduino board is constrained for the Omniglot task and Keywords spotting task, we compare the training progress of Reptile and TinyReptile on these two datasets only on Raspberry Pi 4 in Fig.Â ",
                "4",
                ". Here, we choose the following hyperparameters in the experiments: ",
                "S",
                "t",
                "â€‹",
                "r",
                "â€‹",
                "a",
                "â€‹",
                "i",
                "â€‹",
                "n",
                "â€‹",
                "i",
                "â€‹",
                "n",
                "â€‹",
                "g",
                "=",
                "16",
                "subscript",
                "ğ‘†",
                "ğ‘¡",
                "ğ‘Ÿ",
                "ğ‘",
                "ğ‘–",
                "ğ‘›",
                "ğ‘–",
                "ğ‘›",
                "ğ‘”",
                "16",
                "S_{training}=16",
                ", ",
                "Î²",
                "=",
                "0.002",
                "ğ›½",
                "0.002",
                "\\beta=0.002",
                ", local epoch ",
                "E",
                "=",
                "8",
                "ğ¸",
                "8",
                "E=8",
                " (for training with Reptile), and the number of sampled clients in each round ",
                "T",
                "=",
                "32",
                "ğ‘‡",
                "32",
                "T=32",
                " (for training with the batched version of Reptile). The results confirm that TinyReptile requires slightly more training rounds to obtain the same accuracy as Reptile, which is reasonable because TinyReptile updates on only one data point at a time, whereas Reptile trains on the entire support set in a batch."
            ]
        ]
    }
}