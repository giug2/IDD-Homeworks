{
    "id_table_1": {
        "caption": "Table 1.  Student Mistakes from Altadmri and Brown  (Altadmri and Brown,  2015 )",
        "table": "S3.T1.6",
        "footnotes": [
            ""
        ],
        "references": [
            "To generate synthetic bugs, we investigated three prompting strategies that differed in the level of information provided about how students encounter similar problems in real-world contexts. An example based on Study 2 is presented in Figure  1 .",
            "In the first study, we conducted a replication of the work by Altadmri and Brown  (Altadmri and Brown,  2015 ) . Their research analyzed the frequency of bugs generated by real students across 37 million compilations. They identified 18 errors related to syntax, type, and semantics. These errors are summarized in Table  1 .",
            "We used GPT-4 to generate bugs and experimentally varied the prompts as described in Section  3.1 . In total, 375 output programs with injected bugs were created. This was done by requesting the generation of five bugs for five code examples and repeating this process five times for each of the three prompt permutations to account for the probablistic nature of LLM responses, resulting in:",
            "The first part of the analysis focused on deductively coding the generated data using the original taxonomies from each corresponding study  (Altadmri and Brown,  2015 ; Rigby et al . ,  2020 ) . Two coders independently coded the data and we computed inter-rater reliability (IRR) using Cohens Kappa to determine their agreement which is adjusted for class imbalances. For Study 1, these codes are listed in Table  1  and the Kappa for IRR between the two coders was 0.92. For Study 2, we used the same four bug types coded in their study, High Bounds, Low Bounds, Low Miss, and High Miss. The Kappa for IRR between coders was 0.81."
        ]
    },
    "id_table_2": {
        "caption": "Table 2.  Comparison of bug frequencies (%) with Altadmri and Brown  (Altadmri and Brown,  2015 ) . The table includes out-of-distribution bugs from our thematic analysis and - denotes refusals.",
        "table": "S4.T2.7",
        "footnotes": [
            ""
        ],
        "references": [
            "Our results also show that providing the model with information about the distribution helped to ensure the distribution more closely matched the actual distribution of bugs generated by students. As shown in Table  2 , the  Baseline Prompt , which had no information about the bug types or associated frequencies, produced code containing 68.8% of bugs that were not in the original distribution. Conversely, the  Frequency-informed  and  Taxonomy-informed  prompts produced 9.6% and 6.4% of these out-of-distribution bugs.",
            "In our initial coding, out-of-distribution bugs were labeled  X . We conducted a thematic analysis on these bugs to identify what types of bugs GPT-4 injected into the code. We identified five themes and additional bugs that did not fit into those themes. The five themes are described in Table  3 . The frequency of these five bugs are also reported in Table  2 . Many of these errors were not compilation errors and were therefore not reported in the original study  (Altadmri and Brown,  2015 ) ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3.  The themes of out-of-distribution bug types identified in our thematic analysis.",
        "table": "S4.T3.3",
        "footnotes": [],
        "references": [
            "We used GPT-4 to generate bugs and experimentally varied the prompts as described in Section  3.1 . In total, 375 output programs with injected bugs were created. This was done by requesting the generation of five bugs for five code examples and repeating this process five times for each of the three prompt permutations to account for the probablistic nature of LLM responses, resulting in:",
            "In our initial coding, out-of-distribution bugs were labeled  X . We conducted a thematic analysis on these bugs to identify what types of bugs GPT-4 injected into the code. We identified five themes and additional bugs that did not fit into those themes. The five themes are described in Table  3 . The frequency of these five bugs are also reported in Table  2 . Many of these errors were not compilation errors and were therefore not reported in the original study  (Altadmri and Brown,  2015 ) ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4.  Comparison of bug frequencies (%) with Rigby et al.  (Rigby et al . ,  2020 )  where - and X represent refusals and out-of-distribution errors respectively.",
        "table": "S4.T4.7",
        "footnotes": [
            ""
        ],
        "references": [
            "Similar to Study 1, the  Baseline  prompt produced more out-of-distribution errors (44%) than the  Frequency-informed  and  Taxonomy-informed  prompts which only contained 6% and 8% of bugs that were not in the original distribution respectively. Unlike Study 1, the  Baseline  prompt produced fewer out-of-distribution errors. This may be because the  Baseline  prompt for Study 2 was constrained by only asking for off-by-one errors. We observed statistically significant differences between each distribution and the distribution of students bugs. Based on Chi Square Tests (with p-values corrected using the Bonferroni correction), the  Frequency-informed  (  2 = 69.9 superscript  2 69.9 \\chi^{2}=69.9 italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 69.9 ,  p < 0.01 p 0.01 p<0.01 italic_p < 0.01 ),  Taxonomy-informed  (  2 = 115.7 superscript  2 115.7 \\chi^{2}=115.7 italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 115.7 ,  p < 0.01 p 0.01 p<0.01 italic_p < 0.01 ), and  Baseline  (  2 = 76.4 superscript  2 76.4 \\chi^{2}=76.4 italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 76.4 ,  p < 0.01 p 0.01 p<0.01 italic_p < 0.01 ) prompts produced distributions of off-by-one errors that were different to those seen in practice from real students. Manual inspection of the frequencies in Table  4  indicate that the  Frequency-informed  prompt produced a somewhat more realistic distribution, better matching the most common HighBounds error type."
        ]
    }
}