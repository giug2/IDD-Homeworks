{
    "PAPER'S NUMBER OF TABLES": 3,
    "S3.T1": {
        "caption": "Table 1: \nStatistics for the heterogeneous text-to-SQL datasets. \"μ𝜇\\mu\": the average number under the measure. \"Max\": the max number under the measure.",
        "table": "<table id=\"S3.T1.2.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.2.2.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><span id=\"S3.T1.2.2.3.1.1.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><span id=\"S3.T1.2.2.3.1.2.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T1.2.2.3.1.3.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.3.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T1.2.2.3.1.4.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.3.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><span id=\"S3.T1.2.2.3.1.5.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.3.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T1.2.2.3.1.6.1\" class=\"ltx_text\">SQL</span></th>\n<th id=\"S3.T1.2.2.3.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T1.2.2.3.1.7.1\" class=\"ltx_text\">Questions</span></th>\n<th id=\"S3.T1.2.2.3.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">Unique tables</th>\n<th id=\"S3.T1.2.2.3.1.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">\n<span id=\"S3.T1.2.2.3.1.9.1\" class=\"ltx_text ltx_font_typewriter\">SELECT</span>s</th>\n</tr>\n<tr id=\"S3.T1.2.2.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r\"><span id=\"S3.T1.2.2.4.2.1.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.4.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S3.T1.2.2.4.2.2.1\" class=\"ltx_text\">Domain</span></th>\n<th id=\"S3.T1.2.2.4.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.4.2.3.1\" class=\"ltx_text\">Train</span></th>\n<th id=\"S3.T1.2.2.4.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.4.2.4.1\" class=\"ltx_text\">Dev</span></th>\n<th id=\"S3.T1.2.2.4.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S3.T1.2.2.4.2.5.1\" class=\"ltx_text\">Test</span></th>\n<th id=\"S3.T1.2.2.4.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.4.2.6.1\" class=\"ltx_text\">Pattern</span></th>\n<th id=\"S3.T1.2.2.4.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.4.2.7.1\" class=\"ltx_text\">/ unique query</span></th>\n<th id=\"S3.T1.2.2.4.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" colspan=\"2\">/ query</th>\n<th id=\"S3.T1.2.2.4.2.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" colspan=\"2\">/ query</th>\n</tr>\n<tr id=\"S3.T1.2.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r\"><span id=\"S3.T1.2.2.2.3.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S3.T1.2.2.2.4.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.2.5.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.2.6.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S3.T1.2.2.2.7.1\" class=\"ltx_text\"></span></th>\n<th id=\"S3.T1.2.2.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.2.8.1\" class=\"ltx_text\">count</span></th>\n<th id=\"S3.T1.2.2.2.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.2.9.1\" class=\"ltx_text\">count</span></th>\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text\"><math id=\"S3.T1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mu\" display=\"inline\"><semantics id=\"S3.T1.1.1.1.1.1.m1.1a\"><mi id=\"S3.T1.1.1.1.1.1.m1.1.1\" xref=\"S3.T1.1.1.1.1.1.m1.1.1.cmml\">μ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.1.1.1.1.1.m1.1b\"><ci id=\"S3.T1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T1.1.1.1.1.1.m1.1.1\">𝜇</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.1.1.1.1.1.m1.1c\">\\mu</annotation></semantics></math></span></th>\n<th id=\"S3.T1.2.2.2.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.2.10.1\" class=\"ltx_text\">Max</span></th>\n<th id=\"S3.T1.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.2.2.1\" class=\"ltx_text\"><math id=\"S3.T1.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mu\" display=\"inline\"><semantics id=\"S3.T1.2.2.2.2.1.m1.1a\"><mi id=\"S3.T1.2.2.2.2.1.m1.1.1\" xref=\"S3.T1.2.2.2.2.1.m1.1.1.cmml\">μ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.2.2.2.2.1.m1.1b\"><ci id=\"S3.T1.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T1.2.2.2.2.1.m1.1.1\">𝜇</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.2.2.2.2.1.m1.1c\">\\mu</annotation></semantics></math></span></th>\n<th id=\"S3.T1.2.2.2.11\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.2.2.2.11.1\" class=\"ltx_text\">Max</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.2.2.5.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.2.5.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Advising</td>\n<td id=\"S3.T1.2.2.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Course Infomation</td>\n<td id=\"S3.T1.2.2.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">2629</td>\n<td id=\"S3.T1.2.2.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">229</td>\n<td id=\"S3.T1.2.2.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">573</td>\n<td id=\"S3.T1.2.2.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">174</td>\n<td id=\"S3.T1.2.2.5.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">21.7</td>\n<td id=\"S3.T1.2.2.5.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">3.0</td>\n<td id=\"S3.T1.2.2.5.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">9</td>\n<td id=\"S3.T1.2.2.5.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\">1.23</td>\n<td id=\"S3.T1.2.2.5.1.11\" class=\"ltx_td ltx_align_center ltx_border_t\">6</td>\n</tr>\n<tr id=\"S3.T1.2.2.6.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.2.6.2.1\" class=\"ltx_td ltx_align_left ltx_border_r\">ATIS</td>\n<td id=\"S3.T1.2.2.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flight Booking</td>\n<td id=\"S3.T1.2.2.6.2.3\" class=\"ltx_td ltx_align_center\">4347</td>\n<td id=\"S3.T1.2.2.6.2.4\" class=\"ltx_td ltx_align_center\">486</td>\n<td id=\"S3.T1.2.2.6.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">447</td>\n<td id=\"S3.T1.2.2.6.2.6\" class=\"ltx_td ltx_align_center\">751</td>\n<td id=\"S3.T1.2.2.6.2.7\" class=\"ltx_td ltx_align_center\">5.6</td>\n<td id=\"S3.T1.2.2.6.2.8\" class=\"ltx_td ltx_align_center\">3.8</td>\n<td id=\"S3.T1.2.2.6.2.9\" class=\"ltx_td ltx_align_center\">12</td>\n<td id=\"S3.T1.2.2.6.2.10\" class=\"ltx_td ltx_align_center\">1.79</td>\n<td id=\"S3.T1.2.2.6.2.11\" class=\"ltx_td ltx_align_center\">8</td>\n</tr>\n<tr id=\"S3.T1.2.2.7.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.2.7.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\">GeoQuery</td>\n<td id=\"S3.T1.2.2.7.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">US Geography</td>\n<td id=\"S3.T1.2.2.7.3.3\" class=\"ltx_td ltx_align_center\">549</td>\n<td id=\"S3.T1.2.2.7.3.4\" class=\"ltx_td ltx_align_center\">49</td>\n<td id=\"S3.T1.2.2.7.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">279</td>\n<td id=\"S3.T1.2.2.7.3.6\" class=\"ltx_td ltx_align_center\">98</td>\n<td id=\"S3.T1.2.2.7.3.7\" class=\"ltx_td ltx_align_center\">3.6</td>\n<td id=\"S3.T1.2.2.7.3.8\" class=\"ltx_td ltx_align_center\">1.1</td>\n<td id=\"S3.T1.2.2.7.3.9\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"S3.T1.2.2.7.3.10\" class=\"ltx_td ltx_align_center\">1.77</td>\n<td id=\"S3.T1.2.2.7.3.11\" class=\"ltx_td ltx_align_center\">8</td>\n</tr>\n<tr id=\"S3.T1.2.2.8.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.2.8.4.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Restaurants</td>\n<td id=\"S3.T1.2.2.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Restaurants/Food</td>\n<td id=\"S3.T1.2.2.8.4.3\" class=\"ltx_td ltx_align_center\">228</td>\n<td id=\"S3.T1.2.2.8.4.4\" class=\"ltx_td ltx_align_center\">76</td>\n<td id=\"S3.T1.2.2.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\">74</td>\n<td id=\"S3.T1.2.2.8.4.6\" class=\"ltx_td ltx_align_center\">17</td>\n<td id=\"S3.T1.2.2.8.4.7\" class=\"ltx_td ltx_align_center\">16.4</td>\n<td id=\"S3.T1.2.2.8.4.8\" class=\"ltx_td ltx_align_center\">2.3</td>\n<td id=\"S3.T1.2.2.8.4.9\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"S3.T1.2.2.8.4.10\" class=\"ltx_td ltx_align_center\">1.17</td>\n<td id=\"S3.T1.2.2.8.4.11\" class=\"ltx_td ltx_align_center\">2</td>\n</tr>\n<tr id=\"S3.T1.2.2.9.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.2.9.5.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Scholar</td>\n<td id=\"S3.T1.2.2.9.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Academic Publication</td>\n<td id=\"S3.T1.2.2.9.5.3\" class=\"ltx_td ltx_align_center\">499</td>\n<td id=\"S3.T1.2.2.9.5.4\" class=\"ltx_td ltx_align_center\">100</td>\n<td id=\"S3.T1.2.2.9.5.5\" class=\"ltx_td ltx_align_center ltx_border_r\">218</td>\n<td id=\"S3.T1.2.2.9.5.6\" class=\"ltx_td ltx_align_center\">146</td>\n<td id=\"S3.T1.2.2.9.5.7\" class=\"ltx_td ltx_align_center\">4.2</td>\n<td id=\"S3.T1.2.2.9.5.8\" class=\"ltx_td ltx_align_center\">3.2</td>\n<td id=\"S3.T1.2.2.9.5.9\" class=\"ltx_td ltx_align_center\">6</td>\n<td id=\"S3.T1.2.2.9.5.10\" class=\"ltx_td ltx_align_center\">1.02</td>\n<td id=\"S3.T1.2.2.9.5.11\" class=\"ltx_td ltx_align_center\">2</td>\n</tr>\n<tr id=\"S3.T1.2.2.10.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.2.10.6.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Academic</td>\n<td id=\"S3.T1.2.2.10.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Microsoft Academic</td>\n<td id=\"S3.T1.2.2.10.6.3\" class=\"ltx_td ltx_align_center\">120</td>\n<td id=\"S3.T1.2.2.10.6.4\" class=\"ltx_td ltx_align_center\">38</td>\n<td id=\"S3.T1.2.2.10.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\">38</td>\n<td id=\"S3.T1.2.2.10.6.6\" class=\"ltx_td ltx_align_center\">92</td>\n<td id=\"S3.T1.2.2.10.6.7\" class=\"ltx_td ltx_align_center\">1.1</td>\n<td id=\"S3.T1.2.2.10.6.8\" class=\"ltx_td ltx_align_center\">3</td>\n<td id=\"S3.T1.2.2.10.6.9\" class=\"ltx_td ltx_align_center\">6</td>\n<td id=\"S3.T1.2.2.10.6.10\" class=\"ltx_td ltx_align_center\">1.04</td>\n<td id=\"S3.T1.2.2.10.6.11\" class=\"ltx_td ltx_align_center\">3</td>\n</tr>\n<tr id=\"S3.T1.2.2.11.7\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.2.11.7.1\" class=\"ltx_td ltx_align_left ltx_border_r\">IMDB</td>\n<td id=\"S3.T1.2.2.11.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Internet Movie</td>\n<td id=\"S3.T1.2.2.11.7.3\" class=\"ltx_td ltx_align_center\">78</td>\n<td id=\"S3.T1.2.2.11.7.4\" class=\"ltx_td ltx_align_center\">26</td>\n<td id=\"S3.T1.2.2.11.7.5\" class=\"ltx_td ltx_align_center ltx_border_r\">26</td>\n<td id=\"S3.T1.2.2.11.7.6\" class=\"ltx_td ltx_align_center\">52</td>\n<td id=\"S3.T1.2.2.11.7.7\" class=\"ltx_td ltx_align_center\">1.5</td>\n<td id=\"S3.T1.2.2.11.7.8\" class=\"ltx_td ltx_align_center\">1.9</td>\n<td id=\"S3.T1.2.2.11.7.9\" class=\"ltx_td ltx_align_center\">5</td>\n<td id=\"S3.T1.2.2.11.7.10\" class=\"ltx_td ltx_align_center\">1.01</td>\n<td id=\"S3.T1.2.2.11.7.11\" class=\"ltx_td ltx_align_center\">2</td>\n</tr>\n<tr id=\"S3.T1.2.2.12.8\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.2.12.8.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">Yelp</td>\n<td id=\"S3.T1.2.2.12.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">Yelp Website</td>\n<td id=\"S3.T1.2.2.12.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">78</td>\n<td id=\"S3.T1.2.2.12.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">26</td>\n<td id=\"S3.T1.2.2.12.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">24</td>\n<td id=\"S3.T1.2.2.12.8.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">89</td>\n<td id=\"S3.T1.2.2.12.8.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">1.2</td>\n<td id=\"S3.T1.2.2.12.8.8\" class=\"ltx_td ltx_align_center ltx_border_bb\">2</td>\n<td id=\"S3.T1.2.2.12.8.9\" class=\"ltx_td ltx_align_center ltx_border_bb\">4</td>\n<td id=\"S3.T1.2.2.12.8.10\" class=\"ltx_td ltx_align_center ltx_border_bb\">1</td>\n<td id=\"S3.T1.2.2.12.8.11\" class=\"ltx_td ltx_align_center ltx_border_bb\">1</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As we are the first to study cross-silo FL for semantic parsing, there is no benchmark for this task. Thus we establish an evaluation setup by re-purposing eight single-domain text-to-SQL datasets Finegan-Dollak et al. (2018) as eight “clients”, which demonstrate high heterogeneity in terms of dataset sizes, domains, language usage, database structures and SQL complexity. Table 1 shows their statistics.",
            "(1) The impact of diversity, redundancy and complexity: In Table 2 and 3, for Restaurants, the results of finetuning, centralized training, and varying weighting mechanisms of FedOPT are pretty close and all very high (close to 100%), which shows it is a relatively easy dataset for any learning paradigm and weighting mechanism. Looking at Table 1, Restaurants has the smallest “SQL pattern count” (i.e., lowest diversity), second largest “Questions per unique SQL query” (i.e., second highest redundancy), close to the smallest “Unique tables per query” and “SELECTs per query” (i.e., close to lowest complexity), which makes models easily learn from this dataset (Section 3). For other datasets, they have higher diversity, lower redundancy, or higher complexity, which makes models harder to make predictions and the performance is generally lower than Restaurants. (2) The impact of dataset size: Smaller datasets tend to have lower performance, as shown in Table 2, which means they are harder to learn in general due to lack of data; however, they can benefit more from our proposed FL paradigm."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: \nMain results for different learning paradigms and FL algorithms. \"†\": large-sized clients. \"§\": medium-sized clients. \"*\": small-sized clients.\n",
        "table": "<table id=\"S5.T2.3.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.3.3.4.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.3.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.1.1\" class=\"ltx_text\"></span></th>\n<th id=\"S5.T2.3.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.2.1\" class=\"ltx_text\">Advising†</span></th>\n<th id=\"S5.T2.3.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.3.1\" class=\"ltx_text\">ATIS†</span></th>\n<th id=\"S5.T2.3.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.4.1\" class=\"ltx_text\">GeoQuery§</span></th>\n<th id=\"S5.T2.3.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.5.1\" class=\"ltx_text\">Restaurants§</span></th>\n<th id=\"S5.T2.3.3.4.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.6.1\" class=\"ltx_text\">Scholar§</span></th>\n<th id=\"S5.T2.3.3.4.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.7.1\" class=\"ltx_text\">Academic*</span></th>\n<th id=\"S5.T2.3.3.4.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.8.1\" class=\"ltx_text\">IMDB*</span></th>\n<th id=\"S5.T2.3.3.4.1.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.9.1\" class=\"ltx_text\">Yelp*</span></th>\n<th id=\"S5.T2.3.3.4.1.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.10.1\" class=\"ltx_text\">MacroAvg</span></th>\n<th id=\"S5.T2.3.3.4.1.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T2.3.3.4.1.11.1\" class=\"ltx_text\">MicroAvg</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.3.3.5.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.3.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Finetuning</th>\n<td id=\"S5.T2.3.3.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">84.47</td>\n<td id=\"S5.T2.3.3.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">53.91</td>\n<td id=\"S5.T2.3.3.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">72.76</td>\n<td id=\"S5.T2.3.3.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">98.65</td>\n<td id=\"S5.T2.3.3.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">74.31</td>\n<td id=\"S5.T2.3.3.5.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">57.89</td>\n<td id=\"S5.T2.3.3.5.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">26.92</td>\n<td id=\"S5.T2.3.3.5.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">33.33</td>\n<td id=\"S5.T2.3.3.5.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\">62.78</td>\n<td id=\"S5.T2.3.3.5.1.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">71.47</td>\n</tr>\n<tr id=\"S5.T2.3.3.6.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.3.6.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Centralized</th>\n<td id=\"S5.T2.3.3.6.2.2\" class=\"ltx_td ltx_align_center\">85.51</td>\n<td id=\"S5.T2.3.3.6.2.3\" class=\"ltx_td ltx_align_center\">56.38</td>\n<td id=\"S5.T2.3.3.6.2.4\" class=\"ltx_td ltx_align_center\">79.21</td>\n<td id=\"S5.T2.3.3.6.2.5\" class=\"ltx_td ltx_align_center\">100</td>\n<td id=\"S5.T2.3.3.6.2.6\" class=\"ltx_td ltx_align_center\">72.48</td>\n<td id=\"S5.T2.3.3.6.2.7\" class=\"ltx_td ltx_align_center\">65.79</td>\n<td id=\"S5.T2.3.3.6.2.8\" class=\"ltx_td ltx_align_center\">61.54</td>\n<td id=\"S5.T2.3.3.6.2.9\" class=\"ltx_td ltx_align_center\">41.67</td>\n<td id=\"S5.T2.3.3.6.2.10\" class=\"ltx_td ltx_align_center\">70.32</td>\n<td id=\"S5.T2.3.3.6.2.11\" class=\"ltx_td ltx_nopad_r ltx_align_center\">74.21</td>\n</tr>\n<tr id=\"S5.T2.3.3.7.3\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.3.7.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedOPT</th>\n<td id=\"S5.T2.3.3.7.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">79.76</td>\n<td id=\"S5.T2.3.3.7.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">51.23</td>\n<td id=\"S5.T2.3.3.7.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.3.3.7.3.4.1\" class=\"ltx_text ltx_font_bold\">77.42</span></td>\n<td id=\"S5.T2.3.3.7.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.3.3.7.3.5.1\" class=\"ltx_text ltx_font_bold\">98.65</span></td>\n<td id=\"S5.T2.3.3.7.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.3.3.7.3.6.1\" class=\"ltx_text ltx_font_bold\">66.51</span></td>\n<td id=\"S5.T2.3.3.7.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\">50</td>\n<td id=\"S5.T2.3.3.7.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">34.62</td>\n<td id=\"S5.T2.3.3.7.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\">8.33</td>\n<td id=\"S5.T2.3.3.7.3.10\" class=\"ltx_td ltx_align_center ltx_border_t\">58.32</td>\n<td id=\"S5.T2.3.3.7.3.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">68.49</td>\n</tr>\n<tr id=\"S5.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">FedOPT<sub id=\"S5.T2.1.1.1.1.1\" class=\"ltx_sub\"><span id=\"S5.T2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">lorar</span></sub>\n</th>\n<td id=\"S5.T2.1.1.1.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">80.98</span></td>\n<td id=\"S5.T2.1.1.1.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">52.35</span></td>\n<td id=\"S5.T2.1.1.1.4\" class=\"ltx_td ltx_align_center\">75.99</td>\n<td id=\"S5.T2.1.1.1.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">98.65</span></td>\n<td id=\"S5.T2.1.1.1.6\" class=\"ltx_td ltx_align_center\">64.68</td>\n<td id=\"S5.T2.1.1.1.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.1.7.1\" class=\"ltx_text ltx_font_bold\">68.42</span></td>\n<td id=\"S5.T2.1.1.1.8\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.1.8.1\" class=\"ltx_text ltx_font_bold\">38.46</span></td>\n<td id=\"S5.T2.1.1.1.9\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.1.9.1\" class=\"ltx_text ltx_font_bold\">20.83</span></td>\n<td id=\"S5.T2.1.1.1.10\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.1.10.1\" class=\"ltx_text ltx_font_bold\">62.55</span></td>\n<td id=\"S5.T2.1.1.1.11\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T2.1.1.1.11.1\" class=\"ltx_text ltx_font_bold\">69.39</span></td>\n</tr>\n<tr id=\"S5.T2.3.3.8.4\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.3.8.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedAvg</th>\n<td id=\"S5.T2.3.3.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.3.3.8.4.2.1\" class=\"ltx_text ltx_font_bold\">76.44</span></td>\n<td id=\"S5.T2.3.3.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.3.3.8.4.3.1\" class=\"ltx_text ltx_font_bold\">50.11</span></td>\n<td id=\"S5.T2.3.3.8.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">59.86</td>\n<td id=\"S5.T2.3.3.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">72.97</td>\n<td id=\"S5.T2.3.3.8.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\">38.07</td>\n<td id=\"S5.T2.3.3.8.4.7\" class=\"ltx_td ltx_align_center ltx_border_t\">2.63</td>\n<td id=\"S5.T2.3.3.8.4.8\" class=\"ltx_td ltx_align_center ltx_border_t\">7.69</td>\n<td id=\"S5.T2.3.3.8.4.9\" class=\"ltx_td ltx_align_center ltx_border_t\">12.5</td>\n<td id=\"S5.T2.3.3.8.4.10\" class=\"ltx_td ltx_align_center ltx_border_t\">40.03</td>\n<td id=\"S5.T2.3.3.8.4.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">57.89</td>\n</tr>\n<tr id=\"S5.T2.2.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.2.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">FedAvg<sub id=\"S5.T2.2.2.2.1.1\" class=\"ltx_sub\"><span id=\"S5.T2.2.2.2.1.1.1\" class=\"ltx_text ltx_font_italic\">lorar</span></sub>\n</th>\n<td id=\"S5.T2.2.2.2.2\" class=\"ltx_td ltx_align_center\">74.69</td>\n<td id=\"S5.T2.2.2.2.3\" class=\"ltx_td ltx_align_center\">49.89</td>\n<td id=\"S5.T2.2.2.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.2.2.2.4.1\" class=\"ltx_text ltx_font_bold\">68.82</span></td>\n<td id=\"S5.T2.2.2.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.2.2.2.5.1\" class=\"ltx_text ltx_font_bold\">98.65</span></td>\n<td id=\"S5.T2.2.2.2.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.2.2.2.6.1\" class=\"ltx_text ltx_font_bold\">52.29</span></td>\n<td id=\"S5.T2.2.2.2.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.2.2.2.7.1\" class=\"ltx_text ltx_font_bold\">65.79</span></td>\n<td id=\"S5.T2.2.2.2.8\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.2.2.2.8.1\" class=\"ltx_text ltx_font_bold\">46.15</span></td>\n<td id=\"S5.T2.2.2.2.9\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.2.2.2.9.1\" class=\"ltx_text ltx_font_bold\">25</span></td>\n<td id=\"S5.T2.2.2.2.10\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.2.2.2.10.1\" class=\"ltx_text ltx_font_bold\">60.16</span></td>\n<td id=\"S5.T2.2.2.2.11\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T2.2.2.2.11.1\" class=\"ltx_text ltx_font_bold\">63.91</span></td>\n</tr>\n<tr id=\"S5.T2.3.3.9.5\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.3.9.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedProx</th>\n<td id=\"S5.T2.3.3.9.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.3.3.9.5.2.1\" class=\"ltx_text ltx_font_bold\">74.52</span></td>\n<td id=\"S5.T2.3.3.9.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.3.3.9.5.3.1\" class=\"ltx_text ltx_font_bold\">50.56</span></td>\n<td id=\"S5.T2.3.3.9.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">65.95</td>\n<td id=\"S5.T2.3.3.9.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">81.08</td>\n<td id=\"S5.T2.3.3.9.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\">38.53</td>\n<td id=\"S5.T2.3.3.9.5.7\" class=\"ltx_td ltx_align_center ltx_border_t\">10.53</td>\n<td id=\"S5.T2.3.3.9.5.8\" class=\"ltx_td ltx_align_center ltx_border_t\">3.85</td>\n<td id=\"S5.T2.3.3.9.5.9\" class=\"ltx_td ltx_align_center ltx_border_t\">8.33</td>\n<td id=\"S5.T2.3.3.9.5.10\" class=\"ltx_td ltx_align_center ltx_border_t\">41.67</td>\n<td id=\"S5.T2.3.3.9.5.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">58.84</td>\n</tr>\n<tr id=\"S5.T2.3.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">FedProx<sub id=\"S5.T2.3.3.3.1.1\" class=\"ltx_sub\"><span id=\"S5.T2.3.3.3.1.1.1\" class=\"ltx_text ltx_font_italic\">lorar</span></sub>\n</th>\n<td id=\"S5.T2.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">73.12</td>\n<td id=\"S5.T2.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">49.66</td>\n<td id=\"S5.T2.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">67.38</span></td>\n<td id=\"S5.T2.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.3.3.5.1\" class=\"ltx_text ltx_font_bold\">98.65</span></td>\n<td id=\"S5.T2.3.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.3.3.6.1\" class=\"ltx_text ltx_font_bold\">48.17</span></td>\n<td id=\"S5.T2.3.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.3.3.7.1\" class=\"ltx_text ltx_font_bold\">63.16</span></td>\n<td id=\"S5.T2.3.3.3.8\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.3.3.8.1\" class=\"ltx_text ltx_font_bold\">46.15</span></td>\n<td id=\"S5.T2.3.3.3.9\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.3.3.9.1\" class=\"ltx_text ltx_font_bold\">20.83</span></td>\n<td id=\"S5.T2.3.3.3.10\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.3.3.10.1\" class=\"ltx_text ltx_font_bold\">58.39</span></td>\n<td id=\"S5.T2.3.3.3.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.3.3.11.1\" class=\"ltx_text ltx_font_bold\">62.42</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Centralized vs. Finetuning. As Table 2 shows, compared with the individual finetuning setting, the model performance under the centralized setting has been improved on all the datasets except Scholar. This means merging all the data to train a model, which increases the size and diversity of training data, can improve the model’s generalization ability and lead to improvement for most datasets. This observation also motivates us to leverage these datasets to study FL for semantic parsing, which is a more practical paradigm than the centralized one.",
            "Effectiveness of Lorar in FL. Applying our proposed Lorar mechanism can substantially improve the performance of all three FL algorithms overall. As Table 2 shows, for FedOPT, our proposed FedOPTlorarlorar{}_{\\texttt{lorar}} performs substantially better or similarly on all clients, except for a slight drop on GeoQuery and Scholar. Moreover, on the three smaller datasets: Academic, IMDB and Yelp, Lorar brings much larger performance gains. For FedAvg and FedProx, in addition to these three datasets, Lorar also brings substantial improvements on two medium-sized clients: Restaurants and Scholar. These observations validate the effectiveness of our proposed mechanism under different FL algorithms and across different clients.",
            "FL vs. Finetuning/Centralized.\nAs Table 2 shows, the original FedOPT outperforms finetuning on GeoQuery and IMDB, which shows that FL can boost the model performance for some clients. In addition, although there is still a gap between existing FL algorithms (FedOPT, FedAvg, and FedProx) and the centralized setting, by equipping them with our proposed Lorar, we can reduce the gap by 4-20 points (i.e., absolute difference under MacroAvg). It is worth noting that institutions are often reluctant or prohibited to share their data in practice, especially for SQL data that may directly reveal private database content.\nTherefore, the centralized paradigm is impractical.\nNonetheless, it can serve as a useful reference to help validate how effective an FL algorithm is in fully exploiting heterogeneous data across multiple clients.\nThe results show that our benchmark provides a challenging testbed for a realistic FL problem, and there is still a large room to further improve the FL algorithms.",
            "(1) The impact of diversity, redundancy and complexity: In Table 2 and 3, for Restaurants, the results of finetuning, centralized training, and varying weighting mechanisms of FedOPT are pretty close and all very high (close to 100%), which shows it is a relatively easy dataset for any learning paradigm and weighting mechanism. Looking at Table 1, Restaurants has the smallest “SQL pattern count” (i.e., lowest diversity), second largest “Questions per unique SQL query” (i.e., second highest redundancy), close to the smallest “Unique tables per query” and “SELECTs per query” (i.e., close to lowest complexity), which makes models easily learn from this dataset (Section 3). For other datasets, they have higher diversity, lower redundancy, or higher complexity, which makes models harder to make predictions and the performance is generally lower than Restaurants. (2) The impact of dataset size: Smaller datasets tend to have lower performance, as shown in Table 2, which means they are harder to learn in general due to lack of data; however, they can benefit more from our proposed FL paradigm."
        ]
    },
    "S6.T3": {
        "caption": "Table 3: \nAlternative weighting mechanisms for FedOPT on the test set of our proposed benchmark, where FedOPT only uses a client’s training set size (w/o loss reduction) as its weight, FedOPTlr only uses a client’s loss reduction during each round (w/o train set size) as its weight, FedOPTlorarlorar{}_{\\texttt{lorar}} considers both factors as its weight (Eqn. (6)) and FedOPTequal gives each client equal weight (w/o considering both factors).",
        "table": "<table id=\"S6.T3.3.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T3.3.3.4.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.3.3.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.1.1\" class=\"ltx_text\"></span></th>\n<th id=\"S6.T3.3.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.2.1\" class=\"ltx_text\">Advising</span></th>\n<th id=\"S6.T3.3.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.3.1\" class=\"ltx_text\">ATIS</span></th>\n<th id=\"S6.T3.3.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.4.1\" class=\"ltx_text\">GeoQuery</span></th>\n<th id=\"S6.T3.3.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.5.1\" class=\"ltx_text\">Restaurants</span></th>\n<th id=\"S6.T3.3.3.4.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.6.1\" class=\"ltx_text\">Scholar</span></th>\n<th id=\"S6.T3.3.3.4.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.7.1\" class=\"ltx_text\">Academic</span></th>\n<th id=\"S6.T3.3.3.4.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.8.1\" class=\"ltx_text\">IMDB</span></th>\n<th id=\"S6.T3.3.3.4.1.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.9.1\" class=\"ltx_text\">Yelp</span></th>\n<th id=\"S6.T3.3.3.4.1.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.10.1\" class=\"ltx_text\">MacroAvg</span></th>\n<th id=\"S6.T3.3.3.4.1.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.3.3.4.1.11.1\" class=\"ltx_text\">MicroAvg</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T3.3.3.5.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.3.3.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedOPT</th>\n<td id=\"S6.T3.3.3.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">79.76</td>\n<td id=\"S6.T3.3.3.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">51.23</td>\n<td id=\"S6.T3.3.3.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">77.42</td>\n<td id=\"S6.T3.3.3.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S6.T3.3.3.5.1.5.1\" class=\"ltx_text ltx_font_bold\">98.65</span></td>\n<td id=\"S6.T3.3.3.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S6.T3.3.3.5.1.6.1\" class=\"ltx_text ltx_font_bold\">66.51</span></td>\n<td id=\"S6.T3.3.3.5.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">50</td>\n<td id=\"S6.T3.3.3.5.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">34.62</td>\n<td id=\"S6.T3.3.3.5.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">8.33</td>\n<td id=\"S6.T3.3.3.5.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\">58.32</td>\n<td id=\"S6.T3.3.3.5.1.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">68.49</td>\n</tr>\n<tr id=\"S6.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">FedOPT<sub id=\"S6.T3.1.1.1.1.1\" class=\"ltx_sub\"><span id=\"S6.T3.1.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">lr</span></sub>\n</th>\n<td id=\"S6.T3.1.1.1.2\" class=\"ltx_td ltx_align_center\">75.04</td>\n<td id=\"S6.T3.1.1.1.3\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">53.47</span></td>\n<td id=\"S6.T3.1.1.1.4\" class=\"ltx_td ltx_align_center\">75.63</td>\n<td id=\"S6.T3.1.1.1.5\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T3.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">98.65</span></td>\n<td id=\"S6.T3.1.1.1.6\" class=\"ltx_td ltx_align_center\">62.39</td>\n<td id=\"S6.T3.1.1.1.7\" class=\"ltx_td ltx_align_center\">60.53</td>\n<td id=\"S6.T3.1.1.1.8\" class=\"ltx_td ltx_align_center\">34.62</td>\n<td id=\"S6.T3.1.1.1.9\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T3.1.1.1.9.1\" class=\"ltx_text ltx_font_bold\">25</span></td>\n<td id=\"S6.T3.1.1.1.10\" class=\"ltx_td ltx_align_center\">60.67</td>\n<td id=\"S6.T3.1.1.1.11\" class=\"ltx_td ltx_nopad_r ltx_align_center\">67.12</td>\n</tr>\n<tr id=\"S6.T3.2.2.2\" class=\"ltx_tr\">\n<th id=\"S6.T3.2.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">FedOPT<sub id=\"S6.T3.2.2.2.1.1\" class=\"ltx_sub\"><span id=\"S6.T3.2.2.2.1.1.1\" class=\"ltx_text ltx_font_italic\">equal</span></sub>\n</th>\n<td id=\"S6.T3.2.2.2.2\" class=\"ltx_td ltx_align_center\">76.96</td>\n<td id=\"S6.T3.2.2.2.3\" class=\"ltx_td ltx_align_center\">53.02</td>\n<td id=\"S6.T3.2.2.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T3.2.2.2.4.1\" class=\"ltx_text ltx_font_bold\">77.78</span></td>\n<td id=\"S6.T3.2.2.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T3.2.2.2.5.1\" class=\"ltx_text ltx_font_bold\">98.65</span></td>\n<td id=\"S6.T3.2.2.2.6\" class=\"ltx_td ltx_align_center\">63.3</td>\n<td id=\"S6.T3.2.2.2.7\" class=\"ltx_td ltx_align_center\">63.16</td>\n<td id=\"S6.T3.2.2.2.8\" class=\"ltx_td ltx_align_center\">34.62</td>\n<td id=\"S6.T3.2.2.2.9\" class=\"ltx_td ltx_align_center\">20.83</td>\n<td id=\"S6.T3.2.2.2.10\" class=\"ltx_td ltx_align_center\">61.04</td>\n<td id=\"S6.T3.2.2.2.11\" class=\"ltx_td ltx_nopad_r ltx_align_center\">68.13</td>\n</tr>\n<tr id=\"S6.T3.3.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T3.3.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">FedOPT<sub id=\"S6.T3.3.3.3.1.1\" class=\"ltx_sub\"><span id=\"S6.T3.3.3.3.1.1.1\" class=\"ltx_text ltx_font_italic\">lorar</span></sub>\n</th>\n<td id=\"S6.T3.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S6.T3.3.3.3.2.1\" class=\"ltx_text ltx_font_bold\">80.98</span></td>\n<td id=\"S6.T3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">52.35</td>\n<td id=\"S6.T3.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">75.99</td>\n<td id=\"S6.T3.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S6.T3.3.3.3.5.1\" class=\"ltx_text ltx_font_bold\">98.65</span></td>\n<td id=\"S6.T3.3.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">64.68</td>\n<td id=\"S6.T3.3.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S6.T3.3.3.3.7.1\" class=\"ltx_text ltx_font_bold\">68.42</span></td>\n<td id=\"S6.T3.3.3.3.8\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S6.T3.3.3.3.8.1\" class=\"ltx_text ltx_font_bold\">38.46</span></td>\n<td id=\"S6.T3.3.3.3.9\" class=\"ltx_td ltx_align_center ltx_border_bb\">20.83</td>\n<td id=\"S6.T3.3.3.3.10\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S6.T3.3.3.3.10.1\" class=\"ltx_text ltx_font_bold\">62.55</span></td>\n<td id=\"S6.T3.3.3.3.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S6.T3.3.3.3.11.1\" class=\"ltx_text ltx_font_bold\">69.39</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As FedOPT performs best among all three FL baselines, we use it to compare Lorar with alternative weighting mechanisms. As Table 3 shows, Lorar, which considers both the training set size and the loss reduction\nin the weight, can achieve the best results. Comparing FedOPTlr (i.e., FedOPT with only loss reduction considered in the weight) and FedOPTlorarlorar{}_{\\texttt{lorar}}, we can see removing the training set size from the weight will lead to a large drop under MacroAvg and MicroAvg, which indicates that training set size is an important factor during the aggregation. This is intuitive since for those clients which have more training data, their local models tend to be more reliable and more generalizable. We also compare with FedOPTequal where all clients are given the same weight. We can see that our FedOPTlorarlorar{}_{\\texttt{lorar}} yields superior performance. The conclusion can also be verified in Figure 6 in Appendix, where we show their performance variation under different communication rounds."
        ]
    }
}