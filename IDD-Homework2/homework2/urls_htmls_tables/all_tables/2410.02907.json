{
    "id_table_1": {
        "caption": "Table 1:  Results for MiniWoB++ and WebArena, broken down by domain, reporting mean reward for MiniWoB++ and task success rate (SR) for WebArena. We compare the zero-shot agent with agents fine-tuned with NNetnav and instruction-first demonstrations. Overall, fine-tuning with NNetnav leads to the largest improvements: from 28% to 48% on MiniWoB++; from 1% to 7.2% on WebArena.",
        "table": "S5.T1.1",
        "footnotes": [],
        "references": [
            "Instead of starting with a sampled instruction, we start by sampling an  interaction  first, and then retroactively labeling it into an instruction that is feasible by design. At a high-level, our approach  NNetscape Navigator  (NNetnav, Fig  1 ), uses a language model exploration policy to perform extended interactions with an environment, and another language model trajectory labeler to annotate trajectories with instructions 1 1 1 All code and data will be available  here . . To effectively control the exponential space of meaningful interactions, NNetnav uses the hierarchical structure of language instructions as a pruning heuristic: for exploration to discover a meaningfully complex task, trajectory prefixes must correspond to meaningful sub-tasks. Thus, during an exploration episode, if a language model cannot label trajectory prefixes (at set time-steps) with a sub-task, further exploration is automatically terminated. Imposing such a structure over search not only enhances efficiency, but also results in complex and hierarchical instructions (See Table  5  for examples). NNetnav prompts the same base language model for exploration, relabeling and inferring sub-tasks, and effectively addresses all limitations of instruction-first data collection.",
            "NNetnav (Fig  1 ) is an  interaction-first  method for constructing demonstrations: An exploration policy interacts with a browser in a structured manner to sample long trajectories which are retroactively labeled into instructions ( 3.2 ). We then post-process each trajectory to add post-hoc reasoning steps corresponding to the generated instructions, and then use this data for supervised fine-tuning ( 3.3 ). We provide detailed pseudo-code for the exploration and relabeling steps in NNetnav in Algorithm  1 .",
            "We report results from all model settings in Table  1 . We find that fine-tuning the zero-shot policy   LM subscript  LM \\pi_{\\text{LM}} italic_ start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT  with synthetic demonstrations from NNetnav leads to consistent improvements on all tasks in MiniWoB++, leading to a 20 point improvement overall. We note an improvement of over 6 points from fine-tuning with NNetnav demonstrations on WebArena. Importantly, gains from fine-tuning with NNetnav exceeds those from using instruction-first methods by 12 points on MiniWoB++ and 1.2 points on WebArena.",
            "We observe highly non-uniform improvements on WebArena with no improvements on Reddit and Gitlab in particular. We hypothesize that this is due to the coarse nature of WebArenas success rate (SR) evaluation, since it does not provide partial credit. Thus, inspired by  Pan et al. ( 2024 ) , we develop a model based evaluation using the largest publicly available GPT-4o (specifically  gpt-4o-2024-08-06 ) model to assign a graded reward from 1 to 5 to model outputs for each test instruction (see Appendix  A.2  for full prompt). We present results from model-based evaluation in Table  2 . At the level of model settings we observe the same trend: Zero-Shot  < < <  SFT (Instruction-First)  < < <  SFT (NNetnav + Distil.)  < < <  SFT (NNetnav). However since this evaluation is more graded, we find consistent improvements from using NNetnav demonstrations across all websites, including Reddit and Gitlab, where improvements of 0.92 points and 0.72 points are observed, respectively. As expected, performance rankings sometimes changes with such graded evaluation  e.g.  on CMS, all fine-tuned models are tied in terms of SR (Table  1 ), but not in terms of graded reward (Table  2 ). Overall, we believe WebArena evaluations should incorporate both overall SR and fine-grained model based evaluation for a more comprehensive understanding of system performance.",
            "For MiniWoB++,   LM subscript  LM \\pi_{\\text{LM}} italic_ start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT  conditions on the current observation  o t subscript o t o_{t} italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , the goal  g g g italic_g  and the previous action  a t  1 subscript a t 1 a_{t-1} italic_a start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT  (see prompt in  A.1 ). Thus, we pre-process each  ( g ,  ) g  (g,\\tau) ( italic_g , italic_ )  demonstration into inputs  ( g , o t , a t  1 ) g subscript o t subscript a t 1 (g,o_{t},a_{t-1}) ( italic_g , italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT )  with the corresponding reasoning step and action  ( r t , a t ) subscript r t subscript a t (r_{t},a_{t}) ( italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )  as the target output."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Model-based evaluation on WebArena, broken down by domain. For each test instruction and predicted trajectory, we prompt a GPT-4o based reward model to output a graded reward from 1 to 5 based on a manual rubric. We find that fine-tuning with NNetnav outperforms all other settings.",
        "table": "S5.T2.1",
        "footnotes": [],
        "references": [
            "NNetnav (Fig  1 ) is an  interaction-first  method for constructing demonstrations: An exploration policy interacts with a browser in a structured manner to sample long trajectories which are retroactively labeled into instructions ( 3.2 ). We then post-process each trajectory to add post-hoc reasoning steps corresponding to the generated instructions, and then use this data for supervised fine-tuning ( 3.3 ). We provide detailed pseudo-code for the exploration and relabeling steps in NNetnav in Algorithm  1 .",
            "The exploration policy in this work is implemented using a language model that generates a reasoning step, before choosing an action ( 2 ). Since actions in our demonstration set are a result of exploration, corresponding reasoning steps are not generally related to the retroactively generated instruction. Thus, for each demonstration in our synthetic demonstration set, we post-hoc annotate every action with a new reasoning step that directly corresponds to the generated instruction. Concretely, given every  ( g ^ , o i , a i ) ^ g subscript o i subscript a i (\\hat{g},o_{i},a_{i}) ( over^ start_ARG italic_g end_ARG , italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  tuple in our synthetic demonstration set, we prompt a language model to output a suitable reasoning step for choosing action  a i subscript a i a_{i} italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  given the instruction  g ^ ^ g \\hat{g} over^ start_ARG italic_g end_ARG  and current observation  o i subscript o i o_{i} italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . We note that such a post-hoc reasoning procedure is similar to  Yang et al. ( 2024 ) .",
            "We use the BrowserGym framework  (Drouin et al.,  2024 )  for experiments with MiniWoB++ and prune out the full DOM to only keep visible elements. During inference, we set the max episode length for   LM subscript  LM \\pi_{\\text{LM}} italic_ start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT  as 30 for WebArena (following  Zhou et al. ( 2023 ) ), and 20 for MiniWoB++. WebArena requires agents to output a special  stop  action for outputting answers. We post-process NNetnav demonstrations to add a  stop  action at the end of the trajectory using a prompted LM (See Appendix  A.2  for details).",
            "We observe highly non-uniform improvements on WebArena with no improvements on Reddit and Gitlab in particular. We hypothesize that this is due to the coarse nature of WebArenas success rate (SR) evaluation, since it does not provide partial credit. Thus, inspired by  Pan et al. ( 2024 ) , we develop a model based evaluation using the largest publicly available GPT-4o (specifically  gpt-4o-2024-08-06 ) model to assign a graded reward from 1 to 5 to model outputs for each test instruction (see Appendix  A.2  for full prompt). We present results from model-based evaluation in Table  2 . At the level of model settings we observe the same trend: Zero-Shot  < < <  SFT (Instruction-First)  < < <  SFT (NNetnav + Distil.)  < < <  SFT (NNetnav). However since this evaluation is more graded, we find consistent improvements from using NNetnav demonstrations across all websites, including Reddit and Gitlab, where improvements of 0.92 points and 0.72 points are observed, respectively. As expected, performance rankings sometimes changes with such graded evaluation  e.g.  on CMS, all fine-tuned models are tied in terms of SR (Table  1 ), but not in terms of graded reward (Table  2 ). Overall, we believe WebArena evaluations should incorporate both overall SR and fine-grained model based evaluation for a more comprehensive understanding of system performance.",
            "We visualize overall improvements in exploration efficiency in Fig  2 . Each horizontal line depicts the fraction of interaction episodes that terminate at a specific time-step (indicated by the y-axis), with the red shaded area depicting additional actions that were prevented from early pruning. We find clear evidence of computational savings. In particular, over 60% of all exploration episodes were pruned after 16 actions for WebArena. For MiniWoB++, 65% of episodes were pruned after just 4 actions in MiniWoB++, which we identify as interactions where these first actions resulted in execution failures that our pruning heuristic successfully identified.",
            "As mentioned in  2 , for supervised finetuning each demonstration is converted into multiple training instances. We perform this conversion differently based on input features of   LM subscript  LM \\pi_{\\text{LM}} italic_ start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT .",
            "For WebArena,   LM subscript  LM \\pi_{\\text{LM}} italic_ start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT  conditions on the current observation  o t subscript o t o_{t} italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , the goal  g g g italic_g  and all previous actions  { a 1 , a 2 , ... , a t  1 } subscript a 1 subscript a 2 ... subscript a t 1 \\{a_{1},a_{2},\\ldots,a_{t-1}\\} { italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , italic_a start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT }  (see prompt in  A.2 ). Thus, we pre-process each  ( g ,  ) g  (g,\\tau) ( italic_g , italic_ )  demonstration into inputs  ( g , o t , { a < t } ) g subscript o t subscript a absent t (g,o_{t},\\{a_{<t}\\}) ( italic_g , italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , { italic_a start_POSTSUBSCRIPT < italic_t end_POSTSUBSCRIPT } )  with  ( r t , a t ) subscript r t subscript a t (r_{t},a_{t}) ( italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )  as the target output."
        ]
    },
    "id_table_3": {
        "caption": "Table 5:  Example demonstrations obtained from NNetnav-6k. We note that these instructions are hierarchical, refer to concrete features and entities and plausible by design.",
        "table": "S5.SS0.SSS0.Px1.1.p1.1",
        "footnotes": [],
        "references": [
            "NNetnav (Fig  1 ) is an  interaction-first  method for constructing demonstrations: An exploration policy interacts with a browser in a structured manner to sample long trajectories which are retroactively labeled into instructions ( 3.2 ). We then post-process each trajectory to add post-hoc reasoning steps corresponding to the generated instructions, and then use this data for supervised fine-tuning ( 3.3 ). We provide detailed pseudo-code for the exploration and relabeling steps in NNetnav in Algorithm  1 .",
            "Can NNetnav demonstrations from an LM be used for improving the  same  LM agent? To answer this, we collect another set of NNetnav demonstrations on WebArena, using LM components based on Llama-3-8B-Instruct. Given the limitations of this smaller model, we anticipate fewer meaningful interactions. To compensate, we increase the number of episodes to 200 episodes per website, resulting in 302 demonstrations which we use for fine-tuning the same Llama-3-8B-Instruct agent. From results in Table  3 , we find improvements of 4.3 points on WebArena."
        ]
    },
    "id_table_4": {
        "caption": "Table 6:  Number of instances for supervised training experiments of  5  under various settings. Between NNetnav and Instruction-First, we only control for the number of episodes for a fair comparison, which results in different number of training instances.",
        "table": "S5.SS0.SSS0.Px1.2.p1.1",
        "footnotes": [
            ""
        ],
        "references": [
            "Finally, we use NNetnav to conduct a small study on cross-website generalization in web-agents. Concretely, we perform supervised fine-tuning of   LM subscript  LM \\pi_{\\text{LM}} italic_ start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT  on NNetnav demonstrations from Shopping, Maps and CMS, and evaluate generalization to Reddit and Gitlab. Here, we choose to report only model-based evaluation since success rates are 0 for these domains. From results in Table  4 , we note that average reward improves by 0.06 on held out websites, and by 0.13 on in-domain websites, suggesting some potential for cross-website transfer in LLM web-agents.",
            "To analyze diversity in these instructions, we follow methodology from  Wang et al. ( 2022 ) . Specifically, we use Stanza  (Qi et al.,  2020 )  to parse each instruction, identifying the verb closest to the root and its direct object. Fig  4  presents the top 15 verbs and their corresponding object nouns. Overall, we observe a diverse range of intents in the NNetnav-6k dataset. Additionally, we plot the distribution of instruction as well as trajectory lengths in Fig  4 , revealing further diversity in these aspects. Table  5  provides example demonstrations from NNetnav-6k, showcasing instructions from different websites. We find a number of complex, hierarchical instructions such as  Edit the issue Link to WCAG 2.1 instead of ...  that refer to specific features of the website ( r/art ,  Swings and roundabouts ), and are plausible by design. Many of these instructions share lots of common structure ( e.g.   Get walking directions from ...  and  Get cycling directions from ... ), and incorporating such structure into agents could be a promising direction for future work."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "S6.T5.1",
        "footnotes": [],
        "references": [
            "Instead of starting with a sampled instruction, we start by sampling an  interaction  first, and then retroactively labeling it into an instruction that is feasible by design. At a high-level, our approach  NNetscape Navigator  (NNetnav, Fig  1 ), uses a language model exploration policy to perform extended interactions with an environment, and another language model trajectory labeler to annotate trajectories with instructions 1 1 1 All code and data will be available  here . . To effectively control the exponential space of meaningful interactions, NNetnav uses the hierarchical structure of language instructions as a pruning heuristic: for exploration to discover a meaningfully complex task, trajectory prefixes must correspond to meaningful sub-tasks. Thus, during an exploration episode, if a language model cannot label trajectory prefixes (at set time-steps) with a sub-task, further exploration is automatically terminated. Imposing such a structure over search not only enhances efficiency, but also results in complex and hierarchical instructions (See Table  5  for examples). NNetnav prompts the same base language model for exploration, relabeling and inferring sub-tasks, and effectively addresses all limitations of instruction-first data collection.",
            "To analyze diversity in these instructions, we follow methodology from  Wang et al. ( 2022 ) . Specifically, we use Stanza  (Qi et al.,  2020 )  to parse each instruction, identifying the verb closest to the root and its direct object. Fig  4  presents the top 15 verbs and their corresponding object nouns. Overall, we observe a diverse range of intents in the NNetnav-6k dataset. Additionally, we plot the distribution of instruction as well as trajectory lengths in Fig  4 , revealing further diversity in these aspects. Table  5  provides example demonstrations from NNetnav-6k, showcasing instructions from different websites. We find a number of complex, hierarchical instructions such as  Edit the issue Link to WCAG 2.1 instead of ...  that refer to specific features of the website ( r/art ,  Swings and roundabouts ), and are plausible by design. Many of these instructions share lots of common structure ( e.g.   Get walking directions from ...  and  Get cycling directions from ... ), and incorporating such structure into agents could be a promising direction for future work."
        ]
    },
    "id_table_6": {
        "caption": "",
        "table": "A3.T6.1",
        "footnotes": [],
        "references": [
            "We report number of training instances from NNetnav and instruction-first generation for both environments in Table  6 ."
        ]
    }
}