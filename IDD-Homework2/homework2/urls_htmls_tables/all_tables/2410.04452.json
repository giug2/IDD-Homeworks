{
    "id_table_1": {
        "caption": "Table 1:  Performance evaluation of different methods",
        "table": "S6.T1.1",
        "footnotes": [],
        "references": [
            "This work aims to detect both explicit and implicit cognitive biases in LLMs by single-round or multi-round scene-based dialogues. In addition to detecting existing categories, users can also expand the evaluation scope according to their own needs and do more standard cognitive bias experiments. We designed two tasks: labeled cognitive bias detection and unlabeled cognitive bias detection. The labeled cognitive bias detection task aims to detect biases by explicitly providing the types of cognitive biases and evaluation criteria. Unlabeled cognitive bias detection does not provide specific kinds of cognitive biases. During the detection process, candidates need to be selected from various possible biases based on the current scene and undergo more detailed scrutiny. In Section  4.1  and Section  4.2 , we employed the labeled cognitive bias detection method to provide comprehensive detection results quickly. In addition, our proposed detection method in Section  5.3  aims to address unlabeled cognitive bias detection task, which is more suitable for real-world situations.",
            "The existing multi-agent frameworks based on LLMs cannot meet the controllability requirement for cognitive biases detection, and they are inflexible to construct dynamic multi-round dialogues. Hence, we propose a rule-based multi-agent communication framework (RuleGen), which allows agents to interact in an orderly and controllable manner. Moreover, to detect unlabeled biases in open environments, we propose a learnable bias detection method based on multi-agent framework. In detail, Section  5.1  explains the foundational architecture of RuleGen; Section  5.2  introduces the rules and steps for automatically building scenarios and how to supervise and correct agent behaviors; Section  5.3  describes the bias detection method involving cognitive bias identification, debate competition module, and the learnable decision module."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Ablation studies. Comparison of module performance",
        "table": "S6.T2.1",
        "footnotes": [],
        "references": [
            "This work aims to detect both explicit and implicit cognitive biases in LLMs by single-round or multi-round scene-based dialogues. In addition to detecting existing categories, users can also expand the evaluation scope according to their own needs and do more standard cognitive bias experiments. We designed two tasks: labeled cognitive bias detection and unlabeled cognitive bias detection. The labeled cognitive bias detection task aims to detect biases by explicitly providing the types of cognitive biases and evaluation criteria. Unlabeled cognitive bias detection does not provide specific kinds of cognitive biases. During the detection process, candidates need to be selected from various possible biases based on the current scene and undergo more detailed scrutiny. In Section  4.1  and Section  4.2 , we employed the labeled cognitive bias detection method to provide comprehensive detection results quickly. In addition, our proposed detection method in Section  5.3  aims to address unlabeled cognitive bias detection task, which is more suitable for real-world situations.",
            "While static datasets have played a role in revealing cognitive biases of LLMs, they exhibit limitations in capturing complex biases that require multiple interactions to manifest, such as order biases and planning fallacies. These dynamic biases rely on continuous decision-making processes, which are difficult to fully capture in a single response. Hence, we developed a dynamic dataset capable of simulating and capturing cognitive biases within ongoing interactions. It comprises multi-role scenario scripts, encompassing background settings, characters, tasks, and the logic of interactions between characters. Users can modify these scripts to generate personalized data. There are three distinct roles in the scripts: the Subject, the Confederate, and the Moderator. The Subject is the focal point for cognitive biases detection, the Confederate is to induce the Subject to display the targeted biases, while the Moderator neutrally responds to the Subjects queries and poses impartial questions. Due to constraints in time and cost, psychology experts guided us in selecting 10 cognitive biases suitable for multi-turn dialogue tests. Then psychology experts authored scenario generation texts, including details and output formats; these were further processed by GPT-4 to generate complete dialogue scripts covering scenario purposes, backgrounds, characters, rules, and evaluation methods. For specific scenario rules, refer to  5.2 ; finally, psychology professionals volunteered to fine-tune each GPT-4 generated dialogue script to ensure it aligns with experimental requirements. The reasons for the scripting and the experimental setup are detailed in Appendix B.",
            "The existing multi-agent frameworks based on LLMs cannot meet the controllability requirement for cognitive biases detection, and they are inflexible to construct dynamic multi-round dialogues. Hence, we propose a rule-based multi-agent communication framework (RuleGen), which allows agents to interact in an orderly and controllable manner. Moreover, to detect unlabeled biases in open environments, we propose a learnable bias detection method based on multi-agent framework. In detail, Section  5.1  explains the foundational architecture of RuleGen; Section  5.2  introduces the rules and steps for automatically building scenarios and how to supervise and correct agent behaviors; Section  5.3  describes the bias detection method involving cognitive bias identification, debate competition module, and the learnable decision module.",
            "RuleGen is proposed for simulating the multi-round dialogue in real-world scenarios according to the given script. It needs to control the fine behaviors of agents based on the rules of the current detection task. Inspired by  [ 27 ] , the role agents in RuleGen are composed of memory, planning, reflection, action, and agent configuration modules (Figure  2 ).",
            "Agent configuration : As illustrated in Figure  2 , we have established two distinct types of agents: role agents and system agents. In order to adapt to different scenarios and show personalized differences, RuleGen guides and constrains the action space of the role agents by setting the names, identities, tasks, and background stories. In addition to role agents, we also need system agents to allocate script resources, and supervise and correct the behaviors of role agents.",
            "As shown in Figure  2 , this part is divided into two key components: rule generation and rule interpreter, aiming at constructing various scenarios precisely according to the preset rules alone, without modifying the agents prompt and related codes.",
            "Micro Behavior Monitoring : As illustrated in Figure  2 , micro-level behavior monitoring involves system agents conducting meticulous monitoring of role agents interactions. These system agents evaluate responses against predefined interaction objectives and content. Employing Zero-Shot CoT  [ 36 ]  methodologies, the system agent assesses the appropriateness of a participant agents actions at each timestep  t t t italic_t , and guides corrective measures in the event of deviations. This process includes issuing a rectification directive when a role agents behavior diverges from the script or interaction goals. The role agent then adjusts its actions to ensure adherence to designated interaction protocols. Conversely, adherence to expected behavior is confirmed through a verification instruction.",
            "We utilized 301 static test samples annotated by psychology experts as a test dataset.  As Table  2  demonstrates, our multi-agent detection method significantly outperforms existing techniques. Compared to GPT-4, our method improved overall accuracy by 35.10%. This notable enhancement is especially prominent in complex cases with cognitive biases, where our detection accuracy for such cases increased by nearly 26.48% compared to GPT-4. The experimental results indicate a clear advantage of our method in identifying cases with cognitive biases. Moreover, in cases without cognitive biases, our method achieved an improvement of approximately 38.37% over GPT-4.",
            "First, we analyzed the basic framework combining candidate generation and knowledge retrieval to detect cognitive biases. An initial agent identifies biases and construct the candidate set. The final detection is made by another agent. Next, we added the pruned loser tree method to improve debate and decision-making among agents, with a referee agent finalizing the decision. Lastly, we integrated a reinforcement learning decision module to enhance the referee agents decision-making and adaptability. Results in Table  2  show notable improvements. Also as shown in Table 3, we use various optimization algorithms on our selected debate scenario training set as well as test set. The results show that the optimization of weights by reinforcement learning is optimal on both the training and test sets. The specific experimental setup can be found in Appendix F.2."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Comparison of Decision Module Accuracy under Different Algorithms",
        "table": "S6.T3.1",
        "footnotes": [],
        "references": [
            "This work aims to detect both explicit and implicit cognitive biases in LLMs by single-round or multi-round scene-based dialogues. In addition to detecting existing categories, users can also expand the evaluation scope according to their own needs and do more standard cognitive bias experiments. We designed two tasks: labeled cognitive bias detection and unlabeled cognitive bias detection. The labeled cognitive bias detection task aims to detect biases by explicitly providing the types of cognitive biases and evaluation criteria. Unlabeled cognitive bias detection does not provide specific kinds of cognitive biases. During the detection process, candidates need to be selected from various possible biases based on the current scene and undergo more detailed scrutiny. In Section  4.1  and Section  4.2 , we employed the labeled cognitive bias detection method to provide comprehensive detection results quickly. In addition, our proposed detection method in Section  5.3  aims to address unlabeled cognitive bias detection task, which is more suitable for real-world situations.",
            "The existing multi-agent frameworks based on LLMs cannot meet the controllability requirement for cognitive biases detection, and they are inflexible to construct dynamic multi-round dialogues. Hence, we propose a rule-based multi-agent communication framework (RuleGen), which allows agents to interact in an orderly and controllable manner. Moreover, to detect unlabeled biases in open environments, we propose a learnable bias detection method based on multi-agent framework. In detail, Section  5.1  explains the foundational architecture of RuleGen; Section  5.2  introduces the rules and steps for automatically building scenarios and how to supervise and correct agent behaviors; Section  5.3  describes the bias detection method involving cognitive bias identification, debate competition module, and the learnable decision module.",
            "Existing models performed well when they were told what type of bias to detect  [ 4 ] . However, cognitive bias detection without the type label is more difficult. This paper focuses on a deeper exploration of unlabeled cognitive bias detection, which is more in line with actual application. As shown in Figure  3 , a cognitive bias detection method (CBDC) is proposed to solve the challenges of detecting potential cognitive bias and improving interpretability.",
            "As the details shown in Figure  3 , firstly, we screen the test text  T T T italic_T  through two agents with different personalities: Aggressive  A r subscript A r A_{r} italic_A start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT  and Conservative  A c subscript A c A_{c} italic_A start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , and obtain cognitive bias sets  B r subscript B r B_{r} italic_B start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT  and  B c subscript B c B_{c} italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT . In order to prevent the real bias from being overlooked,  B r subscript B r B_{r} italic_B start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT  and  B c subscript B c B_{c} italic_B start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  are further merged to obtain the candidate set  B B B italic_B . Next, a specific bias category  B i subscript B i B_{i} italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  in the candidate set  B B B italic_B  will be passed to a specific competitive detection agent  CA i subscript CA i \\textit{CA}_{i} CA start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , and  CA i subscript CA i \\textit{CA}_{i} CA start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  will then determine whether the text  T T T italic_T  contains the bias category  B i subscript B i B_{i} italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT .",
            "As revealed in Figure  3 , the constructed loser tree has  N N N italic_N  leaf nodes, each node represents a competitive detection agent dedicated to detecting a specific cognitive bias. This approach can transform unlabeled detection into labeled detection, effectively simplifying the detection process. Subsequently, the agent employs labeled detection techniques to assess the presence of cognitive biases. It then constructs a loser tree for all leaf nodes that exhibit cognitive biases. These agents follow the structure of the loser tree and carry out an orderly and efficient debate in the order of:  1).  Opening (introducing the features and cases of the cognitive bias);  2).  Argument (citing evidence of the cognitive bias);  3).  Refutation (refuting the opponents views according to the previous debate content);  4).  Summarize views. The competition process continues until finally only one competitive detection agent is left. It is considered as the final cognitive bias type.",
            "As illustrated in Figure  3 , the decision module is divided into two stages: the training stage and the decision stage. Specifically, we set up a decision task to assess the performance of two agents within a given environment and make decisions based on a set of weights. In the training phase, we initialize a replay buffer with capacity  N N N italic_N  and define an action-value function  Q Q Q italic_Q  with random initial weights    \\theta italic_ . Concurrently, the target action-value function  Q ^ ^ Q \\hat{Q} over^ start_ARG italic_Q end_ARG  is initialized with    =  superscript    \\theta^{\\prime}=\\theta italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT = italic_ . Over  M M M italic_M  episodes, each episode starts with the initial state and its preprocessed sequence. At each time step  t t t italic_t , the agent uses a genetic algorithm strategy to search for the selection of an action  a t subscript a t a_{t} italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  to be performed in the environment. The resulting transition tuple  ( s t , a t , r t , s t + 1 ) subscript s t subscript a t subscript r t subscript s t 1 (s_{t},a_{t},r_{t},s_{t+1}) ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT )  is stored in the replay buffer  D D D italic_D . A minibatch of transitions is randomly sampled from  D D D italic_D , and the target  y j subscript y j y_{j} italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT  for each transition is computed as follows:  y j = r j subscript y j subscript r j y_{j}=r_{j} italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_r start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT  if the episode ends at the next step; otherwise  y j = r j +   max a   Q ^  ( s j + 1 , a  ;   ) subscript y j subscript r j  subscript superscript a  ^ Q subscript s j 1 superscript a  superscript   y_{j}=r_{j}+\\gamma\\max_{a^{\\prime}}\\hat{Q}(s_{j+1},a^{\\prime};\\theta^{\\prime}) italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_r start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_ roman_max start_POSTSUBSCRIPT italic_a start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT over^ start_ARG italic_Q end_ARG ( italic_s start_POSTSUBSCRIPT italic_j + 1 end_POSTSUBSCRIPT , italic_a start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ; italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ) .The network parameters    \\theta italic_  are updated by minimizing the squared error loss  ( y j  Q  ( s j , a j ;  ) ) 2 superscript subscript y j Q subscript s j subscript a j  2 (y_{j}-Q(s_{j},a_{j};\\theta))^{2} ( italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT - italic_Q ( italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ; italic_ ) ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT  through gradient descent. To ensure stability, the weights    superscript   \\theta^{\\prime} italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  of the target network are updated to match the current Q-network weights    \\theta italic_  every  C C C italic_C  step. This process refines the policy for optimal decision-making in the specified environment. In the decision phase, we leverage the best-performing weights from the training phase as the decision weights, comparing the scores of two agents to declare a winner. The specific experimental setup is detailed in Appendix F.3.",
            "First, we analyzed the basic framework combining candidate generation and knowledge retrieval to detect cognitive biases. An initial agent identifies biases and construct the candidate set. The final detection is made by another agent. Next, we added the pruned loser tree method to improve debate and decision-making among agents, with a referee agent finalizing the decision. Lastly, we integrated a reinforcement learning decision module to enhance the referee agents decision-making and adaptability. Results in Table  2  show notable improvements. Also as shown in Table 3, we use various optimization algorithms on our selected debate scenario training set as well as test set. The results show that the optimization of weights by reinforcement learning is optimal on both the training and test sets. The specific experimental setup can be found in Appendix F.2."
        ]
    },
    "global_footnotes": []
}