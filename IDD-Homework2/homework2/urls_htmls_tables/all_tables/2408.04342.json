{
    "id_table_1": {
        "caption": "Table 1 .  Domain-specific zero-shot performance of the model on the  NF-UNSW-NB15-v2  dataset.",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": [
            "The results of these empirical experiments under the zero-shot evaluation (Table  1  and  2 ) reveal several important insights. Unsurprisingly, the performance of the pre-trained  LLama3  model is worse than random selection, which would have been, considering the macro average, 50% for all metrics, while  GPT-4  is slightly better. This outcome is expected because pre-trained LLMs are primarily designed for natural language tasks and not for the specific task of network classification. In contrast, classical ML models demonstrate near-perfect performance. For instance, on the  NF-UNSW-NB15-v2  dataset, a Random Forest and an LSTM neural network respectively achieve a weighted F1-score of 92.17% and 92.82%  ( layeghy_explainable_2023,  )  while a  DANN  model achieves 97.81%  ( layeghy_di-nids_2023,  ) .",
            "When asked about a TN sample (Fig.  1 ), the model correctly identifies the network flow as a DNS query. However, it inaccurately claims the source IP address is from China, whereas it is actually from Japan, and misidentifies the destination address as being in the USA, although it belongs to the University of New South Wales (UNSW), the datasets creator. Despite these errors, the LLM correctly identifies the byte size range of all packets in the flow as typical for a DNS query. These inaccuracies highlight the LLMs tendency to hallucinate or generate incorrect information, particularly regarding geographical locations."
        ]
    },
    "id_table_2": {
        "caption": "Table 2 .  Domain specific zero-shot performance on the  NF-CSE-CIC-IDS2018-v2  dataset.",
        "table": "S4.T2.1",
        "footnotes": [],
        "references": [
            "The results of these empirical experiments under the zero-shot evaluation (Table  1  and  2 ) reveal several important insights. Unsurprisingly, the performance of the pre-trained  LLama3  model is worse than random selection, which would have been, considering the macro average, 50% for all metrics, while  GPT-4  is slightly better. This outcome is expected because pre-trained LLMs are primarily designed for natural language tasks and not for the specific task of network classification. In contrast, classical ML models demonstrate near-perfect performance. For instance, on the  NF-UNSW-NB15-v2  dataset, a Random Forest and an LSTM neural network respectively achieve a weighted F1-score of 92.17% and 92.82%  ( layeghy_explainable_2023,  )  while a  DANN  model achieves 97.81%  ( layeghy_di-nids_2023,  ) ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3 .  Domain specific performance of the  LLama3-8b-Instruct  model on the  NF-UNSW-NB15-v2  dataset.",
        "table": "S4.T3.1.1",
        "footnotes": [],
        "references": [
            "In comparison to the zero-shot learning results, both fine-tuning methods showed slight improvements but still failed to significantly outperform random selection or approach the performance of related works (Table.  3  and  4 ). Overall,  KTO  performed slightly better, indicating that the choice of fine-tuning method is an important parameter for future research. We see that fine-tuning can enhance performance with increased training, but the improvements observed were minimal. Fine-tuning tends to adjust the models responses to fit a desired style but is insufficient to significantly alter the weights for the binary classification of network attacks. Pre-trained natural language models, which are trained on extensive natural language corpora, may not be capable of recognising the subtle patterns that indicate malicious NetFlows. They are more adept at generating appropriate responses to natural language queries without any further deep understanding."
        ]
    },
    "id_table_4": {
        "caption": "Table 4 .  Domain specific performance of the  LLama3-8b-Instruct  model on the  NF-CSE-CIC-IDS2018-v2  dataset.",
        "table": "S4.T4.1.1",
        "footnotes": [],
        "references": [
            "In comparison to the zero-shot learning results, both fine-tuning methods showed slight improvements but still failed to significantly outperform random selection or approach the performance of related works (Table.  3  and  4 ). Overall,  KTO  performed slightly better, indicating that the choice of fine-tuning method is an important parameter for future research. We see that fine-tuning can enhance performance with increased training, but the improvements observed were minimal. Fine-tuning tends to adjust the models responses to fit a desired style but is insufficient to significantly alter the weights for the binary classification of network attacks. Pre-trained natural language models, which are trained on extensive natural language corpora, may not be capable of recognising the subtle patterns that indicate malicious NetFlows. They are more adept at generating appropriate responses to natural language queries without any further deep understanding."
        ]
    },
    "id_table_5": {
        "caption": "Table 5 .  Complexity of benchmarked model compared to traditional NIDS architectures.",
        "table": "S4.T5.1.1",
        "footnotes": [],
        "references": [
            "Our comparison in Table.  5 , highlights the significant difference in computational complexity among the models. The  LLama3  model exhibited significantly higher inference times due to its complex architecture and a large number of parameters. As  GPT-4  is closed-source and runs on the server side, we were unable to obtain statistics about its inference times and parameter count, which are in a similar range to those of  LLama3 .  In contrast, traditional ML models like the Random Forest and the Decision Tree demonstrated swift inference times, making them more suitable for real-time NIDS applications. For instance, DL models can still offer a reasonable trade-off compromise, with costs potentially being manageable. However, considering the near 7000-fold slower inference time of LLMs compared to lightweight models, it is not feasible to implement LLMs in a real-time NIDS."
        ]
    },
    "global_footnotes": []
}