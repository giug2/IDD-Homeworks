{
    "id_table_1": {
        "caption": "TABLE I:  LLM-Generated Sample Dataset Breakdown",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": [
            "As described in the Methodology section, each selected LLM is integrated into the inference endpoint, where it processes the natural language queries from the generated dataset and classifies them into the appropriate API modules and functions. The inference results are then compared against the labeled data to measure model performance using two metrics: Module Level Classification Accuracy (MLC-Acc) and Function Level Classification Accuracy (FLC-Acc). MLC-Acc measures the models ability to correctly classify a query into the appropriate API module, such as identifying whether the query is related to the calculator, weather, email, or another module. MLC-Acc calculation is shown in Equation ( 1 ) below,"
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Model Performance Across API Modules and Functions",
        "table": "S4.T1.1.2.1.2.1",
        "footnotes": [],
        "references": [
            "FLC-Acc measures how well the model can correctly classify the function within the correct API module, focusing on precision at the function level when the module classification is accurate. FLC-ACC is computed as shown in Equation ( 2 ),"
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "S4.T1.1.3.2.2.1",
        "footnotes": [],
        "references": [
            "We employ GPT-4-turbo to generate the dataset for this experiment. GPT-4-turbo is an optimized version of GPT-4, known for its high accuracy in natural language processing and cost-effectiveness  [ 42 ] . GPT-4-turbo is selected because of its ability to handle complex data generation tasks efficiently, allowing us to create a large-scale, high-quality dataset with minimal manual intervention. As outlined in the Methodology section, we pre-define specific Data Generation Rules to guide dataset generation for the selected API modules and functions. The Data Generation Rules serve as prompts to batch-call the GPT-4-turbo interface and generate labeled datasets in JSON format. The generated datasets are then manually reviewed with an accuracy of 99.9%. The high accuracy demonstrates the reliability of leveraging LLMs to automatically generate high-quality datasets for complex API classification tasks, minimizing the need for extensive manual intervention. Figure  3  presents the Data Generation Rules we employ and sample entries from the generated datasets, where  query  denotes the natural language prompt, the first entry of  label  indicates the classified API module, and the second entry of  label  specifies the corresponding function. The final dataset contains a total of 1300 samples. Table  I  provides a breakdown of the dataset, including simulated functions and the number of samples generated for each API module."
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "S4.T1.1.4.3.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_5": {
        "caption": "",
        "table": "S4.T1.1.5.4.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_6": {
        "caption": "",
        "table": "S4.T1.1.6.5.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_7": {
        "caption": "",
        "table": "S4.T1.1.7.6.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_8": {
        "caption": "",
        "table": "S4.T2.2",
        "footnotes": [],
        "references": []
    }
}