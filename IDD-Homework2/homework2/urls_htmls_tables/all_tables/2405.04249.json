{
    "PAPER'S NUMBER OF TABLES": 3,
    "S4.T1": {
        "caption": "Table 1: List of training data partitions for every layer in topology, where (-) means the bias is mild and (+) means the bias is strong.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Training data partitions</th>\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Devices</th>\n<th id=\"S4.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Edges</th>\n<th id=\"S4.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Cloud</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Equal</td>\n<td id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">33.3%</td>\n<td id=\"S4.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">33.3%</td>\n<td id=\"S4.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">33.3%</td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.3.2.1\" class=\"ltx_td ltx_align_center\">Cloud Bias (-)</td>\n<td id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center\">14.3%</td>\n<td id=\"S4.T1.1.3.2.3\" class=\"ltx_td ltx_align_center\">28.6%</td>\n<td id=\"S4.T1.1.3.2.4\" class=\"ltx_td ltx_align_center\">57.1%</td>\n</tr>\n<tr id=\"S4.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.4.3.1\" class=\"ltx_td ltx_align_center\">Cloud Bias (+)</td>\n<td id=\"S4.T1.1.4.3.2\" class=\"ltx_td ltx_align_center\">3.4%</td>\n<td id=\"S4.T1.1.4.3.3\" class=\"ltx_td ltx_align_center\">19.9%</td>\n<td id=\"S4.T1.1.4.3.4\" class=\"ltx_td ltx_align_center\">76.7%</td>\n</tr>\n<tr id=\"S4.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">Devices Bias (+)</td>\n<td id=\"S4.T1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">76.7%</td>\n<td id=\"S4.T1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">19.9%</td>\n<td id=\"S4.T1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">3.4%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The list of training data partitions we consider can be seen in TableÂ 1, where the values represent the overall percentage of training data across an entire layer of the network. For example, on a per-client level in the equal data partition setting, each device will in actuality hold 1/121121/12 of the entire training data (as there are 4 total devices) and each edge client will hold 1/6161/6 (there are 2 total edge clients). We also examine the scenario where the cloud holds the majority of the training data, which includes the case where it has access to a large public dataset. Lastly, we explore an extreme scenario, where almost all the training data is situated on the devices, reflecting tasks where a limited amount of public data samples are accessible.\nThe data is i.i.d. among all clients in the network.",
            "We also analyze two training data partitions that are more extreme, referred to as the strong cloud bias and the strong devices bias cases (see TableÂ 1). In these scenarios, we focus on analyzing the worst-case settings where the expected service rates are higher for the exits having less data points. In particular, we consider serving rates 80-15-5, 60-30-10, and 45-35-20 for the strong cloud bias partition (where the devices store less than 4% of the samples but need to serve a large fraction of requests), and serving rates 5-15-80, 10-30-60, and 20-35-45 for the strong devices bias partition. In the strong cloud bias setting, it can be useful to set p>0ğ‘0p>0 for the most powerful clients such that they use their larger datasets to help training the simpler device models. This is an effective way to decrease Ïµgensubscriptitalic-Ïµgen\\epsilon_{\\text{gen}}, by increasing |S1,ğ’‘|subscriptğ‘†1ğ’‘|S_{1,\\bm{p}}| and |S2,ğ’‘|subscriptğ‘†2ğ’‘|S_{2,\\bm{p}}|, while not having an impact on Ïµbiassubscriptitalic-Ïµbias\\epsilon_{\\text{bias}}. However, there is still a trade-off, because assigning p>0ğ‘0p>0 will increase Ïµoptsubscriptitalic-Ïµopt\\epsilon_{\\text{opt}} due to the later exits training for fewer epochs (as it uses some of its allotted training epochs to train the earlier exits). In FigureÂ 3, we can see that the performance of the â€œServing Rateâ€ strategy greatly improves as we increase pğ‘p progressive from 0 to 0.1 to 0.2. The â€œEqual Weightâ€ training strategy unsurprisingly struggles in this case because Ïµgensubscriptitalic-Ïµgen\\epsilon_{\\text{gen}} for Exit 1 is exceptionally high, due to it having such a small amount of training data, and its static weight assignment has no means of alleviating this issue."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Experimental results using different dataset partitions across cloud-edge-device topology for a variety of CIS serving rates on the CIFAR10 dataset.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_border_tt\" colspan=\"3\"></td>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\">CIS Serving Rate Setting</th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\"></th>\n<td id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_border_tt\"></td>\n</tr>\n<tr id=\"S4.T2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Dataset Partition</th>\n<th id=\"S4.T2.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Strategy</th>\n<th id=\"S4.T2.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">5-15-80</th>\n<th id=\"S4.T2.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">10-30-60</th>\n<th id=\"S4.T2.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">20-35-45</th>\n<th id=\"S4.T2.1.2.2.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">33-33-33</th>\n<th id=\"S4.T2.1.2.2.7\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">45-35-20</th>\n<th id=\"S4.T2.1.2.2.8\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">60-30-10</th>\n<th id=\"S4.T2.1.2.2.9\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">80-15-5</th>\n</tr>\n<tr id=\"S4.T2.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Equal</td>\n<td id=\"S4.T2.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Equal Weight</td>\n<td id=\"S4.T2.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T2.1.3.3.3.1\" class=\"ltx_text\">84.9%</span></td>\n<td id=\"S4.T2.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T2.1.3.3.4.1\" class=\"ltx_text\">83.6%</span></td>\n<td id=\"S4.T2.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T2.1.3.3.5.1\" class=\"ltx_text ltx_font_bold\">80.0%</span></td>\n<td id=\"S4.T2.1.3.3.6\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T2.1.3.3.6.1\" class=\"ltx_text ltx_font_bold\">74.2%</span></td>\n<td id=\"S4.T2.1.3.3.7\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T2.1.3.3.7.1\" class=\"ltx_text ltx_font_bold\">69.0%</span></td>\n<td id=\"S4.T2.1.3.3.8\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T2.1.3.3.8.1\" class=\"ltx_text\">45.4%</span></td>\n<td id=\"S4.T2.1.3.3.9\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T2.1.3.3.9.1\" class=\"ltx_text\">49.4%</span></td>\n</tr>\n<tr id=\"S4.T2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.4.4.1\" class=\"ltx_td ltx_align_left\">Equal</td>\n<td id=\"S4.T2.1.4.4.2\" class=\"ltx_td ltx_align_left\">FLOPS Prop</td>\n<td id=\"S4.T2.1.4.4.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.4.4.3.1\" class=\"ltx_text ltx_font_bold\">86.4%</span></td>\n<td id=\"S4.T2.1.4.4.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.4.4.4.1\" class=\"ltx_text\">82.9%</span></td>\n<td id=\"S4.T2.1.4.4.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.4.4.5.1\" class=\"ltx_text\">76.2%</span></td>\n<td id=\"S4.T2.1.4.4.6\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.4.4.6.1\" class=\"ltx_text\">68.2%</span></td>\n<td id=\"S4.T2.1.4.4.7\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.4.4.7.1\" class=\"ltx_text\">60.8%</span></td>\n<td id=\"S4.T2.1.4.4.8\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.4.4.8.1\" class=\"ltx_text\">49.5%</span></td>\n<td id=\"S4.T2.1.4.4.9\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.4.4.9.1\" class=\"ltx_text\">35.8%</span></td>\n</tr>\n<tr id=\"S4.T2.1.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.5.5.1\" class=\"ltx_td ltx_align_left\">Equal</td>\n<td id=\"S4.T2.1.5.5.2\" class=\"ltx_td ltx_align_left\">Serving Rate</td>\n<td id=\"S4.T2.1.5.5.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.5.5.3.1\" class=\"ltx_text\">86.1%</span></td>\n<td id=\"S4.T2.1.5.5.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.5.5.4.1\" class=\"ltx_text ltx_font_bold\">84.0%</span></td>\n<td id=\"S4.T2.1.5.5.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.5.5.5.1\" class=\"ltx_text\">79.8%</span></td>\n<td id=\"S4.T2.1.5.5.6\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.5.5.6.1\" class=\"ltx_text ltx_font_bold\">74.2%</span></td>\n<td id=\"S4.T2.1.5.5.7\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.5.5.7.1\" class=\"ltx_text ltx_font_bold\">69.0%</span></td>\n<td id=\"S4.T2.1.5.5.8\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.5.5.8.1\" class=\"ltx_text ltx_font_bold\">62.5%</span></td>\n<td id=\"S4.T2.1.5.5.9\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.5.5.9.1\" class=\"ltx_text ltx_font_bold\">54.6%</span></td>\n</tr>\n<tr id=\"S4.T2.1.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.6.6.1\" class=\"ltx_td ltx_align_left\">Cloud Bias (-)</td>\n<td id=\"S4.T2.1.6.6.2\" class=\"ltx_td ltx_align_left\">Equal Weight</td>\n<td id=\"S4.T2.1.6.6.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.6.6.3.1\" class=\"ltx_text\">86.4%</span></td>\n<td id=\"S4.T2.1.6.6.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.6.6.4.1\" class=\"ltx_text\">84.7%</span></td>\n<td id=\"S4.T2.1.6.6.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.6.6.5.1\" class=\"ltx_text\">80.9%</span></td>\n<td id=\"S4.T2.1.6.6.6\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.6.6.6.1\" class=\"ltx_text ltx_font_bold\">71.7%</span></td>\n<td id=\"S4.T2.1.6.6.7\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.6.6.7.1\" class=\"ltx_text\">61.5%</span></td>\n<td id=\"S4.T2.1.6.6.8\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.6.6.8.1\" class=\"ltx_text\">59.3%</span></td>\n<td id=\"S4.T2.1.6.6.9\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.6.6.9.1\" class=\"ltx_text\">49.4%</span></td>\n</tr>\n<tr id=\"S4.T2.1.7.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.7.7.1\" class=\"ltx_td ltx_align_left\">Cloud Bias (-)</td>\n<td id=\"S4.T2.1.7.7.2\" class=\"ltx_td ltx_align_left\">FLOPS Prop</td>\n<td id=\"S4.T2.1.7.7.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.7.7.3.1\" class=\"ltx_text\">88.6%</span></td>\n<td id=\"S4.T2.1.7.7.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.7.7.4.1\" class=\"ltx_text\">85.4%</span></td>\n<td id=\"S4.T2.1.7.7.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.7.7.5.1\" class=\"ltx_text\">78.7%</span></td>\n<td id=\"S4.T2.1.7.7.6\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.7.7.6.1\" class=\"ltx_text\">69.7%</span></td>\n<td id=\"S4.T2.1.7.7.7\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.7.7.7.1\" class=\"ltx_text\">60.8%</span></td>\n<td id=\"S4.T2.1.7.7.8\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.7.7.8.1\" class=\"ltx_text\">49.3%</span></td>\n<td id=\"S4.T2.1.7.7.9\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.7.7.9.1\" class=\"ltx_text\">33.9%</span></td>\n</tr>\n<tr id=\"S4.T2.1.8.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Cloud Bias (-)</td>\n<td id=\"S4.T2.1.8.8.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">Serving Rate</td>\n<td id=\"S4.T2.1.8.8.3\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.1.8.8.3.1\" class=\"ltx_text ltx_font_bold\">88.7%</span></td>\n<td id=\"S4.T2.1.8.8.4\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.1.8.8.4.1\" class=\"ltx_text ltx_font_bold\">86.4%</span></td>\n<td id=\"S4.T2.1.8.8.5\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.1.8.8.5.1\" class=\"ltx_text ltx_font_bold\">81.5%</span></td>\n<td id=\"S4.T2.1.8.8.6\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.1.8.8.6.1\" class=\"ltx_text ltx_font_bold\">71.7%</span></td>\n<td id=\"S4.T2.1.8.8.7\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.1.8.8.7.1\" class=\"ltx_text ltx_font_bold\">66.4%</span></td>\n<td id=\"S4.T2.1.8.8.8\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.1.8.8.8.1\" class=\"ltx_text ltx_font_bold\">60.5%</span></td>\n<td id=\"S4.T2.1.8.8.9\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T2.1.8.8.9.1\" class=\"ltx_text ltx_font_bold\">52.9%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We first evaluate three training strategies over seven different serving rate settings on ğš²ğš²\\bm{\\Lambda}, which cover the scenarios where devices serve from 5%percent55\\% up to 80%percent8080\\% of all the requests (TableÂ 2). Overall, we can observe that as more requests are served on the cloud (left-most columns), the overall performance is increased since the cloud uses the most complex model for inference. In the 33-33-33 serving rate setting, the â€œEqual Weightâ€ and â€œServing Rateâ€ strategies share the same ğš²~bold-~ğš²\\bm{\\tilde{\\Lambda}}, and thus have the same performance.",
            "The results in TableÂ 2 show that when the data is equally distributed or when bigger nodes have slightly more data, training the EEN by setting the empirical weight ğš²~bold-~ğš²\\bm{\\tilde{\\Lambda}} equal to the serving rate ğš²ğš²\\bm{\\Lambda} is a good choice. This â€œServing Rateâ€ strategy is especially useful when the CIS is expected to serve more requests from the devices, which is an important scenario when the network budget is limited or communication cost needs to be reduced.\nBesides, we note that it is often not necessary to require larger nodes to help train the small models as proposed inÂ [5]. In these two partition settings, all the exits had a sufficiently large dataset portion that Ïµgensubscriptitalic-Ïµgen\\epsilon_{\\text{gen}} was not unreasonably large for any exit."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Experimental results using the Device Bias (+) data partition for a variety of CIS serving rate settings on the CIFAR10 dataset.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_border_tt\" colspan=\"2\"></td>\n<th id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">CIS Serving Rate Setting</th>\n</tr>\n<tr id=\"S4.T3.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Dataset Partition</th>\n<th id=\"S4.T3.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Strategy</th>\n<th id=\"S4.T3.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">5-15-80</th>\n<th id=\"S4.T3.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">10-30-60</th>\n<th id=\"S4.T3.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">20-35-45</th>\n</tr>\n<tr id=\"S4.T3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Device Bias (+)</td>\n<td id=\"S4.T3.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Equal Weight</td>\n<td id=\"S4.T3.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T3.1.3.3.3.1\" class=\"ltx_text\">45.9%</span></td>\n<td id=\"S4.T3.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T3.1.3.3.4.1\" class=\"ltx_text ltx_font_bold\">36.7%</span></td>\n<td id=\"S4.T3.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T3.1.3.3.5.1\" class=\"ltx_text ltx_font_bold\">29.9%</span></td>\n</tr>\n<tr id=\"S4.T3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.4.4.1\" class=\"ltx_td ltx_align_left\">Device Bias (+)</td>\n<td id=\"S4.T3.1.4.4.2\" class=\"ltx_td ltx_align_left\">Serving Rate</td>\n<td id=\"S4.T3.1.4.4.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T3.1.4.4.3.1\" class=\"ltx_text\">44.5%</span></td>\n<td id=\"S4.T3.1.4.4.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T3.1.4.4.4.1\" class=\"ltx_text\">35.8%</span></td>\n<td id=\"S4.T3.1.4.4.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T3.1.4.4.5.1\" class=\"ltx_text\">28.8%</span></td>\n</tr>\n<tr id=\"S4.T3.1.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Device Bias (+)</td>\n<td id=\"S4.T3.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">Gen. Error Adj</td>\n<td id=\"S4.T3.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T3.1.5.5.3.1\" class=\"ltx_text ltx_font_bold\">46.2%</span></td>\n<td id=\"S4.T3.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T3.1.5.5.4.1\" class=\"ltx_text\">35.0%</span></td>\n<td id=\"S4.T3.1.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T3.1.5.5.5.1\" class=\"ltx_text\">25.7%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Under the strong devices bias data partition, the system would benefit from weaker clients periodically training the larger exits. Other works such as HeteroFLÂ [3] have considered this scenario assuming that resources limit the size of the model to be used at inference, but not at training. Under this assumption, it would be possible to tune pğ‘p to obtain exactly the same results as in FigureÂ 3, and in particular the â€œServing Rateâ€ strategy would still outperform the â€œEqual Weightâ€ one. If instead we consider that resource constraints apply both at inference and training, TheoremÂ 1 suggests an alternative approach. The bound indicates that having Exit 3 train on a small dataset may significantly increase Ïµgensubscriptitalic-Ïµgen\\epsilon_{\\text{gen}}. We can compensate for this effect by selecting Î›~3<Î›3subscript~Î›3subscriptÎ›3\\tilde{\\Lambda}_{3}<\\Lambda_{3} (and conversely Î›~1>Î›1subscript~Î›1subscriptÎ›1\\tilde{\\Lambda}_{1}>\\Lambda_{1}) at the expense of introducing a bias Ïµbias>0subscriptitalic-Ïµbias0\\epsilon_{\\text{bias}}>0.\nIn TableÂ 3, we present the results of a simple heuristic which modifies the aggregation weights in this direction:\nÎ›~e=Î›eÃ—|Se,ğ’‘|FLOPSesubscript~Î›ğ‘’subscriptÎ›ğ‘’subscriptğ‘†ğ‘’ğ’‘subscriptFLOPSğ‘’\\tilde{\\Lambda}_{e}=\\Lambda_{e}\\times\\frac{|S_{e,\\bm{p}}|}{\\text{FLOPS}_{e}}."
        ]
    }
}