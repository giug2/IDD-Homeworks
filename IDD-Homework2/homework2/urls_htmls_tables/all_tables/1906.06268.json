{
    "PAPER'S NUMBER OF TABLES": 4,
    "S4.T1": {
        "caption": "TABLE I: Statistics of the datasets used in the experiments.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">K</span></th>\n<th id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Size</span> (<math id=\"S4.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\approx\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mo id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\">≈</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><approx id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\"></approx></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">\\approx</annotation></semantics></math>)</th>\n<th id=\"S4.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Size/K</span></th>\n</tr>\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row\"></th>\n<th id=\"S4.T1.1.2.1.3\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S4.T1.1.2.1.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\">mean</th>\n<th id=\"S4.T1.1.2.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_t\">std</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FEMNIST</th>\n<th id=\"S4.T1.1.3.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t\">100</th>\n<td id=\"S4.T1.1.3.1.3\" class=\"ltx_td ltx_align_right ltx_border_t\">55k</td>\n<td id=\"S4.T1.1.3.1.4\" class=\"ltx_td ltx_align_right ltx_border_t\">0.5k</td>\n<td id=\"S4.T1.1.3.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_t\">54</td>\n</tr>\n<tr id=\"S4.T1.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MNIST</th>\n<th id=\"S4.T1.1.4.2.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">100</th>\n<td id=\"S4.T1.1.4.2.3\" class=\"ltx_td ltx_align_right\">60k</td>\n<td id=\"S4.T1.1.4.2.4\" class=\"ltx_td ltx_align_right\">600</td>\n<td id=\"S4.T1.1.4.2.5\" class=\"ltx_td ltx_nopad_r ltx_align_right\">0</td>\n</tr>\n<tr id=\"S4.T1.1.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PMNIST</th>\n<th id=\"S4.T1.1.5.3.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">100</th>\n<td id=\"S4.T1.1.5.3.3\" class=\"ltx_td ltx_align_right\">60k</td>\n<td id=\"S4.T1.1.5.3.4\" class=\"ltx_td ltx_align_right\">600</td>\n<td id=\"S4.T1.1.5.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_right\">0</td>\n</tr>\n<tr id=\"S4.T1.1.6.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">VSN</th>\n<th id=\"S4.T1.1.6.4.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">23</th>\n<td id=\"S4.T1.1.6.4.3\" class=\"ltx_td ltx_align_right\">68k</td>\n<td id=\"S4.T1.1.6.4.4\" class=\"ltx_td ltx_align_right\">3k</td>\n<td id=\"S4.T1.1.6.4.5\" class=\"ltx_td ltx_nopad_r ltx_align_right\">559</td>\n</tr>\n<tr id=\"S4.T1.1.7.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">HAR</th>\n<th id=\"S4.T1.1.7.5.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">30</th>\n<td id=\"S4.T1.1.7.5.3\" class=\"ltx_td ltx_align_right\">15k</td>\n<td id=\"S4.T1.1.7.5.4\" class=\"ltx_td ltx_align_right\">0.5k</td>\n<td id=\"S4.T1.1.7.5.5\" class=\"ltx_td ltx_nopad_r ltx_align_right\">56</td>\n</tr>\n<tr id=\"S4.T1.1.8.6\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">NLP</th>\n<th id=\"S4.T1.1.8.6.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb\">100</th>\n<td id=\"S4.T1.1.8.6.3\" class=\"ltx_td ltx_align_right ltx_border_bb\">1.2m</td>\n<td id=\"S4.T1.1.8.6.4\" class=\"ltx_td ltx_align_right ltx_border_bb\">13k</td>\n<td id=\"S4.T1.1.8.6.5\" class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_bb\">11k</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "FEMNIST",
                ": This dataset consists of a federated version of the EMNIST dataset ",
                "[",
                "9",
                "]",
                ", maintained by the ",
                "LEAF",
                " project ",
                "[",
                "8",
                "]",
                ". Different clients correspond to different writers. We subsample 100 random writers and use only the 10 digit labels. Train and test split is provided by the distribution.",
                "Vehicle Sensors Network (VSN)",
                "1",
                "1",
                "1",
                "http://www.ecs.umass.edu/~mduarte/Software.html",
                ": A network of 23 different sensors (including seismic, acoustic, and passive infra-red sensors) are place around a road segment to classify vehicles driving through. ",
                "[",
                "13",
                "]",
                ". The raw signal is featurized in the original paper into 50 acoustic and 50 seismic features. We consider every sensor as a client and perform the binary classification of assault amphibious and dragon wagon vehicles.",
                "Human Activity Recognition (HAR)",
                "2",
                "2",
                "2",
                "https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones",
                ": Recordings of 30 subjects performing daily activities are collected using a waist-mounted smartphone with inertial sensors. The raw signal is divided into windows and featurized into a 561-length vector ",
                "[",
                "3",
                "]",
                ". Every individual corresponds to a different client and we perform classification of 12 different activities (e.g., sitting, walking). For both the VSN and the HAR, a 75%-25% train-test split is performed.",
                "MNIST",
                ": The classic MNIST dataset ",
                "[",
                "32",
                "]",
                ", randomly split into 100 different sections, one section per client. Every client has 600 training samples and 100 test samples. This dataset represents an atypical federated dataset with very homogeneous clients, both in terms of dataset sizes and in term of statistical properties of samples.",
                "Permuted MNIST (PMNIST)",
                ": The MNIST dataset is randomly split into 100 sections as above, and a random permutation of pixels is applied to every single client dataset. This dataset has been introduced in ",
                "[",
                "18",
                "]",
                " in the context of continual learning and represent a strongly non-IID federated dataset, with low level features being very dissimilar between clients.",
                "Shakespeare (NLP)",
                ": This dataset is built concatenating the whole literary production of William Shakespeare ",
                "[",
                "27",
                "]",
                ". The task here considered is English words spelling, hence the next character prediction task, over a vocabulary size of 86. The characters are arranged in sequences of 80 and further aggregated in batches of 10 sequences. Every role of a play is considered as a individual client, and we excluded roles that do not contain a single full batch.",
                "A comprehensive description of the statistics of the datasets used is available in ",
                "Table",
                " ",
                "I",
                "."
            ]
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Server (S) and Multi-Task (MT) max accuracy over all dataset at convergence. Values are given in percentage.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Metric</span></th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">FedAvg</span></th>\n<th id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">FedProx</span></th>\n<th id=\"S4.T2.1.1.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Virtual</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"2\"><span id=\"S4.T2.1.2.1.1.1\" class=\"ltx_text\">\n<span id=\"S4.T2.1.2.1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.T2.1.2.1.1.1.1.1\" class=\"ltx_p\">FEMNIST</span>\n<span id=\"S4.T2.1.2.1.1.1.1.2\" class=\"ltx_p\">MLP</span>\n</span></span></th>\n<th id=\"S4.T2.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">MT</th>\n<td id=\"S4.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">94.3</td>\n<td id=\"S4.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">94.5</td>\n<td id=\"S4.T2.1.2.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.2.1.5.1\" class=\"ltx_text ltx_font_bold\">95.7</span></td>\n</tr>\n<tr id=\"S4.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">S</th>\n<td id=\"S4.T2.1.3.2.2\" class=\"ltx_td ltx_align_center\">90.2</td>\n<td id=\"S4.T2.1.3.2.3\" class=\"ltx_td ltx_align_center\">89.9</td>\n<td id=\"S4.T2.1.3.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">90.9</span></td>\n</tr>\n<tr id=\"S4.T2.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" rowspan=\"2\"><span id=\"S4.T2.1.4.3.1.1\" class=\"ltx_text\">\n<span id=\"S4.T2.1.4.3.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.T2.1.4.3.1.1.1.1\" class=\"ltx_p\">FEMNIST</span>\n<span id=\"S4.T2.1.4.3.1.1.1.2\" class=\"ltx_p\">Conv</span>\n</span></span></th>\n<th id=\"S4.T2.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MT</th>\n<td id=\"S4.T2.1.4.3.3\" class=\"ltx_td ltx_align_center\">97.3</td>\n<td id=\"S4.T2.1.4.3.4\" class=\"ltx_td ltx_align_center\">97.0</td>\n<td id=\"S4.T2.1.4.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.1.4.3.5.1\" class=\"ltx_text ltx_font_bold\">98.2</span></td>\n</tr>\n<tr id=\"S4.T2.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">S</th>\n<td id=\"S4.T2.1.5.4.2\" class=\"ltx_td ltx_align_center\">95.5</td>\n<td id=\"S4.T2.1.5.4.3\" class=\"ltx_td ltx_align_center\">95.5</td>\n<td id=\"S4.T2.1.5.4.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.1.5.4.4.1\" class=\"ltx_text ltx_font_bold\">97.3</span></td>\n</tr>\n<tr id=\"S4.T2.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" rowspan=\"2\"><span id=\"S4.T2.1.6.5.1.1\" class=\"ltx_text\">MNIST</span></th>\n<th id=\"S4.T2.1.6.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MT</th>\n<td id=\"S4.T2.1.6.5.3\" class=\"ltx_td ltx_align_center\">96.9</td>\n<td id=\"S4.T2.1.6.5.4\" class=\"ltx_td ltx_align_center\">96.9</td>\n<td id=\"S4.T2.1.6.5.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.1.6.5.5.1\" class=\"ltx_text ltx_font_bold\">97.4</span></td>\n</tr>\n<tr id=\"S4.T2.1.7.6\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">S</th>\n<td id=\"S4.T2.1.7.6.2\" class=\"ltx_td ltx_align_center\">97.6</td>\n<td id=\"S4.T2.1.7.6.3\" class=\"ltx_td ltx_align_center\">97.6</td>\n<td id=\"S4.T2.1.7.6.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.1.7.6.4.1\" class=\"ltx_text ltx_font_bold\">97.8</span></td>\n</tr>\n<tr id=\"S4.T2.1.8.7\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" rowspan=\"2\"><span id=\"S4.T2.1.8.7.1.1\" class=\"ltx_text\">PMNIST</span></th>\n<th id=\"S4.T2.1.8.7.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MT</th>\n<td id=\"S4.T2.1.8.7.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.8.7.3.1\" class=\"ltx_text ltx_font_bold\">85.9</span></td>\n<td id=\"S4.T2.1.8.7.4\" class=\"ltx_td ltx_align_center\">85.6</td>\n<td id=\"S4.T2.1.8.7.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">84.2</td>\n</tr>\n<tr id=\"S4.T2.1.9.8\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">S</th>\n<td id=\"S4.T2.1.9.8.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.9.8.2.1\" class=\"ltx_text ltx_font_bold\">48.3</span></td>\n<td id=\"S4.T2.1.9.8.3\" class=\"ltx_td ltx_align_center\">47.5</td>\n<td id=\"S4.T2.1.9.8.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">42.5</td>\n</tr>\n<tr id=\"S4.T2.1.10.9\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" rowspan=\"2\"><span id=\"S4.T2.1.10.9.1.1\" class=\"ltx_text\">VSN</span></th>\n<th id=\"S4.T2.1.10.9.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MT</th>\n<td id=\"S4.T2.1.10.9.3\" class=\"ltx_td ltx_align_center\">96.2</td>\n<td id=\"S4.T2.1.10.9.4\" class=\"ltx_td ltx_align_center\">96.0</td>\n<td id=\"S4.T2.1.10.9.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.1.10.9.5.1\" class=\"ltx_text ltx_font_bold\">96.6</span></td>\n</tr>\n<tr id=\"S4.T2.1.11.10\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.11.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">S</th>\n<td id=\"S4.T2.1.11.10.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.11.10.2.1\" class=\"ltx_text ltx_font_bold\">89.6</span></td>\n<td id=\"S4.T2.1.11.10.3\" class=\"ltx_td ltx_align_center\">89.5</td>\n<td id=\"S4.T2.1.11.10.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">88.8</td>\n</tr>\n<tr id=\"S4.T2.1.12.11\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.12.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" rowspan=\"2\"><span id=\"S4.T2.1.12.11.1.1\" class=\"ltx_text\">HAR</span></th>\n<th id=\"S4.T2.1.12.11.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MT</th>\n<td id=\"S4.T2.1.12.11.3\" class=\"ltx_td ltx_align_center\">98.9</td>\n<td id=\"S4.T2.1.12.11.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.12.11.4.1\" class=\"ltx_text ltx_font_bold\">99.4</span></td>\n<td id=\"S4.T2.1.12.11.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">99.1</td>\n</tr>\n<tr id=\"S4.T2.1.13.12\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.13.12.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">S</th>\n<td id=\"S4.T2.1.13.12.2\" class=\"ltx_td ltx_align_center\">94.0</td>\n<td id=\"S4.T2.1.13.12.3\" class=\"ltx_td ltx_align_center\">94.0</td>\n<td id=\"S4.T2.1.13.12.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.1.13.12.4.1\" class=\"ltx_text ltx_font_bold\">94.3</span></td>\n</tr>\n<tr id=\"S4.T2.1.14.13\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.14.13.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" rowspan=\"2\"><span id=\"S4.T2.1.14.13.1.1\" class=\"ltx_text\">NLP</span></th>\n<th id=\"S4.T2.1.14.13.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MT</th>\n<td id=\"S4.T2.1.14.13.3\" class=\"ltx_td ltx_align_center\">46.1</td>\n<td id=\"S4.T2.1.14.13.4\" class=\"ltx_td ltx_align_center\">46.4</td>\n<td id=\"S4.T2.1.14.13.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.1.14.13.5.1\" class=\"ltx_text ltx_font_bold\">48.4</span></td>\n</tr>\n<tr id=\"S4.T2.1.15.14\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.15.14.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">S</th>\n<td id=\"S4.T2.1.15.14.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">48.1</td>\n<td id=\"S4.T2.1.15.14.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">48.5</td>\n<td id=\"S4.T2.1.15.14.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.15.14.4.1\" class=\"ltx_text ltx_font_bold\">48.6</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we evaluate the performance of our proposed method and the baselines FedAvg and FedProx in terms of both server and multi-tasks performance.",
                "Metric comparison.",
                "\nFrom ",
                "Figure",
                " ",
                "3",
                " we can first observe that the MT metric is uniformly more stable than the respective server variant since the former assumes clients retaining a private model until further training, while the latter assumes a server model that is updated at every single round, hence experiencing more stochasticity during the training process. Moreover, the MT metric is typically delayed compared to the server counterpart since clients are updated on average only every ",
                "K",
                "/",
                "C",
                "𝐾",
                "𝐶",
                "K/C",
                " rounds. This is responsible for the slower progress of the MT metric, with the values of the losses in the first stages of training being up to a factor of 10 larger than the server counterpart.\nWe further notice from ",
                "Figure",
                " ",
                "3",
                " (last column) that the MT metrics are typically superior to the centralized metrics (with some exceptions that are examined thoroughly in the following), showing that, at convergence, clients can personalize the model to a specific private dataset.",
                "Method comparison.",
                "\nIn ",
                "Table",
                " ",
                "II",
                " we additionally report the maximum accuracy achieved at convergence by the baselines FedAvg and FedProx and our method in all datasets.\nWe can observe that our method outperforms both baselines in almost all datasets (except in the PMNIST datasets) and with all neural network architectures considered (MLPs, convolutional and RNNs).\nVirtual is able to achieve up to ",
                "+",
                "2",
                "%",
                "percent",
                "2",
                "+2\\%",
                " and ",
                "+",
                "1",
                "%",
                "percent",
                "1",
                "+1\\%",
                " in maximum accuracy respectively in the MT and S variant in the FEMNIST, MNIST and Shakespeare datasets, and marginally outperforms the baselines in VSN.\nThe Shakespeare dataset is particularly crucial.\nIn this dataset, the S metrics are superior then the MT metrics, implying that, at convergence, the clients that train further on the private datasets impair their performance.\nThis follows likely from the high heterogeneity of the size of the Shakespeare datasets (see the last row in ",
                "table",
                " ",
                "I",
                "), that can cause clients with a small dataset to over-fit the private data and under-perform the central server model.\nOur proposed method performs particularly well in this scenario, causing only a slight reduction of the MT compared to the S accuracy."
            ]
        ]
    },
    "S4.SS6.1": {
        "caption": "TABLE III: Max accuracy at various levels of updates sparsity. Pruning is performed using the signal-to-noise-ratio of the updates.Figure 5: Additional learning curves.",
        "table": "<table id=\"S4.SS6.1.2\" class=\"ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.SS6.1.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.SS6.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.SS6.1.2.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.SS6.1.2.1.1.1.1.1\" class=\"ltx_p\" style=\"width:48.4pt;\"><span id=\"S4.SS6.1.2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">% pruned</span></span>\n</span>\n</th>\n<th id=\"S4.SS6.1.2.1.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\"></th>\n<th id=\"S4.SS6.1.2.1.1.3\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\"></th>\n<th id=\"S4.SS6.1.2.1.1.4\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\"></th>\n<td id=\"S4.SS6.1.2.1.1.5\" class=\"ltx_td ltx_border_tt\"></td>\n</tr>\n<tr id=\"S4.SS6.1.2.2.2\" class=\"ltx_tr\">\n<th id=\"S4.SS6.1.2.2.2.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">weights</th>\n<th id=\"S4.SS6.1.2.2.2.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column\">\n<span id=\"S4.SS6.1.2.2.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.SS6.1.2.2.2.2.1.1\" class=\"ltx_p\" style=\"width:25.6pt;\"><span id=\"S4.SS6.1.2.2.2.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Delta</span></span>\n</span>\n</th>\n<th id=\"S4.SS6.1.2.2.2.3\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S4.SS6.1.2.2.2.4\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<td id=\"S4.SS6.1.2.2.2.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.SS6.1.2.3.3\" class=\"ltx_tr\">\n<td id=\"S4.SS6.1.2.3.3.1\" class=\"ltx_td\"></td>\n<th id=\"S4.SS6.1.2.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S4.SS6.1.2.3.3.2.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n<th id=\"S4.SS6.1.2.3.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column\">\n<span id=\"S4.SS6.1.2.3.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.SS6.1.2.3.3.3.1.1\" class=\"ltx_p\" style=\"width:59.8pt;\"><span id=\"S4.SS6.1.2.3.3.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Virtual +</span></span>\n</span>\n</th>\n<th id=\"S4.SS6.1.2.3.3.4\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<td id=\"S4.SS6.1.2.3.3.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.SS6.1.2.4.4\" class=\"ltx_tr\">\n<td id=\"S4.SS6.1.2.4.4.1\" class=\"ltx_td\"></td>\n<th id=\"S4.SS6.1.2.4.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"S4.SS6.1.2.4.4.2.1\" class=\"ltx_text ltx_font_bold\">Virtual</span></th>\n<th id=\"S4.SS6.1.2.4.4.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" colspan=\"-1\">FedAvg init</th>\n<th id=\"S4.SS6.1.2.4.4.4\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<td id=\"S4.SS6.1.2.4.4.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.SS6.1.2.5.5\" class=\"ltx_tr\">\n<td id=\"S4.SS6.1.2.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.SS6.1.2.5.5.1.1\" class=\"ltx_text\">0%</span></td>\n<td id=\"S4.SS6.1.2.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"2\"><span id=\"S4.SS6.1.2.5.5.2.1\" class=\"ltx_text\">158k</span></td>\n<td id=\"S4.SS6.1.2.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_t\">MT</td>\n<td id=\"S4.SS6.1.2.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">86.2</td>\n<td id=\"S4.SS6.1.2.5.5.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span id=\"S4.SS6.1.2.5.5.5.1\" class=\"ltx_text ltx_font_bold\">95.6</span></td>\n</tr>\n<tr id=\"S4.SS6.1.2.6.6\" class=\"ltx_tr\">\n<td id=\"S4.SS6.1.2.6.6.1\" class=\"ltx_td ltx_align_left\">S</td>\n<td id=\"S4.SS6.1.2.6.6.2\" class=\"ltx_td ltx_align_center\">89.4</td>\n<td id=\"S4.SS6.1.2.6.6.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.SS6.1.2.6.6.3.1\" class=\"ltx_text ltx_font_bold\">90.9</span></td>\n</tr>\n<tr id=\"S4.SS6.1.2.7.7\" class=\"ltx_tr\">\n<td id=\"S4.SS6.1.2.7.7.1\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.SS6.1.2.7.7.1.1\" class=\"ltx_text\">50%</span></td>\n<td id=\"S4.SS6.1.2.7.7.2\" class=\"ltx_td ltx_align_left\" rowspan=\"2\"><span id=\"S4.SS6.1.2.7.7.2.1\" class=\"ltx_text\">79k</span></td>\n<td id=\"S4.SS6.1.2.7.7.3\" class=\"ltx_td ltx_align_left\">MT</td>\n<td id=\"S4.SS6.1.2.7.7.4\" class=\"ltx_td ltx_align_center\">76.3</td>\n<td id=\"S4.SS6.1.2.7.7.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.SS6.1.2.7.7.5.1\" class=\"ltx_text ltx_font_bold\">94.3</span></td>\n</tr>\n<tr id=\"S4.SS6.1.2.8.8\" class=\"ltx_tr\">\n<td id=\"S4.SS6.1.2.8.8.1\" class=\"ltx_td ltx_align_left\">S</td>\n<td id=\"S4.SS6.1.2.8.8.2\" class=\"ltx_td ltx_align_center\">81.8</td>\n<td id=\"S4.SS6.1.2.8.8.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.SS6.1.2.8.8.3.1\" class=\"ltx_text ltx_font_bold\">89.2</span></td>\n</tr>\n<tr id=\"S4.SS6.1.2.9.9\" class=\"ltx_tr\">\n<td id=\"S4.SS6.1.2.9.9.1\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.SS6.1.2.9.9.1.1\" class=\"ltx_text\">75%</span></td>\n<td id=\"S4.SS6.1.2.9.9.2\" class=\"ltx_td ltx_align_left\" rowspan=\"2\"><span id=\"S4.SS6.1.2.9.9.2.1\" class=\"ltx_text\">40k</span></td>\n<td id=\"S4.SS6.1.2.9.9.3\" class=\"ltx_td ltx_align_left\">MT</td>\n<td id=\"S4.SS6.1.2.9.9.4\" class=\"ltx_td ltx_align_center\">78.7</td>\n<td id=\"S4.SS6.1.2.9.9.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.SS6.1.2.9.9.5.1\" class=\"ltx_text ltx_font_bold\">94.9</span></td>\n</tr>\n<tr id=\"S4.SS6.1.2.10.10\" class=\"ltx_tr\">\n<td id=\"S4.SS6.1.2.10.10.1\" class=\"ltx_td ltx_align_left\">S</td>\n<td id=\"S4.SS6.1.2.10.10.2\" class=\"ltx_td ltx_align_center\">80.4</td>\n<td id=\"S4.SS6.1.2.10.10.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.SS6.1.2.10.10.3.1\" class=\"ltx_text ltx_font_bold\">90.8</span></td>\n</tr>\n<tr id=\"S4.SS6.1.2.11.11\" class=\"ltx_tr\">\n<td id=\"S4.SS6.1.2.11.11.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" rowspan=\"2\"><span id=\"S4.SS6.1.2.11.11.1.1\" class=\"ltx_text\">90%</span></td>\n<td id=\"S4.SS6.1.2.11.11.2\" class=\"ltx_td ltx_align_left ltx_border_bb\" rowspan=\"2\"><span id=\"S4.SS6.1.2.11.11.2.1\" class=\"ltx_text\">16k</span></td>\n<td id=\"S4.SS6.1.2.11.11.3\" class=\"ltx_td ltx_align_left\">MT</td>\n<td id=\"S4.SS6.1.2.11.11.4\" class=\"ltx_td ltx_align_center\">25.5</td>\n<td id=\"S4.SS6.1.2.11.11.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.SS6.1.2.11.11.5.1\" class=\"ltx_text ltx_font_bold\">48.5</span></td>\n</tr>\n<tr id=\"S4.SS6.1.2.12.12\" class=\"ltx_tr\">\n<td id=\"S4.SS6.1.2.12.12.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">S</td>\n<td id=\"S4.SS6.1.2.12.12.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.SS6.1.2.12.12.2.1\" class=\"ltx_text ltx_font_bold\">21.0</span></td>\n<td id=\"S4.SS6.1.2.12.12.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">20.3</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "Note that the scenario here described is very different from usual pruning performed on NNs, as in the latter case the pruning is performed only at test time (or after fine tuning) on fully trained NN [19], or a priori on a carefully initialized NN [15] while in our case the pruning is performed at every training round (hence at every E epochs of training), making it much a much harder task at a high level of pruning.In this work we introduced VIRTUAL, an algorithm for federated learning that tackles the well-known statistical challenges of the federated learning framework in a multi-task setting.\nWe consider the federation of a central server and clients as a Bayesian network and perform training using approximated variational inference.\nThe algorithm naturally complies with the federated setting desiderata, giving access to the central server only to an aggregated parameter update in the form of an overall posterior distribution over shared parameters.\nThe algorithm is shown to outperform the state-of-the-art in many IID and non-IID real world federated datasets.One possible direction for further developments is to consider synchronous updates of multiple clients (as preliminary seen already in [7]) studying empirically the effect of using outdated priors during client training or theoretically developing a new Bayesian model of synchronous updates.Another interesting direction is the exploration of other design choices. Indeed the general method can be tuned for a particular application by modifying, e.g., the architecture of lateral connections between devices (Block-Modular NN [52], NinN architecture [34]), the topology of the Bayesian network (star shape, hierarchical etc.), the choice of the variational inference algorithm.\nFinally, it is possible to study thoroughly VIRTUAL under memory constraints, using more sophisticated pruning procedures, sparsity inducing losses or using optimal strategy for data storage, in the line of coresets theory.In this section, we report the additional learning curves that are not reported in the main text, i.e., training cross-entropy in LABEL:fig:losses_20 and the server, MT and training accuracies in Figure 4b for the dataset considered, and for both MLPs and ConvNet architectures in the case of the FEMNIST dataset.In Figure 6 we also report the learning curves obtained in an additional experiment performed on the FEMNIST dataset, with the epochs per round parameter set to E=100𝐸100E=100, to show the applicability of the method in scenarios of higher node computational load. We can observe that also in this scenario Virtual outperforms both FedAvg and FedProx using MLPs and ConvNet architectures. In table IV the maximum MT and server accuracies are reported, with Virtual achieving a +0.4% and +0.9% respectively on MLPs and convolutional architectures.The Virtual method requires to compute the so-called (un-normalized) cavity distributions s​(θ)si​(θ)𝑠𝜃subscript𝑠𝑖𝜃\\frac{s(\\theta)}{s_{i}(\\theta)}, the client deltas Δi=s​(θ)si​(θ)subscriptΔ𝑖𝑠𝜃subscript𝑠𝑖𝜃\\Delta_{i}=\\frac{s(\\theta)}{s_{i}(\\theta)}, and deltas aggregation Δ=∏i∈𝒞tΔiΔsubscriptproduct𝑖subscript𝒞𝑡subscriptΔ𝑖\\Delta=\\prod_{i\\in\\mathcal{C}_{t}}\\Delta_{i} (see Algorithm 1 in the main text). Using a factorized Gaussian distribution over the weights as si​(𝜽)=∏d=1Ds𝒩​(θd|μi​ds,σi​ds)subscript𝑠𝑖𝜽superscriptsubscriptproduct𝑑1superscript𝐷𝑠𝒩conditionalsubscript𝜃𝑑superscriptsubscript𝜇𝑖𝑑𝑠superscriptsubscript𝜎𝑖𝑑𝑠s_{i}(\\bm{\\theta})=\\prod_{d=1}^{D^{s}}\\mathcal{N}(\\theta_{d}|\\mu_{id}^{s},\\sigma_{id}^{s}), we can easily observe that the factorization extends to all three terms listed above. In turn, in order to implement the Virtual algorithm with factorized Gaussian distributions, we need to compute univariate Gaussian products and ratios that read respectively (see [42, Sec 8.1.8]):where Spsubscript𝑆𝑝S_{p} and Zrsubscript𝑍𝑟Z_{r} are normalization constants andwith σ1<σ2subscript𝜎1subscript𝜎2\\sigma_{1}<\\sigma_{2} in the latter case (ratio).\nIt is easy to observe that using the natural parameterization of the Gaussian distribution with sufficient statistics given byproducts and ratios of Gaussians translates respectively into the sum and difference of the natural parameters χ𝜒\\chi and ξ𝜉\\xi. The implementation used in the code uses natural parameter Gaussian distributions, and sum and difference of its parameters to obtain the required products and ratios. This parameterization and the consequences on product and ratios easily generalize to any exponential family distribution, but it is here presented in the Gaussian case for convenience.At step t𝑡t the global posterior for server parameters is s(t)​(𝜽)=si​(𝜽)​∏j≠iKsj(t−1)​(𝜽)superscript𝑠𝑡𝜽subscript𝑠𝑖𝜽superscriptsubscriptproduct𝑗𝑖𝐾superscriptsubscript𝑠𝑗𝑡1𝜽s^{(t)}(\\bm{\\theta})=s_{i}(\\bm{\\theta})\\prod_{j\\neq i}^{K}s_{j}^{(t-1)}(\\bm{\\theta}) and analogously the client parameters distribution reads c(t)​(ϕ)=ci​(ϕi)​∏j≠iKcj(t−1)​(ϕj)superscript𝑐𝑡bold-italic-ϕsubscript𝑐𝑖subscriptbold-italic-ϕ𝑖superscriptsubscriptproduct𝑗𝑖𝐾superscriptsubscript𝑐𝑗𝑡1subscriptbold-italic-ϕ𝑗c^{(t)}(\\bm{\\phi})=c_{i}(\\bm{\\phi}_{i})\\prod_{j\\neq i}^{K}c_{j}^{(t-1)}(\\bm{\\phi}_{j}). Then the EP-like update for the model described is given by minimizing the following KL divergence w.r.t si​(𝜽)subscript𝑠𝑖𝜽s_{i}(\\bm{\\theta}) and ci​(ϕi)subscript𝑐𝑖subscriptbold-italic-ϕ𝑖c_{i}(\\bm{\\phi}_{i})where the second equality comes from the normalization of client and server pdfs and from Bayes rule p​(𝜽,ϕi|𝒟i)∝p​(𝒟i|𝜽,ϕi)​p​(ϕi)​p​(𝜽)proportional-to𝑝𝜽conditionalsubscriptbold-italic-ϕ𝑖subscript𝒟𝑖𝑝conditionalsubscript𝒟𝑖𝜽subscriptbold-italic-ϕ𝑖𝑝subscriptbold-italic-ϕ𝑖𝑝𝜽p(\\bm{\\theta},\\bm{\\phi}_{i}|\\mathcal{D}_{i})\\propto p(\\mathcal{D}_{i}|\\bm{\\theta},\\bm{\\phi}_{i})p(\\bm{\\phi}_{i})p(\\bm{\\theta}). Notice also that si​(𝜽)s(t)​(𝜽)=si(t−1)​(𝜽)s(t−1)​(𝜽)subscript𝑠𝑖𝜽superscript𝑠𝑡𝜽superscriptsubscript𝑠𝑖𝑡1𝜽superscript𝑠𝑡1𝜽\\frac{s_{i}(\\bm{\\theta})}{s^{(t)}(\\bm{\\theta})}=\\frac{s_{i}^{(t-1)}(\\bm{\\theta})}{s^{(t-1)}(\\bm{\\theta})} because of the factorization in Equation 2, and hence Proposition 1 is proved.\n∎In all experiments reported here and in the main text we use a batch size B=20𝐵20B=20, except for the Shakespeare dataset, where B=10𝐵10B=10. For both baselines and Virtual we perform a careful log spaced grid-search over 5 values of the regularization multiplier β𝛽\\beta and of the client learning rate ηcsubscript𝜂𝑐\\eta_{c}, verifying that optimal values do not lie at the boundaries of the grid. Similarly we use a linearly spaced grid for the server learning rate ηssubscript𝜂𝑠\\eta_{s} of the type {0.2,0.4…,1.}\\{0.2,0.4\\dots,1.\\}. In the case of Virtual, we use an additional damping factor γ∈[0,1]𝛾01\\gamma\\in[0,1], frequently used in the case of message passing algorithms (see [39, 38, 7]), to prevent oscillations. The damping factor acts on the client updates as si​(θ)t+1←si​(θ)t+1γ​si​(θ)t1−γ←subscript𝑠𝑖subscript𝜃𝑡1subscript𝑠𝑖superscriptsubscript𝜃𝑡1𝛾subscript𝑠𝑖superscriptsubscript𝜃𝑡1𝛾s_{i}(\\theta)_{t+1}\\leftarrow s_{i}(\\theta)_{t+1}^{\\gamma}s_{i}(\\theta)_{t}^{1-\\gamma}. In order to retain the same number of hyper-parameters as the baselines FedProx and FedAvg we fix the value of the damping factor γ𝛾\\gamma as 1−ηs1subscript𝜂𝑠1-\\eta_{s} that resulted in good performance of the overall method.",
        "references": [
            [
                "The use of a Bayesian framework allows us to estimate the importance of the client ",
                "i",
                "𝑖",
                "i",
                " using the property of the client posterior distributions and client un-normalized updates distributions ",
                "Δ",
                "i",
                "subscript",
                "Δ",
                "𝑖",
                "\\Delta_{i}",
                ".\nIn ",
                "fig.",
                " ",
                "4",
                " we examine the cumulative distribution function (CDF) of the signal-to-noise (SNR) of the weights of the client posteriors. A CDF located on the right-hand side of the plot represents a compressible network, with only a small ratio of the weights with high SNR being determinant in the model performance (see ",
                "[",
                "5",
                "]",
                " for an application of this concept to simple neural network pruning).\nFor comparison, we also implement a variation of the Virtual method that retains the client loss function used in Virtual, and in addition initializes the weights of the client with the server posterior at the beginning of every training round (Virtual + FedAvg init in ",
                "fig.",
                " ",
                "4",
                "). In these plots, we observe that the server initialization forces all clients to learn a complex model (larger CDF), while with no such initialization the clients specialize to the task at hand with a small ratio of weights.",
                "We, therefore, design a simple updated pruning procedure that sparsifies the client updates setting to zero all ",
                "Δ",
                "i",
                "subscript",
                "Δ",
                "𝑖",
                "\\Delta_{i}",
                " elements that have a SNR smaller than a given percentile.\nThe results are reported in ",
                "section",
                " ",
                "IV-F",
                ".\nVirtual greatly outperforms the FedAvg initialization variant and retains a superior performance compared to the FedProx method (compare with ",
                "Table",
                " ",
                "II",
                ", first and second row) up to an induced sparsity of 75%.\nThis is equivalent to a 50% communication reduction cost compared to FedProx, factoring the use of a Bayesian Neural Network that uses twice as many parameters as a standard deterministic network."
            ]
        ]
    },
    "A1.T4": {
        "caption": "TABLE IV: Server (S) and Multi-Task (MT) maximum accuracy over all datasets at convergence, with E=100𝐸100E=100 epochs per round. Values are given in percentage.",
        "table": "<table id=\"A1.T4.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T4.3.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T4.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"A1.T4.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"A1.T4.3.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"A1.T4.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Metric</span></th>\n<th id=\"A1.T4.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"A1.T4.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\">FedAvg</span></th>\n<th id=\"A1.T4.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"A1.T4.3.1.1.4.1\" class=\"ltx_text ltx_font_bold\">FedProx</span></th>\n<th id=\"A1.T4.3.1.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"A1.T4.3.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Virtual</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T4.3.2.1\" class=\"ltx_tr\">\n<th id=\"A1.T4.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"2\"><span id=\"A1.T4.3.2.1.1.1\" class=\"ltx_text\">\n<span id=\"A1.T4.3.2.1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"A1.T4.3.2.1.1.1.1.1\" class=\"ltx_p\">FEMNIST</span>\n<span id=\"A1.T4.3.2.1.1.1.1.2\" class=\"ltx_p\">MLP</span>\n</span></span></th>\n<th id=\"A1.T4.3.2.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">MT</th>\n<td id=\"A1.T4.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">92.7</td>\n<td id=\"A1.T4.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">92.8</td>\n<td id=\"A1.T4.3.2.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span id=\"A1.T4.3.2.1.5.1\" class=\"ltx_text ltx_font_bold\">93.2</span></td>\n</tr>\n<tr id=\"A1.T4.3.3.2\" class=\"ltx_tr\">\n<th id=\"A1.T4.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">S</th>\n<td id=\"A1.T4.3.3.2.2\" class=\"ltx_td ltx_align_center\">86.2</td>\n<td id=\"A1.T4.3.3.2.3\" class=\"ltx_td ltx_align_center\">86.6</td>\n<td id=\"A1.T4.3.3.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"A1.T4.3.3.2.4.1\" class=\"ltx_text ltx_font_bold\">87.6</span></td>\n</tr>\n<tr id=\"A1.T4.3.4.3\" class=\"ltx_tr\">\n<th id=\"A1.T4.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" rowspan=\"2\"><span id=\"A1.T4.3.4.3.1.1\" class=\"ltx_text\">\n<span id=\"A1.T4.3.4.3.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"A1.T4.3.4.3.1.1.1.1\" class=\"ltx_p\">FEMNIST</span>\n<span id=\"A1.T4.3.4.3.1.1.1.2\" class=\"ltx_p\">Conv</span>\n</span></span></th>\n<th id=\"A1.T4.3.4.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MT</th>\n<td id=\"A1.T4.3.4.3.3\" class=\"ltx_td ltx_align_center\">97.0</td>\n<td id=\"A1.T4.3.4.3.4\" class=\"ltx_td ltx_align_center\">97.3</td>\n<td id=\"A1.T4.3.4.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"A1.T4.3.4.3.5.1\" class=\"ltx_text ltx_font_bold\">98.2</span></td>\n</tr>\n<tr id=\"A1.T4.3.5.4\" class=\"ltx_tr\">\n<th id=\"A1.T4.3.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">S</th>\n<td id=\"A1.T4.3.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">95.5</td>\n<td id=\"A1.T4.3.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">95.6</td>\n<td id=\"A1.T4.3.5.4.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"A1.T4.3.5.4.4.1\" class=\"ltx_text ltx_font_bold\">97.3</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            []
        ]
    }
}