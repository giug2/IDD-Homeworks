{
    "S4.T2": {
        "caption": "Table 1: AP@0.5 on KITTI-val and distribution similarity metrics between generated synthetic data and KITTI-train. Learnt parameters are used from\u00a0[30]. *Results from \u00a0[30] are our reproduced numbers, and we show learning the structure additionally helps close the distribution gap and improves downstream task performance.Table 2: Repeat of experiments in Tab.\u00a02 with a *simple prior on the scene structure. Parameters are learnt using\u00a0[30]. We observe a significant boost in both task performance and distribution similarity metrics, by learning the structure and parameters.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Structure</span></th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Parameters</span></th>\n<th id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Easy</span></th>\n<th id=\"S4.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Medium</span></th>\n<th id=\"S4.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">Hard</span></th>\n<th id=\"S4.T2.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">\n<span id=\"S4.T2.1.1.1.7.1\" class=\"ltx_text ltx_font_bold\">KID</span>&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a>]</cite>\n</th>\n<th id=\"S4.T2.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">\n<span id=\"S4.T2.1.1.1.8.1\" class=\"ltx_text ltx_font_bold\">FID</span>&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a>]</cite>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Prob. Grammar</td>\n<td id=\"S4.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Prior</td>\n<td id=\"S4.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Prior</td>\n<td id=\"S4.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">63.7</td>\n<td id=\"S4.T2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">63.7</td>\n<td id=\"S4.T2.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">62.2</td>\n<td id=\"S4.T2.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">0.066</td>\n<td id=\"S4.T2.1.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_tt\">106.6</td>\n</tr>\n<tr id=\"S4.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Meta-Sim*&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib30\" title=\"\" class=\"ltx_ref\">30</a>]</cite>\n</td>\n<td id=\"S4.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Prior</td>\n<td id=\"S4.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">Learnt</td>\n<td id=\"S4.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">66.5</td>\n<td id=\"S4.T2.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">66.3</td>\n<td id=\"S4.T2.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\">65.8</td>\n<td id=\"S4.T2.1.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0.072</td>\n<td id=\"S4.T2.1.3.2.8\" class=\"ltx_td ltx_align_center\">111.6</td>\n</tr>\n<tr id=\"S4.T2.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Ours</td>\n<td id=\"S4.T2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Learnt</td>\n<td id=\"S4.T2.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Learnt</td>\n<td id=\"S4.T2.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T2.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">67.0</span></td>\n<td id=\"S4.T2.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T2.1.4.3.5.1\" class=\"ltx_text ltx_font_bold\">67.0</span></td>\n<td id=\"S4.T2.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T2.1.4.3.6.1\" class=\"ltx_text ltx_font_bold\">66.2</span></td>\n<td id=\"S4.T2.1.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T2.1.4.3.7.1\" class=\"ltx_text ltx_font_bold\">0.054</span></td>\n<td id=\"S4.T2.1.4.3.8\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.1.4.3.8.1\" class=\"ltx_text ltx_font_bold\">99.7</span></td>\n</tr>\n</tbody>\n</table>\n<table id=\"S4.T2.2\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S4.T2.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Structure</span></th>\n<th id=\"S4.T2.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Parameters</span></th>\n<th id=\"S4.T2.2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.2.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Easy</span></th>\n<th id=\"S4.T2.2.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.2.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Medium</span></th>\n<th id=\"S4.T2.2.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S4.T2.2.1.1.6.1\" class=\"ltx_text ltx_font_bold\">Hard</span></th>\n<th id=\"S4.T2.2.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">\n<span id=\"S4.T2.2.1.1.7.1\" class=\"ltx_text ltx_font_bold\">KID</span>&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a>]</cite>\n</th>\n<th id=\"S4.T2.2.1.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">\n<span id=\"S4.T2.2.1.1.8.1\" class=\"ltx_text ltx_font_bold\">FID</span>&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a>]</cite>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.2.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Prob. Grammar</td>\n<td id=\"S4.T2.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Prior*</td>\n<td id=\"S4.T2.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Prior</td>\n<td id=\"S4.T2.2.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">61.3</td>\n<td id=\"S4.T2.2.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">59.8</td>\n<td id=\"S4.T2.2.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">58.0</td>\n<td id=\"S4.T2.2.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">0.101</td>\n<td id=\"S4.T2.2.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_tt\">130.3</td>\n</tr>\n<tr id=\"S4.T2.2.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Ours</td>\n<td id=\"S4.T2.2.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Learnt</td>\n<td id=\"S4.T2.2.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">Prior</td>\n<td id=\"S4.T2.2.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">63.2</td>\n<td id=\"S4.T2.2.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">62.5</td>\n<td id=\"S4.T2.2.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\">61.2</td>\n<td id=\"S4.T2.2.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.2.3.2.7.1\" class=\"ltx_text ltx_font_bold\">0.059</span></td>\n<td id=\"S4.T2.2.3.2.8\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.2.3.2.8.1\" class=\"ltx_text ltx_font_bold\">100.0</span></td>\n</tr>\n<tr id=\"S4.T2.2.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Ours</td>\n<td id=\"S4.T2.2.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Learnt</td>\n<td id=\"S4.T2.2.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Learnt</td>\n<td id=\"S4.T2.2.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T2.2.4.3.4.1\" class=\"ltx_text ltx_font_bold\">65.2</span></td>\n<td id=\"S4.T2.2.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T2.2.4.3.5.1\" class=\"ltx_text ltx_font_bold\">64.7</span></td>\n<td id=\"S4.T2.2.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T2.2.4.3.6.1\" class=\"ltx_text ltx_font_bold\">63.4</span></td>\n<td id=\"S4.T2.2.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">0.060</td>\n<td id=\"S4.T2.2.4.3.8\" class=\"ltx_td ltx_align_center ltx_border_b\">101.7</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Distribution similarity metrics: In generative modeling of images, the Frechet Inception Distance\u00a0[27], and the Kernel Inception Distance\u00a0[5] have been used to measure progress. We report FID and KID in Tab.\u00a02,\u00a02 between our generated synthetic dataset and the KITTI-train set. We do so by generating 10K synthetic samples and using the full KITTI-train set, computed using the pool-3 features of an Inception-v3 network. Fig.\u00a010 (left) shows the distribution of the number of cars generated by the prior, learnt model and in the KITTI dataset (since we have GT for cars). We do not have ground truth for which KITTI scenes could be classified into rural/suburban/urban, so we compare against the global distribution of the whole dataset. We notice that the model bridges the gap between this particular distribution well after training.",
            "Task Performance: We report average precision for detection at 0.5 IoU i.e.\u00a0AP@0.5 (following\u00a0[30]) of an object detector trained to convergence on our synthetic data and tested on the KITTI validation set. We use the detection head from Mask-RCNN [25] with a Resnet-50-FPN backbone initialized with pre-trained ImageNet weights as our object detector. The task network in each result row of Tab.\u00a02 is finetuned from the snapshot of the previous row.\u00a0[30] show results with adding Image-to-Image translation to the generated images to reduce the appearance gap and results with training on a small amount of real data. We omit those experiments here and refer the reader to their paper for a sketch of expected results in these settings. Training this model directly on the full KITTI training set obtains AP@0.5 of 81.52\u200b(easy)81.52easy81.52(\\text{easy}), 83.58\u200b(medium)83.58medium83.58(\\text{medium}) and 84.48\u200b(hard)84.48hard84.48(\\text{hard}), denoting a large sim-to-real performance gap left to bridge.",
            "Using a simple prior: The priors on the structure in the previous experiments were taken from\u00a0[48]. These priors already involved some human intervention, which we aim to minimize. Therefore, we repeat the experiments above with a very simple and quick to create prior on the scene structure, where a few instances of each kind of object (car, house etc.) is placed in the scene (see Fig.\u00a011 (Left)).\u00a0[30] requires a decently crafted structure prior to train the parameter network. Thus, we use the prior parameters while training our structure generator in this experiment (showing the robustness of training with randomized prior parameters), and learn the parameter network later (Tab.\u00a02). Fig.\u00a010 (right) shows that the method learned the distribution of the number of cars well (unsupervised), even when initialized from a bad prior. Notice that the FID/KID of the learnt model from the simple prior in Tab.\u00a02 is comparable to that trained from a tuned prior in Tab.\u00a02, which we believe is an exciting result.",
            "Table 2: Repeat of experiments in Tab.\u00a02 with a *simple prior on the scene structure. Parameters are learnt using\u00a0[30]. We observe a significant boost in both task performance and distribution similarity metrics, by learning the structure and parameters.",
            "Discussion: We noticed that our method worked better when initialized with more spread out priors than more localized priors (Tab.\u00a02,\u00a02, Fig.\u00a010) We hypothesize this is due to the distribution matching metric we use being the the reverse-KL divergence between the generated and real data (feature) distributions, which is mode-seeking instead of being mode-covering. Therefore, an initialization with a narrow distribution around one of the modes has low incentive to move away from it, hampering learning. Even then, we see a significant improvement in performance when starting from a peaky prior as shown in Tab.\u00a02. We also note the importance of pre-training the task network. Rows in Tab.\u00a02 and Tab.\u00a02 were finetuned from the checkpoint of the previous row. The first row (Prob. Grammar) is a form of Domain Randomization\u00a0[62, 48], which has been shown to be crucial for sim-to-real adaptation. Our method, in essence, reduces the randomization in the generated scenes (by learning to generate scenes similar to the target data), and we observe that progressively training the task network with our (more specialized) generated data improves its performance.\u00a0[1, 66] show the opposite behavior, where increasing randomization (or environment difficulty) through task training results in improved performance. A detailed analysis of this phenomemon is beyond the current scope and is left for future work."
        ]
    }
}