{
    "PAPER'S NUMBER OF TABLES": 2,
    "S4.T1": {
        "caption": "Table 1: Federated training configuration",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\">Rounds</th>\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\">Nbr clients</th>\n<th id=\"S4.T1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Update size</th>\n<th id=\"S4.T1.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Nbr of parameters</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\">30</th>\n<th id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\">10</th>\n<td id=\"S4.T1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">72 MB</td>\n<td id=\"S4.T1.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">19.639.619</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We conduct the experiment on the customer support dataset, which contains 550.287 question-answer pairs on 11 datasets from different companies (Figure 3). To ensure collaborative training, we randomly select and split data through 10 clients with 20% for the validation dataset for all clients. We used an encoder and decoder to build our transformer model, and the implementation is based on TensorFlow and FEDn. For the training process, we set the initial learning rate to 0.001, the batch size to 32 and the maximum number of epochs to 10. Texts are tokenized using Wordpieces Wu et al. (2016) with a maximum length of 30. More configuration is shown in Table 1. The hyper-parameters used in this model are shown in Table 2."
        ]
    },
    "S4.T2": {
        "caption": "Table 2:  Order in which different hyper-parameters are explored and the corresponding values considered\nfor each hyper-parameter. Underlined values indicate the default value.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Step</th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Hyper-parameter</th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Values</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">1</td>\n<td id=\"S4.T2.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">embedding dimension</td>\n<td id=\"S4.T2.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">256, 512, 1024</td>\n</tr>\n<tr id=\"S4.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.3.2.1\" class=\"ltx_td ltx_align_left\">2</td>\n<td id=\"S4.T2.1.3.2.2\" class=\"ltx_td ltx_align_left\">attention heads</td>\n<td id=\"S4.T2.1.3.2.3\" class=\"ltx_td ltx_align_left\">1, 2, 4, <span id=\"S4.T2.1.3.2.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">8</span>, 16</td>\n</tr>\n<tr id=\"S4.T2.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.4.3.1\" class=\"ltx_td ltx_align_left\">3</td>\n<td id=\"S4.T2.1.4.3.2\" class=\"ltx_td ltx_align_left\">dropout</td>\n<td id=\"S4.T2.1.4.3.3\" class=\"ltx_td ltx_align_left\">0.1, <span id=\"S4.T2.1.4.3.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">0.2</span>, 0.3, 0.4, 0.5</td>\n</tr>\n<tr id=\"S4.T2.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.5.4.1\" class=\"ltx_td ltx_align_left\">4</td>\n<td id=\"S4.T2.1.5.4.2\" class=\"ltx_td ltx_align_left\">number of layers</td>\n<td id=\"S4.T2.1.5.4.3\" class=\"ltx_td ltx_align_left\">1, 2, 3, <span id=\"S4.T2.1.5.4.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">4</span>, 5, 6, 7, 8</td>\n</tr>\n<tr id=\"S4.T2.1.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.6.5.1\" class=\"ltx_td ltx_align_left\">5</td>\n<td id=\"S4.T2.1.6.5.2\" class=\"ltx_td ltx_align_left\">number of units</td>\n<td id=\"S4.T2.1.6.5.3\" class=\"ltx_td ltx_align_left\">128, 256, <span id=\"S4.T2.1.6.5.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">512</span>\n</td>\n</tr>\n<tr id=\"S4.T2.1.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.7.6.1\" class=\"ltx_td ltx_align_left\">6</td>\n<td id=\"S4.T2.1.7.6.2\" class=\"ltx_td ltx_align_left\">enc/dec layer dropout</td>\n<td id=\"S4.T2.1.7.6.3\" class=\"ltx_td ltx_align_left\">0, 0.1, <span id=\"S4.T2.1.7.6.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">0.2</span>, 0.3, 0.4</td>\n</tr>\n<tr id=\"S4.T2.1.8.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.8.7.1\" class=\"ltx_td ltx_align_left\">7</td>\n<td id=\"S4.T2.1.8.7.2\" class=\"ltx_td ltx_align_left\">attention dropout</td>\n<td id=\"S4.T2.1.8.7.3\" class=\"ltx_td ltx_align_left\">0, 0.1, <span id=\"S4.T2.1.8.7.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">0.2</span>, 0.3</td>\n</tr>\n<tr id=\"S4.T2.1.9.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.9.8.1\" class=\"ltx_td ltx_align_left\">8</td>\n<td id=\"S4.T2.1.9.8.2\" class=\"ltx_td ltx_align_left\">activation dropout</td>\n<td id=\"S4.T2.1.9.8.3\" class=\"ltx_td ltx_align_left\">0, 0.1, <span id=\"S4.T2.1.9.8.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">0.2</span>, 0.3, 0.4, 0.5</td>\n</tr>\n<tr id=\"S4.T2.1.10.9\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.10.9.1\" class=\"ltx_td ltx_align_left\">9</td>\n<td id=\"S4.T2.1.10.9.2\" class=\"ltx_td ltx_align_left\">batch size</td>\n<td id=\"S4.T2.1.10.9.3\" class=\"ltx_td ltx_align_left\">8, <span id=\"S4.T2.1.10.9.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">32</span>, 64</td>\n</tr>\n<tr id=\"S4.T2.1.11.10\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.11.10.1\" class=\"ltx_td ltx_align_left\">10</td>\n<td id=\"S4.T2.1.11.10.2\" class=\"ltx_td ltx_align_left\">learning rate scheduler</td>\n<td id=\"S4.T2.1.11.10.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T2.1.11.10.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">Transformer standard</span>, inverse square root</td>\n</tr>\n<tr id=\"S4.T2.1.12.11\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.12.11.1\" class=\"ltx_td ltx_align_left\">11</td>\n<td id=\"S4.T2.1.12.11.2\" class=\"ltx_td ltx_align_left\">warm-up steps</td>\n<td id=\"S4.T2.1.12.11.3\" class=\"ltx_td ltx_align_left\">2000, <span id=\"S4.T2.1.12.11.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">4000</span>, 5000, 6000, 8000, 10000</td>\n</tr>\n<tr id=\"S4.T2.1.13.12\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.13.12.1\" class=\"ltx_td ltx_align_left\">12</td>\n<td id=\"S4.T2.1.13.12.2\" class=\"ltx_td ltx_align_left\">learning rate</td>\n<td id=\"S4.T2.1.13.12.3\" class=\"ltx_td ltx_align_left\">0.01, <span id=\"S4.T2.1.13.12.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">0.001</span>, 0.0001, 0.00001</td>\n</tr>\n<tr id=\"S4.T2.1.14.13\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.14.13.1\" class=\"ltx_td ltx_align_left\">13</td>\n<td id=\"S4.T2.1.14.13.2\" class=\"ltx_td ltx_align_left\">epochs</td>\n<td id=\"S4.T2.1.14.13.3\" class=\"ltx_td ltx_align_left\">5, <span id=\"S4.T2.1.14.13.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">10</span>, 15, 20, 25</td>\n</tr>\n<tr id=\"S4.T2.1.15.14\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.15.14.1\" class=\"ltx_td ltx_align_left\">14</td>\n<td id=\"S4.T2.1.15.14.2\" class=\"ltx_td ltx_align_left\">maxlen</td>\n<td id=\"S4.T2.1.15.14.3\" class=\"ltx_td ltx_align_left\">15, 20, 25, <span id=\"S4.T2.1.15.14.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">30</span>\n</td>\n</tr>\n<tr id=\"S4.T2.1.16.15\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.16.15.1\" class=\"ltx_td ltx_align_left ltx_border_b\">15</td>\n<td id=\"S4.T2.1.16.15.2\" class=\"ltx_td ltx_align_left ltx_border_b\">activation function</td>\n<td id=\"S4.T2.1.16.15.3\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S4.T2.1.16.15.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">relu</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We conduct the experiment on the customer support dataset, which contains 550.287 question-answer pairs on 11 datasets from different companies (Figure 3). To ensure collaborative training, we randomly select and split data through 10 clients with 20% for the validation dataset for all clients. We used an encoder and decoder to build our transformer model, and the implementation is based on TensorFlow and FEDn. For the training process, we set the initial learning rate to 0.001, the batch size to 32 and the maximum number of epochs to 10. Texts are tokenized using Wordpieces Wu et al. (2016) with a maximum length of 30. More configuration is shown in Table 1. The hyper-parameters used in this model are shown in Table 2."
        ]
    }
}