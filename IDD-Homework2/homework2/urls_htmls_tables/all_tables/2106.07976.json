{
    "PAPER'S NUMBER OF TABLES": 4,
    "S3.SS3.tab1": {
        "caption": "",
        "table": "<table id=\"S3.SS3.tab1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.SS3.tab1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.SS3.tab1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt\"></th>\n<th id=\"S3.SS3.tab1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Predicted Benign</th>\n<th id=\"S3.SS3.tab1.1.1.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Predicted Malicious</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.SS3.tab1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.SS3.tab1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Actual Benign</th>\n<td id=\"S3.SS3.tab1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">True Negative (TN)</td>\n<td id=\"S3.SS3.tab1.1.2.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\">False Positive (FP)</td>\n</tr>\n<tr id=\"S3.SS3.tab1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.SS3.tab1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">Actual Malicious</th>\n<td id=\"S3.SS3.tab1.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">False Negative (FN)</td>\n<td id=\"S3.SS3.tab1.1.3.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\">True Positive (TP)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We first evaluated the performance of FedDetect algorithm using the global threshold and compared its performance with three baselines. For the baseline CL-Single, we reported the average value of the nine devices’ model performances. The detailed results for the three scenarios are shown in the Table 1.",
            "For the detection model, the more benign data the model can train on, the better performance it should have. Under the global evaluation, the baseline CL-Combined trains on all benign data. Consequently, it is the best performance among all models. Within the same amount of training samples, FL with distributed training achieves nearly the same performance compared to upper bound of centralized training, which demonstrates the efficiency of FedDetect. The FedDetect algorithm has much better performance than CL-Single, because the FedDetect trains on more data among all devices collaboratively, thus it can capture more features. The FPR and TNR performance of FL is little worse than CL, because during ML optimization, the direction of gradient descent is shifted after the aggregation by averaging, leading to sub-optimal minimum, which may not be suitable for the local evaluation targets.",
            "We first verified that FedIoT on the real IoT device could achieve the same results as CPU/GPU distributed training. From Table 2, we could see that the results from the Raspberry Pi are nearly the same as the results from CPU/GPU simulation. The slight difference is due to different random initialization (i.e., different runs in different platforms).",
            "We further tested the system efficiency on the Raspberry Pi platform. From Figure 3, we can see that the training time memory cost occupies only a small fraction of the entire host memory of Raspberry Pi (only 4G host memory). The training time per round is less than 1 minute. To understand the system cost more comprehensively, we analyzed the breakdown of the end-to-end training time when the bandwidth is 7.65MB/s (a reasonable bandwidth in 4G/5G wireless communication), and results are shown in Table 3. Overall, the end-to-end training time is an acceptable training time (less than 1 hour) for practical applications. We can also find that the ratio of communication almost costs half of the end-to-end training time, indicating that the communication compression technique Lin et al. (2017); Tang et al. (2018) is essential to improve the system performance in the IoT setting."
        ]
    },
    "S3.T1": {
        "caption": "Table 1: \nPerformance of anomaly detection under both centralized training and federated training\n",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"></th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Acc</th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">FPR</th>\n<th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">TPR</th>\n<th id=\"S3.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">TNR</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt\"><span id=\"S3.T1.1.2.1.1.1\" class=\"ltx_text ltx_font_italic\">CL-Single</span></td>\n<td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">73.82%</td>\n<td id=\"S3.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">37.50%</td>\n<td id=\"S3.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">86.56%</td>\n<td id=\"S3.T1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">62.50%</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.3.2.1.1\" class=\"ltx_text ltx_font_italic\">CL-Combined</span></td>\n<td id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">98.64%</td>\n<td id=\"S3.T1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2.71%</td>\n<td id=\"S3.T1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">99.99%</td>\n<td id=\"S3.T1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.29%</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.4.3.1.1\" class=\"ltx_text ltx_font_italic\">FL-FedDect</span></td>\n<td id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">98.27%</td>\n<td id=\"S3.T1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">3.45%</td>\n<td id=\"S3.T1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">99.99%</td>\n<td id=\"S3.T1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">96.55%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We first evaluated the performance of FedDetect algorithm using the global threshold and compared its performance with three baselines. For the baseline CL-Single, we reported the average value of the nine devices’ model performances. The detailed results for the three scenarios are shown in the Table 1."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: \nCPU/GPU Training v.s. IoT Edge Training\n",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"></th>\n<th id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Acc</th>\n<th id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">FPR</th>\n<th id=\"S3.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">TPR</th>\n<th id=\"S3.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">TNR</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.2.1.1.1\" class=\"ltx_text ltx_font_italic\">Simulation</span></td>\n<td id=\"S3.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">98.27%</td>\n<td id=\"S3.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">3.45%</td>\n<td id=\"S3.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">99.99%</td>\n<td id=\"S3.T2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">96.55%</td>\n</tr>\n<tr id=\"S3.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.3.2.1.1\" class=\"ltx_text ltx_font_italic\">Raspberry Pi</span></td>\n<td id=\"S3.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">97.47%</td>\n<td id=\"S3.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">4.78%</td>\n<td id=\"S3.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">99.99%</td>\n<td id=\"S3.T2.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">95.22%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We first verified that FedIoT on the real IoT device could achieve the same results as CPU/GPU distributed training. From Table 2, we could see that the results from the Raspberry Pi are nearly the same as the results from CPU/GPU simulation. The slight difference is due to different random initialization (i.e., different runs in different platforms)."
        ]
    },
    "S3.T3": {
        "caption": "Table 3: Breakdown of the End-to-end Training Time",
        "table": "<table id=\"S3.T3.2.2\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T3.2.2.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.2.2.3.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S3.T3.2.2.3.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.2.2.3.1.1.1.1\" class=\"ltx_p\" style=\"width:150.0pt;\">Type</span>\n</span>\n</th>\n<th id=\"S3.T3.2.2.3.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S3.T3.2.2.3.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.2.2.3.1.2.1.1\" class=\"ltx_p\" style=\"width:60.0pt;\">Value</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.2.2.4.1\" class=\"ltx_tr\">\n<td id=\"S3.T3.2.2.4.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T3.2.2.4.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.2.2.4.1.1.1.1\" class=\"ltx_p\" style=\"width:150.0pt;\">end-to-end time</span>\n</span>\n</td>\n<td id=\"S3.T3.2.2.4.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T3.2.2.4.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.2.2.4.1.2.1.1\" class=\"ltx_p\" style=\"width:60.0pt;\">2547 seconds</span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T3.2.2.5.2\" class=\"ltx_tr\">\n<td id=\"S3.T3.2.2.5.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T3.2.2.5.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.2.2.5.2.1.1.1\" class=\"ltx_p\" style=\"width:150.0pt;\">uplink latency</span>\n</span>\n</td>\n<td id=\"S3.T3.2.2.5.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T3.2.2.5.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.2.2.5.2.2.1.1\" class=\"ltx_p\" style=\"width:60.0pt;\">0.167 seconds</span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T3.1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.1.1.1.2.1.1\" class=\"ltx_p\" style=\"width:150.0pt;\">communication time ratio</span>\n</span>\n</td>\n<td id=\"S3.T3.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T3.1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.1.1.1.1.1.1\" class=\"ltx_p\" style=\"width:60.0pt;\">42.2 <math id=\"S3.T3.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S3.T3.1.1.1.1.1.1.m1.1a\"><mo id=\"S3.T3.1.1.1.1.1.1.m1.1.1\" xref=\"S3.T3.1.1.1.1.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.1.1.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T3.1.1.1.1.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.1.1.1.1.1.1.m1.1c\">\\%</annotation></semantics></math></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T3.2.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T3.2.2.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T3.2.2.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.2.2.2.2.1.1\" class=\"ltx_p\" style=\"width:150.0pt;\">computation time ratio</span>\n</span>\n</td>\n<td id=\"S3.T3.2.2.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T3.2.2.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.2.2.2.1.1.1\" class=\"ltx_p\" style=\"width:60.0pt;\">57.8 <math id=\"S3.T3.2.2.2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S3.T3.2.2.2.1.1.1.m1.1a\"><mo id=\"S3.T3.2.2.2.1.1.1.m1.1.1\" xref=\"S3.T3.2.2.2.1.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.2.2.2.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.2.2.2.1.1.1.m1.1.1.cmml\" xref=\"S3.T3.2.2.2.1.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.2.2.2.1.1.1.m1.1c\">\\%</annotation></semantics></math></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T3.2.2.6.3\" class=\"ltx_tr\">\n<td id=\"S3.T3.2.2.6.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\">\n<span id=\"S3.T3.2.2.6.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.2.2.6.3.1.1.1\" class=\"ltx_p\" style=\"width:150.0pt;\">bandwidth</span>\n</span>\n</td>\n<td id=\"S3.T3.2.2.6.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\">\n<span id=\"S3.T3.2.2.6.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T3.2.2.6.3.2.1.1\" class=\"ltx_p\" style=\"width:60.0pt;\">7.65 MB/s</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "*Note: the communication time is measured by computing the interval between the timing when Raspberry Pi uploads local model to the server and the timing that Raspberry Pi receives the global model from the server. The experiment is implemented under the WiFi condition.",
        "references": [
            "We further tested the system efficiency on the Raspberry Pi platform. From Figure 3, we can see that the training time memory cost occupies only a small fraction of the entire host memory of Raspberry Pi (only 4G host memory). The training time per round is less than 1 minute. To understand the system cost more comprehensively, we analyzed the breakdown of the end-to-end training time when the bandwidth is 7.65MB/s (a reasonable bandwidth in 4G/5G wireless communication), and results are shown in Table 3. Overall, the end-to-end training time is an acceptable training time (less than 1 hour) for practical applications. We can also find that the ratio of communication almost costs half of the end-to-end training time, indicating that the communication compression technique Lin et al. (2017); Tang et al. (2018) is essential to improve the system performance in the IoT setting."
        ]
    }
}