{
    "id_table_1": {
        "caption": "Table 1:  Experimental Results on five open-domain QA datasets using two LMs as the target model.    indicates a supervised method, where the reranker or the compressor is trained. The best Accuracy and token-level F1 scores for each dataset are in bold.",
        "table": "S4.T2.1",
        "footnotes": [],
        "references": [
            "We present  FaviComp , a decoding-time evidence compression method that familiarizes the retrieved evidence with the target model while synergizing them with the models parametric knowledge. We first illustrate the motivation for  FaviComp  in  Section   2.1  and provide the preliminaries of compression-based RAG in  Section   2.2 , followed by a detailed definition of  our proposed framework in  Section   2.3 .",
            "Figure   1  illustrates the overview of  FaviComp . In this example,  FaviComp  makes the compressed evidence more favorable to the target model and leverages its parametric knowledge to supplement the missing evidence ( Lionel Messi made his league debut in Barcelona ), effectively combining evidential and parametric knowledge.",
            "In this section, we compare the overall performance of  FaviComp  with other baselines across the five datasets ( Section   4.1 ), explore the impact of ensemble coefficient    \\alpha italic_  on performance and perplexity ( Section   4.2 ), investigate how effectively  FaviComp  incorporate parametric and non-parametric knowledge ( Section   4.3 ), and compare the compression rates with other baselines ( Section   4.4 ).",
            "The overall performance of  FaviComp  and the baselines across the five datasets is presented in  Table   1 . To start with, the compression-based methods consistently outperform the reranking-based methods, due to that the reranking-based methods are prone to losing more question-relevant information by discarding lower-ranked sentences. Next,  FaviComp  outperforms all other baselines across all the datasets, except for the Gold Document which is regarded as the upper bound of the performance. It is noteworthy that  FaviComp , as a training-free, decoding-time strategy, outperforms supervised baselines, some of which are trained on the training set of the datasets. For the MuSiQue dataset,  FaviComp  even outperforms Gold Document baselinewhich can be viewed as a perfect compressorwith Llama3-8B-Instruct, and shows comparable results with Mistral-7B-Instruct. This demonstrates that explicitly incorporating parametric knowledge from the target model can significantly enhance performance in multi-document QA, even when the context is imperfect."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Compression rates of compression-based baselines. The highest compression rate is indicated in bold, while the second highest is underlined.",
        "table": "S5.T3.7.1",
        "footnotes": [],
        "references": [
            "We present  FaviComp , a decoding-time evidence compression method that familiarizes the retrieved evidence with the target model while synergizing them with the models parametric knowledge. We first illustrate the motivation for  FaviComp  in  Section   2.1  and provide the preliminaries of compression-based RAG in  Section   2.2 , followed by a detailed definition of  our proposed framework in  Section   2.3 .",
            "where  c i subscript c i c_{i} italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is the subsequent token, and    \\alpha italic_  is the ensemble coefficient that weighs between the two probability distributions. We demonstrate how the coefficient    \\alpha italic_  impacts both the perplexity and the downstream performance in  Section   4.2 .",
            "For  FaviComp , we use the same LM for both the compression model and the target model. Note that the compression model and the target model can be different, as long as they share the same tokenizer to ensure compatible token logits. Also, we set    \\alpha italic_  to 0.5 by default, for which more analyses are given in  Section   4.2 . The prompts used in the experiment are presented in  Appendix   B .",
            "In this section, we compare the overall performance of  FaviComp  with other baselines across the five datasets ( Section   4.1 ), explore the impact of ensemble coefficient    \\alpha italic_  on performance and perplexity ( Section   4.2 ), investigate how effectively  FaviComp  incorporate parametric and non-parametric knowledge ( Section   4.3 ), and compare the compression rates with other baselines ( Section   4.4 ).",
            "Figure   2  illustrates how performance and perplexity change as the ensemble coefficient    \\alpha italic_  is varied across the values  { 0.0 , 0.1 , 0.3 , 0.5 , 0.7 , 0.9 , 1.0 } 0.0 0.1 0.3 0.5 0.7 0.9 1.0 \\{0.0,0.1,0.3,0.5,0.7,0.9,1.0\\} { 0.0 , 0.1 , 0.3 , 0.5 , 0.7 , 0.9 , 1.0 }  on NQ, HotpotQA and MuSiQue datasets. We calculate the perplexity of the compressed evidence conditioned on the preceding inputs, i.e. instruction, demonstrations, and the question. For all the datasets, performance is the highest when   = 0.5  0.5 \\alpha=0.5 italic_ = 0.5 , indicating that proactively lowering perplexity by equally weighting both input sources yields the best results. Additionally, the performance tends to improve as the perplexity of compressed evidence decreases, which aligns with the previous works  (Liu et al.,  2024 ; Gonen et al.,  2023 ) . Interestingly, when    \\alpha italic_  is equal to 0.9 or 1.0, there is a slight increase in perplexity. At high    \\alpha italic_  values,  FaviComp  is more likely to generate context without referring to external knowledge. As a result, the LMs increased uncertainty when generating context with limited evidential knowledge is likely the cause of the slight rise in perplexity. Results for other datasets are included in  Figure   5 ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Case study of evidence compression:  FaviComp  vs. Raw Document and Zero-shot Summarization. For  FaviComp , the colors  red  and  blue  highlight tokens that are the  arg  max \\arg\\max roman_arg roman_max  of the compression model and the target model, respectively.  Purple  indicates a token that is the  arg  max \\arg\\max roman_arg roman_max  of neither model. Tokens with no coloring represent those that are the  arg  max \\arg\\max roman_arg roman_max  of both models.",
        "table": "A2.T4.1",
        "footnotes": [],
        "references": [
            "We present  FaviComp , a decoding-time evidence compression method that familiarizes the retrieved evidence with the target model while synergizing them with the models parametric knowledge. We first illustrate the motivation for  FaviComp  in  Section   2.1  and provide the preliminaries of compression-based RAG in  Section   2.2 , followed by a detailed definition of  our proposed framework in  Section   2.3 .",
            "In addition, ensemble decoding enables  FaviComp  to seamlessly integrate both retrieval knowledge from the external evidence set and the target models parametric knowledge. Specifically,  FaviComp  selects the  arg  max \\arg\\max roman_arg roman_max  token from the target model only when the tokens probability is higher than that of the compression model, demonstrating that  FaviComp  draws on parametric knowledge only when necessarypotentially when the compression model is uncertain about the next token. This is particularly beneficial for complex tasks like multi-document QA, where the evidence set may not include all the necessary information  (Mallen et al.,  2023 ) . In such cases, the missing information in compressed evidence can be supplemented by tokens generated from context generation by the target model, which is entirely based on parametric knowledge. We demonstrate in  Section   4.3  and  Section   5  that  FaviComp  can incorporate knowledge from both sources effectively, leading to a performance boost compared to compression methods that solely focus on distilling knowledge from the evidence set.",
            "In this section, we compare the overall performance of  FaviComp  with other baselines across the five datasets ( Section   4.1 ), explore the impact of ensemble coefficient    \\alpha italic_  on performance and perplexity ( Section   4.2 ), investigate how effectively  FaviComp  incorporate parametric and non-parametric knowledge ( Section   4.3 ), and compare the compression rates with other baselines ( Section   4.4 ).",
            "The left figure of  Figure   3  compares the accuracy in  H  i  t  s = 0 H i t s 0 Hits=0 italic_H italic_i italic_t italic_s = 0  and  H  i  t  s = 1 H i t s 1 Hits=1 italic_H italic_i italic_t italic_s = 1  subsets across the datasets. We compare  FaviComp  with the top-performing unsupervised compression method, Zero-shot Summarization, and the most competitive supervised compression method, CompAct. Compared to the other two baselines,  FaviComp  performs better in the  H  i  t  s = 0 H i t s 0 Hits=0 italic_H italic_i italic_t italic_s = 0  subset while performing comparably in the  H  i  t  s = 1 H i t s 1 Hits=1 italic_H italic_i italic_t italic_s = 1  subset. This proves that  FaviComp  effectively relies on parametric knowledge rather than evidential knowledge when faced with irrelevant evidence, while maintaining similar effectiveness in utilizing evidential knowledge when relevant evidence is present.",
            "We also evaluate the performance of  FaviComp  with various    \\alpha italic_  values under this setting. The right figure of  Figure   3  shows that   = 0.5  0.5 \\alpha=0.5 italic_ = 0.5  performs the best on the  H  i  t  s = 0 H i t s 0 Hits=0 italic_H italic_i italic_t italic_s = 0  subset, while performance declines as    \\alpha italic_  deviates further from 0.5. This pattern in the  H  i  t  s = 0 H i t s 0 Hits=0 italic_H italic_i italic_t italic_s = 0  subset mirrors the overall performance trend, suggesting that appropriately utilizing parametric knowledge when the evidence is irrelevant is crucial to the overall performance. In the  H  i  t  s = 1 H i t s 1 Hits=1 italic_H italic_i italic_t italic_s = 1  subset, performance remains consistent for    \\alpha italic_  values up to 0.5 but decreases significantly when    \\alpha italic_  exceeds 0.5 due to the diminished utilization of the relevant evidential context.",
            "Table   3  presents two examples from HotpotQA to illustrate how  FaviComp  effectively familiarizes evidence while seamlessly integrating both parametric and non-parametric knowledge during evidence compression. We compare its output with Raw Document, which does not apply any compression, and Zero-shot Summarization, which is equivalent to  FaviComp  with   = 0  0 \\alpha=0 italic_ = 0 ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  System prompts used in evaluation",
        "table": "A2.T5.1",
        "footnotes": [],
        "references": [
            "where  c i subscript c i c_{i} italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is the subsequent token, and    \\alpha italic_  is the ensemble coefficient that weighs between the two probability distributions. We demonstrate how the coefficient    \\alpha italic_  impacts both the perplexity and the downstream performance in  Section   4.2 .",
            "In addition, ensemble decoding enables  FaviComp  to seamlessly integrate both retrieval knowledge from the external evidence set and the target models parametric knowledge. Specifically,  FaviComp  selects the  arg  max \\arg\\max roman_arg roman_max  token from the target model only when the tokens probability is higher than that of the compression model, demonstrating that  FaviComp  draws on parametric knowledge only when necessarypotentially when the compression model is uncertain about the next token. This is particularly beneficial for complex tasks like multi-document QA, where the evidence set may not include all the necessary information  (Mallen et al.,  2023 ) . In such cases, the missing information in compressed evidence can be supplemented by tokens generated from context generation by the target model, which is entirely based on parametric knowledge. We demonstrate in  Section   4.3  and  Section   5  that  FaviComp  can incorporate knowledge from both sources effectively, leading to a performance boost compared to compression methods that solely focus on distilling knowledge from the evidence set.",
            "For  FaviComp , we use the same LM for both the compression model and the target model. Note that the compression model and the target model can be different, as long as they share the same tokenizer to ensure compatible token logits. Also, we set    \\alpha italic_  to 0.5 by default, for which more analyses are given in  Section   4.2 . The prompts used in the experiment are presented in  Appendix   B .",
            "In this section, we compare the overall performance of  FaviComp  with other baselines across the five datasets ( Section   4.1 ), explore the impact of ensemble coefficient    \\alpha italic_  on performance and perplexity ( Section   4.2 ), investigate how effectively  FaviComp  incorporate parametric and non-parametric knowledge ( Section   4.3 ), and compare the compression rates with other baselines ( Section   4.4 ).",
            "The evaluation prompt template is shown in  Figure   4 . For all the evaluations throughout the experiment, we switch the positions of the Question and Context if doing so results in better performance. System prompts and demonstrations used in the evaluation are presented in  Table   4  and  Table   6 , respectively."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Prompt Templates for  FaviComp",
        "table": "A2.T6.1",
        "footnotes": [],
        "references": [
            "In addition, ensemble decoding enables  FaviComp  to seamlessly integrate both retrieval knowledge from the external evidence set and the target models parametric knowledge. Specifically,  FaviComp  selects the  arg  max \\arg\\max roman_arg roman_max  token from the target model only when the tokens probability is higher than that of the compression model, demonstrating that  FaviComp  draws on parametric knowledge only when necessarypotentially when the compression model is uncertain about the next token. This is particularly beneficial for complex tasks like multi-document QA, where the evidence set may not include all the necessary information  (Mallen et al.,  2023 ) . In such cases, the missing information in compressed evidence can be supplemented by tokens generated from context generation by the target model, which is entirely based on parametric knowledge. We demonstrate in  Section   4.3  and  Section   5  that  FaviComp  can incorporate knowledge from both sources effectively, leading to a performance boost compared to compression methods that solely focus on distilling knowledge from the evidence set.",
            "Figure   2  illustrates how performance and perplexity change as the ensemble coefficient    \\alpha italic_  is varied across the values  { 0.0 , 0.1 , 0.3 , 0.5 , 0.7 , 0.9 , 1.0 } 0.0 0.1 0.3 0.5 0.7 0.9 1.0 \\{0.0,0.1,0.3,0.5,0.7,0.9,1.0\\} { 0.0 , 0.1 , 0.3 , 0.5 , 0.7 , 0.9 , 1.0 }  on NQ, HotpotQA and MuSiQue datasets. We calculate the perplexity of the compressed evidence conditioned on the preceding inputs, i.e. instruction, demonstrations, and the question. For all the datasets, performance is the highest when   = 0.5  0.5 \\alpha=0.5 italic_ = 0.5 , indicating that proactively lowering perplexity by equally weighting both input sources yields the best results. Additionally, the performance tends to improve as the perplexity of compressed evidence decreases, which aligns with the previous works  (Liu et al.,  2024 ; Gonen et al.,  2023 ) . Interestingly, when    \\alpha italic_  is equal to 0.9 or 1.0, there is a slight increase in perplexity. At high    \\alpha italic_  values,  FaviComp  is more likely to generate context without referring to external knowledge. As a result, the LMs increased uncertainty when generating context with limited evidential knowledge is likely the cause of the slight rise in perplexity. Results for other datasets are included in  Figure   5 .",
            "(2)  Generated Context : We use the context generation prompt in  Table   5  to generate the context.",
            "(3)  Zero-shot Summarization : We use the evidence compression prompt in  Table   5  to compress the retrieved documents.",
            "The prompt templates for evidence compression and context generation of  FaviComp  are presented in  Table   5"
        ]
    },
    "global_footnotes": [
        "Code and data are available at https://github.com/luka-group/FaviComp",
        "https://huggingface.co/facebook/contriever-msmarco"
    ]
}