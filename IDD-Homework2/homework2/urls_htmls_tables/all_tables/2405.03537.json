{
    "PAPER'S NUMBER OF TABLES": 6,
    "S5.T1": {
        "caption": "TABLE I: Experimental Setup Hyper-Parameters",
        "table": "<table id=\"S5.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Hyper-Parameter</span></th>\n<th id=\"S5.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Value</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Federated Learning Rounds</td>\n<td id=\"S5.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">20</td>\n</tr>\n<tr id=\"S5.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Local Nodes</td>\n<td id=\"S5.T1.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">3</td>\n</tr>\n<tr id=\"S5.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Global Server</td>\n<td id=\"S5.T1.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1</td>\n</tr>\n<tr id=\"S5.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Epochs in Local Node</td>\n<td id=\"S5.T1.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">10</td>\n</tr>\n<tr id=\"S5.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Learning Rate</td>\n<td id=\"S5.T1.1.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.001</td>\n</tr>\n<tr id=\"S5.T1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Data Streams</td>\n<td id=\"S5.T1.1.7.6.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">4</td>\n</tr>\n<tr id=\"S5.T1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Batch Size</td>\n<td id=\"S5.T1.1.8.7.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">16</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To evaluate the efficacy of our proposed hybrid learning paradigm and attention-based classifier model, we conduct an extensive empirical investigation. We compare our approach to pre-existing neural network architectures and investigate the best continual learning strategy for this scenario.",
                "Our experimental setup involves multiple datasets, to assess the performance and adaptability of our solution under various scenarios. We evaluate our approach across different continual learning strategies and model architectures, aiming to identify the optimal setup for robust and accurate phishing detection.",
                "The evaluation metrics considered in our analysis include accuracy, precision, recall and F1-score across various continual learning strategies, namely Naive, Replay, Cumulative, Learning without Forgetting (LwF), and Maximally Interfered Replay (MIR). Each strategy is compared against traditional machine learning models including Simple Multilayer Perceptron (MLP), Deep MLP, and Simple Recurrent Neural Network (RNN).",
                "In Table ",
                "II",
                " the Naive continual learning strategy, our attention-based classifier model achieved an accuracy of 0.70, outperforming Simple MLP, Deep MLP, and Simple RNN models with accuracies of 0.52, 0.50, and 0.64, respectively. The precision, recall, and F1-score for our model were 0.75, 0.60, and 0.67, indicating its effectiveness in capturing phishing website patterns compared to baseline models.",
                "In Table ",
                "III",
                " under the Replay continual learning strategy, our model demonstrated further improvement with an accuracy of 0.73, surpassing Simple MLP, Deep MLP, and Simple RNN models with accuracies of 0.60, 0.65, and 0.67, respectively. Notably, our model achieved the highest precision and F1-score of 0.91 and 0.75, respectively, highlighting its superior ability in distinguishing phishing websites.",
                "In Table ",
                "IV",
                " our attention-based classifier model excelled in the Cumulative continual learning scenario, achieving an accuracy of 0.86, substantially outperforming Simple MLP, Deep MLP, and Simple RNN models with accuracies of 0.72, 0.76, and 0.76, respectively. Additionally, our model exhibited superior precision, recall, and F1-score of 0.87, 0.84, and 0.84, underscoring its robustness and adaptability in cumulative learning settings.",
                "In Table ",
                "V",
                " the LwF continual learning approach, our model demonstrated remarkable performance, achieving an accuracy of 0.93, significantly outperforming Simple MLP, Deep MLP, and Simple RNN models with accuracies of 0.77, 0.73, and 0.88, respectively. With precision, recall, and F1-score values of 0.90, 0.96, and 0.93, our model exhibited superior capability in preserving previously learned knowledge while accommodating new information.",
                "In Table ",
                "VI",
                " under the MIR continual learning strategy, our attention-based classifier model achieved an accuracy of 0.59, surpassing Simple MLP, Deep MLP, and Simple RNN models with accuracies of 0.53, 0.55, and 0.54, respectively. Despite the lower performance compared to other strategies, our model maintained competitive precision, recall, and F1-score values of 0.58 each, showcasing its potential in adapting to evolving data distributions.",
                "In Fig. ",
                "5",
                ", Fig. ",
                "6",
                ", Fig. ",
                "7",
                ", Fig. ",
                "8",
                ", through our comprehensive empirical evaluation and comparative analysis, we demonstrate the superior performance of our proposed hybrid learning paradigm and attention-based classifier model in detecting the latest phishing threats while preserving knowledge from past data distributions. Our results highlight the advantages of integrating federated and continual learning, leveraging attention mechanisms, and incorporating adaptive feature selection for robust and adaptable phishing website detection.",
                "In summary, our proposed solution addresses the limitations of existing approaches by introducing a novel hybrid learning paradigm that combines federated and continual learning, enabling distributed nodes to collaboratively train and continually adapt a shared model to emerging phishing threats. The attention-based classifier model, tailored explicitly for web phishing detection, leverages attention mechanisms and adaptive feature selection to capture intricate patterns and distinguish between legitimate and malicious websites effectively. Through our empirical evaluation and comparative analysis, we demonstrate the efficacy and robustness of our approach, contributing to the ongoing efforts in mitigating the persistent threat of phishing attacks."
            ]
        ]
    },
    "S5.T2": {
        "caption": "TABLE II: Results under Naive Strategy",
        "table": "<table id=\"S5.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S5.T2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S5.T2.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></td>\n<td id=\"S5.T2.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Recall</span></td>\n<td id=\"S5.T2.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">F1-Score</span></td>\n</tr>\n<tr id=\"S5.T2.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Simple MLP</td>\n<td id=\"S5.T2.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.52</td>\n<td id=\"S5.T2.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.25</td>\n<td id=\"S5.T2.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.50</td>\n<td id=\"S5.T2.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.33</td>\n</tr>\n<tr id=\"S5.T2.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Deep MLP</td>\n<td id=\"S5.T2.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.50</td>\n<td id=\"S5.T2.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.43</td>\n<td id=\"S5.T2.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.75</td>\n<td id=\"S5.T2.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.55</td>\n</tr>\n<tr id=\"S5.T2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Simple RNN</td>\n<td id=\"S5.T2.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.64</td>\n<td id=\"S5.T2.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.86</td>\n<td id=\"S5.T2.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.50</td>\n<td id=\"S5.T2.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.62</td>\n</tr>\n<tr id=\"S5.T2.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Ours</td>\n<td id=\"S5.T2.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.70</td>\n<td id=\"S5.T2.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.75</td>\n<td id=\"S5.T2.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.60</td>\n<td id=\"S5.T2.1.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.67</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In Table II the Naive continual learning strategy, our attention-based classifier model achieved an accuracy of 0.70, outperforming Simple MLP, Deep MLP, and Simple RNN models with accuracies of 0.52, 0.50, and 0.64, respectively. The precision, recall, and F1-score for our model were 0.75, 0.60, and 0.67, indicating its effectiveness in capturing phishing website patterns compared to baseline models."
        ]
    },
    "S5.T3": {
        "caption": "TABLE III: Results under Replay Strategy",
        "table": "<table id=\"S5.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S5.T3.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S5.T3.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></td>\n<td id=\"S5.T3.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Recall</span></td>\n<td id=\"S5.T3.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">F1-Score</span></td>\n</tr>\n<tr id=\"S5.T3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Simple MLP</td>\n<td id=\"S5.T3.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.60</td>\n<td id=\"S5.T3.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.70</td>\n<td id=\"S5.T3.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.57</td>\n<td id=\"S5.T3.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.64</td>\n</tr>\n<tr id=\"S5.T3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Deep MLP</td>\n<td id=\"S5.T3.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.65</td>\n<td id=\"S5.T3.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.78</td>\n<td id=\"S5.T3.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.60</td>\n<td id=\"S5.T3.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.67</td>\n</tr>\n<tr id=\"S5.T3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Simple RNN</td>\n<td id=\"S5.T3.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.67</td>\n<td id=\"S5.T3.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.80</td>\n<td id=\"S5.T3.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.63</td>\n<td id=\"S5.T3.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.71</td>\n</tr>\n<tr id=\"S5.T3.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Ours</td>\n<td id=\"S5.T3.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.73</td>\n<td id=\"S5.T3.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.91</td>\n<td id=\"S5.T3.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.63</td>\n<td id=\"S5.T3.1.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.75</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In Table III under the Replay continual learning strategy, our model demonstrated further improvement with an accuracy of 0.73, surpassing Simple MLP, Deep MLP, and Simple RNN models with accuracies of 0.60, 0.65, and 0.67, respectively. Notably, our model achieved the highest precision and F1-score of 0.91 and 0.75, respectively, highlighting its superior ability in distinguishing phishing websites."
        ]
    },
    "S5.T4": {
        "caption": "TABLE IV: Results under Cumulative Strategy",
        "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></td>\n<td id=\"S5.T4.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Recall</span></td>\n<td id=\"S5.T4.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">F1-Score</span></td>\n</tr>\n<tr id=\"S5.T4.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Simple MLP</td>\n<td id=\"S5.T4.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.72</td>\n<td id=\"S5.T4.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.73</td>\n<td id=\"S5.T4.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.75</td>\n<td id=\"S5.T4.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.73</td>\n</tr>\n<tr id=\"S5.T4.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Deep MLP</td>\n<td id=\"S5.T4.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.76</td>\n<td id=\"S5.T4.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.78</td>\n<td id=\"S5.T4.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.75</td>\n<td id=\"S5.T4.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.77</td>\n</tr>\n<tr id=\"S5.T4.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Simple RNN</td>\n<td id=\"S5.T4.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.76</td>\n<td id=\"S5.T4.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.77</td>\n<td id=\"S5.T4.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.77</td>\n<td id=\"S5.T4.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.77</td>\n</tr>\n<tr id=\"S5.T4.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Ours</td>\n<td id=\"S5.T4.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.86</td>\n<td id=\"S5.T4.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.87</td>\n<td id=\"S5.T4.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.84</td>\n<td id=\"S5.T4.1.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.84</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In Table IV our attention-based classifier model excelled in the Cumulative continual learning scenario, achieving an accuracy of 0.86, substantially outperforming Simple MLP, Deep MLP, and Simple RNN models with accuracies of 0.72, 0.76, and 0.76, respectively. Additionally, our model exhibited superior precision, recall, and F1-score of 0.87, 0.84, and 0.84, underscoring its robustness and adaptability in cumulative learning settings."
        ]
    },
    "S5.T5": {
        "caption": "TABLE V: Results under LwF Strategy",
        "table": "<table id=\"S5.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S5.T5.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S5.T5.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></td>\n<td id=\"S5.T5.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Recall</span></td>\n<td id=\"S5.T5.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">F1-Score</span></td>\n</tr>\n<tr id=\"S5.T5.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Simple MLP</td>\n<td id=\"S5.T5.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.77</td>\n<td id=\"S5.T5.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.69</td>\n<td id=\"S5.T5.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.75</td>\n<td id=\"S5.T5.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.71</td>\n</tr>\n<tr id=\"S5.T5.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Deep MLP</td>\n<td id=\"S5.T5.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.73</td>\n<td id=\"S5.T5.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.67</td>\n<td id=\"S5.T5.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.71</td>\n<td id=\"S5.T5.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.69</td>\n</tr>\n<tr id=\"S5.T5.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Simple RNN</td>\n<td id=\"S5.T5.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.88</td>\n<td id=\"S5.T5.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.87</td>\n<td id=\"S5.T5.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.87</td>\n<td id=\"S5.T5.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.87</td>\n</tr>\n<tr id=\"S5.T5.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Ours</td>\n<td id=\"S5.T5.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.93</td>\n<td id=\"S5.T5.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.90</td>\n<td id=\"S5.T5.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.96</td>\n<td id=\"S5.T5.1.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.93</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In Table V the LwF continual learning approach, our model demonstrated remarkable performance, achieving an accuracy of 0.93, significantly outperforming Simple MLP, Deep MLP, and Simple RNN models with accuracies of 0.77, 0.73, and 0.88, respectively. With precision, recall, and F1-score values of 0.90, 0.96, and 0.93, our model exhibited superior capability in preserving previously learned knowledge while accommodating new information."
        ]
    },
    "S5.T6": {
        "caption": "TABLE VI: Results under MIR Strategy",
        "table": "<table id=\"S5.T6.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T6.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S5.T6.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S5.T6.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></td>\n<td id=\"S5.T6.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Recall</span></td>\n<td id=\"S5.T6.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">F1-Score</span></td>\n</tr>\n<tr id=\"S5.T6.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Simple MLP</td>\n<td id=\"S5.T6.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.53</td>\n<td id=\"S5.T6.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.56</td>\n<td id=\"S5.T6.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.53</td>\n<td id=\"S5.T6.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.53</td>\n</tr>\n<tr id=\"S5.T6.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Deep MLP</td>\n<td id=\"S5.T6.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.55</td>\n<td id=\"S5.T6.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.57</td>\n<td id=\"S5.T6.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.53</td>\n<td id=\"S5.T6.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.55</td>\n</tr>\n<tr id=\"S5.T6.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Simple RNN</td>\n<td id=\"S5.T6.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.54</td>\n<td id=\"S5.T6.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.56</td>\n<td id=\"S5.T6.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.53</td>\n<td id=\"S5.T6.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0.55</td>\n</tr>\n<tr id=\"S5.T6.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Ours</td>\n<td id=\"S5.T6.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.59</td>\n<td id=\"S5.T6.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.58</td>\n<td id=\"S5.T6.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.58</td>\n<td id=\"S5.T6.1.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.58</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In Table VI under the MIR continual learning strategy, our attention-based classifier model achieved an accuracy of 0.59, surpassing Simple MLP, Deep MLP, and Simple RNN models with accuracies of 0.53, 0.55, and 0.54, respectively. Despite the lower performance compared to other strategies, our model maintained competitive precision, recall, and F1-score values of 0.58 each, showcasing its potential in adapting to evolving data distributions."
        ]
    }
}