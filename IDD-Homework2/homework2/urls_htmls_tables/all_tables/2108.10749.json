{
    "PAPER'S NUMBER OF TABLES": 1,
    "S4.T1": {
        "caption": "Table 1: Comparison of clustering-based federated learning",
        "table": "<table id=\"S4.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_ll ltx_border_r ltx_border_t\" style=\"width:71.1pt;\">\n<span id=\"S4.T1.3.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.1.1.1.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.1.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Methods</span></span>\n</span>\n</th>\n<th id=\"S4.T1.3.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"width:56.9pt;\">\n<span id=\"S4.T1.3.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.1.1.2.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.1.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Motivation</span></span>\n</span>\n</th>\n<th id=\"S4.T1.3.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"width:51.2pt;\">\n<span id=\"S4.T1.3.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.1.1.3.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.1.1.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Clustering</span></span>\n</span>\n</th>\n<th id=\"S4.T1.3.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"width:56.9pt;\">\n<span id=\"S4.T1.3.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.1.1.4.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.1.1.4.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Factors</span></span>\n</span>\n</th>\n<th id=\"S4.T1.3.1.1.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_rr ltx_border_t\" style=\"width:71.1pt;\">\n<span id=\"S4.T1.3.1.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.1.1.5.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.1.1.5.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Measurement</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.3.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.2.1.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_ll ltx_border_r ltx_border_tt\" style=\"width:71.1pt;\">\n<span id=\"S4.T1.3.2.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.2.1.1.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.2.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Multi-center FL</span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T1.3.2.1.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib34\" title=\"\" class=\"ltx_ref\">34</a><span id=\"S4.T1.3.2.1.1.1.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite></span>\n</span>\n</td>\n<td id=\"S4.T1.3.2.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_tt\" style=\"width:56.9pt;\">\n<span id=\"S4.T1.3.2.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.2.1.2.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.2.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Better initialisation</span></span>\n</span>\n</td>\n<td id=\"S4.T1.3.2.1.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_tt\" style=\"width:51.2pt;\">\n<span id=\"S4.T1.3.2.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.2.1.3.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.2.1.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">K-means</span></span>\n</span>\n</td>\n<td id=\"S4.T1.3.2.1.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_tt\" style=\"width:56.9pt;\">\n<span id=\"S4.T1.3.2.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.2.1.4.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.2.1.4.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model parameters</span></span>\n</span>\n</td>\n<td id=\"S4.T1.3.2.1.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_rr ltx_border_tt\" style=\"width:71.1pt;\">\n<span id=\"S4.T1.3.2.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.2.1.5.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.2.1.5.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">L2-distance</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T1.3.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.3.2.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_ll ltx_border_r ltx_border_t\" style=\"width:71.1pt;\">\n<span id=\"S4.T1.3.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.3.2.1.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.3.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Hierarchical clustering-based FL </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T1.3.3.2.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib31\" title=\"\" class=\"ltx_ref\">31</a>, <a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a><span id=\"S4.T1.3.3.2.1.1.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite></span>\n</span>\n</td>\n<td id=\"S4.T1.3.3.2.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t\" style=\"width:56.9pt;\">\n<span id=\"S4.T1.3.3.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.3.2.2.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.3.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Similar distribution</span></span>\n</span>\n</td>\n<td id=\"S4.T1.3.3.2.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t\" style=\"width:51.2pt;\">\n<span id=\"S4.T1.3.3.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.3.2.3.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.3.2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Hierarchical clustering</span></span>\n</span>\n</td>\n<td id=\"S4.T1.3.3.2.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t\" style=\"width:56.9pt;\">\n<span id=\"S4.T1.3.3.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.3.2.4.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.3.2.4.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Gradients</span></span>\n</span>\n</td>\n<td id=\"S4.T1.3.3.2.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_rr ltx_border_t\" style=\"width:71.1pt;\">\n<span id=\"S4.T1.3.3.2.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.3.2.5.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.3.2.5.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Cosine similarity &amp; L1/L2 distance</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T1.3.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.4.3.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_ll ltx_border_r ltx_border_t\" style=\"width:71.1pt;\">\n<span id=\"S4.T1.3.4.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.4.3.1.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.4.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Hypothesis clustering-based FL </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T1.3.4.3.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>, <a href=\"#bib.bib13\" title=\"\" class=\"ltx_ref\">13</a><span id=\"S4.T1.3.4.3.1.1.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite></span>\n</span>\n</td>\n<td id=\"S4.T1.3.4.3.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t\" style=\"width:56.9pt;\">\n<span id=\"S4.T1.3.4.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.4.3.2.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.4.3.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Better hypothesis</span></span>\n</span>\n</td>\n<td id=\"S4.T1.3.4.3.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t\" style=\"width:51.2pt;\">\n<span id=\"S4.T1.3.4.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.4.3.3.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.4.3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">K-means</span></span>\n</span>\n</td>\n<td id=\"S4.T1.3.4.3.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t\" style=\"width:56.9pt;\">\n<span id=\"S4.T1.3.4.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.4.3.4.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.4.3.4.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Test accuracy</span></span>\n</span>\n</td>\n<td id=\"S4.T1.3.4.3.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_rr ltx_border_t\" style=\"width:71.1pt;\">\n<span id=\"S4.T1.3.4.3.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.3.4.3.5.1.1\" class=\"ltx_p\"><span id=\"S4.T1.3.4.3.5.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">The loss of hypothesis</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "A machine learning model could be treated as a function to approximate the distribution. In general, two models with similar parameters or functions are more likely to produce a similar outcome regarding the same input. Therefore, measuring models’ similarity is an indirect way to measure distribution. Below are the related methods for clustered federated learning.",
                "Xie ",
                "et al.",
                " ",
                "[",
                "34",
                "]",
                " addresses the non-IID challenge of federated learning and proposes a multi-center aggregation approach. The non-IID problem in federated learning is defined as a joint optimization problem of multiple centers/clusters across participants. It can simultaneously learn multiple global models from participants with non-IID data, and the clustering and model learning are jointly optimized in a stochastic expectation maximization framework.\nIn particular, the loss function of the federated learning framework is defined as below.",
                "where the similarity of two models is measured by the L2 distance between the ",
                "i",
                "𝑖",
                "i",
                "-th participant’s model ",
                "W",
                "i",
                "subscript",
                "𝑊",
                "𝑖",
                "W_{i}",
                " and the global model ",
                "W",
                "(",
                "k",
                ")",
                "superscript",
                "𝑊",
                "𝑘",
                "W^{(k)}",
                " of the cluster ",
                "k",
                "𝑘",
                "k",
                ".",
                "In some cases using Convolutional Neural Networks (CNN) as basic model architecture, two neurons from different models may have similar functions but with different neuron indices. Therefore, neuron matching of two CNN models cannot be simply applied to index-based matching, and it needs to be carefully considered for functionality matching. A proper neuron matching mechanism in the context of federated learning can improve the performance ",
                "[",
                "33",
                "]",
                ". It could be further applied to clustering-based federated learning that considers matching neurons in both averaging and clustering steps.",
                "[",
                "31",
                "]",
                " proposes to distinguish participants based on their hidden data generating distribution by inspecting the cosine similarity ",
                "α",
                "i",
                ",",
                "j",
                "subscript",
                "𝛼",
                "𝑖",
                "𝑗",
                "\\alpha_{i,j}",
                " between their gradient updates ",
                "r",
                "i",
                "subscript",
                "𝑟",
                "𝑖",
                "r_{i}",
                " and ",
                "r",
                "j",
                "subscript",
                "𝑟",
                "𝑗",
                "r_{j}",
                ". Based on the measurement in Eq. ",
                "3",
                ", a hierarchical clustering method is proposed to iteratively split participants into multiple groups, in which pairs of participants with larger similarity are more likely to be allocated to the same group. Below is the equation to calculate the similarity between a pair of participants ",
                "i",
                "𝑖",
                "i",
                " and ",
                "j",
                "𝑗",
                "j",
                ". Moreover, ",
                "[",
                "5",
                "]",
                " discussed using different measurements.",
                "where the ",
                "W",
                "i",
                "subscript",
                "𝑊",
                "𝑖",
                "W_{i}",
                " and ",
                "W",
                "j",
                "subscript",
                "𝑊",
                "𝑗",
                "W_{j}",
                " are the model parameters of participants ",
                "i",
                "𝑖",
                "i",
                " ad ",
                "j",
                "𝑗",
                "j",
                " respectively.",
                "Mansour ",
                "et al.",
                " in ",
                "[",
                "25",
                "]",
                " use a performance indicator to decide the cluster assignment for each node. In particular, given ",
                "K",
                "𝐾",
                "K",
                " clusters with model ",
                "F",
                "k",
                "subscript",
                "𝐹",
                "𝑘",
                "F_{k}",
                " controlled by ",
                "W",
                "𝑊",
                "W",
                ", the participant ",
                "i",
                "𝑖",
                "i",
                " will be assigned to cluster ",
                "k",
                "𝑘",
                "k",
                " whose model will generate the minimal loss ",
                "L",
                "𝐿",
                "L",
                " using the test data set ",
                "D",
                "i",
                "subscript",
                "𝐷",
                "𝑖",
                "D_{i}",
                " from participant ",
                "i",
                "𝑖",
                "i",
                ". The overall loss can be rewritten as follows.",
                "in where ",
                "W",
                "(",
                "k",
                ")",
                "subscript",
                "𝑊",
                "𝑘",
                "W_{(k)}",
                " is the parameters of the ",
                "k",
                "𝑘",
                "k",
                "-th global model/hypothesis.\nThe paper gives a comprehensive theoretical analysis of the given method. Then, ",
                "[",
                "13",
                "]",
                " conducts convergence rate analysis in the same method. ",
                "[",
                "27",
                "]",
                " proposes a similar solution from a mixture of distribution perspectives."
            ]
        ]
    }
}