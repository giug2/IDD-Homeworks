{
    "Sx4.T1.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"Sx4.T1.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.1.1.1\">Task</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.1.1.2\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T1.1.1.1.1.3\">Dataset</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.2.2\">\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.2.2.1\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.2.2.2\">GoogLeNet <cite class=\"ltx_cite ltx_citemacro_citep\">(Szegedy et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib34\" title=\"\">2015</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_border_t\" id=\"Sx4.T1.1.1.2.2.3\"/>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T1.1.1.3.3.1\">Image</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.3.3.2\">ResNet-18 <cite class=\"ltx_cite ltx_citemacro_citep\">(He et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib14\" title=\"\">2016</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T1.1.1.3.3.3\">ImageNet-1K</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T1.1.1.4.4.1\">Classification</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.4.4.2\">ECA-MobileNetV2 <cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib37\" title=\"\">2020</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T1.1.1.4.4.3\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Deng et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib8\" title=\"\">2009</a>)</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.5.5\">\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T1.1.1.5.5.1\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.5.5.2\">ConvNeXt-L <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib27\" title=\"\">2022</a>)</cite>\n</td>\n<td class=\"ltx_td\" id=\"Sx4.T1.1.1.5.5.3\"/>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.6.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.6.6.1\">Object</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.6.6.2\">YOLOv8 <cite class=\"ltx_cite ltx_citemacro_citep\">(Jocher et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib17\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T1.1.1.6.6.3\">COCO2017</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.7.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T1.1.1.7.7.1\">Detection</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.7.7.2\">ONE-PEACE <cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib36\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T1.1.1.7.7.3\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Lin et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib24\" title=\"\">2014</a>)</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.8.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.8.8.1\">Instance</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.8.8.2\">YOLOv8 <cite class=\"ltx_cite ltx_citemacro_citep\">(Jocher et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib17\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T1.1.1.8.8.3\">COCO2017</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.9.9\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T1.1.1.9.9.1\">Segmentation</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.9.9.2\">MaskDINO <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib22\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T1.1.1.9.9.3\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Lin et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib24\" title=\"\">2014</a>)</cite></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.10.10\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.10.10.1\">Semantic</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.10.10.2\">MaskDINO <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib22\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T1.1.1.10.10.3\">ADE20K</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T1.1.1.11.11\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" id=\"Sx4.T1.1.1.11.11.1\">Segmentation</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"Sx4.T1.1.1.11.11.2\">ONE-PEACE <cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib36\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"Sx4.T1.1.1.11.11.3\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Zhou et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.17093v1#bib.bib44\" title=\"\">2017</a>)</cite></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 1:  Characteristic of benchmarks and datasets.",
        "footnotes": [
            "Szegedy et al. (2015) \nSzegedy, C.; Liu, W.; Jia, Y.; Sermanet, P.; Reed, S.; Anguelov, D.; Erhan, D.; Vanhoucke, V.; and Rabinovich, A. 2015.\n\n Going deeper with convolutions.\n\n In  2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 1–9.\n\n",
            "He et al. (2016) \nHe, K.; Zhang, X.; Ren, S.; and Sun, J. 2016.\n\n Deep Residual Learning for Image Recognition.\n\n In  2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 770–778.\n\n",
            "Wang et al. (2020) \nWang, Q.; Wu, B.; Zhu, P.; Li, P.; Zuo, W.; and Hu, Q. 2020.\n\n ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks.\n\n In  2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 11531–11539.\n\n",
            "Deng et al. (2009) \nDeng, J.; Dong, W.; Socher, R.; Li, L.-J.; Li, K.; and Fei-Fei, L. 2009.\n\n ImageNet: A large-scale hierarchical image database.\n\n In  2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 248–255.\n\n",
            "Liu et al. (2022) \nLiu, Z.; Mao, H.; Wu, C.; Feichtenhofer, C.; Darrell, T.; and Xie, S. 2022.\n\n A ConvNet for the 2020s.\n\n In  2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 11966–11976.\n\n",
            "Jocher et al. (2023) \nJocher; et al. 2023.\n\n Ultralytics YOLO.\n\n",
            "Wang et al. (2023) \nWang, P.; Wang, S.; Lin, J.; Bai, S.; Zhou, X.; Zhou, J.; Wang, X.; and Zhou, C. 2023.\n\n ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities.\n\n arXiv:2305.11172.\n\n",
            "Lin et al. (2014) \nLin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.; Dollár, P.; and Zitnick, C. L. 2014.\n\n Microsoft COCO: Common Objects in Context.\n\n In  Computer Vision – ECCV 2014 , 740–755. Cham: Springer International Publishing.\n\n",
            "Jocher et al. (2023) \nJocher; et al. 2023.\n\n Ultralytics YOLO.\n\n",
            "Li et al. (2023) \nLi, F.; Zhang, H.; Xu, H.; Liu, S.; Zhang, L.; Ni, L. M.; and Shum, H. 2023.\n\n Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation.\n\n In  2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 3041–3050.\n\n",
            "Lin et al. (2014) \nLin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.; Dollár, P.; and Zitnick, C. L. 2014.\n\n Microsoft COCO: Common Objects in Context.\n\n In  Computer Vision – ECCV 2014 , 740–755. Cham: Springer International Publishing.\n\n",
            "Li et al. (2023) \nLi, F.; Zhang, H.; Xu, H.; Liu, S.; Zhang, L.; Ni, L. M.; and Shum, H. 2023.\n\n Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation.\n\n In  2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 3041–3050.\n\n",
            "Wang et al. (2023) \nWang, P.; Wang, S.; Lin, J.; Bai, S.; Zhou, X.; Zhou, J.; Wang, X.; and Zhou, C. 2023.\n\n ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities.\n\n arXiv:2305.11172.\n\n",
            "Zhou et al. (2017) \nZhou, B.; Zhao, H.; Puig, X.; Fidler, S.; Barriuso, A.; and Torralba, A. 2017.\n\n Scene Parsing through ADE20K Dataset.\n\n In  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 5122–5130.\n\n"
        ],
        "references": [
            "We conduct comprehensive experimental evaluations across diverse vision tasks, encompassing image classification on ImageNet-1K (Deng et al. 2009), object detection and instance segmentation on COCO2017 (Lin et al. 2014), and semantic segmentation on ADE20K (Zhou et al. 2017). Table 1 outlines the characteristics of the benchmarks and datasets.",
            "Within the BitQ framework, a pivotal parameter is the loss balance factor α𝛼\\alphaitalic_α. Varied values of this parameter have the potential to impact inference performance and energy consumption diversely. Specifically, α𝛼\\alphaitalic_α plays a key role in the selection of BFP quantization parameters by striking a balance between accuracy and performance losses. We conduct the sensitivity analysis under different levels of α𝛼\\alphaitalic_α, by seven representative values (α∈𝛼absent\\alpha\\initalic_α ∈ { 0.015, 0.05, 0.15, 0.2, 0.25, 1.5, 3 }, ranging from 0 to 3). We conduct the sensitivity analysis based on the same ten benchmarks (listed in Table 1) for both 16-bit and 8-bit BFP data representation."
        ]
    },
    "Sx4.T2.4.4": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"Sx4.T2.4.4\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Sx4.T2.2.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\" id=\"Sx4.T2.1.1.1.1\">Shared Exponents (<math alttext=\"SE\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.T2.1.1.1.1.m1.1\"><semantics id=\"Sx4.T2.1.1.1.1.m1.1a\"><mrow id=\"Sx4.T2.1.1.1.1.m1.1.1\" xref=\"Sx4.T2.1.1.1.1.m1.1.1.cmml\"><mi id=\"Sx4.T2.1.1.1.1.m1.1.1.2\" xref=\"Sx4.T2.1.1.1.1.m1.1.1.2.cmml\">S</mi><mo id=\"Sx4.T2.1.1.1.1.m1.1.1.1\" xref=\"Sx4.T2.1.1.1.1.m1.1.1.1.cmml\">&#8290;</mo><mi id=\"Sx4.T2.1.1.1.1.m1.1.1.3\" xref=\"Sx4.T2.1.1.1.1.m1.1.1.3.cmml\">E</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.1.1.1.1.m1.1b\"><apply id=\"Sx4.T2.1.1.1.1.m1.1.1.cmml\" xref=\"Sx4.T2.1.1.1.1.m1.1.1\"><times id=\"Sx4.T2.1.1.1.1.m1.1.1.1.cmml\" xref=\"Sx4.T2.1.1.1.1.m1.1.1.1\"/><ci id=\"Sx4.T2.1.1.1.1.m1.1.1.2.cmml\" xref=\"Sx4.T2.1.1.1.1.m1.1.1.2\">&#119878;</ci><ci id=\"Sx4.T2.1.1.1.1.m1.1.1.3.cmml\" xref=\"Sx4.T2.1.1.1.1.m1.1.1.3\">&#119864;</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.1.1.1.1.m1.1c\">SE</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx4.T2.1.1.1.1.m1.1d\">italic_S italic_E</annotation></semantics></math>)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T2.2.2.2.2\">Block Sizes (<math alttext=\"BS\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.T2.2.2.2.2.m1.1\"><semantics id=\"Sx4.T2.2.2.2.2.m1.1a\"><mrow id=\"Sx4.T2.2.2.2.2.m1.1.1\" xref=\"Sx4.T2.2.2.2.2.m1.1.1.cmml\"><mi id=\"Sx4.T2.2.2.2.2.m1.1.1.2\" xref=\"Sx4.T2.2.2.2.2.m1.1.1.2.cmml\">B</mi><mo id=\"Sx4.T2.2.2.2.2.m1.1.1.1\" xref=\"Sx4.T2.2.2.2.2.m1.1.1.1.cmml\">&#8290;</mo><mi id=\"Sx4.T2.2.2.2.2.m1.1.1.3\" xref=\"Sx4.T2.2.2.2.2.m1.1.1.3.cmml\">S</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.2.2.2.2.m1.1b\"><apply id=\"Sx4.T2.2.2.2.2.m1.1.1.cmml\" xref=\"Sx4.T2.2.2.2.2.m1.1.1\"><times id=\"Sx4.T2.2.2.2.2.m1.1.1.1.cmml\" xref=\"Sx4.T2.2.2.2.2.m1.1.1.1\"/><ci id=\"Sx4.T2.2.2.2.2.m1.1.1.2.cmml\" xref=\"Sx4.T2.2.2.2.2.m1.1.1.2\">&#119861;</ci><ci id=\"Sx4.T2.2.2.2.2.m1.1.1.3.cmml\" xref=\"Sx4.T2.2.2.2.2.m1.1.1.3\">&#119878;</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.2.2.2.2.m1.1c\">BS</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx4.T2.2.2.2.2.m1.1d\">italic_B italic_S</annotation></semantics></math>)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T2.4.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T2.3.3.3.1\"><math alttext=\"\\text{BitQ}_{16}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.T2.3.3.3.1.m1.1\"><semantics id=\"Sx4.T2.3.3.3.1.m1.1a\"><msub id=\"Sx4.T2.3.3.3.1.m1.1.1\" xref=\"Sx4.T2.3.3.3.1.m1.1.1.cmml\"><mtext id=\"Sx4.T2.3.3.3.1.m1.1.1.2\" xref=\"Sx4.T2.3.3.3.1.m1.1.1.2a.cmml\">BitQ</mtext><mn id=\"Sx4.T2.3.3.3.1.m1.1.1.3\" xref=\"Sx4.T2.3.3.3.1.m1.1.1.3.cmml\">16</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.3.3.3.1.m1.1b\"><apply id=\"Sx4.T2.3.3.3.1.m1.1.1.cmml\" xref=\"Sx4.T2.3.3.3.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"Sx4.T2.3.3.3.1.m1.1.1.1.cmml\" xref=\"Sx4.T2.3.3.3.1.m1.1.1\">subscript</csymbol><ci id=\"Sx4.T2.3.3.3.1.m1.1.1.2a.cmml\" xref=\"Sx4.T2.3.3.3.1.m1.1.1.2\"><mtext id=\"Sx4.T2.3.3.3.1.m1.1.1.2.cmml\" xref=\"Sx4.T2.3.3.3.1.m1.1.1.2\">BitQ</mtext></ci><cn id=\"Sx4.T2.3.3.3.1.m1.1.1.3.cmml\" type=\"integer\" xref=\"Sx4.T2.3.3.3.1.m1.1.1.3\">16</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.3.3.3.1.m1.1c\">\\text{BitQ}_{16}</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx4.T2.3.3.3.1.m1.1d\">BitQ start_POSTSUBSCRIPT 16 end_POSTSUBSCRIPT</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T2.4.4.4.2\"><math alttext=\"\\text{BitQ}_{8}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.T2.4.4.4.2.m1.1\"><semantics id=\"Sx4.T2.4.4.4.2.m1.1a\"><msub id=\"Sx4.T2.4.4.4.2.m1.1.1\" xref=\"Sx4.T2.4.4.4.2.m1.1.1.cmml\"><mtext id=\"Sx4.T2.4.4.4.2.m1.1.1.2\" xref=\"Sx4.T2.4.4.4.2.m1.1.1.2a.cmml\">BitQ</mtext><mn id=\"Sx4.T2.4.4.4.2.m1.1.1.3\" xref=\"Sx4.T2.4.4.4.2.m1.1.1.3.cmml\">8</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.4.4.4.2.m1.1b\"><apply id=\"Sx4.T2.4.4.4.2.m1.1.1.cmml\" xref=\"Sx4.T2.4.4.4.2.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"Sx4.T2.4.4.4.2.m1.1.1.1.cmml\" xref=\"Sx4.T2.4.4.4.2.m1.1.1\">subscript</csymbol><ci id=\"Sx4.T2.4.4.4.2.m1.1.1.2a.cmml\" xref=\"Sx4.T2.4.4.4.2.m1.1.1.2\"><mtext id=\"Sx4.T2.4.4.4.2.m1.1.1.2.cmml\" xref=\"Sx4.T2.4.4.4.2.m1.1.1.2\">BitQ</mtext></ci><cn id=\"Sx4.T2.4.4.4.2.m1.1.1.3.cmml\" type=\"integer\" xref=\"Sx4.T2.4.4.4.2.m1.1.1.3\">8</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.4.4.4.2.m1.1c\">\\text{BitQ}_{8}</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx4.T2.4.4.4.2.m1.1d\">BitQ start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"Sx4.T2.4.4.4.3\" rowspan=\"2\"><span class=\"ltx_text\" id=\"Sx4.T2.4.4.4.3.1\">{1, 2, 4, 8, 16, 24, 32, 48}</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T2.4.4.5.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"Sx4.T2.4.4.5.1.1\">{2, 3, 4, 5, 6, 7}</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"Sx4.T2.4.4.5.1.2\">{2, 3, 4, 5, 6}</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 2:  BFP quantization configuration candidates.",
        "footnotes": [],
        "references": [
            "Our approach includes two versions based on the size of qbsubscript𝑞𝑏q_{b}italic_q start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT,\nnamely BitQ16subscriptBitQ16\\text{BitQ}_{16}BitQ start_POSTSUBSCRIPT 16 end_POSTSUBSCRIPT and BitQ8subscriptBitQ8\\text{BitQ}_{8}BitQ start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT (qb=16subscript𝑞𝑏16q_{b}=16italic_q start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT = 16 and qb=8subscript𝑞𝑏8q_{b}=8italic_q start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT = 8, where qbsubscript𝑞𝑏q_{b}italic_q start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT is the overall bitwidth of data), respectively. The balance factor α𝛼\\alphaitalic_α is set to be 0.2. The search process identifies the optimal configuration from Table 2 of BFP quantization candidates. We utilize a BFP quantizer for quantization-aware training, extending the training by 1,000 steps to compensate for the reduced data expression range due to quantization, following the recommended parameters."
        ]
    },
    "Sx4.T3.2.2": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"Sx4.T3.2.2\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.3.1\">\n<td class=\"ltx_td ltx_border_r ltx_border_tt\" id=\"Sx4.T3.2.2.3.1.1\"/>\n<td class=\"ltx_td ltx_border_r ltx_border_tt\" id=\"Sx4.T3.2.2.3.1.2\"/>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_tt\" id=\"Sx4.T3.2.2.3.1.3\"/>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_tt\" id=\"Sx4.T3.2.2.3.1.4\">32-bit</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_tt\" colspan=\"3\" id=\"Sx4.T3.2.2.3.1.5\">16-bit</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_tt\" colspan=\"3\" id=\"Sx4.T3.2.2.3.1.6\">8-bit</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.2.3\"><span class=\"ltx_text\" id=\"Sx4.T3.2.2.2.3.1\">Task</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.2.4\"><span class=\"ltx_text\" id=\"Sx4.T3.2.2.2.4.1\">Metric</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.2.5\"><span class=\"ltx_text\" id=\"Sx4.T3.2.2.2.5.1\">Model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.2.6\">Original</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.2.7\">DBPS</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.2.8\">FlexB</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T3.1.1.1.1\"><math alttext=\"\\text{BitQ}_{16}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.T3.1.1.1.1.m1.1\"><semantics id=\"Sx4.T3.1.1.1.1.m1.1a\"><msub id=\"Sx4.T3.1.1.1.1.m1.1.1\" xref=\"Sx4.T3.1.1.1.1.m1.1.1.cmml\"><mtext id=\"Sx4.T3.1.1.1.1.m1.1.1.2\" xref=\"Sx4.T3.1.1.1.1.m1.1.1.2a.cmml\">BitQ</mtext><mn id=\"Sx4.T3.1.1.1.1.m1.1.1.3\" xref=\"Sx4.T3.1.1.1.1.m1.1.1.3.cmml\">16</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T3.1.1.1.1.m1.1b\"><apply id=\"Sx4.T3.1.1.1.1.m1.1.1.cmml\" xref=\"Sx4.T3.1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"Sx4.T3.1.1.1.1.m1.1.1.1.cmml\" xref=\"Sx4.T3.1.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"Sx4.T3.1.1.1.1.m1.1.1.2a.cmml\" xref=\"Sx4.T3.1.1.1.1.m1.1.1.2\"><mtext id=\"Sx4.T3.1.1.1.1.m1.1.1.2.cmml\" xref=\"Sx4.T3.1.1.1.1.m1.1.1.2\">BitQ</mtext></ci><cn id=\"Sx4.T3.1.1.1.1.m1.1.1.3.cmml\" type=\"integer\" xref=\"Sx4.T3.1.1.1.1.m1.1.1.3\">16</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T3.1.1.1.1.m1.1c\">\\text{BitQ}_{16}</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx4.T3.1.1.1.1.m1.1d\">BitQ start_POSTSUBSCRIPT 16 end_POSTSUBSCRIPT</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.2.9\">FAST</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.2.10\">BSFP</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.2.2\"><math alttext=\"\\text{BitQ}_{8}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.T3.2.2.2.2.m1.1\"><semantics id=\"Sx4.T3.2.2.2.2.m1.1a\"><msub id=\"Sx4.T3.2.2.2.2.m1.1.1\" xref=\"Sx4.T3.2.2.2.2.m1.1.1.cmml\"><mtext id=\"Sx4.T3.2.2.2.2.m1.1.1.2\" xref=\"Sx4.T3.2.2.2.2.m1.1.1.2a.cmml\">BitQ</mtext><mn id=\"Sx4.T3.2.2.2.2.m1.1.1.3\" xref=\"Sx4.T3.2.2.2.2.m1.1.1.3.cmml\">8</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T3.2.2.2.2.m1.1b\"><apply id=\"Sx4.T3.2.2.2.2.m1.1.1.cmml\" xref=\"Sx4.T3.2.2.2.2.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"Sx4.T3.2.2.2.2.m1.1.1.1.cmml\" xref=\"Sx4.T3.2.2.2.2.m1.1.1\">subscript</csymbol><ci id=\"Sx4.T3.2.2.2.2.m1.1.1.2a.cmml\" xref=\"Sx4.T3.2.2.2.2.m1.1.1.2\"><mtext id=\"Sx4.T3.2.2.2.2.m1.1.1.2.cmml\" xref=\"Sx4.T3.2.2.2.2.m1.1.1.2\">BitQ</mtext></ci><cn id=\"Sx4.T3.2.2.2.2.m1.1.1.3.cmml\" type=\"integer\" xref=\"Sx4.T3.2.2.2.2.m1.1.1.3\">8</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T3.2.2.2.2.m1.1c\">\\text{BitQ}_{8}</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx4.T3.2.2.2.2.m1.1d\">BitQ start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.4.2\">\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.4.2.1\"/>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.4.2.2\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.4.2.3\">GoogLeNet</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.4.2.4\">67.79%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.4.2.5\">66.71%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.4.2.6\">66.58%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.4.2.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.4.2.7.1\">67.49%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.4.2.8\">66.31%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.4.2.9\">66.54%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.4.2.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.4.2.10.1\">66.58%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.5.3\">\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.5.3.1\"/>\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.5.3.2\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.5.3.3\">ResNet-18</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Sx4.T3.2.2.5.3.4\">69.70%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.5.3.5\">68.42%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.5.3.6\">68.29%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.5.3.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.5.3.7.1\">69.83%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.5.3.8\">68.52%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.5.3.9\">69.67%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.5.3.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.5.3.10.1\">69.71%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.6.4\">\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.6.4.1\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.6.4.2\">Top-1 Acc.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.6.4.3\">ECA-MobV2</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Sx4.T3.2.2.6.4.4\">72.56%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.6.4.5\">68.93%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.6.4.6\">70.25%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.6.4.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.6.4.7.1\">70.85%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.6.4.8\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.6.4.8.1\">70.15%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.6.4.9\">69.63%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.6.4.10\">69.85%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.7.5\">\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.7.5.1\"/>\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.7.5.2\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.7.5.3\">ConvNeXt-L</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Sx4.T3.2.2.7.5.4\">85.82%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.7.5.5\">83.85%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.7.5.6\">83.87%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.7.5.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.7.5.7.1\">84.31%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.7.5.8\">83.82%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.7.5.9\">84.18%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.7.5.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.7.5.10.1\">84.26%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.8.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.8.6.1\"><span class=\"ltx_text\" id=\"Sx4.T3.2.2.8.6.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"Sx4.T3.2.2.8.6.1.1.1\">\n<span class=\"ltx_tr\" id=\"Sx4.T3.2.2.8.6.1.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Sx4.T3.2.2.8.6.1.1.1.1.1\">Image</span></span>\n<span class=\"ltx_tr\" id=\"Sx4.T3.2.2.8.6.1.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Sx4.T3.2.2.8.6.1.1.1.2.1\">Classification</span></span>\n</span></span></td>\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.8.6.2\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.8.6.3\">Gmean_C</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Sx4.T3.2.2.8.6.4\">73.65%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.8.6.5\">71.67%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.8.6.6\">71.94%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.8.6.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.8.6.7.1\">72.84%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.8.6.8\">71.89%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.8.6.9\">72.20%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.8.6.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.8.6.10.1\">72.29%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.9.7\">\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.9.7.1\"/>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.9.7.2\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.9.7.3\">YOLOv8</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.9.7.4\">37.30%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.9.7.5\">36.71%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.9.7.6\">36.28%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.9.7.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.9.7.7.1\">36.78%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.9.7.8\">36.36%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.9.7.9\">36.47%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.9.7.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.9.7.10.1\">36.50%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.10.8\">\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.10.8.1\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.10.8.2\">Box AP</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.10.8.3\">ONE-PEACE</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Sx4.T3.2.2.10.8.4\">60.40%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.10.8.5\">59.47%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.10.8.6\">59.34%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.10.8.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.10.8.7.1\">60.14%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.10.8.8\">59.27%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.10.8.9\">59.23%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.10.8.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.10.8.10.1\">59.35%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.11.9\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.11.9.1\"><span class=\"ltx_text\" id=\"Sx4.T3.2.2.11.9.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"Sx4.T3.2.2.11.9.1.1.1\">\n<span class=\"ltx_tr\" id=\"Sx4.T3.2.2.11.9.1.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Sx4.T3.2.2.11.9.1.1.1.1.1\">Object</span></span>\n<span class=\"ltx_tr\" id=\"Sx4.T3.2.2.11.9.1.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Sx4.T3.2.2.11.9.1.1.1.2.1\">Detection</span></span>\n</span></span></td>\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.11.9.2\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.11.9.3\">Gmean_O</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Sx4.T3.2.2.11.9.4\">47.46%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.11.9.5\">46.72%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.11.9.6\">46.40%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.11.9.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.11.9.7.1\">47.03%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.11.9.8\">46.42%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.11.9.9\">46.48%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.11.9.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.11.9.10.1\">46.54%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.12.10\">\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.12.10.1\"/>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.12.10.2\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.12.10.3\">YOLOv8</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.12.10.4\">30.50%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.12.10.5\">30.03%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.12.10.6\">29.99%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.12.10.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.12.10.7.1\">30.19%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.12.10.8\">29.76%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.12.10.9\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.12.10.9.1\">29.88%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.12.10.10\">29.86%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.13.11\">\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.13.11.1\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.13.11.2\">Mask AP</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.13.11.3\">MaskDINO</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Sx4.T3.2.2.13.11.4\">46.30%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.13.11.5\">46.28%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.13.11.6\">46.30%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.13.11.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.13.11.7.1\">46.31%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.13.11.8\">45.72%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.13.11.9\">45.88%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.13.11.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.13.11.10.1\">45.99%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.14.12\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.14.12.1\"><span class=\"ltx_text\" id=\"Sx4.T3.2.2.14.12.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"Sx4.T3.2.2.14.12.1.1.1\">\n<span class=\"ltx_tr\" id=\"Sx4.T3.2.2.14.12.1.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Sx4.T3.2.2.14.12.1.1.1.1.1\">Instance</span></span>\n<span class=\"ltx_tr\" id=\"Sx4.T3.2.2.14.12.1.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Sx4.T3.2.2.14.12.1.1.1.2.1\">Segmentation</span></span>\n</span></span></td>\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.14.12.2\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.14.12.3\">Gmean_I</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Sx4.T3.2.2.14.12.4\">37.58%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.14.12.5\">37.28%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.14.12.6\">37.26%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.14.12.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.14.12.7.1\">37.39%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.14.12.8\">36.89%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.14.12.9\">37.03%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.14.12.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.14.12.10.1\">37.06%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.15.13\">\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.15.13.1\"/>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.15.13.2\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.15.13.3\">MaskDINO</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.15.13.4\">48.73%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.15.13.5\">48.28%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.15.13.6\">48.13%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T3.2.2.15.13.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.15.13.7.1\">48.37%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.15.13.8\">48.26%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.15.13.9\">48.15%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T3.2.2.15.13.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.15.13.10.1\">48.34%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.16.14\">\n<td class=\"ltx_td ltx_border_r\" id=\"Sx4.T3.2.2.16.14.1\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.16.14.2\">mIoU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.16.14.3\">ONE-PEACE</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Sx4.T3.2.2.16.14.4\">62.27%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.16.14.5\">61.27%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.16.14.6\">61.36%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T3.2.2.16.14.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.16.14.7.1\">61.42%</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.16.14.8\">60.34%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.16.14.9\">60.37%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T3.2.2.16.14.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.16.14.10.1\">60.91%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T3.2.2.17.15\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"Sx4.T3.2.2.17.15.1\"><span class=\"ltx_text\" id=\"Sx4.T3.2.2.17.15.1.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"Sx4.T3.2.2.17.15.1.1.1\">\n<span class=\"ltx_tr\" id=\"Sx4.T3.2.2.17.15.1.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Sx4.T3.2.2.17.15.1.1.1.1.1\">Semantic</span></span>\n<span class=\"ltx_tr\" id=\"Sx4.T3.2.2.17.15.1.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Sx4.T3.2.2.17.15.1.1.1.2.1\">Segmentation</span></span>\n</span></span></td>\n<td class=\"ltx_td ltx_border_bb ltx_border_r\" id=\"Sx4.T3.2.2.17.15.2\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"Sx4.T3.2.2.17.15.3\">Gmean_S</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" id=\"Sx4.T3.2.2.17.15.4\">55.09%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx4.T3.2.2.17.15.5\">54.39%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx4.T3.2.2.17.15.6\">54.34%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"Sx4.T3.2.2.17.15.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.17.15.7.1\">54.51%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx4.T3.2.2.17.15.8\">53.96%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx4.T3.2.2.17.15.9\">53.91%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx4.T3.2.2.17.15.10\"><span class=\"ltx_text ltx_font_bold\" id=\"Sx4.T3.2.2.17.15.10.1\">54.26%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 3:  Validation accuracy metrics. Gmean_C, Gmean_O, Gmean_I, and Gmean_S identify the geometric mean of different models in image classification, object detection, instance segmentation, and semantic segmentation tasks, respectively. The bold data indicate the best value under 16-bit and 8-bit bitwidth settings.",
        "footnotes": [
            "Wang et al. (2020) \nWang, Q.; Wu, B.; Zhu, P.; Li, P.; Zuo, W.; and Hu, Q. 2020.\n\n ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks.\n\n In  2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 11531–11539.\n\n",
            "Noh et al. (2023) \nNoh, S.-H.; Koo, J.; Lee, S.; Park, J.; and Kung, J. 2023.\n\n FlexBlock: A flexible DNN training accelerator with multi-mode block floating point support.\n\n IEEE Transactions on Computers .\n\n"
        ],
        "references": [
            "Table 3 lists the accuracy result. The proposed BitQ16subscriptBitQ16\\text{BitQ}_{16}BitQ start_POSTSUBSCRIPT 16 end_POSTSUBSCRIPT and BitQ8subscriptBitQ8\\text{BitQ}_{8}BitQ start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT show superior performance, winning all 14 and 12 out of 14 comparisons in the 16-bit and 8-bit bitwidth settings, respectively.\nUpon analyzing the baselines, we observe that DBPS (Lee et al. 2023) and FlexBlock (Noh et al. 2023) accelerate the training convergence by utilizing dynamic block sizes. However, since the final block sizes are empirically determined, the training convergence does not necessarily translate to optimal inference performance. FAST (Zhang et al. 2022) employs Stochastic Rounding to implement dynamic training for Transformers, which leads to improved accuracy in some Transformer-based models. The criterion-optimal quantization flow of BSFP (Lo et al. 2023) explores the quantization parameter space only partially, as the exhaustive search would be computationally prohibitive."
        ]
    },
    "Sx4.T4.1.1": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"Sx4.T4.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"Sx4.T4.1.1.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"Sx4.T4.1.1.2.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"Sx4.T4.1.1.2.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"2\" id=\"Sx4.T4.1.1.2.1.2\">16-bit</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"Sx4.T4.1.1.2.1.3\">8-bit</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T4.1.1.3.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"Sx4.T4.1.1.3.2.1\">Acc.</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"Sx4.T4.1.1.3.2.2\">Eng.</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"Sx4.T4.1.1.3.2.3\">Acc.</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"Sx4.T4.1.1.3.2.4\">Eng.</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Sx4.T4.1.1.4.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"Sx4.T4.1.1.4.1.1\">BitQ</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T4.1.1.4.1.2\">69.83%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Sx4.T4.1.1.4.1.3\">0.143J</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T4.1.1.4.1.4\">69.71%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Sx4.T4.1.1.4.1.5\">0.119J</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T4.1.1.5.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"Sx4.T4.1.1.5.2.1\">w/o QAT</th>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T4.1.1.5.2.2\">66.82%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T4.1.1.5.2.3\">0.121J</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T4.1.1.5.2.4\">31.74%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T4.1.1.5.2.5\">0.066J</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T4.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"Sx4.T4.1.1.1.1\">w/o <math alttext=\"DM\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.T4.1.1.1.1.m1.1\"><semantics id=\"Sx4.T4.1.1.1.1.m1.1a\"><mrow id=\"Sx4.T4.1.1.1.1.m1.1.1\" xref=\"Sx4.T4.1.1.1.1.m1.1.1.cmml\"><mi id=\"Sx4.T4.1.1.1.1.m1.1.1.2\" xref=\"Sx4.T4.1.1.1.1.m1.1.1.2.cmml\">D</mi><mo id=\"Sx4.T4.1.1.1.1.m1.1.1.1\" xref=\"Sx4.T4.1.1.1.1.m1.1.1.1.cmml\">&#8290;</mo><mi id=\"Sx4.T4.1.1.1.1.m1.1.1.3\" xref=\"Sx4.T4.1.1.1.1.m1.1.1.3.cmml\">M</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T4.1.1.1.1.m1.1b\"><apply id=\"Sx4.T4.1.1.1.1.m1.1.1.cmml\" xref=\"Sx4.T4.1.1.1.1.m1.1.1\"><times id=\"Sx4.T4.1.1.1.1.m1.1.1.1.cmml\" xref=\"Sx4.T4.1.1.1.1.m1.1.1.1\"/><ci id=\"Sx4.T4.1.1.1.1.m1.1.1.2.cmml\" xref=\"Sx4.T4.1.1.1.1.m1.1.1.2\">&#119863;</ci><ci id=\"Sx4.T4.1.1.1.1.m1.1.1.3.cmml\" xref=\"Sx4.T4.1.1.1.1.m1.1.1.3\">&#119872;</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T4.1.1.1.1.m1.1c\">DM</annotation><annotation encoding=\"application/x-llamapun\" id=\"Sx4.T4.1.1.1.1.m1.1d\">italic_D italic_M</annotation></semantics></math> Expression</th>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T4.1.1.1.2\">69.84%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Sx4.T4.1.1.1.3\">0.197J</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T4.1.1.1.4\">69.73%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Sx4.T4.1.1.1.5\">0.142J</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Sx4.T4.1.1.6.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"Sx4.T4.1.1.6.3.1\">w/o Trade-off</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx4.T4.1.1.6.3.2\">69.43%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"Sx4.T4.1.1.6.3.3\">0.175J</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx4.T4.1.1.6.3.4\">68.84%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Sx4.T4.1.1.6.3.5\">0.136J</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 4:  Ablation results of BitQ on ResNet-18. ",
        "footnotes": [],
        "references": [
            "To further validate the effectiveness of BitQ, we conduct ablation analysis. Since BitQ consists of three components, we perform ablations on each module individually. The specific results are shown in Table 4. In the w/o QAT method, we omit quantization-aware training, selecting quantization parameters solely based on D⁢M𝐷𝑀DMitalic_D italic_M size. This results in suboptimal accuracy but minimizes energy consumption. Conversely, in the w/o D⁢M𝐷𝑀DMitalic_D italic_M Expression method, we exclude data movement simulation during inference, leading to quantization parameters chosen solely for accuracy. While this method achieves optimal accuracy, it increases energy consumption. In the w/o Trade-off method, we independently consider accuracy loss and performance loss, using a Pareto optimal solution for parameter configuration. This method often fails to balance the two, resulting in suboptimal outcomes. Across all ablation settings, the BitQ algorithm consistently yields superior results."
        ]
    }
}