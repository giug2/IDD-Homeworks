{
    "id_table_1": {
        "caption": "Table 1:  Statistics about the  PropaGaze  dataset.",
        "table": "S3.T1.1.1",
        "footnotes": [],
        "references": [
            "We introduce  PropaInsight , a new conceptual framework for comprehensive propaganda analysis. In contrast to previous methods which ignore the underlying purposes and only focus on techniques,  PropaInsight  delves into the more subtle and hidden elements of propaganda. Drawing from foundational social science research on propaganda  Nelson ( 1997 ); Jowett and Odonnell ( 2018 ); Ellul ( 2021 ) , we identify three key elements of each propaganda attempt:  propaganda techniques ,  arousal appeals , and  underlying intent . As shown in Figure  1 , for a given article, we first identify and classify the techniques used. We then infer the arousal appeals these techniques evoke, and we further deduce the underlying intent of the article. To ensure interpretability and consistency, we consolidate these elements into a clear, structured natural language paragraph using a descriptive template, as shown in Figure  1 . Below, we provide a detailed explanation of each element of our proposed framework.",
            "PTC-Gaze  builds on the existing PTC dataset  Martino et al. ( 2020a ) , which includes human-written news articles annotated for propaganda techniques and spans. We reannotate this dataset by hiring human annotators to label appeals and intent independently. For appeals, annotators review propaganda-containing sentences along with their context and describe the feelings evoked. To reduce cognitive load, we provide GPT-4 generated candidate annotations for assistance. Annotators then evaluate whether the generated candidates accurately reflect their interpretations and reactions, and if not, they rewrite the descriptions based on the template in   2  and Appendix  C . For intent, annotators read the full article and infer its underlying intent in a single free-form sentence, and we leave the multi-intent scenarios for future work.As shown in Table  1 , this annotated sub-dataset contains 79 articles, with an average of 12.77 propaganda techniques per article. Additional information, data examples, and analysis of the annotation quality are given in Appendix  D .",
            "As illustrated in Table  1 ,  RUWA-Gaze  consists of 497 articles, and  Politifact-Gaze  consists of 593 articles. While we generated moderate data due to the computational cost. We believe the data generation pipeline is generalizable. The language models can be replaced with cheaper or open-source LLMs to reduce costs and, in turn, generate larger-scale datasets. In addition, we identify that these two subsets come from different domains (Military & War and Politics), and they differ significantly in both content and the use of propaganda techniques.",
            "We acknowledge the discrepancy between the synthetic sub-datasets and the human-annotated sub-dataset in  PropaGaze . As shown in Table  1 , the average number of propaganda techniques per article in  PTC-Gaze  is 12.77, which is about 3.7 times higher than in the synthetic  RUWA-Gaze  and  Politifact-Gaze . This occurs due to the way we generate the synthetic data, where we inject three propaganda techniques per article, with GPT-4-Turbo sometimes reusing techniques. However, we believe this is less of an issue, as  PTC-Gaze  articles are on average 3.3 times longer than those in the other sub-datasets. Moreover, since we treat the injected techniques as silver labels, we have not yet checked whether other sentences in the articles also use propaganda techniques. See the Limitations section for more details. Finally, we note the inherent difference in writing styles between synthetic and human-written articles, which is a common challenge with synthetic datasets."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Model performance on the propaganda technique identification sub-task under different training data settings. We report the performance of trained MGNN model and both k-shot ( k  s k s ks italic_k italic_s ) and fine-tuned ( f  t f t ft italic_f italic_t ) LLMs.",
        "table": "S4.T2.7.7",
        "footnotes": [],
        "references": [
            "PTC-Gaze  builds on the existing PTC dataset  Martino et al. ( 2020a ) , which includes human-written news articles annotated for propaganda techniques and spans. We reannotate this dataset by hiring human annotators to label appeals and intent independently. For appeals, annotators review propaganda-containing sentences along with their context and describe the feelings evoked. To reduce cognitive load, we provide GPT-4 generated candidate annotations for assistance. Annotators then evaluate whether the generated candidates accurately reflect their interpretations and reactions, and if not, they rewrite the descriptions based on the template in   2  and Appendix  C . For intent, annotators read the full article and infer its underlying intent in a single free-form sentence, and we leave the multi-intent scenarios for future work.As shown in Table  1 , this annotated sub-dataset contains 79 articles, with an average of 12.77 propaganda techniques per article. Additional information, data examples, and analysis of the annotation quality are given in Appendix  D .",
            "We construct  RUWA-Gaze  and  Politifact-Gaze  using a partially controlled data generation pipeline, as illustrated in Figure  2 . Specifically,  RUWA-Gaze  is built upon a dataset of real-world news articles focused on the Russia-Ukraine War  Khairova et al. ( 2023 ) , while  Politifact-Gaze  is constructed using the PolitiFact partition of the FakeNewsNet dataset  Shu et al. ( 2020 ) .",
            "Figure  2  shows the data creation pipeline. Initially, we use GPT-3.5 to summarize human-written, published news articles and to identify key events and objective facts. These summaries are intended to be objective, as the original articles may reflect various biases that could influence the creation of new propaganda pieces. Following this, we use GPT-3.5 to extract all focal entities involved in the events. We then randomly select one entitys perspective and set an intent to guide the revision of the article. We also randomly choose a set of propaganda techniques to be inserted into the article, reshaping its narrative.",
            "As outlined in   2 ,  PropaInsight  makes it possible to break the propaganda analysis task into three sub-tasks to ensure detailed evaluation and capture key elements:",
            "As shown in Tables  2  and  3 ,  zero-shot LLMs struggle with propaganda analysis . For example, in identifying propaganda techniques, zero-shot GPT-4-Turbo underperforms compared to the trained MGNN, even in data-sparse conditions, despite MGNN being much smaller in size. Zero-shot LLMs often struggle to pinpoint sentences containing propaganda. Similarly, in appeal analysis, zero-shot GPT-4-Turbo achieves relatively low BertScores. However, these models perform better at inferring intent, as shown by their stronger performance in the intent analysis sub-task (Table  3 ).",
            "PropaGaze  substantially improves the overall propaganda analysis performance , especially in identifying propaganda techniques, under both data-sparse and data-rich training conditions. In the data-sparse setting, fine-tuned LLaMA-7B-Chat outperforms one-shot GPT-4-Turbo, achieving an average of 65.8% higher text span IoU and 33.7% higher technique identification F1 score, as shown in Table  2 . In the data-rich setting, the performance increases even further, with LLaMA-7B-Chat showing 90.9% higher text span IoU and 125.1% higher F1 score compared to the data-sparse results.Table  3  shows similar improvements in appeals and intent analysis. For the appeals sub-task, data-rich fine-tuning leads to an average 70.1% increase in BertScore, while for intent analysis there is a smaller 8.5% gain compared to data-sparse training. This is likely due to the already high baseline performance. These results demonstrate that the synthetic sub-datasets effectively complement the limited human-annotated data, significantly improving the models performance in analyzing propaganda elements.",
            "We list the closed set of propaganda techniques that are used in the paper in Table  6 . We also included the full template that we used to describe appeals and intent. Note that (1) The set of propaganda techniques included here can be freely extended with any other techniques. (2) We made the templates for Appeals and intent with a valid rationale, as detailed in Section  2 . However, we are not claiming that this is the optimal template design among all other possible designs. We believe that prompt engineering and further human assessment are necessary for discovering the optimal template for this task. And we leave this part for future work.",
            "We provide an analysis of the annotation quality of our  PTC-Gaze  dataset. We used Label Studio for design the annotation interface. We present the user interface design of the intent annotation and appeal annotation tasks in Figure  3  and Figure  4 . Two professional annotators from Kitware.Inc is in charge of the annotation task. Annotators choose to utilize the candidate annotation generated by GPT-4 under 59.8% annotated intent data points and 75.1% annotated appeal data points. This demonstrates the high quality of GPT4-provided annotation in terms of appeals and intent, further enhanced our points in   5.2 .",
            "As discussed in   5.2 , we find that the bottleneck of propaganda analysis lies in identifying the correct propagandistic sentences. In this section, we give a case study on LLMs doing propaganda analysis to explain the cause further."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Model performance on appeal and intent analysis sub-tasks under different training data settings. We report the performance of zero-shot ( 0  s 0 s 0s 0 italic_s ) and fine-tuned ( f  t f t ft italic_f italic_t ) LLMs.",
        "table": "S4.T3.6.6",
        "footnotes": [],
        "references": [
            "In real-world scenarios, obtaining a large volume of well-annotated data for analyzing propaganda is challenging, as discussed in   3 . To simulate this limitation, we use both data-rich and data-sparse environments to evaluate the impact of larger, generalized synthetic datasets on model performance.",
            "As shown in Tables  2  and  3 ,  zero-shot LLMs struggle with propaganda analysis . For example, in identifying propaganda techniques, zero-shot GPT-4-Turbo underperforms compared to the trained MGNN, even in data-sparse conditions, despite MGNN being much smaller in size. Zero-shot LLMs often struggle to pinpoint sentences containing propaganda. Similarly, in appeal analysis, zero-shot GPT-4-Turbo achieves relatively low BertScores. However, these models perform better at inferring intent, as shown by their stronger performance in the intent analysis sub-task (Table  3 ).",
            "PropaGaze  substantially improves the overall propaganda analysis performance , especially in identifying propaganda techniques, under both data-sparse and data-rich training conditions. In the data-sparse setting, fine-tuned LLaMA-7B-Chat outperforms one-shot GPT-4-Turbo, achieving an average of 65.8% higher text span IoU and 33.7% higher technique identification F1 score, as shown in Table  2 . In the data-rich setting, the performance increases even further, with LLaMA-7B-Chat showing 90.9% higher text span IoU and 125.1% higher F1 score compared to the data-sparse results.Table  3  shows similar improvements in appeals and intent analysis. For the appeals sub-task, data-rich fine-tuning leads to an average 70.1% increase in BertScore, while for intent analysis there is a smaller 8.5% gain compared to data-sparse training. This is likely due to the already high baseline performance. These results demonstrate that the synthetic sub-datasets effectively complement the limited human-annotated data, significantly improving the models performance in analyzing propaganda elements.",
            "As outlined in   3 , our dataset consists of three subsets:  RUWA-Gaze  (military and war),  Politifact-Gaze  (politics), and  PTC-Gaze  (general news). To explore cross-domain transferability, we perform additional training on each target sub-dataset using data from the other two sub-datasets after the in-domain training. For instance, in a data-sparse scenario, if  RUWA-Gaze  is the target, cross-domain training on  Politifact-Gaze  involves first training the model on the sparse  RUWA-Gaze  data, followed by further training with sparse  Politifact-Gaze  data. In a data-rich scenario, the model is trained on the full in-domain  RUWA-Gaze  data, then further trained on the entire  Politifact-Gaze  dataset. The results are presented in Tables  4  and  5 .",
            "As introduced in Section   3 , the  PropaGaze  dataset comprises three subsets:  RUWA-Gaze ,  Politifact-Gaze , and  PTC-Gaze . More details and data examples are provided in this section.",
            "We provide an analysis of the annotation quality of our  PTC-Gaze  dataset. We used Label Studio for design the annotation interface. We present the user interface design of the intent annotation and appeal annotation tasks in Figure  3  and Figure  4 . Two professional annotators from Kitware.Inc is in charge of the annotation task. Annotators choose to utilize the candidate annotation generated by GPT-4 under 59.8% annotated intent data points and 75.1% annotated appeal data points. This demonstrates the high quality of GPT4-provided annotation in terms of appeals and intent, further enhanced our points in   5.2 ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Model performance ( data-sparse  | | | |  data-rich ) on the propaganda techniques identification sub-task under cross-domain training. The  best result  and  runner-up result  are highlighted per column for the data-sparse and data-rich settings, respectively. Diagonal cells show in-domain training only, without cross-domain training, and are included for reference.",
        "table": "S4.T4.45.45",
        "footnotes": [],
        "references": [
            "As outlined in   3 , our dataset consists of three subsets:  RUWA-Gaze  (military and war),  Politifact-Gaze  (politics), and  PTC-Gaze  (general news). To explore cross-domain transferability, we perform additional training on each target sub-dataset using data from the other two sub-datasets after the in-domain training. For instance, in a data-sparse scenario, if  RUWA-Gaze  is the target, cross-domain training on  Politifact-Gaze  involves first training the model on the sparse  RUWA-Gaze  data, followed by further training with sparse  Politifact-Gaze  data. In a data-rich scenario, the model is trained on the full in-domain  RUWA-Gaze  data, then further trained on the entire  Politifact-Gaze  dataset. The results are presented in Tables  4  and  5 .",
            "In data-sparse settings, we observe that models benefit substantially from incorporating cross-domain data. As shown in Table  4 , when evaluated on  RUWA-Gaze , models trained on additional data from  Politifact-Gaze  and  PTC-Gaze  achieve higher performance than those trained solely on sparse in-domain data. Specifically, LLaMA-7B-Chat fine-tuned with additional  Politifact-Gaze  data achieves the highest text span IoU of 0.271, while MGNN trained with additional  Politifact-Gaze  data reaches the highest technique F1 score of 0.281. This pattern is consistent across other sub-datasets and holds true for appeal analysis as well, as shown in Table  5 . This is expected, as models trained in data-sparse conditions tend to benefit from cross-domain data due to the need for a larger pool of training examples. Access to additional data from related domains enables models to learn generalized patterns of propaganda usage more effectively, leading to improved performance even on tasks outside of their original training domain.",
            "However, in data-rich scenarios, the benefit of cross-domain training diminishes. For example, as shown in Table  4 , models trained on additional  Politifact-Gaze  data underperform those trained solely on in-domain data when evaluated on  RUWA-Gaze . Similarly, when evaluated on  Politifact-Gaze , adding  RUWA-Gaze  data sometimes leads to performance improvements, but the gains are relatively small. This holds for appeal analysis as well, as we can see in Table  5 . These results suggest that  when there is sufficient training data, the quality of the data has a greater impact on performance than its quantity . We further observe that training on both  RUWA-Gaze  and  Politifact-Gaze  improves the performance on the human-annotated  PTC-Gaze  across all sub-tasks. While this is partly due to the data-sparse nature of  PTC-Gaze , making extra training samples valuable, it also highlights that our synthetic data effectively complements the limited human-annotated data.",
            "We provide an analysis of the annotation quality of our  PTC-Gaze  dataset. We used Label Studio for design the annotation interface. We present the user interface design of the intent annotation and appeal annotation tasks in Figure  3  and Figure  4 . Two professional annotators from Kitware.Inc is in charge of the annotation task. Annotators choose to utilize the candidate annotation generated by GPT-4 under 59.8% annotated intent data points and 75.1% annotated appeal data points. This demonstrates the high quality of GPT4-provided annotation in terms of appeals and intent, further enhanced our points in   5.2 ."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Fine-tuned Llama-7B-Chat model performance ( data-sparse  | | | |  data-rich ) on the appeals and intent analysis sub-tasks under cross-domain training. The  best result  and  runner-up result  are highlighted per column for the data-sparse and data-rich settings, respectively. Diagonal cells show in-domain training only, without cross-domain training, and are included for reference.",
        "table": "S4.T5.20.20",
        "footnotes": [],
        "references": [
            "As outlined in   3 , our dataset consists of three subsets:  RUWA-Gaze  (military and war),  Politifact-Gaze  (politics), and  PTC-Gaze  (general news). To explore cross-domain transferability, we perform additional training on each target sub-dataset using data from the other two sub-datasets after the in-domain training. For instance, in a data-sparse scenario, if  RUWA-Gaze  is the target, cross-domain training on  Politifact-Gaze  involves first training the model on the sparse  RUWA-Gaze  data, followed by further training with sparse  Politifact-Gaze  data. In a data-rich scenario, the model is trained on the full in-domain  RUWA-Gaze  data, then further trained on the entire  Politifact-Gaze  dataset. The results are presented in Tables  4  and  5 .",
            "In data-sparse settings, we observe that models benefit substantially from incorporating cross-domain data. As shown in Table  4 , when evaluated on  RUWA-Gaze , models trained on additional data from  Politifact-Gaze  and  PTC-Gaze  achieve higher performance than those trained solely on sparse in-domain data. Specifically, LLaMA-7B-Chat fine-tuned with additional  Politifact-Gaze  data achieves the highest text span IoU of 0.271, while MGNN trained with additional  Politifact-Gaze  data reaches the highest technique F1 score of 0.281. This pattern is consistent across other sub-datasets and holds true for appeal analysis as well, as shown in Table  5 . This is expected, as models trained in data-sparse conditions tend to benefit from cross-domain data due to the need for a larger pool of training examples. Access to additional data from related domains enables models to learn generalized patterns of propaganda usage more effectively, leading to improved performance even on tasks outside of their original training domain.",
            "However, in data-rich scenarios, the benefit of cross-domain training diminishes. For example, as shown in Table  4 , models trained on additional  Politifact-Gaze  data underperform those trained solely on in-domain data when evaluated on  RUWA-Gaze . Similarly, when evaluated on  Politifact-Gaze , adding  RUWA-Gaze  data sometimes leads to performance improvements, but the gains are relatively small. This holds for appeal analysis as well, as we can see in Table  5 . These results suggest that  when there is sufficient training data, the quality of the data has a greater impact on performance than its quantity . We further observe that training on both  RUWA-Gaze  and  Politifact-Gaze  improves the performance on the human-annotated  PTC-Gaze  across all sub-tasks. While this is partly due to the data-sparse nature of  PTC-Gaze , making extra training samples valuable, it also highlights that our synthetic data effectively complements the limited human-annotated data.",
            "We provide an analysis of the annotation quality of our  PTC-Gaze  dataset. We used Label Studio for design the annotation interface. We present the user interface design of the intent annotation and appeal annotation tasks in Figure  3  and Figure  4 . Two professional annotators from Kitware.Inc is in charge of the annotation task. Annotators choose to utilize the candidate annotation generated by GPT-4 under 59.8% annotated intent data points and 75.1% annotated appeal data points. This demonstrates the high quality of GPT4-provided annotation in terms of appeals and intent, further enhanced our points in   5.2 .",
            "As discussed in   5.2 , we find that the bottleneck of propaganda analysis lies in identifying the correct propagandistic sentences. In this section, we give a case study on LLMs doing propaganda analysis to explain the cause further."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  The complete formulation for each component during propaganda analysis. The parts marked by [] indicates the allowance for free generation.",
        "table": "A1.T6.1",
        "footnotes": [],
        "references": [
            "We list the closed set of propaganda techniques that are used in the paper in Table  6 . We also included the full template that we used to describe appeals and intent. Note that (1) The set of propaganda techniques included here can be freely extended with any other techniques. (2) We made the templates for Appeals and intent with a valid rationale, as detailed in Section  2 . However, we are not claiming that this is the optimal template design among all other possible designs. We believe that prompt engineering and further human assessment are necessary for discovering the optimal template for this task. And we leave this part for future work."
        ]
    }
}