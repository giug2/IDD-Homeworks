{
    "id_table_1": {
        "caption": "Table 1:  Summary of main symbols and notations",
        "table": "S3.T1.8.8",
        "footnotes": [],
        "references": [
            "As shown in Figure  1 , we approach the issue of retrieval quality from the perspective of data quality.  Specifically, inspired by Matching Dependencies(MDs), a classical rule-based data quality management method in the database community  Fan et al. ( 2011 ) , we propose  Context Matching Dependencies (CMDs)  that capture and regulate the consistency between the knowledge context and its vector representation.  Then we establish a  Context-Driven Index Trimming (CDIT)  framework that mainly utilizes CMDs and LLM to improve the quality of RALMs answers by trimming the indexes of vector database.  The CDIT framework starts with an initial retrieval by the retriever in RALMs.  Then the preliminary retrieval results are sent to the CMDs where an  LLM is employed to determine whether the retrieved knowledge conforms to  the CMDs constraints.  If the retrieval satisfies the CMDs, it will be passed to LLMs following conventional RALMs.  Otherwise, the retrieval will be discarded, and the vector-search index related to this retrieval will be corrected such that future similar queries can avoid unrelated retrievals return by the vector database.",
            "Table  1  summarizes symbols and notations.",
            "An LLM is employed to extract and compare the subjects, predicates and objects of sentences  and further judge whether the retrieval data and the query are consistent based on CMDs.    Specifically, a prompt consisting of rules and instructions is designed for extraction, comparison and judgement  (see Appendix  B.1  for details).    In the rule part of the prompt, we explain the meaning of CMDs to the LLM via natural language.  In the instruction part, we ask the LLM to extract and compare the sentence components based on the CMD and decide whether the data is consistent.    In our experiments, we adopt GPT-3.5-turbo as the extraction and comparison model,  which provides accurate judgments and is easy to implement with good flexibility and reasonable price.    Continue with Example  1 , as shown in Figure  2 ,  basic semantic components  s  u  b , p  r  e , o  b  j s u b p r e o b j sub,pre,obj italic_s italic_u italic_b , italic_p italic_r italic_e , italic_o italic_b italic_j  of  s 1 , s 2 subscript s 1 subscript s 2 s_{1},s_{2} italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  are firstly extracted by GPT-3.5-turbo.  After comparison, the LLM finds that  t  u  r  n  o  n t u r n o n turn\\ on italic_t italic_u italic_r italic_n italic_o italic_n  and  t  u  r  n  o  f  f t u r n o f f turn\\ off italic_t italic_u italic_r italic_n italic_o italic_f italic_f  are dissimilar,  which is denoted as  s 1  [ p  r  e ]  s 2  [ p  r  e ] subscript s 1 delimited-[] p r e subscript s 2 delimited-[] p r e s_{1}[pre]\\not\\approx s_{2}[pre] italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT [ italic_p italic_r italic_e ]  italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT [ italic_p italic_r italic_e ] .  Therefore, the CMD   1 subscript italic- 1 \\phi_{1} italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  is violated,  and the LLM returns \"False\" which means that  s 1  [ s  i  d ]  s 2  [ s  i  d ] not-similar-to subscript s 1 delimited-[] s i d subscript s 2 delimited-[] s i d s_{1}[sid]\\not\\sim s_{2}[sid] italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT [ italic_s italic_i italic_d ]  italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT [ italic_s italic_i italic_d ] .",
            "We propose an index trimming algorithm (Algorithm  1 ) based on the  Witness Theorem   to prune incorrect indexes of the retrieved data,  such that inconsistent contexts along with their corresponding vectors no longer link together.",
            "In other words, if the  s  i  d s i d sid italic_s italic_i italic_d  consistency judgement of  q , s 1 q subscript s 1 q,s_{1} italic_q , italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and  q , s 2 q subscript s 2 q,s_{2} italic_q , italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  differs, then  q q q italic_q  witnesses the contradiction between  s 1 subscript s 1 s_{1} italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and  s 2 subscript s 2 s_{2} italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT .   As a sufficient number of witnesses are collected,  it can be determined that  s 1 subscript s 1 s_{1} italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and  s 2 subscript s 2 s_{2} italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  are actually dissimilar.   In that case, we modify the vector index  by cutting the similarity linkage between  s 1 subscript s 1 s_{1} italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and  s 2 subscript s 2 s_{2} italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT .  Algorithm  1  shows this process of trimming indexes.",
            "Case Study.   We use the scenario depicted in Figure  1  as an example to explain the working principle of CDIT.  In this scenario, the input query is \" Who turned on the radio? \", and the two relevant retrieved contexts are: \\small{1} \" Mary turned off the radio. \" \\small{2} \" Jack turned on the radio. \"",
            "Table  9  shows the specific results of the top-k experiment.  In this experiment, Llama2-7b, IndexL2Flat are employed as the language generator and the indexing structure.  Top-k varies from 10 to 5.  Table  10  shows the results of the cmd expended experiment.  In this experiment, Llama2-7b, IndexL2Flat are employed as the language generator and the indexing structure.  CMD   1 ,  2 subscript italic- 1 subscript italic- 2 \\phi_{1},\\phi_{2} italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  are employed differently.  Table  11  shows the results of the integration experiment between CDIT and Self-RAG Asai et al. ( 2023 ) .  CDIT is employed firstly to enhance the data quality of retrieved contexts.  Then, the model was trained and tested using the Self-RAG approach.  Llama2-7b is employed as the language generator in this experiment, and top-k is 10."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Experiment results on different language models and index structure. Bold numbers indicate the best performance among models. \"Avg-Impro\" refers to the average improvement of CDIT of all types of datasets.  PopQA,TQA,ARC and Pub  refer to PopQA, TriviaQA-unfiltered, ARC-Challenge, and PubHealth, respectively.",
        "table": "S5.T2.21.21",
        "footnotes": [],
        "references": [
            "Consider the  following two sentences .     s 1 : : subscript s 1 absent s_{1}: italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT :  He turned on the radio.     s 2 : : subscript s 2 absent s_{2}: italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT :  He turned off the radio.     As shown in Figure  2 ,  s 1  [ s  u  b ] subscript s 1 delimited-[] s u b s_{1}[sub] italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT [ italic_s italic_u italic_b ] , s 1  [ p  r  e ] subscript s 1 delimited-[] p r e s_{1}[pre] italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT [ italic_p italic_r italic_e ]  and  s 1  [ o  b  j ] subscript s 1 delimited-[] o b j s_{1}[obj] italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT [ italic_o italic_b italic_j ]  represents  He, turn on and radio in sentence  s 1 subscript s 1 s_{1} italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , respectively,  while  s 2  [ s  u  b ] subscript s 2 delimited-[] s u b s_{2}[sub] italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT [ italic_s italic_u italic_b ] , s 2  [ p  r  e ] subscript s 2 delimited-[] p r e s_{2}[pre] italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT [ italic_p italic_r italic_e ]  and  s 2  [ o  b  j ] subscript s 2 delimited-[] o b j s_{2}[obj] italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT [ italic_o italic_b italic_j ]  denotes  He, turn off and radio in  s 2 subscript s 2 s_{2} italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , respectively.",
            "An LLM is employed to extract and compare the subjects, predicates and objects of sentences  and further judge whether the retrieval data and the query are consistent based on CMDs.    Specifically, a prompt consisting of rules and instructions is designed for extraction, comparison and judgement  (see Appendix  B.1  for details).    In the rule part of the prompt, we explain the meaning of CMDs to the LLM via natural language.  In the instruction part, we ask the LLM to extract and compare the sentence components based on the CMD and decide whether the data is consistent.    In our experiments, we adopt GPT-3.5-turbo as the extraction and comparison model,  which provides accurate judgments and is easy to implement with good flexibility and reasonable price.    Continue with Example  1 , as shown in Figure  2 ,  basic semantic components  s  u  b , p  r  e , o  b  j s u b p r e o b j sub,pre,obj italic_s italic_u italic_b , italic_p italic_r italic_e , italic_o italic_b italic_j  of  s 1 , s 2 subscript s 1 subscript s 2 s_{1},s_{2} italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  are firstly extracted by GPT-3.5-turbo.  After comparison, the LLM finds that  t  u  r  n  o  n t u r n o n turn\\ on italic_t italic_u italic_r italic_n italic_o italic_n  and  t  u  r  n  o  f  f t u r n o f f turn\\ off italic_t italic_u italic_r italic_n italic_o italic_f italic_f  are dissimilar,  which is denoted as  s 1  [ p  r  e ]  s 2  [ p  r  e ] subscript s 1 delimited-[] p r e subscript s 2 delimited-[] p r e s_{1}[pre]\\not\\approx s_{2}[pre] italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT [ italic_p italic_r italic_e ]  italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT [ italic_p italic_r italic_e ] .  Therefore, the CMD   1 subscript italic- 1 \\phi_{1} italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  is violated,  and the LLM returns \"False\" which means that  s 1  [ s  i  d ]  s 2  [ s  i  d ] not-similar-to subscript s 1 delimited-[] s i d subscript s 2 delimited-[] s i d s_{1}[sid]\\not\\sim s_{2}[sid] italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT [ italic_s italic_i italic_d ]  italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT [ italic_s italic_i italic_d ] .",
            "Table  2  compares the answer accuracy of the original RAG and CDIT, where we find the following:    CDIT works  for  various language models.    CDIT surpasses the basic models with average accuracy improvements  of 4.47%, 3.80%, 5.54%, 1.49%, 3.05%, 3.41% and 4.50% on Llama-7b, Llama2-7b, Alpaca-7b, Llama3-8b, Mistral-7b, Bloomz-7b1 and Falcon-7b, respectively,  and the most significant increase reaches up to 15.21%  when applying CDIT framework to Falcon-7b model on TriviaQA dataset with IndexHNSWFlat index.  This is because retrieval information that is unrelated or inconsistent with the query is discarded by CDIT, which reduces the distracting inputs to LLMs.    CDIT works  for  different indexing methods.    CDIT has on average boosted the model accuracy by 3.44%, 4.07%, and 3.75% over IndexFlatL2, IndexHNSWFlat, and IndexIVFFlat, respectively,  which proves its effectiveness in modifying the original vector index.    Moreover, CDIT achieves higher improvements on more coarse-grained indexing structures, such as IndexHNSWFlat.",
            "In particular, as for Llama3, a generator with strong language abilities,  We test its performance with a much larger top-k to evaluate how CDIT helps resolve the retrieval information explosion.  Previously, as shown in Table  2 , the performance gain of applying CDIT to Llama3 is limited,  where the possible reason may be that the strong language ability of Llama3 allows more contexts and better identifies irrelevant retrieval contexts independently without CDIT.  In order to investigate Llama3s ability limit of processing retrieval information explosion  and whether CDIT can still help to improve,  we vary (top-k) from 10 to 50 and test on PopQA with Llama3 as the generator.  As shown in Table  3 , the performance gain of CDIT is significantly enhanced as top-k increases,  which means that CDIT plays a better role when excessively large context information is fed to the LLM."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  The performance of CDIT on Llama3 as top-k ranks from 10 to 50.",
        "table": "S5.T3.5.5",
        "footnotes": [],
        "references": [
            "As shown in Figure  3 , CDIT starts with an initial retrieval (step \\small{1})  and the query will be checked that whether a similar query has been processed before (step \\small{2}).  If a similar query is found by the determiner via semantic similarity search  Gao et al.  ( 2023 ) ,  the initial retrieval along with the query will be used to generate the final answer (step \\small{3}).  Otherwise, CDIT employs an LLM to extract the main semantic components of the retrieved sentences and  checks whether the retrieval data and the query conform with the CMDs (step \\small{4}).  Retrieval results that are determined as consistent by the CMDs and the LLM will be preserved and passed to the following steps,  while inconsistent results are discarded.  Later in step \\small{5}, CDIT trims the vector index based on the LLM judgements,  which enables the database to update its vector search index for better retrieval in the future.   Key steps \\small{4}\\small{5} will be introduced in following sections.",
            "In particular, as for Llama3, a generator with strong language abilities,  We test its performance with a much larger top-k to evaluate how CDIT helps resolve the retrieval information explosion.  Previously, as shown in Table  2 , the performance gain of applying CDIT to Llama3 is limited,  where the possible reason may be that the strong language ability of Llama3 allows more contexts and better identifies irrelevant retrieval contexts independently without CDIT.  In order to investigate Llama3s ability limit of processing retrieval information explosion  and whether CDIT can still help to improve,  we vary (top-k) from 10 to 50 and test on PopQA with Llama3 as the generator.  As shown in Table  3 , the performance gain of CDIT is significantly enhanced as top-k increases,  which means that CDIT plays a better role when excessively large context information is fed to the LLM."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Time to call LLMs in CDIT.",
        "table": "S5.T4.1",
        "footnotes": [],
        "references": [
            "To illustrate, we take IndexHNSWFlat in Faiss as an example.  As shown in Figure  4 , IndexHNSWFlat establishes a vector search index based on HNSW algorithm  Malkov and Yashunin ( 2016 ) ,  where data in the knowledge base is organized as a hierarchical similarity graph to facilitate efficient searching.  From Figure  4 (a), we can see that A and B are regarded as similar and connected by HNSW.  However, as the LLM determines that  q 1 , q 2 subscript q 1 subscript q 2 q_{1},q_{2} italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  are similar to A while dissimilar to B,  and  q 3 subscript q 3 q_{3} italic_q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT  is similar to B but not A (Figure  4 (b)),  there has been adequate number of witnesses for A and B to separate.  Thus, CDIT will cut the edge between A and B (the dashed line in Figure  4 (c))  and the vector search index is trimmed.",
            "LLM costs.   We analyze the costs of utilizing LLMs in CDIT, which has been validated acceptable.  Time to call LLMs is considered to assess the cost with results as follows.  As shown in Table  4 , even with the maximum number of calls to LLMs, without considering repeated queries, the time did not exceed 6 minutes.  Compared to the time required for the inference of language model itself, we consider this cost to be reasonable."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Construction of new queries in query rewriting",
        "table": "A3.T5.2",
        "footnotes": [],
        "references": [
            "As  CDIT is a method of pruning indexes and can be  flexibly   integrated  with other  RALMs  as a functional module,  it is actually an atomic component and is difficult to conduct ablation studies.   Thus, we analyze the impact of hyper-parameters and CMDs on CDIT.     Specific results are shown in  Appendix  C .     Effects of varying top-k.   In order to analyze how the number of documents returned by the retriever affects the performance of CDIT,  we vary the number of retrieved documents (top-k) from 5 to 10 and test on PopQA dataset for all three vector indexes with llama2-7b as the generator.  As shown in Figure  5 , CDIT shows improvements across various top-k, and the improvement is more significant under larger top-k.  The main reason for this is that larger top-k may return more useless information, which deteriorates the performance and can be filtered out by CDIT,  while smaller top-k provides little space for trimming where the performance gain is limited.",
            "After the indexes have been trimmed, we rewrite the query to test the performance.  We follow the approach of  Feng et al. , combining the original query and the top-1 retrieval document to form a new query.  Therefore, the new query sent to the language generator is shown in Table  5 ."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Prompts used in extraction and comparison",
        "table": "A3.3.3",
        "footnotes": [],
        "references": [
            "where  a  t  t , a  d  v a t t a d v att,adv italic_a italic_t italic_t , italic_a italic_d italic_v  denote the attributive and adverbial of the sentence.  We add CMD   2 subscript italic- 2 \\phi_{2} italic_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  to the comparing step,  such that the consistency of  s  i  d s i d sid italic_s italic_i italic_d  requires simultaneous satisfaction of both CMD   1 subscript italic- 1 \\phi_{1} italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and CMD   2 subscript italic- 2 \\phi_{2} italic_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT .  As shown in Figure  6 , different CMDs have an influence on the accuracy of CDIT.  Thus, it is desirable to investigate the optimized combinations of various CMDs in future."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Prompts for generating answers.",
        "table": "A3.T7.4",
        "footnotes": [],
        "references": [
            "Integration with other RALMs.   We analyze the performance of CDIT when integrated with enhanced RAG models.  As CDIT directly modifies the indexes of database, it has strong flexibility and can be easily integrated with  existing RAG models to improve the answer quality.  We integrate CDIT with Self-RAG Asai et al. ( 2023 ) , which is a refined RAG model by improving knowledge retrieval,  and evaluate the accuracy of the answers.  Llama2-7b is used in this test, and other settings are unchanged.  As shown in Figure  7 , CDIT consistently improves the accuracy of answers  after integrating with self-rag, where the average increase is 3.62%.  This shows that based on existing state-of-the-art RAG models that mainly improve 12.3%,  CDIT could further enhance the performance by refining data quality.",
            "After retrieval, we combine the retrieval contexts and other instructions to prompt the language generator for the final answers.  For ARC-Challenge, we follow  Asai et al. , designing task instructions shown in Table  8 .  For other tasks, we do not design additional task instructions.  The final prompts are shown in Table  7 ."
        ]
    },
    "id_table_8": {
        "caption": "Table 8:  Task instruction for ARC-Challenge.",
        "table": "A3.T8.1",
        "footnotes": [],
        "references": [
            "After retrieval, we combine the retrieval contexts and other instructions to prompt the language generator for the final answers.  For ARC-Challenge, we follow  Asai et al. , designing task instructions shown in Table  8 .  For other tasks, we do not design additional task instructions.  The final prompts are shown in Table  7 ."
        ]
    },
    "id_table_9": {
        "caption": "Table 9:  Changes in accuracy for models with and without CDIT on PopQA as the top-k parameter varies.",
        "table": "A3.T9.21",
        "footnotes": [],
        "references": [
            "Table  9  shows the specific results of the top-k experiment.  In this experiment, Llama2-7b, IndexL2Flat are employed as the language generator and the indexing structure.  Top-k varies from 10 to 5.  Table  10  shows the results of the cmd expended experiment.  In this experiment, Llama2-7b, IndexL2Flat are employed as the language generator and the indexing structure.  CMD   1 ,  2 subscript italic- 1 subscript italic- 2 \\phi_{1},\\phi_{2} italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  are employed differently.  Table  11  shows the results of the integration experiment between CDIT and Self-RAG Asai et al. ( 2023 ) .  CDIT is employed firstly to enhance the data quality of retrieved contexts.  Then, the model was trained and tested using the Self-RAG approach.  Llama2-7b is employed as the language generator in this experiment, and top-k is 10."
        ]
    },
    "id_table_10": {
        "caption": "Table 10:  Accuracy of CDIT with different CMDs.",
        "table": "A3.T10.3.3",
        "footnotes": [],
        "references": [
            "Table  9  shows the specific results of the top-k experiment.  In this experiment, Llama2-7b, IndexL2Flat are employed as the language generator and the indexing structure.  Top-k varies from 10 to 5.  Table  10  shows the results of the cmd expended experiment.  In this experiment, Llama2-7b, IndexL2Flat are employed as the language generator and the indexing structure.  CMD   1 ,  2 subscript italic- 1 subscript italic- 2 \\phi_{1},\\phi_{2} italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  are employed differently.  Table  11  shows the results of the integration experiment between CDIT and Self-RAG Asai et al. ( 2023 ) .  CDIT is employed firstly to enhance the data quality of retrieved contexts.  Then, the model was trained and tested using the Self-RAG approach.  Llama2-7b is employed as the language generator in this experiment, and top-k is 10."
        ]
    },
    "id_table_11": {
        "caption": "Table 11:  The performance of CDIT integrated with self-rag on three datasets with top-k being 10.",
        "table": "A3.T11.3",
        "footnotes": [],
        "references": [
            "Table  9  shows the specific results of the top-k experiment.  In this experiment, Llama2-7b, IndexL2Flat are employed as the language generator and the indexing structure.  Top-k varies from 10 to 5.  Table  10  shows the results of the cmd expended experiment.  In this experiment, Llama2-7b, IndexL2Flat are employed as the language generator and the indexing structure.  CMD   1 ,  2 subscript italic- 1 subscript italic- 2 \\phi_{1},\\phi_{2} italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  are employed differently.  Table  11  shows the results of the integration experiment between CDIT and Self-RAG Asai et al. ( 2023 ) .  CDIT is employed firstly to enhance the data quality of retrieved contexts.  Then, the model was trained and tested using the Self-RAG approach.  Llama2-7b is employed as the language generator in this experiment, and top-k is 10."
        ]
    },
    "global_footnotes": []
}