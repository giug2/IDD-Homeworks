{
    "id_table_1": {
        "caption": "Table 1:  Main results on BONAI  (Wang et al.,  2023a ) .",
        "table": "S4.T1.9.9",
        "footnotes": [],
        "references": [
            "For the second aspect, we are inspired by The Law of Geography  (Zhu et al.,  2018 ) : in spatial representation, the information contained is redundant.  In fact, BFE problem can be defined by each two of building segmentation, roof segmentation, offset prediction and facade segmentation, as shown in Fig. 1 .",
            "In Eq. 1 ,  f f f italic_f  represents the Nadaraya-Watson Kernal Regression.  K K \\mathcal{K} caligraphic_K  represents kernal used in regression.  If  f f f italic_f  was described in Transformer,  x x x italic_x  denotes the input  q  u  e  r  y q u e r y query italic_q italic_u italic_e italic_r italic_y ;  { x 1 , x 2 , ... , x n } subscript x 1 subscript x 2 ... subscript x n \\{x_{1},x_{2},...,x_{n}\\} { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }  denotes  k  e  y k e y key italic_k italic_e italic_y ;  { y 1 , y 2 , ... , y n } subscript y 1 subscript y 2 ... subscript y n \\{y_{1},y_{2},...,y_{n}\\} { italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }  denotes  v  a  l  u  e v a l u e value italic_v italic_a italic_l italic_u italic_e .",
            "In BFE problem, our prior knowledge tells us: longer offsets tend to have better direction. Therefore, Eq. 1  is translated as Eq. 2 :",
            "Another applicable knowledge from Geography: the contained information of model results is overlapped between each other.  As shown in Fig. 1 , there are three features, roofs, the body of buildings and building offsets, can be extracted easier than directly searching building footprints.  Extracting footprints with roof segmentation and offsets is intuitive, and this method was popularly adopted in aforementioned methods.  In (c), the extracting method is also explicit: move building mask along the roof-to-footprint offset, and the union between that and building mask is the footprints.  Similarly, if the building mask was moved in the opposite direction, the union would be roof mask.",
            "In (a), the situation was more complicated. The first step was to find a direction which can better represents the direction from roof to footprint.  In this direction, searching algorithm was applied to detect the location of footprints by valuing different length of movements.  Of course, we can also use the predicted global offset direction as this direction.  In Algorithm  1 , we introduced how to extract building footprint with only a roof and building segmentation.",
            "When applying spatial information in Algorithm  1  to extract footprints,  the Best Length Value was defined as following critical condition in Fig. 3 .",
            "In this section, we evaluate our methods on BONAI and OmniCity-view3.  The main comparison will focus on LOFT  (Wang et al.,  2023a ) , Cascade LOFT and OBM between OBMv2, because these are models that available for extensive experiments.  In Tab. 1 , the displayed results were separated into three parts.  The first part lists results from end-to-end models.  In the second part, all available promptable models were compared with our proposed model in part three.  From this table, we know that although OBMv2 can predict offset as accurate as that of OBM in terms of direction, it suffers from incorrect length prediction.  This contributes to a clear drop of footprint F1score (1.29 approximately), and a similar drop of Precision and Recall can be found in this table.  Roof mask quality was surprisingly improved compared with OBM despite the drop in footprint quality.  The comparison and more analysis was provided in discussion. For OBMv2, footprint F1score decreased by 3.43 during the progress of vectorizing masks.  This slight decline was commonly found in experiments because polygonal footprints commonly lost those complex edges for extracting simplified features.",
            "Fig. 8  displayed some typical samples which predict false roofs because of the \"edge problem\".  Low roof quality but relatively correct offsets finally leads to a poor quality footprint.  Aforementioned situation can be improved by using building segmentation like Fig. 1 (c).",
            "OBMv2 is not always better than other models.   e.g.  On BONAI  (Wang et al.,  2023a ) , OBMv2 patially outperform OBM in Tab. 1 ,  but experiments on OmniCity  (Li et al.,  2022 )  showcase the ability of OBMv2.  From Fig. 4 , we speculate that this is likely due to the different pixel proportions occupied by buildings in the same image.  The image embeddings from ViT encoder is downsampled by  16  16\\times 16  .  This downsampling process will adversely influence the quality of embeddings, especially when objects in images only occupied a small number of pixels.  Unfortunately, this feature is very obvious on BONAI compared it on OmniCity."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  SOFA block ablation studies on BONAI.",
        "table": "S4.T2.8.8",
        "footnotes": [],
        "references": [
            "In this paper, we proposed a trainable Self Offset Attention (SOFA) via Nadaraya-Watson Regression  (Nadaraya,  1964 ; Watson,  1964 )   and Look-Ahead Masking  (Vaswani et al.,  2017 )  in Nature Language Processing (NLP) for aforementioned phenomenon.  The diagram of SOFA was plotted in Fig. 2   In machine learning, the nature of attention layer can be understood as a pooling layer.  The mission of SOFA is to accumulate offset knowledge in longer offsets.",
            "In BFE problem, our prior knowledge tells us: longer offsets tend to have better direction. Therefore, Eq. 1  is translated as Eq. 2 :",
            "In Eq. 2 , offset queries  O  = { o 1  , o 2  , ... , o n  }  O  subscript o 1  subscript o 2 ...  subscript o n \\vec{O}=\\{\\vec{o_{1}},\\vec{o_{2}},...,\\vec{o_{n}}\\} over start_ARG italic_O end_ARG = { over start_ARG italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , over start_ARG italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG , ... , over start_ARG italic_o start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG }  was expressed as polar coordinate  O  = { (  1 ,  1 ) , ... , (  n ,  n ) }  O subscript  1 subscript  1 ... subscript  n subscript  n \\vec{O}=\\{(\\rho_{1},\\alpha_{1}),...,(\\rho_{n},\\alpha_{n})\\} over start_ARG italic_O end_ARG = { ( italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , ... , ( italic_ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) } .     \\rho italic_  means length of the offset, and    \\alpha italic_  represents angle of the offset.        \\dot{\\alpha} over  start_ARG italic_ end_ARG  is the corrected offset angle.",
            "Consequently, Eq. 2  transformed as:",
            "To make the whole attention learnable, a trainable parameter  w w w italic_w  was added to Eq. 3.2 :",
            "From Eq. 3.2  and Eq. 3.2 , SOFA is a portable and plug-and-play block,  because (1) the learnable parameter  w w w italic_w  was light;  (2) in one off-nadir image  I , the number of buildings  N N N italic_N  tend to be under 100, which makes the spatial operation of the matrix not consume much GPU memory.",
            "Fig. 2  (a) illustrate the proposed architecture of Offset Building Model v2 (OBMv2).  OBMv2 has four new concepts compared with OBM.  Firstly, Self Offset Attention block is inserted between FFN and Offset Coder ROAM structure.  SOFA block provides a global awareness for each offset head and encoded offset to ensure shorter offsets can better minimize offset error.  Secondly, prompt-level vertex segmentation is added in the decoder part via a vertex token. These tasks will finally be integrated with HiSup  (Xu et al.,  2023 )  to extract polygon.  Thirdly, OBMv2 can receive automatic prompt from other models via a Proposal Network.  Lastly, OBMv2 adopts roof-related information as prompting to reduce the adhesive relationship between buildings and achieve better differentiation of buildings.",
            "OBM is not capable of extracting polygonal footprints.  To insert this function, OBMv2 using a existing roof segmentation task and a vertex segmentation task.  The whole data flow was illustrated in Fig. 2  (a).  To begin with, a new vertex token was initialized together with mask tokens and offset tokens for each prompt.  Then, these tokens will be inputted into a two-way-transformer with custom prompt token.  The output of the transformer will be divided into two streams.  In the mask prediction stream, vertex token will be concatenated with mask tokens;  after using FFN, those tokens will divide image embeddings into roof masks, building masks and vertex masks.  Using methods in HiSup, roof masks and vertex masks will finally get the simplified polygonal roofs.",
            "To ensure SOFA block is appliable in all kinds of offset-based model, the results was listed in Tab. 2 .  In this table, a same model in both prompting mode and roof prompting was written in the same line.",
            "Unlike other transformer blocks, SOFA block was developed not sensitive to the input length of embedded tokens.  Because of this feature, SOFA block can adapt to any offset based models.  SOFA block was trained in the last stage after all other blocks finished training.  In Tab. 2 , SOFA block was applied in all open-source models, and can reduce both prompt-level and instance-level offset error.   e.g.  EPE of LOFT on BONAI dataset declined by 0.33 pixels."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Experimental results on OmniCity-view3.",
        "table": "S4.T3.6.6",
        "footnotes": [],
        "references": [
            "To make the whole attention learnable, a trainable parameter  w w w italic_w  was added to Eq. 3.2 :",
            "From Eq. 3.2  and Eq. 3.2 , SOFA is a portable and plug-and-play block,  because (1) the learnable parameter  w w w italic_w  was light;  (2) in one off-nadir image  I , the number of buildings  N N N italic_N  tend to be under 100, which makes the spatial operation of the matrix not consume much GPU memory.",
            "Promptable models commonly have a problem: how to activate and promote their functions.  This was widely studied especially in NLP  (Gao et al.,  2023 ) .  As a result, proposal network was designed for automatic prompting OBMv2.  The network can be defined as an instance segmentation model, semantic segmentation model or object detection model.  OBMv2 provides a basic semantic segmentation head inspired by Segmenter  (Strudel et al.,  2021 )  and SAM-HQ  (Ke et al.,  2024 ) .  Image embeddings from image encoder will be passed to a segmenter mask transformer.  The outputted image embeddings will be upsampled  4  4\\times 4   as high quality embeddings.  The these embeddings will be used to regress roofs.  In this paper, more different proposal modes were applied to explore how to reach the maximum of OBMv2 in Sec. 3.4 .",
            "When applying spatial information in Algorithm  1  to extract footprints,  the Best Length Value was defined as following critical condition in Fig. 3 .",
            "Fig. 3 (c) illustrates how to extract a more accurate offset.  Aforementioned binary search was applied twice for the  yellow offset  and  red offset .  As the length of  blue offset  equal to that of the  yellow offset .  The length of roof-to-building offset is equal to the  red offset  minor the  yellow offset ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Experimental results on Huizhou test set.",
        "table": "S4.T4.4.4",
        "footnotes": [],
        "references": [
            "Promptable models commonly have a problem: how to activate and promote their functions.  This was widely studied especially in NLP  (Gao et al.,  2023 ) .  As a result, proposal network was designed for automatic prompting OBMv2.  The network can be defined as an instance segmentation model, semantic segmentation model or object detection model.  OBMv2 provides a basic semantic segmentation head inspired by Segmenter  (Strudel et al.,  2021 )  and SAM-HQ  (Ke et al.,  2024 ) .  Image embeddings from image encoder will be passed to a segmenter mask transformer.  The outputted image embeddings will be upsampled  4  4\\times 4   as high quality embeddings.  The these embeddings will be used to regress roofs.  In this paper, more different proposal modes were applied to explore how to reach the maximum of OBMv2 in Sec. 3.4 .",
            "In Fig. 4 , visulized results in prompt mode were provided.  The first and second lines of illustrations were selected from BONAI (Wang et al.,  2023a ) .  The third and fouth lines were from OmniCity-view3 (Li et al.,  2022 ) , and the last line was from Huizhou (Li et al.,  2024a ) .  Our model can provide polygonal results which was more editable compared with other models.",
            "OBMv2 is not always better than other models.   e.g.  On BONAI  (Wang et al.,  2023a ) , OBMv2 patially outperform OBM in Tab. 1 ,  but experiments on OmniCity  (Li et al.,  2022 )  showcase the ability of OBMv2.  From Fig. 4 , we speculate that this is likely due to the different pixel proportions occupied by buildings in the same image.  The image embeddings from ViT encoder is downsampled by  16  16\\times 16  .  This downsampling process will adversely influence the quality of embeddings, especially when objects in images only occupied a small number of pixels.  Unfortunately, this feature is very obvious on BONAI compared it on OmniCity."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Auto extraction results on BONAI test set.",
        "table": "S4.T5.1.1",
        "footnotes": [],
        "references": [
            "In Fig. 5 , BFE problem was solved by different information.  For promptable models, OBM and OBMv2, building segmentation with offsets can predict better building footprint(F1score +1.37 and + 0.23 respectively).  End-to-end ROI-based can also extract footprint with building segmentation and offsets, which provides similar performance with related models using roof and offset.  Additionally, extracting footprints with roof and building segmentation has been proved appliable, although offsets regressed in this version was inaccurate compared with models using roofs.  All models can provide better results than Mask RCNN.",
            "The automatic extraction of building footprints commonly relies on proposal regions.  In Tab. 5 , OBMv2 was tested with different region proposal functions.  Additionally, utilizing different sources of information to extract footprint print was also examined.",
            "BFE problem solved by a promptable model like OBMv2 must also consider those similar problems.  Except Fig. 5  and Tab. 7 ,  there must be more interesting methods which help the model reaching and exceeding \"the ceiling performance of using Ground Truth prompts\"."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Extract footprints with different ground truth labels on BONAI test set.",
        "table": "S5.T6.1.1",
        "footnotes": [],
        "references": [
            "In Fig. 6 , footprints extracted by auto mode were compared with each other.  Our model using can still provide polygonal results compared with other models.",
            "From Tab. 6 , our proposed algorithms can accurately extract building footprints via different information.  Although our algorithms can extract footprints merely with roof and building segmentations,  grid-based digital images always limited by image continuity.  The influence of this problem is more severe especially on the representations of buildings with short offsets,   e.g.  an offset with length 1 pixel, there are only 4 points nearby can represent its end point.  This ambiguity leads to poor perception of direction.  As a result, when offset direction was given, the  a  V  L a V L aVL italic_a italic_V italic_L  dropped by 5.16 pixels and F1score of footprints increased by 6.5%."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Extract footprints with other roof extraction models on BONAI test set.",
        "table": "S5.T7.5.5",
        "footnotes": [],
        "references": [
            "In Tab. 7 , OBMv2 was integrated with its segmentation head, HTC and LOFT.  Specifically, HTC and LOFT are matched with different NMS strategies.     \\spadesuit   represents soft NMS algorithms with score threshold 0.05, IoU threshold 0.5, maximum 2000 instances per image.     \\clubsuit   represents NMS algorithms with score threshold 0.1, IoU threshold 0.5, maximum 2000 instances per image.     \\heartsuit   leverages results from    \\spadesuit  , but the same instance which was repeated predicted will be merged as one instance.",
            "BFE problem solved by a promptable model like OBMv2 must also consider those similar problems.  Except Fig. 5  and Tab. 7 ,  there must be more interesting methods which help the model reaching and exceeding \"the ceiling performance of using Ground Truth prompts\".",
            "On the other hand, OBMv2 was trained with noised ground truth boxes, and these boxes can cover all pixels of each roof.  However, bounding boxes which were received by OBMv2 tend to only cover a small pitch of one building, when integrating with other models, as shown in Fig. 7 .  For such box prompts, OBMv2 cannot predict accurate offsets.  Then, corresponding roofs were consequently moved to wrong places because of the uncertainty.  That is why in Tab. 7  soft NMS has high recall but low precision."
        ]
    },
    "global_footnotes": [
        "https://github.com/opencv/opencv"
    ]
}