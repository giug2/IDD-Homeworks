{
    "PAPER'S NUMBER OF TABLES": 6,
    "S5.T1": {
        "caption": "Table 1: Train Results",
        "table": "<table id=\"S5.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"S5.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Arch</span></th>\n<th id=\"S5.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Fed-Avg</span></th>\n<th id=\"S5.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Fed-ERM</span></th>\n<th id=\"S5.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">CausalFed-RM</span></th>\n<th id=\"S5.T1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T1.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">CausalFed-IRM</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Colored MNIST</td>\n<td id=\"S5.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">ResNet18</td>\n<td id=\"S5.T1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">80.3%</td>\n<td id=\"S5.T1.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S5.T1.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">82.97</span> %</td>\n<td id=\"S5.T1.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">60.42 %</td>\n<td id=\"S5.T1.1.2.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\">59.33 %</td>\n</tr>\n<tr id=\"S5.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Rotated MNIST</td>\n<td id=\"S5.T1.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">ResNet18</td>\n<td id=\"S5.T1.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">85.2%</td>\n<td id=\"S5.T1.1.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S5.T1.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">86.5</span> %</td>\n<td id=\"S5.T1.1.3.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">79.8 %</td>\n<td id=\"S5.T1.1.3.2.6\" class=\"ltx_td ltx_align_left ltx_border_t\">80.2 %</td>\n</tr>\n<tr id=\"S5.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">Rotated FMNIST</td>\n<td id=\"S5.T1.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">LeNet</td>\n<td id=\"S5.T1.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">81.4%</td>\n<td id=\"S5.T1.1.4.3.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">\n<span id=\"S5.T1.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">82.3</span> %</td>\n<td id=\"S5.T1.1.4.3.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">72.1 %</td>\n<td id=\"S5.T1.1.4.3.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">71.5 %</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In our experiments, we compare the performance of federated averaging (Fed-Avg) with the following approaches:",
                "Fed-ERM",
                "\nWithin the CausalFed setup, this approach minimizes the empirical average of loss over training data points and treats the data from different domains as i.i.d.\nERM loss is given by:",
                "where S equals set of clients/ source domains, ",
                "N",
                "C",
                "subscript",
                "ùëÅ",
                "ùê∂",
                "N_{C}",
                " equals number of samples per client ",
                "C",
                "ùê∂",
                "C",
                ", ",
                "‚Ñí",
                "s",
                "subscript",
                "‚Ñí",
                "ùë†",
                "\\mathcal{L}_{s}",
                " equals classification loss. \n",
                "CausalFed-RM",
                "\nIn this approach, we minimize the random match(RMatch) causal loss ",
                "(Mahajan et¬†al., ",
                "2020",
                ")",
                " within the CausalFed setup. RMatch loss is given by:",
                "where ",
                "Œ©",
                "Œ©",
                "\\Omega",
                " represents the match function used to randomly pair the data points across the different client domains.\n",
                "CausalFed-IRM",
                "\nIn this approach, we minimize the IRM loss ",
                "(Arjovsky et¬†al., ",
                "2019",
                ")",
                " within the CausalFed setup.",
                "We observed that when clients have out of distribution data in a federated setup, FedAvg as well as FedERM does not fare well in the server side test data set though they give highly accurate results on train data(iid) whereas CausalFed-RM and CausalFed-IRM perfoms much better on test data(non iid).",
                "Privacy Leakage",
                " In our experiments, within the CausalFed setup, we analyse the privacy leakage on 3 common attacks namely, Membership inference attack, Property inference attack and Backdoor attack. The privacy leakage on each of the attacks is measured by testing the accuracy of attack model. Details on each of the attacks are added in ",
                "A.2",
                " ",
                "A.3",
                ".",
                "We observe that in our setup with an out of distribution(OOD) test set, the membership inference attack accuracy of a federated causal client adversary model is much lesser as compared to a federated setup with associational client models. It was also observed that federated causal models provide better pivacy guarantees against property inference attacks which could be owed to the fact that inversion based on learning correlations between attributes and final prediction, e.g., using color to predict the digit, can be eliminated by causal models, since a non-causal feature will not be included in our final causal federated model."
            ]
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Test Results",
        "table": "<table id=\"S5.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"S5.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Arch</span></th>\n<th id=\"S5.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Fed-Avg</span></th>\n<th id=\"S5.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Fed-ERM</span></th>\n<th id=\"S5.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T2.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">CausalFed-RM</span></th>\n<th id=\"S5.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T2.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">CausalFed-IRM</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Colored MNIST</td>\n<td id=\"S5.T2.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">ResNet18</td>\n<td id=\"S5.T2.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">11%</td>\n<td id=\"S5.T2.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">10.2 %</td>\n<td id=\"S5.T2.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S5.T2.1.2.1.5.1\" class=\"ltx_text ltx_font_bold\">65.62</span> %</td>\n<td id=\"S5.T2.1.2.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\">60.3 %</td>\n</tr>\n<tr id=\"S5.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Rotated MNIST</td>\n<td id=\"S5.T2.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">ResNet18</td>\n<td id=\"S5.T2.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">82.7%</td>\n<td id=\"S5.T2.1.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">82.9 %</td>\n<td id=\"S5.T2.1.3.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S5.T2.1.3.2.5.1\" class=\"ltx_text ltx_font_bold\">90.2</span> %</td>\n<td id=\"S5.T2.1.3.2.6\" class=\"ltx_td ltx_align_left ltx_border_t\">89.1 %</td>\n</tr>\n<tr id=\"S5.T2.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">Rotated FMNIST</td>\n<td id=\"S5.T2.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">LeNet</td>\n<td id=\"S5.T2.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">72%</td>\n<td id=\"S5.T2.1.4.3.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">71.6 %</td>\n<td id=\"S5.T2.1.4.3.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">\n<span id=\"S5.T2.1.4.3.5.1\" class=\"ltx_text ltx_font_bold\">74.6</span> %</td>\n<td id=\"S5.T2.1.4.3.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">73.9 %</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In our experiments, we compare the performance of federated averaging (Fed-Avg) with the following approaches:",
                "Fed-ERM",
                "\nWithin the CausalFed setup, this approach minimizes the empirical average of loss over training data points and treats the data from different domains as i.i.d.\nERM loss is given by:",
                "where S equals set of clients/ source domains, ",
                "N",
                "C",
                "subscript",
                "ùëÅ",
                "ùê∂",
                "N_{C}",
                " equals number of samples per client ",
                "C",
                "ùê∂",
                "C",
                ", ",
                "‚Ñí",
                "s",
                "subscript",
                "‚Ñí",
                "ùë†",
                "\\mathcal{L}_{s}",
                " equals classification loss. \n",
                "CausalFed-RM",
                "\nIn this approach, we minimize the random match(RMatch) causal loss ",
                "(Mahajan et¬†al., ",
                "2020",
                ")",
                " within the CausalFed setup. RMatch loss is given by:",
                "where ",
                "Œ©",
                "Œ©",
                "\\Omega",
                " represents the match function used to randomly pair the data points across the different client domains.\n",
                "CausalFed-IRM",
                "\nIn this approach, we minimize the IRM loss ",
                "(Arjovsky et¬†al., ",
                "2019",
                ")",
                " within the CausalFed setup.",
                "We observed that when clients have out of distribution data in a federated setup, FedAvg as well as FedERM does not fare well in the server side test data set though they give highly accurate results on train data(iid) whereas CausalFed-RM and CausalFed-IRM perfoms much better on test data(non iid).",
                "Privacy Leakage",
                " In our experiments, within the CausalFed setup, we analyse the privacy leakage on 3 common attacks namely, Membership inference attack, Property inference attack and Backdoor attack. The privacy leakage on each of the attacks is measured by testing the accuracy of attack model. Details on each of the attacks are added in ",
                "A.2",
                " ",
                "A.3",
                ".",
                "We observe that in our setup with an out of distribution(OOD) test set, the membership inference attack accuracy of a federated causal client adversary model is much lesser as compared to a federated setup with associational client models. It was also observed that federated causal models provide better pivacy guarantees against property inference attacks which could be owed to the fact that inversion based on learning correlations between attributes and final prediction, e.g., using color to predict the digit, can be eliminated by causal models, since a non-causal feature will not be included in our final causal federated model."
            ]
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Leakage on inference attack",
        "table": "<table id=\"S5.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"S5.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Fed-Avg</span></th>\n<th id=\"S5.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Fed-ERM</span></th>\n<th id=\"S5.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">CausalFed-RM</span></th>\n<th id=\"S5.T3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">CausalFed-IRM</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Colored MNIST</td>\n<td id=\"S5.T3.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">79.21 %</td>\n<td id=\"S5.T3.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">79.45 %</td>\n<td id=\"S5.T3.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">58.57 %</td>\n<td id=\"S5.T3.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">56.9 %</td>\n</tr>\n<tr id=\"S5.T3.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Rotated MNIST</td>\n<td id=\"S5.T3.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">84.4 %</td>\n<td id=\"S5.T3.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">85.24 %</td>\n<td id=\"S5.T3.1.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">68.3 %</td>\n<td id=\"S5.T3.1.3.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">64.4 %</td>\n</tr>\n<tr id=\"S5.T3.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">Rotated FMNIST</td>\n<td id=\"S5.T3.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">76.61 %</td>\n<td id=\"S5.T3.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">78.23 %</td>\n<td id=\"S5.T3.1.4.3.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">57.55 %</td>\n<td id=\"S5.T3.1.4.3.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">55.7 %</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In our experiments, we compare the performance of federated averaging (Fed-Avg) with the following approaches:",
                "Fed-ERM",
                "\nWithin the CausalFed setup, this approach minimizes the empirical average of loss over training data points and treats the data from different domains as i.i.d.\nERM loss is given by:",
                "where S equals set of clients/ source domains, ",
                "N",
                "C",
                "subscript",
                "ùëÅ",
                "ùê∂",
                "N_{C}",
                " equals number of samples per client ",
                "C",
                "ùê∂",
                "C",
                ", ",
                "‚Ñí",
                "s",
                "subscript",
                "‚Ñí",
                "ùë†",
                "\\mathcal{L}_{s}",
                " equals classification loss. \n",
                "CausalFed-RM",
                "\nIn this approach, we minimize the random match(RMatch) causal loss ",
                "(Mahajan et¬†al., ",
                "2020",
                ")",
                " within the CausalFed setup. RMatch loss is given by:",
                "where ",
                "Œ©",
                "Œ©",
                "\\Omega",
                " represents the match function used to randomly pair the data points across the different client domains.\n",
                "CausalFed-IRM",
                "\nIn this approach, we minimize the IRM loss ",
                "(Arjovsky et¬†al., ",
                "2019",
                ")",
                " within the CausalFed setup.",
                "We observed that when clients have out of distribution data in a federated setup, FedAvg as well as FedERM does not fare well in the server side test data set though they give highly accurate results on train data(iid) whereas CausalFed-RM and CausalFed-IRM perfoms much better on test data(non iid).",
                "Privacy Leakage",
                " In our experiments, within the CausalFed setup, we analyse the privacy leakage on 3 common attacks namely, Membership inference attack, Property inference attack and Backdoor attack. The privacy leakage on each of the attacks is measured by testing the accuracy of attack model. Details on each of the attacks are added in ",
                "A.2",
                " ",
                "A.3",
                ".",
                "We observe that in our setup with an out of distribution(OOD) test set, the membership inference attack accuracy of a federated causal client adversary model is much lesser as compared to a federated setup with associational client models. It was also observed that federated causal models provide better pivacy guarantees against property inference attacks which could be owed to the fact that inversion based on learning correlations between attributes and final prediction, e.g., using color to predict the digit, can be eliminated by causal models, since a non-causal feature will not be included in our final causal federated model."
            ]
        ]
    },
    "A1.T4": {
        "caption": "Table 4: Network Architecture",
        "table": "<table id=\"A1.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Architecture</span></th>\n<th id=\"A1.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">No of Layers</span></th>\n<th id=\"A1.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T4.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Kernel spec</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T4.1.2.1\" class=\"ltx_tr\">\n<td id=\"A1.T4.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">LeNet</td>\n<td id=\"A1.T4.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">5</td>\n<td id=\"A1.T4.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">(5x5), (2x2)</td>\n</tr>\n<tr id=\"A1.T4.1.3.2\" class=\"ltx_tr\">\n<td id=\"A1.T4.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">AlexNet</td>\n<td id=\"A1.T4.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">8</td>\n<td id=\"A1.T4.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">(11x11), (5x5), (3x3)</td>\n</tr>\n<tr id=\"A1.T4.1.4.3\" class=\"ltx_tr\">\n<td id=\"A1.T4.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">ResNet18</td>\n<td id=\"A1.T4.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">18</td>\n<td id=\"A1.T4.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">(7x7), (3x3)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            []
        ]
    },
    "A1.T5": {
        "caption": "Table 5: Train Results",
        "table": "<table id=\"A1.T5.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T5.1.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T5.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"A1.T5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Arch</span></th>\n<th id=\"A1.T5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T5.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Fed-Avg</span></th>\n<th id=\"A1.T5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T5.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Fed-ERM</span></th>\n<th id=\"A1.T5.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T5.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">CausalFedGSD-RM</span></th>\n<th id=\"A1.T5.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T5.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">CausalFedGSD-IRM</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T5.1.2.1\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Colored MNIST</td>\n<td id=\"A1.T5.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">ResNet18</td>\n<td id=\"A1.T5.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">80.3%</td>\n<td id=\"A1.T5.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"A1.T5.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">82.97</span> %</td>\n<td id=\"A1.T5.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">57.42 %</td>\n<td id=\"A1.T5.1.2.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\">55.32 %</td>\n</tr>\n<tr id=\"A1.T5.1.3.2\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Rotated MNIST</td>\n<td id=\"A1.T5.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">ResNet18</td>\n<td id=\"A1.T5.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">85.2%</td>\n<td id=\"A1.T5.1.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"A1.T5.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">86.5</span> %</td>\n<td id=\"A1.T5.1.3.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">73.7 %</td>\n<td id=\"A1.T5.1.3.2.6\" class=\"ltx_td ltx_align_left ltx_border_t\">77.2 %</td>\n</tr>\n<tr id=\"A1.T5.1.4.3\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">Rotated FMNIST</td>\n<td id=\"A1.T5.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">LeNet</td>\n<td id=\"A1.T5.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">81.4%</td>\n<td id=\"A1.T5.1.4.3.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">\n<span id=\"A1.T5.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">82.3</span> %</td>\n<td id=\"A1.T5.1.4.3.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">69.2 %</td>\n<td id=\"A1.T5.1.4.3.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">68.6 %</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In ¬†",
                "(Zhao et¬†al., ",
                "2018",
                ")",
                ", it has been shown that globally shared data can reduce EMD(earth mover‚Äôs distance) between the data distribution on clients and the population distribution which can help in improved test accuracy.As this globally shared data is a separate dataset from that of the client, this approach is not privacy sensitive.",
                "With the CausalFed approach, there can be privacy concerns regarding sharing the client data representation to the global server due to which depending on a global data set(with different enviroments) to enhance causal feature learning within a federated learning setup seems plausible.\nAs we have no control on the clients‚Äô data, we can distribute a small subset of global data containing a distribution over all the classes/enviroments from the server side to the clients during the initialization stage of federated learning.",
                "The local model of each client is learned by minimizing the empirical average loss as well as regularizing the model by the gradient norm of the loss for both the shared data from server(Global Environment) and private data from each client(Local Environment). This enhances the learning of causal/invariant features common to both the client and global data environments without losing the privacy of client side data."
            ]
        ]
    },
    "A1.T6": {
        "caption": "Table 6: Test Results",
        "table": "<table id=\"A1.T6.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T6.1.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T6.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T6.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"A1.T6.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T6.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Arch</span></th>\n<th id=\"A1.T6.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T6.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Fed-Avg</span></th>\n<th id=\"A1.T6.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T6.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Fed-ERM</span></th>\n<th id=\"A1.T6.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T6.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">CausalFedGSD-RM</span></th>\n<th id=\"A1.T6.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"A1.T6.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">CausalFedGSD-IRM</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T6.1.2.1\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Colored MNIST</td>\n<td id=\"A1.T6.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">ResNet18</td>\n<td id=\"A1.T6.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">11%</td>\n<td id=\"A1.T6.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">10.2 %</td>\n<td id=\"A1.T6.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"A1.T6.1.2.1.5.1\" class=\"ltx_text ltx_font_bold\">55.62</span> %</td>\n<td id=\"A1.T6.1.2.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\">52.3 %</td>\n</tr>\n<tr id=\"A1.T6.1.3.2\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Rotated MNIST</td>\n<td id=\"A1.T6.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">ResNet18</td>\n<td id=\"A1.T6.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">82.7%</td>\n<td id=\"A1.T6.1.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">82.9 %</td>\n<td id=\"A1.T6.1.3.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"A1.T6.1.3.2.5.1\" class=\"ltx_text ltx_font_bold\">85.2</span> %</td>\n<td id=\"A1.T6.1.3.2.6\" class=\"ltx_td ltx_align_left ltx_border_t\">83.1 %</td>\n</tr>\n<tr id=\"A1.T6.1.4.3\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">Rotated FMNIST</td>\n<td id=\"A1.T6.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">LeNet</td>\n<td id=\"A1.T6.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">72%</td>\n<td id=\"A1.T6.1.4.3.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">71.6 %</td>\n<td id=\"A1.T6.1.4.3.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">\n<span id=\"A1.T6.1.4.3.5.1\" class=\"ltx_text ltx_font_bold\">71.9</span> %</td>\n<td id=\"A1.T6.1.4.3.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">70.2 %</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In ¬†",
                "(Zhao et¬†al., ",
                "2018",
                ")",
                ", it has been shown that globally shared data can reduce EMD(earth mover‚Äôs distance) between the data distribution on clients and the population distribution which can help in improved test accuracy.As this globally shared data is a separate dataset from that of the client, this approach is not privacy sensitive.",
                "With the CausalFed approach, there can be privacy concerns regarding sharing the client data representation to the global server due to which depending on a global data set(with different enviroments) to enhance causal feature learning within a federated learning setup seems plausible.\nAs we have no control on the clients‚Äô data, we can distribute a small subset of global data containing a distribution over all the classes/enviroments from the server side to the clients during the initialization stage of federated learning.",
                "The local model of each client is learned by minimizing the empirical average loss as well as regularizing the model by the gradient norm of the loss for both the shared data from server(Global Environment) and private data from each client(Local Environment). This enhances the learning of causal/invariant features common to both the client and global data environments without losing the privacy of client side data."
            ]
        ]
    }
}