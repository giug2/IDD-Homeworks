{
    "PAPER'S NUMBER OF TABLES": 2,
    "S4.T1": {
        "caption": "Table 1: Benchmark results on EMNIST with federated averaging.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Hardware</th>\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Test accuracy</th>\n<th id=\"S4.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Overall (s)</th>\n<th id=\"S4.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Average training round (s)</th>\n<th id=\"S4.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Full evaluation (s)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">GPU</td>\n<td id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">85.92%</td>\n<td id=\"S4.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">418</td>\n<td id=\"S4.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.26</td>\n<td id=\"S4.T1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">7.21</td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.3.2.1\" class=\"ltx_td ltx_align_center\">TPU</td>\n<td id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center\">85.85%</td>\n<td id=\"S4.T1.1.3.2.3\" class=\"ltx_td ltx_align_center\">258</td>\n<td id=\"S4.T1.1.3.2.4\" class=\"ltx_td ltx_align_center\">0.16</td>\n<td id=\"S4.T1.1.3.2.5\" class=\"ltx_td ltx_align_center\">4.06</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The EMNIST-62 dataset consists of 340034003400 writers and their writing samples, which are one of 626262 classes (alphanumeric).\nFollowing Reddi et al. (2020), we train a convolutional neural network for 150015001500 rounds with 101010 clients per round using federated averaging. We run experiments on GPU (a single NVIDIA V100) and TPU (a single TensorCore on a Google TPU v2) and report the final test accuracy, overall execution time, average training round duration, and full evaluation time in Table 1. We note that with a singleTensorCore, training takes under five minutes."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Benchmark results on Stack Overflow with federated averaging.",
        "table": "<table id=\"S4.T2.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.2.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row\">Hardware</th>\n<th id=\"S4.T2.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Test accuracy</th>\n<th id=\"S4.T2.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Overall (m)</th>\n<th id=\"S4.T2.2.3.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Average training round (s)</th>\n<th id=\"S4.T2.2.3.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Full evaluation (m)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.2.4.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.4.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">GPU</th>\n<td id=\"S4.T2.2.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">24.74%</td>\n<td id=\"S4.T2.2.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">127.2</td>\n<td id=\"S4.T2.2.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4.33</td>\n<td id=\"S4.T2.2.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">17.32</td>\n</tr>\n<tr id=\"S4.T2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">TPU (<span id=\"S4.T2.1.1.1.1\" class=\"ltx_text ltx_markedasmath ltx_font_typewriter\">jax.jit</span>)</th>\n<td id=\"S4.T2.1.1.2\" class=\"ltx_td ltx_align_center\">24.44%</td>\n<td id=\"S4.T2.1.1.3\" class=\"ltx_td ltx_align_center\">106.8</td>\n<td id=\"S4.T2.1.1.4\" class=\"ltx_td ltx_align_center\">3.73</td>\n<td id=\"S4.T2.1.1.5\" class=\"ltx_td ltx_align_center\">11.97</td>\n</tr>\n<tr id=\"S4.T2.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">TPU (<span id=\"S4.T2.2.2.1.1\" class=\"ltx_text ltx_markedasmath ltx_font_typewriter\">jax.pmap</span>)</th>\n<td id=\"S4.T2.2.2.2\" class=\"ltx_td ltx_align_center\">24.67%</td>\n<td id=\"S4.T2.2.2.3\" class=\"ltx_td ltx_align_center\">48.0</td>\n<td id=\"S4.T2.2.2.4\" class=\"ltx_td ltx_align_center\">1.26</td>\n<td id=\"S4.T2.2.2.5\" class=\"ltx_td ltx_align_center\">11.97</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The Stack Overflow dataset consists of questions and answers from the Stack Overflow forum, grouped by username. This dataset consists of roughly 342342342K users in the train split and 204204204K in the test split. Following Reddi et al. (2020), we train a single layer LSTM for 150015001500 rounds with 505050 clients per round using federated averaging. We run experiments on GPU (a single NVIDIA V100), TPU (a single TensorCore on a Google TPU v2) using only jax.jit, and multi-core TPU (eight TensorCores on a Google TPU v2) using jax.pmap and report results in Table 2. Benchmarks show that with multiple TensorCores, recurrent language models can be trained in under an hour. Figure 7 also shows the average training round duration as the number of clients per round increases. We note that training with multiple TensorCores is substantially faster as the number of clients per round increases."
        ]
    }
}