{
    "S4.T1": {
        "caption": "Table 1. Five-core pruned dataset statistics. Implicit datasets upper part, explicit datasets lower part.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.1.1.1\">Name</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.1.1.2\">#Interactions</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.1.1.3\">#Users</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.1.1.4\">#Items</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.1.1.5\">Avg.#Int./User</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.1.1.6\">Avg.#Int/Item</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.1.1.7\">Sparsity</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.1.8\">Domain</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.2.2.1\">Globo</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.2.2.2\">2,482,163</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.2.2.3\">157,926</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.2.2.4\">11,832</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.2.2.5\">15.72</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.2.2.6\">209.78</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.2.2.7\">99.87%</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.2.2.8\">Articles</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.3.3.1\">Hetrec-Lastfm</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.3.3.2\">71,355</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.3.3.3\">1,859</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.3.3.4\">2,823</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.3.3.5\">38.38</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.3.3.6\">25.28</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.3.3.7\">98.64%</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.3.3.8\">Music</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.4.4.1\">Nowplaying</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.4.4.2\">2,447,318</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.4.4.3\">64,392</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.4.4.4\">95,277</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.4.4.5\">38.01</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.4.4.6\">25.69</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.4.4.7\">99.96%</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.4.4.8\">Music</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.5.5.1\">Retailrocket</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.5.5.2\">240,938</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.5.5.3\">22,178</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.5.5.4\">17,803</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.5.5.5\">10.86</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.5.5.6\">13.53</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.5.5.7\">99.94%</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.5.5.8\">Shopping</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.6.6.1\">Sketchfab</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.6.6.2\">547,477</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.6.6.3\">25,655</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.6.6.4\">15,274</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.6.6.5\">21.34</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.6.6.6\">35.84</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.6.6.7\">99.86%</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.6.6.8\">Social</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.7.7.1\">MovieLens-100k</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.7.7.2\">81,697</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.7.7.3\">943</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.7.7.4\">1,203</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.7.7.5\">86.64</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.7.7.6\">67.91</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T1.1.7.7.7\">92.8%</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.7.7.8\">Movies</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.8.8.1\">MovieLens-1M</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.8.8.2\">835,789</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.8.8.3\">6,038</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.8.8.4\">3,307</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.8.8.5\">138.42</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.8.8.6\">252.73</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.8.8.7\">95.81%</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.8.8.8\">Movies</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.9.9.1\">MovieTweetings</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.9.9.2\">563,309</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.9.9.3\">20,643</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.9.9.4\">8,810</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.9.9.5\">27.29</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.9.9.6\">63.94</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S4.T1.1.9.9.7\">99.69%</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.9.9.8\">Movies</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We use eight recommendation algorithms of which two are baseline algorithms and eight different datasets.\nThe recommendation algorithms are from the libraries LensKit <cite class=\"ltx_cite ltx_citemacro_citep\">(Ekstrand, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib17\" title=\"\">2020</a>)</cite> and \n(Ekstrand, 2020) and Implicit <cite class=\"ltx_cite ltx_citemacro_citep\">(Frederickson, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib19\" title=\"\">2023</a>)</cite>.\nFrom \n(Frederickson, 2023).\nFrom LensKit we use the algorithms: Random, PopScore, Item-Item Nearest Neighbour, User-User Nearest Neighbour, and Implicit Matrix Factorization.\nThe algorithms from Implicit are: Alternating Least Square, Bayesian Personalized Ranking, and Logistic Matrix Factorization.\nThe datasets come from a variety of domains, such as: Articles, Locations, Movies, Music and Socials. Table 1 shows all datasets with information about the number of users, items, interactions and domain of the data.\nThe implicit feedback datasets are: Globo <cite class=\"ltx_cite ltx_citemacro_citep\">(de&#160;Souza Pereira&#160;Moreira et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib13\" title=\"\">2018</a>; Moreira et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib29\" title=\"\">2019</a>)</cite>, \n(de\u00a0Souza Pereira\u00a0Moreira et\u00a0al., 2018; Moreira et\u00a0al., 2019), Hetrec-Lastfm <cite class=\"ltx_cite ltx_citemacro_citep\">(Cantador et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib6\" title=\"\">2011</a>)</cite>, \n(Cantador et\u00a0al., 2011), Nowplaying <cite class=\"ltx_cite ltx_citemacro_citep\">(Poddar, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib31\" title=\"\">2020</a>)</cite>, \n(Poddar, 2020), Retailrocket <cite class=\"ltx_cite ltx_citemacro_citep\">(Retailrocket, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib32\" title=\"\">2023</a>)</cite> and \n(Retailrocket, 2023) and Sketchfab <cite class=\"ltx_cite ltx_citemacro_citep\">(Rosenthal, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib35\" title=\"\">2017</a>)</cite>. The explicit feedback data sets are: \n(Rosenthal, 2017). The explicit feedback data sets are: MovieLens-1M <cite class=\"ltx_cite ltx_citemacro_citep\">(Harper and Konstan, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib22\" title=\"\">2015</a>)</cite>, \n(Harper and Konstan, 2015), MovieLens-100k <cite class=\"ltx_cite ltx_citemacro_citep\">(Harper and Konstan, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib22\" title=\"\">2015</a>)</cite>, and \n(Harper and Konstan, 2015), and MovieTweetings <cite class=\"ltx_cite ltx_citemacro_citep\">(Dooms, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib14\" title=\"\">2021</a>)</cite>.\nAll of the mentioned datasets are five-core pruned, so that every user and item has at least five interactions \n(Dooms, 2021).\nAll of the mentioned datasets are five-core pruned, so that every user and item has at least five interactions <cite class=\"ltx_cite ltx_citemacro_citep\">(Sun et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib37\" title=\"\">2019</a>; Yue et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib44\" title=\"\">2021</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.18011v1#bib.bib45\" title=\"\">2022</a>)</cite>.\nFive-core pruning is necessary to prevent cold start problems with our recommendation algorithms.\nWe convert the explicit datasets into implicit datasets by dropping the rating column.\n(Sun et\u00a0al., 2019; Yue et\u00a0al., 2021, 2022).\nFive-core pruning is necessary to prevent cold start problems with our recommendation algorithms.\nWe convert the explicit datasets into implicit datasets by dropping the rating column.",
            "Our results suggest that <math alttext=\"k\" class=\"ltx_Math\" display=\"inline\" id=\"S6.p2.1.m1.1\">\n  <semantics id=\"S6.p2.1.m1.1a\">\n    <mi id=\"S6.p2.1.m1.1.1\" xref=\"S6.p2.1.m1.1.1.cmml\">k</mi>\n    <annotation-xml encoding=\"MathML-Content\" id=\"S6.p2.1.m1.1b\">\n      <ci id=\"S6.p2.1.m1.1.1.cmml\" xref=\"S6.p2.1.m1.1.1\">&#119896;</ci>\n    </annotation-xml>\n    <annotation encoding=\"application/x-tex\" id=\"S6.p2.1.m1.1c\">k</annotation>\n    <annotation encoding=\"application/x-llamapun\" id=\"S6.p2.1.m1.1d\">italic_k</annotation>\n  </semantics>\n</math>\n<semantics id=\"S6.p2.1.m1.1a\">\n  <mi id=\"S6.p2.1.m1.1.1\" xref=\"S6.p2.1.m1.1.1.cmml\">k</mi>\n  <annotation-xml encoding=\"MathML-Content\" id=\"S6.p2.1.m1.1b\">\n    <ci id=\"S6.p2.1.m1.1.1.cmml\" xref=\"S6.p2.1.m1.1.1\">&#119896;</ci>\n  </annotation-xml>\n  <annotation encoding=\"application/x-tex\" id=\"S6.p2.1.m1.1c\">k</annotation>\n  <annotation encoding=\"application/x-llamapun\" id=\"S6.p2.1.m1.1d\">italic_k</annotation>\n</semantics>\n<mi id=\"S6.p2.1.m1.1.1\" xref=\"S6.p2.1.m1.1.1.cmml\">k</mi>\nk<annotation-xml encoding=\"MathML-Content\" id=\"S6.p2.1.m1.1b\">\n  <ci id=\"S6.p2.1.m1.1.1.cmml\" xref=\"S6.p2.1.m1.1.1\">&#119896;</ci>\n</annotation-xml>\n<ci id=\"S6.p2.1.m1.1.1.cmml\" xref=\"S6.p2.1.m1.1.1\">&#119896;</ci>\n\ud835\udc58<annotation encoding=\"application/x-tex\" id=\"S6.p2.1.m1.1c\">k</annotation>\nk<annotation encoding=\"application/x-llamapun\" id=\"S6.p2.1.m1.1d\">italic_k</annotation>\nitalic_k-Means number of interactions increases the recommendation performance for datasets fulfilling two criteria. First, the dataset contains significantly more items than users. Second, a significant portion of users share about the same number of interactions. We find that <math alttext=\"k\" class=\"ltx_Math\" display=\"inline\" id=\"S6.p2.2.m2.1\">\n  <semantics id=\"S6.p2.2.m2.1a\">\n    <mi id=\"S6.p2.2.m2.1.1\" xref=\"S6.p2.2.m2.1.1.cmml\">k</mi>\n    <annotation-xml encoding=\"MathML-Content\" id=\"S6.p2.2.m2.1b\">\n      <ci id=\"S6.p2.2.m2.1.1.cmml\" xref=\"S6.p2.2.m2.1.1\">&#119896;</ci>\n    </annotation-xml>\n    <annotation encoding=\"application/x-tex\" id=\"S6.p2.2.m2.1c\">k</annotation>\n    <annotation encoding=\"application/x-llamapun\" id=\"S6.p2.2.m2.1d\">italic_k</annotation>\n  </semantics>\n</math>\n<semantics id=\"S6.p2.2.m2.1a\">\n  <mi id=\"S6.p2.2.m2.1.1\" xref=\"S6.p2.2.m2.1.1.cmml\">k</mi>\n  <annotation-xml encoding=\"MathML-Content\" id=\"S6.p2.2.m2.1b\">\n    <ci id=\"S6.p2.2.m2.1.1.cmml\" xref=\"S6.p2.2.m2.1.1\">&#119896;</ci>\n  </annotation-xml>\n  <annotation encoding=\"application/x-tex\" id=\"S6.p2.2.m2.1c\">k</annotation>\n  <annotation encoding=\"application/x-llamapun\" id=\"S6.p2.2.m2.1d\">italic_k</annotation>\n</semantics>\n<mi id=\"S6.p2.2.m2.1.1\" xref=\"S6.p2.2.m2.1.1.cmml\">k</mi>\nk<annotation-xml encoding=\"MathML-Content\" id=\"S6.p2.2.m2.1b\">\n  <ci id=\"S6.p2.2.m2.1.1.cmml\" xref=\"S6.p2.2.m2.1.1\">&#119896;</ci>\n</annotation-xml>\n<ci id=\"S6.p2.2.m2.1.1.cmml\" xref=\"S6.p2.2.m2.1.1\">&#119896;</ci>\n\ud835\udc58<annotation encoding=\"application/x-tex\" id=\"S6.p2.2.m2.1c\">k</annotation>\nk<annotation encoding=\"application/x-llamapun\" id=\"S6.p2.2.m2.1d\">italic_k</annotation>\nitalic_k-Means number of interactions increases the average nDCG@10 across all cluster counts for Nowplaying by 63.07% (0.034). Nowplaying has 47.96% more items than users, and 38.01 average interactions per user (see Table 1). The generated clusters separate the users that have differing number of interactions from the majority of users with a similar number of interactions. Selecting recommendation algorithms for these clusters results in the measured increase in recommendation performance."
        ]
    },
    "S5.T2": {
        "caption": "Table 2. Number of clusters for every resolution of Louvain.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T2.3\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T2.3.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r\" id=\"S5.T2.3.1.1.1\">dataset</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S5.T2.3.1.1.2\">0.8</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S5.T2.3.1.1.3\">0.9</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S5.T2.3.1.1.4\">1</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S5.T2.3.1.1.5\">1.1</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S5.T2.3.1.1.6\">1.2</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T2.3.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T2.3.2.1.1\">Globo</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T2.3.2.1.2\">7</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T2.3.2.1.3\">8</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T2.3.2.1.4\">9</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T2.3.2.1.5\">11</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T2.3.2.1.6\">16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.3.3.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T2.3.3.2.1\">Hetrec-lastfm</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.3.2.2\">6</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.3.2.3\">7</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.3.2.4\">8</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.3.2.5\">8</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.3.2.6\">8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.3.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T2.3.4.3.1\">Nowplaying</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.4.3.2\">10</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.4.3.3\">11</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.4.3.4\">14</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.4.3.5\">16</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.4.3.6\">14</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.3.5.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T2.3.5.4.1\">Retailrocket</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.5.4.2\">20</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.5.4.3\">20</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.5.4.4\">25</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.5.4.5\">26</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.5.4.6\">29</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.3.6.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T2.3.6.5.1\">Sketchfab</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.6.5.2\">22</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.6.5.3\">25</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.6.5.4\">22</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.6.5.5\">27</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.6.5.6\">24</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.3.7.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T2.3.7.6.1\">MovieLens-100k</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.7.6.2\">3</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.7.6.3\">3</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.7.6.4\">4</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.7.6.5\">5</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.7.6.6\">6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.3.8.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T2.3.8.7.1\">MovieLens-1M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.8.7.2\">2</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.8.7.3\">3</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.8.7.4\">5</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.8.7.5\">6</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.8.7.6\">8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.3.9.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T2.3.9.8.1\">MovieTweetings</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.9.8.2\">4</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.9.8.3\">5</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.9.8.4\">6</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.9.8.5\">6</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.3.9.8.6\">8</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Louvain uses resolution as the clustering parameter and generates a varying number of clusters. The datasets MovieLens-100k, MovieLens-1M, Hetrec-lastfm, MovieTweetings are split into a range of three to eight clusters. The datasets Sketchfab, Globo, Retailrocket, Nowplaying are split into seven to 29 clusters (see Table 2).\nLouvain increases the average nDCG@10 over all cluster counts for MovieLens-100k by 1.58% (0.006), Retailrocket by 27.27% (0.018), Sketchfab by 10.00% (0.011), Globo by 20.96% (0.018) and Nowplaying by 122.64% (0.065).\nFor Nowplaying, Louvain increases the nDCG@10 by up to 141.51% (0.075) with eleven clusters (0.9 resolution). Nowplaying has an increase in the nDCG@10 for every cluster count. The datasets that show the most increase are the datasets with a low nDCG@10 for the baseline.\nLouvain increases the nDCG@10 for Globo by an average of 16.57% (0.014) with seven to eleven clusters (0.8 to 1.1 resolution), and by 38.55% (0.032) with 16 clusters (1.2 resolution).\nOut of all datasets, Hetrec-lastfm has the highest average nDCG@10 decrease with 8.86% (0.018) over all cluster counts.\nHetrec-lastfm, MovieLens-1m, MovieTweetings have a similar decrease in nDCG@10."
        ]
    }
}