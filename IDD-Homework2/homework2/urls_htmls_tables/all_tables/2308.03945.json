{
    "PAPER'S NUMBER OF TABLES": 4,
    "S3.T1": {
        "caption": "TABLE I: Generally Parameters of ViT and Resnet",
        "table": "<table id=\"S3.T1.2.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.2.2.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.3.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\"></th>\n<th id=\"S3.T1.2.2.3.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S3.T1.2.2.3.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.3.1.2.1.1\" class=\"ltx_p\" style=\"width:113.8pt;\">ViT(s)</span>\n</span>\n</th>\n<th id=\"S3.T1.2.2.3.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S3.T1.2.2.3.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.3.1.3.1.1\" class=\"ltx_p\" style=\"width:99.6pt;\">ResNet(50)</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.2.2.4.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Params</th>\n<td id=\"S3.T1.2.2.4.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T1.2.2.4.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.4.1.2.1.1\" class=\"ltx_p\" style=\"width:113.8pt;\">22.1 M</span>\n</span>\n</td>\n<td id=\"S3.T1.2.2.4.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T1.2.2.4.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.4.1.3.1.1\" class=\"ltx_p\" style=\"width:99.6pt;\">25.6 M</span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Image Size</th>\n<td id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.1.1.1.1.1.1\" class=\"ltx_p\" style=\"width:113.8pt;\"><math id=\"S3.T1.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"224^{2}\" display=\"inline\"><semantics id=\"S3.T1.1.1.1.1.1.1.m1.1a\"><msup id=\"S3.T1.1.1.1.1.1.1.m1.1.1\" xref=\"S3.T1.1.1.1.1.1.1.m1.1.1.cmml\"><mn id=\"S3.T1.1.1.1.1.1.1.m1.1.1.2\" xref=\"S3.T1.1.1.1.1.1.1.m1.1.1.2.cmml\">224</mn><mn id=\"S3.T1.1.1.1.1.1.1.m1.1.1.3\" xref=\"S3.T1.1.1.1.1.1.1.m1.1.1.3.cmml\">2</mn></msup><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.1.1.1.1.1.1.m1.1b\"><apply id=\"S3.T1.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T1.1.1.1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.T1.1.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S3.T1.1.1.1.1.1.1.m1.1.1\">superscript</csymbol><cn type=\"integer\" id=\"S3.T1.1.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S3.T1.1.1.1.1.1.1.m1.1.1.2\">224</cn><cn type=\"integer\" id=\"S3.T1.1.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S3.T1.1.1.1.1.1.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.1.1.1.1.1.1.m1.1c\">224^{2}</annotation></semantics></math></span>\n</span>\n</td>\n<td id=\"S3.T1.2.2.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.2.2.1.1\" class=\"ltx_p\" style=\"width:99.6pt;\"><math id=\"S3.T1.2.2.2.2.1.1.m1.1\" class=\"ltx_Math\" alttext=\"224^{2}\" display=\"inline\"><semantics id=\"S3.T1.2.2.2.2.1.1.m1.1a\"><msup id=\"S3.T1.2.2.2.2.1.1.m1.1.1\" xref=\"S3.T1.2.2.2.2.1.1.m1.1.1.cmml\"><mn id=\"S3.T1.2.2.2.2.1.1.m1.1.1.2\" xref=\"S3.T1.2.2.2.2.1.1.m1.1.1.2.cmml\">224</mn><mn id=\"S3.T1.2.2.2.2.1.1.m1.1.1.3\" xref=\"S3.T1.2.2.2.2.1.1.m1.1.1.3.cmml\">2</mn></msup><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.2.2.2.2.1.1.m1.1b\"><apply id=\"S3.T1.2.2.2.2.1.1.m1.1.1.cmml\" xref=\"S3.T1.2.2.2.2.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.T1.2.2.2.2.1.1.m1.1.1.1.cmml\" xref=\"S3.T1.2.2.2.2.1.1.m1.1.1\">superscript</csymbol><cn type=\"integer\" id=\"S3.T1.2.2.2.2.1.1.m1.1.1.2.cmml\" xref=\"S3.T1.2.2.2.2.1.1.m1.1.1.2\">224</cn><cn type=\"integer\" id=\"S3.T1.2.2.2.2.1.1.m1.1.1.3.cmml\" xref=\"S3.T1.2.2.2.2.1.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.2.2.2.2.1.1.m1.1c\">224^{2}</annotation></semantics></math></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.2.5.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.5.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Batch Size</th>\n<td id=\"S3.T1.2.2.5.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.5.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.5.2.2.1.1\" class=\"ltx_p\" style=\"width:113.8pt;\">32</span>\n</span>\n</td>\n<td id=\"S3.T1.2.2.5.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.5.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.5.2.3.1.1\" class=\"ltx_p\" style=\"width:99.6pt;\">32</span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.2.6.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.6.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Client Epochs</th>\n<td id=\"S3.T1.2.2.6.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.6.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.6.3.2.1.1\" class=\"ltx_p\" style=\"width:113.8pt;\">1</span>\n</span>\n</td>\n<td id=\"S3.T1.2.2.6.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.6.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.6.3.3.1.1\" class=\"ltx_p\" style=\"width:99.6pt;\">1</span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.2.7.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.7.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Communication Rounds</th>\n<td id=\"S3.T1.2.2.7.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.7.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.7.4.2.1.1\" class=\"ltx_p\" style=\"width:113.8pt;\">100</span>\n</span>\n</td>\n<td id=\"S3.T1.2.2.7.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.7.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.7.4.3.1.1\" class=\"ltx_p\" style=\"width:99.6pt;\">100</span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.2.8.5\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.8.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Aggregation</th>\n<td id=\"S3.T1.2.2.8.5.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.8.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.8.5.2.1.1\" class=\"ltx_p\" style=\"width:113.8pt;\">FedAvg</span>\n</span>\n</td>\n<td id=\"S3.T1.2.2.8.5.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.8.5.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.8.5.3.1.1\" class=\"ltx_p\" style=\"width:99.6pt;\">FedAvg</span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.2.9.6\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.9.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Pre-train</th>\n<td id=\"S3.T1.2.2.9.6.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.9.6.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.9.6.2.1.1\" class=\"ltx_p\" style=\"width:113.8pt;\">ImageNet1k</span>\n</span>\n</td>\n<td id=\"S3.T1.2.2.9.6.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.2.9.6.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.9.6.3.1.1\" class=\"ltx_p\" style=\"width:99.6pt;\">ImageNet1k</span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.2.10.7\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.10.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" rowspan=\"2\"><span id=\"S3.T1.2.2.10.7.1.1\" class=\"ltx_text\">Optimizer</span></th>\n<td id=\"S3.T1.2.2.10.7.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b\">\n<span id=\"S3.T1.2.2.10.7.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.10.7.2.1.1\" class=\"ltx_p\" style=\"width:113.8pt;\">AdamW, lr=1e-5, wd= 0.05, momentum=0.9</span>\n</span>\n</td>\n<td id=\"S3.T1.2.2.10.7.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b\">\n<span id=\"S3.T1.2.2.10.7.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.10.7.3.1.1\" class=\"ltx_p\" style=\"width:99.6pt;\">SGD, lr=0.03, wd= 0.0, momentum=0.9</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In our work, we seek to evaluate and compare the performance of Transformer-based and convolution-based architectures in the above mentioned two scenarios.\nTo this end, we employed two models – ViT(s) and Resnet(50) [37] – each designed with a comparable number of parameters.\nThese models are selected as representatives to enable us to draw conclusions about the two types of architectures.\nIn addition, several specific parameters of ViT and ResNet(50) are listed in Table I (see [20] and references therein)."
        ]
    },
    "S3.T2": {
        "caption": "TABLE II: The Accuracy of ViT and Resnet for Different Number of Participants Under Scenario 1 (S1) and Scenario 2 (S2).",
        "table": "<table id=\"S3.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S3.T2.1.1.1.1.1.1\" class=\"ltx_text\">Participants</span></th>\n<th id=\"S3.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"3\">ViT(s)</th>\n<th id=\"S3.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"3\">ResNet(50)</th>\n</tr>\n<tr id=\"S3.T2.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">S1</th>\n<th id=\"S3.T2.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.2.2.2.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">S2 (500)</span></th>\n<th id=\"S3.T2.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.2.2.3.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">S2 (1000)</span></th>\n<th id=\"S3.T2.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">S1</th>\n<th id=\"S3.T2.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.2.2.5.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">S2 (500)</span></th>\n<th id=\"S3.T2.1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.2.2.6.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">S2 (1000)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.1.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">10</th>\n<td id=\"S3.T2.1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9672</td>\n<td id=\"S3.T2.1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.3.1.3.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.8268</span></td>\n<td id=\"S3.T2.1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.3.1.4.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.9001</span></td>\n<td id=\"S3.T2.1.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9397</td>\n<td id=\"S3.T2.1.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.3.1.6.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.5372</span></td>\n<td id=\"S3.T2.1.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.3.1.7.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.7847</span></td>\n</tr>\n<tr id=\"S3.T2.1.1.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">20</th>\n<td id=\"S3.T2.1.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.9568</td>\n<td id=\"S3.T2.1.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.4.2.3.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.8620</span></td>\n<td id=\"S3.T2.1.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.4.2.4.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.9228</span></td>\n<td id=\"S3.T2.1.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0.9178</td>\n<td id=\"S3.T2.1.1.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.4.2.6.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.4887</span></td>\n<td id=\"S3.T2.1.1.4.2.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.4.2.7.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.7909</span></td>\n</tr>\n<tr id=\"S3.T2.1.1.5.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">50</th>\n<td id=\"S3.T2.1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.9422</td>\n<td id=\"S3.T2.1.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.5.3.3.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.8947</span></td>\n<td id=\"S3.T2.1.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.5.3.4.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.9422</span></td>\n<td id=\"S3.T2.1.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0.7867</td>\n<td id=\"S3.T2.1.1.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.5.3.6.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.4936</span></td>\n<td id=\"S3.T2.1.1.5.3.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.5.3.7.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.7867</span></td>\n</tr>\n<tr id=\"S3.T2.1.1.6.4\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\">100</th>\n<td id=\"S3.T2.1.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">0.9064</td>\n<td id=\"S3.T2.1.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.6.4.3.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.9064</span></td>\n<td id=\"S3.T2.1.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.6.4.4.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.9440</span></td>\n<td id=\"S3.T2.1.1.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S3.T2.1.1.6.4.5.1\" class=\"ltx_text ltx_font_bold\" style=\"color:#FF0000;\">0.4942</span></td>\n<td id=\"S3.T2.1.1.6.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.6.4.6.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.4942</span></td>\n<td id=\"S3.T2.1.1.6.4.7\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"background-color:#E1E1FF;\"><span id=\"S3.T2.1.1.6.4.7.1\" class=\"ltx_text\" style=\"background-color:#E1E1FF;\">0.7818</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "ViTFL Characteristics.\nWe identify the performance characteristics of ViTFL with respect to the number of participants (i.e., the degree of heterogeneity in the training dataset) under Scenario 1 and Scenario 2.\nTo this end, Table II represents the global accuracy results obtained by ViT and ResNet under two experimental scenarios, Scenario 1 and Scenario 2, while varying the number of participants from 101010 to 100100100.\nFrom the results, we observe that for both ViT and ResNet under Scenario 1, the global accuracy decreases, when the number of participants increases.\nHowever, the reduction of the global accuracy for the ResNet network due to increasing the number of participants is more significant, than that for the ViT network.\nMore precisely, the ResNet network experiences a significant decrease in global accuracy of 44.55%percent44.5544.55\\% as the number of participants increases from N=10𝑁10N=10 to N=100𝑁100N=100.\nBy contrast, the ViT model demonstrates robustness as the number of participants increases from N=10𝑁10N=10 to N=100𝑁100N=100, with the global accuracy being maintained at over 90.00%percent90.0090.00\\%.\nEssentially, this phenomenon can be attributed to two factors.\nFirstly, with an increase in the number of participants, there is a reduction in the amount of training data available for each participant, resulting in a decline in the quality of training.\nSecondly, as the number of participants increases, the degree of heterogeneity in the training dataset also increases, further exacerbating the training quality.",
            "To determine the primary factor contributing to the exceptional performance of ViT model, we conducted numerous experiments in Scenario 2.\nFor notational briefly, in the scenario where the volume of data contributed by each participant is 500500500 (100010001000), it is denoted by S2(500) (S2(1000)).\nThe corresponding results are still presented in the purple part of Table II.\nIt is clear from Table II that the ViT model consistently outperforms the ResNet network in both S2(500) and S2(1000).\nIn S2(500), where each participant’s dataset is relatively small, the global accuracy of ResNet exhibits a downward trend.\nHowever, the sensitivity of global accuracy to dataset heterogeneity decreases, as the number of participants increases.\nInterestingly, for the ViT model in S2(500), the global accuracy increases with an increase in the level of dataset heterogeneity, as indicated by the rising values of N𝑁N.\nIn addition, the behaviors of the ViT and ResNet in S2(1000) align with those observed in S2(500), respectively.\nCombining the experimental results under Scenarios 1 and 2, we can infer that the robustness of ViT in dealing with dataset heterogeneity appears to be the primary factor in its superiority over the ResNet.\nBased on our analysis, it reveals that the decrease in available training data to each participant is causing a decrease in performance for both ViT and ResNet in Scenario 1.\nThis in essence attributes to that when the available training data contributed by each participant reduces, the amount of diverse and complex patterns present in the data that the models can learn from also decreases, leading to lower performance.",
            "In Fig. 2, we investigate the convergence speed of the ViT and ResNet in S2(500) and S2(1000) using different number of participants, measured by the test accuracy with respect to the communication rounds.\nAs seen in Fig. 2, for both ViT and ResNet, it is difficult to distinguish the convergence speed for N=10,20,50,100𝑁102050100N=10,20,50,100 under a given scenario (S2(500) or S2(1000)).\nWe reasonably speculate that as the number of participants is increased, the resulting training dataset becomes larger and more heterogeneous.\nAnd the positive and negative effects of increased dataset volume and dataset heterogeneity on model convergence performance may cancel each other out.\nThe results of the ResNet presented in Table II for both S2(500) and S2(1000) provide strong evidence that supports our speculation.",
            "To gain insight into the the performance benefits of ViT(s), we conducted a comparative analysis by evaluating its test accuracy against two existing personalized federated learning methods.\nIn our comparative analysis, ResNet(50) is employed as the backbone network for the existing methods, while for our proposed approach, we utilized ViT(s).\nThis selection was made to ensure a fair comparison between the different methods while also highlighting the unique advantages of using ViT(s) in federated learning scenarios.\nSpecifically, we apply two personalized methods, MOON and FedALA, to the ResNet(50) architecture, specifically designed to enhance the performance of models trained on non-IID datasets.\nIn the following, to simplify notation, the above mentioned comparison approaches are defined as ResNet(50)++MOON and ResNet(50)++FedALA111Here, Table III provides a list of other typical pFL methods along with the reasons for not using them as comparison algorithms., respectively.\nThe temperature coefficient of MOON is 0.50.50.5 and the weighting factor μ𝜇\\mu for contrast loss is 5.\nLikewise, set the sample random proportion(s) and the start of the adaptive layer of FedALA to be 100100100 and 111, respectively, when its threshold is 0.050.050.05.\nAs shown in Table IV, it is observed that the ViT enabled FL outperforms both ResNet(50)++MOON and ResNet(50)++FedALA, and the performance gap between them becomes larger with increasing the number of participants.\nWhen the number of participants is small (N∈{10,20}𝑁1020N\\in\\{10,20\\}), the MOON and FedALA methods exhibit a more pronounced performance improvement effect.\nSpecifically, the FedALA method’s performance improvement is particularly notable when there are 101010 participants involved.\nThe ViT achieves an accuracy that is only 1.05%percent1.051.05\\% higher than that of the FedALA method.\nHowever, as the number of participants increases to 100100100, a sharp decline in performance becomes apparent.\nThe results presented in Table II for the ResNet, as well as Table IV for the ResNet(50)++MOON, and ResNet(50)++FedALA, indicate that the current personalized methods (MOON and FedALA) have limitations in addressing heterogeneous datasets in large-scale federated learning ecosystems."
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: Summary of Personalized Federated Learning Methods",
        "table": "<table id=\"S4.T3.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">Method</th>\n<th id=\"S4.T3.1.1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.1.1.2.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">Core Idea</span>\n</span>\n</th>\n<th id=\"S4.T3.1.1.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.1.1.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">Reasons for Not Conducting A Comparison</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S4.T3.1.1.2.1.1.1\" class=\"ltx_text\">FedBN<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite></span></th>\n<td id=\"S4.T3.1.1.2.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.2.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.2.1.2.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">Keep the local BN parameters not synchronized with the global model.</span>\n</span>\n</td>\n<td id=\"S4.T3.1.1.2.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.2.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.2.1.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">The failure to update the parameters of BN layers can adversely affect the performance of the global model.</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S4.T3.1.1.3.2.1.1\" class=\"ltx_text\">Ditto<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">38</a>]</cite></span></th>\n<td id=\"S4.T3.1.1.3.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.3.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.3.2.2.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">Incorporating personalized objectives into local models can strike a balance between personalized and global model performance.</span>\n</span>\n</td>\n<td id=\"S4.T3.1.1.3.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.3.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.3.2.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">Ditto can result in both more robust and fairer models across a diverse set of attacks.</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S4.T3.1.1.4.3.1.1\" class=\"ltx_text\">MOON<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\">26</a>]</cite></span></th>\n<td id=\"S4.T3.1.1.4.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.4.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.4.3.2.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">Incorporate model-level contrast loss into the local training objective.</span>\n</span>\n</td>\n<td id=\"S4.T3.1.1.4.3.3\" class=\"ltx_td ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"></td>\n</tr>\n<tr id=\"S4.T3.1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S4.T3.1.1.5.4.1.1\" class=\"ltx_text\">FedBABU <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib34\" title=\"\" class=\"ltx_ref\">34</a>]</cite></span></th>\n<td id=\"S4.T3.1.1.5.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.5.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.5.4.2.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">Clients update the body of the model during federated training, and the head is fine-tuned for personalization during the evaluation process.</span>\n</span>\n</td>\n<td id=\"S4.T3.1.1.5.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.5.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.5.4.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">The failure to update the parameters of the model’s head can adversely influence the overall performance of the global model.</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S4.T3.1.1.6.5.1.1\" class=\"ltx_text\">pFedLA<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib39\" title=\"\" class=\"ltx_ref\">39</a>]</cite></span></th>\n<td id=\"S4.T3.1.1.6.5.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.6.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.6.5.2.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">Use a dedicated hypernetwork per client on the server side, which is trained to identify the mutual contribution factors at layer granularity.</span>\n</span>\n</td>\n<td id=\"S4.T3.1.1.6.5.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.6.5.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.6.5.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">At the server end, there exist only hypernetworks without a global model.</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\" rowspan=\"2\"><span id=\"S4.T3.1.1.7.6.1.1\" class=\"ltx_text\">FedALA<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a>]</cite></span></th>\n<td id=\"S4.T3.1.1.7.6.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">\n<span id=\"S4.T3.1.1.7.6.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.7.6.2.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\">Aggregate the global model with the local model using an adaptive local aggregation module.</span>\n</span>\n</td>\n<td id=\"S4.T3.1.1.7.6.3\" class=\"ltx_td ltx_align_top ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "To gain insight into the the performance benefits of ViT(s), we conducted a comparative analysis by evaluating its test accuracy against two existing personalized federated learning methods.\nIn our comparative analysis, ResNet(50) is employed as the backbone network for the existing methods, while for our proposed approach, we utilized ViT(s).\nThis selection was made to ensure a fair comparison between the different methods while also highlighting the unique advantages of using ViT(s) in federated learning scenarios.\nSpecifically, we apply two personalized methods, MOON and FedALA, to the ResNet(50) architecture, specifically designed to enhance the performance of models trained on non-IID datasets.\nIn the following, to simplify notation, the above mentioned comparison approaches are defined as ResNet(50)++MOON and ResNet(50)++FedALA111Here, Table III provides a list of other typical pFL methods along with the reasons for not using them as comparison algorithms., respectively.\nThe temperature coefficient of MOON is 0.50.50.5 and the weighting factor μ𝜇\\mu for contrast loss is 5.\nLikewise, set the sample random proportion(s) and the start of the adaptive layer of FedALA to be 100100100 and 111, respectively, when its threshold is 0.050.050.05.\nAs shown in Table IV, it is observed that the ViT enabled FL outperforms both ResNet(50)++MOON and ResNet(50)++FedALA, and the performance gap between them becomes larger with increasing the number of participants.\nWhen the number of participants is small (N∈{10,20}𝑁1020N\\in\\{10,20\\}), the MOON and FedALA methods exhibit a more pronounced performance improvement effect.\nSpecifically, the FedALA method’s performance improvement is particularly notable when there are 101010 participants involved.\nThe ViT achieves an accuracy that is only 1.05%percent1.051.05\\% higher than that of the FedALA method.\nHowever, as the number of participants increases to 100100100, a sharp decline in performance becomes apparent.\nThe results presented in Table II for the ResNet, as well as Table IV for the ResNet(50)++MOON, and ResNet(50)++FedALA, indicate that the current personalized methods (MOON and FedALA) have limitations in addressing heterogeneous datasets in large-scale federated learning ecosystems."
        ]
    },
    "S4.T4": {
        "caption": "TABLE IV: The accuracy of ViT and Resnet with Personalized Methods for Different Number Participants in Scenario 1.",
        "table": "<table id=\"S4.T4.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\">Participants</th>\n<th id=\"S4.T4.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">ViT</th>\n<th id=\"S4.T4.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">ResNet(50)+MOON</th>\n<th id=\"S4.T4.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">ResNet(50)+FedALA</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">10</th>\n<td id=\"S4.T4.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">0.9672</span></td>\n<td id=\"S4.T4.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9437</td>\n<td id=\"S4.T4.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9567</td>\n</tr>\n<tr id=\"S4.T4.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">20</th>\n<td id=\"S4.T4.1.1.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.1.3.2.2.1\" class=\"ltx_text ltx_font_bold\">0.9568</span></td>\n<td id=\"S4.T4.1.1.3.2.3\" class=\"ltx_td ltx_align_center\">0.9046</td>\n<td id=\"S4.T4.1.1.3.2.4\" class=\"ltx_td ltx_align_center\">0.9181</td>\n</tr>\n<tr id=\"S4.T4.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">50</th>\n<td id=\"S4.T4.1.1.4.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.1.4.3.2.1\" class=\"ltx_text ltx_font_bold\">0.9422</span></td>\n<td id=\"S4.T4.1.1.4.3.3\" class=\"ltx_td ltx_align_center\">0.8301</td>\n<td id=\"S4.T4.1.1.4.3.4\" class=\"ltx_td ltx_align_center\">0.7953</td>\n</tr>\n<tr id=\"S4.T4.1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b\">100</th>\n<td id=\"S4.T4.1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T4.1.1.5.4.2.1\" class=\"ltx_text ltx_font_bold\">0.9064</span></td>\n<td id=\"S4.T4.1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T4.1.1.5.4.3.1\" class=\"ltx_text ltx_font_bold\" style=\"color:#FF0000;\">0.4242</span></td>\n<td id=\"S4.T4.1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T4.1.1.5.4.4.1\" class=\"ltx_text ltx_font_bold\" style=\"color:#FF0000;\">0.4968</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "To gain insight into the the performance benefits of ViT(s), we conducted a comparative analysis by evaluating its test accuracy against two existing personalized federated learning methods.\nIn our comparative analysis, ResNet(50) is employed as the backbone network for the existing methods, while for our proposed approach, we utilized ViT(s).\nThis selection was made to ensure a fair comparison between the different methods while also highlighting the unique advantages of using ViT(s) in federated learning scenarios.\nSpecifically, we apply two personalized methods, MOON and FedALA, to the ResNet(50) architecture, specifically designed to enhance the performance of models trained on non-IID datasets.\nIn the following, to simplify notation, the above mentioned comparison approaches are defined as ResNet(50)++MOON and ResNet(50)++FedALA111Here, Table III provides a list of other typical pFL methods along with the reasons for not using them as comparison algorithms., respectively.\nThe temperature coefficient of MOON is 0.50.50.5 and the weighting factor μ𝜇\\mu for contrast loss is 5.\nLikewise, set the sample random proportion(s) and the start of the adaptive layer of FedALA to be 100100100 and 111, respectively, when its threshold is 0.050.050.05.\nAs shown in Table IV, it is observed that the ViT enabled FL outperforms both ResNet(50)++MOON and ResNet(50)++FedALA, and the performance gap between them becomes larger with increasing the number of participants.\nWhen the number of participants is small (N∈{10,20}𝑁1020N\\in\\{10,20\\}), the MOON and FedALA methods exhibit a more pronounced performance improvement effect.\nSpecifically, the FedALA method’s performance improvement is particularly notable when there are 101010 participants involved.\nThe ViT achieves an accuracy that is only 1.05%percent1.051.05\\% higher than that of the FedALA method.\nHowever, as the number of participants increases to 100100100, a sharp decline in performance becomes apparent.\nThe results presented in Table II for the ResNet, as well as Table IV for the ResNet(50)++MOON, and ResNet(50)++FedALA, indicate that the current personalized methods (MOON and FedALA) have limitations in addressing heterogeneous datasets in large-scale federated learning ecosystems."
        ]
    }
}