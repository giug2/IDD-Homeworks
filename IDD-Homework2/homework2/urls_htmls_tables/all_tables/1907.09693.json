{
    "PAPER'S NUMBER OF TABLES": 3,
    "S4.SS2.12": {
        "caption": "Table 1: Comparison among existing published studies. LM denotes Linear Models. DM denotes Decision Trees. NN denotes Neural Networks. CM denotes Cryptographic Methods. DP denotes Differential Privacy.",
        "table": "<table id=\"S4.SS2.12.12.12\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.SS2.12.12.12.13\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<table id=\"S4.SS2.12.12.12.13.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.SS2.12.12.12.13.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">FL</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.13.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Studies</td>\n</tr>\n</table>\n</td>\n<td id=\"S4.SS2.12.12.12.13.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S4.SS2.12.12.12.13.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.SS2.12.12.12.13.2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">main</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.13.2.1.2\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">area</td>\n</tr>\n</table>\n</td>\n<td id=\"S4.SS2.12.12.12.13.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S4.SS2.12.12.12.13.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.SS2.12.12.12.13.3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">data</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.13.3.1.2\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">partitioning</td>\n</tr>\n</table>\n</td>\n<td id=\"S4.SS2.12.12.12.13.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S4.SS2.12.12.12.13.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.SS2.12.12.12.13.4.1.1\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">model</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.13.4.1.2\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.4.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">implementation</td>\n</tr>\n</table>\n</td>\n<td id=\"S4.SS2.12.12.12.13.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S4.SS2.12.12.12.13.5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.SS2.12.12.12.13.5.1.1\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.5.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">privacy</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.13.5.1.2\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.5.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">mechanism</td>\n</tr>\n</table>\n</td>\n<td id=\"S4.SS2.12.12.12.13.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S4.SS2.12.12.12.13.6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.SS2.12.12.12.13.6.1.1\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.6.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">communication</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.13.6.1.2\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.6.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">architecture</td>\n</tr>\n</table>\n</td>\n<td id=\"S4.SS2.12.12.12.13.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S4.SS2.12.12.12.13.7.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.SS2.12.12.12.13.7.1.1\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.13.7.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">remark</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"S4.SS2.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.SS2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedAvgÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib129\" title=\"\" class=\"ltx_ref\">129</a>]</cite>\n</td>\n<td id=\"S4.SS2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"27\"><span id=\"S4.SS2.1.1.1.1.3.1\" class=\"ltx_text\">\n<span id=\"S4.SS2.1.1.1.1.3.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.SS2.1.1.1.1.3.1.1.1\" class=\"ltx_tr\">\n<span id=\"S4.SS2.1.1.1.1.3.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Effective</span></span>\n<span id=\"S4.SS2.1.1.1.1.3.1.1.2\" class=\"ltx_tr\">\n<span id=\"S4.SS2.1.1.1.1.3.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Algorithms</span></span>\n</span></span></td>\n<td id=\"S4.SS2.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"12\"><span id=\"S4.SS2.1.1.1.1.4.1\" class=\"ltx_text\">horizontal</span></td>\n<td id=\"S4.SS2.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n<td id=\"S4.SS2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"17\"><span id=\"S4.SS2.1.1.1.1.1.1\" class=\"ltx_text ltx_nopad\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.1.1.1.1.1.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.1.1.1.1.1.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.1.1.1.1.1.1.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.1.1.1.1.1.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.1.1.1.1.1.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.1.1.1.1.1.1.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></span></td>\n<td id=\"S4.SS2.1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"16\"><span id=\"S4.SS2.1.1.1.1.6.1\" class=\"ltx_text\">centralized</span></td>\n<td id=\"S4.SS2.1.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"13\"><span id=\"S4.SS2.1.1.1.1.7.1\" class=\"ltx_text\">\n<span id=\"S4.SS2.1.1.1.1.7.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.SS2.1.1.1.1.7.1.1.1\" class=\"ltx_tr\">\n<span id=\"S4.SS2.1.1.1.1.7.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">SGD-based</span></span>\n</span></span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.14\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.14.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedSVRGÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib94\" title=\"\" class=\"ltx_ref\">94</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.14.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.15\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.15.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedProxÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib108\" title=\"\" class=\"ltx_ref\">108</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.15.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.16\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.16.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">SCAFFOLDÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib90\" title=\"\" class=\"ltx_ref\">90</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.16.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.17\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.17.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedNovaÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib190\" title=\"\" class=\"ltx_ref\">190</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.17.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.18\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.18.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Per-FedAvg <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib52\" title=\"\" class=\"ltx_ref\">52</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.18.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.19\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.19.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">pFedMe <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib46\" title=\"\" class=\"ltx_ref\">46</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.19.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.20\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.20.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">IAPGD, AL2SGD+ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">69</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.20.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.21\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.21.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">IFCA <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">61</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.21.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.22\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.22.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Agnostic FLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib134\" title=\"\" class=\"ltx_ref\">134</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.22.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.23\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.23.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedRobust <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib155\" title=\"\" class=\"ltx_ref\">155</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.23.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.24\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.24.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedDF <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib114\" title=\"\" class=\"ltx_ref\">114</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.24.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.25\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.25.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"7\">\n<span id=\"S4.SS2.12.12.12.25.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-2 Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â Â Â Â Â \nFedBCDÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib120\" title=\"\" class=\"ltx_ref\">120</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.25.2\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S4.SS2.12.12.12.25.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">vertical</td>\n<td id=\"S4.SS2.12.12.12.25.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"4\"><span id=\"S4.SS2.12.12.12.25.4.1\" class=\"ltx_text\">NN</span></td>\n<td id=\"S4.SS2.12.12.12.25.5\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S4.SS2.12.12.12.25.6\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S4.SS2.12.12.12.25.7\" class=\"ltx_td ltx_nopad_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.26\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.26.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"7\">\n<span id=\"S4.SS2.12.12.12.26.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>4-6\nPNFM <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib213\" title=\"\" class=\"ltx_ref\">213</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.26.2\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S4.SS2.12.12.12.26.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"2\"><span id=\"S4.SS2.12.12.12.26.3.1\" class=\"ltx_text\">horizontal</span></td>\n<td id=\"S4.SS2.12.12.12.26.4\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S4.SS2.12.12.12.26.5\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S4.SS2.12.12.12.26.6\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"3\"><span id=\"S4.SS2.12.12.12.26.6.1\" class=\"ltx_text\">\n<span id=\"S4.SS2.12.12.12.26.6.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.SS2.12.12.12.26.6.1.1.1\" class=\"ltx_tr\">\n<span id=\"S4.SS2.12.12.12.26.6.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">NN-specialized</span></span>\n</span></span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.27\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.27.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedMA <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib189\" title=\"\" class=\"ltx_ref\">189</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.27.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.27.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.27.4\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.28\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.28.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">SplitNN <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib189\" title=\"\" class=\"ltx_ref\">189</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.28.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">vertical</td>\n<td id=\"S4.SS2.12.12.12.28.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.28.4\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.29\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.29.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"7\">\n<span id=\"S4.SS2.12.12.12.29.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-2 Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â Â Â Â Â \nTree-based FLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib217\" title=\"\" class=\"ltx_ref\">217</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.29.2\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S4.SS2.12.12.12.29.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"4\"><span id=\"S4.SS2.12.12.12.29.3.1\" class=\"ltx_text\">horizontal</span></td>\n<td id=\"S4.SS2.12.12.12.29.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"5\"><span id=\"S4.SS2.12.12.12.29.4.1\" class=\"ltx_text\">DT</span></td>\n<td id=\"S4.SS2.12.12.12.29.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">DP</td>\n<td id=\"S4.SS2.12.12.12.29.6\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"2\"><span id=\"S4.SS2.12.12.12.29.6.1\" class=\"ltx_text\">decentralized</span></td>\n<td id=\"S4.SS2.12.12.12.29.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"5\"><span id=\"S4.SS2.12.12.12.29.7.1\" class=\"ltx_text\">DT-specialized</span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.30\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.30.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">SimFLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib104\" title=\"\" class=\"ltx_ref\">104</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.30.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.30.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.30.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">hashing</td>\n<td id=\"S4.SS2.12.12.12.30.5\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.30.6\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.31\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.31.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"7\">\n<span id=\"S4.SS2.12.12.12.31.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-4\nFedXGBÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib122\" title=\"\" class=\"ltx_ref\">122</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.31.2\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S4.SS2.12.12.12.31.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"7\"><span id=\"S4.SS2.12.12.12.31.3.1\" class=\"ltx_text\">CM</span></td>\n<td id=\"S4.SS2.12.12.12.31.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"16\"><span id=\"S4.SS2.12.12.12.31.4.1\" class=\"ltx_text\">centralized</span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.32\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.32.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedForest <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib121\" title=\"\" class=\"ltx_ref\">121</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.32.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.32.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.32.4\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.32.5\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.32.6\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.33\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.33.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">SecureBoostÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">38</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.33.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">vertical</td>\n<td id=\"S4.SS2.12.12.12.33.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.33.4\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.33.5\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.33.6\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.34\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.34.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"7\">\n<span id=\"S4.SS2.12.12.12.34.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-2<span id=\"S4.SS2.12.12.12.34.1.2\" class=\"ltx_ERROR undefined\">\\cdashline</span>5-6 Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â  Â Â  Â Â Â Â Â Â Â Â \nRidge Regression FLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib141\" title=\"\" class=\"ltx_ref\">141</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.34.2\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S4.SS2.12.12.12.34.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"2\"><span id=\"S4.SS2.12.12.12.34.3.1\" class=\"ltx_text\">horizontal</span></td>\n<td id=\"S4.SS2.12.12.12.34.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"5\"><span id=\"S4.SS2.12.12.12.34.4.1\" class=\"ltx_text\">LM</span></td>\n<td id=\"S4.SS2.12.12.12.34.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\" rowspan=\"4\"><span id=\"S4.SS2.12.12.12.34.5.1\" class=\"ltx_text\">LM-specialized</span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.35\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.35.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">PPRRÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">36</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.35.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.35.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.35.4\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.35.5\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.35.6\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.36\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.36.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Linear Regression FLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib162\" title=\"\" class=\"ltx_ref\">162</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.36.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">vertical</td>\n<td id=\"S4.SS2.12.12.12.36.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.36.4\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.36.5\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.36.6\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.37\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.37.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Logistic Regression FLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib72\" title=\"\" class=\"ltx_ref\">72</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.37.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"32\"><span id=\"S4.SS2.12.12.12.37.2.1\" class=\"ltx_text\">horizontal</span></td>\n<td id=\"S4.SS2.12.12.12.37.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.37.4\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.37.5\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.37.6\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.2.2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.SS2.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.2.2.2.2.2.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-4<span id=\"S4.SS2.2.2.2.2.2.2\" class=\"ltx_ERROR undefined\">\\cdashline</span>6-6\nFederated MTLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib169\" title=\"\" class=\"ltx_ref\">169</a>]</cite>\n</td>\n<td id=\"S4.SS2.2.2.2.2.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.2.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"9\"><span id=\"S4.SS2.2.2.2.2.1.1\" class=\"ltx_text ltx_nopad\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.2.2.2.2.1.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.2.2.2.2.1.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.2.2.2.2.1.1.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.2.2.2.2.1.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.2.2.2.2.1.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.2.2.2.2.1.1.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></span></td>\n<td id=\"S4.SS2.2.2.2.2.4\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.2.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">multi-task learning</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.38\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.38.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.38.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-3<span id=\"S4.SS2.12.12.12.38.1.2\" class=\"ltx_ERROR undefined\">\\cdashline</span>5-6\nFederated Meta-LearningÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">33</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.38.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"3\"><span id=\"S4.SS2.12.12.12.38.2.1\" class=\"ltx_text\">NN</span></td>\n<td id=\"S4.SS2.12.12.12.38.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.38.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.SS2.12.12.12.38.4.1\" class=\"ltx_text\">meta-learning</span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.39\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.39.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Personalized FedAvgÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib81\" title=\"\" class=\"ltx_ref\">81</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.39.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.39.3\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.40\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.40.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.40.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-6\nLFRLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">115</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.40.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.40.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.40.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">reinforcement learning</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.41\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.41.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FBOÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib44\" title=\"\" class=\"ltx_ref\">44</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.41.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.41.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM</td>\n<td id=\"S4.SS2.12.12.12.41.4\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.41.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Bayesian optimization</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.42\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.42.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.42.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>3-3<span id=\"S4.SS2.12.12.12.42.1.2\" class=\"ltx_ERROR undefined\">\\cdashline</span>5-6\nStructure UpdatesÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib95\" title=\"\" class=\"ltx_ref\">95</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.42.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"19\"><span id=\"S4.SS2.12.12.12.42.2.1\" class=\"ltx_text\">\n<span id=\"S4.SS2.12.12.12.42.2.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.SS2.12.12.12.42.2.1.1.1\" class=\"ltx_tr\">\n<span id=\"S4.SS2.12.12.12.42.2.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Practicality</span></span>\n<span id=\"S4.SS2.12.12.12.42.2.1.1.2\" class=\"ltx_tr\">\n<span id=\"S4.SS2.12.12.12.42.2.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Enhancement</span></span>\n</span></span></td>\n<td id=\"S4.SS2.12.12.12.42.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"7\"><span id=\"S4.SS2.12.12.12.42.3.1\" class=\"ltx_text\">NN</span></td>\n<td id=\"S4.SS2.12.12.12.42.4\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.42.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"5\"><span id=\"S4.SS2.12.12.12.42.5.1\" class=\"ltx_text\">\n<span id=\"S4.SS2.12.12.12.42.5.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.SS2.12.12.12.42.5.1.1.1\" class=\"ltx_tr\">\n<span id=\"S4.SS2.12.12.12.42.5.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">efficiency</span></span>\n<span id=\"S4.SS2.12.12.12.42.5.1.1.2\" class=\"ltx_tr\">\n<span id=\"S4.SS2.12.12.12.42.5.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">improvement</span></span>\n</span></span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.43\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.43.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Multi-Objective FLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib226\" title=\"\" class=\"ltx_ref\">226</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.43.2\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.44\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.44.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">On-Device MLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib79\" title=\"\" class=\"ltx_ref\">79</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.44.2\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.45\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.45.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Sparse Ternary CompressionÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib164\" title=\"\" class=\"ltx_ref\">164</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.45.2\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.46\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.46.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.46.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-5\nDPASGDÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib128\" title=\"\" class=\"ltx_ref\">128</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.46.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.46.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">decentralized</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.47\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.47.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.47.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-4\nClient-Level DP FLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib60\" title=\"\" class=\"ltx_ref\">60</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.47.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"3\"><span id=\"S4.SS2.12.12.12.47.2.1\" class=\"ltx_text\">DP</span></td>\n<td id=\"S4.SS2.12.12.12.47.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"23\"><span id=\"S4.SS2.12.12.12.47.3.1\" class=\"ltx_text\">centralized</span></td>\n<td id=\"S4.SS2.12.12.12.47.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"5\"><span id=\"S4.SS2.12.12.12.47.4.1\" class=\"ltx_text\">\n<span id=\"S4.SS2.12.12.12.47.4.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.SS2.12.12.12.47.4.1.1.1\" class=\"ltx_tr\">\n<span id=\"S4.SS2.12.12.12.47.4.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">privacy</span></span>\n<span id=\"S4.SS2.12.12.12.47.4.1.1.2\" class=\"ltx_tr\">\n<span id=\"S4.SS2.12.12.12.47.4.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">guarantees</span></span>\n</span></span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.48\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.48.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FL-LSTMÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib130\" title=\"\" class=\"ltx_ref\">130</a>]</cite>\n</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.49\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.49.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Local DP FLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib20\" title=\"\" class=\"ltx_ref\">20</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.49.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.50\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.50.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Secure Aggregation FLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.50.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n<td id=\"S4.SS2.12.12.12.50.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CM</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.51\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.51.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Hybrid FLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib181\" title=\"\" class=\"ltx_ref\">181</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.51.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, DT, NN</td>\n<td id=\"S4.SS2.12.12.12.51.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CM, DP</td>\n</tr>\n<tr id=\"S4.SS2.3.3.3.3\" class=\"ltx_tr\">\n<td id=\"S4.SS2.3.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.3.3.3.3.2.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-3<span id=\"S4.SS2.3.3.3.3.2.2\" class=\"ltx_ERROR undefined\">\\cdashline</span>6-6\nBackdoor FL <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib16\" title=\"\" class=\"ltx_ref\">16</a>, <a href=\"#bib.bib174\" title=\"\" class=\"ltx_ref\">174</a>, <a href=\"#bib.bib188\" title=\"\" class=\"ltx_ref\">188</a>]</cite>\n</td>\n<td id=\"S4.SS2.3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.SS2.3.3.3.3.3.1\" class=\"ltx_text\">NN</span></td>\n<td id=\"S4.SS2.3.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"13\"><span id=\"S4.SS2.3.3.3.3.1.1\" class=\"ltx_text ltx_nopad\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.3.3.3.3.1.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.3.3.3.3.1.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.3.3.3.3.1.1.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.3.3.3.3.1.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.3.3.3.3.1.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.3.3.3.3.1.1.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></span></td>\n<td id=\"S4.SS2.3.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"6\"><span id=\"S4.SS2.3.3.3.3.4.1\" class=\"ltx_text\">robustness and attacks</span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.52\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.52.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Adversarial Lens <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a>]</cite>\n</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.53\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.53.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Distributed Backdoor <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib203\" title=\"\" class=\"ltx_ref\">203</a>]</cite>\n</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.54\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.54.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Image Reconstruction <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib58\" title=\"\" class=\"ltx_ref\">58</a>]</cite>\n</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.55\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.55.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.55.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-3\nRSA <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib100\" title=\"\" class=\"ltx_ref\">100</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.55.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.56\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.56.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Model Poison <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib53\" title=\"\" class=\"ltx_ref\">53</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.56.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n</tr>\n<tr id=\"S4.SS2.4.4.4.4\" class=\"ltx_tr\">\n<td id=\"S4.SS2.4.4.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.4.4.4.4.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>5-6<span id=\"S4.SS2.4.4.4.4.1.2\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-3\n<math id=\"S4.SS2.4.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"q\" display=\"inline\"><semantics id=\"S4.SS2.4.4.4.4.1.m1.1a\"><mi id=\"S4.SS2.4.4.4.4.1.m1.1.1\" xref=\"S4.SS2.4.4.4.4.1.m1.1.1.cmml\">q</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.SS2.4.4.4.4.1.m1.1b\"><ci id=\"S4.SS2.4.4.4.4.1.m1.1.1.cmml\" xref=\"S4.SS2.4.4.4.4.1.m1.1.1\">ğ‘</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.SS2.4.4.4.4.1.m1.1c\">q</annotation></semantics></math>-FedAvg <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib110\" title=\"\" class=\"ltx_ref\">110</a>]</cite>\n</td>\n<td id=\"S4.SS2.4.4.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n<td id=\"S4.SS2.4.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">fairness</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.57\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.57.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">BlockFLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib93\" title=\"\" class=\"ltx_ref\">93</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.57.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.SS2.12.12.12.57.2.1\" class=\"ltx_text\">LM</span></td>\n<td id=\"S4.SS2.12.12.12.57.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.SS2.12.12.12.57.3.1\" class=\"ltx_text\">incentives</span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.58\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.58.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Reputation FL <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib87\" title=\"\" class=\"ltx_ref\">87</a>]</cite>\n</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.59\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.59.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.59.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>3-3<span id=\"S4.SS2.12.12.12.59.1.2\" class=\"ltx_ERROR undefined\">\\cdashline</span>5-6\nFedCSÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib143\" title=\"\" class=\"ltx_ref\">143</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.59.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"9\"><span id=\"S4.SS2.12.12.12.59.2.1\" class=\"ltx_text\">Applications</span></td>\n<td id=\"S4.SS2.12.12.12.59.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.SS2.12.12.12.59.3.1\" class=\"ltx_text\">NN</span></td>\n<td id=\"S4.SS2.12.12.12.59.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.SS2.12.12.12.59.4.1\" class=\"ltx_text\">edge computing</span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.60\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.60.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">DRL-MECÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib194\" title=\"\" class=\"ltx_ref\">194</a>]</cite>\n</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.61\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.61.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Resource-Constrained MECÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib192\" title=\"\" class=\"ltx_ref\">192</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.61.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.62\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.62.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedGKTÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib73\" title=\"\" class=\"ltx_ref\">73</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.62.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.63\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.63.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.63.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-3<span id=\"S4.SS2.12.12.12.63.1.2\" class=\"ltx_ERROR undefined\">\\cdashline</span>5-6\nFedCFÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">14</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.63.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.SS2.12.12.12.63.2.1\" class=\"ltx_text\">LM</span></td>\n<td id=\"S4.SS2.12.12.12.63.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.63.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">collaborative filter</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.64\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.64.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedMFÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib29\" title=\"\" class=\"ltx_ref\">29</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.64.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.64.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">matrix factorization</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.65\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.65.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.65.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-3<span id=\"S4.SS2.12.12.12.65.1.2\" class=\"ltx_ERROR undefined\">\\cdashline</span>6-6\nFedRecSys <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib177\" title=\"\" class=\"ltx_ref\">177</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.65.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n<td id=\"S4.SS2.12.12.12.65.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CM</td>\n<td id=\"S4.SS2.12.12.12.65.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">recommender system</td>\n</tr>\n<tr id=\"S4.SS2.5.5.5.5\" class=\"ltx_tr\">\n<td id=\"S4.SS2.5.5.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FL KeyboardÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib71\" title=\"\" class=\"ltx_ref\">71</a>]</cite>\n</td>\n<td id=\"S4.SS2.5.5.5.5.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.5.5.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n<td id=\"S4.SS2.5.5.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.SS2.5.5.5.5.1.1\" class=\"ltx_text ltx_nopad\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.5.5.5.5.1.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.5.5.5.5.1.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.5.5.5.5.1.1.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.5.5.5.5.1.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.5.5.5.5.1.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.5.5.5.5.1.1.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></span></td>\n<td id=\"S4.SS2.5.5.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">natural language processing</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.66\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.66.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Fraud detection <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib222\" title=\"\" class=\"ltx_ref\">222</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.66.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.66.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n<td id=\"S4.SS2.12.12.12.66.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">credit card transaction</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.67\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.67.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.67.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>5-5\nFedMLÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib74\" title=\"\" class=\"ltx_ref\">74</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.67.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"10\"><span id=\"S4.SS2.12.12.12.67.2.1\" class=\"ltx_text\">Benchmarks</span></td>\n<td id=\"S4.SS2.12.12.12.67.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S4.SS2.12.12.12.67.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.SS2.12.12.12.67.3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.67.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">horizontal</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.67.3.1.2\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.67.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">&amp;vertical</td>\n</tr>\n</table>\n</td>\n<td id=\"S4.SS2.12.12.12.67.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM, NN</td>\n<td id=\"S4.SS2.12.12.12.67.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S4.SS2.12.12.12.67.5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.SS2.12.12.12.67.5.1.1\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.67.5.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">centralized</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.67.5.1.2\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.67.5.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">&amp;decentralized</td>\n</tr>\n</table>\n</td>\n<td id=\"S4.SS2.12.12.12.67.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.SS2.12.12.12.67.6.1\" class=\"ltx_text\">general purpose benchmarks</span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.68\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.68.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedEval <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib30\" title=\"\" class=\"ltx_ref\">30</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.68.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"9\"><span id=\"S4.SS2.12.12.12.68.2.1\" class=\"ltx_text\">horizontal</span></td>\n<td id=\"S4.SS2.12.12.12.68.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n<td id=\"S4.SS2.12.12.12.68.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">centralized</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.69\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.69.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">OARF <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib77\" title=\"\" class=\"ltx_ref\">77</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.69.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n<td id=\"S4.SS2.12.12.12.69.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CM,DP</td>\n<td id=\"S4.SS2.12.12.12.69.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">centralized</td>\n</tr>\n<tr id=\"S4.SS2.8.8.8.8\" class=\"ltx_tr\">\n<td id=\"S4.SS2.8.8.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Edge AIBench <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib70\" title=\"\" class=\"ltx_ref\">70</a>]</cite>\n</td>\n<td id=\"S4.SS2.6.6.6.6.1\" class=\"ltx_td ltx_nopad ltx_align_center ltx_border_r ltx_border_t\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.6.6.6.6.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.6.6.6.6.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.6.6.6.6.1.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.6.6.6.6.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.6.6.6.6.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.6.6.6.6.1.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></td>\n<td id=\"S4.SS2.7.7.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"7\"><span id=\"S4.SS2.7.7.7.7.2.1\" class=\"ltx_text ltx_nopad\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.7.7.7.7.2.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.7.7.7.7.2.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.7.7.7.7.2.1.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.7.7.7.7.2.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.7.7.7.7.2.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.7.7.7.7.2.1.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></span></td>\n<td id=\"S4.SS2.8.8.8.8.3\" class=\"ltx_td ltx_nopad ltx_align_center ltx_border_r ltx_border_t\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.8.8.8.8.3.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.8.8.8.8.3.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.8.8.8.8.3.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.8.8.8.8.3.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.8.8.8.8.3.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.8.8.8.8.3.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.70\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.70.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.12.12.12.70.1.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-3<span id=\"S4.SS2.12.12.12.70.1.2\" class=\"ltx_ERROR undefined\">\\cdashline</span>5-5\nPerfEval <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib142\" title=\"\" class=\"ltx_ref\">142</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.70.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"3\"><span id=\"S4.SS2.12.12.12.70.2.1\" class=\"ltx_text\">NN</span></td>\n<td id=\"S4.SS2.12.12.12.70.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"3\"><span id=\"S4.SS2.12.12.12.70.3.1\" class=\"ltx_text\">centralized</span></td>\n<td id=\"S4.SS2.12.12.12.70.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.SS2.12.12.12.70.4.1\" class=\"ltx_text\">targeted benchmarks</span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.71\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.71.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedReID <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib227\" title=\"\" class=\"ltx_ref\">227</a>]</cite>\n</td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.72\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.72.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">semi-supervised benchmark <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib216\" title=\"\" class=\"ltx_ref\">216</a>]</cite>\n</td>\n</tr>\n<tr id=\"S4.SS2.10.10.10.10\" class=\"ltx_tr\">\n<td id=\"S4.SS2.10.10.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">non-IID benchmark <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib117\" title=\"\" class=\"ltx_ref\">117</a>]</cite>\n</td>\n<td id=\"S4.SS2.9.9.9.9.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.SS2.9.9.9.9.1.1\" class=\"ltx_text ltx_nopad\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.9.9.9.9.1.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.9.9.9.9.1.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.9.9.9.9.1.1.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.9.9.9.9.1.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.9.9.9.9.1.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.9.9.9.9.1.1.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></span></td>\n<td id=\"S4.SS2.10.10.10.10.2\" class=\"ltx_td ltx_nopad ltx_align_center ltx_border_r ltx_border_t\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.10.10.10.10.2.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.10.10.10.10.2.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.10.10.10.10.2.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.10.10.10.10.2.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.10.10.10.10.2.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.10.10.10.10.2.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></td>\n</tr>\n<tr id=\"S4.SS2.11.11.11.11\" class=\"ltx_tr\">\n<td id=\"S4.SS2.11.11.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"S4.SS2.11.11.11.11.2.1\" class=\"ltx_ERROR undefined\">\\cdashline</span>2-5\nLEAFÂ <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite>\n</td>\n<td id=\"S4.SS2.11.11.11.11.1\" class=\"ltx_td ltx_nopad ltx_align_center ltx_border_r\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.11.11.11.11.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.11.11.11.11.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.11.11.11.11.1.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.11.11.11.11.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.11.11.11.11.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.11.11.11.11.1.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></td>\n<td id=\"S4.SS2.11.11.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">centralized</td>\n<td id=\"S4.SS2.11.11.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.SS2.11.11.11.11.4.1\" class=\"ltx_text\">datasets</span></td>\n</tr>\n<tr id=\"S4.SS2.12.12.12.12\" class=\"ltx_tr\">\n<td id=\"S4.SS2.12.12.12.12.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Street Dataset <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib124\" title=\"\" class=\"ltx_ref\">124</a>]</cite>\n</td>\n<td id=\"S4.SS2.12.12.12.12.3\" class=\"ltx_td ltx_border_b ltx_border_r\"></td>\n<td id=\"S4.SS2.12.12.12.12.1\" class=\"ltx_td ltx_nopad ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><svg version=\"1.1\" height=\"0\" width=\"0\" overflow=\"visible\"><g transform=\"translate(0,0) scale(1,-1)\"><path d=\"M 0,0 0,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.12.12.12.12.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.12.12.12.12.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.SS2.12.12.12.12.1.pic1.1.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,1.383700013837) scale(1, -1)\"><foreignobject width=\"1.383700013837\" height=\"1.383700013837\" overflow=\"visible\">\n<span id=\"S4.SS2.12.12.12.12.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.SS2.12.12.12.12.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.SS2.12.12.12.12.1.pic1.2.1.1.1\" class=\"ltx_p\"></span>\n</span>\n</span></foreignobject></g></g></g></svg></td>\n</tr>\n</table>\n\n",
        "footnotes": "While some algorithms are based on SGD, the other algorithms are specially designed for one or several kinds of model architectures. Thus, we classify them into SGD-based algorithms and model specialized algorithms accordingly.If we consider the local data on a party as a single batch, SGD can be easily implemented in a federated setting by performing a single batch gradient calculation each round (i.e., FedSGD [129]). However, such method may require a large number of communication rounds to converge. To reduce the number of communication rounds, FedAvgÂ [129], as introduced in Section 2.3.3 and Figure 1a of the main paper, is now a typical and practical FL framework based on SGD. In FedAvg, each party conducts multiple training rounds with SGD on its local model. Then, the weights of the global model are updated as the mean of weights of the local models. The global model is sent back to the parties to finish a global iteration. By averaging the weights, the local parties can take multiple steps of gradient descent on their local models, so that the number of communication rounds can be reduced compared with FedSGD.KoneÄná»³ etÂ al. [94] propose federated SVRG (FSVRG). The major difference between federated SVRG and federated averaging is the way to update parameters of the local model and global model (i.e., step 2 and step 4). The formulas to update the model weights are based on stochastic variance reduced gradient (SVRG)Â [82] and distributed approximate newton algorithm (DANE) in federated SVRG. They compare their algorithm with the other baselines like CoCoA+Â [126] and simple distributed gradient descent. Their method can achieve better accuracy with the same communication rounds for the logistic regression model. There is no comparison between federated averaging and federated SVRG.A key challenge in federated learning is the heterogeneity of local data (i.e., non-IID data) [106], which can degrade the performance of federated learning a lot [108, 90, 111]. Since the local models are updated towards their local optima, which are far from each other due to non-IID data, the averaged global model may also far from the global optima. To address the challenge,Â Li etÂ al. [108] propose FedProx. Since too many local updates may lead the averaged model far from the global optima, FedProx introduces an additional proximal term in the local objective to limit the amount of local changes. Instead of directly limiting the size of local updates, SCAFFOLD [90] applies the variance reduction technique to correct the local updates. While FedProx and SCAFFOLD improve the local training stage of FedAvg, FedNova [190] improves the aggregation stage of FedAvg. It takes the heterogeneous local updates of each party into consideration and normalizes the local models according to the local updates before averaging.The above studiesâ€™ objective is to minimize the loss on the whole training dataset under the non-IID data setting. Another solution is to design personalized federated learning algorithms, where the aim is that each party learns a personalized model which can perform well on its local data. Per-FedAvg [52] applies the idea of model-agnostic meta-learning [55] framework in FedAvg. pFedMe [46] uses Moreau envelope to help decompose the personalized model optimization. Hanzely etÂ al. [69] establish the lower bound for the communication complexity and local oracle complexity of the personalized federated learning optimization. Moreover, they apply accelerated proximal gradient descent (APGD) and accelerated L2SGD+ [68], which can achieve optimal complexity bound. IFCA [61] assumes that the parties are partitioned into clusters by the local objectives. The idea is to alternatively minimize the loss functions while estimating the cluster identities.Another research direction related to the non-IID data setting is to design robust federated learning against possible combinations of the local distributions. Mohri etÂ al. [134] propose a new framework named agnostic FL. Instead of minimizing the loss with respect to the average distribution among the data distributions from local clients, they try to train a centralized model optimized for any possible target distribution formed by a mixture of the client distributions. FedRobust [155] considers a structured affine distribution shifts. It proposes gradient descent ascent method to solve the distributed minimax optimization problem.While the above studies consider the heterogeneity of data, the heterogeneity of the local models may also exist in federated learning. The parties can train models with different architectures. FedDF [114] utilizes knowledge distillation [75] to aggregate the local models. It assumes a public dataset exists on the server-side, which can be used to extract the knowledge of the local models and update the global model.There are few studies on SGD-based vertical federated learning. [120] propose the Federated Stochastic Block Coordinate Descent (FedBCD) for vertical FL. By applying coordinate descent, each party updates its local parameter for multiple rounds before communicating the intermediate results. They also provide convergence analysis for FedBCD. Hu etÂ al. [78] propose FDML for vertical FL assuming all parties have the labels. Instead of exchanging the intermediate results, it aggregates the local prediction from each of the participated party.Although neural networks can be trained using the SGD optimizer, we can potentially increase the model utility if the model architecture can also be exploited.Â Yurochkin etÂ al. [213] develop probabilistic federated neural matching (PFNM) for multilayer perceptrons by applying Bayesian nonparametric machineryÂ [59]. They use an Beta-Bernoulli process informed matching procedure to combine the local models into a federated global model. The experiments show that their approach can outperform FedAvg on both IID and non-IID data partitioning.Wang etÂ al. [189] show how to apply PFNM to CNNs (convolutional neural networks) and LSTMs (long short-term memory networks). Moreover, they propose Federated Matched Averaging (FedMA) with a layer-wise matching scheme by exploting the model architecture. Specifically, they use matched averaging to update a layer of the global model each time, which also reduces the communication size. The experiments show that FedMA performs better than FedAvg and FedProx [108] on CNNs and LSTMs.Another study for vertical federated learning on neural networks is split learning [184]. Vepakomma etÂ al. [184] propose a novel paradigm named SplitNN, where a neural network is divided into two parts. Each participated party just need to train a few layers of the network, then the output at the cut layer are transmitted to the party who has label and completes the rest of the training.Besides neural networks, decision trees are also widely used in the academic and industryÂ [34, 92, 54, 105]. Compared with NNs, the training and inference of trees are highly efficient. However, the tree parameters cannot be directly optimized by SGD, which means that SGD-based FL frameworks are not applicable to learn trees. We need specialized frameworks for trees. Among the tree models, the Gradient Boosting Decision Tree (GBDT) modelÂ [34] is quite popular. There are several studies on federated GBDT.There are some studies on horizontal federated GBDTs. Zhao etÂ al. [217] propose the first FLS for GBDTs. In their framework, each decision tree is trained locally without the communications between parties. The trees trained in a party are sent to the next party to continuous train a number of trees. Differential privacy is used to protect the decision trees.\nLi etÂ al. [104] exploit similarity information in the building of federated GBDTs by using locality-sensitive hashingÂ [45]. They utilize the data distribution of local parties by aggregating gradients of similar instances. Within a weaker privacy model compared with secure multi-party computation, their approach is effective and efficient.\nLiu etÂ al. [122] propose a federated extreme boosting learning framework for mobile crowdsensing. They adopted secret sharing to achieve privacy-preserving learning of GBDTs.Liu etÂ al. [121] propose Federated Forest, which enables training random forests in the vertical FL setting. In the building of each node, the party with the corresponding split feature is responsible for splitting the samples and sharing the results. They encrypt the communicated data to protect privacy. Their approach is as accurate as the non-federated version.Cheng etÂ al. [38] propose SecureBoost, a framework for GBDTs in the vertical FL setting. In their assumption, only one party has the label information. They used the entity alignment technique to get the common data and then build the decision trees. Additively homomorphic encryption is used to protect the gradients.Linear/logistic regression can be achieved using SGD. Here we show the studies that are not SGD-based and specially designed for linear/logistic regression.In the horizontal FL setting, Nikolaenko etÂ al. [141] propose a system for privacy-preserving ridge regression. Their approaches combine both homomorphic encryption and Yaoâ€™s garbled circuit to achieve privacy requirements. An extra evaluator is needed to run the algorithm.\nChen etÂ al. [36] propose a system for privacy-preserving ridge regression. Their approaches combine both secure summation and homomorphic encryption to achieve privacy requirements. They provided a complete communication and computation overhead comparison among their approach and the previous state-of-the-art approaches.In the vertical FL setting, Sanil etÂ al. [162] present a secure regression model. They focus on the linear regression model and secret sharing is applied to ensure privacy in their solution.\nHardy etÂ al. [72] present a solution for two-party vertical federated logistic regression. They apply entity resolution and additively homomorphic encryption.There are many studies that combine FL with other machine learning techniques such as multi-task learningÂ [157], meta-learningÂ [55], reinforcement learningÂ [133], and transfer learningÂ [147].Smith etÂ al. [169] combine FL with multi-task learningÂ [26, 215]. Their method considers the issues of high communication cost, stragglers, and fault tolerance for MTL in the federated environment.\nCorinzia and Buhmann [43] propose a federated MTL method with non-convex models. They treated the central server and the local parties as a Bayesian network and the inference is performed using variational methods.Chen etÂ al. [33] adopt meta-learning in the learning process of FedAvg. Instead of training the local NNs and exchanging the model parameters, the parties adopt the Model-Agnostic Meta-Learning (MAML)Â [55] algorithm in the local training and exchange the gradients of MAML.\nJiang etÂ al. [81] interpret FedAvg in the light of existing MAML algorithms. Furthermore, they apply Reptile algorithmÂ [139] to fine-tune the global model trained by FedAvg. Their experiments show that the meta-learning algorithm can improve the effectiveness of the global model.Liu etÂ al. [115] propose a lifelong federated reinforcement learning framework. Adopting transfer learning techniques, a global model is trained to effectively remember what the robots have learned in reinforcement learning.Dai etÂ al. [44] considers Bayesian optimization in FL. They propose federated Thompson sampling to address the communication efficiency and heterogeneity of the clients. Their approach can potentially be used in the parameter search in federated learning.Another issue in FL is the package loss or party disconnection during FL process, which usually happens on mobile devices. When the number of failed messages is small, the server can simply ignore them as they have a small weight on the updating of the global model. If the party failure is significant, the server can restart from the results of the previous round [24]. We look forward to more novel solutions to deal with the disconnection issue for effectiveness improvement.We summarize the above studies as follows.As the SGD-based framework has been widely studied and used, more studies focus on model specialized FL recently. We expect to achieve better model accuracy by using model specialized methods. Moreover, we encourage researchers to study on federated decision trees models. The tree models have a small model size and are easy to train compared with neural networks, which can result in a low communication and computation overhead in FL.The study on FL is still on a early stage. Few studies have been done on appling FL to train the state-of-the-art neural networks such as ResNeXt [127] and EfficientNet [178]. How to design an effective and practical algorithm to train a complex machine learning model is still a challenging and on-going research direction.While most studies focus on horizontal FL, there is still no well developed algorithm for vertical FL. However, the vertical federated setting is common in real world applications where multiple organizations are involved. We look forward to more studies on this promising area.While the computation of FL can be accelerated using modern hardware and techniquesÂ [123, 101, 102] in high performance computing communityÂ [197, 199], the FL studies mainly work on reducing the communication size during the FL process.KoneÄná»³ etÂ al. [95] propose two ways, structured updates and sketched updates, to reduce the communication costs in federated averaging. The first approach restricts the structure of local updates and transforms it to the multiplication of two smaller matrices. Only one small matrix is sent during the learning process. The second approach uses a lossy compression method to compress the updates. Their method can reduce the communication cost by two orders of magnitude with a slight degradation in convergence speed.\nZhu and Jin [226] design a multi-objective evolutionary algorithm to minimize the communication costs and global model test errors simultaneously. Considering the minimization of the communication cost and the maximization of the global learning accuracy as two objectives, they formulated FL as a bi-objective optimization problem and solve it by the multi-objective evolutionary algorithm.\nJeong etÂ al. [79] propose a FL framework for devices with non-IID local data. They design federated distillation, whose communication size depends on the output dimension but not on the model size. Also, they propose a data augmentation scheme using a generative adversarial network (GAN) to make the training dataset become IID. Many other studies also design specialize approach for non-IID dataÂ [221, 111, 118, 210].\nSattler etÂ al. [164] propose a new compression framework named sparse ternary compression (STC). Specifically, STC compresses the communication using sparsification, ternarization, error accumulation, and optimal Golomb encoding. Their method is robust to non-IID data and large numbers of parties.Beside the communication size, the communication architecture can also be improved to increase the training efficiency. Marfoq etÂ al. [128] consider the topology design for cross-silo federated learning. They propose an approach to find a throughput-optimal topology, which can significantly reduce the training time.Although the original data is not exchanged in FL, the model parameters can also leak sensitive information about the training data [167, 137, 196]. Thus, it is important to provide privacy guarantees for the exchanged local updates.Differential privacy is a popular method to provide privacy guarantees. Geyer etÂ al. [60] apply differential privacy in federated averaging from a client-level perspective. They use the Gaussian mechanism to distort the sum of updates of gradients to protect a whole clientâ€™s dataset instead of a single data point.\nMcMahan etÂ al. [130] deploy federated averaging in the training of LSTM. They also use client-level differential privacy to protect the parameters.\nBhowmick etÂ al. [20] apply local differential privacy to protect the parameters in FL. To increase the model quality, they consider a practical threat model that wishes to decode individualsâ€™ data but has little prior information on them. Within this assumption, they can better utilize the privacy budget.Bonawitz etÂ al. [23] apply secure multi-party computation to protect the local parameters on the basis of federated averaging. Specifically, they present a secure aggregation protocol to securely compute the sum of vectors based on secret sharing [165]. They also discuss how to combine differential privacy with secure aggregation.Truex etÂ al. [181] combine both secure multiparty computation and differential privacy for privacy-preserving FL. They use differential privacy to inject noises to the local updates. Then the noisy updates will be encrypted using the Paillier cryptosystemÂ [146] before sent to the central server.For the attacks on FL, one kind of popular attack is backdoor attack, which aims to achieve a bad global model by exchanging malicious local updates.Bagdasaryan etÂ al. [16] conduct model poisoning attack on FL. The malicious parties commit the attack models to the server so that the global model may overfit with the poisoned data. The secure multi-party computation cannot prevent such attack since it aims to protect the confidentiality of the model parameters.\nBhagoji etÂ al. [19] also study the model poisoning attack on FL. Since the averaging step will reduce the effect of the malicious model, it adopts an explicit boosting way to increase the committed weight update.\nSun etÂ al. [174] conduct experiments to evaluate backdoor attacks and defenses for federated learning on federated EMNIST dataset to see what factors can affect the performance of adversary. They find that in the absence of defenses, the performance of the attack largely depends on the fraction of adversaries presented and the â€complexityâ€ of the targeted task. The more backdoor tasks we have, the harder it is to backdoor a ï¬xed-capacity model while maintaining its performance on the main task. Wang etÂ al. [188] discuss the backdoor attack from a theoretical view and prove that it is feasible in FL. They also propose a new class of backdoor attacks named edge-case backdoors, which are resistant to the current defending methods. Xie etÂ al. [203] propose a distributed backdoor attack on FL. They decompose the global trigger pattern into local patterns. Each adversarial party only employs one local pattern. The experiments show that their distributed backdoor attack outperforms the central backdoor attack.Another kind of attack is the Byzantine-attacks, where adversaries fully control some authenticated devices and behave arbitrarily to disrupt the network. There have been some existing robust aggregation rules in distributed learning such as Kâ€‹râ€‹uâ€‹mğ¾ğ‘Ÿğ‘¢ğ‘šKrum [21] and Bulyan [132]. These rules can be directly applied in federated learning. However, since each party conduct multiple local update steps in federated learning, it is interesting to investigate the Byzantine attacks and defenses in federated learning. Li etÂ al. [100] propose RSA, a Byzantine-robust stochastic aggregation method for federated learning on non-IID data setting. Fang etÂ al. [53] propose model poison attacks for byzantine-robust federated learning approaches. The goal of their approach is to modify the local models such that the global model deviates the most towards the inverse of the correct update direction. Another line of study about FL attack are the inference attacks. There are existing studies for the inferences attack [56, 167, 137] on the machine learning model trained in a centralized setting. For the federated setting, Geiping etÂ al. [58] show that it is possible to reconstruct the training images from the knowledge of the exchanged gradients.By taking fairness into consideration based on FedAvg,Â Li etÂ al. [110] propose qğ‘q-FedAvg. Specifically, they define the fairness according to the variance of the performance of the model on the parties. If such variance is smaller, then the model is more fair. Thus, they design a new objective inspired by Î±ğ›¼\\alpha-fairnessÂ [13]. Based on federated averaging, they propose qğ‘q-FedAvg to solve their new objective. The major difference between qğ‘q-FedAvg with FedAvg is in the formulas to update model parameters.Kim etÂ al. [93] combine blockchain architecture with FL. On the basis of federated averaging, they use a blockchain network to exchange the devicesâ€™ local model updates, which is more stable than a central server and can provide the rewards for the devices. Kang etÂ al. [87] designed a reputation-based worker selection scheme for reliable FL by using a multi-weight subjective logic model. They also leverage the blockchain to achieve secure reputation management for workers with non-repudiation and tamper-resistance properties in a decentralized manner.According to the review above, we summarize the studies in Section 4.2.2 to Section 4.2.4 as follows.Besides effectiveness, efficiency and privacy are the other two important factors of an FLS. Compared with these three areas, there are fewer studies on fairness and incentive mechanisms. We look forward to more studies on fairness and incentive mechanisms, which can encourage the usage of FL in the real world.For the efficiency improvement of FLSs, the communication overhead is still the main challenge. Most studies [95, 79, 164] try to reduce the communication size of each iteration. How to reasonably set the number of communication rounds is also promising [226]. The trade-off between the computation and communication still needs to be further investigated.For the privacy guarantees, differential privacy and secure multi-party computation are two popular techniques. However, differential privacy may impact the model quality significantly and secure multi-party computation may be very time-consuming. It is still challenging to design a practical FLS with strong privacy guarantees. Also, the effective robust algorithms against poisoning attacks are not widely adopted yet.One related area with FL is edge computing [140, 212, 153, 47, 218], where the parties are edge devices. Many studies try to integrate FL with the mobile edge systems. FL also shows promising results in recommender system [14, 29, 225], natural language processing [71] and transaction fraud detection [222].Nishio and Yonetani [143] implement federated averaging in practical mobile edge computing (MEC) frameworks. They use an operator of MEC framworks to manage the resources of heterogeneous clients. Wang etÂ al. [194] adopt both distributed deep reinforcement learning (DRL) and federatd learning in mobile edge computing system. The usage of DRL and FL can effectively optimize the mobile edge computing, caching, and communication. Wang etÂ al. [192] perform FL on resource-constrained MEC systems. They address the problem of how to efficiently utilize the limited computation and communication resources at the edge. Using federated averaging, they implement many machine learning algorithms including linear regression, SVM, and CNN. He etÂ al. [73] also consider the limited computing resources in the edge devices. They propose FedGKT, where each device only trains a small part of a whole ResNet to reduce the computation overhead.Ammad-ud din etÂ al. [14] formulate the first federated collaborative filter method. Based on a stochastic gradient approach, the item-factor matrix is trained in a global server by aggregating the local updates. They empirically show that the federated method has almost no accuracy loss compared with the centralized method. Chai etÂ al. [29] design a federated matrix factorization framework. They use federated SGD to learn the matrices. Moreover, they adopt homomorphic encryption to protect the communicated gradients. Tan etÂ al. [177] build a federated recommender system (FedRecSys) based on FATE. FedRecSys has implemented popular recommendation algorithms with SMC protocols. The algorithms include matrix factorization, singular value decomposition, factorization machine, and deep learning.Hard etÂ al. [71] apply FL in mobile keyboard next-word prediction. They adopt the federated averaging method to learn a variant of LSTM called Coupled Input and Forget Gate (CIFG) [65]. The FL method can achieve better precision recall than the server-based training with log data.Zheng etÂ al. [222] introduce FL into the field of fraud detection on credit card transaction. They design a novel meta-learning based federated learning framework, named deep K-tuplet network, which not only guarantees data privacy but also achieves a significantly higher performance compared with the existing approaches.According to the above studies, we have the following summaries.Edge computing naturally fits the cross-device federated setting. A nontrivial issue of applying FL to edge computing is how to effectively utilize and manage the edge resources. The usage of FL can bring benefits to users, especially for improving mobile device services.FL can solve many traditional machine learning tasks such as image classification and work prediction. Due to the regulations and â€œdata islandsâ€, the federated setting may be a common setting in the next years. With the fast development of FL, we believe that there will be more applications in computer vision, natural language processing, and healthcare.Benchmark is important for directing the development of FLSs. Multiple benchmark-related works have been conducted recently, and several benchmark frameworks are available online. We categorize them into three types: 1) General purpose benchmark systems aim at comprehensively evaluate FLSs and give a detailed characterization of different aspects of FLSs; 2) Targeted benchmarks aim at one or more aspects that concentrated in a small domain and tries to optimize the performance of the system in that domain; 3) Dataset benchmarks aim at providing dedicated datasets for federated learning.FedMLÂ [74] is a research library that provides both frameworks for federated learning and benchmark functionalities. As a benchmark, it provides comprehensive baseline implementations for multiple ML models and FL algorithms, including FedAvg, FedNAS, Vertical FL, and split learning. Moreover, it supports three computing paradigms, namely distributed training, mobile on-device training, and standalone simulation. Although some of its experiment results are currently still at a preliminary stage, it is one of the most comprehensive benchmark frameworks concerning its functionalities.FedEvalÂ [30] is another evaluation model for federated learning. It features the â€œACTPRâ€ model, i.e., using accuracy, communication, time consumption, privacy and robustness as its evaluation targets. It utilizes Docker containers to provide an isolated evaluation environment to work around the hardware resource limitation problem, and simulated up to 100 clients in the implementation. Currently, two horizontal algorithms are supported: FedSGD and FedAvg, and the models including MLP and LeNet are tested.OARFÂ [77] provides a set of utilities and reference implementations for FL benchmarks. It features the measurement of different components in FLSs, including FL algorithms, encryption mechanisms, privacy mechanisms, and communication methods. In addition, it also features realistic partitioning of datasets, which utilizes public datasets collected from different sources to reflect real-world data distributions. Both horizontal vertical algorithms are tested.Edge AIBenchÂ [70] provides a testbed for federated learning applications, and models four application scenarios as reference implementations: ICU patients monitor, surveillance camera, smart home, and autonomous vehicles. The implementation is open sourced, but no experiment result has been reported currently.Nilsson etÂ al. [142] propose a method utilizing correlated t-test to compare between different types of federated learning algorithms while bypassing the influence of data distributions. Three FL algorithms, FedAvg, FedSVRGÂ [95] and CO-OPÂ [195] are compared in both IID and non-IID setup in their work, and the result shows that FedAvg achieves the highest accuracy among the three algorithms regardless of how data is partitioned.Zhuang etÂ al. [227] utilize benchmark analysis to improve the performance of federated person re-identification. The benchmark part uses 9 different datasets to simulate real-world situations and uses federated partial averaging, an algorithm that allows the aggregation of partially different models, as the reference implementations.Zhang etÂ al. [216] present a benchmark targeted at semi-supervised federated learning setting, where users only have unlabelled data, and the server only has a small amount of labelled data, and explore the relation between final model accuracy and multiple metrics, including the distribution of the data, the algorithm and communication settings, and the number of clients. Utilizing the experiment results, their semi-supervised learning improved method achieves better generalization performance.Liu etÂ al. [117] focus on the non-IID problem, where datasets are distributed unevenly across the participating parties. Their work explores methods for quantitatively describing the skewness of the data distribution, and propose several non-IID dataset generation approaches.LEAFÂ [25] is one of the earliest dataset proposals for federated learning. It contains six datasets covering different domains, including image classification, sentiment analysis, and next-character prediction. A set of utilities is provided to divide datasets into different parties in an IID or non-IID way. For each dataset, a reference implementation is also provided to demonstrate the usage of that dataset in the training process.Luo etÂ al. [124] present real-world image datasets which are collected from 26 different street cameras. Images in that dataset contain objects of 7 different categories and are suitable for the object detection task. Implementations with federated averaging running YOLOv3 model and Faster R-CNN model are provided as references.Summarizing the studies above, we have the following discoveriesBenchmarks serve an important role in the development of federated learning. Through different types of benchmarks, we can quantitatively characterize the different components and aspects of federated learning. Benchmarks regarding the security and privacy issues in federated learning are still at an early stage and require further development.Currently no comprehensive enough benchmark system has been implemented to cover all the algorithms or application types in FLSs. Even the most comprehensive benchmark systems lack supports for certain algorithms and evaluation metrics for each level of the system. Further development of comprehensive benchmark systems requires the support of extensive FL frameworks.Most benchmark researches are using datasets which are split from a single dataset, and there is no consensus on what type of splitting method should be used. Similarly, regarding the non-IID problem, there is no consensus on the metric of non-IID-ness. Using realistic partitioning method, as proposed in FedMLÂ [74] and OARFÂ [77] may mitigate this issue, but for federated learning at a large-scale, realistic partitioning is not suitable due to the difficulty of collecting data from different sources.In this section, we introduce five open source FLSs: Federated AI Technology Enabler (FATE)333https://github.com/FederatedAI/FATE, Google TensorFlow Federated (TFF)444https://github.com/tensorflow/federated, OpenMined PySyft555https://github.com/OpenMined/PySyft, Baidu PaddleFL666https://github.com/PaddlePaddle/PaddleFL, and\nFedML777https://github.com/FedML-AI/FedML.FATE is an industrial level FL framework developed by WeBank, which aims to provide FL services between different organizations. FATE is based on Python and can be installed on Linux or Mac. It has attracted about 3.2k stars and 900 forks on GitHub. The overall structure of FATE is shown in Figure 4. It has six major modules: EggRoll, FederatedML, FATE-Flow, FATE-Serving, FATE-Board, and KubeFATE. EggRoll manages the distributed computing and storage. It provides computing and storage AIPs for the other modules. FederatedML includes the federated algorithms and secure protocols. Currently, it supports training many kinds of machine learning models under both horizontal and vertical federated setting, including NNs, GBDTs, and logistic regression. FATE assumes that the parties are honest-but-curious. Thus, it uses secure multi-party computation and homomorphic encryption to protect the communicated messages. However, it does not support differential privacy to protect the final model. FATE-Flow is a platform for the users to define their pipeline of the FL process. The pipeline can include the data preprocessing, federated training, federated evaluation, model management, and model publishing. FATE-Serving provides inference services for the users. It supports loading the FL models and conducting online inference on them. FATE-Board is a visualization tool for FATE. It provides a visual way to track the job execution and model performance. Last, KubeFATE helps deploy FATE on clusters by using Docker or Kubernetes. It provides customized deployment and cluster management services. In general, FATE is a powerful and easy-to-use FLS. Users can simply set the parameters to run a FL algorithm. Moreover, FATE provides detailed documents on its deployment and usage. However, since FATE provides algorithm-level interfaces, practitioners have to modify the source code of FATE to implement their own federated algorithms. This is not easy for non-expert users.TFF, developed by Google, provides the building blocks for FL based on TensorFlow. It has attracted about 1.5k stars and 380 forks on GitHub. TFF provides a Python package which can be easily installed and imported. As shown in FigureÂ 5, it provides two APIs of different layers: FL API and Federated Core (FC) API. FL API offers high-level interfaces. It includes three key parts, which are models, federated computation builders, and datasets. FL API allows users to define the models or simply load the KerasÂ [66] model. The federated computation builders include the typical federated averaging algorithm. Also, FL API provides simulated federated datasets and functions to access and enumerate the local datasets for FL. Besides high-level interfaces, FC API also includes lower-level interfaces as the foundation of the FL process. Developers can implement their functions and interfaces inside the federated core.\nFinally, FC provides the building blocks for FL. It support multiple federated operators such as federated sum, federated reduce, and federated broadcast. Developers can define their own operators to implement the FL algorithm. Overall, TFF is a lightweight system for developers to design and implement new FL algorithms. Currently, TFF does not consider consider any adversaries during FL training. It does not provide privacy mechanisms. TFF can only deploy on a single machine now, where the federated setting is implemented by simulation.PySyft, first proposed by Ryffel etÂ al. [158] and developed by OpenMined, is a python library that provides interfaces for developers to implement their training algorithm. It has attracted about 7.3k stars and 1.7k forks on GitHub. While TFF is based on TensorFlow, PySyft can work well with both PyTorch and TensorFlow. PySyft provides multiple optional privacy mechanisms including secure multi-party computation and differential privacy. Thus, it can support running on honest-but-curious parties. Moreover, it can be deployed on a single machine or multiple machines, where the communication between different clients is through the websocket APIÂ [168]. However, while PySyft provides a set of tutorials, there is no detailed document on its interfaces and system architecture.PaddleFL is a FLS based on PaddlePaddle888https://github.com/PaddlePaddle/Paddle, which is a deep learning platform developed by Baidu. It is implemented on C++ and Python. It has attracted about 260 stars and 60 forks on GitHub. Like PySyft, PaddleFL supports both differential privacy and secure multi-party computation and can work on honest-but-curious parties. The system structure of PaddleFL is shown in Figure 6. In the compile time, there are four components including FL strategies, user defined models and algorithms, distributed training configuration, and FL job generator. The FL strategies include the horizontal FL algorithms such as FedAvg. Vertical FL algorithms will be integrated in the future. Besides the provided FL strategies, users can also define their own models and training algorithms. The distributed training configuration defines the training node information in the distributed setting. FL job generator generates the jobs for federated server and workers. In the run time, there are three components including FL server, FL worker, and FL scheduler. The server and worker are the manager and parties in FL, respectively. The scheduler selects the workers that participate in the training in each round. Currently, the development of PaddleFL is still in a early stage and the documents and examples are not clear enough.FedML provides both a framework for federated learning and a platform for FL benchmark. It is developed by a team from University of Southern California [74] based on PyTorch. FedML has attracted about 660 stars and 180 forks on GitHub. As an FL framework, Itâ€™s core structure is divided into two levels, as shown in FigureÂ 7. In the low-level FedML-core, training engine and distributed communication infrastructures are implemented.\nThe high-level FedML-API is built on top of them and provides training models, datasets, and FL algorithms. Reference application/benchmark implementations are further built on top of the FedML-API. While most algorithms implemented on FedML does not consider any adversaries, it supports applying differential privacy when aggregating the messages from the parties. FedML supports three computing paradigms, namely standalone simulation, distributed computing and on-device training, which provides a simulation environment for a broad spectrum of hardware requirements. Reference implementations for all supported FL algorithms are provided. Although there are still gaps between some of the experiment results and the optimal results, they provide useful information for further development.There are other closed source federated learning systems. NVIDIA Clara 999https://developer.nvidia.com/clara has enabled FL. It adopts a centralized architecture and encrypted communication channel. The targeted users of Clara FL is hospitals and medical institutions. Ping An Technology aims to build a federated learning system named Hive [2], which targets at the financial industries. While Clara FL provides APIs and documents, we cannot find the official documents of Hive.Overall, FATE, PaddleFL, and FedML try to provide algorithm-level APIs for users to use directly, while TFF and PySyft try to provide more detailed building blocks so that the developers can easily implement their FL process. Table 2 shows the comparison between the open-source systems. In the algorithm level, FATE is the most comprehensive system that supports many machine learning models under both horizontal and vertical settings. TFF and PySyft only implement FedAvg, which is a basic framework in FL as shown in Section 4.2. PaddleFL supports several horizontal FL algorithms currently on NNs and logistic regression. FedML integrates several state-of-the-art FL algorithms such as FedOpt [154] and FedNova [190]. Compared with FATE, TFF, and FedML, PySyft and PaddleFL provide more privacy mechanisms. PySyft covers all the listed features that TFF supports, while TFF is based on TensorFlow and PySyft works better on PyTorch. Based on the popularity on GitHub, PySyft is currently the most impactful federated learning system in the machine learning community.FigureÂ 8 shows the factors that need to be considered in the design of an FLS. Here effectiveness, efficiency, and privacy are three important metrics of FLSs, which are also main research directions of federated learning. Inspired by federated database [166], we also consider autonomy, which is necessary to make FLSs practical. Next, we explain these factors in detail.The core of an FLS is an (multiple) effective algorithm (algorithms). To determine the algorithm to be implemented from lots of existing studies as shown in TableÂ 4.2, we should first check the data partitioning of the parties. If the parties have the same features but different samples, one can use FedAvg [129] for NNs and SimFL [104] for trees. If the parties have the same sample space but different features, one can use FedBCD [120] for NNs and SecureBoost [38] for trees.An important requirement of FLSs is to protect the user privacy. Here we analyze the reliability of the manager. If the manager is honest and not curious, then we do not need to adopt any additional technique, since the FL framework ensures that the raw data is not exchanged. If the manager is honest but curious, then we have to take possible inference attacks into consideration. The model parameters may also expose sensitive information about the training data. One can adopt differential privacy [60, 40, 130] to inject random noises into the parameters or use SMC [22, 72, 23] to exchanged encrypted parameters. If the manager cannot be trusted at all, then we can use trusted execution environments [37] to execute the code in the manager. Blockchain is also an option to play the role as a manager [93].Efficiency is an important factor in the success of many existing systems such as XGBoost [34] and ThunderSVM [198]. Since federated learning involves multi-rounds training and communication, the computation and communication costs may be large, which increases the threshold of usage of FLSs. To increase the efficiency, the most effective way is to deal with the bottleneck. If the bottleneck lies in the computation, we can use powerful hardware such as GPUs [42] and TPUs [83]. If the bottleneck lies in the communication, the compression techniques [18, 95, 164] can be applied to reduce the communication size.Like federated databases [166], a practical FLS has to consider the autonomy of the parties. The parties may drop out (e.g., network failure) during the FL process, especially in the cross-device setting where the scale is large and the parties are unreliable [85]. Thus, the FLS should be robust and stable, which can tolerate the failure of parties or reduce the number of failure cases. Google has developed a practical FLS [24]. In their system, they monitor devicesâ€™ health statistics to avoid wasting devicesâ€™ battery or bandwidth. Also, the system will complete the current round or restart from the results of the previously committed round if there are failures. Zhang etÂ al. [214] propose a blockchain-based approach to detect the device disconnection. Robust secure aggregation [17] is applicable to protect the communicated message in case of party drop out. Besides the disconnection issues, the parties may be selfish and are not willing to share the model with good quality. Incentive mechanisms [87, 88] can encourage the participation of the parties and improve the final model quality.Based on our taxonomy shown in Section 3 and the design factors shown in Figure 8, we derive a simple design reference for developing an FLS.The first step is to identity the participated entities and the task, which significantly influence the system design. The participated entities determines the communication architecture, the data partitioning and the scale of federation. The task determines the suitable machine learning models to train. Then, we can choose or design a suitable FL algorithm according to the above attributes and Table 4.2. After fixing the FL algorithm, to satisfy the privacy requirements, we may determine the privacy mechanisms to protect the communicated messages. DP is preferred if efficiency is more important than model performance compared with SMC. Last, incentive mechanism can be considered to enhance the system. Existing systems [74, 24] usually do not support incentive mechanisms. However, incentive mechanisms can encourage the parties to participate and contribute in the system and make the system more attractive. Shapley value [193, 187] is a fair approach that can be considered.For real-world applications of federated learning systems, please refer to Section 4 of the supplementary material.The evaluation of FLSs is very challenging. According to our studied system factors, it has to cover the following aspects: (1) model performance, (2) system security, (3) system efficiency, and (4) system robustness.For the evaluation of the model, there are two different settings. One is to evaluate the performance (e.g., prediction accuracy) of the final global model on a global dataset. The other one is to evaluate the performance of the final local models on the corresponding non-IID local datasets. The evaluation setting depends on the objective of FL, i.e., learn a global model or learn personalized local models.While theoretical security/privacy guarantee is a good evaluation metric for system security, another way is to conduct membership inference attacks [167] or model inversion attacks [56] to test the system security. These attacks can be conducted in two ways: (1) white-box attack: the attacker has access to all the exchanged models during the FL process. (2) black-box attack: the attacker only has access to the final output model. The attack success ratio can be an evaluation metric for the system security.\nThe efficiency of the system includes two parts: computation efficiency and communication efficiency. An intuitive metric is the training time, including the computation and communication time. Note that FL is usually a multi-round process. Thus, for a fair comparison, one approach is to use time per round as a metric. Another approach is to record the time or round to achieve the same target performance [90, 107].\nIt is challenging to quantifying the robustness of an FLS. A possible solution is to use a similar metric as robust secure aggregation, i.e., the maximum number of disconnected parties that can tolerate during the FL process.\nIn this section, we present several real-world applications of FL according to our taxonomy, as summarized in Table 3.There are many corporations providing predicting service to their mobile users, such as Google KeyboardÂ [208], Appleâ€™s emoji suggestion and QuickTypeÂ [179]. These services bring much convenience to the users. However, the training data come from usersâ€™ edge devices, like smartphones. If the company collects data from all users and trains a global model, it might potentially cause privacy leakage. On the other hand, the data of each single user are insufficient to train an accurate prediction model. FL enables these companies to train an accuracy prediction model without accessing usersâ€™ original data, which means protecting usersâ€™ privacy. In the framework of FLSs, the users calculate and send their local models instead of their original data. That means a Google Keyboard user can enjoy an accurate prediction for the next word while not sharing his/her input history. If FLS can be widely applied to such prediction services, there will be much less data leakage since data are always stored in the edge.In such a scenario, data are usually horizontally split into millions of devices. Hence, the limitation of single device computational resource and the bandwidth are two major problems. Besides, the robustness of the system should also be considered since a user could join or leave the system at anytime. In other words, a centralized, cross-device FLS on horizontal data should be designed for such prediction services.Although the basic framework of an FLS can have somehow protected individualsâ€™ privacy, it may not be secure against inference attacksÂ [167]. Some additional privacy mechanisms like differential privacy should be leveraged to ensure the indistinguishability of individuals. Here secure multi-party computation may not be appropriate since each device has a weak computation capacity and cannot afford expensive encryption operations. Apart from guaranteeing usersâ€™ privacy, some incentive mechanisms should be developed to encourage users to contribute their data. In reality, these incentives could be vouchers or additional service.Modern health systems require cooperation among research institutes, hospitals, and federal agencies to improve health care of the nationÂ [57]. Moreover, collaborative research among countries is vital when facing global health emergencies, like COVID-19Â [6]. These health systems mostly aim to train a model for the diagnosis of a disease. These models for diagnosis should be as accurate as possible. However, the information of patients are not allowed to transfer under some regulations such as GDPRÂ [10]. The privacy of data is even more concerned in international collaboration. Without solving the privacy issue, the collaborative research could be stagnated, threatening the public health. The data privacy in such collaboration is largely based on confidentiality agreement. However, this solution is based on â€œtrustâ€, which is not reliable. FL makes the cooperation possible because it can ensure the privacy theoretically, which is provable and reliable. In this way, every hospital or institute only has to share local models to get an accurate model for diagnosis.In such a scenario, the health care data is partitioned both horizontally and vertically: each party contains health data of residents for a specific purpose (e.g., patient treatment), but the features used in each party are diverse. The number of parties is limited and each party usually has plenty of computational resource. In other words, a private FLS on hybrid partitioned data is required. One of the most challenging problems is how to train the hybrid partitioned data. The design of the FLS could be more complicated than a simple horizontal system. In a federation of healthcare, there is probably no central server. So, another challenging part is the design of a decentralized FLS, which should also be robust against some dishonest or malicious parties. Moreover, the privacy concern can be solved by additional mechanisms like secure multi-party computation and differential privacy. The collaboration is largely motivated by regulations.A federation of financial consists of banks, insurance companies, etc. They often hope to cooperate in daily financial operations. For example, some â€˜badâ€™ users might pack back a loan in one back with the money borrowed from another bank. All the banks want to avoid such malicious behavior while not revealing other customersâ€™ information. Also, insurance companies also want to learn from the banks about the reputation of customers. However, a leakage of â€˜goodâ€™ customersâ€™ information may cause loss of interest or some legal issues.This kind of cooperation can happen if we have a trusted third party, like the government. However, in many cases, the government is not involved in the federation or the government is not always trusted. So, an FLS with privacy mechanisms can be introduced. In the FLS, the privacy of each bank can be guaranteed by theoretical proved privacy mechanisms.In such a scenario, financial data are often vertically partitioned, linked by user ID. Training a classifier in vertically partitioned data is quite challenging. Generally, the training process can be divided into two parts: privacy-preserving record linkageÂ [183] and vertical federated training. The first part aims to find links between vertical partitioned data, and it has been well studied. The second part aims to train the linked data without sharing the original data of each party, which still remains a challenge. The cross-silo and decentralized setting are applied in this federation. Also, some privacy mechanisms should be adopted in this scenario and the participant can be motivated by interest.In this section, we show interesting directions to work on in the future. Although some directions are already covered in existing studies introduced in Section 4, we believe they are important and provide more insights on them.The heterogeneity of the parties is an important characteristic in FLSs. Basically, the parties can differ in the accessibility, privacy requirements, contribution to the federation, and reliability. Thus, it is important to consider such practical issues in FLSs.Dynamic scheduling\nDue to the instability of the parties, the number of parties may not be fixed during the learning process. However, the number of parties is fixed in many existing studies and they do not consider the situations where there are entries of new parties or departures of the current parties. The system should support dynamic scheduling and have the ability to adjust its strategy when there is a change in the number of parties. There are some studies addressing this issue. For example, Googleâ€™s systemÂ [24] can tolerate the drop-out of the devices. Also, the emergence of blockchainÂ [223] can be an ideal and transparent platform for multi-party learning. However, to the best of our knowledge, there is no work that study a increasing number of parties during FL. In such a case, more attention may be paid to the later parties, as the current global model may have been welled trained on existing parties.Diverse privacy restrictions\nLittle work has considered the privacy heterogeneity of FLSs, where the parties have different privacy requirements. The existing systems adopt techniques to protect the model parameters or gradients for all the parties on the same level. However, the privacy restrictions of the parties usually differ in reality. It would be interesting to design an FLS which treats the parties differently according to their privacy restrictions. The learned model should have a better performance if we can maximize the utilization of data of each party while not violating their privacy restrictions. The heterogeneous differential privacyÂ [9] may be useful in such settings, where users have different privacy attitudes and expectations.Intelligent benefitsIntuitively, one party should gain more from the FLS if it contributes more information. Existing incentive mechanisms are mostly based on Shapley values [193, 187], the computation overhead is a major concern. A computation-efficient and fair incentive mechanism needs to be developed.To boost the development of FLSs, besides the detailed algorithm design, we need to study from a high-level view.System architecture\nLike the parameter server [76] in deep learning which controls the parameter synchronization, some common system architectures are needed to be investigated for FL. Although FedAvg is a widely used framework, the applicable scenarios are still limited. For example, while unsupervised learning [129, 107, 108] still adopt model averaging as the model aggregation method, which cannot work if the parties want to train heterogeneous models. We want a general system architecture, which provides many aggregation methods and learning algorithms for different settings.Model market\nModel market [182] is a promising platform for model storing, sharing, and selling. An interesting idea is to use the model market for federated learning. The party can buy the models to conduct model aggregation locally. Moreover, it can contribute its models to the market with additional information such as the target task. Such a design introduces more flexibility to the federation and is more acceptable for the organizations, since the FL just like several transactions. A well evaluation of the models is important in such systems. The incentive mechanisms may be helpful [201, 87, 88].Benchmark\nAs more FLSs are being developed, a benchmark with representative data sets and workloads is quite important to evaluate the existing systems and direct future development. Although there have been quite a few benchmarks [25, 77, 74], no benchmark has been widely used in the experiments of federated learning studies. We need a robust benchmark which has representative datasets and strict privacy evaluation. Also, comprehensive evaluation metric including model performance, system efficiency, system security, and system robustness is often ignored in existing benchmarks. The evaluation of model performance on non-IID datasets and system security under data pollution needs more investigation.Data life cycles\nLearning is simply one aspects of a federated system. A data life cycle [151] consists of multiple stages including data creation, storage, use, share, archive and destroy. For the data security and privacy of the entire application, we need to invent new data life cycles under FL context. Although data sharing is clearly one of the focused stage, the design of FLSs also affects other stages. For example, data creation may help to prepare the data and features that are suitable for FL.Internet-of-thing\nSecurity and privacy issues have been a hot research area in fog computing and edge computing, due to the increasing deployment of Internet-of-thing applications. For more details, readers can refer to some recent surveysÂ [172, 209, 135]. FL can be one potential approach in addressing the data privacy issues, while still offering reasonably good machine learning modelsÂ [113, 138]. The additional key challenges come from the computation and energy constraints. The mechanisms of privacy and security introduces runtime overhead. For example, Jiang etÂ al. [80] apply independent Gaussian random projection to improve the data privacy, and then the training of a deep network can be too costly. The authors need to develop a new resource scheduling algorithm to move the workload to the nodes with more computation power. Similar issues happen in other environments such as vehicle-to-vehicle networksÂ [160].Regulations\nWhile FL enables collaborative learning without exposing the raw data, it is still not clear how FL comply with the existing regulations. For example, GDPR proposes limitations on data transfer. Since the model and gradients are actually not safe enough, is such limitation still apply to the model or gradients? Also, the â€œright to explainabilityâ€ is hard to execute since the global model is an averaging of the local models. The explainability of the FL models is an open problem [67, 161]. Moreover, if a user wants to delete its data, should the global model be retrained without the data [62]? There is still a gap between the FL techniques and the regulations in reality. We may expect the cooperation between the computer science community and the law community.Many efforts have been devoted to developing federated learning systems (FLSs). A complete overview and summary for existing FLSs is important and meaningful. Inspired by the previous federated systems, we have shown that heterogeneity and autonomy are two important factors in the design of practical FLSs. Moreover, with six different aspects, we provide a comprehensive categorization for FLSs. Based on these aspects, we also present the comparison on features and designs among existing FLSs. More importantly, we have pointed out a number of opportunities, ranging from more benchmarks to integration of emerging platforms such as blockchain. FLSs will be an exciting research direction, which calls for the effort from machine learning, system and data privacy communities.This work is supported by a MoE AcRF Tier 1 grant (T1 251RES1824), an SenseTime Young Scholars Research Fund, and a MOE Tier 2 grant (MOE2017-T2-1-122) in Singapore.",
        "references": [
            [
                "We summarize existing popular and state-of-the-art research work, as shown in TableÂ ",
                "4.2",
                ". From TableÂ ",
                "4.2",
                ", we have the following four key findings.",
                "First, most of the existing studies consider a horizontal data partitioning. We conjecture a part of the reason is that the experimental studies and benchmarks in horizontal data partitioning are relatively ready than vertical data partitioning. However, vertical FL is also common in real world, especially between different organizations. Vertical FL can enable more collaboration between diverse parties. Thus, more efforts should be paid to vertical FL to fill the gap.",
                "Second, most studies consider exchanging the raw model parameters without any privacy guarantees. This may not be right if more powerful attacks on machine learning models are discovered in the future. Currently, the mainstream methods to provide privacy guarantees are differential privacy and cryptographic methods (e.g., secure multi-party computation and homomorphic encryption). Differential privacy may influence the final model quality a lot. Moreover, the cryptographic methods bring much computation and communication overhead and may be the bottleneck of FLSs. We look forward to a cheap way with reasonable privacy guarantees to satisfy the regulations.",
                "Third, the centralized design is the mainstream of current implementations. A trusted server is needed in their settings. However, it may be hard to find a trusted server especially in the cross-silo setting. One naive approach to remove the central server is that the parties share the model parameters with all the other parties and each party also maintains the same global model locally. This method bring more communication and computation cost compared with the centralized setting. More studies should be done for practical FL with the decentralized architecture.",
                "Last, the main research directions (also the main challenge) of FL are to improve the effectiveness, efficiency, and privacy, which are also three important metrics to evaluate an FLS. Meanwhile, there are many other research topics on FL such as fairness and incentive mechanisms. Since FL is related to many research areas, we believe that FL will attract more researchers and we can see more interesting studies in the near future."
            ]
        ]
    },
    "S4.T2": {
        "caption": "Table 2: The comparison among some existing FLSs. The notations used in this table are the same as TableÂ 4.2. The cell is left empty if the system does not support the corresponding feature. There is no release version for FedML.",
        "table": "<table id=\"S4.T2.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">Supported features</td>\n<td id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FATE 1.5.0</td>\n<td id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">TFF 0.17.0</td>\n<td id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">PySyft 0.3.0</td>\n<td id=\"S4.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">PaddleFL 1.1.0</td>\n<td id=\"S4.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedML</td>\n</tr>\n<tr id=\"S4.T2.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\"><span id=\"S4.T2.1.1.2.1.1\" class=\"ltx_text\">Operation systems</span></td>\n<td id=\"S4.T2.1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Mac</td>\n<td id=\"S4.T2.1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Linux</td>\n<td id=\"S4.T2.1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Windows</td>\n<td id=\"S4.T2.1.1.4.2\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.4.3\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">iOS</td>\n<td id=\"S4.T2.1.1.5.2\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.5.3\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.5.4\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.5.5\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Android</td>\n<td id=\"S4.T2.1.1.6.2\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.6.3\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.6.4\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.6.5\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.T2.1.1.7.1.1\" class=\"ltx_text\">Data partitioning</span></td>\n<td id=\"S4.T2.1.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">horizontal</td>\n<td id=\"S4.T2.1.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.7.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">vertical</td>\n<td id=\"S4.T2.1.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.8.3\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.8.4\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.8.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.9\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"3\"><span id=\"S4.T2.1.1.9.1.1\" class=\"ltx_text\">Models</span></td>\n<td id=\"S4.T2.1.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NN</td>\n<td id=\"S4.T2.1.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.9.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.9.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.9.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.10\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">DT</td>\n<td id=\"S4.T2.1.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.10.3\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.10.4\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.10.5\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.10.6\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n</tr>\n<tr id=\"S4.T2.1.1.11\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.11.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LM</td>\n<td id=\"S4.T2.1.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.11.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.11.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.11.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.12\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.12.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.T2.1.1.12.1.1\" class=\"ltx_text\">Privacy Mechanisms</span></td>\n<td id=\"S4.T2.1.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">DP</td>\n<td id=\"S4.T2.1.1.12.3\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.12.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.12.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.12.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.12.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.13\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.13.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CM</td>\n<td id=\"S4.T2.1.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.13.3\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.13.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.13.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.13.6\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n</tr>\n<tr id=\"S4.T2.1.1.14\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.14.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.T2.1.1.14.1.1\" class=\"ltx_text\">Communication</span></td>\n<td id=\"S4.T2.1.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">simulated</td>\n<td id=\"S4.T2.1.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.14.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.14.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.14.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.14.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.15\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.15.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">distributed</td>\n<td id=\"S4.T2.1.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.15.3\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.15.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.15.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.15.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.16\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.16.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.T2.1.1.16.1.1\" class=\"ltx_text\">Hardwares</span></td>\n<td id=\"S4.T2.1.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CPUs</td>\n<td id=\"S4.T2.1.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.16.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.16.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.16.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.16.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n<tr id=\"S4.T2.1.1.17\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.17.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">GPUs</td>\n<td id=\"S4.T2.1.1.17.2\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.17.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">âœ“</td>\n<td id=\"S4.T2.1.1.17.5\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.1.1.17.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">âœ“</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Overall, FATE, PaddleFL, and FedML try to provide algorithm-level APIs for users to use directly, while TFF and PySyft try to provide more detailed building blocks so that the developers can easily implement their FL process. Table 2 shows the comparison between the open-source systems. In the algorithm level, FATE is the most comprehensive system that supports many machine learning models under both horizontal and vertical settings. TFF and PySyft only implement FedAvg, which is a basic framework in FL as shown in Section 4.2. PaddleFL supports several horizontal FL algorithms currently on NNs and logistic regression. FedML integrates several state-of-the-art FL algorithms such as FedOpt [154] and FedNova [190]. Compared with FATE, TFF, and FedML, PySyft and PaddleFL provide more privacy mechanisms. PySyft covers all the listed features that TFF supports, while TFF is based on TensorFlow and PySyft works better on PyTorch. Based on the popularity on GitHub, PySyft is currently the most impactful federated learning system in the machine learning community."
        ]
    },
    "S6.T3": {
        "caption": "Table 3: Requirements of the real-world federated systems",
        "table": "<table id=\"S6.T3.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S6.T3.3.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">System Aspect</span></td>\n<td id=\"S6.T3.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Mobile Service</span></td>\n<td id=\"S6.T3.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Healthcare</span></td>\n<td id=\"S6.T3.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Financial</span></td>\n</tr>\n<tr id=\"S6.T3.3.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Data Partitioning</span></td>\n<td id=\"S6.T3.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Horizontal Partitioning</span></td>\n<td id=\"S6.T3.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Hybrid Partitioning</span></td>\n<td id=\"S6.T3.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Vertical Partitioning</span></td>\n</tr>\n<tr id=\"S6.T3.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Machine Learning Model</span></td>\n<td id=\"S6.T3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">No specific Models</span></td>\n<td id=\"S6.T3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">No specific Models</span></td>\n<td id=\"S6.T3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">No specific Models</span></td>\n</tr>\n<tr id=\"S6.T3.3.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.3.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Scale of Federations</span></td>\n<td id=\"S6.T3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Cross-device</span></td>\n<td id=\"S6.T3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Cross-silo</span></td>\n<td id=\"S6.T3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Cross-silo</span></td>\n</tr>\n<tr id=\"S6.T3.3.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.3.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Communication Architecture</span></td>\n<td id=\"S6.T3.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Centralized</span></td>\n<td id=\"S6.T3.3.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Distributed</span></td>\n<td id=\"S6.T3.3.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Distributed</span></td>\n</tr>\n<tr id=\"S6.T3.3.6\" class=\"ltx_tr\">\n<td id=\"S6.T3.3.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Privacy Mechanism</span></td>\n<td id=\"S6.T3.3.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">DP</span></td>\n<td id=\"S6.T3.3.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">DP/SMC</span></td>\n<td id=\"S6.T3.3.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">DP/SMC</span></td>\n</tr>\n<tr id=\"S6.T3.3.7\" class=\"ltx_tr\">\n<td id=\"S6.T3.3.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Motivation of Federation</span></td>\n<td id=\"S6.T3.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Incentive Motivated</span></td>\n<td id=\"S6.T3.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Policy Motivated</span></td>\n<td id=\"S6.T3.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T3.3.7.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Interest Motivated</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In this section, we present several real-world applications of FL according to our taxonomy, as summarized in Table 3."
        ]
    }
}