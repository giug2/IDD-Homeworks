{
    "S2.T1": {
        "caption": "Table 1: Summary of existing LLMs in E-commerce",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S2.T1.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S2.T1.1.1.1.1.1\">Domain</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S2.T1.1.1.1.1.2\">Model Type</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S2.T1.1.1.1.1.3\">Model</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S2.T1.1.1.1.1.4\">Base</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S2.T1.1.1.1.1.5\">Param</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S2.T1.1.1.1.1.6\">Data Source</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.1.2.1.1\">General</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.1.2.1.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.1.2.1.3\">ALBERT<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib10\" title=\"\">10</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.1.2.1.4\">BERT</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.1.2.1.5\">12M/18M/60M/235M</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.1.2.1.6\">BooksCorpus, English Wikipedia</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.3.2.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.3.2.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.3.2.3\">BERT<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib11\" title=\"\">11</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.3.2.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.3.2.5\">110M/340M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.3.2.6\">BooksCorpus, English Wikipedia<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib11\" title=\"\">11</a>]</cite>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.4.3.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.4.3.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.4.3.3\">BART <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib12\" title=\"\">12</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.4.3.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.4.3.5\">140M/400M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.4.3.6\">mix of books and Wikipedia data</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.5.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.5.4.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.5.4.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.5.4.3\">ELECTRA<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib13\" title=\"\">13</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.5.4.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.5.4.5\">14M/110M/335M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.5.4.6\">BooksCorpus, English Wikipedia</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.6.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.6.5.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.6.5.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.6.5.3\">XLNet<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib14\" title=\"\">14</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.6.5.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.6.5.5\">110M/340M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.6.5.6\">Wikipedia, BookCorpus</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.7.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.7.6.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.7.6.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.7.6.3\">ERNIE<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib15\" title=\"\">15</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.7.6.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.7.6.5\">110M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.7.6.6\">Wikipedia, other texts</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.8.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.8.7.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.8.7.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.8.7.3\">Galactica<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib16\" title=\"\">16</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.8.7.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.8.7.5\">6.7B/30.0B/120.0B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.8.7.6\">Scientific papers</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.9.8\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.9.8.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.9.8.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.9.8.3\">GPT-2<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib17\" title=\"\">17</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.9.8.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.9.8.5\">1.5B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.9.8.6\">WebText</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.10.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.10.9.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.10.9.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.10.9.3\">DeBERTa<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib18\" title=\"\">18</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.10.9.4\">BERT</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.10.9.5\">1.5B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.10.9.6\">BooksCorpus, English Wikipedia</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.11.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.11.10.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.11.10.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.11.10.3\">LLaMA<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib19\" title=\"\">19</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.11.10.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.11.10.5\">7B/13B/33B/65B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.11.10.6\">Diverse internet data</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.12.11\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.12.11.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.12.11.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.12.11.3\">LLaMA-2<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib1\" title=\"\">1</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.12.11.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.12.11.5\">7B/13B/34B/70B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.12.11.6\">Larger dataset</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.13.12\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.13.12.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.13.12.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.13.12.3\">GPT-3<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib20\" title=\"\">20</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.13.12.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.13.12.5\">6.7B/13B/175B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.13.12.6\">Extensive internet text</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.14.13\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.14.13.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.14.13.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.14.13.3\">PaLM<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib21\" title=\"\">21</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.14.13.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.14.13.5\">8B/62B/540B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.14.13.6\">Public and proprietary data</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.15.14\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.15.14.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.15.14.2\">Fine-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.15.14.3\">Alpaca<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib22\" title=\"\">22</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.15.14.4\">LLaMA</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.15.14.5\">7B/13B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.15.14.6\">LLaMA datasets, additional data</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.16.15\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.16.15.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.16.15.2\">Fine-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.16.15.3\">InstructGPT <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib23\" title=\"\">23</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.16.15.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.16.15.5\">175B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.16.15.6\">Based on GPT-3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.17.16\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.17.16.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.17.16.2\">Fine-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.17.16.3\">GPT-4 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib3\" title=\"\">3</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.17.16.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.17.16.5\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.17.16.6\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.18.17\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.18.17.1\">General</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.18.17.2\">Fine-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.18.17.3\">Mixtral <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib24\" title=\"\">24</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.18.17.4\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.18.17.5\">8x7B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.18.17.6\">multilingual data using a context size of 32k tokens</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.19.18\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.19.18.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.19.18.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.19.18.3\">E-BERT <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib7\" title=\"\">7</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.19.18.4\">BERT</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.19.18.5\">110M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.19.18.6\">Amazon Dataset</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.20.19\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.20.19.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.20.19.2\">Pre-training</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.20.19.3\">KG-FLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib25\" title=\"\">25</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.20.19.4\">BLIP</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.20.19.5\">224M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.20.19.6\">Amazon Dataset</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.21.20\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.21.20.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.21.20.2\">Fine-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.21.20.3\">Ecom-GPT<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib6\" title=\"\">6</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.21.20.4\">BLOOMZ</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.21.20.5\">560M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.21.20.6\">EcomInstruct</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.22.21\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.22.21.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.22.21.2\">Fine-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.22.21.3\">G2ST<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib26\" title=\"\">26</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.22.21.4\">Qwen-14B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.22.21.5\">14B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.22.21.6\">Alibaba.com</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.23.22\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.23.22.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.23.22.2\">Fine-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.23.22.3\">eCeLLM-L<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib27\" title=\"\">27</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.23.22.4\">Flan-T5-XXL, Llama-2-13B-chat</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.23.22.5\">11B-13B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.23.22.6\">ECInstruct <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib27\" title=\"\">27</a>]</cite>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.24.23\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.24.23.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.24.23.2\">Fine-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.24.23.3\">eCeLLM-M<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib27\" title=\"\">27</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.24.23.4\">Llama-2-7B-chat, Mistral-7B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.24.23.5\">7B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.24.23.6\">ECInstruct <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib27\" title=\"\">27</a>]</cite>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.25.24\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.25.24.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.25.24.2\">Fine-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.25.24.3\">eCeLLM-S<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib27\" title=\"\">27</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.25.24.4\">Flan-T5-XL-3B, Phi-2-3B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.25.24.5\">3B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.25.24.6\">ECInstruct <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib27\" title=\"\">27</a>]</cite>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.26.25\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.26.25.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.26.25.2\">Fine-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.26.25.3\">GPT4Rec<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib28\" title=\"\">28</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.26.25.4\">GPT-2</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.26.25.5\">117M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.26.25.6\">Amazon Review: Beauty and Electronics <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib28\" title=\"\">28</a>]</cite>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.27.26\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.27.26.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.27.26.2\">Prompt-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.27.26.3\">MixPAVE<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib29\" title=\"\">29</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.27.26.4\">Pre-training Transformer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib30\" title=\"\">30</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.27.26.5\">0.445M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.27.26.6\">AE-110K <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib31\" title=\"\">31</a>]</cite> , MAVE<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib29\" title=\"\">29</a>]</cite>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.28.27\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.28.27.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.28.27.2\">Prompt-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.28.27.3\">CTM<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib32\" title=\"\">32</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.28.27.4\">characterBERT , BERT</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.28.27.5\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.28.27.6\">Huski.ai</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.29.28\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.29.28.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.29.28.2\">Prompt-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.29.28.3\">Aspect Extraction LLM<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib33\" title=\"\">33</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.29.28.4\">GPT-2,BERT</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.29.28.5\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.29.28.6\">Amazon, Yelp, Tripadvisor</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.30.29\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.30.29.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.30.29.2\">Prompt-tuning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.30.29.3\">CF Recommender Enhancement Model<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib34\" title=\"\">34</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.30.29.4\">BERT,RoBERTa</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.30.29.5\">-</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.1.30.29.6\">Amazon US Reviews</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.31.30\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S2.T1.1.1.31.30.1\">E-commerce</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S2.T1.1.1.31.30.2\">Prompt-tuning</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S2.T1.1.1.31.30.3\">recGPT<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.13025v2#bib.bib34\" title=\"\">34</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S2.T1.1.1.31.30.4\">pre-trained ChatGPT</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S2.T1.1.1.31.30.5\">-</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S2.T1.1.1.31.30.6\">Amazon reviews and Yelp</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": []
    }
}