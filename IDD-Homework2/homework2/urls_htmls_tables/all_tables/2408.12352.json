{
    "id_table_1": {
        "caption": "Table 1 :  The quantitative comparison results with baselines [ 28 ,  43 ,  31 ,  34 ,  8 ,  5 ,  44 ,  24 ] . Our approach achieves the best performance in comparison with numerous methods, excelling in metrics for image quality and consistency between text and image.",
        "table": "S4.T1.4",
        "footnotes": [],
        "references": [
            "The primary objective of GarmentAligner is to enhance the alignment between input text prompts and generated garment images across multiple semantic levels in both holistic perception and fine-grained semantics.  To achieve this, GarmentAligner integrates pre-trained latent diffusion models  [ 31 ]  as backbones to exploit their inherent knowledge and finetune the pre-trained text-to-image backbone with retrieval-augmented multi-level corrections to adapt it to the text-to-garment generation domain. Besides, an automatic component extraction pipeline (refer to  Sec.   3.1 ) is adopted to attain in-depth component-level information from garment images with advanced open-domain detection and segmentation methods [ 15 ,  21 ,  30 ] .  The overview of the proposed training strategy is depicted in  Fig.   4 .",
            "Our experiments are conducted on the CM-Fashion dataset  [ 43 ] , which consists of 500,000 garment images at a resolution of 512512, each accompanied by corresponding captions.  We employ the proposed automatic component extraction pipeline outlined in  Sec.   3.1  to extract component-level garment segmentation and count of components from the images. Subsequently, we enrich the captions with the extracted information. Consequently, we curate an augmented garment dataset derived from the CM-Fashion dataset  [ 43 ] , featuring optimized captions and component-level segmentation and quantity.",
            "For quantitative comparisons, we employ several metrics: 1) FID [ 13 ]  to assess the fidelity of the generated images, 2) Aesthetic Score to evaluate their aesthetic quality, 3) CLIP Score  [ 12 ]  to measure the relevance between the given text and the generated images, and 4) HPS v2  [ 36 ]  to gauge the degree of alignment with human preferences. The quantitative comparison results are presented in  Tab.   1 , juxtaposed with those of DALLE  [ 28 ] , ARMANI  [ 43 ] , ComposableDiffusion  [ 34 ] , StructureDiffusion  [ 8 ] , Attend-and-Excite  [ 5 ] , DiffCloth  [ 44 ] , SD v1.5 [ 31 ] , SD v2.1 [ 31 ] , and SDXL  [ 24 ] . Our proposed GarmentAligner achieves the lowest FID score and the highest scores in CLIPScore, Aesthetic score, and HPS v2 for garment synthesis, indicating superior performance across all metrics.",
            "To validate the effectiveness of the proposed retrieval-augmented contrastive learning and the three corrections at the component level, we designed six variants of the proposed method and evaluated their performance based on the metric scores, accuracy and visual effects, as shown in  Fig.   10 ,  Fig.   10  and  Tab.   2 .",
            "From  Tab.   2 , it is evident that retrieval-augmented contrastive learning makes the most significant contribution to the overall quality of generated garments, as evinced by its marked improvement across metrics such as FID [ 13 ] , Aesthetic Score, and HPS v2 [ 36 ] , which are indicative of image realism. On the other hand, multi-level corrections prove notably effective in enhancing text-image consistency while concurrently improving performance on all metrics. The accuracy outcomes illustrated in  Fig.   10  demonstrate the significant role of multi-level corrections in enhancing both the quantity and spatial accuracy at the component level, thus validating the effectiveness of our proposed method design.  The combined application of these parts yields superior results, illustrating the complementary nature of the two pivotal components we propose.   Fig.   10  illustrates the disparities among variant models in depicting detailed components of clothing, providing a more intuitive insight into the distinct roles played by different parts."
        ]
    },
    "id_table_2": {
        "caption": "Table 2 :  The quantitative comparison of different parts of the model, where  [ V ] delimited-[] V [V] [ italic_V ]  represents visual correction,  [ S ] delimited-[] S [S] [ italic_S ]  represents spatial correction,  [ C ] delimited-[] C [C] [ italic_C ]  represents quantitative correction,  and  [ R ] delimited-[] R [R] [ italic_R ]  represents retrieval-augmented contrastive learning.",
        "table": "S4.T2.18",
        "footnotes": [],
        "references": [
            "Despite the rapid developments in general text-to-image models [ 29 ,  24 ,  31 ] , adapting these advanced models for garment generation tasks presents significant challenges.  On the one hand, the visual semantics in the fashion domain significantly differ from those in general text-to-image generation. Garment captions possess specific textual structures and professional modifiers. Existing text-to-image models [ 29 ,  24 ,  31 ]  struggle to achieve high consistency between textual descriptions and the generated garment images, as illustrated in  Fig.   2 .  While some methods for garment generation [ 43 ,  44 ,  33 ,  37 ,  11 ]  to capture the semantic structure of garment captions, thereby partially alleviating textual disparities, achieving fine-grained alignment still remains challenging.  On the other hand, garment components, as crucial elements within garments, encompass distinct attributes and intricate interconnections, posing a challenge in the accurate generation of authentic garment images that satisfy the diverse requirements of these components. While several existing methods  [ 37 ,  43 ,  44 ,  41 ]  emphasize the importance of garment components, they primarily focus on the visual semantic aspect, neglecting the exploration of more extensive details such as component positioning and quantity.",
            "A retrieval-augmented contrastive learning approach (refer to  Sec.   3.2 ) to utilize positive and negative samples retrieved from a subset constructed via semantic similarity ranking. This approach leverages an extensive sample pool to enhance the pre-trained models semantic perception capabilities.",
            "To validate the effectiveness of the proposed retrieval-augmented contrastive learning and the three corrections at the component level, we designed six variants of the proposed method and evaluated their performance based on the metric scores, accuracy and visual effects, as shown in  Fig.   10 ,  Fig.   10  and  Tab.   2 .",
            "From  Tab.   2 , it is evident that retrieval-augmented contrastive learning makes the most significant contribution to the overall quality of generated garments, as evinced by its marked improvement across metrics such as FID [ 13 ] , Aesthetic Score, and HPS v2 [ 36 ] , which are indicative of image realism. On the other hand, multi-level corrections prove notably effective in enhancing text-image consistency while concurrently improving performance on all metrics. The accuracy outcomes illustrated in  Fig.   10  demonstrate the significant role of multi-level corrections in enhancing both the quantity and spatial accuracy at the component level, thus validating the effectiveness of our proposed method design.  The combined application of these parts yields superior results, illustrating the complementary nature of the two pivotal components we propose.   Fig.   10  illustrates the disparities among variant models in depicting detailed components of clothing, providing a more intuitive insight into the distinct roles played by different parts."
        ]
    },
    "global_footnotes": []
}