{
    "PAPER'S NUMBER OF TABLES": 9,
    "S4.T1": {
        "caption": "Table 1: The results of our FedOTP and the benchmark methods on the Pathological Non-IID setting with non-overlapping over 10 clients.",
        "table": "<table id=\"S4.T1.4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Methods</th>\n<td id=\"S4.T1.4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Food101</td>\n<td id=\"S4.T1.4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">DTD</td>\n<td id=\"S4.T1.4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Caltech101</td>\n<td id=\"S4.T1.4.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Flowers102</td>\n<td id=\"S4.T1.4.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">OxfordPets</td>\n</tr>\n<tr id=\"S4.T1.4.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"6\"><span id=\"S4.T1.4.1.2.2.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Local Training</span></th>\n</tr>\n<tr id=\"S4.T1.4.1.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Zero-Shot CLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib60\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">60</span></a>]</cite>\n</th>\n<td id=\"S4.T1.4.1.3.3.2\" class=\"ltx_td ltx_align_center\">75.27±0.05</td>\n<td id=\"S4.T1.4.1.3.3.3\" class=\"ltx_td ltx_align_center\">40.21±0.12</td>\n<td id=\"S4.T1.4.1.3.3.4\" class=\"ltx_td ltx_align_center\">85.14±0.24</td>\n<td id=\"S4.T1.4.1.3.3.5\" class=\"ltx_td ltx_align_center\">62.17±0.12</td>\n<td id=\"S4.T1.4.1.3.3.6\" class=\"ltx_td ltx_align_center\">84.47±0.10</td>\n</tr>\n<tr id=\"S4.T1.4.1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CoOp <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib78\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">78</span></a>]</cite>\n</th>\n<td id=\"S4.T1.4.1.4.4.2\" class=\"ltx_td ltx_align_center\">82.54±2.42</td>\n<td id=\"S4.T1.4.1.4.4.3\" class=\"ltx_td ltx_align_center\">82.69±0.63</td>\n<td id=\"S4.T1.4.1.4.4.4\" class=\"ltx_td ltx_align_center\">90.41±0.44</td>\n<td id=\"S4.T1.4.1.4.4.5\" class=\"ltx_td ltx_align_center\">88.23±0.76</td>\n<td id=\"S4.T1.4.1.4.4.6\" class=\"ltx_td ltx_align_center\">94.52±1.30</td>\n</tr>\n<tr id=\"S4.T1.4.1.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"6\"><span id=\"S4.T1.4.1.5.5.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Prompt-based Federated Learning</span></th>\n</tr>\n<tr id=\"S4.T1.4.1.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PromptFL <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">27</span></a>]</cite>\n</th>\n<td id=\"S4.T1.4.1.6.6.2\" class=\"ltx_td ltx_align_center\">74.81±0.64</td>\n<td id=\"S4.T1.4.1.6.6.3\" class=\"ltx_td ltx_align_center\">50.46±0.54</td>\n<td id=\"S4.T1.4.1.6.6.4\" class=\"ltx_td ltx_align_center\">87.90±0.54</td>\n<td id=\"S4.T1.4.1.6.6.5\" class=\"ltx_td ltx_align_center\">73.68±1.58</td>\n<td id=\"S4.T1.4.1.6.6.6\" class=\"ltx_td ltx_align_center\">88.17±1.18</td>\n</tr>\n<tr id=\"S4.T1.4.1.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PromptFL+FT <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">24</span></a>]</cite>\n</th>\n<td id=\"S4.T1.4.1.7.7.2\" class=\"ltx_td ltx_align_center\">77.16±1.56</td>\n<td id=\"S4.T1.4.1.7.7.3\" class=\"ltx_td ltx_align_center\">53.74±1.36</td>\n<td id=\"S4.T1.4.1.7.7.4\" class=\"ltx_td ltx_align_center\">89.70±0.25</td>\n<td id=\"S4.T1.4.1.7.7.5\" class=\"ltx_td ltx_align_center\">72.31±0.91</td>\n<td id=\"S4.T1.4.1.7.7.6\" class=\"ltx_td ltx_align_center\">91.23±0.50</td>\n</tr>\n<tr id=\"S4.T1.4.1.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PromptFL+FedProx <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib42\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">42</span></a>]</cite>\n</th>\n<td id=\"S4.T1.4.1.8.8.2\" class=\"ltx_td ltx_align_center\">73.96±0.75</td>\n<td id=\"S4.T1.4.1.8.8.3\" class=\"ltx_td ltx_align_center\">50.89±0.71</td>\n<td id=\"S4.T1.4.1.8.8.4\" class=\"ltx_td ltx_align_center\">87.80±1.10</td>\n<td id=\"S4.T1.4.1.8.8.5\" class=\"ltx_td ltx_align_center\">74.14±0.65</td>\n<td id=\"S4.T1.4.1.8.8.6\" class=\"ltx_td ltx_align_center\">87.25±1.48</td>\n</tr>\n<tr id=\"S4.T1.4.1.9.9\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PromptFL+FedPer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib1\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">1</span></a>]</cite>\n</th>\n<td id=\"S4.T1.4.1.9.9.2\" class=\"ltx_td ltx_align_center\">71.29±1.87</td>\n<td id=\"S4.T1.4.1.9.9.3\" class=\"ltx_td ltx_align_center\">50.23±0.82</td>\n<td id=\"S4.T1.4.1.9.9.4\" class=\"ltx_td ltx_align_center\">86.72±1.45</td>\n<td id=\"S4.T1.4.1.9.9.5\" class=\"ltx_td ltx_align_center\">72.11±1.35</td>\n<td id=\"S4.T1.4.1.9.9.6\" class=\"ltx_td ltx_align_center\">89.50±1.62</td>\n</tr>\n<tr id=\"S4.T1.4.1.10.10\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PromptFL+FedAMP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">32</span></a>]</cite>\n</th>\n<td id=\"S4.T1.4.1.10.10.2\" class=\"ltx_td ltx_align_center\">74.48±1.71</td>\n<td id=\"S4.T1.4.1.10.10.3\" class=\"ltx_td ltx_align_center\">47.16±0.92</td>\n<td id=\"S4.T1.4.1.10.10.4\" class=\"ltx_td ltx_align_center\">87.31±1.60</td>\n<td id=\"S4.T1.4.1.10.10.5\" class=\"ltx_td ltx_align_center\">69.10±0.13</td>\n<td id=\"S4.T1.4.1.10.10.6\" class=\"ltx_td ltx_align_center\">80.21±0.44</td>\n</tr>\n<tr id=\"S4.T1.4.1.11.11\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.11.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">pFedPrompt <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">26</span></a>]</cite>\n</th>\n<td id=\"S4.T1.4.1.11.11.2\" class=\"ltx_td ltx_align_center\">92.26±1.34</td>\n<td id=\"S4.T1.4.1.11.11.3\" class=\"ltx_td ltx_align_center\">77.14±0.09</td>\n<td id=\"S4.T1.4.1.11.11.4\" class=\"ltx_td ltx_align_center\">96.54±1.31</td>\n<td id=\"S4.T1.4.1.11.11.5\" class=\"ltx_td ltx_align_center\">86.46±0.15</td>\n<td id=\"S4.T1.4.1.11.11.6\" class=\"ltx_td ltx_align_center\">91.84±0.41</td>\n</tr>\n<tr id=\"S4.T1.4.1.12.12\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.12.12.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">FedOTP (Ours)</th>\n<td id=\"S4.T1.4.1.12.12.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.4.1.12.12.2.1\" class=\"ltx_text ltx_font_bold\">92.73±0.15</span></td>\n<td id=\"S4.T1.4.1.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.4.1.12.12.3.1\" class=\"ltx_text ltx_font_bold\">87.67±0.70</span></td>\n<td id=\"S4.T1.4.1.12.12.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.4.1.12.12.4.1\" class=\"ltx_text ltx_font_bold\">97.02±0.36</span></td>\n<td id=\"S4.T1.4.1.12.12.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.4.1.12.12.5.1\" class=\"ltx_text ltx_font_bold\">96.23±0.44</span></td>\n<td id=\"S4.T1.4.1.12.12.6\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.4.1.12.12.6.1\" class=\"ltx_text ltx_font_bold\">98.82±0.11</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Model Evaluation on Label Shifts.\nWe first measured the performance of FedOTP against baselines on datasets with label shifts. The experimental results on CLIP datasets and CIFAR-10/CIFAR-100 datasets are summarized in Table 1 and Table 3. For easy comparison, Table 1 reports results utilizing ResNet50 as the backbone, maintaining consistency with [26]. As shown in Table 1, our FedOTP outperforms state-of-the-art algorithms by a large margin across all datasets, which confirms the effectiveness of our Global-Local prompt cooperation mechanism to handle label shift scenarios.\nRemarkably, while both PromptFL+FedPer (which splits the learnable prompt vector into “base+personalized” vectors) and pFedPrompt (utilizing a shared prompt with a personalized attention module in the vision modal) experience significant declines when datasets are altered, FedOTP exhibits slight fluctuations. This verifies the robustness of our method across diverse scenarios.\nTable 3 shows the results of our FedOTP and benchmark methods on CIFAR-10/CIFAR-100 datasets under Dirichlet setting over 100100100 clients with 10%percent1010\\% partition. Even in this scenario with Dirichlet settings and a large number of clients, FedOTP consistently outperforms the baseline methods, further highlighting the superiority of our approach."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Experimental results on DomainNet dataset with feature &\\& label shifts.",
        "table": "<table id=\"S5.T2.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Datasets</th>\n<td id=\"S5.T2.5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"7\">DomainNet</td>\n</tr>\n<tr id=\"S5.T2.5.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Domains</th>\n<td id=\"S5.T2.5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Clipart</td>\n<td id=\"S5.T2.5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Infograph</td>\n<td id=\"S5.T2.5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Painting</td>\n<td id=\"S5.T2.5.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Quickdraw</td>\n<td id=\"S5.T2.5.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">Real</td>\n<td id=\"S5.T2.5.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">Sketch</td>\n<td id=\"S5.T2.5.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\">Avg.</td>\n</tr>\n<tr id=\"S5.T2.5.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"6\"><span id=\"S5.T2.5.1.3.3.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Local Training</span></th>\n<td id=\"S5.T2.5.1.3.3.2\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T2.5.1.3.3.3\" class=\"ltx_td ltx_border_t\"></td>\n</tr>\n<tr id=\"S5.T2.5.1.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Zero-Shot CLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib60\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">60</span></a>]</cite>\n</th>\n<td id=\"S5.T2.5.1.4.4.2\" class=\"ltx_td ltx_align_center\">8.72±1.73</td>\n<td id=\"S5.T2.5.1.4.4.3\" class=\"ltx_td ltx_align_center\">12.48±3.78</td>\n<td id=\"S5.T2.5.1.4.4.4\" class=\"ltx_td ltx_align_center\">8.53±4.32</td>\n<td id=\"S5.T2.5.1.4.4.5\" class=\"ltx_td ltx_align_center\">9.31±0.69</td>\n<td id=\"S5.T2.5.1.4.4.6\" class=\"ltx_td ltx_align_center\">9.13±2.55</td>\n<td id=\"S5.T2.5.1.4.4.7\" class=\"ltx_td ltx_align_center\">11.96±2.80</td>\n<td id=\"S5.T2.5.1.4.4.8\" class=\"ltx_td ltx_align_center\">10.02±2.65</td>\n</tr>\n<tr id=\"S5.T2.5.1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CoOp <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib78\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">78</span></a>]</cite>\n</th>\n<td id=\"S5.T2.5.1.5.5.2\" class=\"ltx_td ltx_align_center\">44.40±14.89</td>\n<td id=\"S5.T2.5.1.5.5.3\" class=\"ltx_td ltx_align_center\">45.68±16.53</td>\n<td id=\"S5.T2.5.1.5.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.5.1.5.5.4.1\" class=\"ltx_text ltx_font_bold\">47.21±18.20</span></td>\n<td id=\"S5.T2.5.1.5.5.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.5.1.5.5.5.1\" class=\"ltx_text ltx_font_bold\">41.13±20.62</span></td>\n<td id=\"S5.T2.5.1.5.5.6\" class=\"ltx_td ltx_align_center\">48.02±24.49</td>\n<td id=\"S5.T2.5.1.5.5.7\" class=\"ltx_td ltx_align_center\">39.47±5.68</td>\n<td id=\"S5.T2.5.1.5.5.8\" class=\"ltx_td ltx_align_center\">44.32±16.74</td>\n</tr>\n<tr id=\"S5.T2.5.1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"6\"><span id=\"S5.T2.5.1.6.6.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Prompt-based Federated Learning</span></th>\n<td id=\"S5.T2.5.1.6.6.2\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T2.5.1.6.6.3\" class=\"ltx_td ltx_border_t\"></td>\n</tr>\n<tr id=\"S5.T2.5.1.7.7\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PromptFL <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">27</span></a>]</cite>\n</th>\n<td id=\"S5.T2.5.1.7.7.2\" class=\"ltx_td ltx_align_center\">9.31±6.53</td>\n<td id=\"S5.T2.5.1.7.7.3\" class=\"ltx_td ltx_align_center\">12.58±9.91</td>\n<td id=\"S5.T2.5.1.7.7.4\" class=\"ltx_td ltx_align_center\">8.23± 8.47</td>\n<td id=\"S5.T2.5.1.7.7.5\" class=\"ltx_td ltx_align_center\">14.79±12.07</td>\n<td id=\"S5.T2.5.1.7.7.6\" class=\"ltx_td ltx_align_center\">9.37±10.82</td>\n<td id=\"S5.T2.5.1.7.7.7\" class=\"ltx_td ltx_align_center\">7.48±11.32</td>\n<td id=\"S5.T2.5.1.7.7.8\" class=\"ltx_td ltx_align_center\">10.29±10.35</td>\n</tr>\n<tr id=\"S5.T2.5.1.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PromptFL+FedProx <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib42\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">42</span></a>]</cite>\n</th>\n<td id=\"S5.T2.5.1.8.8.2\" class=\"ltx_td ltx_align_center\">9.84±6.60</td>\n<td id=\"S5.T2.5.1.8.8.3\" class=\"ltx_td ltx_align_center\">11.16±11.17</td>\n<td id=\"S5.T2.5.1.8.8.4\" class=\"ltx_td ltx_align_center\">10.64±6.79</td>\n<td id=\"S5.T2.5.1.8.8.5\" class=\"ltx_td ltx_align_center\">13.40±16.09</td>\n<td id=\"S5.T2.5.1.8.8.6\" class=\"ltx_td ltx_align_center\">9.39±7.69</td>\n<td id=\"S5.T2.5.1.8.8.7\" class=\"ltx_td ltx_align_center\">6.78±11.76</td>\n<td id=\"S5.T2.5.1.8.8.8\" class=\"ltx_td ltx_align_center\">10.20±10.99</td>\n</tr>\n<tr id=\"S5.T2.5.1.9.9\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">FedOTP (Ours)</th>\n<td id=\"S5.T2.5.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T2.5.1.9.9.2.1\" class=\"ltx_text ltx_font_bold\">46.14±6.53</span></td>\n<td id=\"S5.T2.5.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T2.5.1.9.9.3.1\" class=\"ltx_text ltx_font_bold\">60.14±18.23</span></td>\n<td id=\"S5.T2.5.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_b\">45.2±16.86</td>\n<td id=\"S5.T2.5.1.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_b\">38.66±7.60</td>\n<td id=\"S5.T2.5.1.9.9.6\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T2.5.1.9.9.6.1\" class=\"ltx_text ltx_font_bold\">49.30±17.80</span></td>\n<td id=\"S5.T2.5.1.9.9.7\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T2.5.1.9.9.7.1\" class=\"ltx_text ltx_font_bold\">49.02±24.22</span></td>\n<td id=\"S5.T2.5.1.9.9.8\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T2.5.1.9.9.8.1\" class=\"ltx_text ltx_font_bold\">48.08±15.21</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Model Evaluation on Feature &\\& Label Shifts.\nIn this set of experiments, we explored scenarios involving both feature shifts and label shifts by partitioning data within a domain into five clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1. We analyzed the mean and variance of clients in the same domain, and the outcomes for the DomainNet dataset are summarized in Table 2.\nIn the presence of two types of data heterogeneity, our method performs favorably against baselines. We observe that, with significant data heterogeneity across clients, traditional federated learning methods experience a pronounced performance decline compared to local training. In contrast, our FedOTP exhibits superior performance, achieving a 3.7%percent3.73.7\\% increase in average accuracy on each domain. Additional experimental results on feature shifts and in the Office-Caltech10 dataset are available in the Appendix Section C.1 and C.2."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: The results of our FedOTP and the benchmark methods on Dirichlet settings in CIFAR-10 and CIFAR-100 over 100 clients.",
        "table": "<table id=\"S5.T3.4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Methods</th>\n<td id=\"S5.T3.4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">CIFAR-10</td>\n<td id=\"S5.T3.4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">CIFAR-100</td>\n</tr>\n<tr id=\"S5.T3.4.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"3\"><span id=\"S5.T3.4.1.2.2.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Local Training</span></th>\n</tr>\n<tr id=\"S5.T3.4.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Zero-Shot CLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib60\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">60</span></a>]</cite>\n</th>\n<td id=\"S5.T3.4.1.3.3.2\" class=\"ltx_td ltx_align_center\">87.71±0.68</td>\n<td id=\"S5.T3.4.1.3.3.3\" class=\"ltx_td ltx_align_center\">64.92±0.53</td>\n</tr>\n<tr id=\"S5.T3.4.1.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CoOp <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib78\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">78</span></a>]</cite>\n</th>\n<td id=\"S5.T3.4.1.4.4.2\" class=\"ltx_td ltx_align_center\">93.11±0.39</td>\n<td id=\"S5.T3.4.1.4.4.3\" class=\"ltx_td ltx_align_center\">74.83±0.45</td>\n</tr>\n<tr id=\"S5.T3.4.1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"3\"><span id=\"S5.T3.4.1.5.5.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Prompt-based Federated Learning</span></th>\n</tr>\n<tr id=\"S5.T3.4.1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PromptFL <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">27</span></a>]</cite>\n</th>\n<td id=\"S5.T3.4.1.6.6.2\" class=\"ltx_td ltx_align_center\">92.30±0.87</td>\n<td id=\"S5.T3.4.1.6.6.3\" class=\"ltx_td ltx_align_center\">73.67±0.56</td>\n</tr>\n<tr id=\"S5.T3.4.1.7.7\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PromptFL+FedProx <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib42\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">42</span></a>]</cite>\n</th>\n<td id=\"S5.T3.4.1.7.7.2\" class=\"ltx_td ltx_align_center\">91.83±0.47</td>\n<td id=\"S5.T3.4.1.7.7.3\" class=\"ltx_td ltx_align_center\">71.11±0.91</td>\n</tr>\n<tr id=\"S5.T3.4.1.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">FedOTP (Ours)</th>\n<td id=\"S5.T3.4.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T3.4.1.8.8.2.1\" class=\"ltx_text ltx_font_bold\">96.05±0.12</span></td>\n<td id=\"S5.T3.4.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T3.4.1.8.8.3.1\" class=\"ltx_text ltx_font_bold\">78.03±0.08</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Model Evaluation on Label Shifts.\nWe first measured the performance of FedOTP against baselines on datasets with label shifts. The experimental results on CLIP datasets and CIFAR-10/CIFAR-100 datasets are summarized in Table 1 and Table 3. For easy comparison, Table 1 reports results utilizing ResNet50 as the backbone, maintaining consistency with [26]. As shown in Table 1, our FedOTP outperforms state-of-the-art algorithms by a large margin across all datasets, which confirms the effectiveness of our Global-Local prompt cooperation mechanism to handle label shift scenarios.\nRemarkably, while both PromptFL+FedPer (which splits the learnable prompt vector into “base+personalized” vectors) and pFedPrompt (utilizing a shared prompt with a personalized attention module in the vision modal) experience significant declines when datasets are altered, FedOTP exhibits slight fluctuations. This verifies the robustness of our method across diverse scenarios.\nTable 3 shows the results of our FedOTP and benchmark methods on CIFAR-10/CIFAR-100 datasets under Dirichlet setting over 100100100 clients with 10%percent1010\\% partition. Even in this scenario with Dirichlet settings and a large number of clients, FedOTP consistently outperforms the baseline methods, further highlighting the superiority of our approach."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Quantitative comparisons on the Pathological Non-IID setting across different numbers of shots over 10 clients.",
        "table": "<table id=\"S5.T4.4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">Datasets</th>\n<th id=\"S5.T4.4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\" colspan=\"2\">Food101</th>\n<th id=\"S5.T4.4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\" colspan=\"2\">DTD</th>\n<th id=\"S5.T4.4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\" colspan=\"2\">Caltech101</th>\n<th id=\"S5.T4.4.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\" colspan=\"2\">Flowers102</th>\n<th id=\"S5.T4.4.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\" colspan=\"2\">OxfordPets</th>\n</tr>\n<tr id=\"S5.T4.4.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T4.4.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" style=\"padding:0.5pt 4.3pt;\">Number of shots</th>\n<th id=\"S5.T4.4.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">2</th>\n<th id=\"S5.T4.4.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">8</th>\n<th id=\"S5.T4.4.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">2</th>\n<th id=\"S5.T4.4.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">8</th>\n<th id=\"S5.T4.4.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">2</th>\n<th id=\"S5.T4.4.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">8</th>\n<th id=\"S5.T4.4.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">2</th>\n<th id=\"S5.T4.4.1.2.2.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">8</th>\n<th id=\"S5.T4.4.1.2.2.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">2</th>\n<th id=\"S5.T4.4.1.2.2.11\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">8</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.4.1.3.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.4.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">FedOTP (Similarity Averaging)</th>\n<td id=\"S5.T4.4.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">83.38±0.54</td>\n<td id=\"S5.T4.4.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">87.59±1.05</td>\n<td id=\"S5.T4.4.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">81.01±0.23</td>\n<td id=\"S5.T4.4.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">88.17±0.73</td>\n<td id=\"S5.T4.4.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">92.68±0.44</td>\n<td id=\"S5.T4.4.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">96.73±0.29</td>\n<td id=\"S5.T4.4.1.3.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">91.73±0.68</td>\n<td id=\"S5.T4.4.1.3.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">97.09±0.18</td>\n<td id=\"S5.T4.4.1.3.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">96.23±0.25</td>\n<td id=\"S5.T4.4.1.3.1.11\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 4.3pt;\">98.34±0.15</td>\n</tr>\n<tr id=\"S5.T4.4.1.4.2\" class=\"ltx_tr\">\n<th id=\"S5.T4.4.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding:0.5pt 4.3pt;\">FedOTP (Classical OT)</th>\n<td id=\"S5.T4.4.1.4.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 4.3pt;\">88.07±0.63</td>\n<td id=\"S5.T4.4.1.4.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 4.3pt;\">89.77±0.62</td>\n<td id=\"S5.T4.4.1.4.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 4.3pt;\">81.42±0.99</td>\n<td id=\"S5.T4.4.1.4.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 4.3pt;\">88.43±0.45</td>\n<td id=\"S5.T4.4.1.4.2.6\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 4.3pt;\">93.17±0.68</td>\n<td id=\"S5.T4.4.1.4.2.7\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 4.3pt;\">96.80±0.23</td>\n<td id=\"S5.T4.4.1.4.2.8\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 4.3pt;\">92.84±1.34</td>\n<td id=\"S5.T4.4.1.4.2.9\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 4.3pt;\">97.07±0.25</td>\n<td id=\"S5.T4.4.1.4.2.10\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 4.3pt;\">96.55±0.26</td>\n<td id=\"S5.T4.4.1.4.2.11\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 4.3pt;\">98.51±0.27</td>\n</tr>\n<tr id=\"S5.T4.4.1.5.3\" class=\"ltx_tr\">\n<th id=\"S5.T4.4.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" style=\"padding:0.5pt 4.3pt;\">FedOTP (Unbalanced OT)</th>\n<td id=\"S5.T4.4.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 4.3pt;\"><span id=\"S5.T4.4.1.5.3.2.1\" class=\"ltx_text ltx_font_bold\">89.12±0.28</span></td>\n<td id=\"S5.T4.4.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 4.3pt;\"><span id=\"S5.T4.4.1.5.3.3.1\" class=\"ltx_text ltx_font_bold\">92.94±0.18</span></td>\n<td id=\"S5.T4.4.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 4.3pt;\"><span id=\"S5.T4.4.1.5.3.4.1\" class=\"ltx_text ltx_font_bold\">85.50±0.35</span></td>\n<td id=\"S5.T4.4.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 4.3pt;\"><span id=\"S5.T4.4.1.5.3.5.1\" class=\"ltx_text ltx_font_bold\">90.25±0.74</span></td>\n<td id=\"S5.T4.4.1.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 4.3pt;\"><span id=\"S5.T4.4.1.5.3.6.1\" class=\"ltx_text ltx_font_bold\">95.05±0.49</span></td>\n<td id=\"S5.T4.4.1.5.3.7\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 4.3pt;\"><span id=\"S5.T4.4.1.5.3.7.1\" class=\"ltx_text ltx_font_bold\">97.34±0.18</span></td>\n<td id=\"S5.T4.4.1.5.3.8\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 4.3pt;\"><span id=\"S5.T4.4.1.5.3.8.1\" class=\"ltx_text ltx_font_bold\">93.96±0.48</span></td>\n<td id=\"S5.T4.4.1.5.3.9\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 4.3pt;\"><span id=\"S5.T4.4.1.5.3.9.1\" class=\"ltx_text ltx_font_bold\">98.23±0.32</span></td>\n<td id=\"S5.T4.4.1.5.3.10\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 4.3pt;\"><span id=\"S5.T4.4.1.5.3.10.1\" class=\"ltx_text ltx_font_bold\">97.73±0.57</span></td>\n<td id=\"S5.T4.4.1.5.3.11\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 4.3pt;\"><span id=\"S5.T4.4.1.5.3.11.1\" class=\"ltx_text ltx_font_bold\">99.02±0.38</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Effectiveness of the Unbalanced OT.\nIn this subsection, we explored the effectiveness of OT on two variants of FedOTP briefly described below: (1) FedOTP (Similarity Averaging): removing OT in FedOTP and matching global and local prompts with visual feature maps by averaging similarities of each visual-textual pair; (2) FedOTP (Classical OT): employing classical OT during the matching process.\nThe results in Table 4 demonstrate the effectiveness of utilizing OT to align feature maps with global and local prompts compared to FedOTP (Similarity Averaging) in almost all cases, particularly on the Food101 dataset.\nThis is because the absence of OT leads to the feature map’s distance from prompts reverting to the mean distance of each feature-prompt pair, highlighting the crucial role of OT in providing resilience to visual misalignment.\nIn addition, the persistent superiority of unbalanced OT over classical OT across all scenarios serves as a compelling testament to the effectiveness of our approach."
        ]
    },
    "A1.T1": {
        "caption": "Table A1: The detailed statistics of datasets used in experiments.",
        "table": "<table id=\"A1.T1.4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T1.4.1.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T1.4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Dataset</th>\n<th id=\"A1.T1.4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Task</th>\n<th id=\"A1.T1.4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Classes</th>\n<th id=\"A1.T1.4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Training Size</th>\n<th id=\"A1.T1.4.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Testing Size</th>\n<th id=\"A1.T1.4.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Domains</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T1.4.1.2.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.4.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Caltech101 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib20\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">20</span></a>]</cite>\n</td>\n<td id=\"A1.T1.4.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Object recognition</td>\n<td id=\"A1.T1.4.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">100</td>\n<td id=\"A1.T1.4.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">4,128</td>\n<td id=\"A1.T1.4.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">2,465</td>\n<td id=\"A1.T1.4.1.2.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">1</td>\n</tr>\n<tr id=\"A1.T1.4.1.3.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.4.1.3.2.1\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">Flowers102 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib54\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">54</span></a>]</cite>\n</td>\n<td id=\"A1.T1.4.1.3.2.2\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">Fine-grained flowers recognition</td>\n<td id=\"A1.T1.4.1.3.2.3\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">102</td>\n<td id=\"A1.T1.4.1.3.2.4\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">4,093</td>\n<td id=\"A1.T1.4.1.3.2.5\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">2,463</td>\n<td id=\"A1.T1.4.1.3.2.6\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">1</td>\n</tr>\n<tr id=\"A1.T1.4.1.4.3\" class=\"ltx_tr\">\n<td id=\"A1.T1.4.1.4.3.1\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">OxfordPets <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib56\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">56</span></a>]</cite>\n</td>\n<td id=\"A1.T1.4.1.4.3.2\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">Fine-grained pets recognition</td>\n<td id=\"A1.T1.4.1.4.3.3\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">37</td>\n<td id=\"A1.T1.4.1.4.3.4\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">2,944</td>\n<td id=\"A1.T1.4.1.4.3.5\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">3,669</td>\n<td id=\"A1.T1.4.1.4.3.6\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">1</td>\n</tr>\n<tr id=\"A1.T1.4.1.5.4\" class=\"ltx_tr\">\n<td id=\"A1.T1.4.1.5.4.1\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">Food101 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib3\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">3</span></a>]</cite>\n</td>\n<td id=\"A1.T1.4.1.5.4.2\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">Fine-grained food recognition</td>\n<td id=\"A1.T1.4.1.5.4.3\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">101</td>\n<td id=\"A1.T1.4.1.5.4.4\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">50,500</td>\n<td id=\"A1.T1.4.1.5.4.5\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">30,300</td>\n<td id=\"A1.T1.4.1.5.4.6\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">1</td>\n</tr>\n<tr id=\"A1.T1.4.1.6.5\" class=\"ltx_tr\">\n<td id=\"A1.T1.4.1.6.5.1\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">DTD <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">11</span></a>]</cite>\n</td>\n<td id=\"A1.T1.4.1.6.5.2\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">Texture recognition</td>\n<td id=\"A1.T1.4.1.6.5.3\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">47</td>\n<td id=\"A1.T1.4.1.6.5.4\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">2,820</td>\n<td id=\"A1.T1.4.1.6.5.5\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">1,692</td>\n<td id=\"A1.T1.4.1.6.5.6\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">1</td>\n</tr>\n<tr id=\"A1.T1.4.1.7.6\" class=\"ltx_tr\">\n<td id=\"A1.T1.4.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">CIFAR-10 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">36</span></a>]</cite>\n</td>\n<td id=\"A1.T1.4.1.7.6.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Image Classification</td>\n<td id=\"A1.T1.4.1.7.6.3\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">10</td>\n<td id=\"A1.T1.4.1.7.6.4\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">50,000</td>\n<td id=\"A1.T1.4.1.7.6.5\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">10,000</td>\n<td id=\"A1.T1.4.1.7.6.6\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">1</td>\n</tr>\n<tr id=\"A1.T1.4.1.8.7\" class=\"ltx_tr\">\n<td id=\"A1.T1.4.1.8.7.1\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">CIFAR-100 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">36</span></a>]</cite>\n</td>\n<td id=\"A1.T1.4.1.8.7.2\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">Image Classification</td>\n<td id=\"A1.T1.4.1.8.7.3\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">100</td>\n<td id=\"A1.T1.4.1.8.7.4\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">50,000</td>\n<td id=\"A1.T1.4.1.8.7.5\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">10,000</td>\n<td id=\"A1.T1.4.1.8.7.6\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">1</td>\n</tr>\n<tr id=\"A1.T1.4.1.9.8\" class=\"ltx_tr\">\n<td id=\"A1.T1.4.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">DomainNet <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib58\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">58</span></a>]</cite>\n</td>\n<td id=\"A1.T1.4.1.9.8.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Image recognition</td>\n<td id=\"A1.T1.4.1.9.8.3\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">10</td>\n<td id=\"A1.T1.4.1.9.8.4\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">18278</td>\n<td id=\"A1.T1.4.1.9.8.5\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">4573</td>\n<td id=\"A1.T1.4.1.9.8.6\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">6</td>\n</tr>\n<tr id=\"A1.T1.4.1.10.9\" class=\"ltx_tr\">\n<td id=\"A1.T1.4.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">Office-Caltech10 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">25</span></a>]</cite>\n</td>\n<td id=\"A1.T1.4.1.10.9.2\" class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">Image recognition</td>\n<td id=\"A1.T1.4.1.10.9.3\" class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">10</td>\n<td id=\"A1.T1.4.1.10.9.4\" class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">2025</td>\n<td id=\"A1.T1.4.1.10.9.5\" class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">508</td>\n<td id=\"A1.T1.4.1.10.9.6\" class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">4</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Recently, vision-language pre-trained models like Contrastive Language-Image Pretraining (CLIP) [60] have shown potential in learning robust and versatile representations suitable for various image distributions, aligning with the objectives of federated learning. However, the substantial communication overhead between the server and clients renders training CLIP in federated learning frameworks. Besides, overfitting concerns may arise when large-scale models are trained with limited client data. Prompt learning [46, 78] provides a flexible way to adapt pre-trained models to downstream tasks by training only additional parameters. This enables prompts to capture task-specific information while guiding the fixed model’s performance. Leveraging its lightweight nature, prior research [76, 27] has explored the integration of prompt learning into federated learning to overcome the problems outlined above.",
            "In real-world scenarios, client data often exhibits variations in domain discrepancies (feature shift) [44] or imbalanced class distributions (label shift) [40].\nSimply applying the FedAvg [52] method on prompts [27] across all clients tends to deviate from their local distribution, leading to unsatisfactory performance. Hence, it’s crucial to develop specialized personalized federated prompt learning approaches to effectively address data heterogeneity.\npFedPrompt [26] introduced personalization into federated prompt learning by maintaining personalized attention modules to generate spatial visual features locally while learning user consensus through shared text prompts. However, in the presence of a significant label shift or notable feature shift, merely learning a shared prompt in the language modality is inadequate.",
            "Model Evaluation on Label Shifts.\nWe first measured the performance of FedOTP against baselines on datasets with label shifts. The experimental results on CLIP datasets and CIFAR-10/CIFAR-100 datasets are summarized in Table 1 and Table 3. For easy comparison, Table 1 reports results utilizing ResNet50 as the backbone, maintaining consistency with [26]. As shown in Table 1, our FedOTP outperforms state-of-the-art algorithms by a large margin across all datasets, which confirms the effectiveness of our Global-Local prompt cooperation mechanism to handle label shift scenarios.\nRemarkably, while both PromptFL+FedPer (which splits the learnable prompt vector into “base+personalized” vectors) and pFedPrompt (utilizing a shared prompt with a personalized attention module in the vision modal) experience significant declines when datasets are altered, FedOTP exhibits slight fluctuations. This verifies the robustness of our method across diverse scenarios.\nTable 3 shows the results of our FedOTP and benchmark methods on CIFAR-10/CIFAR-100 datasets under Dirichlet setting over 100100100 clients with 10%percent1010\\% partition. Even in this scenario with Dirichlet settings and a large number of clients, FedOTP consistently outperforms the baseline methods, further highlighting the superiority of our approach.",
            "Model Evaluation on Feature &\\& Label Shifts.\nIn this set of experiments, we explored scenarios involving both feature shifts and label shifts by partitioning data within a domain into five clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1. We analyzed the mean and variance of clients in the same domain, and the outcomes for the DomainNet dataset are summarized in Table 2.\nIn the presence of two types of data heterogeneity, our method performs favorably against baselines. We observe that, with significant data heterogeneity across clients, traditional federated learning methods experience a pronounced performance decline compared to local training. In contrast, our FedOTP exhibits superior performance, achieving a 3.7%percent3.73.7\\% increase in average accuracy on each domain. Additional experimental results on feature shifts and in the Office-Caltech10 dataset are available in the Appendix Section C.1 and C.2.",
            "Effectiveness of the Unbalanced OT.\nIn this subsection, we explored the effectiveness of OT on two variants of FedOTP briefly described below: (1) FedOTP (Similarity Averaging): removing OT in FedOTP and matching global and local prompts with visual feature maps by averaging similarities of each visual-textual pair; (2) FedOTP (Classical OT): employing classical OT during the matching process.\nThe results in Table 4 demonstrate the effectiveness of utilizing OT to align feature maps with global and local prompts compared to FedOTP (Similarity Averaging) in almost all cases, particularly on the Food101 dataset.\nThis is because the absence of OT leads to the feature map’s distance from prompts reverting to the mean distance of each feature-prompt pair, highlighting the crucial role of OT in providing resilience to visual misalignment.\nIn addition, the persistent superiority of unbalanced OT over classical OT across all scenarios serves as a compelling testament to the effectiveness of our approach.",
            "We select nine representative visual classification datasets as our benchmark. The detailed statistics of each dataset are shown in Table A1, including the original tasks, the number of classes, the size of training and testing samples, and the number of domains.\nAs for datasets with multiple domains, Office-Caltech10 is a standard benchmark dataset consisting of four domains, namely Amazon, Caltech, DSLR, and WebCam, which are acquired using different camera devices or in different real environments with various backgrounds. DomainNet is a large-scale dataset consisting of six domains, namely Clipart, Infograph, Painting, Quickdraw, Real, and Sketch. We selected 10 classes from each of these two datasets for training. Some examples of raw instances of these two datasets can be found in Figure A1. For a clearer illustration, we visualize the three Non-IID settings employed in our paper in Figure A2.",
            "In Table A2, we compared the performance on Office-Caltech10 and DomainNet datasets under the presence of feature shift, where each client is assigned data from distinct domains while sharing the same label distribution. Our method achieved the highest average accuracies 99.16%percent99.1699.16\\% and 94.55%percent94.5594.55\\% on Office-Caltech10 and DomainNet, respectively.",
            "In this set of experiments, we investigated scenarios involving both feature shifts and label shifts by dividing data within a domain into three clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1 for the Office-Caltech10 dataset. We calculated the mean and standard deviation of clients in the same domain, and the outcomes are presented in Table A3. Comparing these results with those in Table A2, we can observe that the introduction of label shift leads to a performance decrease across all methods, with federated learning methods employing a shared prompt experiencing the most significant decline. In spite of this, our FedOTP consistently achieves the highest average accuracy, demonstrating its capability to utilize both global and local prompts to capture general domain-invariant and specific domain-specific knowledge for effective adaptation to extreme data heterogeneity.",
            "In this subsection, we delved into the effect of parameter γ𝛾\\gamma in unbalanced OT, which regulates the mapping size of prompts on the feature map. We conducted experiments on the Pathological Non-IID setting across four datasets with varying numbers of shots and different values of the parameter γ𝛾\\gamma in our FedOTP. Specifically, we set R=5𝑅5R=5 and T=10𝑇10T=10 for these experiments. The results presented in Table A4 reveal a notable trend: as the parameter γ𝛾\\gamma decreases, the overall performance initially increases and subsequently decreases. Interestingly, the majority of optimal results are observed at γ=0.8𝛾0.8\\gamma=0.8 or γ=0.7𝛾0.7\\gamma=0.7. This observation implies that the optimal alignment between global and local prompts and the feature map is achieved when the mapping size of prompts on the feature map is around 70%−80%percent70percent8070\\%-80\\%. Consequently, we adopt γ=0.8𝛾0.8\\gamma=0.8 in other experiments.",
            "In addressing the core challenge of data heterogeneity in personalized federated learning, FedOTP consistently outperforms benchmark methods across various settings. Now, we investigated the effect of heterogeneity in label distribution by considering a range of α𝛼\\alpha values of Dirichlet distribution, specifically α∈{0.1,0.3,0.5,1,5,10}𝛼0.10.30.51510\\alpha\\in\\{0.1,0.3,0.5,1,5,10\\} for CIFAR-100 datasets. It’s worth noting that a smaller α𝛼\\alpha implies a higher degree of data heterogeneity in these experiments. The results presented in Table A5 clearly indicate that as the degree of data heterogeneity increases, the performance of federated learning methods with a shared prompt decreases while the performance of CoOp and our FedOTP improves. Among these methods, FedOTP outperforms them in every case and demonstrates remarkable robustness. These findings underscore the effectiveness of FedOTP in overcoming label distribution heterogeneity across a diverse range of scenarios.",
            "To assess the convergence of our method, we plotted test accuracy curves with R=1𝑅1R=1 and T=50𝑇50T=50 for different methods across four datasets, as illustrated in\nFigure A3. Compared to other methods, FedOTP exhibits notable characteristics of accelerated convergence and enhanced stability, evident from the smaller fluctuations in test accuracy."
        ]
    },
    "A3.T2": {
        "caption": "Table A2: Experimental results on Office-Caltech10 and DomainNet datasets with feature shift.",
        "table": "<table id=\"A3.T2.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A3.T2.4.1.1.1\" class=\"ltx_tr\">\n<td id=\"A3.T2.4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Datasets</td>\n<td id=\"A3.T2.4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"5\">Office-Caltech10</td>\n<td id=\"A3.T2.4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"7\">DomainNet</td>\n</tr>\n<tr id=\"A3.T2.4.1.2.2\" class=\"ltx_tr\">\n<td id=\"A3.T2.4.1.2.2.1\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">Domains</td>\n<td id=\"A3.T2.4.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">A</td>\n<td id=\"A3.T2.4.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">C</td>\n<td id=\"A3.T2.4.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">D</td>\n<td id=\"A3.T2.4.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">W</td>\n<td id=\"A3.T2.4.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Avg.</td>\n<td id=\"A3.T2.4.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">C</td>\n<td id=\"A3.T2.4.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">I</td>\n<td id=\"A3.T2.4.1.2.2.9\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">P</td>\n<td id=\"A3.T2.4.1.2.2.10\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Q</td>\n<td id=\"A3.T2.4.1.2.2.11\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">R</td>\n<td id=\"A3.T2.4.1.2.2.12\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">S</td>\n<td id=\"A3.T2.4.1.2.2.13\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Avg.</td>\n</tr>\n<tr id=\"A3.T2.4.1.3.3\" class=\"ltx_tr\">\n<td id=\"A3.T2.4.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"13\"><span id=\"A3.T2.4.1.3.3.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Local Training</span></td>\n</tr>\n<tr id=\"A3.T2.4.1.4.4\" class=\"ltx_tr\">\n<td id=\"A3.T2.4.1.4.4.1\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">Zero-Shot CLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib60\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">60</span></a>]</cite>\n</td>\n<td id=\"A3.T2.4.1.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">19.3</td>\n<td id=\"A3.T2.4.1.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">18.2</td>\n<td id=\"A3.T2.4.1.4.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">21.9</td>\n<td id=\"A3.T2.4.1.4.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">18.6</td>\n<td id=\"A3.T2.4.1.4.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">19.50</td>\n<td id=\"A3.T2.4.1.4.4.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">49.92</td>\n<td id=\"A3.T2.4.1.4.4.8\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">47.15</td>\n<td id=\"A3.T2.4.1.4.4.9\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">53.63</td>\n<td id=\"A3.T2.4.1.4.4.10\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">31.3</td>\n<td id=\"A3.T2.4.1.4.4.11\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">48.4</td>\n<td id=\"A3.T2.4.1.4.4.12\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">50.18</td>\n<td id=\"A3.T2.4.1.4.4.13\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">46.76</td>\n</tr>\n<tr id=\"A3.T2.4.1.5.5\" class=\"ltx_tr\">\n<td id=\"A3.T2.4.1.5.5.1\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">CoOp <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib78\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">78</span></a>]</cite>\n</td>\n<td id=\"A3.T2.4.1.5.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.38</td>\n<td id=\"A3.T2.4.1.5.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.24</td>\n<td id=\"A3.T2.4.1.5.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">100</td>\n<td id=\"A3.T2.4.1.5.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.31</td>\n<td id=\"A3.T2.4.1.5.5.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.98</td>\n<td id=\"A3.T2.4.1.5.5.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.32</td>\n<td id=\"A3.T2.4.1.5.5.8\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">83.01</td>\n<td id=\"A3.T2.4.1.5.5.9\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.18</td>\n<td id=\"A3.T2.4.1.5.5.10\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">82.37</td>\n<td id=\"A3.T2.4.1.5.5.11\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.21</td>\n<td id=\"A3.T2.4.1.5.5.12\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.70</td>\n<td id=\"A3.T2.4.1.5.5.13\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">92.95</td>\n</tr>\n<tr id=\"A3.T2.4.1.6.6\" class=\"ltx_tr\">\n<td id=\"A3.T2.4.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"13\"><span id=\"A3.T2.4.1.6.6.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Prompt-based Federated Learning</span></td>\n</tr>\n<tr id=\"A3.T2.4.1.7.7\" class=\"ltx_tr\">\n<td id=\"A3.T2.4.1.7.7.1\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">PromptFL <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">27</span></a>]</cite>\n</td>\n<td id=\"A3.T2.4.1.7.7.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.41</td>\n<td id=\"A3.T2.4.1.7.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.39</td>\n<td id=\"A3.T2.4.1.7.7.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.90</td>\n<td id=\"A3.T2.4.1.7.7.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">100</td>\n<td id=\"A3.T2.4.1.7.7.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.42</td>\n<td id=\"A3.T2.4.1.7.7.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.23</td>\n<td id=\"A3.T2.4.1.7.7.8\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">79.91</td>\n<td id=\"A3.T2.4.1.7.7.9\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.89</td>\n<td id=\"A3.T2.4.1.7.7.10\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">66.52</td>\n<td id=\"A3.T2.4.1.7.7.11\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.83</td>\n<td id=\"A3.T2.4.1.7.7.12\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.31</td>\n<td id=\"A3.T2.4.1.7.7.13\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">89.45</td>\n</tr>\n<tr id=\"A3.T2.4.1.8.8\" class=\"ltx_tr\">\n<td id=\"A3.T2.4.1.8.8.1\" class=\"ltx_td ltx_align_left\" style=\"padding-top:1pt;padding-bottom:1pt;\">PromptFL+FedProx <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib42\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">42</span></a>]</cite>\n</td>\n<td id=\"A3.T2.4.1.8.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.93</td>\n<td id=\"A3.T2.4.1.8.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.21</td>\n<td id=\"A3.T2.4.1.8.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.89</td>\n<td id=\"A3.T2.4.1.8.8.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">100</td>\n<td id=\"A3.T2.4.1.8.8.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.01</td>\n<td id=\"A3.T2.4.1.8.8.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.45</td>\n<td id=\"A3.T2.4.1.8.8.8\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">72.32</td>\n<td id=\"A3.T2.4.1.8.8.9\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.00</td>\n<td id=\"A3.T2.4.1.8.8.10\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">63.51</td>\n<td id=\"A3.T2.4.1.8.8.11\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.08</td>\n<td id=\"A3.T2.4.1.8.8.12\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.04</td>\n<td id=\"A3.T2.4.1.8.8.13\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">87.40</td>\n</tr>\n<tr id=\"A3.T2.4.1.9.9\" class=\"ltx_tr\">\n<td id=\"A3.T2.4.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">FedOTP (Ours)</td>\n<td id=\"A3.T2.4.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.2.1\" class=\"ltx_text ltx_font_bold\">97.92</span></td>\n<td id=\"A3.T2.4.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.3.1\" class=\"ltx_text ltx_font_bold\">98.68</span></td>\n<td id=\"A3.T2.4.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.4.1\" class=\"ltx_text ltx_font_bold\">100</span></td>\n<td id=\"A3.T2.4.1.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.5.1\" class=\"ltx_text ltx_font_bold\">100</span></td>\n<td id=\"A3.T2.4.1.9.9.6\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.6.1\" class=\"ltx_text ltx_font_bold\">99.16</span></td>\n<td id=\"A3.T2.4.1.9.9.7\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.7.1\" class=\"ltx_text ltx_font_bold\">98.93</span></td>\n<td id=\"A3.T2.4.1.9.9.8\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.8.1\" class=\"ltx_text ltx_font_bold\">84.52</span></td>\n<td id=\"A3.T2.4.1.9.9.9\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.9.1\" class=\"ltx_text ltx_font_bold\">98.89</span></td>\n<td id=\"A3.T2.4.1.9.9.10\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.10.1\" class=\"ltx_text ltx_font_bold\">87.87</span></td>\n<td id=\"A3.T2.4.1.9.9.11\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.11.1\" class=\"ltx_text ltx_font_bold\">98.64</span></td>\n<td id=\"A3.T2.4.1.9.9.12\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.12.1\" class=\"ltx_text ltx_font_bold\">98.42</span></td>\n<td id=\"A3.T2.4.1.9.9.13\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T2.4.1.9.9.13.1\" class=\"ltx_text ltx_font_bold\">94.55</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Recently, vision-language pre-trained models like Contrastive Language-Image Pretraining (CLIP) [60] have shown potential in learning robust and versatile representations suitable for various image distributions, aligning with the objectives of federated learning. However, the substantial communication overhead between the server and clients renders training CLIP in federated learning frameworks. Besides, overfitting concerns may arise when large-scale models are trained with limited client data. Prompt learning [46, 78] provides a flexible way to adapt pre-trained models to downstream tasks by training only additional parameters. This enables prompts to capture task-specific information while guiding the fixed model’s performance. Leveraging its lightweight nature, prior research [76, 27] has explored the integration of prompt learning into federated learning to overcome the problems outlined above.",
            "In real-world scenarios, client data often exhibits variations in domain discrepancies (feature shift) [44] or imbalanced class distributions (label shift) [40].\nSimply applying the FedAvg [52] method on prompts [27] across all clients tends to deviate from their local distribution, leading to unsatisfactory performance. Hence, it’s crucial to develop specialized personalized federated prompt learning approaches to effectively address data heterogeneity.\npFedPrompt [26] introduced personalization into federated prompt learning by maintaining personalized attention modules to generate spatial visual features locally while learning user consensus through shared text prompts. However, in the presence of a significant label shift or notable feature shift, merely learning a shared prompt in the language modality is inadequate.",
            "Model Evaluation on Label Shifts.\nWe first measured the performance of FedOTP against baselines on datasets with label shifts. The experimental results on CLIP datasets and CIFAR-10/CIFAR-100 datasets are summarized in Table 1 and Table 3. For easy comparison, Table 1 reports results utilizing ResNet50 as the backbone, maintaining consistency with [26]. As shown in Table 1, our FedOTP outperforms state-of-the-art algorithms by a large margin across all datasets, which confirms the effectiveness of our Global-Local prompt cooperation mechanism to handle label shift scenarios.\nRemarkably, while both PromptFL+FedPer (which splits the learnable prompt vector into “base+personalized” vectors) and pFedPrompt (utilizing a shared prompt with a personalized attention module in the vision modal) experience significant declines when datasets are altered, FedOTP exhibits slight fluctuations. This verifies the robustness of our method across diverse scenarios.\nTable 3 shows the results of our FedOTP and benchmark methods on CIFAR-10/CIFAR-100 datasets under Dirichlet setting over 100100100 clients with 10%percent1010\\% partition. Even in this scenario with Dirichlet settings and a large number of clients, FedOTP consistently outperforms the baseline methods, further highlighting the superiority of our approach.",
            "Model Evaluation on Feature &\\& Label Shifts.\nIn this set of experiments, we explored scenarios involving both feature shifts and label shifts by partitioning data within a domain into five clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1. We analyzed the mean and variance of clients in the same domain, and the outcomes for the DomainNet dataset are summarized in Table 2.\nIn the presence of two types of data heterogeneity, our method performs favorably against baselines. We observe that, with significant data heterogeneity across clients, traditional federated learning methods experience a pronounced performance decline compared to local training. In contrast, our FedOTP exhibits superior performance, achieving a 3.7%percent3.73.7\\% increase in average accuracy on each domain. Additional experimental results on feature shifts and in the Office-Caltech10 dataset are available in the Appendix Section C.1 and C.2.",
            "Effectiveness of the Unbalanced OT.\nIn this subsection, we explored the effectiveness of OT on two variants of FedOTP briefly described below: (1) FedOTP (Similarity Averaging): removing OT in FedOTP and matching global and local prompts with visual feature maps by averaging similarities of each visual-textual pair; (2) FedOTP (Classical OT): employing classical OT during the matching process.\nThe results in Table 4 demonstrate the effectiveness of utilizing OT to align feature maps with global and local prompts compared to FedOTP (Similarity Averaging) in almost all cases, particularly on the Food101 dataset.\nThis is because the absence of OT leads to the feature map’s distance from prompts reverting to the mean distance of each feature-prompt pair, highlighting the crucial role of OT in providing resilience to visual misalignment.\nIn addition, the persistent superiority of unbalanced OT over classical OT across all scenarios serves as a compelling testament to the effectiveness of our approach.",
            "We select nine representative visual classification datasets as our benchmark. The detailed statistics of each dataset are shown in Table A1, including the original tasks, the number of classes, the size of training and testing samples, and the number of domains.\nAs for datasets with multiple domains, Office-Caltech10 is a standard benchmark dataset consisting of four domains, namely Amazon, Caltech, DSLR, and WebCam, which are acquired using different camera devices or in different real environments with various backgrounds. DomainNet is a large-scale dataset consisting of six domains, namely Clipart, Infograph, Painting, Quickdraw, Real, and Sketch. We selected 10 classes from each of these two datasets for training. Some examples of raw instances of these two datasets can be found in Figure A1. For a clearer illustration, we visualize the three Non-IID settings employed in our paper in Figure A2.",
            "In Table A2, we compared the performance on Office-Caltech10 and DomainNet datasets under the presence of feature shift, where each client is assigned data from distinct domains while sharing the same label distribution. Our method achieved the highest average accuracies 99.16%percent99.1699.16\\% and 94.55%percent94.5594.55\\% on Office-Caltech10 and DomainNet, respectively.",
            "In this set of experiments, we investigated scenarios involving both feature shifts and label shifts by dividing data within a domain into three clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1 for the Office-Caltech10 dataset. We calculated the mean and standard deviation of clients in the same domain, and the outcomes are presented in Table A3. Comparing these results with those in Table A2, we can observe that the introduction of label shift leads to a performance decrease across all methods, with federated learning methods employing a shared prompt experiencing the most significant decline. In spite of this, our FedOTP consistently achieves the highest average accuracy, demonstrating its capability to utilize both global and local prompts to capture general domain-invariant and specific domain-specific knowledge for effective adaptation to extreme data heterogeneity.",
            "In this subsection, we delved into the effect of parameter γ𝛾\\gamma in unbalanced OT, which regulates the mapping size of prompts on the feature map. We conducted experiments on the Pathological Non-IID setting across four datasets with varying numbers of shots and different values of the parameter γ𝛾\\gamma in our FedOTP. Specifically, we set R=5𝑅5R=5 and T=10𝑇10T=10 for these experiments. The results presented in Table A4 reveal a notable trend: as the parameter γ𝛾\\gamma decreases, the overall performance initially increases and subsequently decreases. Interestingly, the majority of optimal results are observed at γ=0.8𝛾0.8\\gamma=0.8 or γ=0.7𝛾0.7\\gamma=0.7. This observation implies that the optimal alignment between global and local prompts and the feature map is achieved when the mapping size of prompts on the feature map is around 70%−80%percent70percent8070\\%-80\\%. Consequently, we adopt γ=0.8𝛾0.8\\gamma=0.8 in other experiments.",
            "In addressing the core challenge of data heterogeneity in personalized federated learning, FedOTP consistently outperforms benchmark methods across various settings. Now, we investigated the effect of heterogeneity in label distribution by considering a range of α𝛼\\alpha values of Dirichlet distribution, specifically α∈{0.1,0.3,0.5,1,5,10}𝛼0.10.30.51510\\alpha\\in\\{0.1,0.3,0.5,1,5,10\\} for CIFAR-100 datasets. It’s worth noting that a smaller α𝛼\\alpha implies a higher degree of data heterogeneity in these experiments. The results presented in Table A5 clearly indicate that as the degree of data heterogeneity increases, the performance of federated learning methods with a shared prompt decreases while the performance of CoOp and our FedOTP improves. Among these methods, FedOTP outperforms them in every case and demonstrates remarkable robustness. These findings underscore the effectiveness of FedOTP in overcoming label distribution heterogeneity across a diverse range of scenarios.",
            "To assess the convergence of our method, we plotted test accuracy curves with R=1𝑅1R=1 and T=50𝑇50T=50 for different methods across four datasets, as illustrated in\nFigure A3. Compared to other methods, FedOTP exhibits notable characteristics of accelerated convergence and enhanced stability, evident from the smaller fluctuations in test accuracy."
        ]
    },
    "A3.T3": {
        "caption": "Table A3: Experimental results on Office-Caltech10 dataset with feature &\\& label shifts.",
        "table": "<table id=\"A3.T3.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A3.T3.5.1.1.1\" class=\"ltx_tr\">\n<th id=\"A3.T3.5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Datasets</th>\n<td id=\"A3.T3.5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"5\">Office-Caltech10</td>\n</tr>\n<tr id=\"A3.T3.5.1.2.2\" class=\"ltx_tr\">\n<th id=\"A3.T3.5.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">Domains</th>\n<td id=\"A3.T3.5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Amazon</td>\n<td id=\"A3.T3.5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Caltech</td>\n<td id=\"A3.T3.5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">DSLR</td>\n<td id=\"A3.T3.5.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Webcam</td>\n<td id=\"A3.T3.5.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Avg.</td>\n</tr>\n<tr id=\"A3.T3.5.1.3.3\" class=\"ltx_tr\">\n<th id=\"A3.T3.5.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"6\"><span id=\"A3.T3.5.1.3.3.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Local Training</span></th>\n</tr>\n<tr id=\"A3.T3.5.1.4.4\" class=\"ltx_tr\">\n<th id=\"A3.T3.5.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">Zero-Shot CLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib60\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">60</span></a>]</cite>\n</th>\n<td id=\"A3.T3.5.1.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">8.45±1.49</td>\n<td id=\"A3.T3.5.1.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">6.01±4.25</td>\n<td id=\"A3.T3.5.1.4.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">12.92±9.15</td>\n<td id=\"A3.T3.5.1.4.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">6.48±4.82</td>\n<td id=\"A3.T3.5.1.4.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">8.46±6.26</td>\n</tr>\n<tr id=\"A3.T3.5.1.5.5\" class=\"ltx_tr\">\n<th id=\"A3.T3.5.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">CoOp <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib78\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">78</span></a>]</cite>\n</th>\n<td id=\"A3.T3.5.1.5.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T3.5.1.5.5.2.1\" class=\"ltx_text ltx_font_bold\">25.59±6.60</span></td>\n<td id=\"A3.T3.5.1.5.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T3.5.1.5.5.3.1\" class=\"ltx_text ltx_font_bold\">36.23±16.97</span></td>\n<td id=\"A3.T3.5.1.5.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">30.30±5.18</td>\n<td id=\"A3.T3.5.1.5.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">22.56±5.46</td>\n<td id=\"A3.T3.5.1.5.5.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">28.67±11.13</td>\n</tr>\n<tr id=\"A3.T3.5.1.6.6\" class=\"ltx_tr\">\n<th id=\"A3.T3.5.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"6\"><span id=\"A3.T3.5.1.6.6.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Prompt-based Federated Learning</span></th>\n</tr>\n<tr id=\"A3.T3.5.1.7.7\" class=\"ltx_tr\">\n<th id=\"A3.T3.5.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">PromptFL <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">27</span></a>]</cite>\n</th>\n<td id=\"A3.T3.5.1.7.7.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">10.92±4.36</td>\n<td id=\"A3.T3.5.1.7.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">10.37±12.63</td>\n<td id=\"A3.T3.5.1.7.7.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">15.45±15.34</td>\n<td id=\"A3.T3.5.1.7.7.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">15.90±17.33</td>\n<td id=\"A3.T3.5.1.7.7.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">13.16±13.60</td>\n</tr>\n<tr id=\"A3.T3.5.1.8.8\" class=\"ltx_tr\">\n<th id=\"A3.T3.5.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">PromptFL+FedProx <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib42\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">42</span></a>]</cite>\n</th>\n<td id=\"A3.T3.5.1.8.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">11.05±4.70</td>\n<td id=\"A3.T3.5.1.8.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">12.04±10.65</td>\n<td id=\"A3.T3.5.1.8.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">19.70±21.74</td>\n<td id=\"A3.T3.5.1.8.8.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">12.56±12.72</td>\n<td id=\"A3.T3.5.1.8.8.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">13.84±14.29</td>\n</tr>\n<tr id=\"A3.T3.5.1.9.9\" class=\"ltx_tr\">\n<th id=\"A3.T3.5.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">FedOTP (Ours)</th>\n<td id=\"A3.T3.5.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">23.59±4.74</td>\n<td id=\"A3.T3.5.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">31.64±5.25</td>\n<td id=\"A3.T3.5.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T3.5.1.9.9.4.1\" class=\"ltx_text ltx_font_bold\">43.94±5.67</span></td>\n<td id=\"A3.T3.5.1.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T3.5.1.9.9.5.1\" class=\"ltx_text ltx_font_bold\">35.51±9.19</span></td>\n<td id=\"A3.T3.5.1.9.9.6\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T3.5.1.9.9.6.1\" class=\"ltx_text ltx_font_bold\">33.67±9.76</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Recently, vision-language pre-trained models like Contrastive Language-Image Pretraining (CLIP) [60] have shown potential in learning robust and versatile representations suitable for various image distributions, aligning with the objectives of federated learning. However, the substantial communication overhead between the server and clients renders training CLIP in federated learning frameworks. Besides, overfitting concerns may arise when large-scale models are trained with limited client data. Prompt learning [46, 78] provides a flexible way to adapt pre-trained models to downstream tasks by training only additional parameters. This enables prompts to capture task-specific information while guiding the fixed model’s performance. Leveraging its lightweight nature, prior research [76, 27] has explored the integration of prompt learning into federated learning to overcome the problems outlined above.",
            "In real-world scenarios, client data often exhibits variations in domain discrepancies (feature shift) [44] or imbalanced class distributions (label shift) [40].\nSimply applying the FedAvg [52] method on prompts [27] across all clients tends to deviate from their local distribution, leading to unsatisfactory performance. Hence, it’s crucial to develop specialized personalized federated prompt learning approaches to effectively address data heterogeneity.\npFedPrompt [26] introduced personalization into federated prompt learning by maintaining personalized attention modules to generate spatial visual features locally while learning user consensus through shared text prompts. However, in the presence of a significant label shift or notable feature shift, merely learning a shared prompt in the language modality is inadequate.",
            "Model Evaluation on Label Shifts.\nWe first measured the performance of FedOTP against baselines on datasets with label shifts. The experimental results on CLIP datasets and CIFAR-10/CIFAR-100 datasets are summarized in Table 1 and Table 3. For easy comparison, Table 1 reports results utilizing ResNet50 as the backbone, maintaining consistency with [26]. As shown in Table 1, our FedOTP outperforms state-of-the-art algorithms by a large margin across all datasets, which confirms the effectiveness of our Global-Local prompt cooperation mechanism to handle label shift scenarios.\nRemarkably, while both PromptFL+FedPer (which splits the learnable prompt vector into “base+personalized” vectors) and pFedPrompt (utilizing a shared prompt with a personalized attention module in the vision modal) experience significant declines when datasets are altered, FedOTP exhibits slight fluctuations. This verifies the robustness of our method across diverse scenarios.\nTable 3 shows the results of our FedOTP and benchmark methods on CIFAR-10/CIFAR-100 datasets under Dirichlet setting over 100100100 clients with 10%percent1010\\% partition. Even in this scenario with Dirichlet settings and a large number of clients, FedOTP consistently outperforms the baseline methods, further highlighting the superiority of our approach.",
            "Model Evaluation on Feature &\\& Label Shifts.\nIn this set of experiments, we explored scenarios involving both feature shifts and label shifts by partitioning data within a domain into five clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1. We analyzed the mean and variance of clients in the same domain, and the outcomes for the DomainNet dataset are summarized in Table 2.\nIn the presence of two types of data heterogeneity, our method performs favorably against baselines. We observe that, with significant data heterogeneity across clients, traditional federated learning methods experience a pronounced performance decline compared to local training. In contrast, our FedOTP exhibits superior performance, achieving a 3.7%percent3.73.7\\% increase in average accuracy on each domain. Additional experimental results on feature shifts and in the Office-Caltech10 dataset are available in the Appendix Section C.1 and C.2.",
            "Effectiveness of the Unbalanced OT.\nIn this subsection, we explored the effectiveness of OT on two variants of FedOTP briefly described below: (1) FedOTP (Similarity Averaging): removing OT in FedOTP and matching global and local prompts with visual feature maps by averaging similarities of each visual-textual pair; (2) FedOTP (Classical OT): employing classical OT during the matching process.\nThe results in Table 4 demonstrate the effectiveness of utilizing OT to align feature maps with global and local prompts compared to FedOTP (Similarity Averaging) in almost all cases, particularly on the Food101 dataset.\nThis is because the absence of OT leads to the feature map’s distance from prompts reverting to the mean distance of each feature-prompt pair, highlighting the crucial role of OT in providing resilience to visual misalignment.\nIn addition, the persistent superiority of unbalanced OT over classical OT across all scenarios serves as a compelling testament to the effectiveness of our approach.",
            "We select nine representative visual classification datasets as our benchmark. The detailed statistics of each dataset are shown in Table A1, including the original tasks, the number of classes, the size of training and testing samples, and the number of domains.\nAs for datasets with multiple domains, Office-Caltech10 is a standard benchmark dataset consisting of four domains, namely Amazon, Caltech, DSLR, and WebCam, which are acquired using different camera devices or in different real environments with various backgrounds. DomainNet is a large-scale dataset consisting of six domains, namely Clipart, Infograph, Painting, Quickdraw, Real, and Sketch. We selected 10 classes from each of these two datasets for training. Some examples of raw instances of these two datasets can be found in Figure A1. For a clearer illustration, we visualize the three Non-IID settings employed in our paper in Figure A2.",
            "In Table A2, we compared the performance on Office-Caltech10 and DomainNet datasets under the presence of feature shift, where each client is assigned data from distinct domains while sharing the same label distribution. Our method achieved the highest average accuracies 99.16%percent99.1699.16\\% and 94.55%percent94.5594.55\\% on Office-Caltech10 and DomainNet, respectively.",
            "In this set of experiments, we investigated scenarios involving both feature shifts and label shifts by dividing data within a domain into three clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1 for the Office-Caltech10 dataset. We calculated the mean and standard deviation of clients in the same domain, and the outcomes are presented in Table A3. Comparing these results with those in Table A2, we can observe that the introduction of label shift leads to a performance decrease across all methods, with federated learning methods employing a shared prompt experiencing the most significant decline. In spite of this, our FedOTP consistently achieves the highest average accuracy, demonstrating its capability to utilize both global and local prompts to capture general domain-invariant and specific domain-specific knowledge for effective adaptation to extreme data heterogeneity.",
            "In this subsection, we delved into the effect of parameter γ𝛾\\gamma in unbalanced OT, which regulates the mapping size of prompts on the feature map. We conducted experiments on the Pathological Non-IID setting across four datasets with varying numbers of shots and different values of the parameter γ𝛾\\gamma in our FedOTP. Specifically, we set R=5𝑅5R=5 and T=10𝑇10T=10 for these experiments. The results presented in Table A4 reveal a notable trend: as the parameter γ𝛾\\gamma decreases, the overall performance initially increases and subsequently decreases. Interestingly, the majority of optimal results are observed at γ=0.8𝛾0.8\\gamma=0.8 or γ=0.7𝛾0.7\\gamma=0.7. This observation implies that the optimal alignment between global and local prompts and the feature map is achieved when the mapping size of prompts on the feature map is around 70%−80%percent70percent8070\\%-80\\%. Consequently, we adopt γ=0.8𝛾0.8\\gamma=0.8 in other experiments.",
            "In addressing the core challenge of data heterogeneity in personalized federated learning, FedOTP consistently outperforms benchmark methods across various settings. Now, we investigated the effect of heterogeneity in label distribution by considering a range of α𝛼\\alpha values of Dirichlet distribution, specifically α∈{0.1,0.3,0.5,1,5,10}𝛼0.10.30.51510\\alpha\\in\\{0.1,0.3,0.5,1,5,10\\} for CIFAR-100 datasets. It’s worth noting that a smaller α𝛼\\alpha implies a higher degree of data heterogeneity in these experiments. The results presented in Table A5 clearly indicate that as the degree of data heterogeneity increases, the performance of federated learning methods with a shared prompt decreases while the performance of CoOp and our FedOTP improves. Among these methods, FedOTP outperforms them in every case and demonstrates remarkable robustness. These findings underscore the effectiveness of FedOTP in overcoming label distribution heterogeneity across a diverse range of scenarios.",
            "To assess the convergence of our method, we plotted test accuracy curves with R=1𝑅1R=1 and T=50𝑇50T=50 for different methods across four datasets, as illustrated in\nFigure A3. Compared to other methods, FedOTP exhibits notable characteristics of accelerated convergence and enhanced stability, evident from the smaller fluctuations in test accuracy."
        ]
    },
    "A3.T4": {
        "caption": "Table A4: Quantitative comparisons on the Pathological Non-IID setting across varying numbers of shots with different parameter γ𝛾\\gamma in our FedOTP over 10 clients.",
        "table": "<table id=\"A3.T4.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A3.T4.5.1.1.1\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Dataset</th>\n<th id=\"A3.T4.5.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">shot number</th>\n<th id=\"A3.T4.5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">1</th>\n<th id=\"A3.T4.5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.9</th>\n<th id=\"A3.T4.5.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.8</th>\n<th id=\"A3.T4.5.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.7</th>\n<th id=\"A3.T4.5.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.6</th>\n<th id=\"A3.T4.5.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.5</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A3.T4.5.1.2.1\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" rowspan=\"5\"><span id=\"A3.T4.5.1.2.1.1.1\" class=\"ltx_text\">DTD</span></th>\n<th id=\"A3.T4.5.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">1 shot</th>\n<td id=\"A3.T4.5.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.22±0.75</td>\n<td id=\"A3.T4.5.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">73.72±0.79</td>\n<td id=\"A3.T4.5.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">75.75±0.64</td>\n<td id=\"A3.T4.5.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">72.81±0.42</td>\n<td id=\"A3.T4.5.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.2.1.7.1\" class=\"ltx_text ltx_font_bold\">77.36±0.98</span></td>\n<td id=\"A3.T4.5.1.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">77.22±1.46</td>\n</tr>\n<tr id=\"A3.T4.5.1.3.2\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">2 shots</th>\n<td id=\"A3.T4.5.1.3.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">81.89±0.76</td>\n<td id=\"A3.T4.5.1.3.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">84.03±0.57</td>\n<td id=\"A3.T4.5.1.3.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">84.64±0.29</td>\n<td id=\"A3.T4.5.1.3.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.3.2.5.1\" class=\"ltx_text ltx_font_bold\">85.50±0.35</span></td>\n<td id=\"A3.T4.5.1.3.2.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">80.39±0.24</td>\n<td id=\"A3.T4.5.1.3.2.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">82.47±0.40</td>\n</tr>\n<tr id=\"A3.T4.5.1.4.3\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">4 shots</th>\n<td id=\"A3.T4.5.1.4.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">85.06±0.91</td>\n<td id=\"A3.T4.5.1.4.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">85.75±0.63</td>\n<td id=\"A3.T4.5.1.4.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">86.69±0.61</td>\n<td id=\"A3.T4.5.1.4.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.4.3.5.1\" class=\"ltx_text ltx_font_bold\">87.67±0.70</span></td>\n<td id=\"A3.T4.5.1.4.3.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">86.58±0.51</td>\n<td id=\"A3.T4.5.1.4.3.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">85.86±0.44</td>\n</tr>\n<tr id=\"A3.T4.5.1.5.4\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">8 shots</th>\n<td id=\"A3.T4.5.1.5.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">88.64±0.31</td>\n<td id=\"A3.T4.5.1.5.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">88.22±0.30</td>\n<td id=\"A3.T4.5.1.5.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">89.77±0.24</td>\n<td id=\"A3.T4.5.1.5.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\">90.25±0.74</span></td>\n<td id=\"A3.T4.5.1.5.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">89.17±0.53</td>\n<td id=\"A3.T4.5.1.5.4.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">89.67±0.51</td>\n</tr>\n<tr id=\"A3.T4.5.1.6.5\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">16 shots</th>\n<td id=\"A3.T4.5.1.6.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">90.51±0.11</td>\n<td id=\"A3.T4.5.1.6.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">91.02±0.48</td>\n<td id=\"A3.T4.5.1.6.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.6.5.4.1\" class=\"ltx_text ltx_font_bold\">91.31±0.59</span></td>\n<td id=\"A3.T4.5.1.6.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">90.94±0.25</td>\n<td id=\"A3.T4.5.1.6.5.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">89.97±0.34</td>\n<td id=\"A3.T4.5.1.6.5.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">90.33±0.51</td>\n</tr>\n<tr id=\"A3.T4.5.1.7.6\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" rowspan=\"5\"><span id=\"A3.T4.5.1.7.6.1.1\" class=\"ltx_text\">Caltech101</span></th>\n<th id=\"A3.T4.5.1.7.6.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">1 shot</th>\n<td id=\"A3.T4.5.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">89.68±1.19</td>\n<td id=\"A3.T4.5.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">92.13±0.58</td>\n<td id=\"A3.T4.5.1.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.7.6.5.1\" class=\"ltx_text ltx_font_bold\">92.54±0.71</span></td>\n<td id=\"A3.T4.5.1.7.6.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">91.53±0.55</td>\n<td id=\"A3.T4.5.1.7.6.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">90.10±1.74</td>\n<td id=\"A3.T4.5.1.7.6.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">90.67±0.44</td>\n</tr>\n<tr id=\"A3.T4.5.1.8.7\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">2 shots</th>\n<td id=\"A3.T4.5.1.8.7.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.8.7.2.1\" class=\"ltx_text ltx_font_bold\">95.05±0.49</span></td>\n<td id=\"A3.T4.5.1.8.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">93.89±0.35</td>\n<td id=\"A3.T4.5.1.8.7.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">94.45±0.32</td>\n<td id=\"A3.T4.5.1.8.7.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">94.37±0.43</td>\n<td id=\"A3.T4.5.1.8.7.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">93.89±0.65</td>\n<td id=\"A3.T4.5.1.8.7.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">94.68±0.92</td>\n</tr>\n<tr id=\"A3.T4.5.1.9.8\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">4 shots</th>\n<td id=\"A3.T4.5.1.9.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.02±0.36</td>\n<td id=\"A3.T4.5.1.9.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.64±0.41</td>\n<td id=\"A3.T4.5.1.9.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.9.8.4.1\" class=\"ltx_text ltx_font_bold\">97.02±0.36</span></td>\n<td id=\"A3.T4.5.1.9.8.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.68±0.46</td>\n<td id=\"A3.T4.5.1.9.8.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.38±0.42</td>\n<td id=\"A3.T4.5.1.9.8.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.66±0.37</td>\n</tr>\n<tr id=\"A3.T4.5.1.10.9\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">8 shots</th>\n<td id=\"A3.T4.5.1.10.9.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.74±0.21</td>\n<td id=\"A3.T4.5.1.10.9.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.79±0.24</td>\n<td id=\"A3.T4.5.1.10.9.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.91±0.16</td>\n<td id=\"A3.T4.5.1.10.9.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.95±0.26</td>\n<td id=\"A3.T4.5.1.10.9.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.22±0.33</td>\n<td id=\"A3.T4.5.1.10.9.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.10.9.7.1\" class=\"ltx_text ltx_font_bold\">97.34±0.18</span></td>\n</tr>\n<tr id=\"A3.T4.5.1.11.10\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.11.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">16 shots</th>\n<td id=\"A3.T4.5.1.11.10.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.72±0.14</td>\n<td id=\"A3.T4.5.1.11.10.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.69±0.17</td>\n<td id=\"A3.T4.5.1.11.10.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.39±0.11</td>\n<td id=\"A3.T4.5.1.11.10.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.58±0.23</td>\n<td id=\"A3.T4.5.1.11.10.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.74±0.19</td>\n<td id=\"A3.T4.5.1.11.10.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.11.10.7.1\" class=\"ltx_text ltx_font_bold\">97.83±0.18</span></td>\n</tr>\n<tr id=\"A3.T4.5.1.12.11\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.12.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" rowspan=\"5\"><span id=\"A3.T4.5.1.12.11.1.1\" class=\"ltx_text\">Flowers102</span></th>\n<th id=\"A3.T4.5.1.12.11.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">1 shot</th>\n<td id=\"A3.T4.5.1.12.11.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">86.68±1.93</td>\n<td id=\"A3.T4.5.1.12.11.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">85.77±0.74</td>\n<td id=\"A3.T4.5.1.12.11.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">87.42±0.92</td>\n<td id=\"A3.T4.5.1.12.11.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">88.43±0.90</td>\n<td id=\"A3.T4.5.1.12.11.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.12.11.7.1\" class=\"ltx_text ltx_font_bold\">89.14±1.18</span></td>\n<td id=\"A3.T4.5.1.12.11.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">85.56±1.21</td>\n</tr>\n<tr id=\"A3.T4.5.1.13.12\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.13.12.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">2 shots</th>\n<td id=\"A3.T4.5.1.13.12.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">93.09±1.26</td>\n<td id=\"A3.T4.5.1.13.12.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.13.12.3.1\" class=\"ltx_text ltx_font_bold\">93.96±0.48</span></td>\n<td id=\"A3.T4.5.1.13.12.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">93.31±0.55</td>\n<td id=\"A3.T4.5.1.13.12.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">93.13±0.26</td>\n<td id=\"A3.T4.5.1.13.12.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">93.70±0.49</td>\n<td id=\"A3.T4.5.1.13.12.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">93.56±0.86</td>\n</tr>\n<tr id=\"A3.T4.5.1.14.13\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.14.13.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">4 shots</th>\n<td id=\"A3.T4.5.1.14.13.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">95.46±0.55</td>\n<td id=\"A3.T4.5.1.14.13.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.14.13.3.1\" class=\"ltx_text ltx_font_bold\">96.23±0.44</span></td>\n<td id=\"A3.T4.5.1.14.13.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">95.51±0.30</td>\n<td id=\"A3.T4.5.1.14.13.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">95.89±0.50</td>\n<td id=\"A3.T4.5.1.14.13.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.17±0.47</td>\n<td id=\"A3.T4.5.1.14.13.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.16±0.34</td>\n</tr>\n<tr id=\"A3.T4.5.1.15.14\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.15.14.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">8 shots</th>\n<td id=\"A3.T4.5.1.15.14.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.53±0.24</td>\n<td id=\"A3.T4.5.1.15.14.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.49±0.19</td>\n<td id=\"A3.T4.5.1.15.14.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.15.14.4.1\" class=\"ltx_text ltx_font_bold\">98.23±0.32</span></td>\n<td id=\"A3.T4.5.1.15.14.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.11±0.27</td>\n<td id=\"A3.T4.5.1.15.14.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.24±0.28</td>\n<td id=\"A3.T4.5.1.15.14.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.40±0.64</td>\n</tr>\n<tr id=\"A3.T4.5.1.16.15\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.16.15.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">16 shots</th>\n<td id=\"A3.T4.5.1.16.15.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.86±0.15</td>\n<td id=\"A3.T4.5.1.16.15.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.30±0.55</td>\n<td id=\"A3.T4.5.1.16.15.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.16.15.4.1\" class=\"ltx_text ltx_font_bold\">99.11±0.11</span></td>\n<td id=\"A3.T4.5.1.16.15.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.88±0.17</td>\n<td id=\"A3.T4.5.1.16.15.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">99.03±0.12</td>\n<td id=\"A3.T4.5.1.16.15.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.93±0.18</td>\n</tr>\n<tr id=\"A3.T4.5.1.17.16\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.17.16.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" rowspan=\"5\"><span id=\"A3.T4.5.1.17.16.1.1\" class=\"ltx_text\">OxfordPets</span></th>\n<th id=\"A3.T4.5.1.17.16.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">1 shot</th>\n<td id=\"A3.T4.5.1.17.16.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">95.82±1.16</td>\n<td id=\"A3.T4.5.1.17.16.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">94.26±0.38</td>\n<td id=\"A3.T4.5.1.17.16.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.18±0.71</td>\n<td id=\"A3.T4.5.1.17.16.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.17.16.6.1\" class=\"ltx_text ltx_font_bold\">96.37±0.79</span></td>\n<td id=\"A3.T4.5.1.17.16.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">94.21±0.53</td>\n<td id=\"A3.T4.5.1.17.16.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">95.97±0.42</td>\n</tr>\n<tr id=\"A3.T4.5.1.18.17\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.18.17.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">2 shots</th>\n<td id=\"A3.T4.5.1.18.17.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.18.17.2.1\" class=\"ltx_text ltx_font_bold\">97.73±0.57</span></td>\n<td id=\"A3.T4.5.1.18.17.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">96.12±0.32</td>\n<td id=\"A3.T4.5.1.18.17.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.50±1.02</td>\n<td id=\"A3.T4.5.1.18.17.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.49±0.45</td>\n<td id=\"A3.T4.5.1.18.17.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.60±0.40</td>\n<td id=\"A3.T4.5.1.18.17.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">97.27±0.19</td>\n</tr>\n<tr id=\"A3.T4.5.1.19.18\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.19.18.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">4 shots</th>\n<td id=\"A3.T4.5.1.19.18.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.11±1.15</td>\n<td id=\"A3.T4.5.1.19.18.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.46±0.64</td>\n<td id=\"A3.T4.5.1.19.18.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.19.18.4.1\" class=\"ltx_text ltx_font_bold\">98.82±0.11</span></td>\n<td id=\"A3.T4.5.1.19.18.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.51±0.10</td>\n<td id=\"A3.T4.5.1.19.18.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.52±0.25</td>\n<td id=\"A3.T4.5.1.19.18.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.43±0.28</td>\n</tr>\n<tr id=\"A3.T4.5.1.20.19\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.20.19.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">8 shots</th>\n<td id=\"A3.T4.5.1.20.19.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.73±0.27</td>\n<td id=\"A3.T4.5.1.20.19.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.20.19.3.1\" class=\"ltx_text ltx_font_bold\">99.02±0.38</span></td>\n<td id=\"A3.T4.5.1.20.19.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.71±0.16</td>\n<td id=\"A3.T4.5.1.20.19.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.74±0.18</td>\n<td id=\"A3.T4.5.1.20.19.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.54±0.22</td>\n<td id=\"A3.T4.5.1.20.19.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.63±0.13</td>\n</tr>\n<tr id=\"A3.T4.5.1.21.20\" class=\"ltx_tr\">\n<th id=\"A3.T4.5.1.21.20.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">16 shots</th>\n<td id=\"A3.T4.5.1.21.20.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">99.04±0.16</td>\n<td id=\"A3.T4.5.1.21.20.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.82±0.25</td>\n<td id=\"A3.T4.5.1.21.20.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T4.5.1.21.20.4.1\" class=\"ltx_text ltx_font_bold\">99.27±0.23</span></td>\n<td id=\"A3.T4.5.1.21.20.5\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">99.21±0.19</td>\n<td id=\"A3.T4.5.1.21.20.6\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">99.04±0.27</td>\n<td id=\"A3.T4.5.1.21.20.7\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">98.81±0.21</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Recently, vision-language pre-trained models like Contrastive Language-Image Pretraining (CLIP) [60] have shown potential in learning robust and versatile representations suitable for various image distributions, aligning with the objectives of federated learning. However, the substantial communication overhead between the server and clients renders training CLIP in federated learning frameworks. Besides, overfitting concerns may arise when large-scale models are trained with limited client data. Prompt learning [46, 78] provides a flexible way to adapt pre-trained models to downstream tasks by training only additional parameters. This enables prompts to capture task-specific information while guiding the fixed model’s performance. Leveraging its lightweight nature, prior research [76, 27] has explored the integration of prompt learning into federated learning to overcome the problems outlined above.",
            "In real-world scenarios, client data often exhibits variations in domain discrepancies (feature shift) [44] or imbalanced class distributions (label shift) [40].\nSimply applying the FedAvg [52] method on prompts [27] across all clients tends to deviate from their local distribution, leading to unsatisfactory performance. Hence, it’s crucial to develop specialized personalized federated prompt learning approaches to effectively address data heterogeneity.\npFedPrompt [26] introduced personalization into federated prompt learning by maintaining personalized attention modules to generate spatial visual features locally while learning user consensus through shared text prompts. However, in the presence of a significant label shift or notable feature shift, merely learning a shared prompt in the language modality is inadequate.",
            "Model Evaluation on Label Shifts.\nWe first measured the performance of FedOTP against baselines on datasets with label shifts. The experimental results on CLIP datasets and CIFAR-10/CIFAR-100 datasets are summarized in Table 1 and Table 3. For easy comparison, Table 1 reports results utilizing ResNet50 as the backbone, maintaining consistency with [26]. As shown in Table 1, our FedOTP outperforms state-of-the-art algorithms by a large margin across all datasets, which confirms the effectiveness of our Global-Local prompt cooperation mechanism to handle label shift scenarios.\nRemarkably, while both PromptFL+FedPer (which splits the learnable prompt vector into “base+personalized” vectors) and pFedPrompt (utilizing a shared prompt with a personalized attention module in the vision modal) experience significant declines when datasets are altered, FedOTP exhibits slight fluctuations. This verifies the robustness of our method across diverse scenarios.\nTable 3 shows the results of our FedOTP and benchmark methods on CIFAR-10/CIFAR-100 datasets under Dirichlet setting over 100100100 clients with 10%percent1010\\% partition. Even in this scenario with Dirichlet settings and a large number of clients, FedOTP consistently outperforms the baseline methods, further highlighting the superiority of our approach.",
            "Model Evaluation on Feature &\\& Label Shifts.\nIn this set of experiments, we explored scenarios involving both feature shifts and label shifts by partitioning data within a domain into five clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1. We analyzed the mean and variance of clients in the same domain, and the outcomes for the DomainNet dataset are summarized in Table 2.\nIn the presence of two types of data heterogeneity, our method performs favorably against baselines. We observe that, with significant data heterogeneity across clients, traditional federated learning methods experience a pronounced performance decline compared to local training. In contrast, our FedOTP exhibits superior performance, achieving a 3.7%percent3.73.7\\% increase in average accuracy on each domain. Additional experimental results on feature shifts and in the Office-Caltech10 dataset are available in the Appendix Section C.1 and C.2.",
            "Effectiveness of the Unbalanced OT.\nIn this subsection, we explored the effectiveness of OT on two variants of FedOTP briefly described below: (1) FedOTP (Similarity Averaging): removing OT in FedOTP and matching global and local prompts with visual feature maps by averaging similarities of each visual-textual pair; (2) FedOTP (Classical OT): employing classical OT during the matching process.\nThe results in Table 4 demonstrate the effectiveness of utilizing OT to align feature maps with global and local prompts compared to FedOTP (Similarity Averaging) in almost all cases, particularly on the Food101 dataset.\nThis is because the absence of OT leads to the feature map’s distance from prompts reverting to the mean distance of each feature-prompt pair, highlighting the crucial role of OT in providing resilience to visual misalignment.\nIn addition, the persistent superiority of unbalanced OT over classical OT across all scenarios serves as a compelling testament to the effectiveness of our approach.",
            "We select nine representative visual classification datasets as our benchmark. The detailed statistics of each dataset are shown in Table A1, including the original tasks, the number of classes, the size of training and testing samples, and the number of domains.\nAs for datasets with multiple domains, Office-Caltech10 is a standard benchmark dataset consisting of four domains, namely Amazon, Caltech, DSLR, and WebCam, which are acquired using different camera devices or in different real environments with various backgrounds. DomainNet is a large-scale dataset consisting of six domains, namely Clipart, Infograph, Painting, Quickdraw, Real, and Sketch. We selected 10 classes from each of these two datasets for training. Some examples of raw instances of these two datasets can be found in Figure A1. For a clearer illustration, we visualize the three Non-IID settings employed in our paper in Figure A2.",
            "In Table A2, we compared the performance on Office-Caltech10 and DomainNet datasets under the presence of feature shift, where each client is assigned data from distinct domains while sharing the same label distribution. Our method achieved the highest average accuracies 99.16%percent99.1699.16\\% and 94.55%percent94.5594.55\\% on Office-Caltech10 and DomainNet, respectively.",
            "In this set of experiments, we investigated scenarios involving both feature shifts and label shifts by dividing data within a domain into three clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1 for the Office-Caltech10 dataset. We calculated the mean and standard deviation of clients in the same domain, and the outcomes are presented in Table A3. Comparing these results with those in Table A2, we can observe that the introduction of label shift leads to a performance decrease across all methods, with federated learning methods employing a shared prompt experiencing the most significant decline. In spite of this, our FedOTP consistently achieves the highest average accuracy, demonstrating its capability to utilize both global and local prompts to capture general domain-invariant and specific domain-specific knowledge for effective adaptation to extreme data heterogeneity.",
            "In this subsection, we delved into the effect of parameter γ𝛾\\gamma in unbalanced OT, which regulates the mapping size of prompts on the feature map. We conducted experiments on the Pathological Non-IID setting across four datasets with varying numbers of shots and different values of the parameter γ𝛾\\gamma in our FedOTP. Specifically, we set R=5𝑅5R=5 and T=10𝑇10T=10 for these experiments. The results presented in Table A4 reveal a notable trend: as the parameter γ𝛾\\gamma decreases, the overall performance initially increases and subsequently decreases. Interestingly, the majority of optimal results are observed at γ=0.8𝛾0.8\\gamma=0.8 or γ=0.7𝛾0.7\\gamma=0.7. This observation implies that the optimal alignment between global and local prompts and the feature map is achieved when the mapping size of prompts on the feature map is around 70%−80%percent70percent8070\\%-80\\%. Consequently, we adopt γ=0.8𝛾0.8\\gamma=0.8 in other experiments.",
            "In addressing the core challenge of data heterogeneity in personalized federated learning, FedOTP consistently outperforms benchmark methods across various settings. Now, we investigated the effect of heterogeneity in label distribution by considering a range of α𝛼\\alpha values of Dirichlet distribution, specifically α∈{0.1,0.3,0.5,1,5,10}𝛼0.10.30.51510\\alpha\\in\\{0.1,0.3,0.5,1,5,10\\} for CIFAR-100 datasets. It’s worth noting that a smaller α𝛼\\alpha implies a higher degree of data heterogeneity in these experiments. The results presented in Table A5 clearly indicate that as the degree of data heterogeneity increases, the performance of federated learning methods with a shared prompt decreases while the performance of CoOp and our FedOTP improves. Among these methods, FedOTP outperforms them in every case and demonstrates remarkable robustness. These findings underscore the effectiveness of FedOTP in overcoming label distribution heterogeneity across a diverse range of scenarios.",
            "To assess the convergence of our method, we plotted test accuracy curves with R=1𝑅1R=1 and T=50𝑇50T=50 for different methods across four datasets, as illustrated in\nFigure A3. Compared to other methods, FedOTP exhibits notable characteristics of accelerated convergence and enhanced stability, evident from the smaller fluctuations in test accuracy."
        ]
    },
    "A3.T5": {
        "caption": "Table A5: Quantitative comparisons on CIFAR-100 dataset with different α𝛼\\alpha of the Dirichlet setting.",
        "table": "<table id=\"A3.T5.3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A3.T5.3.1.2.1\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Dataset</th>\n<td id=\"A3.T5.3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"6\">CIFAR-100</td>\n</tr>\n<tr id=\"A3.T5.3.1.1\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\"><math id=\"A3.T5.3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\#\\alpha\" display=\"inline\"><semantics id=\"A3.T5.3.1.1.1.m1.1a\"><mrow id=\"A3.T5.3.1.1.1.m1.1.1\" xref=\"A3.T5.3.1.1.1.m1.1.1.cmml\"><mi mathvariant=\"normal\" id=\"A3.T5.3.1.1.1.m1.1.1.2\" xref=\"A3.T5.3.1.1.1.m1.1.1.2.cmml\">#</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"A3.T5.3.1.1.1.m1.1.1.1\" xref=\"A3.T5.3.1.1.1.m1.1.1.1.cmml\">​</mo><mi id=\"A3.T5.3.1.1.1.m1.1.1.3\" xref=\"A3.T5.3.1.1.1.m1.1.1.3.cmml\">α</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A3.T5.3.1.1.1.m1.1b\"><apply id=\"A3.T5.3.1.1.1.m1.1.1.cmml\" xref=\"A3.T5.3.1.1.1.m1.1.1\"><times id=\"A3.T5.3.1.1.1.m1.1.1.1.cmml\" xref=\"A3.T5.3.1.1.1.m1.1.1.1\"></times><ci id=\"A3.T5.3.1.1.1.m1.1.1.2.cmml\" xref=\"A3.T5.3.1.1.1.m1.1.1.2\">#</ci><ci id=\"A3.T5.3.1.1.1.m1.1.1.3.cmml\" xref=\"A3.T5.3.1.1.1.m1.1.1.3\">𝛼</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A3.T5.3.1.1.1.m1.1c\">\\#\\alpha</annotation></semantics></math></th>\n<td id=\"A3.T5.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.1</td>\n<td id=\"A3.T5.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.3</td>\n<td id=\"A3.T5.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.5</td>\n<td id=\"A3.T5.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">1</td>\n<td id=\"A3.T5.3.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">5</td>\n<td id=\"A3.T5.3.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">10</td>\n</tr>\n<tr id=\"A3.T5.3.1.3.2\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"7\"><span id=\"A3.T5.3.1.3.2.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Local Training</span></th>\n</tr>\n<tr id=\"A3.T5.3.1.4.3\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">Zero-Shot CLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib60\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">60</span></a>]</cite>\n</th>\n<td id=\"A3.T5.3.1.4.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">65.22±0.32</td>\n<td id=\"A3.T5.3.1.4.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">64.92±0.53</td>\n<td id=\"A3.T5.3.1.4.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">65.78±0.41</td>\n<td id=\"A3.T5.3.1.4.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">63.93±0.16</td>\n<td id=\"A3.T5.3.1.4.3.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">64.01±0.27</td>\n<td id=\"A3.T5.3.1.4.3.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">65.07±0.35</td>\n</tr>\n<tr id=\"A3.T5.3.1.5.4\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">CoOp <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib78\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">78</span></a>]</cite>\n</th>\n<td id=\"A3.T5.3.1.5.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">62.01±0.29</td>\n<td id=\"A3.T5.3.1.5.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.83±0.45</td>\n<td id=\"A3.T5.3.1.5.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">51.72±0.42</td>\n<td id=\"A3.T5.3.1.5.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">47.03±0.37</td>\n<td id=\"A3.T5.3.1.5.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">41.03±0.23</td>\n<td id=\"A3.T5.3.1.5.4.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">41.37±0.19</td>\n</tr>\n<tr id=\"A3.T5.3.1.6.5\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"7\"><span id=\"A3.T5.3.1.6.5.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Prompt-based Federated Learning</span></th>\n</tr>\n<tr id=\"A3.T5.3.1.7.6\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">PromptFL <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">27</span></a>]</cite>\n</th>\n<td id=\"A3.T5.3.1.7.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">72.45±0.64</td>\n<td id=\"A3.T5.3.1.7.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">73.67±0.56</td>\n<td id=\"A3.T5.3.1.7.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.37±0.18</td>\n<td id=\"A3.T5.3.1.7.6.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">73.95±0.14</td>\n<td id=\"A3.T5.3.1.7.6.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.68±0.05</td>\n<td id=\"A3.T5.3.1.7.6.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.43±0.08</td>\n</tr>\n<tr id=\"A3.T5.3.1.8.7\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">PromptFL+FedProx <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib42\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">42</span></a>]</cite>\n</th>\n<td id=\"A3.T5.3.1.8.7.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">72.57±0.54</td>\n<td id=\"A3.T5.3.1.8.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">71.11±0.91</td>\n<td id=\"A3.T5.3.1.8.7.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.45±0.19</td>\n<td id=\"A3.T5.3.1.8.7.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.19±0.06</td>\n<td id=\"A3.T5.3.1.8.7.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.23±0.09</td>\n<td id=\"A3.T5.3.1.8.7.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.53±0.07</td>\n</tr>\n<tr id=\"A3.T5.3.1.9.8\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">FedOTP (Similarity Averaging)</th>\n<td id=\"A3.T5.3.1.9.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">78.68±0.17</td>\n<td id=\"A3.T5.3.1.9.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">75.70±0.27</td>\n<td id=\"A3.T5.3.1.9.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">75.28±0.12</td>\n<td id=\"A3.T5.3.1.9.8.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.88±0.16</td>\n<td id=\"A3.T5.3.1.9.8.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.48±0.05</td>\n<td id=\"A3.T5.3.1.9.8.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.31±0.39</td>\n</tr>\n<tr id=\"A3.T5.3.1.10.9\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">FedOTP (Classical OT)</th>\n<td id=\"A3.T5.3.1.10.9.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">79.93±0.19</td>\n<td id=\"A3.T5.3.1.10.9.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">77.86±0.09</td>\n<td id=\"A3.T5.3.1.10.9.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">75.76±0.12</td>\n<td id=\"A3.T5.3.1.10.9.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">75.38±0.08</td>\n<td id=\"A3.T5.3.1.10.9.6\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">75.01±0.05</td>\n<td id=\"A3.T5.3.1.10.9.7\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.73±0.05</td>\n</tr>\n<tr id=\"A3.T5.3.1.11.10\" class=\"ltx_tr\">\n<th id=\"A3.T5.3.1.11.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">FedOTP (Unbalanced OT)</th>\n<td id=\"A3.T5.3.1.11.10.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T5.3.1.11.10.2.1\" class=\"ltx_text ltx_font_bold\">80.56±0.12</span></td>\n<td id=\"A3.T5.3.1.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T5.3.1.11.10.3.1\" class=\"ltx_text ltx_font_bold\">78.03±0.08</span></td>\n<td id=\"A3.T5.3.1.11.10.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T5.3.1.11.10.4.1\" class=\"ltx_text ltx_font_bold\">76.75±0.10</span></td>\n<td id=\"A3.T5.3.1.11.10.5\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T5.3.1.11.10.5.1\" class=\"ltx_text ltx_font_bold\">76.17±0.13</span></td>\n<td id=\"A3.T5.3.1.11.10.6\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T5.3.1.11.10.6.1\" class=\"ltx_text ltx_font_bold\">75.75±0.03</span></td>\n<td id=\"A3.T5.3.1.11.10.7\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"A3.T5.3.1.11.10.7.1\" class=\"ltx_text ltx_font_bold\">75.52±0.06</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Recently, vision-language pre-trained models like Contrastive Language-Image Pretraining (CLIP) [60] have shown potential in learning robust and versatile representations suitable for various image distributions, aligning with the objectives of federated learning. However, the substantial communication overhead between the server and clients renders training CLIP in federated learning frameworks. Besides, overfitting concerns may arise when large-scale models are trained with limited client data. Prompt learning [46, 78] provides a flexible way to adapt pre-trained models to downstream tasks by training only additional parameters. This enables prompts to capture task-specific information while guiding the fixed model’s performance. Leveraging its lightweight nature, prior research [76, 27] has explored the integration of prompt learning into federated learning to overcome the problems outlined above.",
            "In real-world scenarios, client data often exhibits variations in domain discrepancies (feature shift) [44] or imbalanced class distributions (label shift) [40].\nSimply applying the FedAvg [52] method on prompts [27] across all clients tends to deviate from their local distribution, leading to unsatisfactory performance. Hence, it’s crucial to develop specialized personalized federated prompt learning approaches to effectively address data heterogeneity.\npFedPrompt [26] introduced personalization into federated prompt learning by maintaining personalized attention modules to generate spatial visual features locally while learning user consensus through shared text prompts. However, in the presence of a significant label shift or notable feature shift, merely learning a shared prompt in the language modality is inadequate.",
            "Model Evaluation on Label Shifts.\nWe first measured the performance of FedOTP against baselines on datasets with label shifts. The experimental results on CLIP datasets and CIFAR-10/CIFAR-100 datasets are summarized in Table 1 and Table 3. For easy comparison, Table 1 reports results utilizing ResNet50 as the backbone, maintaining consistency with [26]. As shown in Table 1, our FedOTP outperforms state-of-the-art algorithms by a large margin across all datasets, which confirms the effectiveness of our Global-Local prompt cooperation mechanism to handle label shift scenarios.\nRemarkably, while both PromptFL+FedPer (which splits the learnable prompt vector into “base+personalized” vectors) and pFedPrompt (utilizing a shared prompt with a personalized attention module in the vision modal) experience significant declines when datasets are altered, FedOTP exhibits slight fluctuations. This verifies the robustness of our method across diverse scenarios.\nTable 3 shows the results of our FedOTP and benchmark methods on CIFAR-10/CIFAR-100 datasets under Dirichlet setting over 100100100 clients with 10%percent1010\\% partition. Even in this scenario with Dirichlet settings and a large number of clients, FedOTP consistently outperforms the baseline methods, further highlighting the superiority of our approach.",
            "Model Evaluation on Feature &\\& Label Shifts.\nIn this set of experiments, we explored scenarios involving both feature shifts and label shifts by partitioning data within a domain into five clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1. We analyzed the mean and variance of clients in the same domain, and the outcomes for the DomainNet dataset are summarized in Table 2.\nIn the presence of two types of data heterogeneity, our method performs favorably against baselines. We observe that, with significant data heterogeneity across clients, traditional federated learning methods experience a pronounced performance decline compared to local training. In contrast, our FedOTP exhibits superior performance, achieving a 3.7%percent3.73.7\\% increase in average accuracy on each domain. Additional experimental results on feature shifts and in the Office-Caltech10 dataset are available in the Appendix Section C.1 and C.2.",
            "Effectiveness of the Unbalanced OT.\nIn this subsection, we explored the effectiveness of OT on two variants of FedOTP briefly described below: (1) FedOTP (Similarity Averaging): removing OT in FedOTP and matching global and local prompts with visual feature maps by averaging similarities of each visual-textual pair; (2) FedOTP (Classical OT): employing classical OT during the matching process.\nThe results in Table 4 demonstrate the effectiveness of utilizing OT to align feature maps with global and local prompts compared to FedOTP (Similarity Averaging) in almost all cases, particularly on the Food101 dataset.\nThis is because the absence of OT leads to the feature map’s distance from prompts reverting to the mean distance of each feature-prompt pair, highlighting the crucial role of OT in providing resilience to visual misalignment.\nIn addition, the persistent superiority of unbalanced OT over classical OT across all scenarios serves as a compelling testament to the effectiveness of our approach.",
            "We select nine representative visual classification datasets as our benchmark. The detailed statistics of each dataset are shown in Table A1, including the original tasks, the number of classes, the size of training and testing samples, and the number of domains.\nAs for datasets with multiple domains, Office-Caltech10 is a standard benchmark dataset consisting of four domains, namely Amazon, Caltech, DSLR, and WebCam, which are acquired using different camera devices or in different real environments with various backgrounds. DomainNet is a large-scale dataset consisting of six domains, namely Clipart, Infograph, Painting, Quickdraw, Real, and Sketch. We selected 10 classes from each of these two datasets for training. Some examples of raw instances of these two datasets can be found in Figure A1. For a clearer illustration, we visualize the three Non-IID settings employed in our paper in Figure A2.",
            "In Table A2, we compared the performance on Office-Caltech10 and DomainNet datasets under the presence of feature shift, where each client is assigned data from distinct domains while sharing the same label distribution. Our method achieved the highest average accuracies 99.16%percent99.1699.16\\% and 94.55%percent94.5594.55\\% on Office-Caltech10 and DomainNet, respectively.",
            "In this set of experiments, we investigated scenarios involving both feature shifts and label shifts by dividing data within a domain into three clients based on the Dirichlet distribution with α=0.1𝛼0.1\\alpha=0.1 for the Office-Caltech10 dataset. We calculated the mean and standard deviation of clients in the same domain, and the outcomes are presented in Table A3. Comparing these results with those in Table A2, we can observe that the introduction of label shift leads to a performance decrease across all methods, with federated learning methods employing a shared prompt experiencing the most significant decline. In spite of this, our FedOTP consistently achieves the highest average accuracy, demonstrating its capability to utilize both global and local prompts to capture general domain-invariant and specific domain-specific knowledge for effective adaptation to extreme data heterogeneity.",
            "In this subsection, we delved into the effect of parameter γ𝛾\\gamma in unbalanced OT, which regulates the mapping size of prompts on the feature map. We conducted experiments on the Pathological Non-IID setting across four datasets with varying numbers of shots and different values of the parameter γ𝛾\\gamma in our FedOTP. Specifically, we set R=5𝑅5R=5 and T=10𝑇10T=10 for these experiments. The results presented in Table A4 reveal a notable trend: as the parameter γ𝛾\\gamma decreases, the overall performance initially increases and subsequently decreases. Interestingly, the majority of optimal results are observed at γ=0.8𝛾0.8\\gamma=0.8 or γ=0.7𝛾0.7\\gamma=0.7. This observation implies that the optimal alignment between global and local prompts and the feature map is achieved when the mapping size of prompts on the feature map is around 70%−80%percent70percent8070\\%-80\\%. Consequently, we adopt γ=0.8𝛾0.8\\gamma=0.8 in other experiments.",
            "In addressing the core challenge of data heterogeneity in personalized federated learning, FedOTP consistently outperforms benchmark methods across various settings. Now, we investigated the effect of heterogeneity in label distribution by considering a range of α𝛼\\alpha values of Dirichlet distribution, specifically α∈{0.1,0.3,0.5,1,5,10}𝛼0.10.30.51510\\alpha\\in\\{0.1,0.3,0.5,1,5,10\\} for CIFAR-100 datasets. It’s worth noting that a smaller α𝛼\\alpha implies a higher degree of data heterogeneity in these experiments. The results presented in Table A5 clearly indicate that as the degree of data heterogeneity increases, the performance of federated learning methods with a shared prompt decreases while the performance of CoOp and our FedOTP improves. Among these methods, FedOTP outperforms them in every case and demonstrates remarkable robustness. These findings underscore the effectiveness of FedOTP in overcoming label distribution heterogeneity across a diverse range of scenarios.",
            "To assess the convergence of our method, we plotted test accuracy curves with R=1𝑅1R=1 and T=50𝑇50T=50 for different methods across four datasets, as illustrated in\nFigure A3. Compared to other methods, FedOTP exhibits notable characteristics of accelerated convergence and enhanced stability, evident from the smaller fluctuations in test accuracy."
        ]
    }
}