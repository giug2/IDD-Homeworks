{
    "PAPER'S NUMBER OF TABLES": 1,
    "S3.T1": {
        "caption": "Table 1:  FashionMnist: The 10%percent1010\\% of less available users (that means 333 out of 303030 users with sampling probabilities 0.0107,0.0078,0.00530.01070.00780.00530.0107,0.0078,0.0053, respectively) carry 222 patterns exclusively. The columns represent the overall testing accuracy, and the testing accuracy, of the global model, at the patterns that belong to the less available users, respectively. The objective becomes risk-neutral when Î±=1.0ğ›¼1.0\\alpha=1.0, or Î³=1.0ğ›¾1.0\\gamma=1.0.",
        "table": "",
        "footnotes": "\n\n\n\n\nğœ¶=1.0ğœ¶1.0\\bm{\\alpha=1.0}\nğœ¶=0.3ğœ¶0.3\\bm{\\alpha=0.3}\nğœ¶=0.2ğœ¶0.2\\bm{\\alpha=0.2}\nğœ¶=0.1ğœ¶0.1\\bm{\\alpha=0.1}\n\n\nOverall. | pattern 1. | pattern 2.\nOverall. | pattern 1. | pattern 2.\nOverall. | pattern 1. | pattern 2.\nOverall. | pattern 1. | pattern 2.\n\nğœ¸=0.0ğœ¸0.0\\bm{\\gamma=0.0}\n\n85.14785.14785.147 Â±0.546plus-or-minus0.546\\pm 0.546\n|\n85.47385.47385.473 Â±1.548plus-or-minus1.548\\pm 1.548\n|\n61.04161.04161.041 Â±3.554plus-or-minus3.554\\pm 3.554\n\n86.15786.15786.157 Â±0.559plus-or-minus0.559\\pm 0.559\n|\n88.32388.32388.323 Â±1.140plus-or-minus1.140\\pm 1.140\n|\n67.16467.16467.164 Â±3.344plus-or-minus3.344\\pm 3.344\n\n86.45386.45386.453 Â±0.592plus-or-minus0.592\\pm 0.592\n|\n88.73688.736\\bm{88.736} Â±1.472plus-or-minus1.472\\bm{\\pm 1.472}\n|\n68.92668.92668.926 Â±2.716plus-or-minus2.716\\pm 2.716\n\n86.08986.08986.089 Â±0.923plus-or-minus0.923\\pm 0.923\n|\n87.53687.53687.536 Â±2.449plus-or-minus2.449\\pm 2.449\n|\n70.60170.60170.601 Â±3.523plus-or-minus3.523\\pm 3.523\n\nğœ¸=0.1ğœ¸0.1\\bm{\\gamma=0.1}\n\n84.89584.89584.895 Â±0.605plus-or-minus0.605\\pm 0.605\n|\n84.58384.58384.583 Â±1.597plus-or-minus1.597\\pm 1.597\n|\n59.64959.64959.649 Â±3.795plus-or-minus3.795\\pm 3.795\n\n86.27686.27686.276 Â±0.519plus-or-minus0.519\\pm 0.519\n|\n88.35388.35388.353 Â±1.058plus-or-minus1.058\\pm 1.058\n|\n66.67666.67666.676 Â±2.883plus-or-minus2.883\\pm 2.883\n\n86.43286.43286.432 Â±0.653plus-or-minus0.653\\pm 0.653\n|\n88.61988.61988.619 Â±1.674plus-or-minus1.674\\pm 1.674\n|\n68.80168.80168.801 Â±2.835plus-or-minus2.835\\pm 2.835\n\n86.54686.546\\bm{86.546} Â±0.540plus-or-minus0.540\\bm{\\pm 0.540} \n|\n88.68188.68188.681 Â±1.454plus-or-minus1.454\\pm 1.454\n|\n71.68171.681\\bm{71.681} Â±2.419plus-or-minus2.419\\bm{\\pm 2.419}\n\nğœ¸=0.2ğœ¸0.2\\bm{\\gamma=0.2}\n\n84.78384.78384.783 Â±0.474plus-or-minus0.474\\pm 0.474\n|\n84.53384.53384.533 Â±1.294plus-or-minus1.294\\pm 1.294\n|\n59.22359.22359.223 Â±2.580plus-or-minus2.580\\pm 2.580\n\n86.17486.17486.174 Â±0.552plus-or-minus0.552\\pm 0.552\n|\n88.02988.02988.029 Â±1.572plus-or-minus1.572\\pm 1.572\n|\n66.37266.37266.372 Â±3.116plus-or-minus3.116\\pm 3.116\n\n86.11086.11086.110 Â±0.573plus-or-minus0.573\\pm 0.573\n|\n88.06188.06188.061 Â±1.663plus-or-minus1.663\\pm 1.663\n|\n67.65967.65967.659 Â±3.156plus-or-minus3.156\\pm 3.156\n\n86.13286.13286.132 Â±0.860plus-or-minus0.860\\pm 0.860\n|\n88.09388.09388.093 Â±1.990plus-or-minus1.990\\pm 1.990\n|\n69.69869.69869.698 Â±4.351plus-or-minus4.351\\pm 4.351\n\nğœ¸=0.3ğœ¸0.3\\bm{\\gamma=0.3}\n\n84.98384.98384.983 Â±0.419plus-or-minus0.419\\pm 0.419\n|\n84.96984.96984.969 Â±1.042plus-or-minus1.042\\pm 1.042\n|\n60.33060.33060.330 Â±2.104plus-or-minus2.104\\pm 2.104\n\n86.03686.03686.036 Â±0.483plus-or-minus0.483\\pm 0.483\n|\n87.61187.61187.611 Â±1.316plus-or-minus1.316\\pm 1.316\n|\n65.95865.95865.958 Â±2.492plus-or-minus2.492\\pm 2.492\n\n86.26386.26386.263 Â±0.517plus-or-minus0.517\\pm 0.517\n|\n88.30088.30088.300 Â±1.772plus-or-minus1.772\\pm 1.772\n|\n68.07668.07668.076 Â±3.054plus-or-minus3.054\\pm 3.054\n\n86.19786.19786.197 Â±0.533plus-or-minus0.533\\pm 0.533\n|\n87.77687.77687.776 Â±2.026plus-or-minus2.026\\pm 2.026\n|\n69.88369.88369.883 Â±2.674plus-or-minus2.674\\pm 2.674\n\nğœ¸=1.0ğœ¸1.0\\bm{\\gamma=1.0}\n\n84.91584.91584.915 Â±0.497plus-or-minus0.497\\pm 0.497\n|\n84.51484.51484.514 Â±1.620plus-or-minus1.620\\pm 1.620\n|\n60.25260.25260.252 Â±3.074plus-or-minus3.074\\pm 3.074\n\n84.82284.82284.822 Â±0.630plus-or-minus0.630\\pm 0.630\n|\n84.48184.48184.481 Â±2.003plus-or-minus2.003\\pm 2.003\n|\n59.00859.00859.008 Â±3.138plus-or-minus3.138\\pm 3.138\n\n84.91684.91684.916 Â±0.454plus-or-minus0.454\\pm 0.454\n|\n85.45985.45985.459 Â±2.870plus-or-minus2.870\\pm 2.870\n| \n60.80560.80560.805 Â±2.399plus-or-minus2.399\\pm 2.399\n\n84.95684.95684.956 Â±0.462plus-or-minus0.462\\pm 0.462\n|\n85.56185.56185.561 Â±1.443plus-or-minus1.443\\pm 1.443\n|\n59.83959.83959.839 Â±3.168plus-or-minus3.168\\pm 3.168\n\n",
        "references": [
            [
                "To guarantee efficient classification and simultaneously mitigate the effect of data starvation, we propose a ",
                "risk-aware objective",
                " that combines the ",
                "Conditional Value-at-Risk",
                " (CVaR) on the RAM distribution with the empirical risk-neutral objective (",
                "2",
                "). The CVaR of a random variable ",
                "Z",
                "ğ‘",
                "Z",
                " at confidence level ",
                "a",
                "âˆˆ",
                "(",
                "0",
                ",",
                "1",
                "]",
                "ğ‘",
                "0",
                "1",
                "a\\in(0,1]",
                " is defined as ",
                "[",
                "24",
                "]",
                "for which it is true that ",
                "CVaR",
                "Î±",
                "â€‹",
                "[",
                "Z",
                "]",
                "=",
                "ğ”¼",
                "â€‹",
                "[",
                "Z",
                "]",
                "superscript",
                "CVaR",
                "ğ›¼",
                "delimited-[]",
                "ğ‘",
                "ğ”¼",
                "delimited-[]",
                "ğ‘",
                "\\text{CVaR}^{\\alpha}\\big{[}Z\\big{]}=\\mathbb{E}[Z]",
                " for ",
                "Î±",
                "=",
                "1",
                "ğ›¼",
                "1",
                "\\alpha=1",
                ", rising up to ",
                "ess sup",
                "â€‹",
                "Z",
                "ess sup",
                "ğ‘",
                "\\text{ess sup}Z",
                ", as ",
                "Î±",
                "â†’",
                "0",
                "â†’",
                "ğ›¼",
                "0",
                "\\alpha\\rightarrow 0",
                ".\nThen, for ",
                "Î³",
                "âˆˆ",
                "(",
                "0",
                ",",
                "1",
                ")",
                "ğ›¾",
                "0",
                "1",
                "\\gamma\\in(0,1)",
                ", our proposed optimization problem is",
                "and using definition (",
                "3",
                ") for ",
                "Z",
                "=",
                "f",
                "I",
                "â€‹",
                "(",
                "Î¸",
                ")",
                "ğ‘",
                "subscript",
                "ğ‘“",
                "ğ¼",
                "ğœƒ",
                "Z=f_{I}(\\theta)",
                ", we have",
                "The objective in the preceding problem may be further simplified as",
                "The CVaR measures expected losses restricted to the upper tail of the distribution of the random variable ",
                "Z",
                "ğ‘",
                "Z",
                " ",
                "[",
                "25",
                "]",
                ". Thus, by tuning the parameters ",
                "Î³",
                "âˆˆ",
                "[",
                "0",
                ",",
                "1",
                "]",
                "ğ›¾",
                "0",
                "1",
                "\\gamma\\in[0,1]",
                " and ",
                "Î±",
                "âˆˆ",
                "(",
                "0",
                ",",
                "1",
                "]",
                "ğ›¼",
                "0",
                "1",
                "\\alpha\\in(0,1]",
                ", we tune the objective in\n(",
                "4",
                ") to boost the learning procedure on data points that come from rare user participation events, and essentially enforce learning under data starvation with a few shots only. Equivalently, a training algorithm based on (",
                "4",
                ") learns how to reject samples from frequent users since ",
                "CVaR",
                "Î±",
                "â€‹",
                "[",
                "â‹…",
                "]",
                "superscript",
                "CVaR",
                "ğ›¼",
                "delimited-[]",
                "â‹…",
                "\\text{CVaR}^{\\alpha}[\\cdot]",
                " is robust to the uncertainty of the environment ",
                "[",
                "24",
                "]",
                " .",
                "Problem (",
                "6",
                ") leads us to devise Algorithm ",
                "1",
                " for tackling (",
                "4",
                "). Algorithm ",
                "1",
                " is an extension of FedAvg, and essentially an instance of FedAvg on the proposed risk-aware problem (",
                "6",
                "). In each round, the server receives the parameters ",
                "(",
                "Î¸",
                "i",
                "n",
                ",",
                "t",
                "i",
                "n",
                ")",
                "superscript",
                "subscript",
                "ğœƒ",
                "ğ‘–",
                "ğ‘›",
                "superscript",
                "subscript",
                "ğ‘¡",
                "ğ‘–",
                "ğ‘›",
                "(\\theta_{i}^{n},t_{i}^{n})",
                " of a certain user ",
                "i",
                "ğ‘–",
                "i",
                " (chosen iid by the RAM and not by the server) and broadcasts those as global parameters\n",
                "(",
                "Î¸",
                "global",
                "n",
                ",",
                "t",
                "global",
                "n",
                ")",
                "superscript",
                "subscript",
                "ğœƒ",
                "global",
                "ğ‘›",
                "superscript",
                "subscript",
                "ğ‘¡",
                "global",
                "ğ‘›",
                "(\\theta_{\\text{global}}^{n},t_{\\text{global}}^{n})",
                " to all users. Then, each user locally applies gradient descent steps on its private dataset, updating its parameters ",
                "Î¸",
                "i",
                "n",
                "+",
                "1",
                "superscript",
                "subscript",
                "ğœƒ",
                "ğ‘–",
                "ğ‘›",
                "1",
                "\\theta_{i}^{n+1}",
                " and ",
                "t",
                "i",
                "n",
                "+",
                "1",
                "superscript",
                "subscript",
                "ğ‘¡",
                "ğ‘–",
                "ğ‘›",
                "1",
                "t_{i}^{n+1}",
                ".",
                "We again note that the server is agnostic to RAM user selection. So, the proposed Algorithm ",
                "1",
                " asks the users to tackle a more general problem than in the standard risk-neutral case (cf. (",
                "1",
                ")), to solve locally. Indeed, Algorithm ",
                "1",
                " asks the users to optimize the risk-aware objective of (",
                "4",
                ") â€“through that of (",
                "6",
                ")â€“, given a desired CVaR confidence level ",
                "a",
                "ğ‘",
                "a",
                " and a trade-off parameter ",
                "Î³",
                "ğ›¾",
                "\\gamma",
                ". When ",
                "Î±",
                "=",
                "1",
                "ğ›¼",
                "1",
                "\\alpha=1",
                ", (",
                "4",
                ") is reduced to the standard FL objective (",
                "1",
                "), and Algorithm ",
                "1",
                " reduces to standard FedAvg."
            ]
        ]
    }
}