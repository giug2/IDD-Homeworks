{
    "S5.T1": {
        "caption": "Table 1: Test performance of different methods, where left table denotes the likelihood for MoG with varying C𝐶C (number of components), oracle is the likelihood of true parameters for the test data, and right denotes the test accuracy for point cloud classification task with varying N𝑁N (number of points).",
        "table": null,
        "footnotes": [],
        "references": [
            "Amortized Clustering with Mixture of Gaussians (MoGs): \nWe consider the task of maximum likelihood of MoGs with C𝐶C components, denoted as P​(x;𝜽)=∑c=1Cπc​N​(x∣μc,diag⁡(σc2))𝑃𝑥𝜽superscriptsubscript𝑐1𝐶subscript𝜋𝑐𝑁conditional𝑥subscript𝜇𝑐diagsuperscriptsubscript𝜎𝑐2P(x;\\bm{\\theta})\\!=\\!\\sum_{c=1}^{C}\\pi_{c}N\\left(x\\mid\\mu_{c},\\operatorname{diag}\\left(\\sigma_{c}^{2}\\right)\\right). Given the dataset X={x1:n}𝑋subscript𝑥:1𝑛X\\!=\\!\\{x_{1:n}\\} generated from the MoG, the goal is to train a neural network, which takes X𝑋X as input set and outputs parameters 𝜽={πc,μc,σc}1,C𝜽subscriptsubscript𝜋𝑐subscript𝜇𝑐subscript𝜎𝑐1𝐶\\bm{\\theta}=\\{\\pi_{c},\\mu_{c},\\sigma_{c}\\}_{1,C}. Each dataset contains n∈[100,500]𝑛100500n\\in[100,500] points on a 2D plane, each of which is sampled from one of C𝐶C Gaussians. Table 1 reports the test average likelihood of different models with varying C∈{4,8}𝐶48C\\!\\in\\!\\{4,8\\}, where we set K=50𝐾50K\\!=\\!50 prototypes for all C𝐶C. We observe that Set Transformer outperforms DeepSets largely, validating the effectiveness of attention mechanisms in this task. We note both Set Transformer(+POT) and DeepSets(+POT) improve their baselines, showing that the POT loss can encourage the summary networks to learn more efficient summary statistics.",
            "Point Cloud Classification: \nHere, we evaluate our method on the task of point cloud classification using the ModelNet40 (Chang et al., 2015) dataset 111We adopt the point-cloud dataset directly from the authors of Zaheer et al. 2017, which consists of 3D objects from 404040 different categories. By treating each object as a point cloud, we represent it as a set of N𝑁N vectors in ℝ3superscriptℝ3\\mathbb{R}^{3} (x; y; z-coordinates). Table 1 reports the classification accuracy, where we perform the experiments with varying N∈{64,1024}𝑁641024N\\in\\{64,1024\\}, set K=40𝐾40K\\!=\\!40 prototypes. Clearly, both DeepSets and Set Transformer can be improved by adding the POT loss. Notably, fewer points would lead to lower performance, where the POT loss plays a more important role. Taking this task as the example, we further study our model’s sensitivity to hyper-parameter ϵitalic-ϵ\\epsilon in Fig. 4 of Appendix C.5."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: 5way5shot and 5way10shot classification accuracy (%) on CUB and miniImageNet, respectively, based on 1000 random trials. Here, (⋅⋅\\cdot) is the p𝑝p-value computed with two-sample t𝑡t-test, and p𝑝p-value with blue (red) color means the increase (reduce) of performance when introducing POT loss.",
        "table": null,
        "footnotes": [],
        "references": [
            "To explore whether our proposed method can improve the metric-based few-shot classification, we consider two commonly-used algorithms as the baselines, including ProtoNet (Snell et al., 2017) and MatchNet (Vinyals et al., 2016). Denoting the feature extractor in each algorithm as fϕ1subscript𝑓subscriptitalic-ϕ1f_{\\phi_{1}}, we consider several popular backbones, including ResNet10 and ResNet34 (He et al., 2016). Recalling the discussions in Section 3.2, to enforce fϕ1subscript𝑓subscriptitalic-ϕ1f_{\\phi_{1}} to learn more powerful image features, we additionally introduce matrix 𝐁𝐁{\\bf B} and net gϕ2subscript𝑔subscriptitalic-ϕ2g_{\\phi_{2}} and learn the model by minimizing the POT loss and classification errors. We perform the experiments on the CUB (Welinder et al., 2010) and miniImageNet (Ravi & Larochelle, 2016). As a fine-grained few-shot classification benchmark, CUB contains 200200200 different classes of birds with a total of 11,7881178811,788 images of size 84×84×38484384\\times 84\\times 3, where we split the dataset into 100100100 base classes, 50 validation classes, and 505050 novel classes following Chen et al. (2019). miniImageNet is derived from ILSVRC-12 dataset (Russakovsky et al., 2015), consisting of\n84×84×38484384\\times 84\\times 3 images from 100 classes with 600 random samples in each class. We follow the splits used in previous work (Ravi & Larochelle, 2016), which splits the dataset into 646464 base classes, 161616 validation classes, and 202020 novel classes. Table 2 reports the 5way5shot and 5way10shot classification results of different methods on miniImageNet and CUB. We see that introducing the POT loss and summary network\ncan consistently improve over baseline classifiers, and the performance gain gradually increases with the development of number of network layers. This suggests that our proposed plug-and-play framework can be flexibly used to enhance the metric-based few-shot classification, without the requirement of designing complicated models on purpose."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: FID ↓↓\\downarrow of images generated by different methods with varying unseen angles A𝐴A on MNIST.",
        "table": null,
        "footnotes": [],
        "references": [
            "Rotated MNIST: Following Wu et al. (2020), we artificially transform each image in MNIST dataset (LeCun, 1998) with 18 rotations (−-180 to 180 by 20 degrees), leading to 181818 distributions characterized by angle A𝐴A. We choose 999 interleaved distributions for training and the rest as unseen distributions for testing. We consider the CGAN-based and DAGAN-based models, respectively. During the test stage, for each unseen distribution, we randomly sample 100010001000 real images and generate 202020 fake images based on every 202020 real images and repeat this process 505050 times (i.e.formulae-sequence𝑖𝑒i.e., 1000/201000201000/20), resulting in 100010001000 generated samples for each method. We summarize the test performance in Table 3 with varying A𝐴A. We can find that our proposed framework allows for better generalization to related but unseen distributions at test time, indicating the POT loss can enforce the summary network to capture more salient characteristics."
        ]
    },
    "A3.T4": {
        "caption": "Table 4: Detailed architectures of Set Transformer used in the MoGs experiments, cited from Lee et al. (2019), where C𝐶C denotes the number of components.",
        "table": null,
        "footnotes": [],
        "references": [
            "DeepSets In terms of the DeepSets, the fϕ1subscript𝑓subscriptitalic-ϕ1f_{\\phi_{1}} in summary network contains 3 permutation-equivariant layers with 256 channels followed by mean-pooling over the set structure. Then the resulting vector representation 𝒛jsubscript𝒛𝑗\\bm{z}_{j} of the set is then fed to a fully connected layer with 512 units followed by a linear layer 512×C​(1+2∗2)512𝐶122512\\times C(1+2*2), where C𝐶C denotes the number of components. We use ELU activation at all layers. To introduce the POT loss into the DeepSets, we further feed the 𝒛jsubscript𝒛𝑗\\bm{z}_{j} into a fully connected layer with 512 units followed by a 50-way softmax unit and also introduce the global matrix 𝐁∈ℝ2×50𝐁superscriptℝ250{\\bf B}\\in\\mathbb{R}^{2\\times 50}.\n\nSet Transformer To perform the MoGs experiments, we adopt the same architecture for Set Transformer following Lee et al. (2019), whose parameters are reported in Table 4. To introduce the POT loss, we also add the two fully connected layers with 256 units on the resulting vector 𝒛jsubscript𝒛𝑗\\bm{z}_{j} followed by a 50-way softmax unit, and a global prototype matrix 𝐁∈ℝ2×50𝐁superscriptℝ250{\\bf B}\\in\\mathbb{R}^{2\\times 50}."
        ]
    },
    "A3.T5": {
        "caption": "Table 5: Detailed architectures of Set Transformer used in the point cloud classification experiments, cited from Lee et al. (2019).",
        "table": null,
        "footnotes": [],
        "references": [
            "Set Transformer We also adopt the same architecture to implement the Set Transformer, where we summarize the parameters in Table 5, following Lee et al. (2019). To improve the Set Transformer with POT loss, we also introduce a fully connected layer with 256 units followed by a 40-way softmax unit, with 90%percent9090\\% dropout rate, and a center matrix 𝐁∈ℝ3×40𝐁superscriptℝ340{\\bf B}\\in\\mathbb{R}^{3\\times 40}."
        ]
    }
}