{
    "PAPER'S NUMBER OF TABLES": 6,
    "S1.T1": {
        "caption": "Table 1: Performance of existing backdoor attacks in academic research scenarios and real-world industrial scenarios.",
        "table": "<table id=\"S1.T1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S1.T1.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\" rowspan=\"2\"><span id=\"S1.T1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Attacks</span></th>\n<td id=\"S1.T1.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S1.T1.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">20% Attackers</span></td>\n<td id=\"S1.T1.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S1.T1.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">1% Attackers</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S1.T1.1.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S1.T1.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S1.T1.1.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n<td id=\"S1.T1.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S1.T1.1.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S1.T1.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S1.T1.1.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Model Replacement</th>\n<td id=\"S1.T1.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.07</td>\n<td id=\"S1.T1.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.93</td>\n<td id=\"S1.T1.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.64</td>\n<td id=\"S1.T1.1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.53</td>\n</tr>\n<tr id=\"S1.T1.1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">3DFed</th>\n<td id=\"S1.T1.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">90.14</td>\n<td id=\"S1.T1.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">98.71</td>\n<td id=\"S1.T1.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">90.36</td>\n<td id=\"S1.T1.1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.52</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Federated learning",
                " (FL) ",
                "McMahan ",
                "et al.",
                " (",
                "2017",
                "); Lu ",
                "et al.",
                " (",
                "2023",
                ")",
                ", one of the prevailing distributed paradigms, facilitates the collaborative construction of a high-precision global model by multiple clients with small amounts of data, all under the coordination of a central server. Notably, FL excels at preserving privacy since clients’ training data remains localized throughout the entire model construction process.",
                "However, the distributed nature of FL also presents a significant challenge: the central server struggles to discern the quality of client-uploaded parameters. Consequently, FL faces a severe threat known as poison attacks ",
                "Shi ",
                "et al.",
                " (",
                "2022",
                "); Lu ",
                "et al.",
                " (",
                "2024",
                ")",
                ". These attacks can be categorized into two main types: Byzantine attacks ",
                "Zhang ",
                "et al.",
                " (",
                "2023b",
                "); Wan ",
                "et al.",
                " (",
                "2024",
                ")",
                ", and backdoor attacks ",
                "Zhang ",
                "et al.",
                " (",
                "2024a",
                ", ",
                "b",
                ")",
                " The former aims to reduce the global model’s recognition accuracy for all samples, while the latter specifically misclassifies samples specified by the adversary without affecting the model’s recognition of normal samples. This indicates that backdoor attacks are more covert and insidious compared to Byzantine attacks.\nTherefore, this paper focuses on backdoor attacks in FL.",
                "FL is shown to be susceptible to backdoor attacks ",
                "Xie ",
                "et al.",
                " (",
                "2020",
                "); Lyu ",
                "et al.",
                " (",
                "2023",
                "); Li ",
                "et al.",
                " (",
                "2023",
                ")",
                ". However, the success of these attacks critically hinges on a high proportion of genuine attackers possessing samples relevant to the main task. Typically, they require ",
                "20",
                "%",
                "percent",
                "20",
                "20\\%",
                " of attackers with authentic training data to successfully inject a backdoor. In real-world industrial scenarios ",
                "Shejwalkar ",
                "et al.",
                " (",
                "2022",
                ")",
                ", attackers often constitute only ",
                "1",
                "%",
                "percent",
                "1",
                "1\\%",
                " or even less of the total clients. As shown in Tab. ",
                "1",
                ", for both the classical Model Replacement Attack ",
                "Bagdasaryan ",
                "et al.",
                " (",
                "2020",
                ")",
                " and the recent 3DFed ",
                "Li ",
                "et al.",
                " (",
                "2023",
                ")",
                ", we consider scenarios with ",
                "20",
                "%",
                "percent",
                "20",
                "20\\%",
                " attackers (academic research scenarios) and ",
                "1",
                "%",
                "percent",
                "1",
                "1\\%",
                " attackers (real-world industrial scenarios). Notably, we employ only the most primitive defense method, Norm Clipping ",
                "Wang ",
                "et al.",
                " (",
                "2020",
                ")",
                ", which restricts the magnitude of local updates to remain within a specified threshold. We observe that in academic research scenarios, these attacks can indeed achieve significant ",
                "attack success rate",
                " (ASR) and ",
                "accuracy of the model",
                " (ACC). However, surprisingly, in real-world industrial scenarios, even the ",
                "state-of-the-art",
                " (SOTA) 3DFed fails to backdoor FL equipped with the simplest defense. We speculate that this is due to the low proportion of attackers, which results in the backdoor task-related knowledge being overshadowed by the main task-related knowledge in the aggregation stage. The result suggests that existing backdoor attacks in FL are impractical, and an effective FL backdoor attack for real-world industrial scenarios is yet to be developed.",
                "In light of this, we embark on the initial steps toward developing backdoor attacks in FL tailored for real-world industrial contexts. Building upon the research in ",
                "Cao and Gong (",
                "2022",
                ")",
                ", we can emulate a series of fake clients using open-source projects or Android emulators. These approaches can significantly increase the number of attackers to match the settings of academic research scenarios. However, these emulated fake clients are unable to provide authentic main task-related data. Consequently, the primary challenge pivots towards devising a data-free backdoor attack in FL.",
                "In this paper, we propose DarkFed, the first ",
                "DA",
                "ta-f",
                "R",
                "ee bac",
                "K",
                "door attack in ",
                "FED",
                "erated learning. Specifically, we first explore the impact of shadow datasets on backdoor attacks. Surprisingly, even when there is a substantial gap between the shadow dataset and the main task dataset (",
                "e.g.",
                ", between CIFAR-10 and GTSRB), the backdoor can be successfully implanted while maintaining model utility. What’s even more astonishing is that using synthetic data devoid of any semantic information (",
                "e.g.",
                ", generated through a Gaussian distribution) as the shadow dataset still yields significant success in backdoor attacks. These promising results inspire us to inject the backdoor using a shadow dataset on the emulated fake clients. However, directly transferring the previous process is prone to detection by existing defenses due to the significant differences between backdoor updates and benign updates, leading to the failure of the attack. To further enhance the stealthiness of the attack, we propose property mimicry, optimizing backdoor updates to mimic benign updates in terms of magnitude, distribution, and consistency. These properties are widely employed by FL backdoor defenses to detect backdoor updates. This optimization significantly boosts the covert nature of the attack.",
                "In summary, our contributions are as follows:",
                "We introduce DarkFed, the first data-free backdoor attack in FL. This attack does not rely on task-specific data, enabling its use in scenarios with emulated fake clients, thus achieving a practical backdoor attack.",
                "We investigate the feasibility of injecting a backdoor with shadow datasets and find that even with synthetic datasets, successful backdoor injection is achievable. We extend this concept into the realm of FL.",
                "We introduce a novel defense evasion technique, property mimicry, which enables backdoor updates to mimic the properties of benign updates, thereby enhancing the stealthiness of the attack.",
                "Extensive experiments demonstrate that DarkFed achieves attack effects comparable to SOTA data-dependent attacks."
            ]
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Impact of shadow datasets on backdoor performance.",
        "table": "<table id=\"S5.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"></th>\n<td id=\"S5.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T2.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">CIFAR-10</span></td>\n<td id=\"S5.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T2.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">CIFAR-100</span></td>\n<td id=\"S5.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T2.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">GTSRB</span></td>\n</tr>\n<tr id=\"S5.T2.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr\"><span id=\"S5.T2.1.1.2.2.1.1\" class=\"ltx_text\">\n<span id=\"S5.T2.1.1.2.2.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S5.T2.1.1.2.2.1.1.1.1\" class=\"ltx_tr\">\n<span id=\"S5.T2.1.1.2.2.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T2.1.1.2.2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Shadow</span></span></span>\n<span id=\"S5.T2.1.1.2.2.1.1.1.2\" class=\"ltx_tr\">\n<span id=\"S5.T2.1.1.2.2.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T2.1.1.2.2.1.1.1.2.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></span></span>\n</span></span></th>\n<td id=\"S5.T2.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S5.T2.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n<td id=\"S5.T2.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S5.T2.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n<td id=\"S5.T2.1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.2.2.6.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S5.T2.1.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.2.2.7.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n</tr>\n<tr id=\"S5.T2.1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">CIFAR-10</th>\n<td id=\"S5.T2.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#9AFF99;\"><span id=\"S5.T2.1.1.3.3.2.1\" class=\"ltx_text\" style=\"background-color:#9AFF99;\">89.17</span></td>\n<td id=\"S5.T2.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#9AFF99;\"><span id=\"S5.T2.1.1.3.3.3.1\" class=\"ltx_text\" style=\"background-color:#9AFF99;\">100.00</span></td>\n<td id=\"S5.T2.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.97</td>\n<td id=\"S5.T2.1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100.00</td>\n<td id=\"S5.T2.1.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.17</td>\n<td id=\"S5.T2.1.1.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100.00</td>\n</tr>\n<tr id=\"S5.T2.1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">CIFAR-100</th>\n<td id=\"S5.T2.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.14</td>\n<td id=\"S5.T2.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100.00</td>\n<td id=\"S5.T2.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#9AFF99;\"><span id=\"S5.T2.1.1.4.4.4.1\" class=\"ltx_text\" style=\"background-color:#9AFF99;\">79.09</span></td>\n<td id=\"S5.T2.1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#9AFF99;\"><span id=\"S5.T2.1.1.4.4.5.1\" class=\"ltx_text\" style=\"background-color:#9AFF99;\">100.00</span></td>\n<td id=\"S5.T2.1.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.13</td>\n<td id=\"S5.T2.1.1.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100.00</td>\n</tr>\n<tr id=\"S5.T2.1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">GTSRB</th>\n<td id=\"S5.T2.1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">88.93</td>\n<td id=\"S5.T2.1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">99.81</td>\n<td id=\"S5.T2.1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.46</td>\n<td id=\"S5.T2.1.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100.00</td>\n<td id=\"S5.T2.1.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#9AFF99;\"><span id=\"S5.T2.1.1.5.5.6.1\" class=\"ltx_text\" style=\"background-color:#9AFF99;\">93.34</span></td>\n<td id=\"S5.T2.1.1.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#9AFF99;\"><span id=\"S5.T2.1.1.5.5.7.1\" class=\"ltx_text\" style=\"background-color:#9AFF99;\">100.00</span></td>\n</tr>\n<tr id=\"S5.T2.1.1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Gauss-I</th>\n<td id=\"S5.T2.1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">88.90</td>\n<td id=\"S5.T2.1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">98.36</td>\n<td id=\"S5.T2.1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.06</td>\n<td id=\"S5.T2.1.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">96.72</td>\n<td id=\"S5.T2.1.1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.08</td>\n<td id=\"S5.T2.1.1.6.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">99.35</td>\n</tr>\n<tr id=\"S5.T2.1.1.7.7\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Gauss-II</th>\n<td id=\"S5.T2.1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.02</td>\n<td id=\"S5.T2.1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">79.63</td>\n<td id=\"S5.T2.1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.19</td>\n<td id=\"S5.T2.1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">75.25</td>\n<td id=\"S5.T2.1.1.7.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">92.60</td>\n<td id=\"S5.T2.1.1.7.7.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">83.54</td>\n</tr>\n<tr id=\"S5.T2.1.1.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.8.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">Uniform</th>\n<td id=\"S5.T2.1.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">89.06</td>\n<td id=\"S5.T2.1.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">93.19</td>\n<td id=\"S5.T2.1.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">78.17</td>\n<td id=\"S5.T2.1.1.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">95.45</td>\n<td id=\"S5.T2.1.1.8.8.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">93.23</td>\n<td id=\"S5.T2.1.1.8.8.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">97.99</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To realize the data-free backdoor attack, it naturally prompts us to explore the utility of a shadow dataset, because obtaining diverse data unrelated to the main task is quite easy. For example, it can be achieved through web scraping of publicly available data or even generating a series of data points using Gaussian distribution. Consequently, we follow ",
                "Lv ",
                "et al.",
                " (",
                "2023",
                ")",
                " and embark on exploring the impact of shadow datasets on backdoor attacks.",
                "Formally, for a clean model ",
                "w",
                "𝑤",
                "w",
                " and a shadow dataset ",
                "D",
                "s",
                "subscript",
                "𝐷",
                "𝑠",
                "D_{s}",
                ", we fine-tune ",
                "w",
                "𝑤",
                "w",
                " into a backdoored version ",
                "w",
                "′",
                "superscript",
                "𝑤",
                "′",
                "w^{\\prime}",
                " with the following optimization objective:",
                "where ",
                "D",
                "s",
                "​",
                "c",
                "subscript",
                "𝐷",
                "𝑠",
                "𝑐",
                "D_{sc}",
                " represents the clean dataset without any modifications in the shadow dataset, and ",
                "D",
                "s",
                "​",
                "p",
                "subscript",
                "𝐷",
                "𝑠",
                "𝑝",
                "D_{sp}",
                " represents the poisoned dataset with triggers applied. ",
                "ℒ",
                "ℒ",
                "\\mathcal{L}",
                " is a loss function, ",
                "e.g.",
                ", cross entropy. ",
                "w",
                "​",
                "(",
                "⋅",
                ")",
                "𝑤",
                "⋅",
                "w(\\cdot)",
                " and ",
                "w",
                "′",
                "​",
                "(",
                "⋅",
                ")",
                "superscript",
                "𝑤",
                "′",
                "⋅",
                "w^{\\prime}(\\cdot)",
                " denote the logits of ",
                "w",
                "𝑤",
                "w",
                " and ",
                "w",
                "′",
                "superscript",
                "𝑤",
                "′",
                "w^{\\prime}",
                ", respectively, ",
                "y",
                "t",
                "subscript",
                "𝑦",
                "𝑡",
                "y_{t}",
                " is the target label, and the hyperparameter ",
                "λ",
                "1",
                "subscript",
                "𝜆",
                "1",
                "\\lambda_{1}",
                " is used to balance the model performance and the poisoning effect. The purpose of ",
                "L",
                "c",
                "​",
                "l",
                "subscript",
                "𝐿",
                "𝑐",
                "𝑙",
                "L_{cl}",
                " is to maintain the performance of the main task, while ",
                "L",
                "b",
                "​",
                "k",
                "subscript",
                "𝐿",
                "𝑏",
                "𝑘",
                "L_{bk}",
                " aims to learn the knowledge related to the backdoor. It should be noted that throughout the entire fine-tuning process, ",
                "λ",
                "1",
                "subscript",
                "𝜆",
                "1",
                "\\lambda_{1}",
                " is fixed at 1, and the clean model ",
                "w",
                "𝑤",
                "w",
                " is treated as a constant that remains unchanged.",
                "We consider three popular image classification tasks: CIFAR-10 ",
                "Krizhevsky and Hinton (",
                "2009",
                ")",
                ", CIFAR-100 ",
                "Krizhevsky and Hinton (",
                "2009",
                ")",
                ", and GTSRB ",
                "Stallkamp ",
                "et al.",
                " (",
                "2011",
                ")",
                ". As for the shadow datasets, in addition to these three real datasets, we also include three synthetic datasets constructed based on certain distributions. These synthetic datasets do not contain any semantic information. Due to the commonality of the three real datasets, we omit their introduction here and focus solely on describing the three synthetic datasets.",
                "Gauss-I.",
                "\nEach image is of size ",
                "32",
                "×",
                "32",
                "×",
                "3",
                "32",
                "32",
                "3",
                "32\\times 32\\times 3",
                ", with each pixel value generated from a Gaussian distribution ",
                "N",
                "​",
                "(",
                "0.5",
                ",",
                "1",
                "2",
                ")",
                "𝑁",
                "0.5",
                "superscript",
                "1",
                "2",
                "N(0.5,1^{2})",
                " and located within the range ",
                "[",
                "0",
                ",",
                "1",
                "]",
                "0",
                "1",
                "\\left[0,1\\right]",
                ".",
                "Gauss-II.",
                "\nEach image is of size ",
                "32",
                "×",
                "32",
                "×",
                "3",
                "32",
                "32",
                "3",
                "32\\times 32\\times 3",
                ", with each pixel value generated from a Gaussian distribution ",
                "N",
                "​",
                "(",
                "0.5",
                ",",
                "0.2",
                "2",
                ")",
                "𝑁",
                "0.5",
                "superscript",
                "0.2",
                "2",
                "N(0.5,0.2^{2})",
                " and located within the range ",
                "[",
                "0",
                ",",
                "1",
                "]",
                "0",
                "1",
                "\\left[0,1\\right]",
                ".",
                "Uniform.",
                "\nEach image is of size ",
                "32",
                "×",
                "32",
                "×",
                "3",
                "32",
                "32",
                "3",
                "32\\times 32\\times 3",
                ", with each pixel value generated from a uniform distribution ",
                "U",
                "​",
                "(",
                "0",
                ",",
                "1",
                ")",
                "𝑈",
                "0",
                "1",
                "U(0,1)",
                ".",
                "Fig. ",
                "1",
                " showcases a subset of samples from these datasets. Notably, significant visual disparities exist among them,\nwhich potentially leads to the presumption that their utilization as shadow datasets would lead to a reduction in the model’s main task recognition accuracy (",
                "i.e.",
                ", ACC) or an unsatisfactory level of backdoor task accuracy (",
                "i.e.",
                ", ASR). However, to our surprise, as shown in Tab. ",
                "2",
                ", the shadow dataset, compared to directly using task-related datasets (highlighted in green), does not significantly impact the backdoor performance, especially when utilizing real datasets. The last three rows in the table illustrate the scenario when synthetic datasets serve as shadow datasets. It can be observed that the performance of Gauss-I is comparable to that of real datasets. Gauss-II fails to achieve satisfactory ASR, and we speculate this is due to its small standard deviation during construction, resulting in lower data richness and thus poorer performance. Uniform’s performance falls between Gauss-I and Gauss-II, achieving over ",
                "90",
                "%",
                "percent",
                "90",
                "90\\%",
                " ASR on each dataset.",
                "We posit that the ability to maintain high ACC with a shadow dataset lies in our strategy of ensuring similarity between the logits of ",
                "w",
                "′",
                "superscript",
                "𝑤",
                "′",
                "w^{\\prime}",
                " and ",
                "w",
                "𝑤",
                "w",
                " (see ",
                "L",
                "c",
                "​",
                "l",
                "subscript",
                "𝐿",
                "𝑐",
                "𝑙",
                "L_{cl}",
                " in Eq. (",
                "2",
                ")), rather than employing hard labels. This allows for minor adjustments to be made to ",
                "w",
                "′",
                "superscript",
                "𝑤",
                "′",
                "w^{\\prime}",
                " based on ",
                "w",
                "𝑤",
                "w",
                ". The achievement of high ASR is attributed to the fact that backdoor learning focuses on the mapping relationship between the trigger and the target label, making it less influenced by the shadow dataset itself."
            ]
        ]
    },
    "S6.T3": {
        "caption": "Table 3: Performance of the initial global model.",
        "table": "<table id=\"S6.T3.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T3.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S6.T3.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">CIFAR-10</span></th>\n<th id=\"S6.T3.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S6.T3.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">CIFAR-100</span></th>\n<th id=\"S6.T3.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S6.T3.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">GTSRB</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T3.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S6.T3.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S6.T3.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.1.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n<td id=\"S6.T3.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.1.1.2.1.3.1\" class=\"ltx_text ltx_font_bold\">ACC(%)</span></td>\n<td id=\"S6.T3.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.1.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">ASR(%)</span></td>\n<td id=\"S6.T3.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.1.1.2.1.5.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S6.T3.1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T3.1.1.2.1.6.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n</tr>\n<tr id=\"S6.T3.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">90.15</td>\n<td id=\"S6.T3.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.77</td>\n<td id=\"S6.T3.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">79.01</td>\n<td id=\"S6.T3.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.79</td>\n<td id=\"S6.T3.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">93.08</td>\n<td id=\"S6.T3.1.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">2.93</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Datasets, models, and codes.",
                "\nWe consider three multi-channel image classification datasets: CIFAR-10 ",
                "Krizhevsky and Hinton (",
                "2009",
                ")",
                ", CIFAR-100 ",
                "Krizhevsky and Hinton (",
                "2009",
                ")",
                ", and GTSRB ",
                "Stallkamp ",
                "et al.",
                " (",
                "2011",
                ")",
                ". Because, compared to single-channel datasets like MNIST ",
                "LeCun ",
                "et al.",
                " (",
                "1998",
                ")",
                " and Fashion-MNIST ",
                "Xiao ",
                "et al.",
                " (",
                "2017",
                ")",
                ", multi-channel datasets are more complex and better represent real-world scenarios. For CIFAR-10 and CIFAR-100, we employ ResNet-18 as the model structure. For GTSRB, we construct a VGG-like model as the global model. It’s worth noting that, to expedite experimentation, we follow  ",
                "Li ",
                "et al.",
                " (",
                "2023",
                ")",
                ", employing a pre-trained model as the initial global model to simulate a scenario where the global model is nearing convergence. The initial model’s ACC and ASR on the three datasets are provided in Tab. ",
                "3",
                ". Note that when calculating ASR, samples corresponding to the target label have not been excluded. This results in some backdoor samples being identified as the target class not because they are triggered, but because they inherently belong to the target class. Consequently, this leads to a relatively higher ASR. This approach is justified since backdooring a FL system when the global model is close to convergence is enough. Our codes will be available at ",
                "https://github.com/hustweiwan/DarkFed",
                ".",
                "Shadow datasets.",
                "\nFor the CIFAR-10 and CIFAR-100 classification tasks, we employ GTSRB as the shadow dataset. Conversely, for the GTSRB classification task, we utilize CIFAR-100 as the shadow dataset. This decision is guided by the relatively small domain gap between CIFAR-10 and CIFAR-100, and we avoid using them interchangeably as shadow datasets.",
                "Attack settings.",
                "\nIn line with ",
                "Lyu ",
                "et al.",
                " (",
                "2023",
                ")",
                ", we establish a FL system encompassing 100 clients, with ",
                "20",
                "%",
                "percent",
                "20",
                "20\\%",
                " of them being emulated fake clients. These fake clients lack training data relevant to the main task and instead utilize a publicly scraped dataset or a synthetic dataset (",
                "e.g.",
                ", generated through Gaussian distribution) to introduce a backdoor. ",
                "20",
                "%",
                "percent",
                "20",
                "20\\%",
                " of the total clients are randomly selected in each iteration. The parameter settings in Alg. ",
                "1",
                " are delineated in Tab ",
                "4",
                ".\nOne might wonder why the estimated cosine similarity between benign updates (",
                "i.e.",
                ", ",
                "α",
                "𝛼",
                "\\alpha",
                ") consistently remains at 0 for different datasets. This is attributed to the research in ",
                "Wan ",
                "et al.",
                " (",
                "2022",
                ")",
                ", which indicates that benign updates exhibit similarity only in the initial rounds, becoming nearly orthogonal in subsequent iterations.",
                "Evaluated defenses.",
                "\nWe evaluate DarkFed against five SOTA defenses: FedAvg ",
                "McMahan ",
                "et al.",
                " (",
                "2017",
                ")",
                ", Norm Clipping ",
                "Bagdasaryan ",
                "et al.",
                " (",
                "2020",
                ")",
                ", FLAME ",
                "Nguyen ",
                "et al.",
                " (",
                "2022",
                ")",
                ", RFLBAT ",
                "Wang ",
                "et al.",
                " (",
                "2022",
                ")",
                ", and FoolsGold ",
                "Fung ",
                "et al.",
                " (",
                "2020",
                ")",
                ". The defenses cover all the types outlined in Sec. ",
                "2.2",
                ", showcasing the universality of DarkFed."
            ]
        ]
    },
    "S6.T4": {
        "caption": "Table 4: Patameter settings in Alg. 1.",
        "table": "<table id=\"S6.T4.6.6\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T4.6.6.6\" class=\"ltx_tr\">\n<th id=\"S6.T4.6.6.6.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_rr ltx_border_t\"><span id=\"S6.T4.6.6.6.7.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"S6.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><math id=\"S6.T4.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T4.1.1.1.1.m1.1a\"><mi id=\"S6.T4.1.1.1.1.m1.1.1\" xref=\"S6.T4.1.1.1.1.m1.1.1.cmml\">α</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T4.1.1.1.1.m1.1b\"><ci id=\"S6.T4.1.1.1.1.m1.1.1.cmml\" xref=\"S6.T4.1.1.1.1.m1.1.1\">𝛼</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T4.1.1.1.1.m1.1c\">\\alpha</annotation></semantics></math></th>\n<th id=\"S6.T4.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><math id=\"S6.T4.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\lambda\" display=\"inline\"><semantics id=\"S6.T4.2.2.2.2.m1.1a\"><mi id=\"S6.T4.2.2.2.2.m1.1.1\" xref=\"S6.T4.2.2.2.2.m1.1.1.cmml\">λ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T4.2.2.2.2.m1.1b\"><ci id=\"S6.T4.2.2.2.2.m1.1.1.cmml\" xref=\"S6.T4.2.2.2.2.m1.1.1\">𝜆</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T4.2.2.2.2.m1.1c\">\\lambda</annotation></semantics></math></th>\n<th id=\"S6.T4.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><math id=\"S6.T4.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\eta\" display=\"inline\"><semantics id=\"S6.T4.3.3.3.3.m1.1a\"><mi id=\"S6.T4.3.3.3.3.m1.1.1\" xref=\"S6.T4.3.3.3.3.m1.1.1.cmml\">η</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T4.3.3.3.3.m1.1b\"><ci id=\"S6.T4.3.3.3.3.m1.1.1.cmml\" xref=\"S6.T4.3.3.3.3.m1.1.1\">𝜂</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T4.3.3.3.3.m1.1c\">\\eta</annotation></semantics></math></th>\n<th id=\"S6.T4.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><math id=\"S6.T4.4.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"E\" display=\"inline\"><semantics id=\"S6.T4.4.4.4.4.m1.1a\"><mi id=\"S6.T4.4.4.4.4.m1.1.1\" xref=\"S6.T4.4.4.4.4.m1.1.1.cmml\">E</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T4.4.4.4.4.m1.1b\"><ci id=\"S6.T4.4.4.4.4.m1.1.1.cmml\" xref=\"S6.T4.4.4.4.4.m1.1.1\">𝐸</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T4.4.4.4.4.m1.1c\">E</annotation></semantics></math></th>\n<th id=\"S6.T4.5.5.5.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><math id=\"S6.T4.5.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"B\" display=\"inline\"><semantics id=\"S6.T4.5.5.5.5.m1.1a\"><mi id=\"S6.T4.5.5.5.5.m1.1.1\" xref=\"S6.T4.5.5.5.5.m1.1.1.cmml\">B</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T4.5.5.5.5.m1.1b\"><ci id=\"S6.T4.5.5.5.5.m1.1.1.cmml\" xref=\"S6.T4.5.5.5.5.m1.1.1\">𝐵</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T4.5.5.5.5.m1.1c\">B</annotation></semantics></math></th>\n<th id=\"S6.T4.6.6.6.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><math id=\"S6.T4.6.6.6.6.m1.1\" class=\"ltx_Math\" alttext=\"D_{s}\" display=\"inline\"><semantics id=\"S6.T4.6.6.6.6.m1.1a\"><msub id=\"S6.T4.6.6.6.6.m1.1.1\" xref=\"S6.T4.6.6.6.6.m1.1.1.cmml\"><mi id=\"S6.T4.6.6.6.6.m1.1.1.2\" xref=\"S6.T4.6.6.6.6.m1.1.1.2.cmml\">D</mi><mi id=\"S6.T4.6.6.6.6.m1.1.1.3\" xref=\"S6.T4.6.6.6.6.m1.1.1.3.cmml\">s</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S6.T4.6.6.6.6.m1.1b\"><apply id=\"S6.T4.6.6.6.6.m1.1.1.cmml\" xref=\"S6.T4.6.6.6.6.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S6.T4.6.6.6.6.m1.1.1.1.cmml\" xref=\"S6.T4.6.6.6.6.m1.1.1\">subscript</csymbol><ci id=\"S6.T4.6.6.6.6.m1.1.1.2.cmml\" xref=\"S6.T4.6.6.6.6.m1.1.1.2\">𝐷</ci><ci id=\"S6.T4.6.6.6.6.m1.1.1.3.cmml\" xref=\"S6.T4.6.6.6.6.m1.1.1.3\">𝑠</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T4.6.6.6.6.m1.1c\">D_{s}</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T4.6.6.7.1\" class=\"ltx_tr\">\n<td id=\"S6.T4.6.6.7.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t\">CIFAR-10</td>\n<td id=\"S6.T4.6.6.7.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S6.T4.6.6.7.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.5</td>\n<td id=\"S6.T4.6.6.7.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.005</td>\n<td id=\"S6.T4.6.6.7.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">15</td>\n<td id=\"S6.T4.6.6.7.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64</td>\n<td id=\"S6.T4.6.6.7.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">GTSRB</td>\n</tr>\n<tr id=\"S6.T4.6.6.8.2\" class=\"ltx_tr\">\n<td id=\"S6.T4.6.6.8.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t\">CIFAR-100</td>\n<td id=\"S6.T4.6.6.8.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S6.T4.6.6.8.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.5</td>\n<td id=\"S6.T4.6.6.8.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.001</td>\n<td id=\"S6.T4.6.6.8.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">15</td>\n<td id=\"S6.T4.6.6.8.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64</td>\n<td id=\"S6.T4.6.6.8.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">GTSRB</td>\n</tr>\n<tr id=\"S6.T4.6.6.9.3\" class=\"ltx_tr\">\n<td id=\"S6.T4.6.6.9.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">GTSRB</td>\n<td id=\"S6.T4.6.6.9.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0</td>\n<td id=\"S6.T4.6.6.9.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.5</td>\n<td id=\"S6.T4.6.6.9.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.00005</td>\n<td id=\"S6.T4.6.6.9.3.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">15</td>\n<td id=\"S6.T4.6.6.9.3.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">64</td>\n<td id=\"S6.T4.6.6.9.3.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">CIFAR-100</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Datasets, models, and codes.",
                "\nWe consider three multi-channel image classification datasets: CIFAR-10 ",
                "Krizhevsky and Hinton (",
                "2009",
                ")",
                ", CIFAR-100 ",
                "Krizhevsky and Hinton (",
                "2009",
                ")",
                ", and GTSRB ",
                "Stallkamp ",
                "et al.",
                " (",
                "2011",
                ")",
                ". Because, compared to single-channel datasets like MNIST ",
                "LeCun ",
                "et al.",
                " (",
                "1998",
                ")",
                " and Fashion-MNIST ",
                "Xiao ",
                "et al.",
                " (",
                "2017",
                ")",
                ", multi-channel datasets are more complex and better represent real-world scenarios. For CIFAR-10 and CIFAR-100, we employ ResNet-18 as the model structure. For GTSRB, we construct a VGG-like model as the global model. It’s worth noting that, to expedite experimentation, we follow  ",
                "Li ",
                "et al.",
                " (",
                "2023",
                ")",
                ", employing a pre-trained model as the initial global model to simulate a scenario where the global model is nearing convergence. The initial model’s ACC and ASR on the three datasets are provided in Tab. ",
                "3",
                ". Note that when calculating ASR, samples corresponding to the target label have not been excluded. This results in some backdoor samples being identified as the target class not because they are triggered, but because they inherently belong to the target class. Consequently, this leads to a relatively higher ASR. This approach is justified since backdooring a FL system when the global model is close to convergence is enough. Our codes will be available at ",
                "https://github.com/hustweiwan/DarkFed",
                ".",
                "Shadow datasets.",
                "\nFor the CIFAR-10 and CIFAR-100 classification tasks, we employ GTSRB as the shadow dataset. Conversely, for the GTSRB classification task, we utilize CIFAR-100 as the shadow dataset. This decision is guided by the relatively small domain gap between CIFAR-10 and CIFAR-100, and we avoid using them interchangeably as shadow datasets.",
                "Attack settings.",
                "\nIn line with ",
                "Lyu ",
                "et al.",
                " (",
                "2023",
                ")",
                ", we establish a FL system encompassing 100 clients, with ",
                "20",
                "%",
                "percent",
                "20",
                "20\\%",
                " of them being emulated fake clients. These fake clients lack training data relevant to the main task and instead utilize a publicly scraped dataset or a synthetic dataset (",
                "e.g.",
                ", generated through Gaussian distribution) to introduce a backdoor. ",
                "20",
                "%",
                "percent",
                "20",
                "20\\%",
                " of the total clients are randomly selected in each iteration. The parameter settings in Alg. ",
                "1",
                " are delineated in Tab ",
                "4",
                ".\nOne might wonder why the estimated cosine similarity between benign updates (",
                "i.e.",
                ", ",
                "α",
                "𝛼",
                "\\alpha",
                ") consistently remains at 0 for different datasets. This is attributed to the research in ",
                "Wan ",
                "et al.",
                " (",
                "2022",
                ")",
                ", which indicates that benign updates exhibit similarity only in the initial rounds, becoming nearly orthogonal in subsequent iterations.",
                "Evaluated defenses.",
                "\nWe evaluate DarkFed against five SOTA defenses: FedAvg ",
                "McMahan ",
                "et al.",
                " (",
                "2017",
                ")",
                ", Norm Clipping ",
                "Bagdasaryan ",
                "et al.",
                " (",
                "2020",
                ")",
                ", FLAME ",
                "Nguyen ",
                "et al.",
                " (",
                "2022",
                ")",
                ", RFLBAT ",
                "Wang ",
                "et al.",
                " (",
                "2022",
                ")",
                ", and FoolsGold ",
                "Fung ",
                "et al.",
                " (",
                "2020",
                ")",
                ". The defenses cover all the types outlined in Sec. ",
                "2.2",
                ", showcasing the universality of DarkFed."
            ]
        ]
    },
    "S6.T5": {
        "caption": "Table 5: Impact of the attacker ratio.",
        "table": "<table id=\"S6.T5.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T5.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T5.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\" rowspan=\"2\"><span id=\"S6.T5.1.1.1.1.1.1\" class=\"ltx_text\">\n<span id=\"S6.T5.1.1.1.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S6.T5.1.1.1.1.1.1.1.1\" class=\"ltx_tr\">\n<span id=\"S6.T5.1.1.1.1.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S6.T5.1.1.1.1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Attacker</span></span></span>\n<span id=\"S6.T5.1.1.1.1.1.1.1.2\" class=\"ltx_tr\">\n<span id=\"S6.T5.1.1.1.1.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S6.T5.1.1.1.1.1.1.1.2.1.1\" class=\"ltx_text ltx_font_bold\">Ratio</span></span></span>\n</span></span></th>\n<td id=\"S6.T5.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S6.T5.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">CIFAR-10</span></td>\n<td id=\"S6.T5.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S6.T5.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">CIFAR-100</span></td>\n<td id=\"S6.T5.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S6.T5.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">GTSRB</span></td>\n</tr>\n<tr id=\"S6.T5.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T5.1.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S6.T5.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T5.1.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n<td id=\"S6.T5.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T5.1.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S6.T5.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T5.1.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n<td id=\"S6.T5.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T5.1.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S6.T5.1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T5.1.1.2.2.6.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n</tr>\n<tr id=\"S6.T5.1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T5.1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">5%</th>\n<td id=\"S6.T5.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.61</td>\n<td id=\"S6.T5.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">95.85</td>\n<td id=\"S6.T5.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">79.13</td>\n<td id=\"S6.T5.1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">94.30</td>\n<td id=\"S6.T5.1.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">92.82</td>\n<td id=\"S6.T5.1.1.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">99.94</td>\n</tr>\n<tr id=\"S6.T5.1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T5.1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">10%</th>\n<td id=\"S6.T5.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.22</td>\n<td id=\"S6.T5.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.81</td>\n<td id=\"S6.T5.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.94</td>\n<td id=\"S6.T5.1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">99.77</td>\n<td id=\"S6.T5.1.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">92.53</td>\n<td id=\"S6.T5.1.1.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100.00</td>\n</tr>\n<tr id=\"S6.T5.1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S6.T5.1.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">15%</th>\n<td id=\"S6.T5.1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.13</td>\n<td id=\"S6.T5.1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">98.51</td>\n<td id=\"S6.T5.1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.82</td>\n<td id=\"S6.T5.1.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">99.92</td>\n<td id=\"S6.T5.1.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">91.84</td>\n<td id=\"S6.T5.1.1.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100.00</td>\n</tr>\n<tr id=\"S6.T5.1.1.6.6\" class=\"ltx_tr\">\n<th id=\"S6.T5.1.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">20%</th>\n<td id=\"S6.T5.1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.04</td>\n<td id=\"S6.T5.1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">98.96</td>\n<td id=\"S6.T5.1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.62</td>\n<td id=\"S6.T5.1.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100.00</td>\n<td id=\"S6.T5.1.1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">91.74</td>\n<td id=\"S6.T5.1.1.6.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100.00</td>\n</tr>\n<tr id=\"S6.T5.1.1.7.7\" class=\"ltx_tr\">\n<th id=\"S6.T5.1.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">25%</th>\n<td id=\"S6.T5.1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">90.09</td>\n<td id=\"S6.T5.1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">99.01</td>\n<td id=\"S6.T5.1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">78.15</td>\n<td id=\"S6.T5.1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">100.00</td>\n<td id=\"S6.T5.1.1.7.7.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">91.51</td>\n<td id=\"S6.T5.1.1.7.7.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">100.00</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Attack performance. ",
                "\nWe systematically verify the attainment of the adversary’s goals to assess the attack performance. Figs. ",
                "3",
                " illustrates the impact of DarkFed on SOTA defenses on CIFAR-10 (first row), CIFAR-100 (second row), and GTSRB (third row). The green line represents ACC, while the red line denotes ASR. In terms of fidelity, DarkFed achieves high ACC on both CIFAR-10 and CIFAR-100, with an accuracy degradation within ",
                "1",
                "%",
                "percent",
                "1",
                "1\\%",
                " compared to the initial model. On GTSRB, across various defenses, accuracy degradation ranges between ",
                "1",
                "%",
                "percent",
                "1",
                "1\\%",
                " and ",
                "3",
                "%",
                "percent",
                "3",
                "3\\%",
                ". These marginal accuracy degradations do not significantly affect model usability, showcasing DarkFed’s fidelity achievement. In terms of effectiveness, DarkFed rapidly achieves nearly ",
                "100",
                "%",
                "percent",
                "100",
                "100\\%",
                " ASR with few iterations across all three datasets (around 20 iterations for CIFAR-10 and CIFAR-100, and 10 iterations for GTSRB), highlighting its remarkable attack effectiveness. The stealthiness goal is indirectly demonstrated through the preceding two goals, as a sufficiently concealed attack is essential to ensure that backdoor updates evade defenses, ultimately resulting in a global model that excels in both the main and backdoor tasks.",
                "Impact of attacker ratio. ",
                "\nTab.",
                "5",
                " illustrates the impact of attacker ratio on DarkFed under FLAME. It is noticeable that as the ratio of attackers increases, ACC experiences a slight decrease, while ASR exhibits an upward trend. However, overall, DarkFed shows minimal susceptibility to changes in the attacker ratio. Even in the presence of a ",
                "5",
                "%",
                "percent",
                "5",
                "5\\%",
                " attacker ratio, the ASR remains notably high, reaching a minimum of ",
                "94.30",
                "%",
                "percent",
                "94.30",
                "94.30\\%",
                ". The ASR nearly peaks when the attacker ratio reaches ",
                "10",
                "%",
                "percent",
                "10",
                "10\\%",
                ".",
                "Comparison with SOTA attacks. ",
                "\nExisting research has not delved into data-free backdoor attacks in FL, thus we showcase DarkFed’s superiority by directly comparing it with SOTA data-dependent attacks. Specifically, we consider the classic Model Replacement Attack ",
                "Bagdasaryan ",
                "et al.",
                " (",
                "2020",
                ")",
                " and the latest 3DFed ",
                "Li ",
                "et al.",
                " (",
                "2023",
                ")",
                ". It’s important to note that these two attacks directly utilize task-specific data, while DarkFed relies solely on shadow dataset. Tab. ",
                "6",
                " presents the comparative results on CIFAR-10.\nIn terms of ACC, these three attacks exhibit no significant differences; all maintain high model accuracy. On average, the differences among them are within ",
                "0.11",
                "%",
                "percent",
                "0.11",
                "0.11\\%",
                ". Regarding ASR, Model Replacement Attack performs relatively poorly, only managing to backdoor FedAvg and Norm Clipping. Both 3DFed and DarkFed can overcome all defenses, but DarkFed’s average ASR is slightly higher than 3DFed. Furthermore, we observe that 3DFed’s ASR under the RFLBAT defense is ",
                "3",
                "%",
                "percent",
                "3",
                "3\\%",
                " lower than DarkFed. We speculate that this is because 3DFed needs to use decoy model updates as bait to mislead RFLBAT. As a result, not all backdoor updates can be accepted by RFLBAT, sacrificing attack performance to some extent.",
                "Attack with synthetic dataset. ",
                "The preceding experiments utilize shadow datasets comprising real data from vastly different domains, yielding highly effective attack outcomes. Consequently, a naturally intriguing question arises: Can we achieve similar attack results with synthetic dataset? To answer this question, we employ Gauss-I as the shadow dataset for CIFAR-10, and the experimental results are depicted in Fig. ",
                "4",
                ". Compared with the earlier experiments (the first row of Fig. ",
                "3",
                "), ACC remains consistent, hovering around ",
                "90",
                "%",
                "percent",
                "90",
                "90\\%",
                ". Although ASR suffers a relative decrease, it still approaches ",
                "90",
                "%",
                "percent",
                "90",
                "90\\%",
                ". The experimental results are promising, indicating that even without crawling any datasets online, the use of self-constructed, semantically meaningless data can successfully inject a backdoor without compromising model accuracy."
            ]
        ]
    },
    "S6.T6": {
        "caption": "Table 6: Comparison with SOTA data-dependent attacks.",
        "table": "<table id=\"S6.T6.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T6.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T6.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"></th>\n<td id=\"S6.T6.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S6.T6.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Model Replacement</span></td>\n<td id=\"S6.T6.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S6.T6.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">3DFed</span></td>\n<td id=\"S6.T6.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S6.T6.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">DarkFed</span></td>\n</tr>\n<tr id=\"S6.T6.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S6.T6.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr\"><span id=\"S6.T6.1.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Defense</span></th>\n<td id=\"S6.T6.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S6.T6.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n<td id=\"S6.T6.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S6.T6.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n<td id=\"S6.T6.1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.2.2.6.1\" class=\"ltx_text ltx_font_bold\">ACC (%)</span></td>\n<td id=\"S6.T6.1.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.2.2.7.1\" class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n</tr>\n<tr id=\"S6.T6.1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T6.1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">FedAvg</th>\n<td id=\"S6.T6.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.3.3.2.1\" class=\"ltx_text\" style=\"color:#009901;\"><span id=\"S6.T6.1.1.3.3.2.1.1\" class=\"ltx_text ltx_font_bold\">89.74</span></span></td>\n<td id=\"S6.T6.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">99.16</td>\n<td id=\"S6.T6.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.66</td>\n<td id=\"S6.T6.1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.3.3.5.1\" class=\"ltx_text\" style=\"color:#9A0000;\"><span id=\"S6.T6.1.1.3.3.5.1.1\" class=\"ltx_text ltx_font_bold\">99.85</span></span></td>\n<td id=\"S6.T6.1.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.54</td>\n<td id=\"S6.T6.1.1.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">99.18</td>\n</tr>\n<tr id=\"S6.T6.1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T6.1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Norm Clipping</th>\n<td id=\"S6.T6.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.07</td>\n<td id=\"S6.T6.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.93</td>\n<td id=\"S6.T6.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.14</td>\n<td id=\"S6.T6.1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">98.71</td>\n<td id=\"S6.T6.1.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.4.4.6.1\" class=\"ltx_text\" style=\"color:#009901;\"><span id=\"S6.T6.1.1.4.4.6.1.1\" class=\"ltx_text ltx_font_bold\">90.26</span></span></td>\n<td id=\"S6.T6.1.1.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.4.4.7.1\" class=\"ltx_text\" style=\"color:#9A0000;\"><span id=\"S6.T6.1.1.4.4.7.1.1\" class=\"ltx_text ltx_font_bold\">99.20</span></span></td>\n</tr>\n<tr id=\"S6.T6.1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S6.T6.1.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">FLAME</th>\n<td id=\"S6.T6.1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.5.5.2.1\" class=\"ltx_text\" style=\"color:#009901;\"><span id=\"S6.T6.1.1.5.5.2.1.1\" class=\"ltx_text ltx_font_bold\">90.26</span></span></td>\n<td id=\"S6.T6.1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">9.74</td>\n<td id=\"S6.T6.1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.01</td>\n<td id=\"S6.T6.1.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.5.5.5.1\" class=\"ltx_text\" style=\"color:#9A0000;\"><span id=\"S6.T6.1.1.5.5.5.1.1\" class=\"ltx_text ltx_font_bold\">99.89</span></span></td>\n<td id=\"S6.T6.1.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.96</td>\n<td id=\"S6.T6.1.1.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">98.51</td>\n</tr>\n<tr id=\"S6.T6.1.1.6.6\" class=\"ltx_tr\">\n<th id=\"S6.T6.1.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">RFLBAT</th>\n<td id=\"S6.T6.1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.17</td>\n<td id=\"S6.T6.1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">8.84</td>\n<td id=\"S6.T6.1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.21</td>\n<td id=\"S6.T6.1.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">96.18</td>\n<td id=\"S6.T6.1.1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.6.6.6.1\" class=\"ltx_text\" style=\"color:#009901;\"><span id=\"S6.T6.1.1.6.6.6.1.1\" class=\"ltx_text ltx_font_bold\">90.24</span></span></td>\n<td id=\"S6.T6.1.1.6.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.6.6.7.1\" class=\"ltx_text\" style=\"color:#9A0000;\"><span id=\"S6.T6.1.1.6.6.7.1.1\" class=\"ltx_text ltx_font_bold\">99.18</span></span></td>\n</tr>\n<tr id=\"S6.T6.1.1.7.7\" class=\"ltx_tr\">\n<th id=\"S6.T6.1.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">FoolsGold</th>\n<td id=\"S6.T6.1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.82</td>\n<td id=\"S6.T6.1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">9.77</td>\n<td id=\"S6.T6.1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.7.7.4.1\" class=\"ltx_text\" style=\"color:#009901;\"><span id=\"S6.T6.1.1.7.7.4.1.1\" class=\"ltx_text ltx_font_bold\">89.97</span></span></td>\n<td id=\"S6.T6.1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">98.51</td>\n<td id=\"S6.T6.1.1.7.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.49</td>\n<td id=\"S6.T6.1.1.7.7.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.7.7.7.1\" class=\"ltx_text\" style=\"color:#9A0000;\"><span id=\"S6.T6.1.1.7.7.7.1.1\" class=\"ltx_text ltx_font_bold\">98.52</span></span></td>\n</tr>\n<tr id=\"S6.T6.1.1.8.8\" class=\"ltx_tr\">\n<th id=\"S6.T6.1.1.8.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">Average</th>\n<td id=\"S6.T6.1.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.8.8.2.1\" class=\"ltx_text\" style=\"color:#009901;\"><span id=\"S6.T6.1.1.8.8.2.1.1\" class=\"ltx_text ltx_font_bold\">90.01</span></span></td>\n<td id=\"S6.T6.1.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">45.09</td>\n<td id=\"S6.T6.1.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">90.00</td>\n<td id=\"S6.T6.1.1.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">98.63</td>\n<td id=\"S6.T6.1.1.8.8.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">89.90</td>\n<td id=\"S6.T6.1.1.8.8.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S6.T6.1.1.8.8.7.1\" class=\"ltx_text\" style=\"color:#9A0000;\"><span id=\"S6.T6.1.1.8.8.7.1.1\" class=\"ltx_text ltx_font_bold\">98.92</span></span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Attack performance. ",
                "\nWe systematically verify the attainment of the adversary’s goals to assess the attack performance. Figs. ",
                "3",
                " illustrates the impact of DarkFed on SOTA defenses on CIFAR-10 (first row), CIFAR-100 (second row), and GTSRB (third row). The green line represents ACC, while the red line denotes ASR. In terms of fidelity, DarkFed achieves high ACC on both CIFAR-10 and CIFAR-100, with an accuracy degradation within ",
                "1",
                "%",
                "percent",
                "1",
                "1\\%",
                " compared to the initial model. On GTSRB, across various defenses, accuracy degradation ranges between ",
                "1",
                "%",
                "percent",
                "1",
                "1\\%",
                " and ",
                "3",
                "%",
                "percent",
                "3",
                "3\\%",
                ". These marginal accuracy degradations do not significantly affect model usability, showcasing DarkFed’s fidelity achievement. In terms of effectiveness, DarkFed rapidly achieves nearly ",
                "100",
                "%",
                "percent",
                "100",
                "100\\%",
                " ASR with few iterations across all three datasets (around 20 iterations for CIFAR-10 and CIFAR-100, and 10 iterations for GTSRB), highlighting its remarkable attack effectiveness. The stealthiness goal is indirectly demonstrated through the preceding two goals, as a sufficiently concealed attack is essential to ensure that backdoor updates evade defenses, ultimately resulting in a global model that excels in both the main and backdoor tasks.",
                "Impact of attacker ratio. ",
                "\nTab.",
                "5",
                " illustrates the impact of attacker ratio on DarkFed under FLAME. It is noticeable that as the ratio of attackers increases, ACC experiences a slight decrease, while ASR exhibits an upward trend. However, overall, DarkFed shows minimal susceptibility to changes in the attacker ratio. Even in the presence of a ",
                "5",
                "%",
                "percent",
                "5",
                "5\\%",
                " attacker ratio, the ASR remains notably high, reaching a minimum of ",
                "94.30",
                "%",
                "percent",
                "94.30",
                "94.30\\%",
                ". The ASR nearly peaks when the attacker ratio reaches ",
                "10",
                "%",
                "percent",
                "10",
                "10\\%",
                ".",
                "Comparison with SOTA attacks. ",
                "\nExisting research has not delved into data-free backdoor attacks in FL, thus we showcase DarkFed’s superiority by directly comparing it with SOTA data-dependent attacks. Specifically, we consider the classic Model Replacement Attack ",
                "Bagdasaryan ",
                "et al.",
                " (",
                "2020",
                ")",
                " and the latest 3DFed ",
                "Li ",
                "et al.",
                " (",
                "2023",
                ")",
                ". It’s important to note that these two attacks directly utilize task-specific data, while DarkFed relies solely on shadow dataset. Tab. ",
                "6",
                " presents the comparative results on CIFAR-10.\nIn terms of ACC, these three attacks exhibit no significant differences; all maintain high model accuracy. On average, the differences among them are within ",
                "0.11",
                "%",
                "percent",
                "0.11",
                "0.11\\%",
                ". Regarding ASR, Model Replacement Attack performs relatively poorly, only managing to backdoor FedAvg and Norm Clipping. Both 3DFed and DarkFed can overcome all defenses, but DarkFed’s average ASR is slightly higher than 3DFed. Furthermore, we observe that 3DFed’s ASR under the RFLBAT defense is ",
                "3",
                "%",
                "percent",
                "3",
                "3\\%",
                " lower than DarkFed. We speculate that this is because 3DFed needs to use decoy model updates as bait to mislead RFLBAT. As a result, not all backdoor updates can be accepted by RFLBAT, sacrificing attack performance to some extent.",
                "Attack with synthetic dataset. ",
                "The preceding experiments utilize shadow datasets comprising real data from vastly different domains, yielding highly effective attack outcomes. Consequently, a naturally intriguing question arises: Can we achieve similar attack results with synthetic dataset? To answer this question, we employ Gauss-I as the shadow dataset for CIFAR-10, and the experimental results are depicted in Fig. ",
                "4",
                ". Compared with the earlier experiments (the first row of Fig. ",
                "3",
                "), ACC remains consistent, hovering around ",
                "90",
                "%",
                "percent",
                "90",
                "90\\%",
                ". Although ASR suffers a relative decrease, it still approaches ",
                "90",
                "%",
                "percent",
                "90",
                "90\\%",
                ". The experimental results are promising, indicating that even without crawling any datasets online, the use of self-constructed, semantically meaningless data can successfully inject a backdoor without compromising model accuracy."
            ]
        ]
    }
}