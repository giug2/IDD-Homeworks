{
    "id_table_1": {
        "caption": "TABLE I:  Simulation parameters of the proposed approach",
        "table": "S6.EGx1",
        "footnotes": [],
        "references": [
            "Framework.   The steps of our proposed method, depicted in Figure  1 , are:",
            "Proposition  1  means we can perform score matching without knowing the underlying distribution  p  ( H v | x ) p conditional subscript H v x p(\\mathbf{H}_{\\mathrm{v}}|\\mathbf{x}) italic_p ( bold_H start_POSTSUBSCRIPT roman_v end_POSTSUBSCRIPT | bold_x ) . By training the neural network  S ~  ( H ~ v | x ;  ) ~ S conditional subscript ~ H v x  \\widetilde{\\mathbf{S}}(\\widetilde{\\mathbf{H}}_{\\mathrm{v}}|\\mathbf{x};\\mathbf{% \\Theta}) over~ start_ARG bold_S end_ARG ( over~ start_ARG bold_H end_ARG start_POSTSUBSCRIPT roman_v end_POSTSUBSCRIPT | bold_x ; bold_ )  to converge to a known  N N \\mathbf{N} bold_N  in a supervised fashion, we can effectively learn the score function   H v | x log  p  ( H v | x ) subscript  conditional subscript H v x p conditional subscript H v x \\nabla_{\\mathbf{H}_{\\mathrm{v}}|\\mathbf{x}}\\log p(\\mathbf{H}_{\\mathrm{v}}|% \\mathbf{x})  start_POSTSUBSCRIPT bold_H start_POSTSUBSCRIPT roman_v end_POSTSUBSCRIPT | bold_x end_POSTSUBSCRIPT roman_log italic_p ( bold_H start_POSTSUBSCRIPT roman_v end_POSTSUBSCRIPT | bold_x ) .",
            "Training Process of the cDDIM Model.  Diffusion-based generative models operate by learning a denoising process across various noise levels. The training process for a conditional DDIM (cDDIM) is described in Algorithm  1 .",
            "As shown in line 1 of Algorithm  1 , our input to the channel consists of channel matrices and corresponding UE position pairs. The process involves scheduling noise levels and denoising steps over  T T T italic_T  iterations. In this context,      [ t ]    delimited-[] t \\overline{\\alpha}[t] over  start_ARG italic_ end_ARG [ italic_t ]  represents the cumulative product of a predefined scaling schedule    \\alpha italic_  over time steps, defined as      [ t ] =  u = 1 t   [ u ]    delimited-[] t superscript subscript product u 1 t  delimited-[] u \\overline{\\alpha}[t]=\\prod_{u=1}^{t}\\alpha[u] over  start_ARG italic_ end_ARG [ italic_t ] =  start_POSTSUBSCRIPT italic_u = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_ [ italic_u ]   [ 26 ] . The variable    [ t ]  delimited-[] t \\sigma[t] italic_ [ italic_t ] , defined as    [ t ] = 1      [ t ]  delimited-[] t 1    delimited-[] t \\sigma[t]=\\sqrt{1-\\overline{\\alpha}[t]} italic_ [ italic_t ] = square-root start_ARG 1 - over  start_ARG italic_ end_ARG [ italic_t ] end_ARG , governs the noise level at each step and is used in the denoising process. Although it is a sequential discrete process, we can represent  H v , train , i  [ t ] subscript H v train i delimited-[] t \\mathbf{H}_{\\mathrm{v,train},i}[t] bold_H start_POSTSUBSCRIPT roman_v , roman_train , italic_i end_POSTSUBSCRIPT [ italic_t ]  in terms of  H v , train , i  [ 0 ] subscript H v train i delimited-[] 0 \\mathbf{H}_{\\mathrm{v,train},i}[0] bold_H start_POSTSUBSCRIPT roman_v , roman_train , italic_i end_POSTSUBSCRIPT [ 0 ]  and noise  N  [ t ] N delimited-[] t \\mathbf{N}[t] bold_N [ italic_t ] , which is",
            "Then, we update    \\mathbf{\\Theta} bold_  by calculating the gradient of the difference between  S ~ ~ S \\widetilde{\\mathbf{S}} over~ start_ARG bold_S end_ARG  with the input of the noise-added channel  H v , train , i  [ t ] subscript H v train i delimited-[] t \\mathbf{H}_{\\mathrm{v,train},i}[t] bold_H start_POSTSUBSCRIPT roman_v , roman_train , italic_i end_POSTSUBSCRIPT [ italic_t ]  and the noise  N  [ t ] N delimited-[] t \\mathbf{N}[t] bold_N [ italic_t ] , as shown in line 8. The output of Algorithm  1  is the trained model  S ~ (  |  ,  ;  ) \\widetilde{\\mathbf{S}}(\\cdot|\\cdot,\\cdot;\\mathbf{\\Theta}) over~ start_ARG bold_S end_ARG (  |  ,  ; bold_ ) , which is used for the inference process, as explained next.",
            "Diffusion models are a recent development, and their analysis is well-understood only in certain special cases, such as Gaussian data  [ 39 ] , which can also be thought of as Rayleigh fading channels. Nevertheless, based on recent findings, we provide theoretical guarantees on the convergence of these models in terms of the latent dimension of the MIMO channels, which we define formally in Remark  1 . The key insight is as follows: leveraging the fact that sparse MIMO channels have low rank  r r r italic_r , we demonstrate that the crucial factor for the convergence of the diffusion model is not the dimension of the channel itself,  N t  N r subscript N t subscript N r N_{t}\\times N_{r} italic_N start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  italic_N start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , but the dimension of the underlying latent vector,  d  r d r d\\leq r italic_d  italic_r .",
            "Remark  1  tells us that if we can assume the channel matrix distribution can be projected onto a low-rank space, we can establish an asymptotic error bound for the diffusion model when using a finite amount of data. Given that our dataset consists of sparse MIMO channels in beamspace, this assumption is highly plausible. Thus, even for high-dimensional channel data, the low-rank and sparse nature of mmWave channels allows the diffusion model to learn the score function with only a finite amount of data, as it is the dimension of the underlying latent vector that is crucial.",
            "A  \\ac CRNet consists of two deep neural networks: an encoder  E E \\mathcal{E} caligraphic_E  and a decoder  D D \\mathcal{D} caligraphic_D . First, we apply  \\ac DFT to the channel matrix  H H \\mathbf{H} bold_H  to obtain its beamspace representation  H v subscript H v \\mathbf{H}_{\\mathrm{v}} bold_H start_POSTSUBSCRIPT roman_v end_POSTSUBSCRIPT . We then input the channel matrix  H v subscript H v \\mathbf{H}_{\\mathrm{v}} bold_H start_POSTSUBSCRIPT roman_v end_POSTSUBSCRIPT  into the encoder  E E \\mathcal{E} caligraphic_E . Subsequently, we decode the latent vector using the decoder  D D \\mathcal{D} caligraphic_D  and perform inverse DFT (IDFT) to reconstruct the channel matrix. The following formula ( 10 ) explains the process, illustrated in Fig.  6 ."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Site-specific beamforming simulation parameters",
        "table": "S6.EGx2",
        "footnotes": [],
        "references": [
            "Architecture of Our Method: The cDDIM Model.  We refer to the cDDIM model as a U-net structure  [ 38 ] , designed to learn the denoising process using classifier guidance  [ 29 ] . The model takes the conditional input, UE position  x x \\mathbf{x} bold_x , and the inference step  t t t italic_t , iterating T times from  t = T t T t=T italic_t = italic_T  to  t = 1 t 1 t=1 italic_t = 1 . The conditional input  x x \\mathbf{x} bold_x  is embedded and elementwise multiplied with the concatenated vector, and the time step  t t t italic_t  is elementwise added after embedding. The model structure is shown in Fig.  2 , and the entire process is illustrated in Fig.  3 .",
            "Inference Process of the cDDIM Model.  Our goal is to generate  H v  p  ( H v | x ) similar-to subscript H v p conditional subscript H v x \\mathbf{H}_{\\mathrm{v}}\\sim p(\\mathbf{H}_{\\mathrm{v}}|\\mathbf{x}) bold_H start_POSTSUBSCRIPT roman_v end_POSTSUBSCRIPT  italic_p ( bold_H start_POSTSUBSCRIPT roman_v end_POSTSUBSCRIPT | bold_x )  for a given UE position  x x \\mathbf{x} bold_x  as input. The sampling process is described in detail in Algorithm  2 .",
            "Samples are generated from latent variables using a fixed procedure, without any stochastic noise involved in ( 8 ). Consequently, the model functions as an implicit probabilistic model. This process is repeated for all  N aug subscript N aug N_{\\text{aug}} italic_N start_POSTSUBSCRIPT aug end_POSTSUBSCRIPT  UE positions, as shown in lines 3 to 8 of Algorithm  2 . The final output of the model is an augmented dataset  { H ~ v , aug , i  [ 0 ] } i = 1 N aug superscript subscript subscript ~ H v aug i delimited-[] 0 i 1 subscript N aug \\{\\widetilde{\\mathbf{H}}_{\\mathrm{v,aug},i}[0]\\}_{i=1}^{N_{\\mathrm{aug}}} { over~ start_ARG bold_H end_ARG start_POSTSUBSCRIPT roman_v , roman_aug , italic_i end_POSTSUBSCRIPT [ 0 ] } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT roman_aug end_POSTSUBSCRIPT end_POSTSUPERSCRIPT , which we use for downstream wireless communication tasks.",
            "To address this, we introduce a low-complexity approach using consistency training  [ 32 ] . The term consistency here refers to the models ability to produce consistent outputs when generating the initial channel state  H v , train  [ 0 ] subscript H v train delimited-[] 0 \\mathbf{H}_{\\mathrm{v,train}}[0] bold_H start_POSTSUBSCRIPT roman_v , roman_train end_POSTSUBSCRIPT [ 0 ]  from different intermediate states  H v , train  [ t ] subscript H v train delimited-[] t \\mathbf{H}_{\\mathrm{v,train}}[t] bold_H start_POSTSUBSCRIPT roman_v , roman_train end_POSTSUBSCRIPT [ italic_t ]  along the  \\ac PF-ODE trajectory from ( 3 ). The key distinction of Algorithm  3  from Algorithm  2  is that while Algorithm  2  trains one noise estimator for each time step  t t t italic_t , Algorithm  3  focuses on minimizing the difference between the noise estimations at consecutive steps  t t t italic_t  and  t + 1 t 1 t+1 italic_t + 1 , ensuring the model to follow the PF-ODE trajectory consistently. As a result, the required number of steps  T T T italic_T  in consistency training can be smaller than in DDIM."
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "S3.E6",
        "footnotes": [],
        "references": [
            "Architecture of Our Method: The cDDIM Model.  We refer to the cDDIM model as a U-net structure  [ 38 ] , designed to learn the denoising process using classifier guidance  [ 29 ] . The model takes the conditional input, UE position  x x \\mathbf{x} bold_x , and the inference step  t t t italic_t , iterating T times from  t = T t T t=T italic_t = italic_T  to  t = 1 t 1 t=1 italic_t = 1 . The conditional input  x x \\mathbf{x} bold_x  is embedded and elementwise multiplied with the concatenated vector, and the time step  t t t italic_t  is elementwise added after embedding. The model structure is shown in Fig.  2 , and the entire process is illustrated in Fig.  3 .",
            "When sampling from the model, we need to perform a backward process. The backward process transforms arbitrary Gaussian noise into a clean image through a sequence of  T T T italic_T  denoising steps. Since we are trying to train the deterministic function between  x x \\mathbf{x} bold_x  and  H v  [ 0 ] subscript H v delimited-[] 0 \\mathbf{H}_{\\mathrm{v}}[0] bold_H start_POSTSUBSCRIPT roman_v end_POSTSUBSCRIPT [ 0 ] , we use  \\Ac DDIM  [ 30 ] , which follows a deterministic generation process. While the previous equation ( 3 ) utilized the score function, the current approach approximates this process using  S ~ ~ S \\widetilde{\\mathbf{S}} over~ start_ARG bold_S end_ARG  in the DDIM framework. The DDIM sampling equation is",
            "To address this, we introduce a low-complexity approach using consistency training  [ 32 ] . The term consistency here refers to the models ability to produce consistent outputs when generating the initial channel state  H v , train  [ 0 ] subscript H v train delimited-[] 0 \\mathbf{H}_{\\mathrm{v,train}}[0] bold_H start_POSTSUBSCRIPT roman_v , roman_train end_POSTSUBSCRIPT [ 0 ]  from different intermediate states  H v , train  [ t ] subscript H v train delimited-[] t \\mathbf{H}_{\\mathrm{v,train}}[t] bold_H start_POSTSUBSCRIPT roman_v , roman_train end_POSTSUBSCRIPT [ italic_t ]  along the  \\ac PF-ODE trajectory from ( 3 ). The key distinction of Algorithm  3  from Algorithm  2  is that while Algorithm  2  trains one noise estimator for each time step  t t t italic_t , Algorithm  3  focuses on minimizing the difference between the noise estimations at consecutive steps  t t t italic_t  and  t + 1 t 1 t+1 italic_t + 1 , ensuring the model to follow the PF-ODE trajectory consistently. As a result, the required number of steps  T T T italic_T  in consistency training can be smaller than in DDIM."
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "S4.T1.8",
        "footnotes": [],
        "references": [
            "We aim to learn    \\mathbf{\\Theta} bold_  that minimizes the loss function above in ( 4 ), but it cannot be directly calculated since the score function is unknown.",
            "Evaluate the performance : We evaluate the effectiveness of our method through both qualitative visualization and quantitative metrics. Specifically, we visualize the generated channels in Fig.  4  and compare peak index match probabilities in Fig.  5 .",
            "Observations from Generated Channel.  In our scenario, with a LOS path and using ULA antennas, the sparse beam domain of the channel typically shows one main cluster with a significantly higher magnitude value than any other point. We define this as the peak, specifically examining the peak BS side index. In Fig.  4 , we compare five random channel samples generated by cGAN, cDDIM, and the reference channels at the same position. The visualization highlights how each method predicts the peak BS index in the LOS path.",
            "Fig.  4  shows the visualization of five random samples in the test set. The right column displays the augmented channel  H v , aug , i , i = 1 , ... , 5 formulae-sequence subscript H v aug i i 1 ... 5 \\mathbf{H}_{\\mathrm{v,aug},i},\\quad i=1,\\ldots,5 bold_H start_POSTSUBSCRIPT roman_v , roman_aug , italic_i end_POSTSUBSCRIPT , italic_i = 1 , ... , 5 . We compare reference channels with channels created using cGAN and cDDIM, conditioned on UE coordinates  x aug , i , i = 1 , ... , 5 formulae-sequence subscript x aug i i 1 ... 5 \\mathbf{x}_{\\mathrm{aug},i},\\quad i=1,\\ldots,5 bold_x start_POSTSUBSCRIPT roman_aug , italic_i end_POSTSUBSCRIPT , italic_i = 1 , ... , 5 , demonstrating that only cDDIM predicts the correct BS index of the LOS path. cGAN produces channels that lack diversity and consistently place peaks at similar coordinates in the synthetic channels, even though the reference channels have peaks at different coordinates. However, when we examine the middle column, which shows the cDDIM-based generated channel, we observe that the BS index of the peak in the beamspace domain is always similar to that of the reference channel matrix. This suggests that cDDIM can make accurate estimates given the UE coordinates, resulting in a dataset with correct predictions."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "S5.T2.9",
        "footnotes": [],
        "references": [
            "Evaluate the performance : We evaluate the effectiveness of our method through both qualitative visualization and quantitative metrics. Specifically, we visualize the generated channels in Fig.  4  and compare peak index match probabilities in Fig.  5 .",
            "We compare the peak index difference  D D D italic_D  with channels generated by our method, cDDIM, and the baseline method, cGAN. Fig.  5  shows the CDF of  D D D italic_D , ranging from 0 to 9, for the cGAN and cDDIM methods when aligned against a reference dataset. The cDDIM method, shown as the dashed blue line with    markers consistently outperform the cGAN method, shown as a green line with  +  markers. Notably, even at  D = 0 D 0 D=0 italic_D = 0 , meaning the peak index exactly matches, the cDDIM method achieves a match probability above 0.6, in contrast to the cGAN methods 0.024, indicating superior accuracy in BS peak index localization. Random guessing has an accuracy of  1 / 32 = 0.031 1 32 0.031 1/32=0.031 1 / 32 = 0.031 , indicating that the cGAN method does not even perform better than random guessing in peak index localization.",
            "In this experiment, we also compared our method with the strategy of selecting the closest channel matrix by finding the nearest UE coordinate in the training dataset,  j close = arg  min j  x v , train , i  x v , train , j  subscript j close subscript arg min j norm subscript x v train i subscript x v train j {j_{\\text{close}}}=\\mathop{\\rm arg\\,min}_{j}\\|\\mathbf{x}_{\\mathrm{v,train},i}-% \\mathbf{x}_{\\mathrm{v,train},j}\\| italic_j start_POSTSUBSCRIPT close end_POSTSUBSCRIPT = start_BIGOP roman_arg roman_min end_BIGOP start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT  bold_x start_POSTSUBSCRIPT roman_v , roman_train , italic_i end_POSTSUBSCRIPT - bold_x start_POSTSUBSCRIPT roman_v , roman_train , italic_j end_POSTSUBSCRIPT  , and choosing the corresponding channel  H v , train , j close subscript H v train subscript j close \\mathbf{H}_{\\mathrm{v,train},{j_{\\text{close}}}} bold_H start_POSTSUBSCRIPT roman_v , roman_train , italic_j start_POSTSUBSCRIPT close end_POSTSUBSCRIPT end_POSTSUBSCRIPT . With 90,000 data samples uniformly distributed within a 100 m radius, it is densely packed, and the closest point is expected to be very near, causing the peak to not shift significantly from that closest  \\ac UE points channel. This approach is labeled as Closest in training set and is represented by the red solid line with  o  markers. Surprisingly, cDDIM even demonstrated slightly better accuracy than this approach in Fig.  5 . This result clearly shows that the model appropriately synthesizes the channel among multiple points in the dataset.",
            "In Fig.  5 , the consistency training is represented by the sky blue line with    and    markers and progressive distillation are represented by the pink line with  x  markers. Consistency training at  T = 32 T 32 T=32 italic_T = 32  shows 40% accuracy for the exact dominant beam index and 67% for being one index off. Additionally, training preserves an 80% probability that the peak index difference of the generated channel paths stays within 2, which is less than 11.25 degrees, which is just 10% less compared to cDDIM, even though it uses only 1/8 of the time steps."
        ]
    }
}