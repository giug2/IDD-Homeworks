{
    "id_table_1": {
        "caption": "TABLE I:  Label mapping scheme",
        "table": "S3.T2.1",
        "footnotes": [],
        "references": [
            "As an example, consider Figure  1 . It depicts different methods performances on a recently released fact-checking dataset AVeriTec  [ 2 ] . This dataset comprises four labels, besides the typical 3-class label (Support, Not Enougn Info (NEI), Refute), it includes a new one for Conflict (Conflicting Evidence). When performing zero-shot on the  T5-3B  (green bars), a model pre-trained with NLI datasets (fact verification is often considered similar to NLI) shows reasonable results on the Support and Refute classes but performs poorly on NEI, and completely fails on the new Conflict class. Self-rationalization fine-tuned on  T5-3B , depicted by the orange bars in Figure  1 , fails to learn the new class, resulting in low veracity prediction performance.",
            "In this context, we propose a label-adaptive self-rationalization approach to tackle the challenge of the labeling shift for fact verification/checking. We first fine-tune a pre-trained model to learn the classification task with different labels; then, we fine-tune it again with labels and explanations to learn the self-rationalization task (explanations). Our results show that the 2-step formulation significantly outperforms direct self-rationalization learning by more than 20 percentage points (on the AVeriTec dataset) (Figure  1 ). This approach also achieves the best results compared to state-of-the-art methods.",
            "Provided with labels and explanations, directly fine-tuning for self-rationalization fails on newly added labels (as shown in Figure  1 ), thus we take a step-by-step approach to slowly adapt the model for the new domain and class. Our method is based on  T5-3B  model, as its size is comparable to many open large language models, and self-rationalization has been shown to perform well on T5 models  [ 6 ,  14 ,  5 ] ."
        ]
    }
}