{
    "PAPER'S NUMBER OF TABLES": 3,
    "S4.T1": {
        "caption": "Table 1: Accuracy for Color Skewed Distribution for 18 communication rounds under different levels of skew for 2 collaborators. D&C (using FedAvg) delivers high classification accuracy under this non-iidness",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">#Col</span></th>\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Skew</span></th>\n<th id=\"S4.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FedAvg</span></th>\n<th id=\"S4.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FedProx</span></th>\n<th id=\"S4.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FedMA</span></th>\n<th id=\"S4.T1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">D&amp;C</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S4.T1.1.2.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">2</span></th>\n<td id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.2.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">95-5%</span></td>\n<td id=\"S4.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.2.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">53.1%</span></td>\n<td id=\"S4.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.2.1.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">56.2%</span></td>\n<td id=\"S4.T1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.2.1.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">81.0%</span></td>\n<td id=\"S4.T1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.2.1.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">80.1%</span></td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T1.1.3.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">2</span></th>\n<td id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.3.2.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">75-25%</span></td>\n<td id=\"S4.T1.1.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.3.2.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">52.8%</span></td>\n<td id=\"S4.T1.1.3.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.3.2.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">74.6%</span></td>\n<td id=\"S4.T1.1.3.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.3.2.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">78.8%</span></td>\n<td id=\"S4.T1.1.3.2.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.3.2.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">79.2%</span></td>\n</tr>\n<tr id=\"S4.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S4.T1.1.4.3.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">2</span></th>\n<td id=\"S4.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.4.3.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">50-50%</span></td>\n<td id=\"S4.T1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.4.3.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">49.1%</span></td>\n<td id=\"S4.T1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.4.3.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">67.2%</span></td>\n<td id=\"S4.T1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.4.3.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">79.9%</span></td>\n<td id=\"S4.T1.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.4.3.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">81.8%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Training accuracy and convergence profile for different aggregation algorithms using Color Skewed 95-5% CIFAR10 data are shown in Figure 8. It can be seen that for this category of non-IIDness, the model reaches high accuracy with much smaller communication rounds compared to FedAvg. Divide5 was used for this analysis as described in the earlier section along with the same values for Epsubscriptùê∏ùëùE_{p} and Œ∑ùúÇ\\eta. Results for additional levels of Color Skew is presented in Table 1. We chose 18 rounds of communication for the comparison to align with FedMA."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Accuracy for Class-Imbalanced Distribution for 18 communication rounds using 5 & 10 collaborators. Accuracy from D&C (using FedAvg) is inline with other algorithms.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">#Col</span></th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FedAvg</span></th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FedProx</span></th>\n<th id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FedMA</span></th>\n<th id=\"S4.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.1.1.1.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">D&amp;C</span></th>\n<th id=\"S4.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.1.1.1.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">D&amp;C‚Äô</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S4.T2.1.2.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">5</span></th>\n<td id=\"S4.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.2.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">88.5%</span></td>\n<td id=\"S4.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.2.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">87.5%</span></td>\n<td id=\"S4.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.2.1.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">87.5%</span></td>\n<td id=\"S4.T2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.2.1.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">87.1%</span></td>\n<td id=\"S4.T2.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.2.1.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">89.3%</span></td>\n</tr>\n<tr id=\"S4.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S4.T2.1.3.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">10</span></th>\n<td id=\"S4.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.3.2.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">83.5%</span></td>\n<td id=\"S4.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.3.2.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">80.0%</span></td>\n<td id=\"S4.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.3.2.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">82.5%</span></td>\n<td id=\"S4.T2.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.3.2.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">76.8%</span></td>\n<td id=\"S4.T2.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.3.2.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">82.2%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "For Class Imbalanced data, the observed weight divergence from the pre-pass run was high for most layers. This indicates that ",
                "Divide-and-Conquer",
                " does not offer any advantages over FedAvg. As an experiment, we divided the topology at layer8 similar to traditional ",
                "fine-tuning",
                ". ",
                "Divide-and-Conquer",
                " yields slightly lower accuracy compared to FedAvg and FedMA as documented in table [",
                "2",
                "]. However, if bandwidth saving is not considered as a requirement and ",
                "Divide-and-Conquer",
                " is run for additional rounds to get a similar amount of model transfer as FedAvg, the performance of ",
                "Divide-and-Conquer",
                " is marginally better. This is captured in the table under the column ",
                "D&C‚Äô",
                ". Though FedMA achieves its accuracy levels using much lower communication bandwidth, compute overhead for layer matching increases with model depth as well as width, as discussed earlier, making it less desirable for practical deployments.",
                "Given the results, it is clear that in cases where weight divergence suggests no clear split layer, it is recommended not to adopt ",
                "Divide-and-Conquer",
                ". As collaborator count increases, training data per collaborator decreases in the simulation environment, as the data is divided across the collaborators. This could also lead to increased divergence when ",
                "feature-learning",
                " is done aggressively on sparse data. In a truly federated set up with a large training corpus across collaborators, we expect our methodology to offer better accuracy improvements.",
                "An extreme case of Class Imbalance based heterogeneity is when each collaborator exclusively holds data from one unique class. All the tested algorithms performed poorly (accuracy less than 15%) under this scenario, suggesting a need for more research in this area."
            ]
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Accuracy for next-character prediction lstm model for 9 communication rounds using 66 collaborators. Accuracy from D&C (using FedAvg) is inline with other algorithms",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">#Col</span></th>\n<th id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FedAvg</span></th>\n<th id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FedProx</span></th>\n<th id=\"S4.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.1.1.1.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FedMA</span></th>\n<th id=\"S4.T3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.1.1.1.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">D&amp;C</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\"><span id=\"S4.T3.1.2.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">66</span></th>\n<td id=\"S4.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.1.2.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">50.8%</span></td>\n<td id=\"S4.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.1.2.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">44.6%</span></td>\n<td id=\"S4.T3.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.1.2.1.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">47.4%</span></td>\n<td id=\"S4.T3.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.1.2.1.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">49.6%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Results from application of Divide-and-Conquer to a character prediction model is shown in table 3. At end of 9 communication rounds, the accuracy from Divide-and-Conquer is comparable to other algorithms while only requiring half the amount of data transfer as FedAvg. 9 rounds of communication was chosen to align with FedMA."
        ]
    }
}