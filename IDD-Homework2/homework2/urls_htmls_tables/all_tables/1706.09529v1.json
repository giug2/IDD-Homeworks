{
    "S4.T1": {
        "caption": "Table 1: Final-testing performance for different regression meta learning strategies (MSE).",
        "table": null,
        "footnotes": [],
        "references": [
            "For meta-testing each task has only a few-shots K∈{4,6,8}𝐾468K\\in\\{4,6,8\\} pairs of (x,y)𝑥𝑦(x,y) for training. We generate 100100100 new testing tasks in total, and for each generate 100100100 testing samples on which to evaluate the final-testing MSE. We repeat every adapting round (corresponding to a task) 101010 times with different (x,y)𝑥𝑦(x,y) pairs, so one testing task has 101010 MSE values on the same out-of-sample set. The mean and standard deviation of all tasks’ MSEs are summarised in Table 1. For our method we also explore semi-supervised learning using unlabelled x𝑥x. In real-world problems these would correspond to unlabelled instances, but for this synthetic problem, we simply uniformly sample x∼[−5,5]similar-to𝑥55x\\sim\\left[-5,5\\right]. We can see that our meta-critic performs comparably or better than alternatives. Here we also evaluate Meta-Critic-SL: our method where the meta-testing actor is pre-trained with standard supervised learning before training by the meta-critic. The similar performance of these two variants shows that via the shared meta-critic, a good performing actor can be obtained by learning from scratch, without requiring any pre-training.",
            "For qualitative illustration, we randomly pick tasks for K=4𝐾4K=4 shot learning from sinusoid only condition and line+sinusoid mixture condition, as shown in Fig. 2. We see that all models fit the K=4𝐾4K=4 shot meta-testing data. In the sin-only condition (Fig. 2(a)) MAML is not much worse than meta-critic in the out-of-sample areas. However, in the mixture condition (Fig. 2(b)), MAML is much worse than meta-critic. The reason is that a single globally shared prior/initialisation parameter implicitly assumes that tasks are similar, and their distribution is uni-modal. In the mixture case where tasks are diversely distributed and with varying relatedness, then this assumption is too strong and performance is poor. We increased the number of parameters for the actor network in MAML so that there was ample capacity for learning a complex multi-modal model, but it didn’t help. In contrast, our meta-critic approach is flexible enough to model this multi-modal task-distribution and learns to supervise the actor appropriately. These qualitative results are reflected quantitatively in Table 1, where we see that MAML and Meta-Critic perform comparably – and better than Standard/All-Fine-Tune – in the Sin only condition, but Meta-Critic is clearly better in the mixture condition. This is because the TAEN successfully learns to embed task category information in its task description z𝑧z. Taking the z𝑧zs for all the tasks in the mixture condition, we find that a simple classifier (SVM with RBF kernel) can obtain 85%percent8585\\% accuracy in predicting the task category (linear vs sinusoid)."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Different meta-learning strategies for dependent multi-arm bandit. Reward in final-testing.",
        "table": null,
        "footnotes": [],
        "references": [
            "The results are shown in Table 2, quantified by average reward which is calculated by the dot product of its softmax output and the bandit’s configuration (probability of getting a reward by pulling each arm). The Upper bound is calculated by always pulling the arm with largest probability of getting reward, which is 0.750.750.75 for 2-arm, 0.520.520.52 for 4-arm, and 0.410.410.41 for 6-arm. The random choice lower bound is always equal to 1Num. of Arms1Num. of Arms\\frac{1}{\\text{Num. of Arms}}. Our meta-critic strategy achieves higher reward than competitors for any given number of trials."
        ]
    }
}