{
    "PAPER'S NUMBER OF TABLES": 5,
    "S3.T1": {
        "caption": "Table 1. Computation and communication cost of inserting adapters into each transformer block (width=32) and full-model tuning on Jetson TX2.",
        "table": "<table id=\"S3.T1.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.4.5.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S3.T1.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Model</span></th>\n<th id=\"S3.T1.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S3.T1.4.5.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Method</span></th>\n<th id=\"S3.T1.4.5.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\">\n<table id=\"S3.T1.4.5.1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.4.5.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.4.5.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.4.5.1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Training Time</span></td>\n</tr>\n</table>\n</th>\n<th id=\"S3.T1.4.5.1.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\">\n<table id=\"S3.T1.4.5.1.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.4.5.1.4.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.4.5.1.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.4.5.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Updated Paras.</span></td>\n</tr>\n</table>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S3.T1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">BERT</span></th>\n<th id=\"S3.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">Full Fine-tuning</span></th>\n<td id=\"S3.T1.1.1.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">1.86 sec</span></td>\n<td id=\"S3.T1.1.1.1\" class=\"ltx_td ltx_align_right ltx_border_t\">\n<span id=\"S3.T1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">110.01 x </span><math id=\"S3.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"10^{6}\" display=\"inline\"><semantics id=\"S3.T1.1.1.1.m1.1a\"><msup id=\"S3.T1.1.1.1.m1.1.1\" xref=\"S3.T1.1.1.1.m1.1.1.cmml\"><mn mathsize=\"80%\" id=\"S3.T1.1.1.1.m1.1.1.2\" xref=\"S3.T1.1.1.1.m1.1.1.2.cmml\">10</mn><mn mathsize=\"80%\" id=\"S3.T1.1.1.1.m1.1.1.3\" xref=\"S3.T1.1.1.1.m1.1.1.3.cmml\">6</mn></msup><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.1.1.1.m1.1b\"><apply id=\"S3.T1.1.1.1.m1.1.1.cmml\" xref=\"S3.T1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.T1.1.1.1.m1.1.1.1.cmml\" xref=\"S3.T1.1.1.1.m1.1.1\">superscript</csymbol><cn type=\"integer\" id=\"S3.T1.1.1.1.m1.1.1.2.cmml\" xref=\"S3.T1.1.1.1.m1.1.1.2\">10</cn><cn type=\"integer\" id=\"S3.T1.1.1.1.m1.1.1.3.cmml\" xref=\"S3.T1.1.1.1.m1.1.1.3\">6</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.1.1.1.m1.1c\">10^{6}</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S3.T1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S3.T1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Adapter</span></th>\n<td id=\"S3.T1.2.2.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">1.14 sec</span></td>\n<td id=\"S3.T1.2.2.1\" class=\"ltx_td ltx_align_right ltx_border_t\">\n<span id=\"S3.T1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.61 x </span><math id=\"S3.T1.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"10^{6}\" display=\"inline\"><semantics id=\"S3.T1.2.2.1.m1.1a\"><msup id=\"S3.T1.2.2.1.m1.1.1\" xref=\"S3.T1.2.2.1.m1.1.1.cmml\"><mn mathsize=\"80%\" id=\"S3.T1.2.2.1.m1.1.1.2\" xref=\"S3.T1.2.2.1.m1.1.1.2.cmml\">10</mn><mn mathsize=\"80%\" id=\"S3.T1.2.2.1.m1.1.1.3\" xref=\"S3.T1.2.2.1.m1.1.1.3.cmml\">6</mn></msup><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.2.2.1.m1.1b\"><apply id=\"S3.T1.2.2.1.m1.1.1.cmml\" xref=\"S3.T1.2.2.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.T1.2.2.1.m1.1.1.1.cmml\" xref=\"S3.T1.2.2.1.m1.1.1\">superscript</csymbol><cn type=\"integer\" id=\"S3.T1.2.2.1.m1.1.1.2.cmml\" xref=\"S3.T1.2.2.1.m1.1.1.2\">10</cn><cn type=\"integer\" id=\"S3.T1.2.2.1.m1.1.1.3.cmml\" xref=\"S3.T1.2.2.1.m1.1.1.3\">6</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.2.2.1.m1.1c\">10^{6}</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S3.T1.3.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S3.T1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">DistilBERT</span></th>\n<th id=\"S3.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S3.T1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">Full Fine-tuning</span></th>\n<td id=\"S3.T1.3.3.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.91 sec</span></td>\n<td id=\"S3.T1.3.3.1\" class=\"ltx_td ltx_align_right ltx_border_t\">\n<span id=\"S3.T1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">67 x </span><math id=\"S3.T1.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"10^{6}\" display=\"inline\"><semantics id=\"S3.T1.3.3.1.m1.1a\"><msup id=\"S3.T1.3.3.1.m1.1.1\" xref=\"S3.T1.3.3.1.m1.1.1.cmml\"><mn mathsize=\"80%\" id=\"S3.T1.3.3.1.m1.1.1.2\" xref=\"S3.T1.3.3.1.m1.1.1.2.cmml\">10</mn><mn mathsize=\"80%\" id=\"S3.T1.3.3.1.m1.1.1.3\" xref=\"S3.T1.3.3.1.m1.1.1.3.cmml\">6</mn></msup><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.3.3.1.m1.1b\"><apply id=\"S3.T1.3.3.1.m1.1.1.cmml\" xref=\"S3.T1.3.3.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.T1.3.3.1.m1.1.1.1.cmml\" xref=\"S3.T1.3.3.1.m1.1.1\">superscript</csymbol><cn type=\"integer\" id=\"S3.T1.3.3.1.m1.1.1.2.cmml\" xref=\"S3.T1.3.3.1.m1.1.1.2\">10</cn><cn type=\"integer\" id=\"S3.T1.3.3.1.m1.1.1.3.cmml\" xref=\"S3.T1.3.3.1.m1.1.1.3\">6</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.3.3.1.m1.1c\">10^{6}</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S3.T1.4.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Adapter</span></th>\n<td id=\"S3.T1.4.4.3\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.56 sec</span></td>\n<td id=\"S3.T1.4.4.1\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_t\">\n<span id=\"S3.T1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.32 x </span><math id=\"S3.T1.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"10^{6}\" display=\"inline\"><semantics id=\"S3.T1.4.4.1.m1.1a\"><msup id=\"S3.T1.4.4.1.m1.1.1\" xref=\"S3.T1.4.4.1.m1.1.1.cmml\"><mn mathsize=\"80%\" id=\"S3.T1.4.4.1.m1.1.1.2\" xref=\"S3.T1.4.4.1.m1.1.1.2.cmml\">10</mn><mn mathsize=\"80%\" id=\"S3.T1.4.4.1.m1.1.1.3\" xref=\"S3.T1.4.4.1.m1.1.1.3.cmml\">6</mn></msup><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.4.4.1.m1.1b\"><apply id=\"S3.T1.4.4.1.m1.1.1.cmml\" xref=\"S3.T1.4.4.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.T1.4.4.1.m1.1.1.1.cmml\" xref=\"S3.T1.4.4.1.m1.1.1\">superscript</csymbol><cn type=\"integer\" id=\"S3.T1.4.4.1.m1.1.1.2.cmml\" xref=\"S3.T1.4.4.1.m1.1.1.2\">10</cn><cn type=\"integer\" id=\"S3.T1.4.4.1.m1.1.1.3.cmml\" xref=\"S3.T1.4.4.1.m1.1.1.3\">6</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.4.4.1.m1.1c\">10^{6}</annotation></semantics></math>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Network cost analysis\nThe trainable parameter number per adapter is 2​m​n+n+m2𝑚𝑛𝑛𝑚2mn+n+m.\nClients only send those parameters and last-layer classifier parameters after on-device training to the aggregator.\nTherefore the network transmission per round is reduced to\nD×(2​m​n+n+m)+n×#​l​a​b​e​l​s𝐷2𝑚𝑛𝑛𝑚𝑛#𝑙𝑎𝑏𝑒𝑙𝑠D\\times(2mn+n+m)+n\\times\\#labels,\nwhere D𝐷D is the total number of transformer blocks of the NLP model.\nAs shown in Table 1,\ncompared to fine-tuning the whole BERT model, the network saving could be more than 99%.",
            "Compute cost analysis\nThe computation FLOPs of each adapter in forward pass is 2×m×n×s​e​q​l​e​n2𝑚𝑛𝑠𝑒𝑞𝑙𝑒𝑛2\\times m\\times n\\times seqlen (normalized to single data sample), where s​e​q​l​e​n𝑠𝑒𝑞𝑙𝑒𝑛seqlen is the sequence length (default 256 in BERT).\nThis incurred overhead is trivial compared to the original model complexity, e.g., less than 1% on BERT.\nOn the other hand, since all other parameters are fixed during training, calculating the gradients of those fixed weights can be avoided in backward propagation. Table 1 shows adapter brings around 40% training time reduction."
        ]
    },
    "S3.T2": {
        "caption": "Table 2. The optimal adapter configuration (i.e., best time-to-accuracy) for different target accuracy (ratio to the full convergence) and different datasets.\n",
        "table": "<table id=\"S3.T2.2\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.2.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">\n<span id=\"S3.T2.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">\n</span><span id=\"S3.T2.2.1.1.1.2\" class=\"ltx_text\" style=\"font-size:80%;\">Model</span>\n</td>\n<td id=\"S3.T2.2.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S3.T2.2.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Datasets</span></td>\n<td id=\"S3.T2.2.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"5\">\n<span id=\"S3.T2.2.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T2.2.1.1.3.1.1\" class=\"ltx_p\"><span id=\"S3.T2.2.1.1.3.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Optimal adapter configuration </span><span id=\"S3.T2.2.1.1.3.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">(depth, width)</span><span id=\"S3.T2.2.1.1.3.1.1.3\" class=\"ltx_text\" style=\"font-size:80%;\"></span></span>\n<span id=\"S3.T2.2.1.1.3.1.2\" class=\"ltx_p ltx_align_left\"><span id=\"S3.T2.2.1.1.3.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">towards different target accuracy</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T2.2.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.2.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_r\" rowspan=\"4\"><span id=\"S3.T2.2.2.2.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">BERT</span></td>\n<td id=\"S3.T2.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">99%</span></td>\n<td id=\"S3.T2.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.2.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">95%</span></td>\n<td id=\"S3.T2.2.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.2.2.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">90%</span></td>\n<td id=\"S3.T2.2.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.2.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">80%</span></td>\n<td id=\"S3.T2.2.2.2.6\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T2.2.2.2.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">70%</span></td>\n</tr>\n<tr id=\"S3.T2.2.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.2.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.3.3.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">20news</span></td>\n<td id=\"S3.T2.2.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.3.3.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">(2,64)</span></td>\n<td id=\"S3.T2.2.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.3.3.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(2,32)</span></td>\n<td id=\"S3.T2.2.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.3.3.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">(2,8)</span></td>\n<td id=\"S3.T2.2.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.3.3.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">(2,8)</span></td>\n<td id=\"S3.T2.2.3.3.6\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T2.2.3.3.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">(2,8)</span></td>\n</tr>\n<tr id=\"S3.T2.2.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.2.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.4.4.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">agnews</span></td>\n<td id=\"S3.T2.2.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.4.4.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">(3,16)</span></td>\n<td id=\"S3.T2.2.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.4.4.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(2,16)</span></td>\n<td id=\"S3.T2.2.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.4.4.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">(2,8)</span></td>\n<td id=\"S3.T2.2.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.4.4.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">(0,8)</span></td>\n<td id=\"S3.T2.2.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T2.2.4.4.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">(0,8)</span></td>\n</tr>\n<tr id=\"S3.T2.2.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.2.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.5.5.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">semeval</span></td>\n<td id=\"S3.T2.2.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.5.5.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">(10,8)</span></td>\n<td id=\"S3.T2.2.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.5.5.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(6,8)</span></td>\n<td id=\"S3.T2.2.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.5.5.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">(6,8)</span></td>\n<td id=\"S3.T2.2.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.5.5.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">(2,8)</span></td>\n<td id=\"S3.T2.2.5.5.6\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T2.2.5.5.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">(2,8)</span></td>\n</tr>\n<tr id=\"S3.T2.2.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T2.2.6.6.1\" class=\"ltx_td ltx_border_b ltx_border_r\"></td>\n<td id=\"S3.T2.2.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.6.6.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">ontonotes</span></td>\n<td id=\"S3.T2.2.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.6.6.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(12, 32)</span></td>\n<td id=\"S3.T2.2.6.6.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.6.6.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">(12, 32)</span></td>\n<td id=\"S3.T2.2.6.6.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.6.6.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">(10, 32)</span></td>\n<td id=\"S3.T2.2.6.6.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T2.2.6.6.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">(0, 16)</span></td>\n<td id=\"S3.T2.2.6.6.7\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\"><span id=\"S3.T2.2.6.6.7.1\" class=\"ltx_text\" style=\"font-size:80%;\">(0, 16)</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Such upgrading mechanism is inspired by curriculum learning (bengio2009curriculum, ), a learning strategy that trains a model beginning from easier data samples to harder ones.\nInstead of altering the training samples, we propose to alter the model structure.\nIn the beginning, a simpler adapter configuration can learn fast.\nThis is because, by focusing on fewer compact trainable parameters closer to the model output, the model can rapidly learn the coarse-grained domain-specific knowledge for the downstream tasks, such as new class labels (ro2021autolr, ).\nFor simple downstream tasks, fine-tuning without re-learning deep features is enough to obtain satisfactory model accuracy, e.g., depth 2 and width 64 for 20NEWS dataset (lang1995newsweeder, ).\nAs the training proceeds, the model encounters a “choke point” where the learning curve becomes gentle.\nIt demands deeper or wider adapters to learn new features.\nThe experiment results in Table 2 attests to our claim that a higher target accuracy favors deeper and wider adapters."
        ]
    },
    "S5.T3": {
        "caption": "Table 3. Development boards used in experiments.",
        "table": "<table id=\"S5.T3.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.2.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T3.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Device</span></th>\n<th id=\"S5.T3.2.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"width:113.8pt;\">\n<span id=\"S5.T3.2.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.2.1.1.2.1.1\" class=\"ltx_p\"><span id=\"S5.T3.2.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Processor</span></span>\n</span>\n</th>\n<th id=\"S5.T3.2.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t\" style=\"width:42.7pt;\">\n<span id=\"S5.T3.2.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.2.1.1.3.1.1\" class=\"ltx_p\"><span id=\"S5.T3.2.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Per-batch Latency (s)</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.2.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">\n<span id=\"S5.T3.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Jetson TX2 </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span id=\"S5.T3.2.2.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">(</span><a href=\"#bib.bib1\" title=\"\" class=\"ltx_ref\">tx2<span id=\"S5.T3.2.2.1.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">, </span></a><span id=\"S5.T3.2.2.1.1.4.3\" class=\"ltx_text\" style=\"font-size:80%;\">)</span></cite>\n</th>\n<td id=\"S5.T3.2.2.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t\" style=\"width:113.8pt;\">\n<span id=\"S5.T3.2.2.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.2.2.1.2.1.1\" class=\"ltx_p\"><span id=\"S5.T3.2.2.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">256-core NVIDIA Pascal™ GPU.</span></span>\n</span>\n</td>\n<td id=\"S5.T3.2.2.1.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:42.7pt;\">\n<span id=\"S5.T3.2.2.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.2.2.1.3.1.1\" class=\"ltx_p\"><span id=\"S5.T3.2.2.1.3.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.88</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T3.2.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">\n<span id=\"S5.T3.2.3.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Jetson Nano </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span id=\"S5.T3.2.3.2.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">(</span><a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\">nano<span id=\"S5.T3.2.3.2.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">, </span></a><span id=\"S5.T3.2.3.2.1.4.3\" class=\"ltx_text\" style=\"font-size:80%;\">)</span></cite>\n</th>\n<td id=\"S5.T3.2.3.2.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t\" style=\"width:113.8pt;\">\n<span id=\"S5.T3.2.3.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.2.3.2.2.1.1\" class=\"ltx_p\"><span id=\"S5.T3.2.3.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">128-core NVIDIA CUDA® GPU.</span></span>\n</span>\n</td>\n<td id=\"S5.T3.2.3.2.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:42.7pt;\">\n<span id=\"S5.T3.2.3.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.2.3.2.3.1.1\" class=\"ltx_p\"><span id=\"S5.T3.2.3.2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">1.89</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T3.2.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\">\n<span id=\"S5.T3.2.4.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">RPI 4B </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span id=\"S5.T3.2.4.3.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">(</span><a href=\"#bib.bib3\" title=\"\" class=\"ltx_ref\">rpi4b<span id=\"S5.T3.2.4.3.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">, </span></a><span id=\"S5.T3.2.4.3.1.4.3\" class=\"ltx_text\" style=\"font-size:80%;\">)</span></cite>\n</th>\n<td id=\"S5.T3.2.4.3.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t\" style=\"width:113.8pt;\">\n<span id=\"S5.T3.2.4.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.2.4.3.2.1.1\" class=\"ltx_p\"><span id=\"S5.T3.2.4.3.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Broadcom BCM2711B0 quad-core A72 64-bit @ 1.5GHz CPU.</span></span>\n</span>\n</td>\n<td id=\"S5.T3.2.4.3.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_t\" style=\"width:42.7pt;\">\n<span id=\"S5.T3.2.4.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.2.4.3.3.1.1\" class=\"ltx_p\"><span id=\"S5.T3.2.4.3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">18.27</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We have fully implemented the ",
                "FedAdapter",
                " prototype atop ",
                "FedNLP",
                " ",
                "(",
                "lin2021fednlp, ",
                ")",
                " (the SOTA framework to evaluate FL methods on NLP tasks) and ",
                "Adapterhub",
                " ",
                "(",
                "pfeiffer2020adapterhub, ",
                ")",
                " (a library that facilitates the integration of pre-trained adapters for different tasks).\nAs prior work ",
                "(",
                "bonawitz2019towards, ",
                ")",
                ", we adopt the parameter server (PS) architecture among the clients and central server.\nAt the server side, once job is submitted by the developer, the server initializes the pluggable meta adapter to be trained (through the API of ",
                "Adapterhub",
                ") into the pre-trained model.\nThe server also splits the initialized meta adapter into three branches: normal, wider and deeper.\nThe wider branch will stack a few meta adapters parallel to expand the bottleneck size of adapter in single layer.\nThe deeper branch will insert the meta adapter into one more deeper layer.\nA client selector will sample 3N clients from available devices and shuffle them into 3 groups.\nWe now employ a random client selector (default in most FL literature) but more advanced selection strategies ",
                "(",
                "li2021hermes, ",
                "; ",
                "lipyramidfl, ",
                "; ",
                "nishio2019client, ",
                "; ",
                "xu2020client, ",
                "; ",
                "wang2021device, ",
                "; ",
                "lai2020oort, ",
                "; ",
                "zhao2021quality, ",
                "; ",
                "li2021sample, ",
                ")",
                " can be plugged into our implementation as well.\nThen, the server sends three branches of adapters to three groups separately via MPI (in standalone mode) or WLAN/Cellular (in distributed mode).\nOnce receiving the adapters, the clients insert the adapter into their local pre-trained model.\nThey fine-tune the model with their own private data.\nThe trained adapters will be collected in the central server and aggregated through ",
                "FedAvg",
                " algorithm ",
                "(",
                "mcmahan2017communication, ",
                ")",
                ".\nAll clients run in synchronized mode ",
                "(",
                "ho2013more, ",
                ")",
                ".",
                "Metrics",
                "\nWe mainly report the time-to-accuracy metric.\nWe divide the dataset of each device for training (80%) and testing (20%).\nFor clarity, we pay attention to a few typical accuracy targets, e.g., 99%, 95%, 90% of the full convergence accuracy achievable by the baseline that fine-tunes the whole model.\nWe refer to those accuracy numbers as ",
                "relative target accuracy",
                ".\nFor example, the 100% relative target accuracy of BERT is 0.8 (accuracy) for ",
                "20NEWS",
                "; 0.9 (accuracy) for ",
                "AGNews",
                "; 0.8 (accuracy) for ",
                "SEMEVAL",
                "; and 0.75 (token-F1) for ",
                "ONTONOTES",
                ".\nWe also report the resource cost in an FL process, including the total energy consumption on data transmitting and training computation on each client; the total amount of network traffic; and the peak memory usage.",
                "Hardware",
                "\nAs prior FL literature ",
                "(",
                "lin2021fednlp, ",
                "; ",
                "li2021hermes, ",
                "; ",
                "lipyramidfl, ",
                "; ",
                "lai2020oort, ",
                "; ",
                "shin2022fedbalancer, ",
                ")",
                ", our experiments are carried out in an emulation manner on a GPU server with 8x NVIDIA A40.\nThe on-device training time is obtained on 3 development boards with similar hardware capacity to mainstream mobile devices, i.e., Jetson TX2 ",
                "(",
                "tx2, ",
                ")",
                ", Jetson Nano ",
                "(",
                "nano, ",
                ")",
                ", and Raspberry Pi 4B ",
                "(",
                "rpi4b, ",
                ")",
                ".\nThe numbers are then plugged into the emulation framework to calculate the elapsed time.\nThe default network bandwidth between clients and server is set to 1MB/s, a typical setting for mobile and IoT devices ",
                "(",
                "wifi-state, ",
                "; ",
                "han2016mp, ",
                ")",
                ".\nNote that while home/office WiFi downlink could be faster, the uplink bandwidth is often bound by the\nbroadband backbone ",
                "(",
                "huang2013lte, ",
                ")",
                ".\nIn ",
                "§",
                "§",
                "\\S",
                "6.1",
                ", we will also quantify the performance of ",
                "FedAdapter",
                " under various hardware and bandwidth settings (100KB/s–10MB/s).",
                "Models",
                "\nWe use two representative models for FedNLP tasks: BERT ",
                "(",
                "devlin2018bert, ",
                ")",
                " (default) and its varient DistilBERT ",
                "(",
                "sanh2019distilbert, ",
                ")",
                ".\nBERT and DistilBERT are composed of 12 and 6 transformer blocks, respectively.\nDistilBERT leverages knowledge distillation during the pre-training phase and reduces the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster.\nWe use BERT for most of our experiments, as all BERT-based variants derive from it.\nThe pre-trained weights of both models are downloaded directly from Hugging Face ",
                "(",
                "wolf2019huggingface, ",
                ")",
                ".",
                "Tasks and datasets",
                "\nWe evaluate ",
                "FedAdapter",
                " on 4 classic NLP downstream datasets as shown in Table ",
                "4",
                ".\nWe follow the approach in ",
                "(",
                "lin2021fednlp, ",
                ")",
                " to build the non-IID datasets.\n(1) ",
                "20NEWS",
                " (IID) ",
                "(",
                "lang1995newsweeder, ",
                ")",
                " dataset is a collection of approximately 20,000 newsgroup documents.\n(2) ",
                "AGNEWS",
                " (non-IID) ",
                "(",
                "zhang2015character, ",
                ")",
                " is a collection of 127.6K news articles gathered from more than 2,000 news sources.\n(3) ",
                "SEMEVAL",
                " (non-IID) ",
                "(",
                "hendrickx2019semeval, ",
                ")",
                " is a relation classification datasets which assigns predefined relation labels to the entity pairs that occur in texts.\nThe above 3 datasets are used for text classification (TC) ",
                "(",
                "sun2019fine, ",
                ")",
                " tasks, where the output is a label in a fixed set of label set (e.g., political, sports, and entertainment).\n(4) ",
                "ONTONOTES",
                " (non-IID) ",
                "(",
                "pradhan2013towards, ",
                ")",
                " is a corpus where sentences have annotations for the entity spans and types.\nThis dataset is for sequence tagging (ST) ",
                "(",
                "aras2021evaluation, ",
                ")",
                " task, where the output is a sequence of tags.",
                "Baselines",
                "\nWe compare ",
                "FedAdapter",
                " to the following alternatives.\n(1) ",
                "Vanilla Fine-Tuning",
                " (FT) always fine-tunes the whole model on each client.\nThis is the default fine-tuning methodology used in most NLP literature ",
                "(",
                "devlin2018bert, ",
                "; ",
                "sanh2019distilbert, ",
                ")",
                ".\n(2) ",
                "Fine",
                "-",
                "Tuning",
                "-",
                "Quantized",
                " (FTQ) quantizes the model parameters from FP32 to lower precision to reduce the network traffic between clients and aggregator.\nQuantization is one of the most widely adopted approaches to reduce the communication cost and speedup FL process.\nWe use a state-of-the-art quantization algorithm ",
                "(",
                "wu2018error, ",
                ")",
                " in our FedNLP tasks.\nAccording to the algorithm, we observe the NLP models are quantized to INT4 or INT8 adaptively.\n(3) ",
                "LayerFreeze-Oracle",
                " (",
                "LF",
                "oracle",
                ") freezes a few transformer layers at bottom and only fine-tunes the ones above.\nThis is widely used to reduce the fine-tuning cost ",
                "(",
                "guo2019spottune, ",
                "; ",
                "lin2021fednlp, ",
                ")",
                ".\nThe number of freezed layers is selected per task to achieve the best time-to-accuracy at 99% relative accuracy target.\n(4) ",
                "LayerFreeze",
                "-",
                "Quantized",
                "-",
                "Oracle",
                " (",
                "LFQ",
                "oracle",
                ") combines the above quantization and freezing techniques and selects the best setting for each task, i.e., the number of freezed layers and the quantized data precision.\nTo be noted, ",
                "LF",
                "oracle",
                " and ",
                "LFQ",
                "oracle",
                " are impractical in reality as they require prior knowledge to obtain an oracle system parameter.\nFor a fair comparison, all baselines use the same model aggregation algorithm (",
                "FedAvg",
                " ",
                "(",
                "mcmahan2017communication, ",
                ")",
                ") and client sampling (random), which are also the default setting in prior FL literature ",
                "(",
                "lin2021fednlp, ",
                ")",
                ".",
                "Hyper-parameters",
                "\nUnless otherwise stated, ",
                "FedAdapter",
                " and all baselines use the same set of hyper-parameters as ",
                "FedNLP",
                " ",
                "(",
                "lin2021fednlp, ",
                ")",
                " framework: mini-batch size as 4; local training iteration as 1; learning rate as 0.1; max sequence length as 256 for ",
                "20NEWS",
                " and ",
                "ONTONOTES",
                ", 64 for ",
                "AGNEWS",
                " and ",
                "SEMEVAL",
                ".\nFor the FL configurations at the server side, we follow the prior FedNLP literature to select 15 participants by default for each training round, i.e., 5 clients in each trial group of ",
                "FedAdapter",
                "."
            ]
        ]
    },
    "S5.T4": {
        "caption": "Table 4. Datasets and settings used in experiments for Text Classification and Sequence Tagging. “a” is a parameter that controls the datasets’ non-IID level (lin2021fednlp, ).",
        "table": "<table id=\"S5.T4.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.2.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T4.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Task</span></th>\n<th id=\"S5.T4.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T4.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Dataset</span></th>\n<th id=\"S5.T4.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T4.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\"># of Clients</span></th>\n<th id=\"S5.T4.2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T4.2.1.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Labels</span></th>\n<th id=\"S5.T4.2.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T4.2.1.1.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Non-IID</span></th>\n<th id=\"S5.T4.2.1.1.6\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T4.2.1.1.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Samples</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.2.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">TC</span></td>\n<td id=\"S5.T4.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<span id=\"S5.T4.2.2.1.2.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">20NEWS</span><span id=\"S5.T4.2.2.1.2.2\" class=\"ltx_text\" style=\"font-size:80%;\"> </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span id=\"S5.T4.2.2.1.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(</span><a href=\"#bib.bib45\" title=\"\" class=\"ltx_ref\">lang1995newsweeder<span id=\"S5.T4.2.2.1.2.4.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">, </span></a><span id=\"S5.T4.2.2.1.2.5.3\" class=\"ltx_text\" style=\"font-size:80%;\">)</span></cite>\n</td>\n<td id=\"S5.T4.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.2.2.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">100</span></td>\n<td id=\"S5.T4.2.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.2.2.1.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">20</span></td>\n<td id=\"S5.T4.2.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.2.2.1.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">/</span></td>\n<td id=\"S5.T4.2.2.1.6\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\"><span id=\"S5.T4.2.2.1.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">18.8k</span></td>\n</tr>\n<tr id=\"S5.T4.2.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.2.3.2.1\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.2.3.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">TC</span></td>\n<td id=\"S5.T4.2.3.2.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S5.T4.2.3.2.2.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">AGNEWS</span><span id=\"S5.T4.2.3.2.2.2\" class=\"ltx_text\" style=\"font-size:80%;\"> </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span id=\"S5.T4.2.3.2.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(</span><a href=\"#bib.bib93\" title=\"\" class=\"ltx_ref\">zhang2015character<span id=\"S5.T4.2.3.2.2.4.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">, </span></a><span id=\"S5.T4.2.3.2.2.5.3\" class=\"ltx_text\" style=\"font-size:80%;\">)</span></cite>\n</td>\n<td id=\"S5.T4.2.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.2.3.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">1,000</span></td>\n<td id=\"S5.T4.2.3.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.2.3.2.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">4</span></td>\n<td id=\"S5.T4.2.3.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.2.3.2.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">a=10</span></td>\n<td id=\"S5.T4.2.3.2.6\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S5.T4.2.3.2.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">127.6k</span></td>\n</tr>\n<tr id=\"S5.T4.2.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.2.4.3.1\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.2.4.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">TC</span></td>\n<td id=\"S5.T4.2.4.3.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S5.T4.2.4.3.2.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">SEMEVAL</span><span id=\"S5.T4.2.4.3.2.2\" class=\"ltx_text\" style=\"font-size:80%;\"> </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span id=\"S5.T4.2.4.3.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(</span><a href=\"#bib.bib31\" title=\"\" class=\"ltx_ref\">hendrickx2019semeval<span id=\"S5.T4.2.4.3.2.4.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">, </span></a><span id=\"S5.T4.2.4.3.2.5.3\" class=\"ltx_text\" style=\"font-size:80%;\">)</span></cite>\n</td>\n<td id=\"S5.T4.2.4.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.2.4.3.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">100</span></td>\n<td id=\"S5.T4.2.4.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.2.4.3.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">19</span></td>\n<td id=\"S5.T4.2.4.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.2.4.3.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">a=100</span></td>\n<td id=\"S5.T4.2.4.3.6\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S5.T4.2.4.3.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">10.7k</span></td>\n</tr>\n<tr id=\"S5.T4.2.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.2.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T4.2.5.4.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">ST</span></td>\n<td id=\"S5.T4.2.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<span id=\"S5.T4.2.5.4.2.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">ONTONOTES</span><span id=\"S5.T4.2.5.4.2.2\" class=\"ltx_text\" style=\"font-size:80%;\"> </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span id=\"S5.T4.2.5.4.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(</span><a href=\"#bib.bib60\" title=\"\" class=\"ltx_ref\">pradhan2013towards<span id=\"S5.T4.2.5.4.2.4.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">, </span></a><span id=\"S5.T4.2.5.4.2.5.3\" class=\"ltx_text\" style=\"font-size:80%;\">)</span></cite>\n</td>\n<td id=\"S5.T4.2.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T4.2.5.4.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">600</span></td>\n<td id=\"S5.T4.2.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T4.2.5.4.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">37</span></td>\n<td id=\"S5.T4.2.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T4.2.5.4.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">a=10</span></td>\n<td id=\"S5.T4.2.5.4.6\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\"><span id=\"S5.T4.2.5.4.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">5.5k</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Tasks and datasets\nWe evaluate FedAdapter on 4 classic NLP downstream datasets as shown in Table 4.\nWe follow the approach in (lin2021fednlp, ) to build the non-IID datasets.\n(1) 20NEWS (IID) (lang1995newsweeder, ) dataset is a collection of approximately 20,000 newsgroup documents.\n(2) AGNEWS (non-IID) (zhang2015character, ) is a collection of 127.6K news articles gathered from more than 2,000 news sources.\n(3) SEMEVAL (non-IID) (hendrickx2019semeval, ) is a relation classification datasets which assigns predefined relation labels to the entity pairs that occur in texts.\nThe above 3 datasets are used for text classification (TC) (sun2019fine, ) tasks, where the output is a label in a fixed set of label set (e.g., political, sports, and entertainment).\n(4) ONTONOTES (non-IID) (pradhan2013towards, ) is a corpus where sentences have annotations for the entity spans and types.\nThis dataset is for sequence tagging (ST) (aras2021evaluation, ) task, where the output is a sequence of tags."
        ]
    },
    "S5.T5": {
        "caption": "Table 5. Elapsed training time taken to reach different relative target accuracy. NLP model: BERT. Unit: Hour.\n",
        "table": "<table id=\"S5.T5.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.2.3.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.2.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T5.2.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Datasets</span></th>\n<td id=\"S5.T5.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\"><span id=\"S5.T5.2.3.1.2.1\" class=\"ltx_text ltx_font_typewriter ltx_font_bold\">20NEWS</span></td>\n<td id=\"S5.T5.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\"><span id=\"S5.T5.2.3.1.3.1\" class=\"ltx_text ltx_font_typewriter ltx_font_bold\">AGNEWS</span></td>\n<td id=\"S5.T5.2.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\"><span id=\"S5.T5.2.3.1.4.1\" class=\"ltx_text ltx_font_typewriter ltx_font_bold\">SEMEVAL</span></td>\n<td id=\"S5.T5.2.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"3\"><span id=\"S5.T5.2.3.1.5.1\" class=\"ltx_text ltx_font_typewriter ltx_font_bold\">ONTONOTES</span></td>\n</tr>\n<tr id=\"S5.T5.2.4.2\" class=\"ltx_tr\">\n<th id=\"S5.T5.2.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">Relative Accuracy</th>\n<td id=\"S5.T5.2.4.2.2\" class=\"ltx_td ltx_align_center\">99%</td>\n<td id=\"S5.T5.2.4.2.3\" class=\"ltx_td ltx_align_center\">95%</td>\n<td id=\"S5.T5.2.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">90%</td>\n<td id=\"S5.T5.2.4.2.5\" class=\"ltx_td ltx_align_center\">99%</td>\n<td id=\"S5.T5.2.4.2.6\" class=\"ltx_td ltx_align_center\">95%</td>\n<td id=\"S5.T5.2.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_r\">90%</td>\n<td id=\"S5.T5.2.4.2.8\" class=\"ltx_td ltx_align_center\">99%</td>\n<td id=\"S5.T5.2.4.2.9\" class=\"ltx_td ltx_align_center\">95%</td>\n<td id=\"S5.T5.2.4.2.10\" class=\"ltx_td ltx_align_center ltx_border_r\">90%</td>\n<td id=\"S5.T5.2.4.2.11\" class=\"ltx_td ltx_align_center\">99%</td>\n<td id=\"S5.T5.2.4.2.12\" class=\"ltx_td ltx_align_center\">95%</td>\n<td id=\"S5.T5.2.4.2.13\" class=\"ltx_td ltx_align_center\">90%</td>\n</tr>\n<tr id=\"S5.T5.2.5.3\" class=\"ltx_tr\">\n<th id=\"S5.T5.2.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T5.2.5.3.1.1\" class=\"ltx_text ltx_font_typewriter\">FT</span></th>\n<td id=\"S5.T5.2.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">44.0</td>\n<td id=\"S5.T5.2.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">23.4</td>\n<td id=\"S5.T5.2.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">13.1</td>\n<td id=\"S5.T5.2.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">31.1</td>\n<td id=\"S5.T5.2.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">10.1</td>\n<td id=\"S5.T5.2.5.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">5.2</td>\n<td id=\"S5.T5.2.5.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">124.3</td>\n<td id=\"S5.T5.2.5.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\">89.9</td>\n<td id=\"S5.T5.2.5.3.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">61.7</td>\n<td id=\"S5.T5.2.5.3.11\" class=\"ltx_td ltx_align_center ltx_border_t\">76.1</td>\n<td id=\"S5.T5.2.5.3.12\" class=\"ltx_td ltx_align_center ltx_border_t\">55.9</td>\n<td id=\"S5.T5.2.5.3.13\" class=\"ltx_td ltx_align_center ltx_border_t\">35.6</td>\n</tr>\n<tr id=\"S5.T5.2.6.4\" class=\"ltx_tr\">\n<th id=\"S5.T5.2.6.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T5.2.6.4.1.1\" class=\"ltx_text ltx_font_typewriter\">FTQ</span></th>\n<td id=\"S5.T5.2.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">12.7</td>\n<td id=\"S5.T5.2.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">6.8</td>\n<td id=\"S5.T5.2.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.8</td>\n<td id=\"S5.T5.2.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">9.1</td>\n<td id=\"S5.T5.2.6.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\">2.6</td>\n<td id=\"S5.T5.2.6.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.7</td>\n<td id=\"S5.T5.2.6.4.8\" class=\"ltx_td ltx_align_center ltx_border_t\">32.0</td>\n<td id=\"S5.T5.2.6.4.9\" class=\"ltx_td ltx_align_center ltx_border_t\">23.1</td>\n<td id=\"S5.T5.2.6.4.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">15.9</td>\n<td id=\"S5.T5.2.6.4.11\" class=\"ltx_td ltx_align_center ltx_border_t\">21.2</td>\n<td id=\"S5.T5.2.6.4.12\" class=\"ltx_td ltx_align_center ltx_border_t\">15.5</td>\n<td id=\"S5.T5.2.6.4.13\" class=\"ltx_td ltx_align_center ltx_border_t\">9.9</td>\n</tr>\n<tr id=\"S5.T5.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.1\" class=\"ltx_text ltx_font_typewriter\">LF<sub id=\"S5.T5.1.1.1.1.1\" class=\"ltx_sub\"><span id=\"S5.T5.1.1.1.1.1.1\" class=\"ltx_text ltx_font_serif ltx_font_italic\">oracle</span></sub></span></th>\n<td id=\"S5.T5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">18.5</td>\n<td id=\"S5.T5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">8.1</td>\n<td id=\"S5.T5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4.3</td>\n<td id=\"S5.T5.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">9.6</td>\n<td id=\"S5.T5.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">1.4</td>\n<td id=\"S5.T5.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.1</td>\n<td id=\"S5.T5.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">74.0</td>\n<td id=\"S5.T5.1.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">46.8</td>\n<td id=\"S5.T5.1.1.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.2</td>\n<td id=\"S5.T5.1.1.11\" class=\"ltx_td ltx_align_center ltx_border_t\">82.5</td>\n<td id=\"S5.T5.1.1.12\" class=\"ltx_td ltx_align_center ltx_border_t\">43.8</td>\n<td id=\"S5.T5.1.1.13\" class=\"ltx_td ltx_align_center ltx_border_t\">24.5</td>\n</tr>\n<tr id=\"S5.T5.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T5.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T5.2.2.1.1\" class=\"ltx_text ltx_font_typewriter\">LFQ<sub id=\"S5.T5.2.2.1.1.1\" class=\"ltx_sub\"><span id=\"S5.T5.2.2.1.1.1.1\" class=\"ltx_text ltx_font_serif ltx_font_italic\">oracle</span></sub></span></th>\n<td id=\"S5.T5.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">5.2</td>\n<td id=\"S5.T5.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">2.5</td>\n<td id=\"S5.T5.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.1</td>\n<td id=\"S5.T5.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">1.6</td>\n<td id=\"S5.T5.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.3</td>\n<td id=\"S5.T5.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.2</td>\n<td id=\"S5.T5.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\">16.8</td>\n<td id=\"S5.T5.2.2.9\" class=\"ltx_td ltx_align_center ltx_border_t\">11.0</td>\n<td id=\"S5.T5.2.2.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7.7</td>\n<td id=\"S5.T5.2.2.11\" class=\"ltx_td ltx_align_center ltx_border_t\">23.9</td>\n<td id=\"S5.T5.2.2.12\" class=\"ltx_td ltx_align_center ltx_border_t\">12.9</td>\n<td id=\"S5.T5.2.2.13\" class=\"ltx_td ltx_align_center ltx_border_t\">7.2</td>\n</tr>\n<tr id=\"S5.T5.2.7.5\" class=\"ltx_tr\">\n<th id=\"S5.T5.2.7.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T5.2.7.5.1.1\" class=\"ltx_text ltx_font_typewriter ltx_font_bold\">FedAdapter</span></th>\n<td id=\"S5.T5.2.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.7.5.2.1\" class=\"ltx_text ltx_font_bold\">1.3</span></td>\n<td id=\"S5.T5.2.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.7.5.3.1\" class=\"ltx_text ltx_font_bold\">0.4</span></td>\n<td id=\"S5.T5.2.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T5.2.7.5.4.1\" class=\"ltx_text ltx_font_bold\">0.1</span></td>\n<td id=\"S5.T5.2.7.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.7.5.5.1\" class=\"ltx_text ltx_font_bold\">0.2</span></td>\n<td id=\"S5.T5.2.7.5.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.7.5.6.1\" class=\"ltx_text ltx_font_bold\">0.03</span></td>\n<td id=\"S5.T5.2.7.5.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T5.2.7.5.7.1\" class=\"ltx_text ltx_font_bold\">0.02</span></td>\n<td id=\"S5.T5.2.7.5.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.7.5.8.1\" class=\"ltx_text ltx_font_bold\">2.3</span></td>\n<td id=\"S5.T5.2.7.5.9\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.7.5.9.1\" class=\"ltx_text ltx_font_bold\">1.1</span></td>\n<td id=\"S5.T5.2.7.5.10\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T5.2.7.5.10.1\" class=\"ltx_text ltx_font_bold\">0.6</span></td>\n<td id=\"S5.T5.2.7.5.11\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.7.5.11.1\" class=\"ltx_text ltx_font_bold\">4.5</span></td>\n<td id=\"S5.T5.2.7.5.12\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.7.5.12.1\" class=\"ltx_text ltx_font_bold\">2.4</span></td>\n<td id=\"S5.T5.2.7.5.13\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.7.5.13.1\" class=\"ltx_text ltx_font_bold\">1.3</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "FedAdapter reduces model convergence delays significantly, making FedNLP practical.\nTable 5 summarizes the convergence time and Figure 5 illustrates the convergence process under the default setting.\nTo reach 99% relative target accuracy, FedAdapter is 33.8×\\times, 155.5×\\times, 54.0×\\times and 16.9×\\times faster than FT on the four datasets, respectively.\nWith a lower target accuracy such as 90%, the speedup brought by FedAdapter is even more significant, i.e., 27.4×\\times–260.0×\\times.\nIt takes at most one hour for FedAdapter to reach a usable accuracy."
        ]
    }
}