{
    "S5.T1": {
        "caption": "Table 1: Final inner-loop learning rates for meta-SGD.",
        "table": "<table id=\"S5.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S5.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Layer</span></th>\n<th id=\"S5.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Mean</span></th>\n<th id=\"S5.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T1.1.1.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Std. Dev.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S5.T1.1.2.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Conv1</span></th>\n<td id=\"S5.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.2.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">-0.006</span></td>\n<td id=\"S5.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.2.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">0.032</span></td>\n</tr>\n<tr id=\"S5.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.1.3.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Conv2</span></th>\n<td id=\"S5.T1.1.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.3.2.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">-0.004</span></td>\n<td id=\"S5.T1.1.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.3.2.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">0.027</span></td>\n</tr>\n<tr id=\"S5.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.1.4.3.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Conv3</span></th>\n<td id=\"S5.T1.1.4.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.4.3.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">-0.013</span></td>\n<td id=\"S5.T1.1.4.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.4.3.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">0.027</span></td>\n</tr>\n<tr id=\"S5.T1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.1.5.4.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Conv4</span></th>\n<td id=\"S5.T1.1.5.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.5.4.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">-0.018</span></td>\n<td id=\"S5.T1.1.5.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.5.4.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">0.030</span></td>\n</tr>\n<tr id=\"S5.T1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S5.T1.1.6.5.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Logits</span></th>\n<td id=\"S5.T1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.1.6.5.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">0.043</span></td>\n<td id=\"S5.T1.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.1.6.5.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">0.072</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "The inner-loop learning rate after 60,000 iterations can be seen in Â 6 and the distribution statistics for each layer is shown in 1. It is interesting to note that the mean learning rate for every convolutional layer is negative and only the mean learning rate for the linear output layer is positive."
        ]
    }
}