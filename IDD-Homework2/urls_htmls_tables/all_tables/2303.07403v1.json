{
    "S3.T1": {
        "caption": "Table 1:  Accuracy Comparison between Baseline VQA Models on test data",
        "table": "<table id=\"S3.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">VQA Model</th>\n<th id=\"S3.T1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Overall</th>\n<th id=\"S3.T1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Radar Category</th>\n<th id=\"S3.T1.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Place Category</th>\n<th id=\"S3.T1.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Zone Category</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.3.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.3.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">Q-Only</td>\n<td id=\"S3.T1.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.51</td>\n<td id=\"S3.T1.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.63</td>\n<td id=\"S3.T1.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.54</td>\n<td id=\"S3.T1.3.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.43</td>\n</tr>\n<tr id=\"S3.T1.3.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.3.3.2.1\" class=\"ltx_td ltx_align_center\">VIS-LSTM <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib13\" title=\"\" class=\"ltx_ref\">13</a>]</cite>\n</td>\n<td id=\"S3.T1.3.3.2.2\" class=\"ltx_td ltx_align_center\">0.96</td>\n<td id=\"S3.T1.3.3.2.3\" class=\"ltx_td ltx_align_center\">0.96</td>\n<td id=\"S3.T1.3.3.2.4\" class=\"ltx_td ltx_align_center\">0.93</td>\n<td id=\"S3.T1.3.3.2.5\" class=\"ltx_td ltx_align_center\">0.99</td>\n</tr>\n<tr id=\"S3.T1.3.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.3.4.3.1\" class=\"ltx_td ltx_align_center\">CNN+LSTM <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">12</a>]</cite>\n</td>\n<td id=\"S3.T1.3.4.3.2\" class=\"ltx_td ltx_align_center\">0.96</td>\n<td id=\"S3.T1.3.4.3.3\" class=\"ltx_td ltx_align_center\">0.95</td>\n<td id=\"S3.T1.3.4.3.4\" class=\"ltx_td ltx_align_center\">0.94</td>\n<td id=\"S3.T1.3.4.3.5\" class=\"ltx_td ltx_align_center\">0.99</td>\n</tr>\n<tr id=\"S3.T1.3.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.3.5.4.1\" class=\"ltx_td ltx_align_center\">SAN <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a>]</cite>\n</td>\n<td id=\"S3.T1.3.5.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T1.3.5.4.2.1\" class=\"ltx_text ltx_font_bold\">0.97</span></td>\n<td id=\"S3.T1.3.5.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T1.3.5.4.3.1\" class=\"ltx_text ltx_font_bold\">0.97</span></td>\n<td id=\"S3.T1.3.5.4.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T1.3.5.4.4.1\" class=\"ltx_text ltx_font_bold\">0.94</span></td>\n<td id=\"S3.T1.3.5.4.5\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T1.3.5.4.5.1\" class=\"ltx_text ltx_font_bold\">0.99</span></td>\n</tr>\n<tr id=\"S3.T1.3.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.3.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_b\">MFB-CoAttention <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">6</a>]</cite>\n</td>\n<td id=\"S3.T1.3.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_b\">0.97</td>\n<td id=\"S3.T1.3.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_b\">0.96</td>\n<td id=\"S3.T1.3.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_b\">0.94</td>\n<td id=\"S3.T1.3.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_b\">0.99</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "From Table 1, we can see that prediction directly from question Q-Only is very poor compared to the other VQA approaches. This demonstrates that there is less language bias (i.e., the ability to predict an answer directly from a question) present in our dataset. The other four VQA models perform nearly the same on our Polar-VQA dataset. We can identify that overall accuracy lies somewhere between 0.96âˆ’0.970.960.970.96-0.97 which is nearly perfect on test data. The accuracy for each category is also close to 111. These promising results highlight that the VQA framework is highly capable of identifying the types of radars, recognizing locations, and differentiating between dry and wet zone images very efficiently.",
            "Table 2 highlights the performance of two types of questions for each question category. We can see that for open-ended (OE) questions, the accuracy is 1 in the case of identifying the dry and wet zone images, regardless of the VQA models. However, the accuracy of the place category is lower than that of the other two categories. On the other hand, for close-ended (CE) questions, performance is better for the zone category among all the question categories. From both Table 1 and 2, we understand that performance among the VQA approaches given a question category is less deviated than the performance between question categories."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Question-wise Accuracy Comparison Between Baseline Models for Each Question Category",
        "table": "<table id=\"S3.T2.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.3.1.1.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S3.T2.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">VQA Model</th>\n<th id=\"S3.T2.3.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Open-Ended</th>\n<th id=\"S3.T2.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Close-Ended</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.3.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" rowspan=\"4\"><span id=\"S3.T2.3.2.1.1.1\" class=\"ltx_text\">Zone</span></th>\n<td id=\"S3.T2.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">VIS-LSTM</td>\n<td id=\"S3.T2.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">1</td>\n<td id=\"S3.T2.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.995</td>\n</tr>\n<tr id=\"S3.T2.3.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.3.2.1\" class=\"ltx_td ltx_align_center\">CNN+LSTM</td>\n<td id=\"S3.T2.3.3.2.2\" class=\"ltx_td ltx_align_center\">1</td>\n<td id=\"S3.T2.3.3.2.3\" class=\"ltx_td ltx_align_center\">0.998</td>\n</tr>\n<tr id=\"S3.T2.3.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.4.3.1\" class=\"ltx_td ltx_align_center\">SAN</td>\n<td id=\"S3.T2.3.4.3.2\" class=\"ltx_td ltx_align_center\">1</td>\n<td id=\"S3.T2.3.4.3.3\" class=\"ltx_td ltx_align_center\">0.995</td>\n</tr>\n<tr id=\"S3.T2.3.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.5.4.1\" class=\"ltx_td ltx_align_center\">MFB-CoAttention</td>\n<td id=\"S3.T2.3.5.4.2\" class=\"ltx_td ltx_align_center\">1</td>\n<td id=\"S3.T2.3.5.4.3\" class=\"ltx_td ltx_align_center\">0.996</td>\n</tr>\n<tr id=\"S3.T2.3.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T2.3.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"4\"><span id=\"S3.T2.3.6.5.1.1\" class=\"ltx_text\">Place</span></th>\n<td id=\"S3.T2.3.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">VIS-LSTM</td>\n<td id=\"S3.T2.3.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.93</td>\n<td id=\"S3.T2.3.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.93</td>\n</tr>\n<tr id=\"S3.T2.3.7.6\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.7.6.1\" class=\"ltx_td ltx_align_center\">CNN+LSTM</td>\n<td id=\"S3.T2.3.7.6.2\" class=\"ltx_td ltx_align_center\">0.94</td>\n<td id=\"S3.T2.3.7.6.3\" class=\"ltx_td ltx_align_center\">0.94</td>\n</tr>\n<tr id=\"S3.T2.3.8.7\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.8.7.1\" class=\"ltx_td ltx_align_center\">SAN</td>\n<td id=\"S3.T2.3.8.7.2\" class=\"ltx_td ltx_align_center\">0.93</td>\n<td id=\"S3.T2.3.8.7.3\" class=\"ltx_td ltx_align_center\">0.94</td>\n</tr>\n<tr id=\"S3.T2.3.9.8\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.9.8.1\" class=\"ltx_td ltx_align_center\">MFB-CoAttention</td>\n<td id=\"S3.T2.3.9.8.2\" class=\"ltx_td ltx_align_center\">0.93</td>\n<td id=\"S3.T2.3.9.8.3\" class=\"ltx_td ltx_align_center\">0.94</td>\n</tr>\n<tr id=\"S3.T2.3.10.9\" class=\"ltx_tr\">\n<th id=\"S3.T2.3.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\" rowspan=\"4\"><span id=\"S3.T2.3.10.9.1.1\" class=\"ltx_text\">Radar</span></th>\n<td id=\"S3.T2.3.10.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\">VIS-LSTM</td>\n<td id=\"S3.T2.3.10.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.99</td>\n<td id=\"S3.T2.3.10.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.96</td>\n</tr>\n<tr id=\"S3.T2.3.11.10\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.11.10.1\" class=\"ltx_td ltx_align_center\">CNN+LSTM</td>\n<td id=\"S3.T2.3.11.10.2\" class=\"ltx_td ltx_align_center\">0.99</td>\n<td id=\"S3.T2.3.11.10.3\" class=\"ltx_td ltx_align_center\">0.94</td>\n</tr>\n<tr id=\"S3.T2.3.12.11\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.12.11.1\" class=\"ltx_td ltx_align_center\">SAN</td>\n<td id=\"S3.T2.3.12.11.2\" class=\"ltx_td ltx_align_center\">0.99</td>\n<td id=\"S3.T2.3.12.11.3\" class=\"ltx_td ltx_align_center\">0.96</td>\n</tr>\n<tr id=\"S3.T2.3.13.12\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.13.12.1\" class=\"ltx_td ltx_align_center ltx_border_b\">MFB-CoAttention</td>\n<td id=\"S3.T2.3.13.12.2\" class=\"ltx_td ltx_align_center ltx_border_b\">0.99</td>\n<td id=\"S3.T2.3.13.12.3\" class=\"ltx_td ltx_align_center ltx_border_b\">0.95</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Table 2 highlights the performance of two types of questions for each question category. We can see that for open-ended (OE) questions, the accuracy is 1 in the case of identifying the dry and wet zone images, regardless of the VQA models. However, the accuracy of the place category is lower than that of the other two categories. On the other hand, for close-ended (CE) questions, performance is better for the zone category among all the question categories. From both Table 1 and 2, we understand that performance among the VQA approaches given a question category is less deviated than the performance between question categories."
        ]
    }
}