{
    "PAPER'S NUMBER OF TABLES": 1,
    "S5.T1": {
        "caption": "TABLE I: A summary of average percentage accuracy improvement",
        "table": "<table id=\"S5.T1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"></th>\n<th id=\"S5.T1.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">CIFAR100</span></th>\n<th id=\"S5.T1.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">FC100</span></th>\n<th id=\"S5.T1.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Corn50</span></th>\n<th id=\"S5.T1.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">\n<table id=\"S5.T1.1.1.1.1.5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.1.1.1.1.5.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.1.1.5.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.1.1.5.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Mini</span></td>\n</tr>\n<tr id=\"S5.T1.1.1.1.1.5.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.1.1.5.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.1.1.5.1.2.1.1\" class=\"ltx_text ltx_font_bold\">Imagenet</span></td>\n</tr>\n</table>\n</th>\n<th id=\"S5.T1.1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\" colspan=\"3\">\n<table id=\"S5.T1.1.1.1.1.6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.1.1.1.1.6.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.1.1.6.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.1.1.6.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Tiny</span></td>\n</tr>\n<tr id=\"S5.T1.1.1.1.1.6.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.1.1.6.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.1.1.6.1.2.1.1\" class=\"ltx_text ltx_font_bold\">Imagenet</span></td>\n</tr>\n</table>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Task1</span></td>\n<td id=\"S5.T1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">36.52%</td>\n<td id=\"S5.T1.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">36.16%</td>\n<td id=\"S5.T1.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">17.31%</td>\n<td id=\"S5.T1.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">10.21%</td>\n<td id=\"S5.T1.1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">16.00%</td>\n<td id=\"S5.T1.1.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.2.1.7.1\" class=\"ltx_text ltx_font_bold\">Task11</span></td>\n<td id=\"S5.T1.1.1.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">64.00%</td>\n</tr>\n<tr id=\"S5.T1.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.3.2.1.1\" class=\"ltx_text ltx_font_bold\">Task2</span></td>\n<td id=\"S5.T1.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">74.74%</td>\n<td id=\"S5.T1.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">63.62%</td>\n<td id=\"S5.T1.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">38.80%</td>\n<td id=\"S5.T1.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">20.39%</td>\n<td id=\"S5.T1.1.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">18.31%</td>\n<td id=\"S5.T1.1.1.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.3.2.7.1\" class=\"ltx_text ltx_font_bold\">Task12</span></td>\n<td id=\"S5.T1.1.1.3.2.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">67.98%</td>\n</tr>\n<tr id=\"S5.T1.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.4.3.1.1\" class=\"ltx_text ltx_font_bold\">Task3</span></td>\n<td id=\"S5.T1.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">82.58%</td>\n<td id=\"S5.T1.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">74.89%</td>\n<td id=\"S5.T1.1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">32.54%</td>\n<td id=\"S5.T1.1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">37.04%</td>\n<td id=\"S5.T1.1.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">20.62%</td>\n<td id=\"S5.T1.1.1.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.4.3.7.1\" class=\"ltx_text ltx_font_bold\">Task13</span></td>\n<td id=\"S5.T1.1.1.4.3.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">73.00%</td>\n</tr>\n<tr id=\"S5.T1.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.5.4.1.1\" class=\"ltx_text ltx_font_bold\">Task4</span></td>\n<td id=\"S5.T1.1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">84.84%</td>\n<td id=\"S5.T1.1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">79.22%</td>\n<td id=\"S5.T1.1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">46.21%</td>\n<td id=\"S5.T1.1.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">70.30%</td>\n<td id=\"S5.T1.1.1.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">28.22%</td>\n<td id=\"S5.T1.1.1.5.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.5.4.7.1\" class=\"ltx_text ltx_font_bold\">Task14</span></td>\n<td id=\"S5.T1.1.1.5.4.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">80.27%</td>\n</tr>\n<tr id=\"S5.T1.1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.6.5.1.1\" class=\"ltx_text ltx_font_bold\">Task5</span></td>\n<td id=\"S5.T1.1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">88.69%</td>\n<td id=\"S5.T1.1.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">86.83%</td>\n<td id=\"S5.T1.1.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">45.39%</td>\n<td id=\"S5.T1.1.1.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">68.12%</td>\n<td id=\"S5.T1.1.1.6.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">33.00%</td>\n<td id=\"S5.T1.1.1.6.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.6.5.7.1\" class=\"ltx_text ltx_font_bold\">Task15</span></td>\n<td id=\"S5.T1.1.1.6.5.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">84.00%</td>\n</tr>\n<tr id=\"S5.T1.1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.7.6.1.1\" class=\"ltx_text ltx_font_bold\">Task6</span></td>\n<td id=\"S5.T1.1.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">94.87%</td>\n<td id=\"S5.T1.1.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">86.15%</td>\n<td id=\"S5.T1.1.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">37.27%</td>\n<td id=\"S5.T1.1.1.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">70.57%</td>\n<td id=\"S5.T1.1.1.7.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">35.09%</td>\n<td id=\"S5.T1.1.1.7.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.7.6.7.1\" class=\"ltx_text ltx_font_bold\">Task16</span></td>\n<td id=\"S5.T1.1.1.7.6.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">93.50%</td>\n</tr>\n<tr id=\"S5.T1.1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.8.7.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.8.7.1.1\" class=\"ltx_text ltx_font_bold\">Task7</span></td>\n<td id=\"S5.T1.1.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">92.40%</td>\n<td id=\"S5.T1.1.1.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">88.81%</td>\n<td id=\"S5.T1.1.1.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">37.06%</td>\n<td id=\"S5.T1.1.1.8.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">65.61%</td>\n<td id=\"S5.T1.1.1.8.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">45.00%</td>\n<td id=\"S5.T1.1.1.8.7.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.8.7.7.1\" class=\"ltx_text ltx_font_bold\">Task17</span></td>\n<td id=\"S5.T1.1.1.8.7.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">95.00%</td>\n</tr>\n<tr id=\"S5.T1.1.1.9.8\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.9.8.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.9.8.1.1\" class=\"ltx_text ltx_font_bold\">Task8</span></td>\n<td id=\"S5.T1.1.1.9.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">95.52%</td>\n<td id=\"S5.T1.1.1.9.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">85.50%</td>\n<td id=\"S5.T1.1.1.9.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">51.84%</td>\n<td id=\"S5.T1.1.1.9.8.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">67.98%</td>\n<td id=\"S5.T1.1.1.9.8.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">54.46%</td>\n<td id=\"S5.T1.1.1.9.8.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.9.8.7.1\" class=\"ltx_text ltx_font_bold\">Task18</span></td>\n<td id=\"S5.T1.1.1.9.8.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">97.78%</td>\n</tr>\n<tr id=\"S5.T1.1.1.10.9\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.10.9.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.10.9.1.1\" class=\"ltx_text ltx_font_bold\">Task9</span></td>\n<td id=\"S5.T1.1.1.10.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">98.72%</td>\n<td id=\"S5.T1.1.1.10.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">87.57%</td>\n<td id=\"S5.T1.1.1.10.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">56.65%</td>\n<td id=\"S5.T1.1.1.10.9.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">70.34%</td>\n<td id=\"S5.T1.1.1.10.9.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">52.00%</td>\n<td id=\"S5.T1.1.1.10.9.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.10.9.7.1\" class=\"ltx_text ltx_font_bold\">Task19</span></td>\n<td id=\"S5.T1.1.1.10.9.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">91.00%</td>\n</tr>\n<tr id=\"S5.T1.1.1.11.10\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.11.10.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.11.10.1.1\" class=\"ltx_text ltx_font_bold\">Task10</span></td>\n<td id=\"S5.T1.1.1.11.10.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">97.75%</td>\n<td id=\"S5.T1.1.1.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">90.49%</td>\n<td id=\"S5.T1.1.1.11.10.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">54.72%</td>\n<td id=\"S5.T1.1.1.11.10.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">72.18%</td>\n<td id=\"S5.T1.1.1.11.10.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">61.49%</td>\n<td id=\"S5.T1.1.1.11.10.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.11.10.7.1\" class=\"ltx_text ltx_font_bold\">Task20</span></td>\n<td id=\"S5.T1.1.1.11.10.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">87.57%</td>\n</tr>\n<tr id=\"S5.T1.1.1.12.11\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.12.11.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"><span id=\"S5.T1.1.1.12.11.1.1\" class=\"ltx_text ltx_font_bold\">Task11</span></td>\n<td id=\"S5.T1.1.1.12.11.2\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"></td>\n<td id=\"S5.T1.1.1.12.11.3\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"></td>\n<td id=\"S5.T1.1.1.12.11.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">63.22%</td>\n<td id=\"S5.T1.1.1.12.11.5\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"></td>\n<td id=\"S5.T1.1.1.12.11.6\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"></td>\n<td id=\"S5.T1.1.1.12.11.7\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"></td>\n<td id=\"S5.T1.1.1.12.11.8\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "This section’s evaluation compares ",
                "model accuracy",
                " and ",
                "training time",
                " between FedKNOW and 11 baseline techniques. ",
                "To make our comparisons fair and avoid leakage of test data, we employ the prevalent benchmarking method ",
                "[",
                "12",
                "]",
                " that searches hyperparameter using an additional test dataset (that is, SVHN ",
                "[",
                "39",
                "]",
                " with two tasks and each class has 5 classes). For each dataset, this method searches the optimal hyperparameters that produce the highest accuracy on the SVHN dataset.",
                " The model training settings include two parts:",
                "Common training settings for all techniques",
                ". In comparison, the model is trained using the same initial weights, training samples, hyperparameters, and a cluster of 20 heterogeneous edge clients, including 2 Jetson AGX, 2 Jetson TX2, 8 Jetson Xavier NX, and 8 Jetson Nano platforms.\n",
                "In hyperparameter search, the search scopes of aggregation rounds and training iterations are 5 to 15 and 5 to 150, respectively. The search scopes of learning rates and decreases rates are {0.0005,0.0008,0.001,0.005} and {1e-6,1e-5,1e-4}. The scopes of both hyperparameters satisfy the condition of convergency in Section ",
                "IV",
                ".\nFor Cifar100, FC100, CORe50, MinyImageNet, and TinyImageNet workloads, the numbers of global aggregation rounds are set to 15, 15, 15, 10, and 5, respectively. Each round consists of 25 local local training iterations (i.e. 5 epoches). In these five workloads, the learning rates are set to 0.001, 0.001, 0.001, 0.0008, and 0.0008, and their decrease rates are set to 1e-4, 1e-4, 1e-4, 1e-5, and 1e-5, respectively.\n",
                "Specific settings for some techniques",
                ". ",
                "In hyperparameter search of each baseline method, we set the lower and upper bounds of search space as 1/2 and 2 of the parameter value in its original evaluation.",
                " In memory-based continual learning methods(GEM, BCN, ",
                "C",
                "​",
                "o",
                "2",
                "​",
                "L",
                "𝐶",
                "superscript",
                "𝑜",
                "2",
                "𝐿",
                "Co^{2}L",
                "), 10% of training samples are retained to avoid catastrophic forgetting. In regularization-based continual learning methods, the regularization hyper-parameters are 40000 and 100 for EWC and MAS. In FLCN, we select 10% of training samples randomly to the server for updating the regularization parameters.\n",
                "\nIn FedKNOW, the search space of ratio ",
                "ρ",
                "𝜌",
                "\\rho",
                " of retained weights and number ",
                "k",
                "𝑘",
                "k",
                " of selected gradients in integration are ",
                "{",
                "5",
                "%",
                ",",
                "10",
                "%",
                ",",
                "20",
                "%",
                "}",
                "percent",
                "5",
                "percent",
                "10",
                "percent",
                "20",
                "\\{5\\%,10\\%,20\\%\\}",
                ", and ",
                "{",
                "5",
                ",",
                "10",
                ",",
                "20",
                "}",
                "5",
                "10",
                "20",
                "\\{5,10,20\\}",
                ", respectively.\nRatio ",
                "ρ",
                "𝜌",
                "\\rho",
                " is set to 10% because 20% of weights exceed the memory constraint of 4 GB and 10% produces a better accuracy than that of 5%.\nGradient number ",
                "k",
                "𝑘",
                "k",
                " is set to 10 because it produces the highest accuracy within the time constraint (that is, each task’s computational time is smaller than 20 minutes).\n",
                "Comparison results",
                ". Figure ",
                "4",
                " displays the comparison results of 12 techniques and we have three key observations.",
                "Impact of catastrophic forgetting",
                ". Three federated learning baselines take less time to converge because these methods donot consider previous task information in model training, hence their model accuracies are lower than most of the other techniques due to catastrophic forgetting.\nThis also explains the results that when the number of task increases, the accuracies of all techniques decrease. FedKNOW suffers least from the accuracy depredation because when learning a new task, it integrates its knowledge with the seen tasks that are most dissimilar from the current task model. In contrast, FedWEIT uses the maintained knowledge of all tasks (stored at the server) and may lower the influence of important tasks.\n",
                "Impact of negative knowledge transfer",
                ". In a federated learning environment, the non-IID datasets in different clients also considerably influence model accuracy. The five continual learning baselines well address catastrophic forgetting, but suffer from negative knowledge transfer from other clients. For example, AGS-CL’s loss function considers the changes in model weights. Hence the large changes in global model weights cause non-convergence in CORe50, MiniImageNet, and TinyImageNet datasets, and this observation is no observed in Figures ",
                "4",
                "(c), (g), and (h). In addition, FedWEIT has higher accuracies than other baseline methods in the first three datasets.\nHowever, its parameter decomposition strategy may harm the functionalities of some particular layers (downsample in ResNet) and thus its accuracies are lower in this DNN model (Figures ",
                "4",
                " (g) and (h)). In contrast, FedKNOW achieves the highest accuracies in all settings thanks to its reliable gradient integration mechanism.\n",
                "Impact of heterogeneous edge devices",
                ". We extend the above evaluation by adding 10 CPU-based devices (Raspberry Pi 4B) to the cluster with 20 Jetson devices. The Raspberry Pi devices consist of one with 2 GB memory, five ones with 4 GB memory, and four ones with 8 GB memory. Using the Cifar100, FC100, and CORe50 datasets, this evaluation compares the three techniques (GEM, FedWEIT, and FedKNOW) that produce the highest accuracies among all techniques. Figures ",
                "4",
                "(d), (e), and (f) show that: (i) training in resource-limited Raspberry Pi devices considerably delays the training time of all techniques by an average of 12 times. In particular, FedWEIT has the largest increase in training time because its global knowledge becomes larger with more tasks and clients. For example, FedWEIT’s training time of the last task is 1 hour longer than the other two techniques. (ii) Resource heterogeneity decreases accuracies for all three techniques by 3% to 5%. The results show FedKNOW still achieves the highest accuracies because it is lightweight and integrates task knowledge locally. In contrast, FedWEIT requires each client using the heavyweight global knowledge, which makes the Raspberry Pi of 2 GB memory out of memory after learning 7 tasks and cannot participate in the following federated learning.\n",
                "Table ",
                "I",
                " summarizes the percentages of increase in the average accuracy, when comparing the accuracy of FedKNOW against the average accuracy of all 11 baselines techniques across 5 different datasets",
                ". For each dataset, the increased accuracy of each task is reported.\nWe can see that when the task number increases, the percentage accuracy improvement increases from 10.21% to 98.72%.\nOverall, when considering all evaluation cases, our approach improves the accuracy by an average of 77.35%, 33.26%, and 31.27% compared to continual learning, federated learning, and FCL baselines, respectively."
            ]
        ]
    }
}