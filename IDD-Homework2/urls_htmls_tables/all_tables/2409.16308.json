{
    "id_table_1": {
        "caption": "Table 1:  Summary of hyperparameters and their constraints in model ( 12 ).",
        "table": "S2.F2.2",
        "footnotes": [
            ""
        ],
        "references": [
            "Our work is based on a unique dataset representing wind power production from the Electric Reliability Council of Texas (ERCOT) control area. Funded by ARPA-Es PERFORM Program  [ 53 ] , this dataset is a highly realistic and detailed database of grid-wide renewable generation serving as a basis for cutting-edge grid management optimization platforms. The data is synthetically generated and was created by multiple teams based on re-analysis of ECMWF numerical weather prediction system and satellite meteorological imagery. It consists of hourly wind production (in megawatts, MW) during the calendar year 2018 for hundreds of wind farms in ERCOT. ERCOT consists of 8 zones (Coast, West, Far West, North, North Central, East, Southern, and South Central), which are used to delineate the geographic distribution of the wind farms see Figure  1 . Geographic locations  s s \\mathbf{s} bold_s  are specified as longitude-latitude coordinate pairs, ranging from  26.12 26.12 26.12 26.12  to  36.50 36.50 36.50 36.50  degrees latitude, and   104.74 104.74 -104.74 - 104.74  to   95.46 95.46 -95.46 - 95.46  degrees longitude. Certain wind farms were excluded from the analysis due to either overlapping spatial coordinates or the presence of anomalous data collection. The dataset includes day-ahead ECMWF-based hourly-scale forecasts  p m , t , n F subscript superscript p F m t n p^{F}_{m,t,n} italic_p start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m , italic_t , italic_n end_POSTSUBSCRIPT  of wind generation and paired realized actuals  p m , t , n A subscript superscript p A m t n p^{A}_{m,t,n} italic_p start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m , italic_t , italic_n end_POSTSUBSCRIPT , both indexed by location  s m subscript s m \\mathbf{s}_{m} bold_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , hour  j j j italic_j  and day  n n n italic_n ,  m  { 1 , 2 , ... , M } , j  { 1 , 2 , ... , T } , n  { 1 , 2 , ... , N } formulae-sequence m 1 2 ... M formulae-sequence j 1 2 ... T n 1 2 ... N m\\in\\{1,2,\\ldots,M\\},j\\in\\{1,2,\\ldots,T\\},n\\in\\{1,2,\\ldots,N\\} italic_m  { 1 , 2 , ... , italic_M } , italic_j  { 1 , 2 , ... , italic_T } , italic_n  { 1 , 2 , ... , italic_N } . The temporal domain is fixed throughout to be  T = 24 T 24 T=24 italic_T = 24  hours. For each facility, the day-ahead forecast is generated in batch based on the medium-term ECMWF model. This forecast is issued at noon, hence is 12-36 hours into the future; all the 24 hourly forecast values are issued at once. One motivation for our work is that while the ARPA-E dataset took significant computational resources (several months of NREL supercomputers) to produce, it contains no quantification of joint uncertainty; instead only marginal predictive standard deviation is reported based on ECMWF ensemble forecasts.",
            "where  Y n = ( Y 1 , 1 , n , Y 1 , 2 , n , ... , Y 1 , T , n , ... . , Y M , T , n )  \\mathbf{Y}_{n}=(Y_{1,1,n},Y_{1,2,n},...,Y_{1,T,n},....,Y_{M,T,n})^{\\top} bold_Y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = ( italic_Y start_POSTSUBSCRIPT 1 , 1 , italic_n end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT 1 , 2 , italic_n end_POSTSUBSCRIPT , ... , italic_Y start_POSTSUBSCRIPT 1 , italic_T , italic_n end_POSTSUBSCRIPT , ... . , italic_Y start_POSTSUBSCRIPT italic_M , italic_T , italic_n end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  n = 1 , 2 , ... , N n 1 2 ... N n=1,2,...,N italic_n = 1 , 2 , ... , italic_N , and   2 superscript  2 \\sigma^{2} italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT  is the nugget hyperparameter, representing the variance of the observation noise. The prior mean function    (  )   \\mu(\\cdot) italic_ (  )  is set to be zero since we centered the forecast error by each location to have mean zero in the data preprocessing step. The covariance matrix  K K \\mathbf{K} bold_K  is decided by the structure of kernel  k  (  ,  ) k   k(\\cdot,\\cdot) italic_k (  ,  )  and GP hyperparameters    \\bm{\\theta} bold_italic_ . Section  3.1  reviews spatiotemporal GP and kernels. The statistical inference for our spatiotemporal GP is provided in Section  3.2 . In Section  3.3  we review and summarize the input warping technique and its applications in our analysis.",
            "Selecting an appropriate kernel function and tuning its hyperparameters are key steps to build the GP model that captures data patterns, as well as make accurate predictions or inferences. In Section  5.1  we employ synthetic examples to assess the efficacy of different kernel choices in our setting.",
            "The weights  w w w italic_w  are limited within  (  1 , 1 2  exp  ( 3 2 ) ) 1 1 2 3 2 (-1,\\frac{1}{2}\\exp(\\frac{3}{2})) ( - 1 , divide start_ARG 1 end_ARG start_ARG 2 end_ARG roman_exp ( divide start_ARG 3 end_ARG start_ARG 2 end_ARG ) )  to ensure injectivity, a positive (resp. negative) weight  w d subscript w d w_{d} italic_w start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT  expands (resp. contracts) dimension  d d d italic_d . The stretching transformation is carried out relative to the center    \\bm{\\gamma} bold_italic_ . The scale  a > 0 a 0 a>0 italic_a > 0  governs the warping resolution, smaller values of  a a a italic_a  allow for more localized deformation. Figure  5  illustrates examples of the warping effect induced by the RBF unit, as described by Equation ( 10 ) in  D = 2 D 2 D=2 italic_D = 2  dimensions: Figures  5(a)  and  5(b)  visualize the warping effect of one RBF unit, Figure  5(c)  depicts warping with two compositional layers. Each layer independently transforms the uniform  ( 0 , 1 )  ( 0 , 1 ) 0 1 0 1 (0,1)\\times(0,1) ( 0 , 1 )  ( 0 , 1 )  grid centered around its respective location. Additionally, the two layers exhibit interaction with each other. The Figures visualize how a greater absolute value of the weight corresponds to a more pronounced deformation impact along the associated axis; similarly a larger value of scale  a a a italic_a  shows a more global contraction (with negative weights  w w \\mathbf{w} bold_w ) or expansion (with positive weights  w w \\mathbf{w} bold_w ).",
            "To train our GP model, we maximize the log-likelihood in Equation ( 7 ). Table  1  summarizes the parameters of the GP kernel, warping, and nugget:   := (  k ,  w ,  2 ) assign  subscript  k subscript  w superscript  2 \\bm{\\theta}:=({\\bm{\\theta}}_{k},{\\bm{\\theta}}_{w},{\\sigma}^{2}) bold_italic_ := ( bold_italic_ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , bold_italic_ start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT , italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) , specifying whether they are involved in the training step and outlining the constraints imposed during the optimization process. We build isotropic spatial kernels from the Matern family, and a Matern plus periodic kernel ( 13 ) for temporal kernels. Therefore, we have 6 kernel parameters   k = (  ,  S ,  T ,  p ,  p , p ) subscript  k  subscript  S subscript  T subscript  p subscript  p p \\bm{\\theta}_{k}=(\\eta,\\rho_{S},\\rho_{T},\\eta_{p},\\rho_{p},p) bold_italic_ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = ( italic_ , italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_p ) :    \\eta italic_  signifies the overall variance of our spatiotemporal GP, while  (  S ,  T ) subscript  S subscript  T (\\rho_{S},\\rho_{T}) ( italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT )  serve as range parameters representing smoothness characteristics of the spatial and temporal dimensions; parameters within the temporal kernels periodic component  (  p ,  p , p ) subscript  p subscript  p p (\\eta_{p},\\rho_{p},p) ( italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_p )  are designed to account for the daily periodic pattern of the forecast error.",
            "where  l k  (  ; y ) = log   p  ( y | k ,  ) subscript l k  y log  p conditional y k  l_{k}(\\bm{\\theta};\\mathbf{y})=\\text{log }p(\\mathbf{y}|k,\\bm{\\theta}) italic_l start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_ ; bold_y ) = log italic_p ( bold_y | italic_k , bold_italic_ )  is the log-likelihood of  y y \\mathbf{y} bold_y  under a given kernel  k k k italic_k  calculated in Equation ( 6 ),   ^ ^  \\hat{\\bm{\\theta}} over^ start_ARG bold_italic_ end_ARG  is the maximum likelihood estimate (MLE) of  l k  (  ; y ) subscript l k  y l_{k}(\\bm{\\theta};\\mathbf{y}) italic_l start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_ ; bold_y ) ,  |  ^ w S | subscript ^  subscript w S |\\hat{\\bm{\\theta}}_{w_{S}}| | over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT end_POSTSUBSCRIPT |  (respectively  |  ^ w T | subscript ^  subscript w T |\\hat{\\bm{\\theta}}_{w_{T}}| | over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUBSCRIPT | ) is the number of estimated spatial (temporal) warping hyperparameters and  |  ^ k | subscript ^  k |\\hat{\\bm{\\theta}}_{k}| | over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT |  is the number of trained kernel hyperparameters. In a conventional BIC definition, the penalty term reflects the number of parameters in the model and the number of data points. In ( 14 ) we modify it to account for the fact that training days are i.i.d. and hence do not impact model complexity. The penalty terms are thus: the first term penalizes the parameters associated with spatial warping and the number of spatial locations ( M M M italic_M ); the second one penalizes the parameters related to temporal warping and the number of hours ( T T T italic_T ); the third term penalizes the kernel parameters and the product  M  T M T MT italic_M italic_T , which represents the number of location-hour combinations and determines the size of the GP covariance matrix.",
            "In the first synthetic example, we focus on comparing various spatial kernel choices. The primary objective is to understand to what extent it is possible to distinguish and identify the true spatial kernel based on a synthetic dataset that is similar to our test one. Specifically, we generate a synthetic dataset for 27 locations  s j subscript s j \\mathbf{s}_{j} bold_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT  under a separable, isotropic kernel setting, with the temporal kernel set to be Matern-3/2 (denoted as M32) and the spatial kernel  M M M italic_M  one of Squared Exponential (SE), Matern-5/2 (M52), Matern-3/2 (M32), Matern-1/2 (M12) families, i.e.,  M  { SE, M52, M32, M12 } M SE, M52, M32, M12 M\\in\\{\\text{SE, M52, M32, M12}\\} italic_M  { SE, M52, M32, M12 } , discussed in Section  3.1 . The 27 locations are a subset of the West zone in ERCOT, with 25 used for training and 2 for testing. The ground-truth generative distribution is",
            "Table  A.2  and  A.1  in the Appendix shows the true and model training loss, as well as the estimated parameters including lengthscales   ^ = (  T ,  S ) ^  subscript  T subscript  S \\hat{\\bm{\\rho}}=(\\rho_{T},\\rho_{S}) over^ start_ARG bold_italic_ end_ARG = ( italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT )  and variance   ^ ^  \\hat{\\eta} over^ start_ARG italic_ end_ARG  across these 16 testbeds. Across all four simulated datasets, models employing the same kernel as the data-generating process,  M True = M Model subscript M True subscript M Model M_{\\text{True}}=M_{\\text{Model}} italic_M start_POSTSUBSCRIPT True end_POSTSUBSCRIPT = italic_M start_POSTSUBSCRIPT Model end_POSTSUBSCRIPT  outperform the other three, achieving the lowest training loss. Notably, the SE, M52, and M32 demonstrate comparable training losses when the true and model kernels are among these three. However, when the true spatial kernel is M12, models using the other three kernels exhibit significantly higher training loss values. All 16 trained models successfully recover the nugget term   2 superscript  2 \\sigma^{2} italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT .",
            "The synthetic data is simulated for the same 27 locations in Section  5.1  in the West zone of ERCOT, maintaining the same setup except for adding spatial nonstationary through a known warping:",
            "Case Study  W 1 subscript W 1 W_{1} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT : Single Warping Layer.  In this case study, we aim to demonstrate that incorporating a warping structure effectively addresses data nonstationarity. Simulation data is generated by sampling from a GP with a single RBF warping unit (see Equation ( 11 )) for spatial locations only,  g  ( s ) = g rbf  ( s ) g s subscript g rbf s g(\\mathbf{s})=g_{\\text{rbf}}(\\mathbf{s}) italic_g ( bold_s ) = italic_g start_POSTSUBSCRIPT rbf end_POSTSUBSCRIPT ( bold_s ) .",
            "with  g 1 subscript g 1 g_{1} italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and  g 2 subscript g 2 g_{2} italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  as in ( 11 ); the respective warping parameters  ( w 1 , w 2 ,  1 ,  2 , a ) superscript w 1 superscript w 2 superscript  1 superscript  2 a (\\mathbf{w}^{1},\\mathbf{w}^{2},\\bm{\\gamma}^{1},\\bm{\\gamma}^{2},\\mathbf{a}) ( bold_w start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , bold_w start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , bold_italic_ start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , bold_italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , bold_a )  and three kernel hyperparameters  (  ,  T ,  S )  subscript  T subscript  S (\\eta,\\rho_{T},\\rho_{S}) ( italic_ , italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT )  are in Table  A.4  in the Appendix.",
            "Augmented with a periodic term, the temporal kernel is set to be M32 warped by a one-dimensional RBF unit. The spatial kernel is set to SE or M12 based on the synthetic results discussed in Section  5.1 . To address spatial nonstationarity, we incorporate 1-3 two-dimensional RBF units into the spatial warping. In total, we build 10 models with different spatial kernel choices and warping structures, shown in Table  3 .",
            "An important use case of area-wide wind scenarios is bottom-up modeling of  zonal  renewable generation which drives respective financial markets of zonal price indices and ancillary services. A joint probabilistic model of locational generation can be naturally summed across multiple assets to obtain consistent scenarios of aggregated production. As an illustration, Figure  10  visualizes such simulations for the aggregated power ratios in the Far West and North zones of ERCOT. These simulations are obtained by first simulating individual assets like in Figure  9  and then summing and re-normalizing in terms of zonal nameplate capacity across the given ERCOT zone.",
            "In Figure  10 , we sample scenarios from the joint distribution of asset wind power ratios given the day-ahead forecast only. After doing a weighted average to compute the zonal power ratio, the figure shows the mean of 1000 simulations, several respective quantile bands, as well as the hourly zonal forecast  p ~ F superscript ~ p F \\tilde{p}^{F} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT  and the actual generation ratio  p ~ A superscript ~ p A \\tilde{p}^{A} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT . Since the scenarios represent zonal generation based solely on the day-ahead forecast, the scenario mean is roughly the forecast plus the average  y     y \\bar{y} over  start_ARG italic_y end_ARG  within the zone. Compared to the asset-level Figure  9 , we observe much tighter uncertainty bands and lower RMSEs at the zonal level thanks to spatial averaging. The standard deviation of the zone-level scenario is about 10-12% around the forecast, yielding an 80% interval band of approximately 0.2-0.3."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Comparison of model performances on the test set.",
        "table": "S3.T1.18",
        "footnotes": [],
        "references": [
            "The motivating dataset, described in more detail in Sections  2  and  6 , has been recently created by several other teams as part of the ARPA-E PERFORM Data Plan suite  [ 53 ] . Its setting is tailored to the purposes of daily electric grid operations and implies several notable differences compared to standard spatiotemporal statistical setups. First, it directly reports hourly power generation in megawatt-hours (MWh), rather than wind speed. Hence, it operates in energy units rather than meteorological quantities. Second, the dataset provides not only the realized generation but also respective day-ahead point forecasts. These forecasts are produced daily and make the paired forecast-actuals no longer a time-series but a sequence of daily blocks. This pairing reflects the reality that the primary grid uncertainty quantification is conditional on the latest available weather forecast and is done once a day. Third, the provided measurements are hourly (with no missing dates), and are only available at wind farm locations, forming a highly irregular and non-uniform spatial pattern.",
            "The rest of the paper is organized as follows. Section  2  introduces our Texas wind power dataset and the data preprocessing procedure. Section  3  provides a summary of model details, including a review of spatiotemporal Gaussian Processes, kernel structures and the input warping technique. In Section  4  we summarize various evaluation metrics for model predictive performance. Section  5  discusses synthetic results about kernel choice and warping recovery. Results for the Texas dataset and model-based simulations are in Section  6 ; Section  7  concludes.",
            "We focus on modeling the forecast errors  y m , j , n subscript y m j n y_{m,j,n} italic_y start_POSTSUBSCRIPT italic_m , italic_j , italic_n end_POSTSUBSCRIPT  defined below in Equation ( 2 ). We first compute the difference between the forecasted and actual power ratios:",
            "and then center the  y ~ ~ y \\tilde{y} over~ start_ARG italic_y end_ARG s to ensure their mean is zero. In general, forecasts are biased. For example, on a calm day the wind forecast is essentially zero, while the actual production is non-negative, so on average will be higher than the forecast, see Figure  2 a. To center  y ~  subscript ~ y  \\tilde{y}_{\\cdot} over~ start_ARG italic_y end_ARG start_POSTSUBSCRIPT  end_POSTSUBSCRIPT  we randomly divide the dataset days into a training set and a testing set. The training set includes all 181 locations with 80% of samples (24 hours across 87 days) while the testing set has 37 locations, 22 days. For each location  m m m italic_m , we compute the mean,  y   m subscript   y m \\bar{{y}}_{m} over  start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT  over a period of 24 hours across 87 days in the training set. Then we get the forecast error as:",
            "Compared to the actual and forecast data, the forecast error rarely reaches the bounds and exhibits a symmetric distribution. The typical standard deviation of forecast errors ranges between 0.135 and 0.268, with an average value of approximately 0.188. The distribution of forecast errors tends to have a slight right skew on average, with about 87% of the locations exhibiting positive skewness. This results in a distribution that more closely approximates a Gaussian distribution, better aligning with the assumptions of GP than the original datasets. Figure  2 b presents the forecast errors for the selected wind farm over the same time period as depicted in Figure  2 a.",
            "where  Y n = ( Y 1 , 1 , n , Y 1 , 2 , n , ... , Y 1 , T , n , ... . , Y M , T , n )  \\mathbf{Y}_{n}=(Y_{1,1,n},Y_{1,2,n},...,Y_{1,T,n},....,Y_{M,T,n})^{\\top} bold_Y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = ( italic_Y start_POSTSUBSCRIPT 1 , 1 , italic_n end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT 1 , 2 , italic_n end_POSTSUBSCRIPT , ... , italic_Y start_POSTSUBSCRIPT 1 , italic_T , italic_n end_POSTSUBSCRIPT , ... . , italic_Y start_POSTSUBSCRIPT italic_M , italic_T , italic_n end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  n = 1 , 2 , ... , N n 1 2 ... N n=1,2,...,N italic_n = 1 , 2 , ... , italic_N , and   2 superscript  2 \\sigma^{2} italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT  is the nugget hyperparameter, representing the variance of the observation noise. The prior mean function    (  )   \\mu(\\cdot) italic_ (  )  is set to be zero since we centered the forecast error by each location to have mean zero in the data preprocessing step. The covariance matrix  K K \\mathbf{K} bold_K  is decided by the structure of kernel  k  (  ,  ) k   k(\\cdot,\\cdot) italic_k (  ,  )  and GP hyperparameters    \\bm{\\theta} bold_italic_ . Section  3.1  reviews spatiotemporal GP and kernels. The statistical inference for our spatiotemporal GP is provided in Section  3.2 . In Section  3.3  we review and summarize the input warping technique and its applications in our analysis.",
            "When constructing the warping structure, unlike Zammit et al.  [ 62 ]  and Vu et al.  [ 56 ] , which fix all warping hyperparameters, we fit them as part of the model training process. To simplify inference, we restrict attention to warping via RBF units  g rbf subscript g rbf g_{\\text{rbf}} italic_g start_POSTSUBSCRIPT rbf end_POSTSUBSCRIPT . The number of warping layers is varied and fine-tuned manually. Thanks to working with a separable kernel, we may independently vary  l S , l T subscript l S subscript l T l_{S},l_{T} italic_l start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  based on the patterns in each input domain. The selection of the number of warping layers must also consider model complexity, as each layer introduces multiple parameters to be learned. In Section  5.2 , we validate the above logic using synthetic examples to show the impact of the warping function  g  (  ) g  g(\\cdot) italic_g (  )  structure on model performance.",
            "In this section, we summarize several evaluation metrics for model selection and predictive performance. To evaluate the appropriateness of model choices, we use a modified Bayesian Information Criterion (BIC) to quantify both the model performance on the training dataset and the complexity of the model. To evaluate model performance on the test set, we use the root mean squared error (RMSE) for point prediction and probabilistic forecast assessment methods introduced in Section  4.2  for probabilistic prediction. Let  y y \\mathbf{y} bold_y ,  y  superscript y \\mathbf{y}^{*} bold_y start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  denote observations in the training and testing dataset,  M M M italic_M  and  T T T italic_T  the number of training spatial locations and training temporal hours and  M  , T  superscript M superscript T M^{*},T^{*} italic_M start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , italic_T start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  the number of test locations and test hours.",
            "Table  A.2  and  A.1  in the Appendix shows the true and model training loss, as well as the estimated parameters including lengthscales   ^ = (  T ,  S ) ^  subscript  T subscript  S \\hat{\\bm{\\rho}}=(\\rho_{T},\\rho_{S}) over^ start_ARG bold_italic_ end_ARG = ( italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT )  and variance   ^ ^  \\hat{\\eta} over^ start_ARG italic_ end_ARG  across these 16 testbeds. Across all four simulated datasets, models employing the same kernel as the data-generating process,  M True = M Model subscript M True subscript M Model M_{\\text{True}}=M_{\\text{Model}} italic_M start_POSTSUBSCRIPT True end_POSTSUBSCRIPT = italic_M start_POSTSUBSCRIPT Model end_POSTSUBSCRIPT  outperform the other three, achieving the lowest training loss. Notably, the SE, M52, and M32 demonstrate comparable training losses when the true and model kernels are among these three. However, when the true spatial kernel is M12, models using the other three kernels exhibit significantly higher training loss values. All 16 trained models successfully recover the nugget term   2 superscript  2 \\sigma^{2} italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT .",
            "Next, we evaluate 16 trained models on our test set, presented in Table  A.2  and  A.3  in the Appendix. The SE, M52, and M32 kernels present similar test RMSE values when both the true and model kernels are among these three. However, a model using the M12 kernel has a higher testing RMSE when the true kernel is among the other three. Furthermore, when the true kernel is M12, models employing the other three kernels display significantly higher RMSE values. In terms of probabilistic predictive performance, we confirm the consistent pattern that the M12 kernel exhibits a different performance pattern compared to the other three.",
            "The top half of Table  2  summarizes model performances on the test set. The model with warping structure,  W 1 ( M 1 ) superscript subscript W 1 subscript M 1 W_{1}^{(M_{1})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT , shows enhanced accuracy in both point and probabilistic predictions, evidenced by a lower test RMSE, lower average IS and a higher KS test p-value. In sum, incorporating the warping structure substantially improves both goodness-of-fit and testing performance and hence is effective in mitigating data covariance nonstationarity.",
            "Regarding performance on the test set, models with warping outperform the model without warping across most metrics, see bottom half of Table  2 . Furthermore, the one-layer model  W 2 ( M 1 ) superscript subscript W 2 subscript M 1 W_{2}^{(M_{1})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  exhibits comparable performance to the two-layer  W 2 ( M 2 ) superscript subscript W 2 subscript M 2 W_{2}^{(M_{2})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  while maintaining reduced model complexity.",
            "Temporally, warping yields a contraction centered around noon. Hence, mid-day hours are more correlated relative to morning or evening hours. Figure  A.2  in the Appendix shows the corresponding temporal correlation of M12-2-1 relative to 4 AM. Moving away from the reference hour, the correlation first drops rapidly and then slowly decreases to zero because of the periodic effect. Decorrelation occurs after approximately 6 hours: the estimated temporal lengthscale   T = 0.10 subscript  T 0.10 \\rho_{T}=0.10 italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 0.10  corresponds to about 2.5 hours; for M32 kernel decorrelation is achieved roughly beyond two lengthscales."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Model performance for the ERCOT wind dataset across different kernels and warping choices. The first column presents the model setting. For example, in SE-0-1, the spatial warping kernel is SE, with no spatial warping layer and one temporal warping layer.",
        "table": "S5.T2.27",
        "footnotes": [],
        "references": [
            "The rest of the paper is organized as follows. Section  2  introduces our Texas wind power dataset and the data preprocessing procedure. Section  3  provides a summary of model details, including a review of spatiotemporal Gaussian Processes, kernel structures and the input warping technique. In Section  4  we summarize various evaluation metrics for model predictive performance. Section  5  discusses synthetic results about kernel choice and warping recovery. Results for the Texas dataset and model-based simulations are in Section  6 ; Section  7  concludes.",
            "We next explore the stylized features of the covariance structure in the resulting dataset of forecast errors  y y y italic_y  across 181 distinct locations over 24 hours. As mentioned, different days are treated as i.i.d. samples of the space-time field  y m , j ,  subscript y m j  y_{m,j,\\cdot} italic_y start_POSTSUBSCRIPT italic_m , italic_j ,  end_POSTSUBSCRIPT . To determine whether we can model the covariance structure within the spatial and temporal dimensions separately, we assess if variations in the temporal domain are independent of spatial variations. This is accomplished by constructing autocorrelation plots across different time lags for each spatial location. Our findings, depicted in Figure  3 , show a consistent pattern across all locations, with autocorrelation rapidly decreasing for lags less than 8-10 hours, and then increasing for lags over 12 hours. The consistent pattern across regions suggests a limited interdependence, supporting our use of a separable structure for the spatial and temporal variations.",
            "To recap, we validate using a separable covariance structure across time and space components but must address nonstationarity in both dimensions, as well as a periodic covariance pattern in time. We also emphasize that the spatial input dimension is continuous,  s  R 2 s superscript R 2 \\mathbf{s}\\in\\mathbb{R}^{2} bold_s  blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , while the temporal dimension is gridded with each unit representing an hour,  t  { 0 : 00 , 1 : 00 , ... , 23 : 00 } t conditional-set 0 : 00 1 00 ... 23 : 00 t\\in\\{0:00,1:00,...,23:00\\} italic_t  { 0 : 00 , 1 : 00 , ... , 23 : 00 } . The next section lays out our spatiotemporal GP model capturing this features with the ultimate formulation and discussion in Section  3.4 .",
            "Let  X X \\mathcal{X} caligraphic_X  represent our input domain, and  x = ( s , t ) x s t \\mathbf{x}=(\\mathbf{s},t) bold_x = ( bold_s , italic_t )  denote an input point. To mitigate disparities in data scales across input domains, space and time, all dimensions of  x x \\mathbf{x} bold_x  are normalized to the range  ( 0 , 1 ) 0 1 (0,1) ( 0 , 1 )  without reaching the bounds. This normalization facilitates the warping effect at the boundaries, which will be discussed in Section  3.3 . Notably, the spatial domain includes two coordinates: longitude and latitude. The normalization process is conducted while preserving the proportional relationship of spatial distances between locations. Consequently, pairs of locations equidistant in physical space maintain an equivalent distance in the normalized spatial domain.",
            "where  Y n = ( Y 1 , 1 , n , Y 1 , 2 , n , ... , Y 1 , T , n , ... . , Y M , T , n )  \\mathbf{Y}_{n}=(Y_{1,1,n},Y_{1,2,n},...,Y_{1,T,n},....,Y_{M,T,n})^{\\top} bold_Y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = ( italic_Y start_POSTSUBSCRIPT 1 , 1 , italic_n end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT 1 , 2 , italic_n end_POSTSUBSCRIPT , ... , italic_Y start_POSTSUBSCRIPT 1 , italic_T , italic_n end_POSTSUBSCRIPT , ... . , italic_Y start_POSTSUBSCRIPT italic_M , italic_T , italic_n end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  n = 1 , 2 , ... , N n 1 2 ... N n=1,2,...,N italic_n = 1 , 2 , ... , italic_N , and   2 superscript  2 \\sigma^{2} italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT  is the nugget hyperparameter, representing the variance of the observation noise. The prior mean function    (  )   \\mu(\\cdot) italic_ (  )  is set to be zero since we centered the forecast error by each location to have mean zero in the data preprocessing step. The covariance matrix  K K \\mathbf{K} bold_K  is decided by the structure of kernel  k  (  ,  ) k   k(\\cdot,\\cdot) italic_k (  ,  )  and GP hyperparameters    \\bm{\\theta} bold_italic_ . Section  3.1  reviews spatiotemporal GP and kernels. The statistical inference for our spatiotemporal GP is provided in Section  3.2 . In Section  3.3  we review and summarize the input warping technique and its applications in our analysis.",
            "Presuming an isotropic structure enables more concise parameterizations of the kernel function. However, it may not adequately capture the variation patterns in real-world spatial and temporal data. To address this limitation, we propose a solution involving the mapping of the original input space to a latent space, where stationarity is maintained. This is achieved through the application of input warping on both space and time, as discussed in Section  3.3 .",
            "Considering our model as specified in Equations ( 3 ) and ( 4 ) with hyperparameters    \\bm{\\theta} bold_italic_ , the likelihood function of observed data  y y \\mathbf{y} bold_y  across  M M M italic_M  different spatial locations and  T T T italic_T  hours in  N N N italic_N  days is:",
            "Since autocorrelation is closely connected to the covariance, the temporal kernel  k temporal subscript k temporal k_{\\text{temporal}} italic_k start_POSTSUBSCRIPT temporal end_POSTSUBSCRIPT  should emulate the pattern depicted in Figure  3 . To capture this shape, we adopt a Matern kernel augmented with a periodic component,",
            "To train our GP model, we maximize the log-likelihood in Equation ( 7 ). Table  1  summarizes the parameters of the GP kernel, warping, and nugget:   := (  k ,  w ,  2 ) assign  subscript  k subscript  w superscript  2 \\bm{\\theta}:=({\\bm{\\theta}}_{k},{\\bm{\\theta}}_{w},{\\sigma}^{2}) bold_italic_ := ( bold_italic_ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , bold_italic_ start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT , italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) , specifying whether they are involved in the training step and outlining the constraints imposed during the optimization process. We build isotropic spatial kernels from the Matern family, and a Matern plus periodic kernel ( 13 ) for temporal kernels. Therefore, we have 6 kernel parameters   k = (  ,  S ,  T ,  p ,  p , p ) subscript  k  subscript  S subscript  T subscript  p subscript  p p \\bm{\\theta}_{k}=(\\eta,\\rho_{S},\\rho_{T},\\eta_{p},\\rho_{p},p) bold_italic_ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = ( italic_ , italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_p ) :    \\eta italic_  signifies the overall variance of our spatiotemporal GP, while  (  S ,  T ) subscript  S subscript  T (\\rho_{S},\\rho_{T}) ( italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT )  serve as range parameters representing smoothness characteristics of the spatial and temporal dimensions; parameters within the temporal kernels periodic component  (  p ,  p , p ) subscript  p subscript  p p (\\eta_{p},\\rho_{p},p) ( italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_p )  are designed to account for the daily periodic pattern of the forecast error.",
            "In the first synthetic example, we focus on comparing various spatial kernel choices. The primary objective is to understand to what extent it is possible to distinguish and identify the true spatial kernel based on a synthetic dataset that is similar to our test one. Specifically, we generate a synthetic dataset for 27 locations  s j subscript s j \\mathbf{s}_{j} bold_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT  under a separable, isotropic kernel setting, with the temporal kernel set to be Matern-3/2 (denoted as M32) and the spatial kernel  M M M italic_M  one of Squared Exponential (SE), Matern-5/2 (M52), Matern-3/2 (M32), Matern-1/2 (M12) families, i.e.,  M  { SE, M52, M32, M12 } M SE, M52, M32, M12 M\\in\\{\\text{SE, M52, M32, M12}\\} italic_M  { SE, M52, M32, M12 } , discussed in Section  3.1 . The 27 locations are a subset of the West zone in ERCOT, with 25 used for training and 2 for testing. The ground-truth generative distribution is",
            "Next, we evaluate 16 trained models on our test set, presented in Table  A.2  and  A.3  in the Appendix. The SE, M52, and M32 kernels present similar test RMSE values when both the true and model kernels are among these three. However, a model using the M12 kernel has a higher testing RMSE when the true kernel is among the other three. Furthermore, when the true kernel is M12, models employing the other three kernels display significantly higher RMSE values. In terms of probabilistic predictive performance, we confirm the consistent pattern that the M12 kernel exhibits a different performance pattern compared to the other three.",
            "Augmented with a periodic term, the temporal kernel is set to be M32 warped by a one-dimensional RBF unit. The spatial kernel is set to SE or M12 based on the synthetic results discussed in Section  5.1 . To address spatial nonstationarity, we incorporate 1-3 two-dimensional RBF units into the spatial warping. In total, we build 10 models with different spatial kernel choices and warping structures, shown in Table  3 .",
            "Figure  8  visualizes the warping effects of the selected M12-2-1 model. The transformation on the spatial domain is performed around two locations in central and western Texas, expanding the southern part of Great Plains while condensing the northern Great Plains, North Central Plains, as well as the southern Gulf Coast plains. Distances within the southern part of the Far West and West regions are stretched, while those within the South, North, North Central and rest of Far West and West regions are squeezed. Figure  A.3  in the Appendix illustrates the spatial correlation between two reference assets, Aguayo and Whirlwind, and other locations across Texas. The contour lines represent levels of correlation; due to the warping effects, different locations exhibit varying correlation patterns in their neighborhood. The correlation for the Aguayo wind farm drops off more sharply along the latitude, particularly to the south. We also observe compressed correlation to the west of Aguayo compared to its east. In contrast, Whirlwind is far from the fitted warping centers   ^ 1 , 2 subscript ^  1 2 \\hat{\\bm{\\gamma}}_{1,2} over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT  and as a result the respective neighborhood correlation pattern is nearly elliptical, decreasing at a similar rate in all directions.",
            "To validate the consistency of model performance, we adopt a cross-validation method, randomly dividing the 181 locations into leave-one-out folds. Specifically, we train 5 models that use 4 out of the 5 folds for training and the fifth one as the test set. The five train-test splits differ from those for Table  3  to ensure the replicability of our results under the same model setting. All of them follow the M12-2-1 model structure: an M12 spatial kernel and M32 plus periodic temporal kernel, with one RBF warping layer in the temporal domain and two layers in the spatial domain. Note that comparing BIC values across folds is equivalent to comparing their training loss.",
            "Table  4  presents the performance across the five folds. The model variances    \\eta italic_  are in the range  [ 0.040 , 0.52 ] 0.040 0.52 [0.040,0.52] [ 0.040 , 0.52 ] ; lengthscales   T subscript  T \\rho_{T} italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  around 0.1 and   S subscript  S \\rho_{S} italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT  around  0.06  0.01 plus-or-minus 0.06 0.01 0.06\\pm 0.01 0.06  0.01 , consistent with the M12-2-1 row in Table  3 . Hence, the recovered GP hyperparameters are meaningful and stable as the training set is varied. The performance metrics are also consistent across the different train-test splits, with fold #2 being somewhat of an outlier (cf. its higher    \\sigma italic_  estimate and worse coverage, KS statistic and interval score).",
            "Figure  9  shows the hourly-based single-asset simulations for Aguayo and Whirlwind assets, located in the North Central and North regions respectively, on a couple of representative days in the testing set. The figure shows the original forecast  p ~ m  ,  , d  F subscript superscript ~ p F superscript m  superscript d \\tilde{p}^{F}_{m^{*},\\cdot,d^{*}} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , the actual wind power ratio  p ~ s  ,  , d  A subscript superscript ~ p A superscript s  superscript d \\tilde{p}^{A}_{s^{*},\\cdot,d^{*}} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_s start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , and the mean of GP-based simulations. We also plot the model quantile bands at levels   = 0.10 , 0.20 , 0.50  0.10 0.20 0.50 \\alpha=0.10,0.20,0.50 italic_ = 0.10 , 0.20 , 0.50 , calculated by sorting the hourly simulated values and then saving the respective  1   2  100 %  1  2 percent 100 \\frac{1-\\alpha}{2}\\cdot 100\\% divide start_ARG 1 - italic_ end_ARG start_ARG 2 end_ARG  100 %  and  1 +  2  100 %  1  2 percent 100 \\frac{1+\\alpha}{2}\\cdot 100\\% divide start_ARG 1 + italic_ end_ARG start_ARG 2 end_ARG  100 %  quantiles. Since the GP model generates forecast errors relative to  p ~ F superscript ~ p F \\tilde{p}^{F} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT , we clip the resulting  Y m  , t , d  + p ~ t F + y   m  subscript Y superscript m t superscript d subscript superscript ~ p F t subscript   y superscript m Y_{m^{*},t,d^{*}}+\\tilde{p}^{F}_{t}+\\bar{y}_{m^{*}} italic_Y start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , italic_t , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT + over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + over  start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  to ensure it falls within  [ 0 , 1 ] 0 1 [0,1] [ 0 , 1 ] . We observe that the 10-90% quantile band is roughly 0.6 in width, i.e., the production ratio is often   30 % plus-or-minus percent 30 \\pm 30\\%  30 %  above or below the predicted mean calculated from the forecast. Also, for about 70-80% of the hours, the realized generation is within the 10-90th quantile band, which is consistent with the coverage estimates shown in Table  3 .",
            "For assets that are only weakly influenced by the training locations, such as Aguayo (which is relatively far from most training locations and hence is correlated to only a few of them, see the left panel of Figure  A.3 ), the predictive distribution has a mean   ^ m  , t , d  subscript ^  superscript m t superscript d \\hat{\\mu}_{m^{*},t,d^{*}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , italic_t , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  close to zero. Hence, the scenario mean is effectively the forecast  p ~ m  ,  , d  F subscript superscript ~ p F superscript m  superscript d \\tilde{p}^{F}_{m^{*},\\cdot,d^{*}} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  plus  y   m  subscript   y superscript m \\bar{y}_{m^{*}} over  start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , see the almost constant gap between the blue and green curves in the left and middle panels of Figure  9  (in Aguayos case, the average forecast error  y   m  subscript   y superscript m \\bar{y}_{m^{*}} over  start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  is highly positive). In contrast, for assets that are highly correlated with observed locations, such as Whirlwind (see right panel of Figure  A.3 ), more information is obtained from the observed data and   ^ m  , t , d  subscript ^  superscript m t superscript d \\hat{\\mu}_{m^{*},t,d^{*}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , italic_t , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  has a non-trivial shape. Thus, the difference between the scenario mean and forecast is influenced by both  y   m  subscript   y superscript m \\bar{y}_{m^{*}} over  start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and the predictive mean. Moreover, thanks to information fusion we observe notable improvement in predictive performance (scenarios closer to actuals compared to forecast) as well as tighter predictive bands."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Cross-validated training and testing results. Each folded model is trained using 80% of the locations and uses the rest 20% as the testing set.",
        "table": "S6.T3.96",
        "footnotes": [],
        "references": [
            "The rest of the paper is organized as follows. Section  2  introduces our Texas wind power dataset and the data preprocessing procedure. Section  3  provides a summary of model details, including a review of spatiotemporal Gaussian Processes, kernel structures and the input warping technique. In Section  4  we summarize various evaluation metrics for model predictive performance. Section  5  discusses synthetic results about kernel choice and warping recovery. Results for the Texas dataset and model-based simulations are in Section  6 ; Section  7  concludes.",
            "Naturally, locations that are closer together tend to experience more similar weather and wind and hence have more correlated  y y y italic_y s. This suggests that spatial covariance of  y  , t subscript y  t y_{\\cdot,t} italic_y start_POSTSUBSCRIPT  , italic_t end_POSTSUBSCRIPT  is linked to the respective spatial distance. A graphical representation of the spatial dependence of the data is provided by the variogram  [ 10 ] . For a dataset with a stationary spatial covariance structure, the variogram initially increases, indicating increasing dissimilarity with increasing distance between points, and then stabilizes asymptotically as the distance grows. In the real world, pairs of locations that share the same spatial distance may not necessarily exhibit the same level of similarity due to variations in the natural landscape. For example, the correlation between data from two wind farms built on mountains is likely to differ from that between two wind farms built on plains. Figure  4(a) , visualizes the variogram of our forecast error data versus spatial distances. For two locations  s 1 subscript s 1 \\mathbf{s}_{1} bold_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and  s 2 subscript s 2 \\mathbf{s}_{2} bold_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  in the normalized spatial domain, we construct the  ( d , v ) d v (d,v) ( italic_d , italic_v )  pair by first taking the  L 2 subscript L 2 L_{2} italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  norm between them,  d =  s 1  s 2  2 d subscript norm subscript s 1 subscript s 2 2 d=\\|\\mathbf{s}_{1}-\\mathbf{s}_{2}\\|_{2} italic_d =  bold_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ; then we compute the sample variance by taking the mean squared difference  v = 1 N  T   n = 1 N  t = 1 T ( y 1 , t , n  y 2 , t , n ) 2 v 1 N T superscript subscript n 1 N superscript subscript t 1 T superscript subscript y 1 t n subscript y 2 t n 2 v=\\frac{1}{NT}\\sum_{n=1}^{N}\\sum_{t=1}^{T}(y_{1,t,n}-y_{2,t,n})^{2} italic_v = divide start_ARG 1 end_ARG start_ARG italic_N italic_T end_ARG  start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( italic_y start_POSTSUBSCRIPT 1 , italic_t , italic_n end_POSTSUBSCRIPT - italic_y start_POSTSUBSCRIPT 2 , italic_t , italic_n end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , across days  n = 1 , ... , N n 1 ... N n=1,\\ldots,N italic_n = 1 , ... , italic_N  and hours  t = 1 , ... , T t 1 ... T t=1,\\ldots,T italic_t = 1 , ... , italic_T . It is evident that the spatial variation does not exhibit a consistent pattern, since for a given spatial distance we observe widely different variogram values. This suggests that the data variation within the space dimension is not solely determined by the spatial distance between two locations. This observation highlights a significant spatial nonstationarity within our dataset, thus representing a primary challenge in our modeling analysis.",
            "Switching to the temporal dimension, the temporal variogram is shown in Figure  4(b) . For two time points  t 1 subscript t 1 t_{1} italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and  t 2 subscript t 2 t_{2} italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  in the normalized temporal domain, we construct  ( d , v ) d v (d,v) ( italic_d , italic_v )  pair by taking the  L 1 subscript L 1 L_{1} italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  norm between them,  d =  t 1  t 2  1 d subscript norm subscript t 1 subscript t 2 1 d=\\|t_{1}-t_{2}\\|_{1} italic_d =  italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and then computing the sample variance by taking the mean squared difference  v = 1 N  M   n = 1 N  m = 1 M ( y m , t 1 , n  y m , t 2 , n ) 2 v 1 N M superscript subscript n 1 N superscript subscript m 1 M superscript subscript y m subscript t 1 n subscript y m subscript t 2 n 2 v=\\frac{1}{NM}\\sum_{n=1}^{N}\\sum_{m=1}^{M}(y_{m,t_{1},n}-y_{m,t_{2},n})^{2} italic_v = divide start_ARG 1 end_ARG start_ARG italic_N italic_M end_ARG  start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT italic_m = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT ( italic_y start_POSTSUBSCRIPT italic_m , italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_n end_POSTSUBSCRIPT - italic_y start_POSTSUBSCRIPT italic_m , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_n end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , across days  n = 1 , ... , N n 1 ... N n=1,\\ldots,N italic_n = 1 , ... , italic_N  and locations  m = 1 , ... , M m 1 ... M m=1,\\ldots,M italic_m = 1 , ... , italic_M . Two distinct patterns of data variation are clearly visible when the temporal distance is within the range  [ 0.2 , 0.4 ] 0.2 0.4 [0.2,0.4] [ 0.2 , 0.4 ] . This indicates that the temporal covariance structure cannot be adequately described solely by time difference.",
            "To recap, we validate using a separable covariance structure across time and space components but must address nonstationarity in both dimensions, as well as a periodic covariance pattern in time. We also emphasize that the spatial input dimension is continuous,  s  R 2 s superscript R 2 \\mathbf{s}\\in\\mathbb{R}^{2} bold_s  blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , while the temporal dimension is gridded with each unit representing an hour,  t  { 0 : 00 , 1 : 00 , ... , 23 : 00 } t conditional-set 0 : 00 1 00 ... 23 : 00 t\\in\\{0:00,1:00,...,23:00\\} italic_t  { 0 : 00 , 1 : 00 , ... , 23 : 00 } . The next section lays out our spatiotemporal GP model capturing this features with the ultimate formulation and discussion in Section  3.4 .",
            "Considering our model as specified in Equations ( 3 ) and ( 4 ) with hyperparameters    \\bm{\\theta} bold_italic_ , the likelihood function of observed data  y y \\mathbf{y} bold_y  across  M M M italic_M  different spatial locations and  T T T italic_T  hours in  N N N italic_N  days is:",
            "Our model implementation utilizes Python and the  PyTorch  framework. The synthetic studies in Section  5  and real data analyses in Section  6  were executed on a 2021 MacBook Pro, featuring the Apple M1 Pro chip and 16 GB of memory. The trained models are evaluated using metrics discussed in Section  4 .",
            "In this section, we summarize several evaluation metrics for model selection and predictive performance. To evaluate the appropriateness of model choices, we use a modified Bayesian Information Criterion (BIC) to quantify both the model performance on the training dataset and the complexity of the model. To evaluate model performance on the test set, we use the root mean squared error (RMSE) for point prediction and probabilistic forecast assessment methods introduced in Section  4.2  for probabilistic prediction. Let  y y \\mathbf{y} bold_y ,  y  superscript y \\mathbf{y}^{*} bold_y start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  denote observations in the training and testing dataset,  M M M italic_M  and  T T T italic_T  the number of training spatial locations and training temporal hours and  M  , T  superscript M superscript T M^{*},T^{*} italic_M start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , italic_T start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  the number of test locations and test hours.",
            "where  l k  (  ; y ) = log   p  ( y | k ,  ) subscript l k  y log  p conditional y k  l_{k}(\\bm{\\theta};\\mathbf{y})=\\text{log }p(\\mathbf{y}|k,\\bm{\\theta}) italic_l start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_ ; bold_y ) = log italic_p ( bold_y | italic_k , bold_italic_ )  is the log-likelihood of  y y \\mathbf{y} bold_y  under a given kernel  k k k italic_k  calculated in Equation ( 6 ),   ^ ^  \\hat{\\bm{\\theta}} over^ start_ARG bold_italic_ end_ARG  is the maximum likelihood estimate (MLE) of  l k  (  ; y ) subscript l k  y l_{k}(\\bm{\\theta};\\mathbf{y}) italic_l start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_ ; bold_y ) ,  |  ^ w S | subscript ^  subscript w S |\\hat{\\bm{\\theta}}_{w_{S}}| | over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT end_POSTSUBSCRIPT |  (respectively  |  ^ w T | subscript ^  subscript w T |\\hat{\\bm{\\theta}}_{w_{T}}| | over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUBSCRIPT | ) is the number of estimated spatial (temporal) warping hyperparameters and  |  ^ k | subscript ^  k |\\hat{\\bm{\\theta}}_{k}| | over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT |  is the number of trained kernel hyperparameters. In a conventional BIC definition, the penalty term reflects the number of parameters in the model and the number of data points. In ( 14 ) we modify it to account for the fact that training days are i.i.d. and hence do not impact model complexity. The penalty terms are thus: the first term penalizes the parameters associated with spatial warping and the number of spatial locations ( M M M italic_M ); the second one penalizes the parameters related to temporal warping and the number of hours ( T T T italic_T ); the third term penalizes the kernel parameters and the product  M  T M T MT italic_M italic_T , which represents the number of location-hour combinations and determines the size of the GP covariance matrix.",
            "In both case studies, we generate data based on a known spatio-temporal structure, namely a GP with a given kernel. We then fit several variants of our framework and compare the resulting estimated GPs to the ground truth. Models are evaluated according to metrics discussed in Section  4 . For coverage tests, we use reference level of  80 % percent 80 80\\% 80 % ; the interval score is calculated based on the  95 95 95 95 % predictive interval.",
            "Table  A.4  in the Appendix shows the ground truth hyperparameters vis-a-vis the model trained hyperparameters. We build two models:  W 1 ( M 1 ) superscript subscript W 1 subscript M 1 W_{1}^{(M_{1})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  that includes one RBF layer and hence has 9 hyperparameters to train and  W 1 ( M 0 ) superscript subscript W 1 subscript M 0 W_{1}^{(M_{0})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  with no warping, and four hyperparameters. Both of them successfully recover the nugget term. However, model  W 1 ( M 1 ) superscript subscript W 1 subscript M 1 W_{1}^{(M_{1})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  provides a closer estimate of the variance parameter. It also successfully recovers the range parameter values and attains a similar BIC value as  W 1 ( M 0 ) superscript subscript W 1 subscript M 0 W_{1}^{(M_{0})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT , indicating a comparable training performance and thus does not introduce excessive training complexity. For the warping component, Model  W 1 ( M 1 ) superscript subscript W 1 subscript M 1 W_{1}^{(M_{1})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  accurately estimates the hyperparameters in the warping function and successfully reconstructs the warped space, see Table  A.4  and Figure  6(b) .",
            "with  g 1 subscript g 1 g_{1} italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and  g 2 subscript g 2 g_{2} italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  as in ( 11 ); the respective warping parameters  ( w 1 , w 2 ,  1 ,  2 , a ) superscript w 1 superscript w 2 superscript  1 superscript  2 a (\\mathbf{w}^{1},\\mathbf{w}^{2},\\bm{\\gamma}^{1},\\bm{\\gamma}^{2},\\mathbf{a}) ( bold_w start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , bold_w start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , bold_italic_ start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , bold_italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , bold_a )  and three kernel hyperparameters  (  ,  T ,  S )  subscript  T subscript  S (\\eta,\\rho_{T},\\rho_{S}) ( italic_ , italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT )  are in Table  A.4  in the Appendix.",
            "We then train three GP models  W 2 ( M i ) superscript subscript W 2 subscript M i W_{2}^{(M_{i})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT , with  i = 0 , 1 , 2 i 0 1 2 i=0,1,2 italic_i = 0 , 1 , 2  RBF warping layers respectively. All three models utilize a separable kernel with M32 in the time dimension and SE in the space dimension. Consistent with the findings of the first study above, the model  W 2 ( M 0 ) superscript subscript W 2 subscript M 0 W_{2}^{(M_{0})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  that lacks a warping structure mis-estimates the variance and range parameters relative to the ground truth. Although models incorporating warping,  W 2 ( M 2 ) superscript subscript W 2 subscript M 2 W_{2}^{(M_{2})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  and  W 2 ( M 1 ) superscript subscript W 2 subscript M 1 W_{2}^{(M_{1})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT , do not perfectly recover the warped space (see Table  A.4  and the visual comparison of the fitted warping effect in Figure  7 ), both provide close estimates of the kernel hyperparameters. Between them, the one-layer warping model demonstrates better training performance, evidenced by a lower BIC value.",
            "Table  4  presents the performance across the five folds. The model variances    \\eta italic_  are in the range  [ 0.040 , 0.52 ] 0.040 0.52 [0.040,0.52] [ 0.040 , 0.52 ] ; lengthscales   T subscript  T \\rho_{T} italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  around 0.1 and   S subscript  S \\rho_{S} italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT  around  0.06  0.01 plus-or-minus 0.06 0.01 0.06\\pm 0.01 0.06  0.01 , consistent with the M12-2-1 row in Table  3 . Hence, the recovered GP hyperparameters are meaningful and stable as the training set is varied. The performance metrics are also consistent across the different train-test splits, with fold #2 being somewhat of an outlier (cf. its higher    \\sigma italic_  estimate and worse coverage, KS statistic and interval score)."
        ]
    },
    "id_table_5": {
        "caption": "Table A.1:  Estimated kernel parameters, range   ^ = (  ^ T ,  ^ S ) ^  subscript ^  T subscript ^  S \\hat{\\bm{\\rho}}=(\\hat{\\rho}_{T},\\hat{\\rho}_{S}) over^ start_ARG bold_italic_ end_ARG = ( over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT )  and variance   ^ ^  \\hat{\\eta} over^ start_ARG italic_ end_ARG , for the synthetic experiment in Section  5.1 .",
        "table": "S6.T4.45",
        "footnotes": [
            ""
        ],
        "references": [
            "The rest of the paper is organized as follows. Section  2  introduces our Texas wind power dataset and the data preprocessing procedure. Section  3  provides a summary of model details, including a review of spatiotemporal Gaussian Processes, kernel structures and the input warping technique. In Section  4  we summarize various evaluation metrics for model predictive performance. Section  5  discusses synthetic results about kernel choice and warping recovery. Results for the Texas dataset and model-based simulations are in Section  6 ; Section  7  concludes.",
            "Selecting an appropriate kernel function and tuning its hyperparameters are key steps to build the GP model that captures data patterns, as well as make accurate predictions or inferences. In Section  5.1  we employ synthetic examples to assess the efficacy of different kernel choices in our setting.",
            "The weights  w w w italic_w  are limited within  (  1 , 1 2  exp  ( 3 2 ) ) 1 1 2 3 2 (-1,\\frac{1}{2}\\exp(\\frac{3}{2})) ( - 1 , divide start_ARG 1 end_ARG start_ARG 2 end_ARG roman_exp ( divide start_ARG 3 end_ARG start_ARG 2 end_ARG ) )  to ensure injectivity, a positive (resp. negative) weight  w d subscript w d w_{d} italic_w start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT  expands (resp. contracts) dimension  d d d italic_d . The stretching transformation is carried out relative to the center    \\bm{\\gamma} bold_italic_ . The scale  a > 0 a 0 a>0 italic_a > 0  governs the warping resolution, smaller values of  a a a italic_a  allow for more localized deformation. Figure  5  illustrates examples of the warping effect induced by the RBF unit, as described by Equation ( 10 ) in  D = 2 D 2 D=2 italic_D = 2  dimensions: Figures  5(a)  and  5(b)  visualize the warping effect of one RBF unit, Figure  5(c)  depicts warping with two compositional layers. Each layer independently transforms the uniform  ( 0 , 1 )  ( 0 , 1 ) 0 1 0 1 (0,1)\\times(0,1) ( 0 , 1 )  ( 0 , 1 )  grid centered around its respective location. Additionally, the two layers exhibit interaction with each other. The Figures visualize how a greater absolute value of the weight corresponds to a more pronounced deformation impact along the associated axis; similarly a larger value of scale  a a a italic_a  shows a more global contraction (with negative weights  w w \\mathbf{w} bold_w ) or expansion (with positive weights  w w \\mathbf{w} bold_w ).",
            "When constructing the warping structure, unlike Zammit et al.  [ 62 ]  and Vu et al.  [ 56 ] , which fix all warping hyperparameters, we fit them as part of the model training process. To simplify inference, we restrict attention to warping via RBF units  g rbf subscript g rbf g_{\\text{rbf}} italic_g start_POSTSUBSCRIPT rbf end_POSTSUBSCRIPT . The number of warping layers is varied and fine-tuned manually. Thanks to working with a separable kernel, we may independently vary  l S , l T subscript l S subscript l T l_{S},l_{T} italic_l start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  based on the patterns in each input domain. The selection of the number of warping layers must also consider model complexity, as each layer introduces multiple parameters to be learned. In Section  5.2 , we validate the above logic using synthetic examples to show the impact of the warping function  g  (  ) g  g(\\cdot) italic_g (  )  structure on model performance.",
            "Our model implementation utilizes Python and the  PyTorch  framework. The synthetic studies in Section  5  and real data analyses in Section  6  were executed on a 2021 MacBook Pro, featuring the Apple M1 Pro chip and 16 GB of memory. The trained models are evaluated using metrics discussed in Section  4 .",
            "The synthetic data is simulated for the same 27 locations in Section  5.1  in the West zone of ERCOT, maintaining the same setup except for adding spatial nonstationary through a known warping:",
            "Augmented with a periodic term, the temporal kernel is set to be M32 warped by a one-dimensional RBF unit. The spatial kernel is set to SE or M12 based on the synthetic results discussed in Section  5.1 . To address spatial nonstationarity, we incorporate 1-3 two-dimensional RBF units into the spatial warping. In total, we build 10 models with different spatial kernel choices and warping structures, shown in Table  3 ."
        ]
    },
    "id_table_6": {
        "caption": "Table A.2:  Goodness of fit and predictive evaluation metrics for the synthetic experiment in Section  5.1 . Training loss, Kolmogorov-Smirnov (KS) test p-values, and average interval score  Avg IS 0.05 subscript Avg IS 0.05 \\text{Avg IS}_{0.05} Avg IS start_POSTSUBSCRIPT 0.05 end_POSTSUBSCRIPT . Lower loss, larger p-values and smaller interval scores indicate better performance. The lowest  Avg IS 0.05 subscript Avg IS 0.05 \\text{Avg IS}_{0.05} Avg IS start_POSTSUBSCRIPT 0.05 end_POSTSUBSCRIPT  is typically achieved when  M Model = M True subscript M Model subscript M True M_{\\text{Model}}=M_{\\text{True}} italic_M start_POSTSUBSCRIPT Model end_POSTSUBSCRIPT = italic_M start_POSTSUBSCRIPT True end_POSTSUBSCRIPT . Notably, the other three kernels get lower p-values of KS test than in other cases when  M True = M  12 subscript M True M 12 M_{\\text{True}}=M12 italic_M start_POSTSUBSCRIPT True end_POSTSUBSCRIPT = italic_M 12 .",
        "table": "A1.T1.35",
        "footnotes": [
            ""
        ],
        "references": [
            "The motivating dataset, described in more detail in Sections  2  and  6 , has been recently created by several other teams as part of the ARPA-E PERFORM Data Plan suite  [ 53 ] . Its setting is tailored to the purposes of daily electric grid operations and implies several notable differences compared to standard spatiotemporal statistical setups. First, it directly reports hourly power generation in megawatt-hours (MWh), rather than wind speed. Hence, it operates in energy units rather than meteorological quantities. Second, the dataset provides not only the realized generation but also respective day-ahead point forecasts. These forecasts are produced daily and make the paired forecast-actuals no longer a time-series but a sequence of daily blocks. This pairing reflects the reality that the primary grid uncertainty quantification is conditional on the latest available weather forecast and is done once a day. Third, the provided measurements are hourly (with no missing dates), and are only available at wind farm locations, forming a highly irregular and non-uniform spatial pattern.",
            "The rest of the paper is organized as follows. Section  2  introduces our Texas wind power dataset and the data preprocessing procedure. Section  3  provides a summary of model details, including a review of spatiotemporal Gaussian Processes, kernel structures and the input warping technique. In Section  4  we summarize various evaluation metrics for model predictive performance. Section  5  discusses synthetic results about kernel choice and warping recovery. Results for the Texas dataset and model-based simulations are in Section  6 ; Section  7  concludes.",
            "Our model implementation utilizes Python and the  PyTorch  framework. The synthetic studies in Section  5  and real data analyses in Section  6  were executed on a 2021 MacBook Pro, featuring the Apple M1 Pro chip and 16 GB of memory. The trained models are evaluated using metrics discussed in Section  4 .",
            "where  l k  (  ; y ) = log   p  ( y | k ,  ) subscript l k  y log  p conditional y k  l_{k}(\\bm{\\theta};\\mathbf{y})=\\text{log }p(\\mathbf{y}|k,\\bm{\\theta}) italic_l start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_ ; bold_y ) = log italic_p ( bold_y | italic_k , bold_italic_ )  is the log-likelihood of  y y \\mathbf{y} bold_y  under a given kernel  k k k italic_k  calculated in Equation ( 6 ),   ^ ^  \\hat{\\bm{\\theta}} over^ start_ARG bold_italic_ end_ARG  is the maximum likelihood estimate (MLE) of  l k  (  ; y ) subscript l k  y l_{k}(\\bm{\\theta};\\mathbf{y}) italic_l start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_ ; bold_y ) ,  |  ^ w S | subscript ^  subscript w S |\\hat{\\bm{\\theta}}_{w_{S}}| | over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT end_POSTSUBSCRIPT |  (respectively  |  ^ w T | subscript ^  subscript w T |\\hat{\\bm{\\theta}}_{w_{T}}| | over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUBSCRIPT | ) is the number of estimated spatial (temporal) warping hyperparameters and  |  ^ k | subscript ^  k |\\hat{\\bm{\\theta}}_{k}| | over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT |  is the number of trained kernel hyperparameters. In a conventional BIC definition, the penalty term reflects the number of parameters in the model and the number of data points. In ( 14 ) we modify it to account for the fact that training days are i.i.d. and hence do not impact model complexity. The penalty terms are thus: the first term penalizes the parameters associated with spatial warping and the number of spatial locations ( M M M italic_M ); the second one penalizes the parameters related to temporal warping and the number of hours ( T T T italic_T ); the third term penalizes the kernel parameters and the product  M  T M T MT italic_M italic_T , which represents the number of location-hour combinations and determines the size of the GP covariance matrix.",
            "Table  A.4  in the Appendix shows the ground truth hyperparameters vis-a-vis the model trained hyperparameters. We build two models:  W 1 ( M 1 ) superscript subscript W 1 subscript M 1 W_{1}^{(M_{1})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  that includes one RBF layer and hence has 9 hyperparameters to train and  W 1 ( M 0 ) superscript subscript W 1 subscript M 0 W_{1}^{(M_{0})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  with no warping, and four hyperparameters. Both of them successfully recover the nugget term. However, model  W 1 ( M 1 ) superscript subscript W 1 subscript M 1 W_{1}^{(M_{1})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  provides a closer estimate of the variance parameter. It also successfully recovers the range parameter values and attains a similar BIC value as  W 1 ( M 0 ) superscript subscript W 1 subscript M 0 W_{1}^{(M_{0})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT , indicating a comparable training performance and thus does not introduce excessive training complexity. For the warping component, Model  W 1 ( M 1 ) superscript subscript W 1 subscript M 1 W_{1}^{(M_{1})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  accurately estimates the hyperparameters in the warping function and successfully reconstructs the warped space, see Table  A.4  and Figure  6(b) ."
        ]
    },
    "id_table_7": {
        "caption": "Table A.3:  Root Mean Squared Error (RMSE) and Coverage  C 0.20 subscript C 0.20 C_{0.20} italic_C start_POSTSUBSCRIPT 0.20 end_POSTSUBSCRIPT  for the synthetic experiment in Section  5.1 . Lower RMSE and closer to  80 % percent 80 80\\% 80 %  coverage means better performance. The lowest RMSE is typically observed when  M Model = M True subscript M Model subscript M True M_{\\text{Model}}=M_{\\text{True}} italic_M start_POSTSUBSCRIPT Model end_POSTSUBSCRIPT = italic_M start_POSTSUBSCRIPT True end_POSTSUBSCRIPT . The SE, M52, and M32 kernels exhibit similar coverage when  M True subscript M True M_{\\text{True}} italic_M start_POSTSUBSCRIPT True end_POSTSUBSCRIPT  is one of them, while they deviate from 80% when  M True = M  12 subscript M True M 12 M_{\\text{True}}=M12 italic_M start_POSTSUBSCRIPT True end_POSTSUBSCRIPT = italic_M 12 .",
        "table": "A1.T2.49",
        "footnotes": [
            ""
        ],
        "references": [
            "The rest of the paper is organized as follows. Section  2  introduces our Texas wind power dataset and the data preprocessing procedure. Section  3  provides a summary of model details, including a review of spatiotemporal Gaussian Processes, kernel structures and the input warping technique. In Section  4  we summarize various evaluation metrics for model predictive performance. Section  5  discusses synthetic results about kernel choice and warping recovery. Results for the Texas dataset and model-based simulations are in Section  6 ; Section  7  concludes.",
            "To train our GP model, we maximize the log-likelihood in Equation ( 7 ). Table  1  summarizes the parameters of the GP kernel, warping, and nugget:   := (  k ,  w ,  2 ) assign  subscript  k subscript  w superscript  2 \\bm{\\theta}:=({\\bm{\\theta}}_{k},{\\bm{\\theta}}_{w},{\\sigma}^{2}) bold_italic_ := ( bold_italic_ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , bold_italic_ start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT , italic_ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) , specifying whether they are involved in the training step and outlining the constraints imposed during the optimization process. We build isotropic spatial kernels from the Matern family, and a Matern plus periodic kernel ( 13 ) for temporal kernels. Therefore, we have 6 kernel parameters   k = (  ,  S ,  T ,  p ,  p , p ) subscript  k  subscript  S subscript  T subscript  p subscript  p p \\bm{\\theta}_{k}=(\\eta,\\rho_{S},\\rho_{T},\\eta_{p},\\rho_{p},p) bold_italic_ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = ( italic_ , italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_p ) :    \\eta italic_  signifies the overall variance of our spatiotemporal GP, while  (  S ,  T ) subscript  S subscript  T (\\rho_{S},\\rho_{T}) ( italic_ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT )  serve as range parameters representing smoothness characteristics of the spatial and temporal dimensions; parameters within the temporal kernels periodic component  (  p ,  p , p ) subscript  p subscript  p p (\\eta_{p},\\rho_{p},p) ( italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_p )  are designed to account for the daily periodic pattern of the forecast error.",
            "We then train three GP models  W 2 ( M i ) superscript subscript W 2 subscript M i W_{2}^{(M_{i})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT , with  i = 0 , 1 , 2 i 0 1 2 i=0,1,2 italic_i = 0 , 1 , 2  RBF warping layers respectively. All three models utilize a separable kernel with M32 in the time dimension and SE in the space dimension. Consistent with the findings of the first study above, the model  W 2 ( M 0 ) superscript subscript W 2 subscript M 0 W_{2}^{(M_{0})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  that lacks a warping structure mis-estimates the variance and range parameters relative to the ground truth. Although models incorporating warping,  W 2 ( M 2 ) superscript subscript W 2 subscript M 2 W_{2}^{(M_{2})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  and  W 2 ( M 1 ) superscript subscript W 2 subscript M 1 W_{2}^{(M_{1})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT , do not perfectly recover the warped space (see Table  A.4  and the visual comparison of the fitted warping effect in Figure  7 ), both provide close estimates of the kernel hyperparameters. Between them, the one-layer warping model demonstrates better training performance, evidenced by a lower BIC value."
        ]
    },
    "id_table_8": {
        "caption": "Table A.4:  Summary of the true setting and training results from three models for the experiment in Section  5.2 . For the single-layer case study, both models have similar BIC values.  W 1 ( M 1 ) superscript subscript W 1 subscript M 1 W_{1}^{(M_{1})} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  successfully recovers the kernel and warping hyperparameter values. For the two-layer case study,  W 2 ( M 0 ) superscript subscript W 2 subscript M 0 W_{2}^{(M_{0})} italic_W start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT  shows a larger BIC and inaccurate kernel parameters estimation. None of the three models recover the warped space.",
        "table": "A1.T3.33",
        "footnotes": [
            ""
        ],
        "references": [
            "where the testing set has  N  superscript N N^{*} italic_N start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  days and   ^ m , t , n subscript ^  m t n \\hat{\\mu}_{{m,t,n}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_m , italic_t , italic_n end_POSTSUBSCRIPT  is the model predicted mean for  x = ( s m , h t ) x subscript s m subscript h t \\mathbf{x}=(\\mathbf{s}_{m},h_{t}) bold_x = ( bold_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )  on day  d n subscript d n d_{n} italic_d start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , see Equation ( 8 ).",
            "Figure  8  visualizes the warping effects of the selected M12-2-1 model. The transformation on the spatial domain is performed around two locations in central and western Texas, expanding the southern part of Great Plains while condensing the northern Great Plains, North Central Plains, as well as the southern Gulf Coast plains. Distances within the southern part of the Far West and West regions are stretched, while those within the South, North, North Central and rest of Far West and West regions are squeezed. Figure  A.3  in the Appendix illustrates the spatial correlation between two reference assets, Aguayo and Whirlwind, and other locations across Texas. The contour lines represent levels of correlation; due to the warping effects, different locations exhibit varying correlation patterns in their neighborhood. The correlation for the Aguayo wind farm drops off more sharply along the latitude, particularly to the south. We also observe compressed correlation to the west of Aguayo compared to its east. In contrast, Whirlwind is far from the fitted warping centers   ^ 1 , 2 subscript ^  1 2 \\hat{\\bm{\\gamma}}_{1,2} over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT 1 , 2 end_POSTSUBSCRIPT  and as a result the respective neighborhood correlation pattern is nearly elliptical, decreasing at a similar rate in all directions.",
            "The developed framework is designed to simulate wind generation for day-ahead planning purposes. To showcase, we generate scenarios based on the the fitted M12-2-1 model with warping described above for various dates from 02/06/2018 to 05/25/2018. The scenarios are generated jointly across multiple assets and represent counterfactual realizations of wind power ratios on those days, conditioned on the given exogenous forecast. Starting with a single-asset perspective, we first illustrate such scenarios when conditioning both on the location-specific day-ahead forecast as well as realized generation from assets in the training set. Namely, considering asset  s  ( m  ) s superscript m \\mathbf{s}(m^{*}) bold_s ( italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT )  and date  d  superscript d d^{*} italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  within the test set, we sample 1000 scenarios from the GP predictive distribution conditional on observed data, i.e., realized forecast errors  y m , t , d  subscript y m t superscript d y_{m,t,d^{*}} italic_y start_POSTSUBSCRIPT italic_m , italic_t , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  on date  d  superscript d d^{*} italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  of  m = 1 , ... , 144 m 1 ... 144 m=1,\\ldots,144 italic_m = 1 , ... , 144  assets that are not in the test set (see Equation ( 8 ) and ( 9 )). By using the actual production ratios from neighboring locations, we can quantify the uncertainty of assets that are not directly observed."
        ]
    },
    "id_table_9": {
        "caption": "",
        "table": "A1.T4.56",
        "footnotes": [],
        "references": [
            "A probabilistic forecast takes the form of a predictive probability distribution  [ 23 ,  25 ] . Under our model, the predicted distribution for the input  ( s m , h t ) subscript s m subscript h t (\\mathbf{s}_{m},h_{t}) ( bold_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )  on day  n n n italic_n  is  Y m , t , n  N  (  ^ m , t , n ,  ^ m , t 2 ) similar-to subscript Y m t n N subscript ^  m t n subscript superscript ^  2 m t Y_{m,t,n}\\sim\\mathcal{N}(\\hat{\\mu}_{{m,t,n}},\\hat{\\sigma}^{2}_{m,t}) italic_Y start_POSTSUBSCRIPT italic_m , italic_t , italic_n end_POSTSUBSCRIPT  caligraphic_N ( over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_m , italic_t , italic_n end_POSTSUBSCRIPT , over^ start_ARG italic_ end_ARG start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m , italic_t end_POSTSUBSCRIPT ) , where the model predicted variance   ^ m , t 2 subscript superscript ^  2 m t \\hat{\\sigma}^{2}_{m,t} over^ start_ARG italic_ end_ARG start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m , italic_t end_POSTSUBSCRIPT  for  x = ( s m , h t ) x subscript s m subscript h t \\mathbf{x}=(\\mathbf{s}_{m},h_{t}) bold_x = ( bold_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )  corresponds to the diagonal element in    +  ^ 2  I superscript  superscript ^  2 I \\bm{\\Sigma}^{*}+\\hat{\\sigma}^{2}\\mathbf{I} bold_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT + over^ start_ARG italic_ end_ARG start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT bold_I . Notably, this predicted variance remains constant across different days for a fixed input  x x \\mathbf{x} bold_x , as indicated by Equation ( 9 ). To assess this predictive distribution, we apply several probabilistic metrics for uncertainty quantification and calibration.",
            "The developed framework is designed to simulate wind generation for day-ahead planning purposes. To showcase, we generate scenarios based on the the fitted M12-2-1 model with warping described above for various dates from 02/06/2018 to 05/25/2018. The scenarios are generated jointly across multiple assets and represent counterfactual realizations of wind power ratios on those days, conditioned on the given exogenous forecast. Starting with a single-asset perspective, we first illustrate such scenarios when conditioning both on the location-specific day-ahead forecast as well as realized generation from assets in the training set. Namely, considering asset  s  ( m  ) s superscript m \\mathbf{s}(m^{*}) bold_s ( italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT )  and date  d  superscript d d^{*} italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  within the test set, we sample 1000 scenarios from the GP predictive distribution conditional on observed data, i.e., realized forecast errors  y m , t , d  subscript y m t superscript d y_{m,t,d^{*}} italic_y start_POSTSUBSCRIPT italic_m , italic_t , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  on date  d  superscript d d^{*} italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  of  m = 1 , ... , 144 m 1 ... 144 m=1,\\ldots,144 italic_m = 1 , ... , 144  assets that are not in the test set (see Equation ( 8 ) and ( 9 )). By using the actual production ratios from neighboring locations, we can quantify the uncertainty of assets that are not directly observed.",
            "Figure  9  shows the hourly-based single-asset simulations for Aguayo and Whirlwind assets, located in the North Central and North regions respectively, on a couple of representative days in the testing set. The figure shows the original forecast  p ~ m  ,  , d  F subscript superscript ~ p F superscript m  superscript d \\tilde{p}^{F}_{m^{*},\\cdot,d^{*}} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , the actual wind power ratio  p ~ s  ,  , d  A subscript superscript ~ p A superscript s  superscript d \\tilde{p}^{A}_{s^{*},\\cdot,d^{*}} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_s start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , and the mean of GP-based simulations. We also plot the model quantile bands at levels   = 0.10 , 0.20 , 0.50  0.10 0.20 0.50 \\alpha=0.10,0.20,0.50 italic_ = 0.10 , 0.20 , 0.50 , calculated by sorting the hourly simulated values and then saving the respective  1   2  100 %  1  2 percent 100 \\frac{1-\\alpha}{2}\\cdot 100\\% divide start_ARG 1 - italic_ end_ARG start_ARG 2 end_ARG  100 %  and  1 +  2  100 %  1  2 percent 100 \\frac{1+\\alpha}{2}\\cdot 100\\% divide start_ARG 1 + italic_ end_ARG start_ARG 2 end_ARG  100 %  quantiles. Since the GP model generates forecast errors relative to  p ~ F superscript ~ p F \\tilde{p}^{F} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT , we clip the resulting  Y m  , t , d  + p ~ t F + y   m  subscript Y superscript m t superscript d subscript superscript ~ p F t subscript   y superscript m Y_{m^{*},t,d^{*}}+\\tilde{p}^{F}_{t}+\\bar{y}_{m^{*}} italic_Y start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , italic_t , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT + over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + over  start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  to ensure it falls within  [ 0 , 1 ] 0 1 [0,1] [ 0 , 1 ] . We observe that the 10-90% quantile band is roughly 0.6 in width, i.e., the production ratio is often   30 % plus-or-minus percent 30 \\pm 30\\%  30 %  above or below the predicted mean calculated from the forecast. Also, for about 70-80% of the hours, the realized generation is within the 10-90th quantile band, which is consistent with the coverage estimates shown in Table  3 .",
            "For assets that are only weakly influenced by the training locations, such as Aguayo (which is relatively far from most training locations and hence is correlated to only a few of them, see the left panel of Figure  A.3 ), the predictive distribution has a mean   ^ m  , t , d  subscript ^  superscript m t superscript d \\hat{\\mu}_{m^{*},t,d^{*}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , italic_t , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  close to zero. Hence, the scenario mean is effectively the forecast  p ~ m  ,  , d  F subscript superscript ~ p F superscript m  superscript d \\tilde{p}^{F}_{m^{*},\\cdot,d^{*}} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  plus  y   m  subscript   y superscript m \\bar{y}_{m^{*}} over  start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , see the almost constant gap between the blue and green curves in the left and middle panels of Figure  9  (in Aguayos case, the average forecast error  y   m  subscript   y superscript m \\bar{y}_{m^{*}} over  start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  is highly positive). In contrast, for assets that are highly correlated with observed locations, such as Whirlwind (see right panel of Figure  A.3 ), more information is obtained from the observed data and   ^ m  , t , d  subscript ^  superscript m t superscript d \\hat{\\mu}_{m^{*},t,d^{*}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , italic_t , italic_d start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  has a non-trivial shape. Thus, the difference between the scenario mean and forecast is influenced by both  y   m  subscript   y superscript m \\bar{y}_{m^{*}} over  start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_m start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and the predictive mean. Moreover, thanks to information fusion we observe notable improvement in predictive performance (scenarios closer to actuals compared to forecast) as well as tighter predictive bands.",
            "An important use case of area-wide wind scenarios is bottom-up modeling of  zonal  renewable generation which drives respective financial markets of zonal price indices and ancillary services. A joint probabilistic model of locational generation can be naturally summed across multiple assets to obtain consistent scenarios of aggregated production. As an illustration, Figure  10  visualizes such simulations for the aggregated power ratios in the Far West and North zones of ERCOT. These simulations are obtained by first simulating individual assets like in Figure  9  and then summing and re-normalizing in terms of zonal nameplate capacity across the given ERCOT zone.",
            "In Figure  10 , we sample scenarios from the joint distribution of asset wind power ratios given the day-ahead forecast only. After doing a weighted average to compute the zonal power ratio, the figure shows the mean of 1000 simulations, several respective quantile bands, as well as the hourly zonal forecast  p ~ F superscript ~ p F \\tilde{p}^{F} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT  and the actual generation ratio  p ~ A superscript ~ p A \\tilde{p}^{A} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT . Since the scenarios represent zonal generation based solely on the day-ahead forecast, the scenario mean is roughly the forecast plus the average  y     y \\bar{y} over  start_ARG italic_y end_ARG  within the zone. Compared to the asset-level Figure  9 , we observe much tighter uncertainty bands and lower RMSEs at the zonal level thanks to spatial averaging. The standard deviation of the zone-level scenario is about 10-12% around the forecast, yielding an 80% interval band of approximately 0.2-0.3."
        ]
    },
    "id_table_10": {
        "caption": "",
        "table": "A1.F3.4",
        "footnotes": [],
        "references": [
            "The weights  w w w italic_w  are limited within  (  1 , 1 2  exp  ( 3 2 ) ) 1 1 2 3 2 (-1,\\frac{1}{2}\\exp(\\frac{3}{2})) ( - 1 , divide start_ARG 1 end_ARG start_ARG 2 end_ARG roman_exp ( divide start_ARG 3 end_ARG start_ARG 2 end_ARG ) )  to ensure injectivity, a positive (resp. negative) weight  w d subscript w d w_{d} italic_w start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT  expands (resp. contracts) dimension  d d d italic_d . The stretching transformation is carried out relative to the center    \\bm{\\gamma} bold_italic_ . The scale  a > 0 a 0 a>0 italic_a > 0  governs the warping resolution, smaller values of  a a a italic_a  allow for more localized deformation. Figure  5  illustrates examples of the warping effect induced by the RBF unit, as described by Equation ( 10 ) in  D = 2 D 2 D=2 italic_D = 2  dimensions: Figures  5(a)  and  5(b)  visualize the warping effect of one RBF unit, Figure  5(c)  depicts warping with two compositional layers. Each layer independently transforms the uniform  ( 0 , 1 )  ( 0 , 1 ) 0 1 0 1 (0,1)\\times(0,1) ( 0 , 1 )  ( 0 , 1 )  grid centered around its respective location. Additionally, the two layers exhibit interaction with each other. The Figures visualize how a greater absolute value of the weight corresponds to a more pronounced deformation impact along the associated axis; similarly a larger value of scale  a a a italic_a  shows a more global contraction (with negative weights  w w \\mathbf{w} bold_w ) or expansion (with positive weights  w w \\mathbf{w} bold_w ).",
            "An important use case of area-wide wind scenarios is bottom-up modeling of  zonal  renewable generation which drives respective financial markets of zonal price indices and ancillary services. A joint probabilistic model of locational generation can be naturally summed across multiple assets to obtain consistent scenarios of aggregated production. As an illustration, Figure  10  visualizes such simulations for the aggregated power ratios in the Far West and North zones of ERCOT. These simulations are obtained by first simulating individual assets like in Figure  9  and then summing and re-normalizing in terms of zonal nameplate capacity across the given ERCOT zone.",
            "In Figure  10 , we sample scenarios from the joint distribution of asset wind power ratios given the day-ahead forecast only. After doing a weighted average to compute the zonal power ratio, the figure shows the mean of 1000 simulations, several respective quantile bands, as well as the hourly zonal forecast  p ~ F superscript ~ p F \\tilde{p}^{F} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT  and the actual generation ratio  p ~ A superscript ~ p A \\tilde{p}^{A} over~ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT . Since the scenarios represent zonal generation based solely on the day-ahead forecast, the scenario mean is roughly the forecast plus the average  y     y \\bar{y} over  start_ARG italic_y end_ARG  within the zone. Compared to the asset-level Figure  9 , we observe much tighter uncertainty bands and lower RMSEs at the zonal level thanks to spatial averaging. The standard deviation of the zone-level scenario is about 10-12% around the forecast, yielding an 80% interval band of approximately 0.2-0.3."
        ]
    }
}