{
    "S5.T1": {
        "caption": "Table 1. Dataset statistics.",
        "table": null,
        "footnotes": [],
        "references": [
            "Note that all test items did not appear in both datasets in the training period, i.e., all test items are completely cold-start. The statistics of the datasets are listed in Table¬†1.",
            "Compared to N0 and N2, N1 has more training users who purchased from small shops. N2 is a combination of N0 and N1. In Table¬†10, N0 has the highest Recall@1M in both item-level and shop-level evaluation. N0 and N2 keep a similar recall at the shop-level, while N2 achieves a much smaller variance.\nIn Figure¬†7, we show the recall distribution of test shops. The slop gets smaller from N0 to N1, which indicates the recall distributes more evenly among shops.\nIn summary, even though N2 achieves lower shop-wise performance variance, the overall performance was similar to N0. Nevertheless, the selecting negative samples requires more computation costs.",
            "Table¬†11 shows experimental results on the Ichiba dataset with different Œ≥ùõæ\\gamma, which is the weight to balance between original loss and the regularizer. Bigger Œ≥ùõæ\\gamma gives bigger weights on the regularizer. With Œ≥=0.8ùõæ0.8\\gamma=0.8, we see improvement over small existing shop‚Äôs recommendation. Nevertheless, the new shop‚Äôs recommendation accuracy was dropped. We also tried bigger Œ≥ùõæ\\gamma; however, it did not return better results. In conclusion, the regularizer only helps small shops that existed in training, but not new shops that did not exist."
        ]
    },
    "S5.T2": {
        "caption": "Table 2.  Item-level and shop-level recall on Ichiba dataset.",
        "table": null,
        "footnotes": [],
        "references": [
            "We summarize item-level performance results in Tables¬†2 and 3. For the Ichiba dataset, MeSh performs the best for the new shops. It has a 60.1% relative improvement compared to LV2 and 17.8% to MeLU for R@1M. For the existing shops, MeLU becomes competitive for the large shops. It is reasonable since MeLU may see more items transactions from large shops\nin each user‚Äôs support/query set. With more training samples from large shops, MeLU will have more advantages.\nFor the Movielens dataset, we see similar results, except that MeLU outperforms MeSh in the existing shop section. The reason may be that the explicit feedback from Movielens further helps MeLU learn better item representations during item-level optimization. At the same time, the Ichiba dataset experiment only utilizes 0 or 1 feedback. Also, we notice that MeLU was not the best model for new shops on Movielens,\nwhich implies possible overfitting.",
            "To further understand the impact of Meta-Shop on small business advertisements, we focus on the new shop‚Äôs shop-level results. New shops belong to the small business scenario as they do not exist in the training set and only require 10 transactions for the local update before the test. From the right side of Tables 2 and 3, we see Meta-Shop models outperform others in new shop sections on both datasets. On the Ichiba dataset, the relative improvement of MeSh over Baseline for the new shops and large existing shops are 16.6% and 1.6% for R@1M. On Movielens, the relative improvement of MeSh-i over Wide & deep for the new shops and large existing shops are 40.4% and 9.5% for nDCG@3. More significant improvements for new shops indicate that our model truly helps small business advertisement."
        ]
    },
    "S5.T3": {
        "caption": "Table 3. Item-level and shop-level evaluations on Movielens dataset.",
        "table": null,
        "footnotes": [],
        "references": [
            "We summarize item-level performance results in Tables¬†2 and 3. For the Ichiba dataset, MeSh performs the best for the new shops. It has a 60.1% relative improvement compared to LV2 and 17.8% to MeLU for R@1M. For the existing shops, MeLU becomes competitive for the large shops. It is reasonable since MeLU may see more items transactions from large shops\nin each user‚Äôs support/query set. With more training samples from large shops, MeLU will have more advantages.\nFor the Movielens dataset, we see similar results, except that MeLU outperforms MeSh in the existing shop section. The reason may be that the explicit feedback from Movielens further helps MeLU learn better item representations during item-level optimization. At the same time, the Ichiba dataset experiment only utilizes 0 or 1 feedback. Also, we notice that MeLU was not the best model for new shops on Movielens,\nwhich implies possible overfitting.",
            "To further understand the impact of Meta-Shop on small business advertisements, we focus on the new shop‚Äôs shop-level results. New shops belong to the small business scenario as they do not exist in the training set and only require 10 transactions for the local update before the test. From the right side of Tables 2 and 3, we see Meta-Shop models outperform others in new shop sections on both datasets. On the Ichiba dataset, the relative improvement of MeSh over Baseline for the new shops and large existing shops are 16.6% and 1.6% for R@1M. On Movielens, the relative improvement of MeSh-i over Wide & deep for the new shops and large existing shops are 40.4% and 9.5% for nDCG@3. More significant improvements for new shops indicate that our model truly helps small business advertisement."
        ]
    },
    "S5.T4": {
        "caption": "Table 4. Left: The portion of shops with R@1M above a specific value on the Ichiba dataset. Right: Shop-level R@1M mean and variance. ‚Üë‚Üë\\uparrow means the metric the higher, the better, ‚Üì‚Üì\\downarrow means the metric the lower, the better.",
        "table": null,
        "footnotes": [],
        "references": [
            "In Table¬†4, we compute the portion of shops with shop-level R@1M above a specific value and mean and variance of shop-level R@1M of each shop. Our model outperforms the rest methods. Specifically, in MeSh, more than 77% of shops have R@1M more than 0.5. It is twice more than LV2 and 6.9% more than MeLU. It also achieves a 2.2% relative improvement of shop-level R@1M compared to baseline while keeping a smaller variance, which indicates that our model is more robust across all different-sized shops. We plot the distribution of test shops with different R@1M in Figure¬†5. The smooth tail of the distribution matches the fact that MeSh has a smaller shop-level recall variance.\nEven though MeLU performs the best in item-level evaluation on the Movielens dataset, it losses its advantage when considering shop-level performance, as shown in Table¬†5. In MeSh-i, more than 72% of shops have a nDCG@3 score of more than 0.35. It also achieves a 1.5% relative improvement of shop-level nDCG@3 with a smaller variance than MeLU.\nIn summary, the above results indicate that MeSh and Mesh-i provide less-biased recommendations for all shops and movie genres."
        ]
    },
    "S5.T5": {
        "caption": "Table 5. Left: The portion of shops with nDCG@3 above a specific value on the Movielens dataset. Right: Shop-level nDCG@3 mean and variance.",
        "table": null,
        "footnotes": [],
        "references": [
            "In Table¬†4, we compute the portion of shops with shop-level R@1M above a specific value and mean and variance of shop-level R@1M of each shop. Our model outperforms the rest methods. Specifically, in MeSh, more than 77% of shops have R@1M more than 0.5. It is twice more than LV2 and 6.9% more than MeLU. It also achieves a 2.2% relative improvement of shop-level R@1M compared to baseline while keeping a smaller variance, which indicates that our model is more robust across all different-sized shops. We plot the distribution of test shops with different R@1M in Figure¬†5. The smooth tail of the distribution matches the fact that MeSh has a smaller shop-level recall variance.\nEven though MeLU performs the best in item-level evaluation on the Movielens dataset, it losses its advantage when considering shop-level performance, as shown in Table¬†5. In MeSh-i, more than 72% of shops have a nDCG@3 score of more than 0.35. It also achieves a 1.5% relative improvement of shop-level nDCG@3 with a smaller variance than MeLU.\nIn summary, the above results indicate that MeSh and Mesh-i provide less-biased recommendations for all shops and movie genres."
        ]
    },
    "S5.T6": {
        "caption": "Table 6. GMV improvement over LV2 on Ichiba dataset.",
        "table": null,
        "footnotes": [],
        "references": [
            "Table¬†6 lists the Gross Merchandise Value (GMV) improvement over the LV2 model on the Ichiba dataset. The GMV improvement is more than 200% in the new shop section when using MeSh which further proves the effectiveness of our model in helping small businesses."
        ]
    },
    "S5.T7": {
        "caption": "Table 7. Performance of one-shop training on the Ichiba dataset.",
        "table": null,
        "footnotes": [],
        "references": [
            "One practical solution for sample bias in the real world is to train separate models for each shop. Here, we randomly select 6 shops from small and large existing shops respectively, train and test each shop separately using the Wide & Deep model, namely the one-shop model. The difference between one-shop and Wide & Deep is that the former is trained only using one shop‚Äôs user-item (all available) interaction data instead of all shops‚Äô.\nWe report the mean and variance of the shop-level test results in Table¬†7. Results on Movielens dataset with 2 shops in each section are in Table¬†8.\nOne-shop model results are more than 4 times worse than MeSh‚Äôs on the Ichiba dataset for R@1M and more than 1.4 times worse on the Movielens for MAE. In summary, one-shop training is not a good solution for sample bias, especially when the dataset is highly sparse and long-tailed like the Ichiba dataset."
        ]
    },
    "S5.T8": {
        "caption": "Table 8. Performance of one-shop training on Movielens dataset.",
        "table": null,
        "footnotes": [],
        "references": [
            "One practical solution for sample bias in the real world is to train separate models for each shop. Here, we randomly select 6 shops from small and large existing shops respectively, train and test each shop separately using the Wide & Deep model, namely the one-shop model. The difference between one-shop and Wide & Deep is that the former is trained only using one shop‚Äôs user-item (all available) interaction data instead of all shops‚Äô.\nWe report the mean and variance of the shop-level test results in Table¬†7. Results on Movielens dataset with 2 shops in each section are in Table¬†8.\nOne-shop model results are more than 4 times worse than MeSh‚Äôs on the Ichiba dataset for R@1M and more than 1.4 times worse on the Movielens for MAE. In summary, one-shop training is not a good solution for sample bias, especially when the dataset is highly sparse and long-tailed like the Ichiba dataset."
        ]
    },
    "S5.T9": {
        "caption": "Table 9. Item-level R@1M of models with different definitions of tasks on the Ichiba dataset.",
        "table": null,
        "footnotes": [],
        "references": [
            "The number of tasks also plays an important role for training stability and performance. Given the Ichiba dataset, we define tasks based on unique items, users and shops; Item-based and shop-based are MeLU and MeSh models defined in Section¬†5.2. User-based model treats each user‚Äôs preferences as each tasks as the original MeLU paper proposed. Item-based and user-based models have a total 459K and 1.3M tasks respectively while shop-based only has 7K tasks. We believe smaller number of tasks improves performance more as we show in Table¬†9. Too many tasks will affect model‚Äôs generalization and convergence speed as shown in ¬†(Antoniou\net¬†al., 2019)."
        ]
    },
    "S5.T10": {
        "caption": "Table 10.  R@1M using different negative sampling on Ichiba dataset.",
        "table": null,
        "footnotes": [],
        "references": [
            "Compared to N0 and N2, N1 has more training users who purchased from small shops. N2 is a combination of N0 and N1. In Table¬†10, N0 has the highest Recall@1M in both item-level and shop-level evaluation. N0 and N2 keep a similar recall at the shop-level, while N2 achieves a much smaller variance.\nIn Figure¬†7, we show the recall distribution of test shops. The slop gets smaller from N0 to N1, which indicates the recall distributes more evenly among shops.\nIn summary, even though N2 achieves lower shop-wise performance variance, the overall performance was similar to N0. Nevertheless, the selecting negative samples requires more computation costs."
        ]
    },
    "S5.T11": {
        "caption": "Table 11. Item-level R@1M of models with different regularization weights on Ichiba dataset.",
        "table": null,
        "footnotes": [],
        "references": [
            "Table¬†11 shows experimental results on the Ichiba dataset with different Œ≥ùõæ\\gamma, which is the weight to balance between original loss and the regularizer. Bigger Œ≥ùõæ\\gamma gives bigger weights on the regularizer. With Œ≥=0.8ùõæ0.8\\gamma=0.8, we see improvement over small existing shop‚Äôs recommendation. Nevertheless, the new shop‚Äôs recommendation accuracy was dropped. We also tried bigger Œ≥ùõæ\\gamma; however, it did not return better results. In conclusion, the regularizer only helps small shops that existed in training, but not new shops that did not exist."
        ]
    }
}