{
    "S4.T1": {
        "caption": "Table 1: Results of Decision Transformer on topic recommendation task, using previous 20 turn-pairs as input. Best results per data subset are in bold.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S4.T1.1.1.1.1.1\">\n<span class=\"ltx_ERROR undefined\" id=\"S4.T1.1.1.1.1.1.1\">\\ul</span><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1.2\">Decision Transformer</span>\n</th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"S4.T1.1.1.1.1.2\"/>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"S4.T1.1.1.1.1.3\"/>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"S4.T1.1.1.1.1.4\"/>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"S4.T1.1.1.1.1.5\"/>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"S4.T1.1.1.1.1.6\"/>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row\" id=\"S4.T1.1.1.2.2.1\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T1.1.1.2.2.2\">Depression</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T1.1.1.2.2.3\">Anxiety</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T1.1.1.2.2.4\">Schizophrenia</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T1.1.1.2.2.5\">Suicidal</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T1.1.1.2.2.6\">All</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.3.1.1\">Full</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.1.2\">.176</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.1.3\">.233</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.1.4\">.246</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.1.5\">.213</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3.1.6\">.361</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.1.1.4.2.1\">Task</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.4.2.2.1\">.291</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.4.2.3.1\">.320</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.2.4\">.247</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.2.5\">.231</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.4.2.6\">.323</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.1.1.5.3.1\">Bond</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.3.2\">.270</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.3.3\">.314</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.3.4\">.231</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.5.3.5.1\">.239</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.5.3.6\">.335</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.1.1.6.4.1\">Goal</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.6.4.2.1\">.291</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.4.3\">.313</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.6.4.4.1\">.249</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.4.5\">.229</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.6.4.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.6.4.6.1\">.375</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "The results of the Decision Transformer on a 95%/5% train-test split, reflecting the set-up of the original SupervisorBot paper, are provided in Table 1. We reproduce results for the other RL methods in the original paper for performance on the full-scale rewards; Decision Transformer outperforms these baselines as noted in Table 3.\nWe note that Decision Transformer specifically performs best for all reward scales when trained on the full dataset; among individual diseases, the model performs best on the task, bond, and goal scales for anxiety."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Decision Transformer model performance trained on varying context lengths. Best results per reward scale are in bold.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row\" id=\"S4.T2.1.1.1.1.1\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" colspan=\"4\" id=\"S4.T2.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.1.2.1\">Context Lengths</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S4.T2.1.1.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.2.2.1.1\">Rewards</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.2.2.2\">5</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.2.2.3\">10</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.2.2.4\">15</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.2.2.5\">20</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T2.1.1.3.1.1\">Full</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.3.1.2\">0.346</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.3.1.3\">0.345</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.3.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.3.1.4.1\">0.403</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.3.1.5\">0.361</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T2.1.1.4.2.1\">Bond</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.2.2\">0.284</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.2.3\">0.343</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.4.2.4.1\">0.359</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.4.2.5\">0.335</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T2.1.1.5.3.1\">Task</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.5.3.2\">0.272</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.5.3.3\">0.298</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.5.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.5.3.4.1\">0.342</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.5.3.5\">0.322</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T2.1.1.6.4.1\">Goal</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.6.4.2\">0.278</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.6.4.3\">0.339</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.6.4.4\">0.348</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.6.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.6.4.5.1\">0.375</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We additionally evaluate whether or not the 20-timestep context is necessary for good performance from the Decision Transformer model, and these results are provided in Table 2. We note that 15 time-steps is optimal for a majority of the reward sclaes, suggesting that the Decision Transformer is better able to make decisions provided a briefer learning history. An advantage of utilizing a transformer-based model for this task is that we are able to investigate its internal structure to understand specifically which historical features\u2013\u2013including which time-steps\u2013\u2013are significant for inference."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Baseline RL performance on full-scale rewards on the full dataset, with a comparison to DT performance (the negative values suggest that these baselines perform worse than our proposed DT-based recommendation model, which improves upon them).",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row\" id=\"S4.T3.1.1.1.1.1\"/>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T3.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.2.1\">DDPG</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T3.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.3.1\">BCQ</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T3.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.4.1\">TD3</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.1.2.1.1\">Full</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.2.1.2\">.264 (-.97)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.2.1.3\">.170 (-1.91)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.2.1.4\">.286 (-.75)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "The results of the Decision Transformer on a 95%/5% train-test split, reflecting the set-up of the original SupervisorBot paper, are provided in Table 1. We reproduce results for the other RL methods in the original paper for performance on the full-scale rewards; Decision Transformer outperforms these baselines as noted in Table 3.\nWe note that Decision Transformer specifically performs best for all reward scales when trained on the full dataset; among individual diseases, the model performs best on the task, bond, and goal scales for anxiety."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Results of fine-tuning LLaMA-2 7B on DT output and gold-standard labels.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row\" id=\"S4.T4.1.1.1.1.1\"/>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T4.1.1.1.1.2\">Full</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T4.1.1.1.1.3\">Task</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T4.1.1.1.1.4\">Bond</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S4.T4.1.1.1.1.5\">Goal</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.2.1.1.1\">LLaMA-2 7B + DT</span></th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.1.2.1.2\">.148</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.1.2.1.3\">.118</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.1.2.1.4\">.158</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.1.2.1.5\">.115</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.1.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.3.2.1.1\">LLaMA-2 7B + Gold</span></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.1.3.2.2\">.371</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.1.3.2.3\">.259</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.1.3.2.4\">.315</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.1.3.2.5\">.332</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Additionally, we note that the LLaMA-2 model trained on the gold-standard data does not necessarily outperform the Decision Transformer for all reward scales as indicated in Table 4, indicating that the off-the-shelf language model may not be conducive for a reinforcement learning task.\nLLaMA-2 trained on the Decision Transformer output directly also does not perform particularly well; future work may include modifying the way in which the Decision Transformer synthetic labels are used by a language model. It\u2019s possible that prompting the language model may yield better results than treating it as a sequence classifier."
        ]
    }
}