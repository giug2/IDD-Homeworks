{
    "PAPER'S NUMBER OF TABLES": 2,
    "S4.T1": {
        "caption": "TABLE I: Shared network model.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\">Network 1</span></th>\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_smallcaps\">network 2</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.1.1.1\" class=\"ltx_text ltx_font_smallcaps\">Conv2d(1, 16, 5)</span></td>\n<td id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.1.2.1\" class=\"ltx_text ltx_font_smallcaps\">FC(256, 512)</span></td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.3.2.1.1\" class=\"ltx_text ltx_font_smallcaps\">MaxPool2d(2, 2)</span></td>\n<td id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.1.3.2.2.1\" class=\"ltx_text ltx_font_smallcaps\">FC(512, 1024)</span></td>\n</tr>\n<tr id=\"S4.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.4.3.1.1\" class=\"ltx_text ltx_font_smallcaps\">Conv2d(16, 48, 3)</span></td>\n<td id=\"S4.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.1.4.3.2.1\" class=\"ltx_text ltx_font_smallcaps\">FC(1024, 2048)</span></td>\n</tr>\n<tr id=\"S4.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.5.4.1.1\" class=\"ltx_text ltx_font_smallcaps\">MaxPool2d(2, 2)</span></td>\n<td id=\"S4.T1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.1.5.4.2.1\" class=\"ltx_text ltx_font_smallcaps\">FC(2048, 512)</span></td>\n</tr>\n<tr id=\"S4.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.6.5.1.1\" class=\"ltx_text ltx_font_smallcaps\">Conv2d(48, 64, 3)</span></td>\n<td id=\"S4.T1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.1.6.5.2.1\" class=\"ltx_text ltx_font_smallcaps\">FC(512, 256)</span></td>\n</tr>\n<tr id=\"S4.T1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.7.6.1.1\" class=\"ltx_text ltx_font_smallcaps\">MaxPool2d(2, 2)</span></td>\n<td id=\"S4.T1.1.7.6.2\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.T1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.8.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.8.7.1.1\" class=\"ltx_text ltx_font_smallcaps\">Conv2d(64, 64, 2)</span></td>\n<td id=\"S4.T1.1.8.7.2\" class=\"ltx_td ltx_border_b ltx_border_r\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We choose Î³ğ›¾\\gamma as 0.9 through our experiments. Note that Î³ğ›¾\\gamma is the only hyperparameter of FedGradNorm, and it should be determined with respect to the task asymmetry in the system. The learning rate Î²ğ›½\\beta, which is used for training of global shared network and the personalized network on the client side is 0.0002, and the learning rate Î±ğ›¼\\alpha for Fgradsubscriptğ¹gradF_{\\textrm{grad}} optimization is 0.004. We use Adam optimizer for both network training and Fgradsubscriptğ¹gradF_{\\textrm{grad}} optimization. The shared network model is explained in TableÂ I. Each client also has a simple linear layer that maps the shared networkâ€™s output to the corresponding prediction value for a personalized network. Cross-entropy and mean squared error (MSE) are used as the loss functions for classification and regression tasks, respectively."
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Comparison of task losses after 100 epochs in FedGradNorm and FedRep; imbalanced data allocation among tasks.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Tasks</th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">face landmark</th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">gender</th>\n<th id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">smile</th>\n<th id=\"S4.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">glass</th>\n<th id=\"S4.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">pose</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">\n<em id=\"S4.T2.1.2.1.1.1\" class=\"ltx_emph ltx_font_italic\">FedRep</em> loss</th>\n<td id=\"S4.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.28</td>\n<td id=\"S4.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.66</td>\n<td id=\"S4.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.60</td>\n<td id=\"S4.T2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.44</td>\n<td id=\"S4.T2.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.1</td>\n</tr>\n<tr id=\"S4.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">\n<em id=\"S4.T2.1.3.2.1.1\" class=\"ltx_emph ltx_font_italic\">FedGradNorm</em> loss</th>\n<td id=\"S4.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">33.25</td>\n<td id=\"S4.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\">0.56</span></td>\n<td id=\"S4.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">0.57</span></td>\n<td id=\"S4.T2.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.43</td>\n<td id=\"S4.T2.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1.1</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Next, we investigate the case where the data allocation is imbalanced, namely, some clients have a smaller portion of the dataset. In the following simulation, task 2 and task 4 have access to 500 data points while other tasks have 3000 data points to use in the training procedure. As shown in TableÂ II, FedGradNorm again has a better performance compared to the equal-weighting case in FedRep."
        ]
    }
}