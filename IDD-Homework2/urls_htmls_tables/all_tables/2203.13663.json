{
    "PAPER'S NUMBER OF TABLES": 2,
    "S4.T1": {
        "caption": "TABLE I: Shared network model.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\">Network 1</span></th>\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_smallcaps\">network 2</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.1.1.1\" class=\"ltx_text ltx_font_smallcaps\">Conv2d(1, 16, 5)</span></td>\n<td id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.1.2.1\" class=\"ltx_text ltx_font_smallcaps\">FC(256, 512)</span></td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.3.2.1.1\" class=\"ltx_text ltx_font_smallcaps\">MaxPool2d(2, 2)</span></td>\n<td id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.1.3.2.2.1\" class=\"ltx_text ltx_font_smallcaps\">FC(512, 1024)</span></td>\n</tr>\n<tr id=\"S4.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.4.3.1.1\" class=\"ltx_text ltx_font_smallcaps\">Conv2d(16, 48, 3)</span></td>\n<td id=\"S4.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.1.4.3.2.1\" class=\"ltx_text ltx_font_smallcaps\">FC(1024, 2048)</span></td>\n</tr>\n<tr id=\"S4.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.5.4.1.1\" class=\"ltx_text ltx_font_smallcaps\">MaxPool2d(2, 2)</span></td>\n<td id=\"S4.T1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.1.5.4.2.1\" class=\"ltx_text ltx_font_smallcaps\">FC(2048, 512)</span></td>\n</tr>\n<tr id=\"S4.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.6.5.1.1\" class=\"ltx_text ltx_font_smallcaps\">Conv2d(48, 64, 3)</span></td>\n<td id=\"S4.T1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.1.6.5.2.1\" class=\"ltx_text ltx_font_smallcaps\">FC(512, 256)</span></td>\n</tr>\n<tr id=\"S4.T1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.7.6.1.1\" class=\"ltx_text ltx_font_smallcaps\">MaxPool2d(2, 2)</span></td>\n<td id=\"S4.T1.1.7.6.2\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S4.T1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.8.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r\"><span id=\"S4.T1.1.8.7.1.1\" class=\"ltx_text ltx_font_smallcaps\">Conv2d(64, 64, 2)</span></td>\n<td id=\"S4.T1.1.8.7.2\" class=\"ltx_td ltx_border_b ltx_border_r\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We choose γ𝛾\\gamma as 0.9 through our experiments. Note that γ𝛾\\gamma is the only hyperparameter of FedGradNorm, and it should be determined with respect to the task asymmetry in the system. The learning rate β𝛽\\beta, which is used for training of global shared network and the personalized network on the client side is 0.0002, and the learning rate α𝛼\\alpha for Fgradsubscript𝐹gradF_{\\textrm{grad}} optimization is 0.004. We use Adam optimizer for both network training and Fgradsubscript𝐹gradF_{\\textrm{grad}} optimization. The shared network model is explained in Table I. Each client also has a simple linear layer that maps the shared network’s output to the corresponding prediction value for a personalized network. Cross-entropy and mean squared error (MSE) are used as the loss functions for classification and regression tasks, respectively."
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Comparison of task losses after 100 epochs in FedGradNorm and FedRep; imbalanced data allocation among tasks.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Tasks</th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">face landmark</th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">gender</th>\n<th id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">smile</th>\n<th id=\"S4.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">glass</th>\n<th id=\"S4.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">pose</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">\n<em id=\"S4.T2.1.2.1.1.1\" class=\"ltx_emph ltx_font_italic\">FedRep</em> loss</th>\n<td id=\"S4.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.28</td>\n<td id=\"S4.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.66</td>\n<td id=\"S4.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.60</td>\n<td id=\"S4.T2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.44</td>\n<td id=\"S4.T2.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.1</td>\n</tr>\n<tr id=\"S4.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">\n<em id=\"S4.T2.1.3.2.1.1\" class=\"ltx_emph ltx_font_italic\">FedGradNorm</em> loss</th>\n<td id=\"S4.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">33.25</td>\n<td id=\"S4.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\">0.56</span></td>\n<td id=\"S4.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">0.57</span></td>\n<td id=\"S4.T2.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.43</td>\n<td id=\"S4.T2.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1.1</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Next, we investigate the case where the data allocation is imbalanced, namely, some clients have a smaller portion of the dataset. In the following simulation, task 2 and task 4 have access to 500 data points while other tasks have 3000 data points to use in the training procedure. As shown in Table II, FedGradNorm again has a better performance compared to the equal-weighting case in FedRep."
        ]
    }
}