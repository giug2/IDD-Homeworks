{
    "id_table_1": {
        "caption": "Table 5 .  Failure categories of vanilla LLMs GPT-4o (4o), GPT-3.5-Turbo (3.5T), Llama3:8b (L3:8b), Llama3:70b (L3:70b), and the best found RAG variant on dependency validation.",
        "table": "S4.T1.6",
        "footnotes": [],
        "references": [
            "Modern software development requires coordinating a wide range of technologies, such as code frameworks, build tools, and databases  (Sayagh et al . ,  2017 ) . This coordination usually revolves around configuring each technology in its own format. For instance, container configurations are defined in a  Dockerfile , whereas Java application options are set in a  applications.yml . These configuration files often encode hundreds of configuration options in their own structure, syntax, and semantic  (Siegmund et al . ,  2020 ) . Most of these diverse technologies configurations need to be harmonized to ensure their correct interplay and interoperability. In the exemplary Spring Boot application scenario shown in  Figure 1 , the port configurations in the  application.yml  in Listing  1  and in the  Dockerfile  in Listing  2  must match for the application to work. This constraint constitutes a  configuration dependency . Such dependencies can exist both within a single technology ( intra- technology) and across multiple technologies ( cross- technology).",
            "We vary between several core elements, such as the embedding model (ada2 vs. Qwen2) , the re-ranking algorithm (Colbert vs. Sentence Transformer), and the final number of context chunks provided to the LLM (3 vs. 5). By varying only one component at a time, we obtain four different RAG variants, shown in Table  1 . Note, that we clearly could manipulate many more aspects of the RAG pipeline. However, this is the first and unrefined setup with which we start the evaluation, these configurations might be refined during experimentation if the failure analysis reveals significant room for improvement.",
            "The dependent variable in our demonstration is the effectiveness of the approach in validating configuration dependencies. We measure effectiveness using traditional classification metrics: precision ( 1a ), recall ( 1b ), and F1-score ( 1c ). Precision represents the proportion of true dependencies (TP) among positively labeled ones (TP + FP), while recall reflects the proportion of true dependencies among all actual dependencies (TP + FN). These metrics highlight the trade-off between identifying as many true dependencies as possible (recall) and ensuring the correctness of positively labeled dependencies (precision). High precision and recall are crucial for trustworthy validation. The F1-score, the harmonic mean of precision and recall, provides a single scalar value while allowing for more detailed analysis when examining each metric individually.",
            "We validated 500 manually labeled configuration dependencies of a cross-technology stack from ten real-world software projects with four state-of-the-art LLMs. Table   4  shows the number of validation failures (#Failures) as well as precision, recall, and F1-score for each vanilla LLM and unrefined RAG variant. Column RAG ID maps to the individual RAG systems given in Table  1 . Vanilla LLMs without RAG are marked with w/o."
        ]
    },
    "id_table_2": {
        "caption": "",
        "table": "S4.T2.6",
        "footnotes": [],
        "references": [
            "Such an iterative, and empirical-driven development process requires a sound research methodology when a RAG system is not only built but also evaluated in a sound way. Without a proper methodology, we may end up in missing opportunities (e.g., due to unconsidered RAG variants), unsound results (e.g., by not being able to causally trace evaluation outcomes to individual RAG design decision), or non-generalizable claims (e.g., by overfitting the RAG adaptions in the iterative development process to the used benchmark). With such a heterogeneity and number of aspects, it can be difficult to not miss important considerations in the study design and evaluation as we will describe in Section  2.2 . Although a generally accepted methodology for RAG evaluation clearly calls for a community endeavor, we aim to propose a first blueprint of how such a methodology may look like and apply it on a real-world software engineering research task.",
            "Modern software development requires coordinating a wide range of technologies, such as code frameworks, build tools, and databases  (Sayagh et al . ,  2017 ) . This coordination usually revolves around configuring each technology in its own format. For instance, container configurations are defined in a  Dockerfile , whereas Java application options are set in a  applications.yml . These configuration files often encode hundreds of configuration options in their own structure, syntax, and semantic  (Siegmund et al . ,  2020 ) . Most of these diverse technologies configurations need to be harmonized to ensure their correct interplay and interoperability. In the exemplary Spring Boot application scenario shown in  Figure 1 , the port configurations in the  application.yml  in Listing  1  and in the  Dockerfile  in Listing  2  must match for the application to work. This constraint constitutes a  configuration dependency . Such dependencies can exist both within a single technology ( intra- technology) and across multiple technologies ( cross- technology).",
            "Figure  2  highlights the key aspects to consider when conducting an empirical evaluation. We use the empirical terminology of dependent and independent variables to define the factors influencing the evaluation process and outcomes. For each consideration, we will now provide guiding questions and discussions.",
            "RAG is an umbrella of different components, design decisions, and domain-specific adaption. For example, there are hundreds of different embedding models to encode the semantics of textual information for later search  (Wang et al . ,  2024 ) , there are multiple ways for searching relevant documents in a multitude of vector stores  (Huang and Huang,  2024 ) , and there are plenty of ways on how to preprocess information (e.g., splitting documents), as well as how to filter and re-rank retrieved documents  (Gao et al . ,  2023 ) . All these  architectural  decisions in a RAG system can influence result accuracy and therefore need to be considered in a sound empirical study. As discussed in Section  2.2 , there is a current lack in reporting on design decisions, as well as improvements and refinements on them. Whether a proposed RAG system is a first, naive version or a carefully crafted one based on multiple iterations and feedback runs remains unclear, but is important on estimating the (un)tapped potential of the RAG system.",
            "To assess the effectiveness of our RAG variants for dependency validation, we compare their validation abilities against vanilla LLMs. Throughout our empirical study, we leverage four state-of-the-art LLMs, including two proprietary LLMs developed by OpenAI 3 3 3 https://openai.com/  (i.e., GPT-4o and GPT-3.5-Turbo) and two open-source LLMs developed by Meta 4 4 4 https://llama.meta.com/llama3/  (i.e., LLama3:8b and LLama3:70b (non-quantized)). The open-source LLMs are executed on our own hardware, a MacBook Pro with an Apple M3 chip and 128GB of RAM. A summary of the studied LLMs with their properties can be found in Table  2 . For all LLMs, we set the temperature to 0 in order to improve determinism and consistency of LLM outputs. Note that the LLMs play a second role here. They are not only baselines, but also independent variables as we vary and compare them (to each other)."
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "S4.T3.3",
        "footnotes": [],
        "references": [
            "We created a prompt for dependency validation using a collective prompt design process, in which all authors discussed and adjusted the prompt and its components in multiple iterations. Our final prompt for dependency validation includes five elements: (1) a system message, which defines the role of the LLM, (2) a definition of the dependency that it has to validate, (3) the retrieved context information, (4) the actual instruction to validate the given dependency, and (5) a description of the JSON format in which the LLM should respond. The validation prompt and its components are shown in  Figure 3 .",
            "To evaluate the effectiveness of our approach in validating configuration dependencies, we collected a dataset of potential configuration dependencies. We ran  CfgNet , an existing dependency detection framework from the literature  (Simon et al . ,  2023 ) , on ten real-world software projects. The selected projects used at least the following technologies: Spring Boot, Maven, Docker, and Docker Compose, and were among the most starred on GitHub. An overview of the systems is provided in Table  3 . For each software project, we sampled 50 potential dependencies, leading to a final set of 500 candidates. The rational for this sampling is that all dependencies must be manually checked in detail to create a trustworthy and correct ground truth. We manually labeled each dependency as either  true  if it correctly represents a dependency, or  false  if it is a false positive. This way, we created the largest ground truth cross-technology configuration dependency dataset that we are aware of and that has been used in any study. As a notable contribution of this work, we make this dataset available for other researchers and tool developers."
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "S5.T4.4",
        "footnotes": [],
        "references": [
            "By using our blueprint, we can give a concise overview in Figure  4  of how we addressed several design choices for conducting the evaluation. We will now discuss each decision in detail.",
            "We validated 500 manually labeled configuration dependencies of a cross-technology stack from ten real-world software projects with four state-of-the-art LLMs. Table   4  shows the number of validation failures (#Failures) as well as precision, recall, and F1-score for each vanilla LLM and unrefined RAG variant. Column RAG ID maps to the individual RAG systems given in Table  1 . Vanilla LLMs without RAG are marked with w/o.",
            "We answer the research question on which failures do occur based on a qualitative analysis. We approach this by identifying common failure categories. To this end, we manually inspect every false classification of all vanilla LLMs and RAG variant 2, as it yield the highest validation score and lowest number of false classifications among the RAG systems (see Table  4  rows ean). In total, we reviewed 1 203 validation failures from which we derived eight failure categories. Table  5  depicts a summary of all categories and their distribution across the LLMs and RAG variant 2. We provide a detailed description for each category on our supplementary Web page. We see that some failures are unique to specific LLM. For instance, while  GPT-4o  reliably validated dependencies in the  Port Mapping ,  Resource Sharing , and  Independent Technologies/Services  category, all other LLMs still struggle with these dependency types. However, there are also failure categories in which all LLMs encounter difficulties, particularly in the categories  Inheritance and Overrides  and  Configuration Consistency , which show the highest number or failures."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "S5.T5.4",
        "footnotes": [],
        "references": [
            "We answer the research question on which failures do occur based on a qualitative analysis. We approach this by identifying common failure categories. To this end, we manually inspect every false classification of all vanilla LLMs and RAG variant 2, as it yield the highest validation score and lowest number of false classifications among the RAG systems (see Table  4  rows ean). In total, we reviewed 1 203 validation failures from which we derived eight failure categories. Table  5  depicts a summary of all categories and their distribution across the LLMs and RAG variant 2. We provide a detailed description for each category on our supplementary Web page. We see that some failures are unique to specific LLM. For instance, while  GPT-4o  reliably validated dependencies in the  Port Mapping ,  Resource Sharing , and  Independent Technologies/Services  category, all other LLMs still struggle with these dependency types. However, there are also failure categories in which all LLMs encounter difficulties, particularly in the categories  Inheritance and Overrides  and  Configuration Consistency , which show the highest number or failures.",
            "With our refinement, we could clearly show that a RAG system is beneficial for configuration dependency validation. Although clarifying the task improves the usage of all LLMs (especially the smaller ones), it is the additional contextual information available in a RAG system that achieves the highest scores. Although beyond the focus of this work, a further refinement concentrating on the retrieval part seems promising to reach even higher F1-scores. Especially when looking at Figure  5(c) , we observe that the main context information is Web search, potentially leaving out other relevant information. Here, it makes sense to apply metrics, such as RAGAS  (Es et al . ,  2023 )  to find more failure categories that are concerned with retrieval relevance. Moreover, the failure analysis is a tedious manual process, which has to be taken into account when trying to automate the development of RAG systems for certain software engineering scenarios. An artifact is that the refinements could become very specific. For our case, this could mean to jeopardize the technology-independent part. Hence, we concentrate on making all refinements agnostic to the technology at hand, but this might not be possible in any case."
        ]
    },
    "id_table_6": {
        "caption": "",
        "table": "S5.T6.4",
        "footnotes": [],
        "references": [
            "Table  6  presents the final validation scores for all evaluated models on the holdout set. There are two notable observations: (1) The small refined vanilla LLMs especially benefit from the improved prompting. We observe a  Llama3:8b  model that is now on-par with the most advanced refined model  GPT-4o  and even surpasses the unrefined  GPT-4o  model for the F1 score. (2) The refined RAG systems clearly outperform the refined vanilla LLM baseline in all cases. Most notably, one of the smaller open-source models,  Llama3:70b  now performs best compared to all other models with an F1 score of 0.89. Thus, both smaller open-source models combined with RAG are now a preferable option to the two large proprietary models."
        ]
    },
    "global_footnotes": []
}