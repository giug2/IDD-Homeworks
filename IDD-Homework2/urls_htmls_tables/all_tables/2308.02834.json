{
    "PAPER'S NUMBER OF TABLES": 4,
    "S2.T1": {
        "caption": "TABLE I: Abbreviations",
        "table": "<table id=\"S2.T1.11.11\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S2.T1.11.11.12.1\" class=\"ltx_tr\">\n<th id=\"S2.T1.11.11.12.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\">Terminology</th>\n<th id=\"S2.T1.11.11.12.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">Explanation</th>\n<th id=\"S2.T1.11.11.12.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">Abbreviation</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S2.T1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Aggregation Server</td>\n<td id=\"S2.T1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Server used to aggregate models from different parties</td>\n<td id=\"S2.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math id=\"S2.T1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"AS\" display=\"inline\"><semantics id=\"S2.T1.1.1.1.1.m1.1a\"><mrow id=\"S2.T1.1.1.1.1.m1.1.1\" xref=\"S2.T1.1.1.1.1.m1.1.1.cmml\"><mi id=\"S2.T1.1.1.1.1.m1.1.1.2\" xref=\"S2.T1.1.1.1.1.m1.1.1.2.cmml\">A</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.1.1.1.1.m1.1.1.1\" xref=\"S2.T1.1.1.1.1.m1.1.1.1.cmml\">​</mo><mi id=\"S2.T1.1.1.1.1.m1.1.1.3\" xref=\"S2.T1.1.1.1.1.m1.1.1.3.cmml\">S</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.1.1.1.1.m1.1b\"><apply id=\"S2.T1.1.1.1.1.m1.1.1.cmml\" xref=\"S2.T1.1.1.1.1.m1.1.1\"><times id=\"S2.T1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S2.T1.1.1.1.1.m1.1.1.1\"></times><ci id=\"S2.T1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S2.T1.1.1.1.1.m1.1.1.2\">𝐴</ci><ci id=\"S2.T1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S2.T1.1.1.1.1.m1.1.1.3\">𝑆</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.1.1.1.1.m1.1c\">AS</annotation></semantics></math></td>\n</tr>\n<tr id=\"S2.T1.2.2.2\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Worker</td>\n<td id=\"S2.T1.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Server contributing to FL via pushing the local model to aggregation servers</td>\n<td id=\"S2.T1.2.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math id=\"S2.T1.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"w\" display=\"inline\"><semantics id=\"S2.T1.2.2.2.1.m1.1a\"><mi id=\"S2.T1.2.2.2.1.m1.1.1\" xref=\"S2.T1.2.2.2.1.m1.1.1.cmml\">w</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.2.2.2.1.m1.1b\"><ci id=\"S2.T1.2.2.2.1.m1.1.1.cmml\" xref=\"S2.T1.2.2.2.1.m1.1.1\">𝑤</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.2.2.2.1.m1.1c\">w</annotation></semantics></math></td>\n</tr>\n<tr id=\"S2.T1.3.3.3\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Aggregation algorithms</td>\n<td id=\"S2.T1.3.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Algorithms used to combine model results from different workers to a single model</td>\n<td id=\"S2.T1.3.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math id=\"S2.T1.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"f_{aggr}\" display=\"inline\"><semantics id=\"S2.T1.3.3.3.1.m1.1a\"><msub id=\"S2.T1.3.3.3.1.m1.1.1\" xref=\"S2.T1.3.3.3.1.m1.1.1.cmml\"><mi id=\"S2.T1.3.3.3.1.m1.1.1.2\" xref=\"S2.T1.3.3.3.1.m1.1.1.2.cmml\">f</mi><mrow id=\"S2.T1.3.3.3.1.m1.1.1.3\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.cmml\"><mi id=\"S2.T1.3.3.3.1.m1.1.1.3.2\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.2.cmml\">a</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.3.3.3.1.m1.1.1.3.1\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.1.cmml\">​</mo><mi id=\"S2.T1.3.3.3.1.m1.1.1.3.3\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.3.cmml\">g</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.3.3.3.1.m1.1.1.3.1a\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.1.cmml\">​</mo><mi id=\"S2.T1.3.3.3.1.m1.1.1.3.4\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.4.cmml\">g</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.3.3.3.1.m1.1.1.3.1b\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.1.cmml\">​</mo><mi id=\"S2.T1.3.3.3.1.m1.1.1.3.5\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.5.cmml\">r</mi></mrow></msub><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.3.3.3.1.m1.1b\"><apply id=\"S2.T1.3.3.3.1.m1.1.1.cmml\" xref=\"S2.T1.3.3.3.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S2.T1.3.3.3.1.m1.1.1.1.cmml\" xref=\"S2.T1.3.3.3.1.m1.1.1\">subscript</csymbol><ci id=\"S2.T1.3.3.3.1.m1.1.1.2.cmml\" xref=\"S2.T1.3.3.3.1.m1.1.1.2\">𝑓</ci><apply id=\"S2.T1.3.3.3.1.m1.1.1.3.cmml\" xref=\"S2.T1.3.3.3.1.m1.1.1.3\"><times id=\"S2.T1.3.3.3.1.m1.1.1.3.1.cmml\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.1\"></times><ci id=\"S2.T1.3.3.3.1.m1.1.1.3.2.cmml\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.2\">𝑎</ci><ci id=\"S2.T1.3.3.3.1.m1.1.1.3.3.cmml\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.3\">𝑔</ci><ci id=\"S2.T1.3.3.3.1.m1.1.1.3.4.cmml\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.4\">𝑔</ci><ci id=\"S2.T1.3.3.3.1.m1.1.1.3.5.cmml\" xref=\"S2.T1.3.3.3.1.m1.1.1.3.5\">𝑟</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.3.3.3.1.m1.1c\">f_{aggr}</annotation></semantics></math></td>\n</tr>\n<tr id=\"S2.T1.4.4.4\" class=\"ltx_tr\">\n<td id=\"S2.T1.4.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Worker selection algorithm</td>\n<td id=\"S2.T1.4.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Algorithms used by aggregation server to select workers for participating in FL.</td>\n<td id=\"S2.T1.4.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math id=\"S2.T1.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"f_{sel}\" display=\"inline\"><semantics id=\"S2.T1.4.4.4.1.m1.1a\"><msub id=\"S2.T1.4.4.4.1.m1.1.1\" xref=\"S2.T1.4.4.4.1.m1.1.1.cmml\"><mi id=\"S2.T1.4.4.4.1.m1.1.1.2\" xref=\"S2.T1.4.4.4.1.m1.1.1.2.cmml\">f</mi><mrow id=\"S2.T1.4.4.4.1.m1.1.1.3\" xref=\"S2.T1.4.4.4.1.m1.1.1.3.cmml\"><mi id=\"S2.T1.4.4.4.1.m1.1.1.3.2\" xref=\"S2.T1.4.4.4.1.m1.1.1.3.2.cmml\">s</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.4.4.4.1.m1.1.1.3.1\" xref=\"S2.T1.4.4.4.1.m1.1.1.3.1.cmml\">​</mo><mi id=\"S2.T1.4.4.4.1.m1.1.1.3.3\" xref=\"S2.T1.4.4.4.1.m1.1.1.3.3.cmml\">e</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.4.4.4.1.m1.1.1.3.1a\" xref=\"S2.T1.4.4.4.1.m1.1.1.3.1.cmml\">​</mo><mi id=\"S2.T1.4.4.4.1.m1.1.1.3.4\" xref=\"S2.T1.4.4.4.1.m1.1.1.3.4.cmml\">l</mi></mrow></msub><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.4.4.4.1.m1.1b\"><apply id=\"S2.T1.4.4.4.1.m1.1.1.cmml\" xref=\"S2.T1.4.4.4.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S2.T1.4.4.4.1.m1.1.1.1.cmml\" xref=\"S2.T1.4.4.4.1.m1.1.1\">subscript</csymbol><ci id=\"S2.T1.4.4.4.1.m1.1.1.2.cmml\" xref=\"S2.T1.4.4.4.1.m1.1.1.2\">𝑓</ci><apply id=\"S2.T1.4.4.4.1.m1.1.1.3.cmml\" xref=\"S2.T1.4.4.4.1.m1.1.1.3\"><times id=\"S2.T1.4.4.4.1.m1.1.1.3.1.cmml\" xref=\"S2.T1.4.4.4.1.m1.1.1.3.1\"></times><ci id=\"S2.T1.4.4.4.1.m1.1.1.3.2.cmml\" xref=\"S2.T1.4.4.4.1.m1.1.1.3.2\">𝑠</ci><ci id=\"S2.T1.4.4.4.1.m1.1.1.3.3.cmml\" xref=\"S2.T1.4.4.4.1.m1.1.1.3.3\">𝑒</ci><ci id=\"S2.T1.4.4.4.1.m1.1.1.3.4.cmml\" xref=\"S2.T1.4.4.4.1.m1.1.1.3.4\">𝑙</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.4.4.4.1.m1.1c\">f_{sel}</annotation></semantics></math></td>\n</tr>\n<tr id=\"S2.T1.6.6.6\" class=\"ltx_tr\">\n<td id=\"S2.T1.6.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Aggregation server model weights</td>\n<td id=\"S2.T1.5.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">The model weights of the model held by aggregation server (aggregate for <math id=\"S2.T1.5.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"i\" display=\"inline\"><semantics id=\"S2.T1.5.5.5.1.m1.1a\"><mi id=\"S2.T1.5.5.5.1.m1.1.1\" xref=\"S2.T1.5.5.5.1.m1.1.1.cmml\">i</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.5.5.5.1.m1.1b\"><ci id=\"S2.T1.5.5.5.1.m1.1.1.cmml\" xref=\"S2.T1.5.5.5.1.m1.1.1\">𝑖</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.5.5.5.1.m1.1c\">i</annotation></semantics></math> times)</td>\n<td id=\"S2.T1.6.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math id=\"S2.T1.6.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"M_{asi}\" display=\"inline\"><semantics id=\"S2.T1.6.6.6.2.m1.1a\"><msub id=\"S2.T1.6.6.6.2.m1.1.1\" xref=\"S2.T1.6.6.6.2.m1.1.1.cmml\"><mi id=\"S2.T1.6.6.6.2.m1.1.1.2\" xref=\"S2.T1.6.6.6.2.m1.1.1.2.cmml\">M</mi><mrow id=\"S2.T1.6.6.6.2.m1.1.1.3\" xref=\"S2.T1.6.6.6.2.m1.1.1.3.cmml\"><mi id=\"S2.T1.6.6.6.2.m1.1.1.3.2\" xref=\"S2.T1.6.6.6.2.m1.1.1.3.2.cmml\">a</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.6.6.6.2.m1.1.1.3.1\" xref=\"S2.T1.6.6.6.2.m1.1.1.3.1.cmml\">​</mo><mi id=\"S2.T1.6.6.6.2.m1.1.1.3.3\" xref=\"S2.T1.6.6.6.2.m1.1.1.3.3.cmml\">s</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.6.6.6.2.m1.1.1.3.1a\" xref=\"S2.T1.6.6.6.2.m1.1.1.3.1.cmml\">​</mo><mi id=\"S2.T1.6.6.6.2.m1.1.1.3.4\" xref=\"S2.T1.6.6.6.2.m1.1.1.3.4.cmml\">i</mi></mrow></msub><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.6.6.6.2.m1.1b\"><apply id=\"S2.T1.6.6.6.2.m1.1.1.cmml\" xref=\"S2.T1.6.6.6.2.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S2.T1.6.6.6.2.m1.1.1.1.cmml\" xref=\"S2.T1.6.6.6.2.m1.1.1\">subscript</csymbol><ci id=\"S2.T1.6.6.6.2.m1.1.1.2.cmml\" xref=\"S2.T1.6.6.6.2.m1.1.1.2\">𝑀</ci><apply id=\"S2.T1.6.6.6.2.m1.1.1.3.cmml\" xref=\"S2.T1.6.6.6.2.m1.1.1.3\"><times id=\"S2.T1.6.6.6.2.m1.1.1.3.1.cmml\" xref=\"S2.T1.6.6.6.2.m1.1.1.3.1\"></times><ci id=\"S2.T1.6.6.6.2.m1.1.1.3.2.cmml\" xref=\"S2.T1.6.6.6.2.m1.1.1.3.2\">𝑎</ci><ci id=\"S2.T1.6.6.6.2.m1.1.1.3.3.cmml\" xref=\"S2.T1.6.6.6.2.m1.1.1.3.3\">𝑠</ci><ci id=\"S2.T1.6.6.6.2.m1.1.1.3.4.cmml\" xref=\"S2.T1.6.6.6.2.m1.1.1.3.4\">𝑖</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.6.6.6.2.m1.1c\">M_{asi}</annotation></semantics></math></td>\n</tr>\n<tr id=\"S2.T1.9.9.9\" class=\"ltx_tr\">\n<td id=\"S2.T1.9.9.9.4\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Worker model weights</td>\n<td id=\"S2.T1.8.8.8.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">The weights of the model locally held by worker <math id=\"S2.T1.7.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"x\" display=\"inline\"><semantics id=\"S2.T1.7.7.7.1.m1.1a\"><mi id=\"S2.T1.7.7.7.1.m1.1.1\" xref=\"S2.T1.7.7.7.1.m1.1.1.cmml\">x</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.7.7.7.1.m1.1b\"><ci id=\"S2.T1.7.7.7.1.m1.1.1.cmml\" xref=\"S2.T1.7.7.7.1.m1.1.1\">𝑥</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.7.7.7.1.m1.1c\">x</annotation></semantics></math> (based on version <math id=\"S2.T1.8.8.8.2.m2.1\" class=\"ltx_Math\" alttext=\"i\" display=\"inline\"><semantics id=\"S2.T1.8.8.8.2.m2.1a\"><mi id=\"S2.T1.8.8.8.2.m2.1.1\" xref=\"S2.T1.8.8.8.2.m2.1.1.cmml\">i</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.8.8.8.2.m2.1b\"><ci id=\"S2.T1.8.8.8.2.m2.1.1.cmml\" xref=\"S2.T1.8.8.8.2.m2.1.1\">𝑖</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.8.8.8.2.m2.1c\">i</annotation></semantics></math> of the aggregation server and trained for j times)</td>\n<td id=\"S2.T1.9.9.9.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math id=\"S2.T1.9.9.9.3.m1.3\" class=\"ltx_Math\" alttext=\"Mw_{x,i,j}\" display=\"inline\"><semantics id=\"S2.T1.9.9.9.3.m1.3a\"><mrow id=\"S2.T1.9.9.9.3.m1.3.4\" xref=\"S2.T1.9.9.9.3.m1.3.4.cmml\"><mi id=\"S2.T1.9.9.9.3.m1.3.4.2\" xref=\"S2.T1.9.9.9.3.m1.3.4.2.cmml\">M</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.9.9.9.3.m1.3.4.1\" xref=\"S2.T1.9.9.9.3.m1.3.4.1.cmml\">​</mo><msub id=\"S2.T1.9.9.9.3.m1.3.4.3\" xref=\"S2.T1.9.9.9.3.m1.3.4.3.cmml\"><mi id=\"S2.T1.9.9.9.3.m1.3.4.3.2\" xref=\"S2.T1.9.9.9.3.m1.3.4.3.2.cmml\">w</mi><mrow id=\"S2.T1.9.9.9.3.m1.3.3.3.5\" xref=\"S2.T1.9.9.9.3.m1.3.3.3.4.cmml\"><mi id=\"S2.T1.9.9.9.3.m1.1.1.1.1\" xref=\"S2.T1.9.9.9.3.m1.1.1.1.1.cmml\">x</mi><mo id=\"S2.T1.9.9.9.3.m1.3.3.3.5.1\" xref=\"S2.T1.9.9.9.3.m1.3.3.3.4.cmml\">,</mo><mi id=\"S2.T1.9.9.9.3.m1.2.2.2.2\" xref=\"S2.T1.9.9.9.3.m1.2.2.2.2.cmml\">i</mi><mo id=\"S2.T1.9.9.9.3.m1.3.3.3.5.2\" xref=\"S2.T1.9.9.9.3.m1.3.3.3.4.cmml\">,</mo><mi id=\"S2.T1.9.9.9.3.m1.3.3.3.3\" xref=\"S2.T1.9.9.9.3.m1.3.3.3.3.cmml\">j</mi></mrow></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.9.9.9.3.m1.3b\"><apply id=\"S2.T1.9.9.9.3.m1.3.4.cmml\" xref=\"S2.T1.9.9.9.3.m1.3.4\"><times id=\"S2.T1.9.9.9.3.m1.3.4.1.cmml\" xref=\"S2.T1.9.9.9.3.m1.3.4.1\"></times><ci id=\"S2.T1.9.9.9.3.m1.3.4.2.cmml\" xref=\"S2.T1.9.9.9.3.m1.3.4.2\">𝑀</ci><apply id=\"S2.T1.9.9.9.3.m1.3.4.3.cmml\" xref=\"S2.T1.9.9.9.3.m1.3.4.3\"><csymbol cd=\"ambiguous\" id=\"S2.T1.9.9.9.3.m1.3.4.3.1.cmml\" xref=\"S2.T1.9.9.9.3.m1.3.4.3\">subscript</csymbol><ci id=\"S2.T1.9.9.9.3.m1.3.4.3.2.cmml\" xref=\"S2.T1.9.9.9.3.m1.3.4.3.2\">𝑤</ci><list id=\"S2.T1.9.9.9.3.m1.3.3.3.4.cmml\" xref=\"S2.T1.9.9.9.3.m1.3.3.3.5\"><ci id=\"S2.T1.9.9.9.3.m1.1.1.1.1.cmml\" xref=\"S2.T1.9.9.9.3.m1.1.1.1.1\">𝑥</ci><ci id=\"S2.T1.9.9.9.3.m1.2.2.2.2.cmml\" xref=\"S2.T1.9.9.9.3.m1.2.2.2.2\">𝑖</ci><ci id=\"S2.T1.9.9.9.3.m1.3.3.3.3.cmml\" xref=\"S2.T1.9.9.9.3.m1.3.3.3.3\">𝑗</ci></list></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.9.9.9.3.m1.3c\">Mw_{x,i,j}</annotation></semantics></math></td>\n</tr>\n<tr id=\"S2.T1.11.11.11\" class=\"ltx_tr\">\n<td id=\"S2.T1.11.11.11.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Worker averaging weights</td>\n<td id=\"S2.T1.10.10.10.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">Weights allocated for weighted federated averaging for worker <math id=\"S2.T1.10.10.10.1.m1.1\" class=\"ltx_Math\" alttext=\"x\" display=\"inline\"><semantics id=\"S2.T1.10.10.10.1.m1.1a\"><mi id=\"S2.T1.10.10.10.1.m1.1.1\" xref=\"S2.T1.10.10.10.1.m1.1.1.cmml\">x</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.10.10.10.1.m1.1b\"><ci id=\"S2.T1.10.10.10.1.m1.1.1.cmml\" xref=\"S2.T1.10.10.10.1.m1.1.1\">𝑥</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.10.10.10.1.m1.1c\">x</annotation></semantics></math>\n</td>\n<td id=\"S2.T1.11.11.11.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><math id=\"S2.T1.11.11.11.2.m1.1\" class=\"ltx_Math\" alttext=\"WEI_{x}\" display=\"inline\"><semantics id=\"S2.T1.11.11.11.2.m1.1a\"><mrow id=\"S2.T1.11.11.11.2.m1.1.1\" xref=\"S2.T1.11.11.11.2.m1.1.1.cmml\"><mi id=\"S2.T1.11.11.11.2.m1.1.1.2\" xref=\"S2.T1.11.11.11.2.m1.1.1.2.cmml\">W</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.11.11.11.2.m1.1.1.1\" xref=\"S2.T1.11.11.11.2.m1.1.1.1.cmml\">​</mo><mi id=\"S2.T1.11.11.11.2.m1.1.1.3\" xref=\"S2.T1.11.11.11.2.m1.1.1.3.cmml\">E</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S2.T1.11.11.11.2.m1.1.1.1a\" xref=\"S2.T1.11.11.11.2.m1.1.1.1.cmml\">​</mo><msub id=\"S2.T1.11.11.11.2.m1.1.1.4\" xref=\"S2.T1.11.11.11.2.m1.1.1.4.cmml\"><mi id=\"S2.T1.11.11.11.2.m1.1.1.4.2\" xref=\"S2.T1.11.11.11.2.m1.1.1.4.2.cmml\">I</mi><mi id=\"S2.T1.11.11.11.2.m1.1.1.4.3\" xref=\"S2.T1.11.11.11.2.m1.1.1.4.3.cmml\">x</mi></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.11.11.11.2.m1.1b\"><apply id=\"S2.T1.11.11.11.2.m1.1.1.cmml\" xref=\"S2.T1.11.11.11.2.m1.1.1\"><times id=\"S2.T1.11.11.11.2.m1.1.1.1.cmml\" xref=\"S2.T1.11.11.11.2.m1.1.1.1\"></times><ci id=\"S2.T1.11.11.11.2.m1.1.1.2.cmml\" xref=\"S2.T1.11.11.11.2.m1.1.1.2\">𝑊</ci><ci id=\"S2.T1.11.11.11.2.m1.1.1.3.cmml\" xref=\"S2.T1.11.11.11.2.m1.1.1.3\">𝐸</ci><apply id=\"S2.T1.11.11.11.2.m1.1.1.4.cmml\" xref=\"S2.T1.11.11.11.2.m1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S2.T1.11.11.11.2.m1.1.1.4.1.cmml\" xref=\"S2.T1.11.11.11.2.m1.1.1.4\">subscript</csymbol><ci id=\"S2.T1.11.11.11.2.m1.1.1.4.2.cmml\" xref=\"S2.T1.11.11.11.2.m1.1.1.4.2\">𝐼</ci><ci id=\"S2.T1.11.11.11.2.m1.1.1.4.3.cmml\" xref=\"S2.T1.11.11.11.2.m1.1.1.4.3\">𝑥</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.11.11.11.2.m1.1c\">WEI_{x}</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In this section, we discuss the required FL concepts, review techniques targeting to optimize FL based on system parameters, and describe FogBus2’s main components. The terminologies used for FL are summarized in table I."
        ]
    },
    "S2.SS2.SSS1.tab1": {
        "caption": "TABLE II: Recent research on system parameter-based federated learning optimisation",
        "table": "<table id=\"S2.SS2.SSS1.tab1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S2.SS2.SSS1.tab1.3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.1\" class=\"ltx_td ltx_align_right\">Work</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.1.1.2.1.1\" class=\"ltx_p\">Implementation</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_right\">Updt</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.4\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.5\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.6\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.7\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.8\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.9\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.10\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.11\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.12\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.13\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.14\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.15\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.16\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.17\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.18\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.19\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.20\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.21\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.22\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.23\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.24\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.25\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.1.1.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.1\" class=\"ltx_td ltx_align_right\">Freq</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.2.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.2.2.2.1.1\" class=\"ltx_p\">Perf</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.3\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.4\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.5\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.6\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.7\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.8\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.9\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.10\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.11\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.12\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.13\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.14\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.15\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.16\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.17\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.18\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.19\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.20\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.21\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.22\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.23\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.24\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.25\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.2.2.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.1\" class=\"ltx_td ltx_align_right\">Check</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.3.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.3.3.2.1.1\" class=\"ltx_p\">Time</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.3\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.4\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.5\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.6\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.7\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.8\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.9\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.10\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.11\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.12\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.13\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.14\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.15\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.16\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.17\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.18\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.19\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.20\" class=\"ltx_td ltx_align_center\" style=\"width:0.0pt;\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.21\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.22\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.23\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.24\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.25\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.3.3.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.1\" class=\"ltx_td ltx_align_right\">Const</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.4.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.4.4.2.1.1\" class=\"ltx_p\">Asyn</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.3\" class=\"ltx_td ltx_align_center\">WSP</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.4\" class=\"ltx_td ltx_align_right\">System Paramters</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.5\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.6\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.7\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.8\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.9\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.10\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.4.4.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.4.4.11.1.1\" class=\"ltx_p\">Tuned FL Parameters</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.12\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.13\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.14\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.15\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.16\" class=\"ltx_td ltx_align_right\">Derived Parameters</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.17\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.18\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.19\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.20\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.21\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.22\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.23\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.24\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.25\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.4.4.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.5.5\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.1\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.2\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.3\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.4\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.5\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.6\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.7\" class=\"ltx_td\"></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.5.5.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.5.5.8.1.1\" class=\"ltx_p\">F</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.9\" class=\"ltx_td ltx_align_center\">P</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.10\" class=\"ltx_td ltx_align_right\">B</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.5.5.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.5.5.11.1.1\" class=\"ltx_p\">G</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.12\" class=\"ltx_td ltx_align_center\">D</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.13\" class=\"ltx_td ltx_align_right\">WDS</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.5.5.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.5.5.14.1.1\" class=\"ltx_p\">WL</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.15\" class=\"ltx_td ltx_align_center\">T</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.16\" class=\"ltx_td ltx_align_right\">t</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.5.5.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.5.5.17.1.1\" class=\"ltx_p\">MDR</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.18\" class=\"ltx_td ltx_align_center\">OR</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.19\" class=\"ltx_td ltx_align_right\">TDS</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.5.5.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.5.5.20.1.1\" class=\"ltx_p\">TC</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.21\" class=\"ltx_td ltx_align_center\">TU</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.22\" class=\"ltx_td ltx_align_center\">TW</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.23\" class=\"ltx_td ltx_align_left\">EC</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.24\" class=\"ltx_td ltx_align_left\">EU</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.25\" class=\"ltx_td ltx_align_right\">L</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.5.5.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.6.6\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib21\" title=\"\" class=\"ltx_ref\">21</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.2.1.1\" class=\"ltx_p\">Analytical</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.3\" class=\"ltx_td ltx_align_center\">Epoch</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.4\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.7\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.9\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.11.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.12\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.13\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.14.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.15\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.16\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.19\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.6.6.20.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.21\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.22\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.23\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.24\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.25\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.6.6.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.7.7\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.2.1.1\" class=\"ltx_p\">Analytical</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.3\" class=\"ltx_td ltx_align_center\">Epoch</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.4\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.7\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.9\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.11.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.12\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.13\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.14.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.15\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.16\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.19\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.7.7.20.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.21\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.22\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.23\" class=\"ltx_td ltx_align_left\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.24\" class=\"ltx_td ltx_align_left\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.25\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.7.7.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.8.8\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\">26</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.2.1.1\" class=\"ltx_p\">Analytical</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.3\" class=\"ltx_td ltx_align_center\">Epoch</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.4\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.7\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.9\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.11.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.12\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.13\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.14.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.15\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.16\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.19\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.8.8.20.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.21\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.22\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.23\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.24\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.25\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.8.8.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.9.9\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.2.1.1\" class=\"ltx_p\">Simulation</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.3\" class=\"ltx_td ltx_align_center\">Once</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.4\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.7\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.9\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.11.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.12\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.13\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.14.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.15\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.16\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.19\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.9.9.20.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.21\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.22\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.23\" class=\"ltx_td ltx_align_left\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.24\" class=\"ltx_td ltx_align_left\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.25\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.9.9.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.10.10\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.2.1.1\" class=\"ltx_p\">Simulation</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.3\" class=\"ltx_td ltx_align_center\">Epoch</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.4\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.5.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.7\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.9\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.11.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.12\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.13\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.14.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.15\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.16\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.19\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.10.10.20.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.21\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.22\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.23\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.24\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.25\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.10.10.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.11.11\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib29\" title=\"\" class=\"ltx_ref\">29</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.2.1.1\" class=\"ltx_p\">Simulation</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.3\" class=\"ltx_td ltx_align_center\">Epoch</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.4\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.5.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.7\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.9\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.11.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.12\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.13\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.14.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.15\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.16\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.17.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.19\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.11.11.20.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.21\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.22\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.23\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.24\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.25\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.11.11.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.12.12\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">24</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.2.1.1\" class=\"ltx_p\">Simulation</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.3\" class=\"ltx_td ltx_align_center\">Epoch</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.4\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.7\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.9\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.11.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.12\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.13\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.14.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.15\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.16\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.19\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.12.12.20.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.21\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.22\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.23\" class=\"ltx_td ltx_align_left\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.24\" class=\"ltx_td ltx_align_left\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.25\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.12.12.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.13.13\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib20\" title=\"\" class=\"ltx_ref\">20</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.2.1.1\" class=\"ltx_p\">Prototype</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.3\" class=\"ltx_td ltx_align_center\">Epoch</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.4\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.7\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.9\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.11.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.12\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.13\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.14.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.15\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.16\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.19\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.13.13.20.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.21\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.22\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.23\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.24\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.25\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.13.13.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.14.14\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">28</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.2.1.1\" class=\"ltx_p\">Prototype</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.3\" class=\"ltx_td ltx_align_center\">Epoch</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.4\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.7\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.9\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.11.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.12\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.13\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.14.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.15\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.16\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.19\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.14.14.20.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.21\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.22\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.23\" class=\"ltx_td ltx_align_left\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.24\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.25\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.14.14.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.15.15\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib30\" title=\"\" class=\"ltx_ref\">30</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.2.1.1\" class=\"ltx_p\">Prototype</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.3\" class=\"ltx_td ltx_align_center\">Once</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.4\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.7\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.9\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.10\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.11.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.12\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.13\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.14.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.15\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.16\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.19\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.15.15.20.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.21\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.22\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.23\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.24\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.25\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.15.15.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.16.16\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.1\" class=\"ltx_td ltx_align_right\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite></td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.2.1.1\" class=\"ltx_p\">Prototype</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.3\" class=\"ltx_td ltx_align_center\">Epoch</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.4\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.5.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.6\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.7\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.9\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.11.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.12\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.13\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.14.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.15\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.16\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.19\" class=\"ltx_td ltx_align_right\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.16.16.20.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.21\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.22\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.23\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.24\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.25\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.16.16.26\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S2.SS2.SSS1.tab1.3.1.17.17\" class=\"ltx_tr\">\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.1\" class=\"ltx_td ltx_align_right\">FLight</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.2.1.1\" class=\"ltx_p\">Prototype</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.3\" class=\"ltx_td ltx_align_center\">Epoch</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.4\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.6\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.7\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.8\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.8.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.9\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.10\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.11\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.11.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.11.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.12\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.13\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.14\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.14.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.14.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.15\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.16\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.17\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.17.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.17.1.1\" class=\"ltx_p\">✗</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.18\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.19\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.20\" class=\"ltx_td ltx_align_center\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.20.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.SS2.SSS1.tab1.3.1.17.17.20.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.21\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.22\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.23\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.24\" class=\"ltx_td ltx_align_left\">✗</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.25\" class=\"ltx_td ltx_align_right\">✓</td>\n<td id=\"S2.SS2.SSS1.tab1.3.1.17.17.26\" class=\"ltx_td\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "This section identifies important parameters in FL and summarizes the properties of the current literature considering the identified parameters. Table II-B1 depicts an overview of the current FL studies and their properties. In what follows, the identified parameters and their respective symbols in the table are explained.Implementation level: A prototype system refers to the technique that is deployed on different servers, and the results are practically verified. Analytical refers to only mathematically modeling the FL training process, such that the training time and accuracy of the underlying model are not tested on any data but tested by mathematical models. Simulation mimics the network delay and computation difference on a single server.Update Frequency (Updt Freq): It refers to the frequency of updates (i.e., optimization) in each technique. While each epoch means the optimization strategy will be updated each time the aggregation server finishes aggregating model weights, once means the optimization policy is only calculated once and will keep steady throughout the FL training process.Performance Check (Perf Check): It describes whether performance is analyzed throughout the FL training.Time Constraint: It shows whether training time is considered a constraint throughout the training process.Asynchronous (Asyn): It identifies if the technique can run asynchronously.Worker Selection Policy (WSP): It identifies if the technique offers worker selection policy.System parameters: It is the raw statistics extracted from a system used to formulate FL optimization algorithms. These statistics include: 1) F: processor frequency, 2) P: transmission power, 3) B: bandwidth, 4) G: channel gain, 5) D: aggregation server and worker distance, 6) WDS: worker data size, 7) WL: Workload required to compute one epoch of training from the worker side.Tuned FL Parameters: 1) T: Total epoch number trained throughout the FL, 2) t: Number of epochs trained on workers between two aggregation processes from the aggregation server, 3) MDR: model dropout ratio, 4) TDS: training data size, 5) OR: offloading ratio.Derived Parameter: 1) TC: the time required for workers to communicate model weights, 2) TU: the time required for training as well as loading the model, 3) TW: the time required to wait until an aggregation server or a worker is available, 4) EC: energy required for local training, 5) EU: energy required to upload the model, 6) L: training loss.Considering the current literature, each work depends on different system parameters and derives different intermediate results for optimization purposes. However, the current literature always compares their performance with no optimization or random worker selection policy [20, 21, 27, 22, 23, 28, 29, 24, 30, 25, 26], which partially proves the proposed algorithms’ necessity. However, it is hard to compare these works against each other because reproducing the experimental results is cumbersome due to the difference between their system setup and programming style. Consequently, implementing an FL framework that allows different techniques to be integrated allows a fair comparison for studying the effectiveness of different techniques. Besides, none of the works has studied the asynchronous FL to utilize the full computational capacity of workers. While unselected workers have to wait until the next round of federated worker selection to contribute to the FL training, asynchronous FL permits all workers to participate in FL. This is because asynchronous FL is not concerned about slow workers to keep fast workers waiting. Instead, asynchronous FL can start aggregation when fast workers finish responding with their trained model weights. Also, when slow workers finish training, the aggregation server can merge the results from slow workers. Moreover, the worker selection policy is required to select the most suitable workers for the purpose of FL training.Accordingly, to address these challenges, we design a lightweight FL framework called FLight by extending the FogBus2 resource management framework. Flight provides a mechanism to integrate different worker selection policies and also proposes a lightweight policy. Finally, FLight offers asynchronous FL to further improve the current literature.To implement the FL framework based on system parameters, the above-mentioned system parameters should be provided for the FL on demand. Moreover, the FL framework requires access and manage distributed servers in the environment, which are often highly heterogeneous in terms of hardware, operating systems, and software. Besides, the connection establishment stage of the FL requires various interaction models and online information about the whole system. To satisfy these requirements, the FogBus2 framework [31] is chosen as the underlying resource management framework.FogBus2 is a new Python-based framework consisting of five lightweight and containerized modules (called Master, Actor, User, Task Executor, and RemoteLogger) that support centralized, distributed, and hierarchical deployments. To suit different resource management requirements, it offers several mechanisms and associated policies, including registration, profiling, scheduling, scalability, dynamic resource discovery, IoT application integration, database integration, etc.FogBus2 provides systems parameters required for the FL, such as CPU frequency, RAM, resource utilization, and networking characteristics, just to mention a few, using a profiling module integrated into its main components. It supports on-demand and periodical profiling, which is helpful for asynchronous FL that frequently merges model weights from workers. After each merging, new worker selection can be conducted, resulting in a more frequent worker selection process. Frequent updates about system parameters among workers allow asynchronous FL to update worker selection accordingly. A more dynamic and adaptive worker selection policy results in more time-efficient FL. This suggests that frequent system parameter update is beneficial for more efficient FL practice. Also, systems parameters in the FogBus2 framework are accessible centrally and also in distributed databases, facilitating the process of obtaining system parameters.As FogBus2 is dockerized [32], it helps the FL framework to be easily deployed on machines with heterogeneous environments and various operating systems. FL intends to train ML models, requiring support from different ML libraries such as PyTorch. While manually installing ML dependencies on different operating systems require various configuration, containerized FogBus2 framework facilitates this process by adding required dependencies to the configuration file.Finally, FogBus2 provides a resource discovery sub-module that facilitates the connection establishment process of FL. The connection establishment process of FL occurs when different participants connect with each other and know their role in the FL framework. This requires network configuration to allow different servers to communicate with each other while message handlers on each server need to forward the message to the FL training agent. Moreover, it requires the participant who starts the FL process to be aware of potentially available computing resources within the network, so it can send initiative commands and invite them to participate in FL. Moreover, it has integrated task allocation policies, allowing all available sites with sufficient computing resources to conduct FL training, which is convenient for testing and verifying FL implementation.In this section, we describe the FLight framework and how it extends the FogBus2 framework.The relationship between the FL module and FogBus2 framework is shown in Fig. 1. In this figure, bold dashed boxes show sub-components of FogBus2 that provide information to the FL module. Moreover, the FL module overrides the TaskExecutor component originally available in FogBus2. This section introduces how FogBus2 components can provide information to support the FL. Then, it describes how the FL module exists as tasks in the TaskExecutor component of FogBus2.The Sensor sub-component in the User component of FogBus2 is used to grasp input from users and forward it to the Master component, which will be further forwarded to the executor within the TaskExecutor component. Executors are classes that run FL tasks as functions, where function inputs are users’ inputs stored in a dictionary. The Sensor sub-component is then configured to ask hyperparameters from users for the FL training process. While there can be various hyperparameters specific to different deployed FL algorithms, current hyperparameters collected from users include:\n1) The model shared by participants cooperating in the FL training,\n2) Total number of aggregations to perform on the aggregation server side,\n3) Number of training epochs each worker has to complete before contributing the local model weights to the FL aggregation process,\n4) Whether the FL training is conducted synchronously or asynchronously, and\n5) The learning rate initially used by different workers to update the model.\nWhen the FL application runs in FogBus2 and all corresponding TaskExecutors are ready, the Sensor sub-component collects those hyperparameters from users. It is the first step of the FL training. Next, different executors will conduct FL training based on hyperparameters.In the FL implementation, different participants must regularly communicate with each other to transmit messages and model weights. This requires that different TaskExecutors running FL tasks know the IP address and port number of other FL TaskExecutors before FL training starts. In FogBus2, different tasks within an application are linked to each other according to a dependency graph. In the dependency graph, a task may be the parent of one/several tasks and be the child of one/several tasks. Also, results from parents will be forwarded to their children as input to task function calls on children. This feature is used to transmit the IP address and port number between different TaskExecutors of FL. The aggregation server is responsible for starting the FL training process by creating the FL model and calling selected workers to start training. This makes the Executor running the aggregation server know the network address of all other Executors running as workers so that it can send instructions. Other Executors running as workers only need to wait until the aggregation server contacts them, so the network address of the aggregation server is available, and they can send messages back. Thus, the implementation lets the task that operates as the aggregation server be a child task of all other tasks which run as workers. Moreover, the implementation lets the returning results of tasks that run as workers be the network address to which they are listening. These results will be inputs of the task running the aggregation server. In this way, the aggregation server can have the network address of all other workers before FL training starts.Since Executors running as workers need to return the network address to which they are listening, they need to listen to that address. In order to make the Executor aware of the IP address for tasks running FL training, the implementation takes the IP address from the Actor module. The Actor component is responsible for starting the docker container of the TaskExecutor component in place. Thus, the Actor is physically on the same machine as the TaskExecutor, which makes the IP address of the Message Handler sub-component of the Actor module the same as the IP address of the Executor. The implementation adds a tag noting whether input data from users are related to FL or not. When the Actor component calls the TaskExecutor component to start tasks, it will add the IP address of its Message Handler to the input dictionary if the tag indicating tasks are related to FL. Since the Executor running FL tasks needs to communicate with each other regularly, the implementation lets them communicate with a separate port instead of the port used by the Message Handler sub-component to avoid congestion. The port is subject to the port availability of the machine running TaskExecutor. In this way, the TaskExecutor can start the socket server listening on the same IP address and different port compared to the Message Handler of the Actor, initializing it for FL purposes.The Profiler sub-component in FogBus2 is responsible for collecting statistics related to available system resources. FL optimization depends on parameters describing available system resources. Since the Actor initializes the TaskExecutor, the Profiler sub-component within the Actor is physically on the same machine as the Executor sub-component within TaskExecutor. Thus, data from Profiler of Actor also describe available resources for the Executor running FL tasks. The aggregation server is responsible for making optimization decisions, so it requires system parameters from all workers. The FLight implementation uses the property that parent tasks will pass results to child tasks to pass profiling information from worker Executors to the aggregation Executor. This is achieved by adding profiling data to Executor running as worker results if tasks are tagged as relating to FL. The TaskExecutor that runs the aggregation server will then receive the profiling information, which can be exploited to implement different FL optimization mechanisms accordingly.After properly initializing the aggregation server Executor and multiple worker Executors, the necessary information is ready for FL tasks. In particular, worker Executors will start the socket server listening for instructions from the aggregation server. At the same time, the aggregation server Executor will own the network addresses of socket servers on workers, as well as profiling information describing available computing resources. Then, the aggregation server task call functions from the FL component to define the FL process and execute the training accordingly. It is worth noting that Executors running as workers still are kept alive by holding the socket server on a separate thread after returning the socket server address. This is different from other tasks in FogBus2 that will terminate after returning results for children’s tasks. This is because worker tasks still need to regularly listen to instructions from the aggregation server to perform FL training.In this section, we describe how FogBus2’s TaskExecutor component is extended to enable FL. Fig.  2 shows the design of FL implementation and its sub-components.The FL components take the network address of other Executors and statistics of available resources from Executors of the FogBus2 framework. The FL component is divided into three sub-components: 1) ML APIs, 2) FL Communicator, and 3) Data warehouse. The Data warehouse sub-component allows easy storage and data access required by FL. Moreover, the FL Communicator is used for communicating messages between different participants of FL training and handling them correspondingly. Lastly, ML APIs are sub-components that encapsulate FL logic such that calling those APIs is sufficient to define FL training. Overriding those APIs enables new ML models to be trained by FL.Figure 3 shows the design of the data warehouse sub-component. This sub-component is responsible for providing an interface to access and store all kinds of data related to FL training. In FL training, data that needs to be stored includes 1) ML classes, 2) Parameter weights of ML models, 3) Parameter weights of ML models of other participants, and 4) Training Data. These four types of data can be placed in different storage, including RAM, remote repository, database, or files on local storage. However, to write and retrieve data from these storages, different implementations are required. The data warehouse sub-component encapsulates these various implementations. The data warehouse provides the getter and setter functions such that all kinds of data can be accessed by providing a unique ID. Moreover, if data is saved to the warehouse for the first time, the sub-component will return an ID that uniquely identifies that data. When a unique ID is provided to the getter function, the data warehouse uses the ID to retrieve the saved credentials and storage type used to store the data corresponding to the provided ID. Then it will use those credentials to retrieve the actual data. While setters allow data to be stored on a specified type of storage, default storage for ML model weights and training data is set to the local disk.This design allows extension for different storage types. Defining a new storage type can be done by defining the methods to write and retrieve data and then adding that to the data warehouse. Due to the design that only a unique ID is sufficient to retrieve data, the ML model, which is one type of data, can be referred to only by the ID locally. Referring to a remote ML model needs to specify the network address as well. This gives rise to the idea of the Pointer class, used by FL training participants to identify a model on a remote site uniquely. The Pointer class consists of the data warehouse’s network address and unique ID for it. For example, when the aggregation server asks a remote worker to conduct training, multiple worker network addresses can be saved, and each worker can own several ML models. The aggregation server can provide the address to uniquely identify the worker and the unique ID to identify the model on that worker.Fig. 4 shows the design of the FL communicator. Since FL training involves frequent message communication between different parties, the FL implementation provides its communicator. The FL communicator’s sub-component consists of a socket server, a message converter, a message dispatcher, and handlers. The socket server is a server that listens to incoming messages via a receiver and sends out messages by the sender. All messages that go through the socket server are binary data. The message converter is responsible for converting messages into binary formats so that data can be transmitted between the local message sender and remote message receiver. The message dispatcher uses message types to forward messages to corresponding handlers. There are three handlers in the implementation. Firstly, the relationship handler is responsible for handling incoming requests for establishing an FL relationship. For example, if the aggregation server asks a remote site to be the worker of itself, then the relationship handler on that remote site is responsible for handling related messages. Secondly, training handlers are responsible for handling messages related to FL training. This includes the aggregation server asking a worker to start training, and the worker acknowledges to the server that local training is complete. Lastly, model transmission handlers are responsible for sending a request to fetch the weights of a remote model and send back the credentials required to download the weights.It is important to note that the weights are not transmitted directly through the socket connection between the message sender and receiver. This is because model weights are large compared to other messages. If weights are sent over the communication channel of FL, other messages have to wait for the weights to finish transmission. This long waiting time influences the time efficiency if the weights are sent over the communication channel of FL. Alternatively, in FLight, when a server receives the request to fetch a local model weight, the server saves the weights to a File Transmission Protocol (FTP) server and sends back a one-time login credential. The remote server fetching the model weights can use the credential to log in to the FTP server and download through FTP.\nFig. 5 shows the design of the ML APIs sub-component. This sub-component is a minimum set of functions that an ML model requires to define for the training of different participants. All these functions are collected into a single class. Therefore, ML models can override functions to be deployed for FL training. ML APIs are further divided into relationships, training, and transmission APIs.Relationship APIs are functions to establish a relationship with other models. It includes functions to request remote servers to act as its workers or request being workers of a remote aggregation server. Functions related to relationships first send a message via the communication sub-component, and the relationship handler on other sites will handle the forwarded message. Training APIs are functions related to ML training, including remote and local training functions. Remote training APIs are functions used by aggregation servers to request a remote worker to perform specified rounds of training. Those functions need a pointer class that refers to a remote model as an argument. So the message sender within the FL communication sub-component can use the network address within the pointer to send the message to a remote message receiver, and the handler can use a unique ID within the pointer on the remote side to retrieve the model via getter of the data warehouse module. Local training APIs are functions used to conduct some calculations on a locally stored model. These include functions to conduct training based on available data, which is the same as regular ML training. Moreover, local training APIs include various functions to federate model weights from workers for the aggregation server based on different algorithms. Besides, Model transmission APIs are functions used to transfer model weights between different participants. Fetcher functions are responsible for sending messages requesting remote model weights. After receiving the fetch request, the FTP access generator on the remote side generates a credential that the participant uses to fetch the model and downloads the model weights from the FTP server. The actual download functionality is implemented in the Downloader.The ML APIs, FL communicator, and data warehouse sub-components enable FL mechanisms. This section presents how these different sub-components cooperate together to enable important functionalities, including the addition of a worker, model transmission between different servers, and conducting the training.The sub-components to add a remote server as a worker is shown in Fig. 6, while Fig. 7 depicts the corresponding sequence diagram. The aggregation server is called side S𝑆S, and the worker is denoted by W𝑊W. The function is called on side S𝑆S initially, which contains the following steps: 1) Before calling the function, an ML model should be created on the side S𝑆S. 2) User first calls the relationship function in the ML APIs sub-component for worker addition on S𝑆S. Then, S𝑆S requests W𝑊W to create an ML model with the same structure and initiate the worker model. 3) After calling the function of worker addition, the message sender on S𝑆S is called to send an invitation to the remote participant regarding the network address. Function arguments also include the unique ID of the aggregation server model. Then, W𝑊W creates a pointer class composed of the network address of the message sender on side S𝑆S and a unique ID of the aggregation server model. The remote worker model can use this pointer to refer to its server model. 4) The communicator calls the message converter on S𝑆S to pack the message into a tuple and serialize it into binary data for socket transmission. 5) After receiving data in binary format, the message sender on S𝑆S sends the data over the socket to the message receiver on W𝑊W. 6) The message receiver on W𝑊W interprets the message and sends the remaining messages to the relationship handler on W𝑊W. 7) The relationship handler on W𝑊W creates a model with an identical structure to the aggregation server model on W𝑊W. The model is also added to the data warehouse sub-component for later retrieval. 8) The worker model on side W𝑊W saves the unique ID of the aggregation server model and the S𝑆S network address as the server model’s pointer. Next, the worker model is ready for further instructions, such as training. 9) The relationship handler on W𝑊W informs S𝑆S that the worker model is ready. The message contains the unique ID of the worker model and the aggregation server model, as well as the network address of the S𝑆S. Then the message passes through the converter, which serializes the message and transmits the message through a socket. 10) After S𝑆S receives the acknowledgment from W𝑊W that the worker model is ready, it lets the relationship handler on S𝑆S handle the message. 11) The relationship handler on S𝑆S uses the server ID to retrieve the aggregation server model from the data warehouse. After that, the pointer referring to the worker model, which consists of the unique ID of the worker model and the network address of W𝑊W, will be recorded into the aggregation server model class. After these steps, the aggregation server model on S𝑆S has one extra stored worker model pointer. Moreover, the worker model on W𝑊W has one stored server pointer, referring to the aggregation server model.Fig. 8 shows the sub-components involved in communicating model weights between servers, while Fig. 9 depicts the respective sequence diagram. We assume the server fetching the model weight is F𝐹F, and the server that sends back model weights is on side S𝑆S. 1) A model on F𝐹F calls a fetching model function within the model transmission APIs. Arguments include a pointer referring to the remote model from which the local model fetches weights. Moreover, identification information, such as the unique ID of the model on F𝐹F, is also provided. 2) Message is then serialized by a message converter and sent out by the message sender on F𝐹F. The message converter will also add an additional tag to indicate that the message is about fetching the model so that the remote handler can react correspondingly. 3) When the message receiver on S𝑆S gets the message, the dispatcher forwards the message to its own model transmission handlers. The handler checks the pointer that F𝐹F has sent and uses the ID to retrieve the ML model from the data warehouse. 4) If the model exists, S𝑆S also checks whether it has the privilege to access its weights. Since model weights are not shared in public, it has to check for the identity of remote servers fetching it. 5) If the access check passes, the model transmission handler exports the model weights to a file in the FTP server. 6) The model transmission handler on S𝑆S collects the file name where model weights are stored and also login credentials for downloading that file from the FTP server as a response. 7) The credential will be sent back from S𝑆S to F𝐹F. 8) After the message receiver on F𝐹F gets the message and forwards it to the model transmission handler, the handler sends out a fetch request. 9) If the check suggests the local model still wants remote model weights, then the model transmission handler will use the Downloader function to log in to the FTP server and download model weights to a local file. After these steps, a file containing the latest model weights of a remote model at the time of fetching is generated on S𝑆S.Fig. 10 shows the sub-component involved when an aggregation server asks a remote worker to train, while Fig. 11 depicts the respective sequence diagram. Let’s represent the aggregation server by S𝑆S and the remote worker by W𝑊W: 1) Starting from S𝑆S, the user calls the function from the Training APIs sub-component in an aggregation server model. The argument points to a remote worker model asking to train and the number of training epochs. 2) The function call in APIs serializes the message by message converter on S𝑆S. The serialized message is then forwarded to site W𝑊W with a specified network address. 3) After receiving the message asking the worker model to conduct training, the dispatcher on W𝑊W returns the training handler to handle the message. 4) The training handler first retrieves the local worker model based on the pointer that S𝑆S provided. Next, the training handler checks whether the local model agrees to conduct specified training or not. Reasons for rejecting training instructions from a remote server may include the remote server is not recognized by the worker model or there are insufficient computation resources at the moment. 5) The worker model on W𝑊W fetches the aggregation server model weights. 6) After receiving the aggregation server model weights from S𝑆S, the original parameter weights of the worker model will be replaced by aggregation server model weights. Next, the model is trained based on a specified epoch number. The training data comes from local data files, and the FLight framework support reading from the database for real-time applications or a local file for testing purposes. 7) After the training, W𝑊W acknowledges the training is done by sending the message back to S𝑆S. The acknowledgment message contains pointers to the worker model and the aggregation server. 8) When the acknowledgment is received on S𝑆S, the training handler controls the remaining message. It retrieves the aggregation server model from the data warehouse module and then checks if the aggregation server model still requires results from W𝑊W. This is because the aggregation server can finish multiple rounds of aggregation while the worker model on W𝑊W conducts training. In this way, model weights from W𝑊W are outdated and useless. In the asynchronous FL case, the aggregation server takes the results no matter how many rounds of aggregation have already been conducted. The criteria for whether accepting results from a worker can be overridden by other logic for other use cases. 9) If the model accepts the model weights from the worker model on W𝑊W, it fetches the model weights. After these steps, the aggregation server has a new file containing the model weights of a remote worker model. The aggregation server model can use weights to update local weights via aggregation.When the aggregation server model receives enough model weights or reaches a time limit, it then aggregates the received model weights. The default implementation of the FLight for synchronous FL waits until a specified amount of model weights are downloaded from workers. The default implementation of FLight for asynchronous FL starts aggregation once it receives any model weights from any worker. Noting that this step does not involve any communication with remote workers since all model weights have been downloaded beforehand. Moreover, during the aggregation process, if some workers respond with their updated model weights, the aggregation server ignores them or keeps those model weights for the next round of aggregation rather than the current aggregation round.This section describes two heuristic algorithms to select workers participating in FL. The worker selection algorithms can be applied to synchronous and asynchronous FL. Both heuristic algorithms depend on the required time to complete training an entire batch of data for one epoch To​n​esubscript𝑇𝑜𝑛𝑒{T_{one}} and the time required to transmit the model Tt​r​a​n​s​m​i​tsubscript𝑇𝑡𝑟𝑎𝑛𝑠𝑚𝑖𝑡{T_{transmit}}; however, they differ from the perspective of acceptable maximum training time.Algorithm 1 demonstrates the first heuristic algorithm.After each round of aggregation, r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax are updated based on average accuracy among all selected workers. Let a​c​c​nn𝑎𝑐𝑐subscript𝑛𝑛accn_{n} be the accuracy achieved at the aggregation server on round n, and a​c​c​nn−1𝑎𝑐𝑐subscript𝑛𝑛1accn_{n-1} be the accuracy achieved at the last round. Then r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax are updated:Firstly, this algorithm takes the training time required for each worker to go through their training data for one epoch as input. Also, the time required for communicating the model weights between the aggregation server and a worker is considered. After that, r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax are two hyperparameters that define the minimum and the maximum number of epochs a worker should train before sending back the worker model weights to the aggregation server.If a worker trains for an insufficient amount of epochs before responding to the aggregation server, then model weights from that worker will have limited differences compared to the original model weights obtained from the aggregation server. r​m​i​n𝑟𝑚𝑖𝑛rmin is then selected to let the worker contribute model parameter weights with a promising difference. Among different ML models and available data sizes, difference r​m​i​n𝑟𝑚𝑖𝑛rmin needs to be figured out to ensure a meaningful update from workers. r​m​a​x𝑟𝑚𝑎𝑥rmax, on the other hand, defines the maximum number of epochs a worker can train before responding. If a worker trains for too many epochs before aggregation, the model weights will be biased to training data that the worker locally uses. This will result in a large divergence between the aggregation server’s update trend and the worker. In order to keep workers updating model weights in a similar direction as the average direction among all workers, regular communication with the aggregation server is necessary. This makes the algorithm introduce r​m​a​x𝑟𝑚𝑎𝑥rmax to limit workers from training too many epochs locally. After selecting r​m​a​x𝑟𝑚𝑎𝑥rmax and r​m​i​n𝑟𝑚𝑖𝑛rmin, the algorithm calculates the time required to train those amount of epochs plus transmission time for each worker. This time can also be interpreted as the required time after the aggregation server sends out the instruction to conduct training until the aggregation server receives a response. Although this time can be varied since estimation for To​n​ewsubscript𝑇𝑜𝑛subscript𝑒𝑤T_{one_{w}} and Tt​r​a​n​s​m​i​twsubscript𝑇𝑡𝑟𝑎𝑛𝑠𝑚𝑖subscript𝑡𝑤T_{transmit_{w}} has a difference with reality, it provides a heuristic suggesting which worker will respond faster. The selection criteria intend to minimize the time that fast computing workers wait for slow computing workers. When there is a difference between the time required to finish specified training, fast computing workers can train for more epochs than slow computing workers, which allows them to respond to the aggregation server in a similar time. However, extra training rounds from fast computing workers cannot exceed r​m​a​x𝑟𝑚𝑎𝑥rmax. For slow computing workers, the minimum requirement is complete r​m​i​n𝑟𝑚𝑖𝑛rmin rounds of training. This suggests the selection criteria described in algorithm 1 (lines 3−4343-4). If a worker requires more time to train a minimum number of epochs compared to the worker that can finish the maximum number of epochs for training, then that worker is excluded. After excluding slow computing workers, it is guaranteed that within the time the fastest computing workers finish maximum epochs of training, all other selected workers can at least complete the minimum training requirement. In order to achieve time efficiency of training, the worker selection algorithm lets fast computing workers participate in earlier training rounds. The initial worker selection process guarantees that only fast computing workers are selected. In order to generally include slow computing workers as training proceeds, the update will decrease r​m​i​n𝑟𝑚𝑖𝑛rmin while increasing r​m​a​x𝑟𝑚𝑎𝑥rmax. Increasing the upper limit and decreasing the lower limit has the following impact: 1) Since the maximum number of iterations a worker can train before aggregation increases, this also increases the time required to complete full training rounds for all workers. Consequently, it increases the minimum value among those times. 2) In the same way, with decreasing r​m​i​n𝑟𝑚𝑖𝑛rmin, the minimum requirement for workers decreases, resulting in reducing the time required for each worker to complete minimum training requirements. 3) According to the selection criteria, a worker will be selected only when they can finish the minimum required training before the fastest worker completes the maximum allowed amount of training between aggregation on the server side. With decreasing time, slow-computing workers are required to finish minimum training, and with increasing time, fast-computing workers need to finish maximum training epochs. Slow-computing workers can be included since they can finish minimum training before fast-computing workers finish the maximum allowed training amounts. Consequently, decreasing r​m​i​n𝑟𝑚𝑖𝑛rmin while increasing r​m​a​x𝑟𝑚𝑎𝑥rmax as the training progress can provide the effect of fast computing workers joining in an earlier round and slow computing workers joining later, which is time efficient. Training progress is expressed as an increase in the accuracy achieved by aggregated model weights against testing data. According to Eq. 1 and Eq. 2, r​m​i​n𝑟𝑚𝑖𝑛rmin is updated by multiplying the accuracy of previous aggregation rounds and dividing it by the accuracy in the current round. So, the more significant increase between the accuracy achieved by the aggregation server model in two aggregation rounds, the faster r​m​i​n𝑟𝑚𝑖𝑛rmin drops and vice versa for r​m​a​x𝑟𝑚𝑎𝑥rmax. Furthermore, these equations adjusts the numerator and denominator by adding one to avoid the situation in which ML model accuracy surges in earlier training rounds. Without the adjustment, when there is a significant increase in accuracy, the factor deciding the decrease in r​m​i​n𝑟𝑚𝑖𝑛rmin is going to be very large. This will cause r​m​i​n𝑟𝑚𝑖𝑛rmin to decrease very fast and hit a low value in earlier training rounds. The same condition applies to r​m​a​x𝑟𝑚𝑎𝑥rmax in terms of increase. If r​m​i​n𝑟𝑚𝑖𝑛rmin reaches a low value and r​m​a​x𝑟𝑚𝑎𝑥rmax reaches a very large value, then a large proportion of workers is eligible based on the selection criteria. This causes slow-computing workers to be included in training too early.The algorithm addressed above has the potential to accelerate the FL training efficiency. However, the design has defects that may fail under specific scenarios.The first scenario is due to improper initialization of r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax. If r​m​i​n𝑟𝑚𝑖𝑛rmin is initialized too low, it requires minimum time to satisfy the minimum training epochs. At the worker selection stage before the first round of training, since all workers have the relatively low time required to satisfy minimum training epochs, many slow-computing workers will be included. Including a large number of inefficient workers is harmful to training efficiency. On the other hand, initializing r​m​i​n𝑟𝑚𝑖𝑛rmin to a large value will result in a large training time required to satisfy minimum training epochs. This excludes a large number of workers in the early stage. Although workers selected under large initial r​m​i​n𝑟𝑚𝑖𝑛rmin are fast responding, inadequate workers participating in early-stage training can cause a large time before model accuracy starts to increase. Since r​m​i​n𝑟𝑚𝑖𝑛rmin only starts to drop once accuracy rises, slow accuracy growth in the early stage delays the time when more workers are included. This negatively affects training efficiency. The same scenario happens when the initialization of r​m​a​x𝑟𝑚𝑎𝑥rmax is chosen inappropriately. For every available machine learning model structure and training data, optimal initialization of r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax can be derived by grid search. However, a closed-form solution cannot be derived before training. This makes the worker selection algorithm 1 hard to be applied to large categories of models. Secondly, the value of r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax may drop and increase too fast in the early stage. For ML training from scratch, model weights are initialized randomly. This causes the initial accuracy of the ML model to be relatively low compared to accuracy after a few epochs of training during the early stage. Since a significant accuracy increase leads to low r​m​i​n𝑟𝑚𝑖𝑛rmin and high r​m​a​x𝑟𝑚𝑎𝑥rmax, the large difference between r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax arises when the accuracy surge happens in an earlier round of ML training. As a result, many slow workers will be selected in early rounds, which is time inefficient. If the ML model uses a pre-trained model, it can bypass the scenario that accuracy differences are too significant in earlier training rounds. However, this limits the types of applicable ML models to those models working with a pre-trained model. Furthermore, the issue of r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax diverging too quickly gets worse when the FL is conducted asynchronously. This is because asynchronous FL can aggregate results more frequently, causing a more frequent update of r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax and leading to a large diverge. Consequently, algorithm 1 has the issue of hard initialization of r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax such that they do not diverge too quickly. During training, if the accuracy increases unstably, the values of r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax will be extremely low and large. This will cause a large proportion of slow workers to be selected, reducing time efficiency. Changing the FL from synchronous to asynchronous further worsened the situation.Algorithm 2 is a modified version of algorithm 1 that addresses the aforementioned issues.This algorithm selects workers based on the time required to complete a specified amount of training. Moreover, the algorithm will update T𝑇T, which refers to the time allowed for each round of training. Let Wn​ssubscript𝑊𝑛𝑠W_{ns} be the group of workers not selected yet, a​c​c​nn𝑎𝑐𝑐subscript𝑛𝑛accn_{n} be the accuracy achieved at the current round of aggregation, and a​c​c​nn−1𝑎𝑐𝑐subscript𝑛𝑛1accn_{n-1} be the accuracy achieved last round. Let A𝐴A be the accuracy improvement threshold such that T𝑇T will only increase when the accuracy boost between two rounds of aggregation is less than that threshold. The update can be expressed in Eq. 3.The idea of the worker selection algorithm 2 is that each worker should perform unified epochs of training before responding to the aggregation server. This allows calculating the total time required to conduct training and communicate model weights back as Tt​o​t​a​lsubscript𝑇𝑡𝑜𝑡𝑎𝑙T_{total}. After that, a threshold time is selected, which excludes slow-computing workers from training. As the training progresses, if the aggregation server model’s accuracy stops increasing, more workers are included. This is achieved by increasing the time limit. For algorithm 2, the only hyperparameter that needs to be initialized is T𝑇T. The initialization is straightforward, in which T𝑇T can be set to zero at the start. In this case, no worker can be selected, causing no increase in the accuracy. Thus, the update mechanism in Eq. 3 for T𝑇T is triggered. This allows more workers to be eligible for FL training. Initializing T𝑇T to zero or a small value has little impact on time efficiency. This is because if accuracy fails to increase for one epoch due to an insufficient worker selected, T𝑇T will increase and allow a more significant amount of workers to participate in FL training. The worker selection algorithm 2 together with the update Eq. refequation:tupdate sacrifice a little training time to allow the appropriate amount of workers to be selected, which has the potential to boost overall efficiency. Secondly, bringing in slower workers only when accuracy stops increasing means slow-computing workers are selected only when a converged accuracy is achieved from faster-computing workers. This prevents slow computing workers from joining in the early stage and only allows those slow workers to train when it is necessary to include them to achieve the desired accuracy, which improves time efficiency. Thirdly, r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax also diverge fast if FL is conducted asynchronously since there is more frequent aggregation and hence more frequent update of r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax. Each update increases the difference between r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax. The divergence between r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax leads to slow-computing workers being included in early training epochs. Algorithm 2, on the other hand, is compatible with asynchronous FL. This is because even when more frequent aggregation is conducted, as long as the model accuracy keeps increasing, update Eq. 3 will not be triggered, preventing slow-computing workers from joining the training process.Both worker selection algorithms depend on the time required to communicate model weights and conduct training for each worker. When each worker is selected and the response model weights to the aggregation server are sent, the actual time consumed for communication and training is updated. Initially, the value is estimated by a heuristic. The estimated training time is based on system parameters provided by the FogBus2 framework. For the required time to transmit model weights, the estimated time is obtained based on the randomly transmitted model weights from the aggregation server to each worker to obtain the required time for the transmission. For training time, To​n​esubscript𝑇𝑜𝑛𝑒T_{one} is the required time to train one epoch based on CPU availability and the CPU frequency of all workers. The aggregation server conducts training over one piece of data and records the consumed time as well as the CPU frequency allocated to conduct training. Moreover, the amount of training data that each worker contain is collected when the worker acknowledges they are ready to train. Then, To​n​ewsubscript𝑇𝑜𝑛subscript𝑒𝑤T_{one_{w}} is estimated:The Eq. 4 first estimates the time required to train one piece of data on each worker based on the time to train one data on the aggregation server and the multiplier between CPU frequencies. After that, the estimated required time for the training of each worker is obtained by multiplying by the obtained value to the amount of data belonging to each worker.This section presents the system configuration and training dataset used for the performance evaluation along with the results obtained from different experiments.To perform experiments, we have used a Mac Book Pro with 8 ARM-based CPU cores and 16 GB of RAM and a Desktop computer with 8 Core Core i9 CPU and 32 GB of RAM to run four Virtual Machines (VMs). One VM runs the aggregation server model, while the rest of the VMs run worker models. Each VM is allocated 2 GB of RAM, while the CPU core number and base CPU frequency of all VMs are the same. Three VMs evenly distribute all worker models for different numbers of worker models participating in FL. We conduct an FL with only one worker model, which simulates sequential implementation. Afterward, we use FL with 10-worker models and 30-worker models, in which workers are evenly distributed into three different machines. A VM has 3-4 FL worker models when there are 10 models in the FL, or a VM has 10 worker models when there are 30 models in total. For communication, each VM is assigned a separate network address through which different FL and FogBus2 components can communicate.We have used two different datasets in experiments that are commonly used in other FL research: 1) MINST [33] and 2) CIFAR-10 [34]. These datasets have sufficient data such that both sets have 60000 training data. The data is split and distributed to different workers, ensuring all workers have a sufficient amount of distinct training data. The amount of training data allocated to each worker model in each experimental configuration when there are 10 and 30 worker models are shown in table III and table IV, respectively.Configurations 1 and 4 in table III and table IV only allocate training batches of data to one worker model to simulate sequential training. However, other configurations distribute training data to different worker models. Configurations 2 and 5 indicate the situation where each worker model holds an even amount of training data, while configurations 3 and 6 denote the case that training data is unevenly distributed. The total amount of available data for training among all workers is the same for configurations 1-3 and 4-6. Different amount of training data leads to a different time to complete the training among workers. All the training is conducted asynchronously and synchronously for one hundred epochs. The long training epoch ensures sufficient time for the aggregation server model to achieve potential accuracy under available workers.Fig. 12 to Fig. 18 illustrate the results of FL training under configurations in tables III and IV, which are described in the following.FL with even data distribution requires less time to reach stable accuracy, meaning faster training at the initial stage. But sequential one eventually reaches a better accuracy. This can be seen from Fig. 12 that the even data distribution line reaches a high accuracy before the sequential training. However, sequential training reaches better results over time. Moreover, as it can be seen from Fig. 13, the time required for sets of workers that have even or uneven amounts of training data to reach stable accuracy is similar.According to Fig. 14, random worker selection eventually reaches the same accuracy level as sequential implementation. However, random worker selection requires a longer time to get the same accuracy as sequential. Moreover, it shows that the accuracy growth of random worker selection is unstable compared to sequential one. Besides, based on Fig. 15, the r-min and r-max worker selection algorithm is not more time efficient compared to sequential implementation. Moreover, incorrect initialization of r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax can lead to inefficient training processes such that accuracy never approaches the potential accuracy achievable based on all data from all workers. This latter case can be seen from Fig.  16 that when r​m​a​x𝑟𝑚𝑎𝑥rmax is initialized to 5, 6, and 7, the accuracy stays around 15%. In contrast, theoretical accuracy is around 50%. Overall, the Algorithm 1 is time inefficient because r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax diverge too fast in the early stage of ML training. Since model weights are randomly initialized, there is significant accuracy growth in the earlier rounds of training. This accelerates the update of r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax based on the update Eq. 1 and causes faster divergence. When r​m​i​n𝑟𝑚𝑖𝑛rmin and r​m​a​x𝑟𝑚𝑎𝑥rmax becomes far different, slow computing workers are also considered since the time required to complete minimal training is much less than the time necessary for faster workers to meet maximally allowed training epochs. Thus, the worker selection algorithm 1 quickly turns into selecting all workers after a few rounds of aggregation on the server.According to Fig. 17, the worker selection algorithm 2, when combined with synchronous FL training, outperforms random worker selection and sequential ML training during the early phase of training. This shows the effectiveness of the worker selection algorithm 2. However, such performance only takes part in an early phase of training, while sequential training always reaches stable accuracy faster. The worker selection algorithm 2 is more time efficient in the early phase compared to sequential ML training because only fast computing workers are selected to participate in training. When the FL training requires slower workers to join in later rounds of training, since synchronous FL requires faster workers to wait for slower workers, it becomes time inefficient as training progress to later rounds. This is also proved by the fact that the accuracy of sequential training exceeds it in later training rounds. As shown in Fig. 18, the worker selection algorithm 2 combined with asynchronous FL training has similar performance in the earlier phase. However, during a later stage of training, asynchronous FL has faster accuracy growth. This makes asynchronous FL and worker selection algorithm 2 more time efficient than synchronous FL or sequential ML training. Asynchronous FL, even when it involves slower workers, does not require faster workers to wait, resulting in asynchronous FL outperforms sequential and synchronous training in terms of time efficiency.In this paper, we have designed and implemented a lightweight and containerized framework for FL, called FLight, by extending the FogBus2 framework. FLight enables the integration of new ML models and supports different mechanisms relating to worker selection access control and storage implementation to be extended easily. Moreover, two worker selection algorithms are introduced in this work to improve the training time efficiency. FLight enables easy extension of mechanism related to FL. New ML models can be extended as long as import and export model weights and merging model weights are defined. Moreover, the worker selection strategy can be extended by overriding the worker selection function skeleton, where multiple system parameters relating to available workers are available for different algorithm designs. Also, the flexible storage model design enables the model weights to be stored on different media, which supports deployment on various computing resources. The implementation also supports asynchronous FL. The easy extension and lightweight property of the FLight makes it a good tool for comparing different federated learning mechanism design.\nIn future works, we plan to integrate other the-state-of-the-art FL optimization mechanisms into the FLight framework. Moreover, the current framework provides the opportunity to integrate other ML techniques in a distributed manner, such as some of the state-of-the-art distributed deep reinforcement learning techniques for dynamic scheduling of resources [35]. Also, considering security and privacy perspectives, although FL inherently protects data privacy as data stays locally at its origination, model weights shared to remote sites still can leak information about training data. Thus, extra modification on shared model weights is necessary to prevent any sensitive information regarding training data leaked out through the format of ML model weights. This is important since protecting training data privacy is the key goal of FL which emphasize this feature should be integrated into the Flight framework. Finally, because Flight is a containerized FL framework, one logical step to expand its properties is enabling container orchestration properties for the Flight framework. So, we plan to deploy the Flight on container orchestration platforms, such as Kubernetes and K3S, to offer higher scalability, automated monitoring, and failure handling for the Flight framework.The source code of the FLight framework is accessible from:\nhttps://github.com/Cloudslab/FLight",
        "references": [
            "This section identifies important parameters in FL and summarizes the properties of the current literature considering the identified parameters. Table II-B1 depicts an overview of the current FL studies and their properties. In what follows, the identified parameters and their respective symbols in the table are explained."
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: Batch of data each worker is allocated (10 worker)",
        "table": "<table id=\"S4.T3.4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Config</th>\n<th id=\"S4.T3.4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Data set</th>\n<th id=\"S4.T3.4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W1</th>\n<th id=\"S4.T3.4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W2/W3</th>\n<th id=\"S4.T3.4.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W4</th>\n<th id=\"S4.T3.4.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W5/W6</th>\n<th id=\"S4.T3.4.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W7</th>\n<th id=\"S4.T3.4.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W8/W9/W10</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.4.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">1</th>\n<th id=\"S4.T3.4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">MINST</th>\n<td id=\"S4.T3.4.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T3.4.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S4.T3.4.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">2</th>\n<th id=\"S4.T3.4.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">MINST</th>\n<td id=\"S4.T3.4.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T3.4.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T3.4.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T3.4.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T3.4.1.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T3.4.1.3.2.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n</tr>\n<tr id=\"S4.T3.4.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">3</th>\n<th id=\"S4.T3.4.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">MINST</th>\n<td id=\"S4.T3.4.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T3.4.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3</td>\n<td id=\"S4.T3.4.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.4.3.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2</td>\n</tr>\n<tr id=\"S4.T3.4.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">4</th>\n<th id=\"S4.T3.4.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">CIFAR</th>\n<td id=\"S4.T3.4.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100</td>\n<td id=\"S4.T3.4.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.5.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.5.4.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S4.T3.4.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">5</th>\n<th id=\"S4.T3.4.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">CIFAR</th>\n<td id=\"S4.T3.4.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T3.4.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T3.4.1.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T3.4.1.6.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T3.4.1.6.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T3.4.1.6.5.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n</tr>\n<tr id=\"S4.T3.4.1.7.6\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">6</th>\n<th id=\"S4.T3.4.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\">CIFAR</th>\n<td id=\"S4.T3.4.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T3.4.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">30</td>\n<td id=\"S4.T3.4.1.7.6.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.7.6.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T3.4.1.7.6.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">20</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We have used two different datasets in experiments that are commonly used in other FL research: 1) MINST [33] and 2) CIFAR-10 [34]. These datasets have sufficient data such that both sets have 60000 training data. The data is split and distributed to different workers, ensuring all workers have a sufficient amount of distinct training data. The amount of training data allocated to each worker model in each experimental configuration when there are 10 and 30 worker models are shown in table III and table IV, respectively.",
            "Configurations 1 and 4 in table III and table IV only allocate training batches of data to one worker model to simulate sequential training. However, other configurations distribute training data to different worker models. Configurations 2 and 5 indicate the situation where each worker model holds an even amount of training data, while configurations 3 and 6 denote the case that training data is unevenly distributed. The total amount of available data for training among all workers is the same for configurations 1-3 and 4-6. Different amount of training data leads to a different time to complete the training among workers. All the training is conducted asynchronously and synchronously for one hundred epochs. The long training epoch ensures sufficient time for the aggregation server model to achieve potential accuracy under available workers."
        ]
    },
    "S4.T4": {
        "caption": "TABLE IV: Batch of data each worker is allocated (30 worker)",
        "table": "<table id=\"S4.T4.4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Config</th>\n<th id=\"S4.T4.4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Data set</th>\n<th id=\"S4.T4.4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W1</th>\n<th id=\"S4.T4.4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W2 - W10</th>\n<th id=\"S4.T4.4.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W11</th>\n<th id=\"S4.T4.4.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W12 - W20</th>\n<th id=\"S4.T4.4.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W21</th>\n<th id=\"S4.T4.4.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">W22 - W30</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.4.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">1</th>\n<th id=\"S4.T4.4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">MINST</th>\n<td id=\"S4.T4.4.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">30</td>\n<td id=\"S4.T4.4.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S4.T4.4.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">2</th>\n<th id=\"S4.T4.4.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">MINST</th>\n<td id=\"S4.T4.4.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T4.4.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T4.4.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T4.4.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T4.4.1.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n<td id=\"S4.T4.4.1.3.2.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>\n</tr>\n<tr id=\"S4.T4.4.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">3</th>\n<th id=\"S4.T4.4.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">MINST</th>\n<td id=\"S4.T4.4.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4</td>\n<td id=\"S4.T4.4.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">8</td>\n<td id=\"S4.T4.4.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.4.3.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2</td>\n</tr>\n<tr id=\"S4.T4.4.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">4</th>\n<th id=\"S4.T4.4.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">CIFAR</th>\n<td id=\"S4.T4.4.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">300</td>\n<td id=\"S4.T4.4.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.5.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.5.4.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S4.T4.4.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">5</th>\n<th id=\"S4.T4.4.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">CIFAR</th>\n<td id=\"S4.T4.4.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T4.4.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T4.4.1.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T4.4.1.6.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T4.4.1.6.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n<td id=\"S4.T4.4.1.6.5.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10</td>\n</tr>\n<tr id=\"S4.T4.4.1.7.6\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">6</th>\n<th id=\"S4.T4.4.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\">CIFAR</th>\n<td id=\"S4.T4.4.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">40</td>\n<td id=\"S4.T4.4.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">80</td>\n<td id=\"S4.T4.4.1.7.6.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.7.6.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0</td>\n<td id=\"S4.T4.4.1.7.6.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">20</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We have used two different datasets in experiments that are commonly used in other FL research: 1) MINST [33] and 2) CIFAR-10 [34]. These datasets have sufficient data such that both sets have 60000 training data. The data is split and distributed to different workers, ensuring all workers have a sufficient amount of distinct training data. The amount of training data allocated to each worker model in each experimental configuration when there are 10 and 30 worker models are shown in table III and table IV, respectively.",
            "Configurations 1 and 4 in table III and table IV only allocate training batches of data to one worker model to simulate sequential training. However, other configurations distribute training data to different worker models. Configurations 2 and 5 indicate the situation where each worker model holds an even amount of training data, while configurations 3 and 6 denote the case that training data is unevenly distributed. The total amount of available data for training among all workers is the same for configurations 1-3 and 4-6. Different amount of training data leads to a different time to complete the training among workers. All the training is conducted asynchronously and synchronously for one hundred epochs. The long training epoch ensures sufficient time for the aggregation server model to achieve potential accuracy under available workers."
        ]
    }
}