{
    "PAPER'S NUMBER OF TABLES": 1,
    "S3.T1": {
        "caption": "TABLE I: List of trainable layers of a simple CNN.",
        "table": "<table id=\"S3.T1.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.2.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_t\" style=\"padding-bottom:2.15277pt;\">Order</th>\n<th id=\"S3.T1.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-bottom:2.15277pt;\">Layer</th>\n<th id=\"S3.T1.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-bottom:2.15277pt;\">Parameters</th>\n<th id=\"S3.T1.2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-bottom:2.15277pt;\">Dimension</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.2.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"S3.T1.2.2.1.1.1\" class=\"ltx_text\">1</span></td>\n<td id=\"S3.T1.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S3.T1.2.2.1.2.1\" class=\"ltx_text\">conv 1</span></td>\n<td id=\"S3.T1.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">weights</td>\n<td id=\"S3.T1.2.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">288</td>\n</tr>\n<tr id=\"S3.T1.2.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.3.2.1\" class=\"ltx_td ltx_align_center\">biases</td>\n<td id=\"S3.T1.2.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">32</td>\n</tr>\n<tr id=\"S3.T1.2.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_l\" rowspan=\"2\"><span id=\"S3.T1.2.4.3.1.1\" class=\"ltx_text\">2</span></td>\n<td id=\"S3.T1.2.4.3.2\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S3.T1.2.4.3.2.1\" class=\"ltx_text\">conv 2</span></td>\n<td id=\"S3.T1.2.4.3.3\" class=\"ltx_td ltx_align_center\">weights</td>\n<td id=\"S3.T1.2.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">18432</td>\n</tr>\n<tr id=\"S3.T1.2.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.5.4.1\" class=\"ltx_td ltx_align_center\">biases</td>\n<td id=\"S3.T1.2.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">64</td>\n</tr>\n<tr id=\"S3.T1.2.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_l\" rowspan=\"2\"><span id=\"S3.T1.2.6.5.1.1\" class=\"ltx_text\">3</span></td>\n<td id=\"S3.T1.2.6.5.2\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S3.T1.2.6.5.2.1\" class=\"ltx_text\">dense 1</span></td>\n<td id=\"S3.T1.2.6.5.3\" class=\"ltx_td ltx_align_center\">weights</td>\n<td id=\"S3.T1.2.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">1179648</td>\n</tr>\n<tr id=\"S3.T1.2.7.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.7.6.1\" class=\"ltx_td ltx_align_center\">biases</td>\n<td id=\"S3.T1.2.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">128</td>\n</tr>\n<tr id=\"S3.T1.2.8.7\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.8.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l\" rowspan=\"2\"><span id=\"S3.T1.2.8.7.1.1\" class=\"ltx_text\">4</span></td>\n<td id=\"S3.T1.2.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_b\" rowspan=\"2\"><span id=\"S3.T1.2.8.7.2.1\" class=\"ltx_text\">dense 2</span></td>\n<td id=\"S3.T1.2.8.7.3\" class=\"ltx_td ltx_align_center\">weights</td>\n<td id=\"S3.T1.2.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_r\">1280</td>\n</tr>\n<tr id=\"S3.T1.2.9.8\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.9.8.1\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-bottom:4.30554pt;\">biases</td>\n<td id=\"S3.T1.2.9.8.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"padding-bottom:4.30554pt;\">10</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Many existing robust aggregation algorithms utilize some form of outlier detection to filter out Byzantine gradients based on the assumption that, in comparison to Byzantine gradients, honest gradients will be “similar”.\nTheoretically, the relative similarity of gradients will decrease as the similarity of their local distributions decreases.\nIn this section, we observe the effect of Byzantine threats from a different aspect, i.e., observing how different layers of the neural network react to a Byzantine attack in the FL system.\nIn Figure 4, we highlight some results that illustrate key observations from our study of the response of gradients per layer to Byzantine attacks.\nIn this study, we train a simple convolutional neural network (CNN) with two convolutional layers and dense layers,\nwhose trainable layer weights and biases are listed in Table I,\nin a FL system with ten workers. Each worker has 1,00010001,000 data points randomly drawn from the MNIST dataset  [16] so their local distributions are IID. We therefore expect local gradients to be relatively similar. By using ℓ2subscriptℓ2\\ell_{2} norms to measure the difference among them, we confirm this expectation and further study the similarity at a layer level and with the inclusion of Byzantine gradients. But first, we provide the notation used throughout this paper."
        ]
    }
}