{
    "id_table_1": {
        "caption": "Table 1:  Summary of synthetic data",
        "table": "Sx1.EGx1",
        "footnotes": [],
        "references": [
            "After evaluation of Lipschitz constant, we move on to the formulation of DC algorithm in our proposed method. In DC algorithm, subderivative   h  ( w i ) h subscript w i \\partial h(\\bm{w}_{i})  italic_h ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  is necessary for the calculation of  h ( t )  subscript superscript h t  {}_{\\nabla}\\bm{h}^{(t)} start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  in the process (i), which is given by equation ( 10 ),",
            "The minimization problem in equation ( 11 ) can be regarded as a generalized lasso problem  [ 29 ] , whose solution cannot be obtained analytically. Hence, we attempt to find the solution numerically by the method of alternating directions method of multipliers (ADMM)  [ 30 ] . In the application of ADMM,  w i ( t + 1 ) superscript subscript w i t 1 \\bm{w}_{i}^{(t+1)} bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  is computed by minimizing augmented Lagrangian  L   ( w ,  ,  ) subscript L  w   \\mathcal{L}_{\\rho}(\\bm{w},\\bm{\\gamma},\\bm{\\tau}) caligraphic_L start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( bold_italic_w , bold_italic_ , bold_italic_ ) ,",
            "The variables  w ,  ,  w   \\bm{w},\\bm{\\gamma},\\bm{\\tau} bold_italic_w , bold_italic_ , bold_italic_  minimizing  L   ( w ,  ,  ) subscript L  w   \\mathcal{L}_{\\rho}(\\bm{w},\\bm{\\gamma},\\bm{\\tau}) caligraphic_L start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( bold_italic_w , bold_italic_ , bold_italic_ )  are alternately updated by equations ( 13 ), ( 14 ) and ( 15 ) until convergence.",
            "where  ( Q # ) j , subscript superscript Q # j (\\bm{Q}^{\\#})_{j,} ( bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT italic_j , end_POSTSUBSCRIPT  means the  j j j italic_j -th row vector of  Q # superscript Q # \\bm{Q}^{\\#} bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT  and  S a  ( x ) subscript S a x \\mathrm{S}_{a}(x) roman_S start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_x )  is soft thresholding function defined in equation ( 18 ),",
            "Finally, by combining these results, our proposed algorithm is obtained, which is summarized in Algorithm  1 .",
            "The significant difference of DC algorithm in our  l 1 subscript l 1 \\ell_{1} roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT -regularized ICA is orthogonalization and normalization after variable update, which requires a slight change in the proof for convergence condition of DC algorithm. For this purpose, we should distinguish the variable after orthogonalization and normalization, which is denoted by  w ^ i ( t + 1 ) superscript subscript ^ w i t 1 \\widehat{\\bm{w}}_{i}^{(t+1)} over^ start_ARG bold_italic_w end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT . With this variable, we can show that our proposed algorithm converges to a point in equation ( 19 ) if the inequality  J o  ( w ^ i ( t + 1 ) )  J o  ( w i ( t ) ) subscript J o superscript subscript ^ w i t 1 subscript J o superscript subscript w i t J_{o}(\\widehat{\\bm{w}}_{i}^{(t+1)})\\leq J_{o}(\\bm{w}_{i}^{(t)}) italic_J start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( over^ start_ARG bold_italic_w end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT )  italic_J start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT )  is satisfied.",
            "Note that the factor  (  h ( t )  ) T  w i ( t + 1 )   h ( t )   2   w i ( t + 1 )  2 superscript subscript superscript h t  T superscript subscript w i t 1 subscript norm subscript superscript h t  2 subscript norm superscript subscript w i t 1 2 \\frac{(-{}_{\\nabla}\\bm{h}^{(t)})^{T}\\bm{w}_{i}^{(t+1)}}{\\|-{}_{\\nabla}\\bm{h}^{% (t)}\\|_{2}\\|\\bm{w}_{i}^{(t+1)}\\|_{2}} divide start_ARG ( - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT end_ARG start_ARG  - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG  on the right hand side of inequality ( LABEL:eq:upper_bound_of_3rd_term ) is cosine similarity. The inequality in ( 24 ) is from the upper bound of the general quadratic form. The first inequality in ( 25 ) is derived by the relation between  l 1 subscript l 1 \\ell_{1} roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT -norm and  l 2 subscript l 2 \\ell_{2} roman_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT -norm, namely   x  2   x  1  N   x  2 subscript norm x 2 subscript norm x 1 N subscript norm x 2 \\|\\bm{x}\\|_{2}\\leq\\|\\bm{x}\\|_{1}\\leq\\sqrt{N}\\|\\bm{x}\\|_{2}  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT   bold_italic_x  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  square-root start_ARG italic_N end_ARG  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  for an  N N N italic_N -dimensional vector  x x \\bm{x} bold_italic_x , and the second inequality is from the upper and the lower bounds of the general quadratic form. The inequality in ( LABEL:eq:upper_bound_of_3rd_term ) is Cauchy-Schwarz inequality. By these results and from the definition of  w i ( t + 1 ) superscript subscript w i t 1 \\bm{w}_{i}^{(t+1)} bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  in ( 11 ), the last inequality in ( 23 ) is shown using the constant  C C C italic_C  in ( 21 ). Then, if the condition ( 20 ) is satisfied, one has",
            "In this experiment, we apply our proposed method and FastICA to 4 synthetic data  X ( 1 ) , X ( 2 ) superscript X 1 superscript X 2 \\bm{X}^{(1)},\\bm{X}^{(2)} bold_italic_X start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_X start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ,  X ( 3 ) superscript X 3 \\bm{X}^{(3)} bold_italic_X start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT , and  X ( 4 ) superscript X 4 \\bm{X}^{(4)} bold_italic_X start_POSTSUPERSCRIPT ( 4 ) end_POSTSUPERSCRIPT , which are generated as follows. In particular, in constructing  X ( 3 ) superscript X 3 \\bm{X}^{(3)} bold_italic_X start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT  and  X ( 4 ) superscript X 4 \\bm{X}^{(4)} bold_italic_X start_POSTSUPERSCRIPT ( 4 ) end_POSTSUPERSCRIPT , the values of parameters are chosen to model large-size real fMRI data. (See also Table  1 .)",
            "We depict the behaviours of the sparsity of the estimated mixture matrix  A A \\bm{A} bold_italic_A , the kurtosis of the estimated signal matrix  S S \\bm{S} bold_italic_S , and the reconstruction error obtained by our proposed method and FastICA in Figure  1 . The results for  X ( 1 ) superscript X 1 \\bm{X}^{(1)} bold_italic_X start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  (top, under the mixtures of Laplace/uniform distributions) and  X ( 2 ) superscript X 2 \\bm{X}^{(2)} bold_italic_X start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  (bottom, log-normal/uniform distributions) are compared. From this figure, there is no significant difference between mixtures of Laplace/uniform distributions and log-normal/uniform distributions. This implies that the result does not depend on the choice of non-gaussian distribution.",
            "We move on to the detail of the results in Figure  1 . First, we discuss the sparsity of the estimated mixture matrix  A A \\bm{A} bold_italic_A . The sparsity of  A A \\bm{A} bold_italic_A  by our proposed method is larger than FastICA regardless of the value of   ,    \\alpha,\\kappa italic_ , italic_ . We also observe that the sparsity by our method is very large and close to 0.9 under larger    \\alpha italic_  and   = 0.9  0.9 \\kappa=0.9 italic_ = 0.9 . When the value of    \\alpha italic_  is fixed, large sparsity is obtained for large    \\kappa italic_  under   = 10  2  superscript 10 2 \\alpha=10^{-2} italic_ = 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT  or  10 1 superscript 10 1 10^{1} 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT . In general,    \\kappa italic_  must be larger for larger sparsity of  A A \\bm{A} bold_italic_A , while    \\alpha italic_  should be tuned carefully.",
            "We also mention the result of the reconstruction error. In Figure  1 , no change in  RMSE X subscript RMSE X {\\rm RMSE}_{\\bm{X}} roman_RMSE start_POSTSUBSCRIPT bold_italic_X end_POSTSUBSCRIPT  is observed even if    \\alpha italic_  is varied, and  RMSE X subscript RMSE X {\\rm RMSE}_{\\bm{X}} roman_RMSE start_POSTSUBSCRIPT bold_italic_X end_POSTSUBSCRIPT  depends only on    \\kappa italic_ . It is easy to prove analytically that  RMSE X subscript RMSE X {\\rm RMSE}_{\\bm{X}} roman_RMSE start_POSTSUBSCRIPT bold_italic_X end_POSTSUBSCRIPT  depends only on the approximation accuracy of  Q # superscript Q # \\bm{Q}^{\\#} bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT  using the orthogonality of the matrix  W W \\bm{W} bold_italic_W , which is also indicated by numerical result. In addition, by fixing    \\alpha italic_ , it is found that  RMSE X subscript RMSE X {\\rm RMSE}_{\\bm{X}} roman_RMSE start_POSTSUBSCRIPT bold_italic_X end_POSTSUBSCRIPT  tends to increase for larger    \\kappa italic_ . To summarize,    \\alpha italic_  can be chosen arbitrarily for better reconstruction error, while    \\kappa italic_  must be carefully adjusted. Additionally, from the fact that larger sparsity of  A A \\bm{A} bold_italic_A  can be obtained under larger    \\kappa italic_ , large sparsity and small reconstruction error have a trade-off relation.",
            "The behavior of reconstruction error is similar to Figure  1 , while its value is much larger than those in Figure  1 . This is caused by the fact that Moore-Penrose pseudo inverse matrix cannot approximate the true inverse matrix appropriately under  p > N p N p>N italic_p > italic_N , which is the problem inherent in original ICA."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Result of application to  X ( 4 ) superscript X 4 \\bm{X}^{(4)} bold_italic_X start_POSTSUPERSCRIPT ( 4 ) end_POSTSUPERSCRIPT  (noisy data)",
        "table": "Sx1.EGx2",
        "footnotes": [],
        "references": [
            "The organization of this article is as follows. In section  2 , the framework of ICA is overviewed and several related works are presented. In section  3 , we provide how to construct our proposed method and discuss the convergence of our algorithm theoretically. In section  4 , we apply our method both to synthetic data and real-world data, then discuss the validity. Finally, section  5  is devoted to conclusions and future works.",
            "In the above equation,  G ( . ) G(.) italic_G ( . )  is a nonlinear function and defined by  G  ( y ) =  e  y 2 / 2 G y superscript e superscript y 2 2 G(y)=-e^{-y^{2}/2} italic_G ( italic_y ) = - italic_e start_POSTSUPERSCRIPT - italic_y start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / 2 end_POSTSUPERSCRIPT . The variable   j subscript  j \\nu_{j} italic_ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT   ( j  { 1 , ... , N } (j\\in\\{1,\\ldots,N\\} ( italic_j  { 1 , ... , italic_N } ) is a normal random variable with zero mean and unit variance. In maximizing  J f  ( w i ) subscript J f subscript w i J_{f}(\\bm{w}_{i}) italic_J start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , a fixed point algorithm in equation ( 2 ) is used.",
            "Note that the factor  (  h ( t )  ) T  w i ( t + 1 )   h ( t )   2   w i ( t + 1 )  2 superscript subscript superscript h t  T superscript subscript w i t 1 subscript norm subscript superscript h t  2 subscript norm superscript subscript w i t 1 2 \\frac{(-{}_{\\nabla}\\bm{h}^{(t)})^{T}\\bm{w}_{i}^{(t+1)}}{\\|-{}_{\\nabla}\\bm{h}^{% (t)}\\|_{2}\\|\\bm{w}_{i}^{(t+1)}\\|_{2}} divide start_ARG ( - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT end_ARG start_ARG  - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG  on the right hand side of inequality ( LABEL:eq:upper_bound_of_3rd_term ) is cosine similarity. The inequality in ( 24 ) is from the upper bound of the general quadratic form. The first inequality in ( 25 ) is derived by the relation between  l 1 subscript l 1 \\ell_{1} roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT -norm and  l 2 subscript l 2 \\ell_{2} roman_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT -norm, namely   x  2   x  1  N   x  2 subscript norm x 2 subscript norm x 1 N subscript norm x 2 \\|\\bm{x}\\|_{2}\\leq\\|\\bm{x}\\|_{1}\\leq\\sqrt{N}\\|\\bm{x}\\|_{2}  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT   bold_italic_x  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  square-root start_ARG italic_N end_ARG  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  for an  N N N italic_N -dimensional vector  x x \\bm{x} bold_italic_x , and the second inequality is from the upper and the lower bounds of the general quadratic form. The inequality in ( LABEL:eq:upper_bound_of_3rd_term ) is Cauchy-Schwarz inequality. By these results and from the definition of  w i ( t + 1 ) superscript subscript w i t 1 \\bm{w}_{i}^{(t+1)} bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  in ( 11 ), the last inequality in ( 23 ) is shown using the constant  C C C italic_C  in ( 21 ). Then, if the condition ( 20 ) is satisfied, one has",
            "For  X ( 1 ) superscript X 1 \\bm{X}^{(1)} bold_italic_X start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  X ( 2 ) superscript X 2 \\bm{X}^{(2)} bold_italic_X start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT , we set   = 0.8 , p = 10 formulae-sequence  0.8 p 10 \\chi=0.8,p=10 italic_ = 0.8 , italic_p = 10 , namely the size of the data is small. In contrast, we set  p = 10 4 p superscript 10 4 p=10^{4} italic_p = 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT  for  X ( 3 ) superscript X 3 \\bm{X}^{(3)} bold_italic_X start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT  and  X ( 4 ) superscript X 4 \\bm{X}^{(4)} bold_italic_X start_POSTSUPERSCRIPT ( 4 ) end_POSTSUPERSCRIPT  to model real fMRI data, because the voxel size of fMRI data often takes the order from  10 4 superscript 10 4 10^{4} 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT  to  10 5 superscript 10 5 10^{5} 10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT . Moreover, in real fMRI data analysis as mentioned in section  4.2 , elements of brain activity above 3 standard deviations from the mean can be interpreted as clear characteristic activations. Namely, the number of elements representing strong activations is typically of the order of  10 1 superscript 10 1 10^{1} 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT . From this observation, we set   = 0.999  0.999 \\chi=0.999 italic_ = 0.999  for  X ( 3 ) superscript X 3 \\bm{X}^{(3)} bold_italic_X start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT  and  X ( 4 ) superscript X 4 \\bm{X}^{(4)} bold_italic_X start_POSTSUPERSCRIPT ( 4 ) end_POSTSUPERSCRIPT .",
            "sparsity   Sparsity of the estimated mixture matrix  A A \\bm{A} bold_italic_A  is defined in equation ( 32 ).",
            "Lastly, we give the result of the reconstruction success rate. Before evaluating SR of our method, we evaluate Amari distance by FastICA in 20 trials with different initial matrix, whose average is  43.04  ( 8.87  10  3 ) plus-or-minus 43.04 8.87 superscript 10 3 43.04\\pm(8.87\\times 10^{-3}) 43.04  ( 8.87  10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT ) . Based on this result, the threshold of success is set as   = 35  35 \\psi=35 italic_ = 35  in our experiment, which is the appropriate value because it is below the average of Amari distance by FastICA. For reconstruction success rate, we evaluate it in 20 trials with different initial matrix for   = 1.0  10  4 , 2.0  10  4 , ... , 1.0  10  3  1.0 superscript 10 4 2.0 superscript 10 4 ... 1.0 superscript 10 3 \\alpha=1.0\\times 10^{-4},2.0\\times 10^{-4},\\ldots,1.0\\times 10^{-3} italic_ = 1.0  10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 2.0  10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , ... , 1.0  10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT . Parameter    \\kappa italic_  is set to 0.9 in all cases. In Figure  2 , we show the frequency of samples and SR under various sparsity of estimated matrix  A A \\bm{A} bold_italic_A . The largest SR is observed in the range of  0.75  Sparsity  ( A ) < 0.85 0.75 Sparsity A 0.85 0.75\\leq{\\rm Sparsity}(\\bm{A})<0.85 0.75  roman_Sparsity ( bold_italic_A ) < 0.85 . As stated in the experimental conditions, the sparsity of the ground-truth mixture matrix  A  superscript A \\bm{A}^{*} bold_italic_A start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  is 0.8. Therefore, this result indicates that the ground-truth mixture matrix  A  superscript A \\bm{A}^{*} bold_italic_A start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  can be obtained by our method with high probability, especially when the sparsity of  A A \\bm{A} bold_italic_A  is close to the one of  A  superscript A \\bm{A}^{*} bold_italic_A start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT .",
            "Lastly, we compare the result of application to  X ( 4 ) superscript X 4 \\bm{X}^{(4)} bold_italic_X start_POSTSUPERSCRIPT ( 4 ) end_POSTSUPERSCRIPT  with FastICA. Before comparison with FastICA, we evaluate the sparsity and AD by FastICA in 20 trials with different initial matrix. The average of sparsity is  0.765  ( 2.85  10  4 ) plus-or-minus 0.765 2.85 superscript 10 4 0.765\\pm(2.85\\times 10^{-4}) 0.765  ( 2.85  10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT )  and the average of AD is  38.82  1.17 plus-or-minus 38.82 1.17 38.82\\pm 1.17 38.82  1.17 . Then, in the application of our method here, the parameter    \\kappa italic_  is set to be  0.7 , 0.8 , 0.9 0.7 0.8 0.9 0.7,0.8,0.9 0.7 , 0.8 , 0.9 , and the experiment is conducted in 20 trials with different initial matrix for each value of    \\kappa italic_  (totally 60 trials). The parameter    \\alpha italic_  is fixed at  10  1 superscript 10 1 10^{-1} 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT . Table  2  shows the result by our method. The threshold in the definition of SR is set at   = 38.82  38.82 \\psi=38.82 italic_ = 38.82  for comparison with FastICA. This result in the table suggests that the factorized matrix with lower AD than FastICA can be obtained with approximately 50% probability, when the sparsity is larger than FastICA. Namely, our proposed method can obtain a closer factorized matrix to the ground-truth mixing matrix  S  superscript S \\bm{S}^{*} bold_italic_S start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  than FastICA at a certain probability. This suggests that our method is competitive with original FastICA for evaluating of sparse and independent factorized matrices from large-size noisy data. As written in section  4.2 , it should be emphasized that the validity of our method for application to fMRI data will be discussed.",
            "As performance measures, we use sparsity in equation ( 32 ) and correlation defined by"
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Result of Students two-sample  t t t italic_t -test",
        "table": "Sx1.EGx3",
        "footnotes": [],
        "references": [
            "The organization of this article is as follows. In section  2 , the framework of ICA is overviewed and several related works are presented. In section  3 , we provide how to construct our proposed method and discuss the convergence of our algorithm theoretically. In section  4 , we apply our method both to synthetic data and real-world data, then discuss the validity. Finally, section  5  is devoted to conclusions and future works.",
            "The variables  w ,  ,  w   \\bm{w},\\bm{\\gamma},\\bm{\\tau} bold_italic_w , bold_italic_ , bold_italic_  minimizing  L   ( w ,  ,  ) subscript L  w   \\mathcal{L}_{\\rho}(\\bm{w},\\bm{\\gamma},\\bm{\\tau}) caligraphic_L start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( bold_italic_w , bold_italic_ , bold_italic_ )  are alternately updated by equations ( 13 ), ( 14 ) and ( 15 ) until convergence.",
            "Note that the factor  (  h ( t )  ) T  w i ( t + 1 )   h ( t )   2   w i ( t + 1 )  2 superscript subscript superscript h t  T superscript subscript w i t 1 subscript norm subscript superscript h t  2 subscript norm superscript subscript w i t 1 2 \\frac{(-{}_{\\nabla}\\bm{h}^{(t)})^{T}\\bm{w}_{i}^{(t+1)}}{\\|-{}_{\\nabla}\\bm{h}^{% (t)}\\|_{2}\\|\\bm{w}_{i}^{(t+1)}\\|_{2}} divide start_ARG ( - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT end_ARG start_ARG  - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG  on the right hand side of inequality ( LABEL:eq:upper_bound_of_3rd_term ) is cosine similarity. The inequality in ( 24 ) is from the upper bound of the general quadratic form. The first inequality in ( 25 ) is derived by the relation between  l 1 subscript l 1 \\ell_{1} roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT -norm and  l 2 subscript l 2 \\ell_{2} roman_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT -norm, namely   x  2   x  1  N   x  2 subscript norm x 2 subscript norm x 1 N subscript norm x 2 \\|\\bm{x}\\|_{2}\\leq\\|\\bm{x}\\|_{1}\\leq\\sqrt{N}\\|\\bm{x}\\|_{2}  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT   bold_italic_x  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  square-root start_ARG italic_N end_ARG  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  for an  N N N italic_N -dimensional vector  x x \\bm{x} bold_italic_x , and the second inequality is from the upper and the lower bounds of the general quadratic form. The inequality in ( LABEL:eq:upper_bound_of_3rd_term ) is Cauchy-Schwarz inequality. By these results and from the definition of  w i ( t + 1 ) superscript subscript w i t 1 \\bm{w}_{i}^{(t+1)} bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  in ( 11 ), the last inequality in ( 23 ) is shown using the constant  C C C italic_C  in ( 21 ). Then, if the condition ( 20 ) is satisfied, one has",
            "sparsity   Sparsity of the estimated mixture matrix  A A \\bm{A} bold_italic_A  is defined in equation ( 32 ).",
            "We also apply our method and FastICA to synthetic data  X ( 3 ) superscript X 3 \\bm{X}^{(3)} bold_italic_X start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT  and  X ( 4 ) superscript X 4 \\bm{X}^{(4)} bold_italic_X start_POSTSUPERSCRIPT ( 4 ) end_POSTSUPERSCRIPT , which model real fMRI data with larger dimension. Similar to the applications to  X ( 1 ) superscript X 1 \\bm{X}^{(1)} bold_italic_X start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  X ( 2 ) superscript X 2 \\bm{X}^{(2)} bold_italic_X start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT , the behaviors of the sparsity of  A A \\bm{A} bold_italic_A , the kurtosis of  S S \\bm{S} bold_italic_S , and the reconstruction error are depicted in Figure  3 .",
            "As performance measures, we use sparsity in equation ( 32 ) and correlation defined by",
            "where overline means the arithmetic average of all elements in the vector. The vector  s i subscript s i \\bm{s}_{i} bold_italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  means the  i i i italic_i -th temporal feature vector in the matrix  S S \\bm{S} bold_italic_S . The column vector  d REST superscript d REST \\bm{d}^{\\mathrm{REST}} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT  represents the ground-truth timing of resting state: the  j j j italic_j -th element of  d REST superscript d REST \\bm{d}^{\\mathrm{REST}} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT  is 1 if no image is shown to the test subject at the  j j j italic_j -th time step, and 0 if one of the images is shown, respectively. Therefore, the quantity in equation ( 37 ) measures the correlation between the ground-truth timing vector of the resting state  d REST superscript d REST \\bm{d}^{\\rm REST} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT  and temporal feature vector in  s s \\bm{s} bold_italic_s ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Sparsity Sparsity \\rm Sparsity roman_Sparsity ( A A \\bm{A} bold_italic_A ),  MAK MAK \\rm MAK roman_MAK ( S ) \\bm{S}) bold_italic_S ) , and  RMSE X subscript RMSE X \\mathrm{RMSE}_{\\bm{X}} roman_RMSE start_POSTSUBSCRIPT bold_italic_X end_POSTSUBSCRIPT  under various   ,    \\alpha,\\kappa italic_ , italic_",
        "table": "Sx1.EGx4",
        "footnotes": [
            "",
            "",
            "",
            ""
        ],
        "references": [
            "The organization of this article is as follows. In section  2 , the framework of ICA is overviewed and several related works are presented. In section  3 , we provide how to construct our proposed method and discuss the convergence of our algorithm theoretically. In section  4 , we apply our method both to synthetic data and real-world data, then discuss the validity. Finally, section  5  is devoted to conclusions and future works.",
            "In our method, the  i i i italic_i -th vector in the projection matrix  w i subscript w i \\bm{w}_{i} bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  minimizing cost function in equation ( 4 ) must be evaluated.",
            "The variables  w ,  ,  w   \\bm{w},\\bm{\\gamma},\\bm{\\tau} bold_italic_w , bold_italic_ , bold_italic_  minimizing  L   ( w ,  ,  ) subscript L  w   \\mathcal{L}_{\\rho}(\\bm{w},\\bm{\\gamma},\\bm{\\tau}) caligraphic_L start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( bold_italic_w , bold_italic_ , bold_italic_ )  are alternately updated by equations ( 13 ), ( 14 ) and ( 15 ) until convergence.",
            "Note that the factor  (  h ( t )  ) T  w i ( t + 1 )   h ( t )   2   w i ( t + 1 )  2 superscript subscript superscript h t  T superscript subscript w i t 1 subscript norm subscript superscript h t  2 subscript norm superscript subscript w i t 1 2 \\frac{(-{}_{\\nabla}\\bm{h}^{(t)})^{T}\\bm{w}_{i}^{(t+1)}}{\\|-{}_{\\nabla}\\bm{h}^{% (t)}\\|_{2}\\|\\bm{w}_{i}^{(t+1)}\\|_{2}} divide start_ARG ( - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT end_ARG start_ARG  - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG  on the right hand side of inequality ( LABEL:eq:upper_bound_of_3rd_term ) is cosine similarity. The inequality in ( 24 ) is from the upper bound of the general quadratic form. The first inequality in ( 25 ) is derived by the relation between  l 1 subscript l 1 \\ell_{1} roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT -norm and  l 2 subscript l 2 \\ell_{2} roman_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT -norm, namely   x  2   x  1  N   x  2 subscript norm x 2 subscript norm x 1 N subscript norm x 2 \\|\\bm{x}\\|_{2}\\leq\\|\\bm{x}\\|_{1}\\leq\\sqrt{N}\\|\\bm{x}\\|_{2}  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT   bold_italic_x  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  square-root start_ARG italic_N end_ARG  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  for an  N N N italic_N -dimensional vector  x x \\bm{x} bold_italic_x , and the second inequality is from the upper and the lower bounds of the general quadratic form. The inequality in ( LABEL:eq:upper_bound_of_3rd_term ) is Cauchy-Schwarz inequality. By these results and from the definition of  w i ( t + 1 ) superscript subscript w i t 1 \\bm{w}_{i}^{(t+1)} bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  in ( 11 ), the last inequality in ( 23 ) is shown using the constant  C C C italic_C  in ( 21 ). Then, if the condition ( 20 ) is satisfied, one has",
            "For  X ( 1 ) superscript X 1 \\bm{X}^{(1)} bold_italic_X start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  X ( 2 ) superscript X 2 \\bm{X}^{(2)} bold_italic_X start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT , we set   = 0.8 , p = 10 formulae-sequence  0.8 p 10 \\chi=0.8,p=10 italic_ = 0.8 , italic_p = 10 , namely the size of the data is small. In contrast, we set  p = 10 4 p superscript 10 4 p=10^{4} italic_p = 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT  for  X ( 3 ) superscript X 3 \\bm{X}^{(3)} bold_italic_X start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT  and  X ( 4 ) superscript X 4 \\bm{X}^{(4)} bold_italic_X start_POSTSUPERSCRIPT ( 4 ) end_POSTSUPERSCRIPT  to model real fMRI data, because the voxel size of fMRI data often takes the order from  10 4 superscript 10 4 10^{4} 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT  to  10 5 superscript 10 5 10^{5} 10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT . Moreover, in real fMRI data analysis as mentioned in section  4.2 , elements of brain activity above 3 standard deviations from the mean can be interpreted as clear characteristic activations. Namely, the number of elements representing strong activations is typically of the order of  10 1 superscript 10 1 10^{1} 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT . From this observation, we set   = 0.999  0.999 \\chi=0.999 italic_ = 0.999  for  X ( 3 ) superscript X 3 \\bm{X}^{(3)} bold_italic_X start_POSTSUPERSCRIPT ( 3 ) end_POSTSUPERSCRIPT  and  X ( 4 ) superscript X 4 \\bm{X}^{(4)} bold_italic_X start_POSTSUPERSCRIPT ( 4 ) end_POSTSUPERSCRIPT .",
            "Lastly, we compare the result of application to  X ( 4 ) superscript X 4 \\bm{X}^{(4)} bold_italic_X start_POSTSUPERSCRIPT ( 4 ) end_POSTSUPERSCRIPT  with FastICA. Before comparison with FastICA, we evaluate the sparsity and AD by FastICA in 20 trials with different initial matrix. The average of sparsity is  0.765  ( 2.85  10  4 ) plus-or-minus 0.765 2.85 superscript 10 4 0.765\\pm(2.85\\times 10^{-4}) 0.765  ( 2.85  10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT )  and the average of AD is  38.82  1.17 plus-or-minus 38.82 1.17 38.82\\pm 1.17 38.82  1.17 . Then, in the application of our method here, the parameter    \\kappa italic_  is set to be  0.7 , 0.8 , 0.9 0.7 0.8 0.9 0.7,0.8,0.9 0.7 , 0.8 , 0.9 , and the experiment is conducted in 20 trials with different initial matrix for each value of    \\kappa italic_  (totally 60 trials). The parameter    \\alpha italic_  is fixed at  10  1 superscript 10 1 10^{-1} 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT . Table  2  shows the result by our method. The threshold in the definition of SR is set at   = 38.82  38.82 \\psi=38.82 italic_ = 38.82  for comparison with FastICA. This result in the table suggests that the factorized matrix with lower AD than FastICA can be obtained with approximately 50% probability, when the sparsity is larger than FastICA. Namely, our proposed method can obtain a closer factorized matrix to the ground-truth mixing matrix  S  superscript S \\bm{S}^{*} bold_italic_S start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  than FastICA at a certain probability. This suggests that our method is competitive with original FastICA for evaluating of sparse and independent factorized matrices from large-size noisy data. As written in section  4.2 , it should be emphasized that the validity of our method for application to fMRI data will be discussed.",
            "The result of correlation is depicted in Figure  4  under various   ,    \\alpha,\\kappa italic_ , italic_ :   = 10  6 , 10  2 , 10 1  superscript 10 6 superscript 10 2 superscript 10 1 \\alpha=10^{-6},10^{-2},10^{1} italic_ = 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT , 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT , 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT  and   = 0 , 0.5 , 0.9  0 0.5 0.9 \\kappa=0,0.5,0.9 italic_ = 0 , 0.5 , 0.9 . Other parameters are set as follows:  K = 20 , M = 500 ,  = 1 ,  = 10  5 ,  = 10  3 formulae-sequence K 20 formulae-sequence M 500 formulae-sequence  1 formulae-sequence  superscript 10 5  superscript 10 3 K=20,M=500,\\rho=1,\\zeta=10^{-5},\\eta=10^{-3} italic_K = 20 , italic_M = 500 , italic_ = 1 , italic_ = 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT , italic_ = 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT . From this figure, the value of correlation is at most 0.6 for   = 0 , 0.5  0 0.5 \\kappa=0,0.5 italic_ = 0 , 0.5 , whereas it sometimes exceeds 0.6 under   = 10  2 , 10 1  superscript 10 2 superscript 10 1 \\alpha=10^{-2},10^{1} italic_ = 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT , 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT  for   = 0.9  0.9 \\kappa=0.9 italic_ = 0.9 . In addition, to confirm the validity of our method, we apply FastICA and our proposed method under   = 0.9 ,  = 10 1 formulae-sequence  0.9  superscript 10 1 \\kappa=0.9,\\alpha=10^{1} italic_ = 0.9 , italic_ = 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT  to the same data 50 times with different initial matrix, then conduct Students two-sample  t t t italic_t -test for the first, the second, and the third largest values of Correlation. The result is shown in Table 3, where negative value means that the Correlation by our method is larger. From this result, there is a significant difference between the results by our method and FastICA, and it is clear that the first and the second largest values of Correlation by our method are larger than FastICA. Although the third largest value by FastICA is larger, we think it is sufficient to claim the advantage of our method over FastICA.",
            "Next, we visualize the extracted feature vectors by our method. The 18th row vector in  S S \\bm{S} bold_italic_S  by our method under   = 10 1 ,  = 0.9 formulae-sequence  superscript 10 1  0.9 \\alpha=10^{1},\\kappa=0.9 italic_ = 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_ = 0.9  is depicted in Figure  5 A. Note that the 18th row vector has the largest Correlation in our result under   = 10 1 ,  = 0.9 formulae-sequence  superscript 10 1  0.9 \\alpha=10^{1},\\kappa=0.9 italic_ = 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_ = 0.9  as shown in Figure  4 . The timing of showing image to a test subject, which reflects the information of the vector  d REST superscript d REST \\bm{d}^{\\mathrm{REST}} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT , is also shown in the figure. From this result, the temporal changes between resting and non-resting states can be tracked easily in the feature vector by our method. Additionally, the spatial map of the 18th spatial feature vector in  A A \\bm{A} bold_italic_A  by our method is shown on the cross sections of the brain in Figure  5 B. Note that this spatial feature vector is the counterpart of the 18th temporal feature vector in Figure  5 A. For spatial map, the column vectors in  A A \\bm{A} bold_italic_A  are normalized to have zero mean and unit variance, and elements within 3 standard deviations of the mean are truncated to zero. For visualization of the spatial map, we use Nilearn (version 0.10.1) in Python library. In this figure, several active regions under resting state or the response to some visual stimuli can be observed. In particular, strong activations are observed in the cerebellum, which is known to be activated by visual stimuli. This result indicates that our method with high sparsity setting can identify brain regions for information processing of visual stimuli with high accuracy.",
            "To compare our proposed method and FastICA, we show the behaviors of two feature vectors given by FastICA, namely the 3rd and the 17th vectors. For clarity, extracted feature vectors are denoted with a superscript, which represents the method for comparing FastICA and our proposed method. For example, the 3rd vector in  S S \\bm{S} bold_italic_S  by FastICA is written as  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT . First, the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  and the spatial map of  a 3 ( FastICA ) superscript subscript a 3 FastICA \\bm{a}_{3}^{(\\rm FastICA)} bold_italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  are depicted in Figures  6 A and  6 B, respectively. Note that the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is most strongly correlated with the timing vector of visual stimuli as in Figure  4 . However, from Figure  6 A, resting and non-resting regions in fMRI data cannot be discriminated from the shape of the feature vector by FastICA. In addition, we cannot clearly identify which parts of the brain are strongly activated from Figure  6 B. We also depict the vector  s 17 ( FastICA ) superscript subscript s 17 FastICA \\bm{s}_{17}^{\\rm(FastICA)} bold_italic_s start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  and the spatial map of  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  in Figures  7 A and  7 B, respectively. Note that the vector  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is most strongly correlated with the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT , whose counterpart  s 18 ( ours ) superscript subscript s 18 ours \\bm{s}_{18}^{\\rm(ours)} bold_italic_s start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  has the largest value of Correlation with  d REST superscript d REST \\bm{d}^{\\rm REST} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT  under appropriate   ,    \\alpha,\\kappa italic_ , italic_  as in Figure 4. For Correlation between these two column vectors, see also Figure  8 A in the following. Similarly to the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT , we cannot find significant synchronization with the timing of visual stimuli from Figure  7 A, and it is difficult to understand what the spatial map of  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  means because the area of activation in the brain is not clear from Figure  7 B.",
            "We think the advantage of our method is due to the sparsity of the estimated mixture matrix  A A \\bm{A} bold_italic_A . To support this, the sparsity of  A A \\bm{A} bold_italic_A  by this experiment is summarized in Table  4 . From this table, it is found that the parameters giving the feature vector with the largest correlation (  = 10 1 ,  = 0.9 formulae-sequence  superscript 10 1  0.9 \\alpha=10^{1},\\kappa=0.9 italic_ = 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_ = 0.9 ) lead to the sparsest matrix  A A \\bm{A} bold_italic_A . On the other hand,  Sparsity  ( A ) Sparsity A {\\rm Sparsity}(\\bm{A}) roman_Sparsity ( bold_italic_A )  by FastICA is evaluated as 0.104, which is much smaller than our method. In the previous study  [ 35 ,  36 ,  13 ] , it is claimed that the method of MF giving sparse  A A \\bm{A} bold_italic_A  can extract appropriate temporal feature vector characterizing the external stimuli. Therefore, the result indicating the advantage of our method is consistent with the previous studies.",
            "To verify the significance of sparsity, the kurtosis of the estimated temporal feature matrix  S S \\bm{S} bold_italic_S  and the reconstruction error by our method are also summarized in Table  4 . For comparison,  MAK  ( S ) MAK S {\\rm MAK}(\\bm{S}) roman_MAK ( bold_italic_S )  and  RMSE X subscript RMSE X {\\rm RMSE}_{\\bm{X}} roman_RMSE start_POSTSUBSCRIPT bold_italic_X end_POSTSUBSCRIPT  obtained by FastICA are 12.37 and 0.904, respectively. Recall that the objective of this experiment is to identify the temporal features response to external stimuli. Hence, this result suggests that the sparsity of spatial features is more important than the kurtosis of temporal features or the reconstruction error in feature extraction of neuronal activity data. This fact can be reinforced by the result of previous study  [ 13 ] , where they applied sparse MF methods, namely SparsePCA and method of optimal directions (MOD), to the same dataset and investigated the performance of feature extraction and reconstruction error. As a result, even under the case of the large reconstruction error, appropriate features are obtained if the sparsity of the spatial feature in the brain is large. Our result of experiment shows that the accuracy of synchronization between extracted temporal features and the timing of showing images can be improved by sparsifying spatial features in the brain, even if the kurtosis of temporal features is decreased. Therefore, it can be concluded that the sparsity of spatial features in the brain is the most important to obtain features corresponding to visual stimuli."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "Sx1.EGx5",
        "footnotes": [],
        "references": [
            "The organization of this article is as follows. In section  2 , the framework of ICA is overviewed and several related works are presented. In section  3 , we provide how to construct our proposed method and discuss the convergence of our algorithm theoretically. In section  4 , we apply our method both to synthetic data and real-world data, then discuss the validity. Finally, section  5  is devoted to conclusions and future works.",
            "Here     p \\|\\cdot\\|_{p}    start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT  is  l p subscript l p \\ell_{p} roman_l start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT -norm,  J f ~  ( w i ) =  J f  ( w i ) ~ subscript J f subscript w i subscript J f subscript w i \\widetilde{J_{f}}(\\bm{w}_{i})=-{J_{f}}(\\bm{w}_{i}) over~ start_ARG italic_J start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = - italic_J start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , and  Q #  R p  K superscript Q # superscript R p K \\bm{Q}^{\\#}\\in\\mathbb{R}^{p\\times K} bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT  blackboard_R start_POSTSUPERSCRIPT italic_p  italic_K end_POSTSUPERSCRIPT  is given by the minimizer in equation ( 5 ).",
            "The variables  w ,  ,  w   \\bm{w},\\bm{\\gamma},\\bm{\\tau} bold_italic_w , bold_italic_ , bold_italic_  minimizing  L   ( w ,  ,  ) subscript L  w   \\mathcal{L}_{\\rho}(\\bm{w},\\bm{\\gamma},\\bm{\\tau}) caligraphic_L start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( bold_italic_w , bold_italic_ , bold_italic_ )  are alternately updated by equations ( 13 ), ( 14 ) and ( 15 ) until convergence.",
            "Note that the factor  (  h ( t )  ) T  w i ( t + 1 )   h ( t )   2   w i ( t + 1 )  2 superscript subscript superscript h t  T superscript subscript w i t 1 subscript norm subscript superscript h t  2 subscript norm superscript subscript w i t 1 2 \\frac{(-{}_{\\nabla}\\bm{h}^{(t)})^{T}\\bm{w}_{i}^{(t+1)}}{\\|-{}_{\\nabla}\\bm{h}^{% (t)}\\|_{2}\\|\\bm{w}_{i}^{(t+1)}\\|_{2}} divide start_ARG ( - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT end_ARG start_ARG  - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG  on the right hand side of inequality ( LABEL:eq:upper_bound_of_3rd_term ) is cosine similarity. The inequality in ( 24 ) is from the upper bound of the general quadratic form. The first inequality in ( 25 ) is derived by the relation between  l 1 subscript l 1 \\ell_{1} roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT -norm and  l 2 subscript l 2 \\ell_{2} roman_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT -norm, namely   x  2   x  1  N   x  2 subscript norm x 2 subscript norm x 1 N subscript norm x 2 \\|\\bm{x}\\|_{2}\\leq\\|\\bm{x}\\|_{1}\\leq\\sqrt{N}\\|\\bm{x}\\|_{2}  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT   bold_italic_x  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  square-root start_ARG italic_N end_ARG  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  for an  N N N italic_N -dimensional vector  x x \\bm{x} bold_italic_x , and the second inequality is from the upper and the lower bounds of the general quadratic form. The inequality in ( LABEL:eq:upper_bound_of_3rd_term ) is Cauchy-Schwarz inequality. By these results and from the definition of  w i ( t + 1 ) superscript subscript w i t 1 \\bm{w}_{i}^{(t+1)} bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  in ( 11 ), the last inequality in ( 23 ) is shown using the constant  C C C italic_C  in ( 21 ). Then, if the condition ( 20 ) is satisfied, one has",
            "Next, we visualize the extracted feature vectors by our method. The 18th row vector in  S S \\bm{S} bold_italic_S  by our method under   = 10 1 ,  = 0.9 formulae-sequence  superscript 10 1  0.9 \\alpha=10^{1},\\kappa=0.9 italic_ = 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_ = 0.9  is depicted in Figure  5 A. Note that the 18th row vector has the largest Correlation in our result under   = 10 1 ,  = 0.9 formulae-sequence  superscript 10 1  0.9 \\alpha=10^{1},\\kappa=0.9 italic_ = 10 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_ = 0.9  as shown in Figure  4 . The timing of showing image to a test subject, which reflects the information of the vector  d REST superscript d REST \\bm{d}^{\\mathrm{REST}} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT , is also shown in the figure. From this result, the temporal changes between resting and non-resting states can be tracked easily in the feature vector by our method. Additionally, the spatial map of the 18th spatial feature vector in  A A \\bm{A} bold_italic_A  by our method is shown on the cross sections of the brain in Figure  5 B. Note that this spatial feature vector is the counterpart of the 18th temporal feature vector in Figure  5 A. For spatial map, the column vectors in  A A \\bm{A} bold_italic_A  are normalized to have zero mean and unit variance, and elements within 3 standard deviations of the mean are truncated to zero. For visualization of the spatial map, we use Nilearn (version 0.10.1) in Python library. In this figure, several active regions under resting state or the response to some visual stimuli can be observed. In particular, strong activations are observed in the cerebellum, which is known to be activated by visual stimuli. This result indicates that our method with high sparsity setting can identify brain regions for information processing of visual stimuli with high accuracy."
        ]
    },
    "id_table_6": {
        "caption": "",
        "table": "Sx1.EGx6",
        "footnotes": [],
        "references": [
            "To compare our proposed method and FastICA, we show the behaviors of two feature vectors given by FastICA, namely the 3rd and the 17th vectors. For clarity, extracted feature vectors are denoted with a superscript, which represents the method for comparing FastICA and our proposed method. For example, the 3rd vector in  S S \\bm{S} bold_italic_S  by FastICA is written as  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT . First, the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  and the spatial map of  a 3 ( FastICA ) superscript subscript a 3 FastICA \\bm{a}_{3}^{(\\rm FastICA)} bold_italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  are depicted in Figures  6 A and  6 B, respectively. Note that the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is most strongly correlated with the timing vector of visual stimuli as in Figure  4 . However, from Figure  6 A, resting and non-resting regions in fMRI data cannot be discriminated from the shape of the feature vector by FastICA. In addition, we cannot clearly identify which parts of the brain are strongly activated from Figure  6 B. We also depict the vector  s 17 ( FastICA ) superscript subscript s 17 FastICA \\bm{s}_{17}^{\\rm(FastICA)} bold_italic_s start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  and the spatial map of  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  in Figures  7 A and  7 B, respectively. Note that the vector  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is most strongly correlated with the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT , whose counterpart  s 18 ( ours ) superscript subscript s 18 ours \\bm{s}_{18}^{\\rm(ours)} bold_italic_s start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  has the largest value of Correlation with  d REST superscript d REST \\bm{d}^{\\rm REST} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT  under appropriate   ,    \\alpha,\\kappa italic_ , italic_  as in Figure 4. For Correlation between these two column vectors, see also Figure  8 A in the following. Similarly to the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT , we cannot find significant synchronization with the timing of visual stimuli from Figure  7 A, and it is difficult to understand what the spatial map of  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  means because the area of activation in the brain is not clear from Figure  7 B."
        ]
    },
    "id_table_7": {
        "caption": "",
        "table": "Sx1.EGx7",
        "footnotes": [],
        "references": [
            "For application of DC algorithm to minimization in our method, the cost function  J o  ( w i ) subscript J o subscript w i J_{o}(\\bm{w}_{i}) italic_J start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  must be expressed by the difference of two convex functions. First, Lipschitz constant  L L L italic_L  of  J f ~  ( w i ) ~ subscript J f subscript w i \\widetilde{J_{f}}(\\bm{w}_{i}) over~ start_ARG italic_J start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  is introduced, which can be defined because  J f ~  ( w i ) ~ subscript J f subscript w i \\widetilde{J_{f}}(\\bm{w}_{i}) over~ start_ARG italic_J start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  is secondary differentiable. Then, the function  ( L / 2 )   w i  2 2  J f ~  ( w i ) L 2 superscript subscript norm subscript w i 2 2 ~ subscript J f subscript w i (L/2)\\|\\bm{w}_{i}\\|_{2}^{2}-\\widetilde{J_{f}}(\\bm{w}_{i}) ( italic_L / 2 )  bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - over~ start_ARG italic_J start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  is easily proved to be convex by the definition of Lipschitz constant  L L L italic_L . Moreover, regularization term   Q #  w i  1 subscript norm superscript Q # subscript w i 1 \\|\\bm{Q}^{\\#}\\bm{w}_{i}\\|_{1}  bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  is clearly convex, and the sum of two convex functions  ( L / 2 )   w i  2 2 +    Q #  w i  1 L 2 superscript subscript norm subscript w i 2 2  subscript norm superscript Q # subscript w i 1 (L/2)\\|\\bm{w}_{i}\\|_{2}^{2}+\\alpha\\|\\bm{Q}^{\\#}\\bm{w}_{i}\\|_{1} ( italic_L / 2 )  bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_  bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  is also convex. Therefore,  J o  ( w i ) subscript J o subscript w i J_{o}(\\bm{w}_{i}) italic_J start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  can be represented by the difference of two convex functions  g  ( w i ) , h  ( w i ) g subscript w i h subscript w i g(\\bm{w}_{i}),h(\\bm{w}_{i}) italic_g ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_h ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  like  J o  ( w i ) = g  ( w i )  h  ( w i ) subscript J o subscript w i g subscript w i h subscript w i J_{o}(\\bm{w}_{i})=g(\\bm{w}_{i})-h(\\bm{w}_{i}) italic_J start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_g ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - italic_h ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , where the two convex functions are defined in equations ( 7 ) and ( 8 ).",
            "where overline means the arithmetic average of all elements in the vector. The vector  s i subscript s i \\bm{s}_{i} bold_italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  means the  i i i italic_i -th temporal feature vector in the matrix  S S \\bm{S} bold_italic_S . The column vector  d REST superscript d REST \\bm{d}^{\\mathrm{REST}} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT  represents the ground-truth timing of resting state: the  j j j italic_j -th element of  d REST superscript d REST \\bm{d}^{\\mathrm{REST}} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT  is 1 if no image is shown to the test subject at the  j j j italic_j -th time step, and 0 if one of the images is shown, respectively. Therefore, the quantity in equation ( 37 ) measures the correlation between the ground-truth timing vector of the resting state  d REST superscript d REST \\bm{d}^{\\rm REST} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT  and temporal feature vector in  s s \\bm{s} bold_italic_s .",
            "To compare our proposed method and FastICA, we show the behaviors of two feature vectors given by FastICA, namely the 3rd and the 17th vectors. For clarity, extracted feature vectors are denoted with a superscript, which represents the method for comparing FastICA and our proposed method. For example, the 3rd vector in  S S \\bm{S} bold_italic_S  by FastICA is written as  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT . First, the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  and the spatial map of  a 3 ( FastICA ) superscript subscript a 3 FastICA \\bm{a}_{3}^{(\\rm FastICA)} bold_italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  are depicted in Figures  6 A and  6 B, respectively. Note that the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is most strongly correlated with the timing vector of visual stimuli as in Figure  4 . However, from Figure  6 A, resting and non-resting regions in fMRI data cannot be discriminated from the shape of the feature vector by FastICA. In addition, we cannot clearly identify which parts of the brain are strongly activated from Figure  6 B. We also depict the vector  s 17 ( FastICA ) superscript subscript s 17 FastICA \\bm{s}_{17}^{\\rm(FastICA)} bold_italic_s start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  and the spatial map of  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  in Figures  7 A and  7 B, respectively. Note that the vector  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is most strongly correlated with the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT , whose counterpart  s 18 ( ours ) superscript subscript s 18 ours \\bm{s}_{18}^{\\rm(ours)} bold_italic_s start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  has the largest value of Correlation with  d REST superscript d REST \\bm{d}^{\\rm REST} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT  under appropriate   ,    \\alpha,\\kappa italic_ , italic_  as in Figure 4. For Correlation between these two column vectors, see also Figure  8 A in the following. Similarly to the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT , we cannot find significant synchronization with the timing of visual stimuli from Figure  7 A, and it is difficult to understand what the spatial map of  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  means because the area of activation in the brain is not clear from Figure  7 B.",
            "For relation between spatial maps by the two methods, we evaluate the absolute value of Correlation between the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  and each column vector of  A A \\bm{A} bold_italic_A  by FastICA in Figure  8 A. From this result, we find that the vector  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is most strongly correlated with the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT . In Figure  8 B, we depict the scatter plot of the element in the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  vs. the corresponding element in the vector  a 3 ( FastICA ) superscript subscript a 3 FastICA \\bm{a}_{3}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  (top) or  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  (bottom), where the values of the elements in spatial vectors are normalized to the range  [  1 , 1 ] 1 1 [-1,1] [ - 1 , 1 ]  by the linear transformation. From this figure, the vector  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is more strongly correlated with the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT . Hence, these two spatial feature vectors will represent similar spatial networks. As mentioned in the result of Figure  7 , synchronization with the timing of visual stimuli is not observed in the vector  s 17 ( FastICA ) superscript subscript s 17 FastICA \\bm{s}_{17}^{\\rm(FastICA)} bold_italic_s start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT , which is the counterpart of the spatial feature vector  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT . In contrast, the temporal feature vector  s 18 ( ours ) superscript subscript s 18 ours \\bm{s}_{18}^{\\rm(ours)} bold_italic_s start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  is clearly synchronized with the timing of visual stimuli, and the corresponding spatial feature  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  also shows activation in the region related to visual stimuli. From these facts, we can conclude that our method outperforms FastICA in feature extraction from fMRI data."
        ]
    },
    "id_table_8": {
        "caption": "",
        "table": "Sx1.EGx8",
        "footnotes": [],
        "references": [
            "For application of DC algorithm to minimization in our method, the cost function  J o  ( w i ) subscript J o subscript w i J_{o}(\\bm{w}_{i}) italic_J start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  must be expressed by the difference of two convex functions. First, Lipschitz constant  L L L italic_L  of  J f ~  ( w i ) ~ subscript J f subscript w i \\widetilde{J_{f}}(\\bm{w}_{i}) over~ start_ARG italic_J start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  is introduced, which can be defined because  J f ~  ( w i ) ~ subscript J f subscript w i \\widetilde{J_{f}}(\\bm{w}_{i}) over~ start_ARG italic_J start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  is secondary differentiable. Then, the function  ( L / 2 )   w i  2 2  J f ~  ( w i ) L 2 superscript subscript norm subscript w i 2 2 ~ subscript J f subscript w i (L/2)\\|\\bm{w}_{i}\\|_{2}^{2}-\\widetilde{J_{f}}(\\bm{w}_{i}) ( italic_L / 2 )  bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - over~ start_ARG italic_J start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  is easily proved to be convex by the definition of Lipschitz constant  L L L italic_L . Moreover, regularization term   Q #  w i  1 subscript norm superscript Q # subscript w i 1 \\|\\bm{Q}^{\\#}\\bm{w}_{i}\\|_{1}  bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  is clearly convex, and the sum of two convex functions  ( L / 2 )   w i  2 2 +    Q #  w i  1 L 2 superscript subscript norm subscript w i 2 2  subscript norm superscript Q # subscript w i 1 (L/2)\\|\\bm{w}_{i}\\|_{2}^{2}+\\alpha\\|\\bm{Q}^{\\#}\\bm{w}_{i}\\|_{1} ( italic_L / 2 )  bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_  bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  is also convex. Therefore,  J o  ( w i ) subscript J o subscript w i J_{o}(\\bm{w}_{i}) italic_J start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  can be represented by the difference of two convex functions  g  ( w i ) , h  ( w i ) g subscript w i h subscript w i g(\\bm{w}_{i}),h(\\bm{w}_{i}) italic_g ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_h ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  like  J o  ( w i ) = g  ( w i )  h  ( w i ) subscript J o subscript w i g subscript w i h subscript w i J_{o}(\\bm{w}_{i})=g(\\bm{w}_{i})-h(\\bm{w}_{i}) italic_J start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_g ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - italic_h ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , where the two convex functions are defined in equations ( 7 ) and ( 8 ).",
            "where  ( Q # ) j , subscript superscript Q # j (\\bm{Q}^{\\#})_{j,} ( bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT italic_j , end_POSTSUBSCRIPT  means the  j j j italic_j -th row vector of  Q # superscript Q # \\bm{Q}^{\\#} bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT  and  S a  ( x ) subscript S a x \\mathrm{S}_{a}(x) roman_S start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_x )  is soft thresholding function defined in equation ( 18 ),",
            "To compare our proposed method and FastICA, we show the behaviors of two feature vectors given by FastICA, namely the 3rd and the 17th vectors. For clarity, extracted feature vectors are denoted with a superscript, which represents the method for comparing FastICA and our proposed method. For example, the 3rd vector in  S S \\bm{S} bold_italic_S  by FastICA is written as  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT . First, the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  and the spatial map of  a 3 ( FastICA ) superscript subscript a 3 FastICA \\bm{a}_{3}^{(\\rm FastICA)} bold_italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  are depicted in Figures  6 A and  6 B, respectively. Note that the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is most strongly correlated with the timing vector of visual stimuli as in Figure  4 . However, from Figure  6 A, resting and non-resting regions in fMRI data cannot be discriminated from the shape of the feature vector by FastICA. In addition, we cannot clearly identify which parts of the brain are strongly activated from Figure  6 B. We also depict the vector  s 17 ( FastICA ) superscript subscript s 17 FastICA \\bm{s}_{17}^{\\rm(FastICA)} bold_italic_s start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  and the spatial map of  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  in Figures  7 A and  7 B, respectively. Note that the vector  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is most strongly correlated with the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT , whose counterpart  s 18 ( ours ) superscript subscript s 18 ours \\bm{s}_{18}^{\\rm(ours)} bold_italic_s start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  has the largest value of Correlation with  d REST superscript d REST \\bm{d}^{\\rm REST} bold_italic_d start_POSTSUPERSCRIPT roman_REST end_POSTSUPERSCRIPT  under appropriate   ,    \\alpha,\\kappa italic_ , italic_  as in Figure 4. For Correlation between these two column vectors, see also Figure  8 A in the following. Similarly to the vector  s 3 ( FastICA ) superscript subscript s 3 FastICA \\bm{s}_{3}^{(\\rm FastICA)} bold_italic_s start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT , we cannot find significant synchronization with the timing of visual stimuli from Figure  7 A, and it is difficult to understand what the spatial map of  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  means because the area of activation in the brain is not clear from Figure  7 B.",
            "For relation between spatial maps by the two methods, we evaluate the absolute value of Correlation between the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  and each column vector of  A A \\bm{A} bold_italic_A  by FastICA in Figure  8 A. From this result, we find that the vector  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is most strongly correlated with the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT . In Figure  8 B, we depict the scatter plot of the element in the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  vs. the corresponding element in the vector  a 3 ( FastICA ) superscript subscript a 3 FastICA \\bm{a}_{3}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  (top) or  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  (bottom), where the values of the elements in spatial vectors are normalized to the range  [  1 , 1 ] 1 1 [-1,1] [ - 1 , 1 ]  by the linear transformation. From this figure, the vector  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT  is more strongly correlated with the vector  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT . Hence, these two spatial feature vectors will represent similar spatial networks. As mentioned in the result of Figure  7 , synchronization with the timing of visual stimuli is not observed in the vector  s 17 ( FastICA ) superscript subscript s 17 FastICA \\bm{s}_{17}^{\\rm(FastICA)} bold_italic_s start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT , which is the counterpart of the spatial feature vector  a 17 ( FastICA ) superscript subscript a 17 FastICA \\bm{a}_{17}^{\\rm(FastICA)} bold_italic_a start_POSTSUBSCRIPT 17 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_FastICA ) end_POSTSUPERSCRIPT . In contrast, the temporal feature vector  s 18 ( ours ) superscript subscript s 18 ours \\bm{s}_{18}^{\\rm(ours)} bold_italic_s start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  is clearly synchronized with the timing of visual stimuli, and the corresponding spatial feature  a 18 ( ours ) superscript subscript a 18 ours \\bm{a}_{18}^{\\rm(ours)} bold_italic_a start_POSTSUBSCRIPT 18 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( roman_ours ) end_POSTSUPERSCRIPT  also shows activation in the region related to visual stimuli. From these facts, we can conclude that our method outperforms FastICA in feature extraction from fMRI data."
        ]
    },
    "id_table_9": {
        "caption": "",
        "table": "S4.T1.14",
        "footnotes": [],
        "references": [
            "In DC algorithm, computation of Lipschitz constant  L L L italic_L  needs maximum eigenvalue of Hessian   2 J f ~  ( w i ) superscript  2 ~ subscript J f subscript w i \\nabla^{2}\\widetilde{J_{f}}(\\bm{w}_{i})  start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT over~ start_ARG italic_J start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , whose computational complexity is  O  ( K 3 ) O superscript K 3 O(K^{3}) italic_O ( italic_K start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) . In practice,  L L L italic_L  is evaluated by backtracking line search algorithm  [ 28 ] . In this algorithm, we prepare the tentative Lipschitz constant  l ( t ) superscript l t l^{(t)} italic_l start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  in the  t t t italic_t -th update, then  l ( t ) superscript l t l^{(t)} italic_l start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  is accepted as the final Lipschitz constant if the criterion of inequality ( 9 ) is satisfied for    ( 0 , 1 )  0 1 \\zeta\\in(0,1) italic_  ( 0 , 1 ) . Otherwise,  l ( t ) superscript l t l^{(t)} italic_l start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  is rescaled by  l ( t )    l ( t )  superscript l t  superscript l t l^{(t)}\\leftarrow\\eta l^{(t)} italic_l start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  italic_ italic_l start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  with the constant   > 1  1 \\eta>1 italic_ > 1 , then inequality ( 9 ) is checked again.",
            "The significant difference of DC algorithm in our  l 1 subscript l 1 \\ell_{1} roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT -regularized ICA is orthogonalization and normalization after variable update, which requires a slight change in the proof for convergence condition of DC algorithm. For this purpose, we should distinguish the variable after orthogonalization and normalization, which is denoted by  w ^ i ( t + 1 ) superscript subscript ^ w i t 1 \\widehat{\\bm{w}}_{i}^{(t+1)} over^ start_ARG bold_italic_w end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT . With this variable, we can show that our proposed algorithm converges to a point in equation ( 19 ) if the inequality  J o  ( w ^ i ( t + 1 ) )  J o  ( w i ( t ) ) subscript J o superscript subscript ^ w i t 1 subscript J o superscript subscript w i t J_{o}(\\widehat{\\bm{w}}_{i}^{(t+1)})\\leq J_{o}(\\bm{w}_{i}^{(t)}) italic_J start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( over^ start_ARG bold_italic_w end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT )  italic_J start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT )  is satisfied.",
            "For comparison, we also apply another sparse ICA method in the previous work  [ 21 ]  to the same data. In their method, the sparsity of the matrix  W T  Q superscript W T Q {\\bm{W}}^{T}{\\bm{Q}} bold_italic_W start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_Q  is controlled by two parameters   ,    \\lambda,\\alpha italic_ , italic_ , and we set   = 0.1 , 0.5 , 1.0 ,  = 10  4 , 10  3 , 10  2 formulae-sequence  0.1 0.5 1.0  superscript 10 4 superscript 10 3 superscript 10 2 \\lambda=0.1,0.5,1.0,\\alpha=10^{-4},10^{-3},10^{-2} italic_ = 0.1 , 0.5 , 1.0 , italic_ = 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT , 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT , respectively. The result in Figure  9  shows that very large value of Correlation over 0.5 cannot be obtained, in other words appropriate feature cannot be extracted sufficiently by the ICA method of sparsifying the matrix  W T  Q superscript W T Q {\\bm{W}}^{T}{\\bm{Q}} bold_italic_W start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_Q . In contrast, our method sparsifying the matrix  Q #  W superscript Q # W \\bm{Q}^{\\#}\\bm{W} bold_italic_Q start_POSTSUPERSCRIPT # end_POSTSUPERSCRIPT bold_italic_W  yields very large value of Correlation and works more appropriately for feature extraction from fMRI data."
        ]
    },
    "id_table_10": {
        "caption": "",
        "table": "Sx1.EGx9",
        "footnotes": [],
        "references": [
            "After evaluation of Lipschitz constant, we move on to the formulation of DC algorithm in our proposed method. In DC algorithm, subderivative   h  ( w i ) h subscript w i \\partial h(\\bm{w}_{i})  italic_h ( bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  is necessary for the calculation of  h ( t )  subscript superscript h t  {}_{\\nabla}\\bm{h}^{(t)} start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  in the process (i), which is given by equation ( 10 ),"
        ]
    },
    "id_table_11": {
        "caption": "",
        "table": "S4.T2.3",
        "footnotes": [],
        "references": [
            "The minimization problem in equation ( 11 ) can be regarded as a generalized lasso problem  [ 29 ] , whose solution cannot be obtained analytically. Hence, we attempt to find the solution numerically by the method of alternating directions method of multipliers (ADMM)  [ 30 ] . In the application of ADMM,  w i ( t + 1 ) superscript subscript w i t 1 \\bm{w}_{i}^{(t+1)} bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  is computed by minimizing augmented Lagrangian  L   ( w ,  ,  ) subscript L  w   \\mathcal{L}_{\\rho}(\\bm{w},\\bm{\\gamma},\\bm{\\tau}) caligraphic_L start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( bold_italic_w , bold_italic_ , bold_italic_ ) ,",
            "Note that the factor  (  h ( t )  ) T  w i ( t + 1 )   h ( t )   2   w i ( t + 1 )  2 superscript subscript superscript h t  T superscript subscript w i t 1 subscript norm subscript superscript h t  2 subscript norm superscript subscript w i t 1 2 \\frac{(-{}_{\\nabla}\\bm{h}^{(t)})^{T}\\bm{w}_{i}^{(t+1)}}{\\|-{}_{\\nabla}\\bm{h}^{% (t)}\\|_{2}\\|\\bm{w}_{i}^{(t+1)}\\|_{2}} divide start_ARG ( - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT end_ARG start_ARG  - start_FLOATSUBSCRIPT  end_FLOATSUBSCRIPT bold_italic_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG  on the right hand side of inequality ( LABEL:eq:upper_bound_of_3rd_term ) is cosine similarity. The inequality in ( 24 ) is from the upper bound of the general quadratic form. The first inequality in ( 25 ) is derived by the relation between  l 1 subscript l 1 \\ell_{1} roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT -norm and  l 2 subscript l 2 \\ell_{2} roman_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT -norm, namely   x  2   x  1  N   x  2 subscript norm x 2 subscript norm x 1 N subscript norm x 2 \\|\\bm{x}\\|_{2}\\leq\\|\\bm{x}\\|_{1}\\leq\\sqrt{N}\\|\\bm{x}\\|_{2}  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT   bold_italic_x  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  square-root start_ARG italic_N end_ARG  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  for an  N N N italic_N -dimensional vector  x x \\bm{x} bold_italic_x , and the second inequality is from the upper and the lower bounds of the general quadratic form. The inequality in ( LABEL:eq:upper_bound_of_3rd_term ) is Cauchy-Schwarz inequality. By these results and from the definition of  w i ( t + 1 ) superscript subscript w i t 1 \\bm{w}_{i}^{(t+1)} bold_italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t + 1 ) end_POSTSUPERSCRIPT  in ( 11 ), the last inequality in ( 23 ) is shown using the constant  C C C italic_C  in ( 21 ). Then, if the condition ( 20 ) is satisfied, one has"
        ]
    },
    "id_table_12": {
        "caption": "",
        "table": "S4.T3.5",
        "footnotes": [],
        "references": []
    },
    "id_table_13": {
        "caption": "",
        "table": "S4.T4.19",
        "footnotes": [],
        "references": [
            "The variables  w ,  ,  w   \\bm{w},\\bm{\\gamma},\\bm{\\tau} bold_italic_w , bold_italic_ , bold_italic_  minimizing  L   ( w ,  ,  ) subscript L  w   \\mathcal{L}_{\\rho}(\\bm{w},\\bm{\\gamma},\\bm{\\tau}) caligraphic_L start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( bold_italic_w , bold_italic_ , bold_italic_ )  are alternately updated by equations ( 13 ), ( 14 ) and ( 15 ) until convergence."
        ]
    },
    "id_table_14": {
        "caption": "",
        "table": "S4.T4.26",
        "footnotes": [],
        "references": [
            "The variables  w ,  ,  w   \\bm{w},\\bm{\\gamma},\\bm{\\tau} bold_italic_w , bold_italic_ , bold_italic_  minimizing  L   ( w ,  ,  ) subscript L  w   \\mathcal{L}_{\\rho}(\\bm{w},\\bm{\\gamma},\\bm{\\tau}) caligraphic_L start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( bold_italic_w , bold_italic_ , bold_italic_ )  are alternately updated by equations ( 13 ), ( 14 ) and ( 15 ) until convergence."
        ]
    },
    "id_table_15": {
        "caption": "",
        "table": "S4.T4.33",
        "footnotes": [],
        "references": [
            "The variables  w ,  ,  w   \\bm{w},\\bm{\\gamma},\\bm{\\tau} bold_italic_w , bold_italic_ , bold_italic_  minimizing  L   ( w ,  ,  ) subscript L  w   \\mathcal{L}_{\\rho}(\\bm{w},\\bm{\\gamma},\\bm{\\tau}) caligraphic_L start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( bold_italic_w , bold_italic_ , bold_italic_ )  are alternately updated by equations ( 13 ), ( 14 ) and ( 15 ) until convergence."
        ]
    }
}