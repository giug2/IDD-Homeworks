{
    "PAPER'S NUMBER OF TABLES": 2,
    "S5.T1": {
        "caption": "Table 1: The simulation results of a binary classification.",
        "table": "<table id=\"S5.T1.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.5.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.5.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T1.5.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Methods</span></th>\n<td id=\"S5.T1.5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T1.5.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Vanilla SGD</span></td>\n<td id=\"S5.T1.5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T1.5.1.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">Adagrad</span></td>\n<td id=\"S5.T1.5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T1.5.1.1.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">Adam</span></td>\n<td id=\"S5.T1.5.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T1.5.1.1.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">FQNGD</span></td>\n</tr>\n<tr id=\"S5.T1.5.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.5.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T1.5.2.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Accuracy</span></th>\n<td id=\"S5.T1.5.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T1.5.2.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">98.48</span></td>\n<td id=\"S5.T1.5.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T1.5.2.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">98.81</span></td>\n<td id=\"S5.T1.5.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T1.5.2.2.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">98.87</span></td>\n<td id=\"S5.T1.5.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T1.5.2.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">99.32</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To demonstrate the FQNGD algorithm for QFL, we perform the binary and ternary classification tasks on the standard MNIST dataset ",
                "[",
                "35",
                "]",
                ", with digits ",
                "{",
                "2",
                ",",
                "5",
                "}",
                "2",
                "5",
                "\\{2,5\\}",
                " for the binary task and ",
                "{",
                "1",
                ",",
                "3",
                ",",
                "7",
                "}",
                "1",
                "3",
                "7",
                "\\{1,3,7\\}",
                " for the ternary one. There are ",
                "11379",
                "11379",
                "11379",
                " training data and ",
                "1924",
                "1924",
                "1924",
                " test data for the binary classification, and ",
                "19138",
                "19138",
                "19138",
                " training data and ",
                "3173",
                "3173",
                "3173",
                " test data are assigned for the ternary classification. As for the setup of QFL in our experiments, the QFL system consists of ",
                "6",
                "6",
                "6",
                " identically local VQC participants, each of which owns the same amount of training data. The test data are stored in the global part and are used to evaluate the classification performance.",
                "We compare our proposed FQNGD algorithm with other three optimizers: the naive SGD optimizer, the Adagrad optimizer ",
                "[",
                "36",
                "]",
                ", and the Adam optimizer ",
                "[",
                "37",
                "]",
                ". The Adagrad optimizer is a gradient descent optimizer with a past-gradient-dependent learning rate in each dimension. The Adam optimizer refers to the gradient descent method with an adaptive learning rate as well as adaptive first and second moments.",
                "As shown in Figure ",
                "5",
                ", our simulation results suggest that our proposed FQNGD method is capable of achieving the fastest convergence rate among the optimization approaches. It means that the FQNGD method can reduce the communication overhead cost and maintain the baseline performance of binary and ternary classifications on the MNIST dataset. Moreover, we evaluate the QFL performance in terms of classification accuracy. The FQNGD method outperforms the other counterparts with the highest accuracy values. In particular, the FQNGD is designed for the VQC model and can attain better empirical results than the Adam and Adagrad methods with adaptive learning rates over epochs."
            ]
        ]
    },
    "S5.T2": {
        "caption": "Table 2: The simulation results of a ternary classification.",
        "table": "<table id=\"S5.T2.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.5.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T2.5.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Methods</span></th>\n<td id=\"S5.T2.5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T2.5.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Vanilla SGD</span></td>\n<td id=\"S5.T2.5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T2.5.1.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">Adagrad</span></td>\n<td id=\"S5.T2.5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T2.5.1.1.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">Adam</span></td>\n<td id=\"S5.T2.5.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T2.5.1.1.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">FQNGD</span></td>\n</tr>\n<tr id=\"S5.T2.5.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.5.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T2.5.2.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Accuracy</span></th>\n<td id=\"S5.T2.5.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T2.5.2.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">97.86</span></td>\n<td id=\"S5.T2.5.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T2.5.2.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">98.63</span></td>\n<td id=\"S5.T2.5.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T2.5.2.2.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">98.71</span></td>\n<td id=\"S5.T2.5.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.2pt;padding-bottom:1.2pt;\"><span id=\"S5.T2.5.2.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">99.12</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To demonstrate the FQNGD algorithm for QFL, we perform the binary and ternary classification tasks on the standard MNIST dataset ",
                "[",
                "35",
                "]",
                ", with digits ",
                "{",
                "2",
                ",",
                "5",
                "}",
                "2",
                "5",
                "\\{2,5\\}",
                " for the binary task and ",
                "{",
                "1",
                ",",
                "3",
                ",",
                "7",
                "}",
                "1",
                "3",
                "7",
                "\\{1,3,7\\}",
                " for the ternary one. There are ",
                "11379",
                "11379",
                "11379",
                " training data and ",
                "1924",
                "1924",
                "1924",
                " test data for the binary classification, and ",
                "19138",
                "19138",
                "19138",
                " training data and ",
                "3173",
                "3173",
                "3173",
                " test data are assigned for the ternary classification. As for the setup of QFL in our experiments, the QFL system consists of ",
                "6",
                "6",
                "6",
                " identically local VQC participants, each of which owns the same amount of training data. The test data are stored in the global part and are used to evaluate the classification performance.",
                "We compare our proposed FQNGD algorithm with other three optimizers: the naive SGD optimizer, the Adagrad optimizer ",
                "[",
                "36",
                "]",
                ", and the Adam optimizer ",
                "[",
                "37",
                "]",
                ". The Adagrad optimizer is a gradient descent optimizer with a past-gradient-dependent learning rate in each dimension. The Adam optimizer refers to the gradient descent method with an adaptive learning rate as well as adaptive first and second moments.",
                "As shown in Figure ",
                "5",
                ", our simulation results suggest that our proposed FQNGD method is capable of achieving the fastest convergence rate among the optimization approaches. It means that the FQNGD method can reduce the communication overhead cost and maintain the baseline performance of binary and ternary classifications on the MNIST dataset. Moreover, we evaluate the QFL performance in terms of classification accuracy. The FQNGD method outperforms the other counterparts with the highest accuracy values. In particular, the FQNGD is designed for the VQC model and can attain better empirical results than the Adam and Adagrad methods with adaptive learning rates over epochs."
            ]
        ]
    }
}