{
    "id_table_1": {
        "caption": "Table 1:  Data samples by domain and format.",
        "table": "Sx3.T1.1",
        "footnotes": [],
        "references": [
            "Previous research  (Kumar et al.  2020 ; Shvartzshnaider et al.  2019 )  has operationalized CI in NLP systems through a two-phase process: extracting CI parameters from user-provided data and comparing data flows against established norms. This approach allows for separate evaluations of a models contextual understanding and its ability to judge adherence to norms. Recent advances in LLMs  (Yang et al.  2023 )  suggest a new paradigm that expands AI assistant capabilities with two additional phases. LLM-based AI assistants can learn relevant norms from human instructions  (Ouyang et al.  2022 ; Wang et al.  2023b ; Bai et al.  2022 ) , and then generate appropriate responses from user requests according to learned norms. As shown in Figure  1 , a typical AI assistant facilitates information exchange between the user and various third-party entities, including other AI assistants, human users, APIs, and other groups of agents. It accesses user information and user expectations, interacts with another party to achieve specific goals, and ultimately executes tasks on the users behalf.",
            "Each data format encompasses four benchmark phases, as detailed in the Benchmark section. Each benchmark phase contains several evaluation tasks. Overall, the CI-Bench dataset comprises a total of 44,100 test cases, with a negative to positive label ratio of 7.4:1, spanning the eight distinct domains illustrated in Table  1 .",
            "We quantified the inherent trade-off between utility and privacy-consciousness by employing the metrics of sensitivity and specificity. Utility, synonymous with sensitivity in this context, strives to maximize the volume of pertinent information shared or utilized. Conversely, privacy-consciousness, analogous to specificity, prioritizes the minimization of sensitive or personal data disclosure. Achieving an optimal equilibrium between these two competing objectives is paramount, and we represent this dynamic interplay through a two-dimensional sensitivity-specificity plot, as illustrated in Figure  10 ."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  A sample of the structured data.",
        "table": "Sx3.T2.1",
        "footnotes": [],
        "references": [
            "Figure  2  presents a case study demonstrating this framework in action. The scenario involves a user interacting with a doctors office staff via an AI assistant, whom has access to user information and user expectations.",
            "To generate the data samples, we establish a multi-step pipeline that synthetically generates natural communications, such as dialogues and emails, from structured scenario data. This pipeline first extracts key characteristics from publicly available real-world dialogues and fills in values for each column of the data structure in Table  2 . It then utilizes an LLM to synthetically generate realistic task scenarios based on these structured scenarios. Finally, it programmatically generates test questions for each benchmark phase introduced in the Benchmark section. All test questions are presented alongside essential background information, such as the task scenario, user data, and/or user expectations.",
            "We next investigated the influence of expectations on a models ability to assess the appropriateness of information sharing. To do this, we framed a task as True/False questions, where models judged the appropriateness of a given context. These test cases were annotated by human experts, providing the ground truth for AUC computation. The annotation process involved assigning a True/False label to each sample within the structured scenarios (Table  2 ), encompassing all relevant parameters. This task was undertaken by a subgroup of the papers authors, who engaged in thorough discussions and reviews on appropriateness of the information flow defined within this structured data."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Sample scenarios: dialogue and email",
        "table": "Sx3.T3.1",
        "footnotes": [],
        "references": [
            "Task Scenarios  We utilized an LLM model to generate realistic task scenarios based on the structured scenarios, employing a prompt template, as shown in the Appendix. In designing this prompt, we ensured the accurate inclusion of all CI data components within the generated scenario, while avoiding irrelevant context switching that could arise from multi-turn communications. As demonstrated in Table  3 , user intention, information attributes, and other relevant context elements are precisely conveyed in the conversation.",
            "To assess language models ability to understand and extract relevant information from complex contexts, CI-Bench includes MCQ tasks for each contextual information parameter. Figure  3  presents the evaluation results across different model sizes.",
            "Figure  4  shows the performance of identifying relevant norms for two formats: dialogue and email. Performance differences between these formats were observed on the Nano model, but these differences disappeared with larger models, suggesting that smaller models are more sensitive to format changes. Compared to Figure  3 , the AUC numbers in this task were lower than those for the simpler task of identifying individual context parameters, as expected."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Information attributes by category.",
        "table": "Sx3.T3.1.2.1.1",
        "footnotes": [],
        "references": [
            "Figure  4  shows the performance of identifying relevant norms for two formats: dialogue and email. Performance differences between these formats were observed on the Nano model, but these differences disappeared with larger models, suggesting that smaller models are more sensitive to format changes. Compared to Figure  3 , the AUC numbers in this task were lower than those for the simpler task of identifying individual context parameters, as expected.",
            "Test cases in the dataset comprises 49 distinct information pieces, systematically categorized into seven types: personal identifiers, demographic information, behavioral information, financial information, health information, psychological information, and other sensitive information, as detailed in Table  4 . Each information piece represents a unique attribute that could potentially be disclosed within a conversational context.",
            "Following Figure 5 in the paper, we conducted a granular analysis of the experimental results, dissecting them by both domain and information category. As detailed in Table  4 , each category encompasses a specific set of information attributes that were strategically incorporated into the scenarios. To gauge an AI systems proficiency in preventing inadvertent leakage of sensitive information, we employed specificity as our metric of choice. Specificity is defined as the probability of test cases being accurately classified as not appropriate to share, given the entire set of genuinely negative instances."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  The list of multi-domain scenarios used to generate the CI-Bench dataset scenarios.",
        "table": "Sx3.T3.1.2.2.1",
        "footnotes": [],
        "references": [
            "We separated our analysis into scenarios where expectations were explicit in the provided text and where they were implicit. AI assistants based on Gemini models, aligned with human values, can judge appropriateness even without explicit expectations. The results are illustrated in Figure  5 . As expected, performance for the implicit case of the Nano model was significantly worse, approaching randomness in the worst case. However, performance improved with larger models and significantly improved when the norm was made explicit.",
            "To rigorously assess the models capacity to navigate diverse conversational scenarios, we have meticulously crafted 50 distinct scenarios spanning eight domains, as elucidated in Table  5 . These scenarios are designed to encompass a broad spectrum of real-world conversational contexts, thus ensuring a comprehensive evaluation of the models performance in handling sensitive information across various situations."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Prompt templates used to generate test cases.",
        "table": "A2.T4.1",
        "footnotes": [],
        "references": [
            "In Figure  6 , we presented the performance by domains without providing explicit norms. While there were some minor variations in AUC numbers, we did not observe significant performance differences among the domains evaluated. However, performance consistently improved with increasing model size, which aligns with our earlier findings.",
            "The prompt templates employed in our evaluation framework are presented in Table  6 . The initial two prompts serve to generate scenarios, incorporating parameters as specified in Table 2 of the paper. The subsequent four prompt templates are dedicated to the evaluation of the four core tasks delineated in Section Benchmark. All of these prompt templates receive the scenario (either in dialogue or email format) as input."
        ]
    },
    "id_table_7": {
        "caption": "",
        "table": "A2.T5.1",
        "footnotes": [],
        "references": [
            "Figure  7  presents the appropriateness judgment results specifically for dialogues. Within this figure, each cell value corresponds to the specificity of appropriate judgment exhibited by a system utilizing the Gemini Ultra model, with consideration given to each domain and information category. The results reveal that demographic and financial information are generally handled adeptly by the system. In contrast, safeguarding behavioral information presents a more formidable challenge, as evidenced by its comparatively lower specificity value. When examining the performance across different problem domains, it becomes apparent that Healthcare and Finance emerge as particularly demanding, especially when juxtaposed with domains such as Education and eCommerce."
        ]
    },
    "id_table_8": {
        "caption": "",
        "table": "A2.T6.1",
        "footnotes": [],
        "references": [
            "Further investigation into the experimental results unveiled a subtle yet noteworthy trend: the specificity metric experiences a slight dip in test cases presented within email scenarios, as depicted in Figure  8 . Echoing the observations from the dialogue analysis, demographic and financial information once again attained higher specificity metric values. Conversely, test cases involving PII exhibited diminished performance within certain problem domains, underscoring the heightened sensitivity and complexity associated with handling such data."
        ]
    }
}