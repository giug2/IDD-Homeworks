{
    "id_table_1": {
        "caption": "Table 1:  SoTA Comparison. Face verification accuracy (%) of LResNet50-IR on different benchmarks when trained on synthetic datasets from ID 3  and state-of-the-art SFR generative models. For fairness, all methods generate face datasets of 10K identities each of which has 50 face images.",
        "table": "A5.EGx1",
        "footnotes": [],
        "references": [
            "With the introduction of various regulations restricting the use of large-scale facial data in recent years, such as GDPR, synthetic-based face recognition (SFR)  ( Boutros et al. ,  2023 )  has received widespread attention from the academic community  ( Qiu et al. ,  2021 ;  Wood et al. ,  2021 ;  Wang et al. ,  2023 ) . The goal of SFR is to generate synthetic face datasets that mimic the distribution of real face images, and use it to train a face recognition (FR) model such that the model can recognize real face images as effectively as possible.",
            "There exist numerous efforts to address SFR, which can be categorized into  GAN -based models and  diffusion  models. GAN-based models utilize adversarial training to learn to generate synthetic data for FR training. Recently, with the empirical advantages of diffusion models over GANs, many works have attempted to use diffusion models to generate synthetic face data in place of authentic data. However, the reported results by these state-of-the-art (SoTA) SFR generative models  ( Bae et al. ,  2023 ;  Boutros et al. ,  2022 ;  Kolf et al. ,  2023 ;  Qiu et al. ,  2021 ;  Boutros et al. ,  2023 )  show significant degradation in the verification accuracy in comparison to FR models trained by authentic data. We deduce the degradation might be due to two reasons. First, while previous works adopt diffusion models, they operate in the original score vector field without injecting the direction with regards to identity information, which makes them unable to guarantee identity-preserving sampling. Second, they fail to consider the structure of face manifold in terms of diversity during sampling.",
            "To this end, in this paper, we propose a novel  ID entity-preserving-yet- D iversified  D iffusion generative model termed  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  and a sampling algorithm for inference. Jointly leveraging identity and face attributes as conditioning signals,  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  can synthesize diversified face images that conform to desired attributes while preserving intra-class identity. Specifically,  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  generates a new sample based upon two conditioning signals: a target face embedding and a specific set of face attributes. The target face embedding enforces identity preservation while face attributes enrich intra-class diversity. To optimize  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT , we propose a new loss function that involves an explicit term to preserve identity. Theoretically, we show that with the addition of this term, minimizing the proposed loss function is equivalent to maximizing the lower bound of the likelihood of an adjusted conditional data log-likelihood. Consequently, this theoretical analysis motivates a new ID-preserving sampling algorithm that generates desired synthetic face images. To generate an SFR dataset, we further propose a new dataset-generating algorithm. This algorithm ensures inter-class diversity by solving the Tammes problem  ( Tammes ,  1930 ) , which maximally separates identity embeddings on the face manifold. In the meantime, it encourages intra-class diversity by perturbing identity embeddings randomly within prescribed areas. It works in conjunction with identity embeddings and diverse attributes to ensure inter-/intra-class diversity while preserving identity. Extensive experiments show that  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  outperforms other existing methods in multiple challenging benchmarks.",
            "We propose a conditional diffusion model, ID 3  (see Figure  1  for details). Specifically, we extend the denoising network by conditioning it on two sources of signals: identity signals  y y \\mathbf{y} bold_y  and face attribute signals  s s \\mathbf{s} bold_s . The identity signals capture discernible faces in generated images, whereas face attribute signals specify the identity-irrelevant attributes, including poses, ages, etc. We introduce how to obtain these two conditioning signals, respectively, in the next two subsections.",
            "Face attributes capture identity-irrelevant information about face images, such as age, face poses, etc. To obtain face attribute as conditioning signals, we employ pretrained attribute predictors  ( Serengil and Ozpinar ,  2021 )  which output these attributes when given a face image as input. The pretrained attribute predictors are a collection of ad-hoc domain experts in age estimation and pose estimation. After obtaining each of these attribute values,  s age  [ 0 , 100 ] subscript s age 0 100 \\mathbf{s}_{\\text{age}}\\in[0,100] bold_s start_POSTSUBSCRIPT age end_POSTSUBSCRIPT  [ 0 , 100 ] ,  s pose  [  90  , 90  ] 3 subscript s pose superscript superscript 90 superscript 90 3 \\mathbf{s}_{\\text{pose}}\\in[-90^{\\circ},90^{\\circ}]^{3} bold_s start_POSTSUBSCRIPT pose end_POSTSUBSCRIPT  [ - 90 start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , 90 start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT , we concatenate them as the overall attribute  s = [ s age , s pose ] s subscript s age subscript s pose \\mathbf{s}=[\\mathbf{s}_{\\text{age}},\\mathbf{s}_{\\text{pose}}] bold_s = [ bold_s start_POSTSUBSCRIPT age end_POSTSUBSCRIPT , bold_s start_POSTSUBSCRIPT pose end_POSTSUBSCRIPT ]  which is then fed into the diffusion model as conditioning signals.",
            "Now the denoising network in Eq. ( 1 ) becomes  x ^   ( x t , t , y , s ) subscript ^ x  subscript x t t y s \\hat{\\mathbf{x}}_{\\bm{\\theta}}(\\mathbf{x}_{t},t,\\mathbf{y},\\mathbf{s}) over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT bold_italic_ end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , bold_y , bold_s )  that takes as input the noised  x t subscript x t \\mathbf{x}_{t} bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , the time step  t t t italic_t , and the conditioning signals  y y \\mathbf{y} bold_y  and  s s \\mathbf{s} bold_s . To optimize  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT , we construct a training objective upon the ELBO of  log  p  ( x | y , s ) p conditional x y s \\log p(\\mathbf{x}|\\mathbf{y},\\mathbf{s}) roman_log italic_p ( bold_x | bold_y , bold_s ) , ensuring that  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  generates identity-preserving yet diversified faces:",
            "Theorem  3.1  provides insights for designing a novel sampling algorithm in the spirit of Langevin dynamics applied on the adjusted conditional likelihood  p ~  ( x t | y , s ) ~ p conditional subscript x t y s \\tilde{p}(\\mathbf{x}_{t}|\\mathbf{y},\\mathbf{s}) over~ start_ARG italic_p end_ARG ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_y , bold_s ) . We note that Langevin dynamics can generate new samples from a probability density  p p p italic_p  by virtue of its score function (i.e., the gradient of the logarithm of the probability density w.r.t. the sample,   x log  p subscript  x p \\nabla_{\\mathbf{x}}{\\log p}  start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT roman_log italic_p ). Motivated by this observation, we aim to find the score function of the adjusted likelihood for sample generation. Specifically, taking the logarithm and the gradient w.r.t.  x x \\mathbf{x} bold_x  on both sides of Eq. ( 6 ) yields",
            "Our proposed dataset-generating algorithm goes as follows: given  N N N italic_N  target identities, we generate  N N N italic_N  anchor embeddings distributed on the sphere:  w 1 , w 2 , ... , w N  S d  1 subscript w 1 subscript w 2 ... subscript w N superscript S d 1 \\mathbf{w}_{1},\\mathbf{w}_{2},...,\\mathbf{w}_{N}\\in\\mathbb{S}^{d-1} bold_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , bold_w start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT  blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT  as uniformly as possible in the sense that each pair of the embeddings are maximally separated on the unit sphere * * * This is known as the Tammes problem  ( Tammes ,  1930 )  for which there exists no exact solution for hypersphere  S d  1 , d > 3 superscript S d 1 d 3 \\mathbb{S}^{d-1},d>3 blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT , italic_d > 3 . However, one can use the optimization technique introduced in  ( Mettes et al. ,  2019 ) . . For each anchor  w i subscript w i \\mathbf{w}_{i} bold_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , we would like to generate  m m m italic_m  identity embeddings perturbed around  w i subscript w i \\mathbf{w}_{i} bold_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  while ensuring that these  m m m italic_m  identity embeddings get close to but different than  w i subscript w i \\mathbf{w}_{i} bold_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Specifically, to find these  m m m italic_m  identity embeddings, we solve the following optimization problem  P i subscript P i \\mathbf{P}_{i} bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT :",
            "We train our proposed ID 3  on FFHQ  ( Karras et al. ,  2019 )  dataset. The FFHQ (FaceForensics++) dataset is a large-scale dataset used for benchmarking and evaluating the performance of deep learning models in the field of face forensics. It is an extension of the original FaceForensics dataset, which was designed to facilitate the development and comparison of methods for detecting and preventing face manipulation and deepfakes. In order to compare with DCFace  ( Kim et al. ,  2023 ) , we also train ID 3  on CASIA-WebFace  ( Yi et al. ,  2014 ) . The CASIA-WebFace dataset is used for face verification and face recognition tasks. This dataset contains 494,414 face images of 10,575 real identities collected from the web.",
            "Benchmarks:  The performance of face recognition models is evaluated on various benchmark datasets: LFW   ( Huang et al. ,  2008 ) , CFP-FP   ( Sengupta et al. ,  2016 ) , CPLFW  ( Zheng and Deng ,  2018 ) , AgeDB  ( Moschoglou et al. ,  2017 )  and CALFW  ( Zheng et al. ,  2017 ) . They are used to measure the impact of different factors on face image, such as pose changes and age variations.",
            "For our ID 3 , we implement the denoising network with a U-net architecture and the projection module with a three-layer perceptron (hidden-layer size  ( 512 , 256 , 768 ) 512 256 768 (512,256,768) ( 512 , 256 , 768 ) ) with ReLU activation. All models are implemented with PyTorch and trained from scratch using 8 NVIDIA Tesla V100 GPUs. Specifically, we set   t  x t = 0.5  ( 1  1 / ( 1 + exp (  t / T ) ) \\lambda_{t}\\kappa_{\\mathbf{x}_{t}}=0.5\\cdot(1-1/(1+\\exp{(-t/T)}) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT = 0.5  ( 1 - 1 / ( 1 + roman_exp ( - italic_t / italic_T ) )  for the loss coefficients in Eq. ( 3 ), and use  T = 1 , 000 T 1 000 T=1,000 italic_T = 1 , 000  for the diffusion model; training batch size is set to  16 16 16 16  and the total training steps  500 , 000 500 000 500,000 500 , 000 . We directly use a pre-trained face recognition (FR) model sourced from pSp  ( Richardson et al. ,  2021 )  as the identity feature extractor. Throughout the entire training process, these pre-trained models are frozen. In addition, we set # of identity embeddings  m = 25 m 25 m=25 italic_m = 25  in Eq. ( 9 ) for each ID and match their embeddings with randomly selected attributes as conditioning signals for the diffusion model. For face recognition, we use LResNet50-IR  ( Deng et al. ,  2019 ) , a variant of ResNet  ( He et al. ,  2016 ) , as the backbone framework and follow the original configurations.",
            "We test the performance of the face recognition model trained on synthetic face data generated by ID 3  and compare against SoTA SFR generative models, including IDiff-Face  ( Boutros et al. ,  2023 ) , ID-Net  ( Kolf et al. ,  2023 ) , DigiFace  ( Bae et al. ,  2023 ) , SFace  ( Boutros et al. ,  2022 ) , SynFace  ( Qiu et al. ,  2021 )  and DCFace  ( Kim et al. ,  2023 ) .",
            "We compare the accuracies of FR models trained on the synthetic face datasets generated by different generative models and demonstrate the results in Table  1 .",
            "As shown in Table  1 , ID 3  demonstrates consistent superior performance, achieving the highest average accuracy of  86.50 % percent 86.50 86.50\\% 86.50 % , and outperforms other baselines in all benchmarks, notably scoring  83.78 % percent 83.78 83.78\\% 83.78 %  in AgeDB and  85.00 % percent 85.00 85.00\\% 85.00 %  in CFP-FP. This demonstrates the effectiveness of ID 3  in gaining pose and age control. Other methods, while effective to varying degrees, attain average scores below  86.50 % percent 86.50 86.50\\% 86.50 %  and are inferior to ID 3 .",
            "It can be shown that the reversed likelihood  p  ( y , s | x ) p y conditional s x p(\\mathbf{y},\\mathbf{s}|\\mathbf{x}) italic_p ( bold_y , bold_s | bold_x )  is a joint vMF density  ( Xu et al. ,  2023 ;  Hasnat et al. ,  2017 ) :",
            "Note that these reasonable assumptions are applied in  ( Xu et al. ,  2023 ;  Li et al. ,  2021 ;  Hasnat et al. ,  2017 ) . Now we can specify the value of the scalar  C C C italic_C :",
            "We illustrate the dataset generating algorithm in Figure  A.1 . First,  N N N italic_N  anchor embeddings are generated on the sphere as uniformly as possible. Then, for each anchor,  m m m italic_m  identity embeddings are generated around the anchor. This strategy ensures inter-class diversity while intra-class identity preservation is guaranteed. Colors show the correspondence between the generation procedure on the left and the generated samples on the right.",
            "Face Recognition (FR) is the task of matching query imagery to an enrolled identity database. SoTA FR models are trained using margin-based softmax losses  ( Wang et al. ,  2018 ;  Deng et al. ,  2019 )  on large-scale web-crawled datasets   ( Guo et al. ,  2016 ;  Zhu et al. ,  2021 ) . These datasets encompasses three characteristics in common (as mentioned in the introduction): (i) sufficient inter-class diversity; (ii) intra-class diversity; (iii) intra-class identity preservation. However, due to the introduction of various regulations restricing the use of authentic face data, researchers switch their attention to synthetic face recognition (SFR). We argue that the crux of SFR is to generate a training dataset that inherits the three characteristics above.",
            "GAN-based SFR models.  Most of the deep generative models for synthetic faces generation are based on GANs. DigiFace  ( Bae et al. ,  2023 )  utilizes a digital rendering pipeline to generate synthetic images based on a learned model of facial geometry and attributes. SFace  ( Boutros et al. ,  2022 )  and ID-Net  ( Kolf et al. ,  2023 )  train a StyleGAN-ADA  ( Karras et al. ,  2020 )  under a class-conditional setting. SynFace  ( Qiu et al. ,  2021 )  extends DiscoFaceGAN  ( Deng et al. ,  2020 )  using synthetic identity mix-up to enhance the intra-class diversity. However, the reported results shown by these models show significant performance degradation in comparison to FR trained on real data. This performance gap is mainly due to inter-class discrimination and small intra-class diversity in their generated synthetic training datasets.",
            "Diffusion models for SFR.  Recently, Diffusion Models (DMs)  ( Ho et al. ,  2020 ;  Lin et al. ,  2018 ;  Song et al. ,  2020 )  gained attention for both research and industry due to their potential to rival GANs on image synthesis, as they are easier to train without stability issues, and stem from a solid theoretical foundation. Among SFR diffusion models, IDiff-Face  ( Boutros et al. ,  2023 )  achieves SoTA performance. On the basis of a diffusion model, it incorporates Contextual Partial Dropout to generate diverse intra-class images. However, IDiff-Face fails to regularize the relationship among different identities."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Ablation Study. Face verification accuracy (%) of LResNet50-IR when trained on synthetic datasets from ID 3  and other model variants. ID 3 - [ l  b , u  b ] l b u b [lb,ub] [ italic_l italic_b , italic_u italic_b ]  represents an ID 3  variant using  l  b l b lb italic_l italic_b  and  u  b u b ub italic_u italic_b  as lower- and upper-bound for sampling   i  j subscript  i j \\nu_{ij} italic_ start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT s. ID 3 -random denotes a model variant that randomly sets anchors on the unit hypersphere for sample generation. ID 3 -w/o-attribute denotes one that does not use attributes as conditioning signals. ID 3 -w/o-reversed denotes one that removes the reversed likelihood score from Eq. ( 8 ) in the proposed ID-preserving sampling algorithm.",
        "table": "S4.T1.4",
        "footnotes": [
            ""
        ],
        "references": [
            "With the introduction of various regulations restricting the use of large-scale facial data in recent years, such as GDPR, synthetic-based face recognition (SFR)  ( Boutros et al. ,  2023 )  has received widespread attention from the academic community  ( Qiu et al. ,  2021 ;  Wood et al. ,  2021 ;  Wang et al. ,  2023 ) . The goal of SFR is to generate synthetic face datasets that mimic the distribution of real face images, and use it to train a face recognition (FR) model such that the model can recognize real face images as effectively as possible.",
            "There exist numerous efforts to address SFR, which can be categorized into  GAN -based models and  diffusion  models. GAN-based models utilize adversarial training to learn to generate synthetic data for FR training. Recently, with the empirical advantages of diffusion models over GANs, many works have attempted to use diffusion models to generate synthetic face data in place of authentic data. However, the reported results by these state-of-the-art (SoTA) SFR generative models  ( Bae et al. ,  2023 ;  Boutros et al. ,  2022 ;  Kolf et al. ,  2023 ;  Qiu et al. ,  2021 ;  Boutros et al. ,  2023 )  show significant degradation in the verification accuracy in comparison to FR models trained by authentic data. We deduce the degradation might be due to two reasons. First, while previous works adopt diffusion models, they operate in the original score vector field without injecting the direction with regards to identity information, which makes them unable to guarantee identity-preserving sampling. Second, they fail to consider the structure of face manifold in terms of diversity during sampling.",
            "We build up our generative model,  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT , upon denoising diffusion probabilistic models (diffusion models for short)   ( Ho et al. ,  2020 ;  Song et al. ,  2022 ;  Rombach et al. ,  2022 )  as they empirically exhibit SoTA performance in the field of image generation. Diffusion models can be seen as a hierarchical VAE whose optimization objective is to minimize the KL divergence between the true data distribution and the model distribution  p  subscript p  p_{\\bm{\\theta}} italic_p start_POSTSUBSCRIPT bold_italic_ end_POSTSUBSCRIPT , which is equivalent to minimizing the expected negative log-likelihood (NLL),  E x  D  [  log  p   ( x ) ] subscript E similar-to x D delimited-[] subscript p  x \\mathbb{E}_{\\mathbf{x}\\sim\\mathcal{D}}[-\\log p_{\\bm{\\theta}}(\\mathbf{x})] blackboard_E start_POSTSUBSCRIPT bold_x  caligraphic_D end_POSTSUBSCRIPT [ - roman_log italic_p start_POSTSUBSCRIPT bold_italic_ end_POSTSUBSCRIPT ( bold_x ) ] . However, directly minimizing the expected NLL is intractable, therefore diffusion models instead minimize its evidence lower bound (ELBO), where the ELBO term can further simply to a denoising task with several model assumptions:",
            "Face attributes capture identity-irrelevant information about face images, such as age, face poses, etc. To obtain face attribute as conditioning signals, we employ pretrained attribute predictors  ( Serengil and Ozpinar ,  2021 )  which output these attributes when given a face image as input. The pretrained attribute predictors are a collection of ad-hoc domain experts in age estimation and pose estimation. After obtaining each of these attribute values,  s age  [ 0 , 100 ] subscript s age 0 100 \\mathbf{s}_{\\text{age}}\\in[0,100] bold_s start_POSTSUBSCRIPT age end_POSTSUBSCRIPT  [ 0 , 100 ] ,  s pose  [  90  , 90  ] 3 subscript s pose superscript superscript 90 superscript 90 3 \\mathbf{s}_{\\text{pose}}\\in[-90^{\\circ},90^{\\circ}]^{3} bold_s start_POSTSUBSCRIPT pose end_POSTSUBSCRIPT  [ - 90 start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , 90 start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT , we concatenate them as the overall attribute  s = [ s age , s pose ] s subscript s age subscript s pose \\mathbf{s}=[\\mathbf{s}_{\\text{age}},\\mathbf{s}_{\\text{pose}}] bold_s = [ bold_s start_POSTSUBSCRIPT age end_POSTSUBSCRIPT , bold_s start_POSTSUBSCRIPT pose end_POSTSUBSCRIPT ]  which is then fed into the diffusion model as conditioning signals.",
            "Remark.  We have just shown that our proposed loss is the upper bound of an adjusted conditional negative data log-likelihood. This adjusted likelihood  p ~  ( x | y , s ) ~ p conditional x y s \\tilde{p}(\\mathbf{x}|\\mathbf{y},\\mathbf{s}) over~ start_ARG italic_p end_ARG ( bold_x | bold_y , bold_s )  can be factorized into the original likelihood  p  ( x | y , s ) p conditional x y s p(\\mathbf{x}|\\mathbf{y},\\mathbf{s}) italic_p ( bold_x | bold_y , bold_s )  and a reversed likelihood  p  ( y , s | x ) p y conditional s x p(\\mathbf{y},\\mathbf{s}|\\mathbf{x}) italic_p ( bold_y , bold_s | bold_x )  with some positive power. We term it as adjusted since the original likelihood is discounted by the reversed likelihood. Intuitively, the reversed likelihood shifts the original likelihood such that the adjusted likelihood covers ID-preserving data, which is attributed to the inner-product term we introduce into the loss function in Eq. ( 2 ).",
            "See Appendix B for the derivation of the above equations. As such, our ID-preserving sampling algorithm performs sampling by searching a trajectory in the vector field   log  p ~  ( x t | y , s )  ~ p conditional subscript x t y s \\nabla\\log\\tilde{p}(\\mathbf{x}_{t}|\\mathbf{y},\\mathbf{s})  roman_log over~ start_ARG italic_p end_ARG ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_y , bold_s )  that can maximize the adjusted conditional likelihood  p ~  ( x t | y , s ) ~ p conditional subscript x t y s \\tilde{p}(\\mathbf{x}_{t}|\\mathbf{y},\\mathbf{s}) over~ start_ARG italic_p end_ARG ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_y , bold_s ) . See Algorithm  2  for the specific procedure.",
            "Our proposed dataset-generating algorithm goes as follows: given  N N N italic_N  target identities, we generate  N N N italic_N  anchor embeddings distributed on the sphere:  w 1 , w 2 , ... , w N  S d  1 subscript w 1 subscript w 2 ... subscript w N superscript S d 1 \\mathbf{w}_{1},\\mathbf{w}_{2},...,\\mathbf{w}_{N}\\in\\mathbb{S}^{d-1} bold_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , bold_w start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT  blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT  as uniformly as possible in the sense that each pair of the embeddings are maximally separated on the unit sphere * * * This is known as the Tammes problem  ( Tammes ,  1930 )  for which there exists no exact solution for hypersphere  S d  1 , d > 3 superscript S d 1 d 3 \\mathbb{S}^{d-1},d>3 blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT , italic_d > 3 . However, one can use the optimization technique introduced in  ( Mettes et al. ,  2019 ) . . For each anchor  w i subscript w i \\mathbf{w}_{i} bold_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , we would like to generate  m m m italic_m  identity embeddings perturbed around  w i subscript w i \\mathbf{w}_{i} bold_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  while ensuring that these  m m m italic_m  identity embeddings get close to but different than  w i subscript w i \\mathbf{w}_{i} bold_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Specifically, to find these  m m m italic_m  identity embeddings, we solve the following optimization problem  P i subscript P i \\mathbf{P}_{i} bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT :",
            "We train our proposed ID 3  on FFHQ  ( Karras et al. ,  2019 )  dataset. The FFHQ (FaceForensics++) dataset is a large-scale dataset used for benchmarking and evaluating the performance of deep learning models in the field of face forensics. It is an extension of the original FaceForensics dataset, which was designed to facilitate the development and comparison of methods for detecting and preventing face manipulation and deepfakes. In order to compare with DCFace  ( Kim et al. ,  2023 ) , we also train ID 3  on CASIA-WebFace  ( Yi et al. ,  2014 ) . The CASIA-WebFace dataset is used for face verification and face recognition tasks. This dataset contains 494,414 face images of 10,575 real identities collected from the web.",
            "Benchmarks:  The performance of face recognition models is evaluated on various benchmark datasets: LFW   ( Huang et al. ,  2008 ) , CFP-FP   ( Sengupta et al. ,  2016 ) , CPLFW  ( Zheng and Deng ,  2018 ) , AgeDB  ( Moschoglou et al. ,  2017 )  and CALFW  ( Zheng et al. ,  2017 ) . They are used to measure the impact of different factors on face image, such as pose changes and age variations.",
            "For our ID 3 , we implement the denoising network with a U-net architecture and the projection module with a three-layer perceptron (hidden-layer size  ( 512 , 256 , 768 ) 512 256 768 (512,256,768) ( 512 , 256 , 768 ) ) with ReLU activation. All models are implemented with PyTorch and trained from scratch using 8 NVIDIA Tesla V100 GPUs. Specifically, we set   t  x t = 0.5  ( 1  1 / ( 1 + exp (  t / T ) ) \\lambda_{t}\\kappa_{\\mathbf{x}_{t}}=0.5\\cdot(1-1/(1+\\exp{(-t/T)}) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT = 0.5  ( 1 - 1 / ( 1 + roman_exp ( - italic_t / italic_T ) )  for the loss coefficients in Eq. ( 3 ), and use  T = 1 , 000 T 1 000 T=1,000 italic_T = 1 , 000  for the diffusion model; training batch size is set to  16 16 16 16  and the total training steps  500 , 000 500 000 500,000 500 , 000 . We directly use a pre-trained face recognition (FR) model sourced from pSp  ( Richardson et al. ,  2021 )  as the identity feature extractor. Throughout the entire training process, these pre-trained models are frozen. In addition, we set # of identity embeddings  m = 25 m 25 m=25 italic_m = 25  in Eq. ( 9 ) for each ID and match their embeddings with randomly selected attributes as conditioning signals for the diffusion model. For face recognition, we use LResNet50-IR  ( Deng et al. ,  2019 ) , a variant of ResNet  ( He et al. ,  2016 ) , as the backbone framework and follow the original configurations.",
            "We test the performance of the face recognition model trained on synthetic face data generated by ID 3  and compare against SoTA SFR generative models, including IDiff-Face  ( Boutros et al. ,  2023 ) , ID-Net  ( Kolf et al. ,  2023 ) , DigiFace  ( Bae et al. ,  2023 ) , SFace  ( Boutros et al. ,  2022 ) , SynFace  ( Qiu et al. ,  2021 )  and DCFace  ( Kim et al. ,  2023 ) .",
            "It is worth mentioning that ID 3 , apart from using real data during training, does not introduce any real images as auxiliary data during the sampling phase. The synthetic data is directly used in the training of the face recognition model without undergoing any secondary or manual filtering. Additionally, when training the face recognition model using the synthetic data, no real images are introduced as auxiliary data. On the other hand, DCFace, as described and reported in  ( Kim et al. ,  2023 ) , introduces real face images as auxiliary data during the training phase for face recognition. This helps enhance the diversity of the training data and leads to slightly better results than ID 3  in the two benchmarks.",
            "We further investigate the impact of each contributing component of ID 3  in generating a synthetic face dataset on SFR. This includes three ablation studies shown in Table  2 : the effect of the reversed likelihood score in Eq. ( 8 ) on ID-preserving sampling algorithm (ID 3  vs. ID 3 -w/o-reversed), the effect of using anchors in ID 3  (ID 3  vs. ID 3 -random), and the effect of lower- and upper-bound of Uniform distribution for sampling   i  j subscript  i j \\nu_{ij} italic_ start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT s.",
            "It can be shown that the reversed likelihood  p  ( y , s | x ) p y conditional s x p(\\mathbf{y},\\mathbf{s}|\\mathbf{x}) italic_p ( bold_y , bold_s | bold_x )  is a joint vMF density  ( Xu et al. ,  2023 ;  Hasnat et al. ,  2017 ) :",
            "Note that these reasonable assumptions are applied in  ( Xu et al. ,  2023 ;  Li et al. ,  2021 ;  Hasnat et al. ,  2017 ) . Now we can specify the value of the scalar  C C C italic_C :",
            "We recognize   L 1 subscript L 1 -\\mathcal{L}_{1} - caligraphic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  is the evidence lower bound (ELBO) of  log  p  ( x | y , s ) p conditional x y s \\log p(\\mathbf{x}|\\mathbf{y},\\mathbf{s}) roman_log italic_p ( bold_x | bold_y , bold_s )   ( Luo ,  2022 ) , i.e.",
            "For the original likelihood score, we note that our proposed ID 3  itself is a conditional diffusion model. By virtue of the relation between the score and the denoising module (i.e. the Tweedies Formula) in diffusion models (cf. Equation (133) in  ( Luo ,  2022 ) ), we are able to show that",
            "Face Recognition (FR) is the task of matching query imagery to an enrolled identity database. SoTA FR models are trained using margin-based softmax losses  ( Wang et al. ,  2018 ;  Deng et al. ,  2019 )  on large-scale web-crawled datasets   ( Guo et al. ,  2016 ;  Zhu et al. ,  2021 ) . These datasets encompasses three characteristics in common (as mentioned in the introduction): (i) sufficient inter-class diversity; (ii) intra-class diversity; (iii) intra-class identity preservation. However, due to the introduction of various regulations restricing the use of authentic face data, researchers switch their attention to synthetic face recognition (SFR). We argue that the crux of SFR is to generate a training dataset that inherits the three characteristics above.",
            "GAN-based SFR models.  Most of the deep generative models for synthetic faces generation are based on GANs. DigiFace  ( Bae et al. ,  2023 )  utilizes a digital rendering pipeline to generate synthetic images based on a learned model of facial geometry and attributes. SFace  ( Boutros et al. ,  2022 )  and ID-Net  ( Kolf et al. ,  2023 )  train a StyleGAN-ADA  ( Karras et al. ,  2020 )  under a class-conditional setting. SynFace  ( Qiu et al. ,  2021 )  extends DiscoFaceGAN  ( Deng et al. ,  2020 )  using synthetic identity mix-up to enhance the intra-class diversity. However, the reported results shown by these models show significant performance degradation in comparison to FR trained on real data. This performance gap is mainly due to inter-class discrimination and small intra-class diversity in their generated synthetic training datasets.",
            "Diffusion models for SFR.  Recently, Diffusion Models (DMs)  ( Ho et al. ,  2020 ;  Lin et al. ,  2018 ;  Song et al. ,  2020 )  gained attention for both research and industry due to their potential to rival GANs on image synthesis, as they are easier to train without stability issues, and stem from a solid theoretical foundation. Among SFR diffusion models, IDiff-Face  ( Boutros et al. ,  2023 )  achieves SoTA performance. On the basis of a diffusion model, it incorporates Contextual Partial Dropout to generate diverse intra-class images. However, IDiff-Face fails to regularize the relationship among different identities.",
            "We show the inter-class and intra-class similarity in Figure  A.2 when using  [ 0.5 , 0.7 ] 0.5 0.7 [0.5,0.7] [ 0.5 , 0.7 ]  and  [ 0.7 , 0.9 ] 0.7 0.9 [0.7,0.9] [ 0.7 , 0.9 ]  as the lower- and upper-bound  [ l  b , u  b ] l b u b [lb,ub] [ italic_l italic_b , italic_u italic_b ]  for sampling   i  j subscript  i j \\nu_{ij} italic_ start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT s in our proposed dataset-generating algorithm."
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "S4.T2.26",
        "footnotes": [],
        "references": [
            "With the introduction of various regulations restricting the use of large-scale facial data in recent years, such as GDPR, synthetic-based face recognition (SFR)  ( Boutros et al. ,  2023 )  has received widespread attention from the academic community  ( Qiu et al. ,  2021 ;  Wood et al. ,  2021 ;  Wang et al. ,  2023 ) . The goal of SFR is to generate synthetic face datasets that mimic the distribution of real face images, and use it to train a face recognition (FR) model such that the model can recognize real face images as effectively as possible.",
            "There exist numerous efforts to address SFR, which can be categorized into  GAN -based models and  diffusion  models. GAN-based models utilize adversarial training to learn to generate synthetic data for FR training. Recently, with the empirical advantages of diffusion models over GANs, many works have attempted to use diffusion models to generate synthetic face data in place of authentic data. However, the reported results by these state-of-the-art (SoTA) SFR generative models  ( Bae et al. ,  2023 ;  Boutros et al. ,  2022 ;  Kolf et al. ,  2023 ;  Qiu et al. ,  2021 ;  Boutros et al. ,  2023 )  show significant degradation in the verification accuracy in comparison to FR models trained by authentic data. We deduce the degradation might be due to two reasons. First, while previous works adopt diffusion models, they operate in the original score vector field without injecting the direction with regards to identity information, which makes them unable to guarantee identity-preserving sampling. Second, they fail to consider the structure of face manifold in terms of diversity during sampling.",
            "To this end, in this paper, we propose a novel  ID entity-preserving-yet- D iversified  D iffusion generative model termed  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  and a sampling algorithm for inference. Jointly leveraging identity and face attributes as conditioning signals,  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  can synthesize diversified face images that conform to desired attributes while preserving intra-class identity. Specifically,  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  generates a new sample based upon two conditioning signals: a target face embedding and a specific set of face attributes. The target face embedding enforces identity preservation while face attributes enrich intra-class diversity. To optimize  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT , we propose a new loss function that involves an explicit term to preserve identity. Theoretically, we show that with the addition of this term, minimizing the proposed loss function is equivalent to maximizing the lower bound of the likelihood of an adjusted conditional data log-likelihood. Consequently, this theoretical analysis motivates a new ID-preserving sampling algorithm that generates desired synthetic face images. To generate an SFR dataset, we further propose a new dataset-generating algorithm. This algorithm ensures inter-class diversity by solving the Tammes problem  ( Tammes ,  1930 ) , which maximally separates identity embeddings on the face manifold. In the meantime, it encourages intra-class diversity by perturbing identity embeddings randomly within prescribed areas. It works in conjunction with identity embeddings and diverse attributes to ensure inter-/intra-class diversity while preserving identity. Extensive experiments show that  ID 3 superscript ID 3 \\text{ID}^{3} ID start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  outperforms other existing methods in multiple challenging benchmarks.",
            "Theorem  3.1  provides insights for designing a novel sampling algorithm in the spirit of Langevin dynamics applied on the adjusted conditional likelihood  p ~  ( x t | y , s ) ~ p conditional subscript x t y s \\tilde{p}(\\mathbf{x}_{t}|\\mathbf{y},\\mathbf{s}) over~ start_ARG italic_p end_ARG ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_y , bold_s ) . We note that Langevin dynamics can generate new samples from a probability density  p p p italic_p  by virtue of its score function (i.e., the gradient of the logarithm of the probability density w.r.t. the sample,   x log  p subscript  x p \\nabla_{\\mathbf{x}}{\\log p}  start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT roman_log italic_p ). Motivated by this observation, we aim to find the score function of the adjusted likelihood for sample generation. Specifically, taking the logarithm and the gradient w.r.t.  x x \\mathbf{x} bold_x  on both sides of Eq. ( 6 ) yields",
            "Our proposed dataset-generating algorithm goes as follows: given  N N N italic_N  target identities, we generate  N N N italic_N  anchor embeddings distributed on the sphere:  w 1 , w 2 , ... , w N  S d  1 subscript w 1 subscript w 2 ... subscript w N superscript S d 1 \\mathbf{w}_{1},\\mathbf{w}_{2},...,\\mathbf{w}_{N}\\in\\mathbb{S}^{d-1} bold_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , bold_w start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT  blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT  as uniformly as possible in the sense that each pair of the embeddings are maximally separated on the unit sphere * * * This is known as the Tammes problem  ( Tammes ,  1930 )  for which there exists no exact solution for hypersphere  S d  1 , d > 3 superscript S d 1 d 3 \\mathbb{S}^{d-1},d>3 blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT , italic_d > 3 . However, one can use the optimization technique introduced in  ( Mettes et al. ,  2019 ) . . For each anchor  w i subscript w i \\mathbf{w}_{i} bold_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , we would like to generate  m m m italic_m  identity embeddings perturbed around  w i subscript w i \\mathbf{w}_{i} bold_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  while ensuring that these  m m m italic_m  identity embeddings get close to but different than  w i subscript w i \\mathbf{w}_{i} bold_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Specifically, to find these  m m m italic_m  identity embeddings, we solve the following optimization problem  P i subscript P i \\mathbf{P}_{i} bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT :",
            "After solving Eq. ( 9 ), we are able to retrieve the  m m m italic_m  optimal unnormalized vector  y i  1  , ... , y i  m  superscript subscript y i 1 ... superscript subscript y i m \\mathbf{y}_{i1}^{*},...,\\mathbf{y}_{im}^{*} bold_y start_POSTSUBSCRIPT italic_i 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , ... , bold_y start_POSTSUBSCRIPT italic_i italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT . These  m m m italic_m  vectors are then normalized, yielding  m m m italic_m  identity embeddings:  norm  ( y i  j  ) norm superscript subscript y i j \\operatorname{norm}(\\mathbf{y}_{ij}^{*}) roman_norm ( bold_y start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ) , for  j = 1 , ... , m j 1 ... m j=1,...,m italic_j = 1 , ... , italic_m . Then, the resulting identity embeddings, along with face attributes, are fed into our generative models to generate face images. Finally, the entire dataset is generated by solving each  P i , i = 1 , ... , N formulae-sequence subscript P i i 1 ... N \\mathbf{P}_{i},i=1,...,N bold_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_i = 1 , ... , italic_N , which yields  N N N italic_N  identities, each with  m m m italic_m  face images. The entire algorithm is summarized in Algorithm  3 .",
            "We train our proposed ID 3  on FFHQ  ( Karras et al. ,  2019 )  dataset. The FFHQ (FaceForensics++) dataset is a large-scale dataset used for benchmarking and evaluating the performance of deep learning models in the field of face forensics. It is an extension of the original FaceForensics dataset, which was designed to facilitate the development and comparison of methods for detecting and preventing face manipulation and deepfakes. In order to compare with DCFace  ( Kim et al. ,  2023 ) , we also train ID 3  on CASIA-WebFace  ( Yi et al. ,  2014 ) . The CASIA-WebFace dataset is used for face verification and face recognition tasks. This dataset contains 494,414 face images of 10,575 real identities collected from the web.",
            "For our ID 3 , we implement the denoising network with a U-net architecture and the projection module with a three-layer perceptron (hidden-layer size  ( 512 , 256 , 768 ) 512 256 768 (512,256,768) ( 512 , 256 , 768 ) ) with ReLU activation. All models are implemented with PyTorch and trained from scratch using 8 NVIDIA Tesla V100 GPUs. Specifically, we set   t  x t = 0.5  ( 1  1 / ( 1 + exp (  t / T ) ) \\lambda_{t}\\kappa_{\\mathbf{x}_{t}}=0.5\\cdot(1-1/(1+\\exp{(-t/T)}) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT = 0.5  ( 1 - 1 / ( 1 + roman_exp ( - italic_t / italic_T ) )  for the loss coefficients in Eq. ( 3 ), and use  T = 1 , 000 T 1 000 T=1,000 italic_T = 1 , 000  for the diffusion model; training batch size is set to  16 16 16 16  and the total training steps  500 , 000 500 000 500,000 500 , 000 . We directly use a pre-trained face recognition (FR) model sourced from pSp  ( Richardson et al. ,  2021 )  as the identity feature extractor. Throughout the entire training process, these pre-trained models are frozen. In addition, we set # of identity embeddings  m = 25 m 25 m=25 italic_m = 25  in Eq. ( 9 ) for each ID and match their embeddings with randomly selected attributes as conditioning signals for the diffusion model. For face recognition, we use LResNet50-IR  ( Deng et al. ,  2019 ) , a variant of ResNet  ( He et al. ,  2016 ) , as the backbone framework and follow the original configurations.",
            "We test the performance of the face recognition model trained on synthetic face data generated by ID 3  and compare against SoTA SFR generative models, including IDiff-Face  ( Boutros et al. ,  2023 ) , ID-Net  ( Kolf et al. ,  2023 ) , DigiFace  ( Bae et al. ,  2023 ) , SFace  ( Boutros et al. ,  2022 ) , SynFace  ( Qiu et al. ,  2021 )  and DCFace  ( Kim et al. ,  2023 ) .",
            "Here, we illustrate a collection of face images generated by ID 3  as qualitative evaluation. Figure  3  shows the results for randomly sampled identities (IDs) under various attribute conditions; Obviously, when comparing different identities (inter-class), the essential intrinsic key information of each identity is still retained and can be easily identified. Also, different samples of each identity (intra-class) exhibit distinct diversity, stemming from variations in similarity scores (  i  j subscript  i j \\nu_{ij} italic_ start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT s) and differences in face attributes as conditioning signals. In terms of the effect of our proposed adjusted score and the original score on the sampling algorithm, we observe that the face images generated by our proposed ID 3  exhibits much better quality and identity preservation than those generated by the original score function, as shown in Figure 2.",
            "It is worth mentioning that ID 3 , apart from using real data during training, does not introduce any real images as auxiliary data during the sampling phase. The synthetic data is directly used in the training of the face recognition model without undergoing any secondary or manual filtering. Additionally, when training the face recognition model using the synthetic data, no real images are introduced as auxiliary data. On the other hand, DCFace, as described and reported in  ( Kim et al. ,  2023 ) , introduces real face images as auxiliary data during the training phase for face recognition. This helps enhance the diversity of the training data and leads to slightly better results than ID 3  in the two benchmarks.",
            "In the first study, we compare ID 3  with ID 3 -w/o-reversed, which removes the reversed likelihood score from Eq. ( 8 ) in the proposed ID-preserving sampling algorithm. We observed ID 3  consistently outperforms ID 3 -w/o-reversed with large margins. This suggests the necessity of the inner-product term in the proposed loss function Eq. ( 3 ) and the reversed likelihood score in the adjusted likelihood score Eq. ( 8 ).",
            "In the second study (cf. Appendix E), an appropriate smaller value of  l  b l b lb italic_l italic_b , if not exceeding a certain range, can increase the intra-class diversity, resulting in more diverse intra-class face images. This aligns with our objective of increasing intra-class diversity in the generated data to enhance the effectiveness of SFR. As per the constraints of Eq. ( 9 ), each generated identity embedding  y i  j subscript y i j \\mathbf{y}_{ij} bold_y start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT  maintains the same identity as the anchor  w i subscript w i \\mathbf{w}_{i} bold_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . This, along with our proposed inner-product term in Eq. ( 3 ), ensures consistent intra-class identities while introducing a significant amount of diversity.",
            "It can be shown that the reversed likelihood  p  ( y , s | x ) p y conditional s x p(\\mathbf{y},\\mathbf{s}|\\mathbf{x}) italic_p ( bold_y , bold_s | bold_x )  is a joint vMF density  ( Xu et al. ,  2023 ;  Hasnat et al. ,  2017 ) :",
            "Note that these reasonable assumptions are applied in  ( Xu et al. ,  2023 ;  Li et al. ,  2021 ;  Hasnat et al. ,  2017 ) . Now we can specify the value of the scalar  C C C italic_C :",
            "GAN-based SFR models.  Most of the deep generative models for synthetic faces generation are based on GANs. DigiFace  ( Bae et al. ,  2023 )  utilizes a digital rendering pipeline to generate synthetic images based on a learned model of facial geometry and attributes. SFace  ( Boutros et al. ,  2022 )  and ID-Net  ( Kolf et al. ,  2023 )  train a StyleGAN-ADA  ( Karras et al. ,  2020 )  under a class-conditional setting. SynFace  ( Qiu et al. ,  2021 )  extends DiscoFaceGAN  ( Deng et al. ,  2020 )  using synthetic identity mix-up to enhance the intra-class diversity. However, the reported results shown by these models show significant performance degradation in comparison to FR trained on real data. This performance gap is mainly due to inter-class discrimination and small intra-class diversity in their generated synthetic training datasets.",
            "Diffusion models for SFR.  Recently, Diffusion Models (DMs)  ( Ho et al. ,  2020 ;  Lin et al. ,  2018 ;  Song et al. ,  2020 )  gained attention for both research and industry due to their potential to rival GANs on image synthesis, as they are easier to train without stability issues, and stem from a solid theoretical foundation. Among SFR diffusion models, IDiff-Face  ( Boutros et al. ,  2023 )  achieves SoTA performance. On the basis of a diffusion model, it incorporates Contextual Partial Dropout to generate diverse intra-class images. However, IDiff-Face fails to regularize the relationship among different identities."
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "A5.EGx2",
        "footnotes": [],
        "references": [
            "We train our proposed ID 3  on FFHQ  ( Karras et al. ,  2019 )  dataset. The FFHQ (FaceForensics++) dataset is a large-scale dataset used for benchmarking and evaluating the performance of deep learning models in the field of face forensics. It is an extension of the original FaceForensics dataset, which was designed to facilitate the development and comparison of methods for detecting and preventing face manipulation and deepfakes. In order to compare with DCFace  ( Kim et al. ,  2023 ) , we also train ID 3  on CASIA-WebFace  ( Yi et al. ,  2014 ) . The CASIA-WebFace dataset is used for face verification and face recognition tasks. This dataset contains 494,414 face images of 10,575 real identities collected from the web.",
            "is a proper probability density function of  a a a italic_a  with  b = b 0 b subscript b 0 b=b_{0} italic_b = italic_b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  given. Therefore, Eq. ( A.4 ) can be written as  p ~  ( a | b = b 0 ) ~ p conditional a b subscript b 0 \\tilde{p}(a|b=b_{0}) over~ start_ARG italic_p end_ARG ( italic_a | italic_b = italic_b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) . The above proof holds true for any  b 0 subscript b 0 b_{0} italic_b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , which concludes the proof for  p ~  ( a | b )  p  ( a | b )  p  ( b | a ) w , w > 0 formulae-sequence proportional-to ~ p conditional a b  p conditional a b p superscript conditional b a w w 0 \\tilde{p}(a|b)\\propto p(a|b)\\cdot p(b|a)^{w},w>0 over~ start_ARG italic_p end_ARG ( italic_a | italic_b )  italic_p ( italic_a | italic_b )  italic_p ( italic_b | italic_a ) start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT , italic_w > 0 . Note that this result can be trivially extended to multivariate random variables."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "A1.E16",
        "footnotes": [],
        "references": []
    },
    "id_table_6": {
        "caption": "",
        "table": "A1.E17",
        "footnotes": [],
        "references": [
            "Theorem  3.1  provides insights for designing a novel sampling algorithm in the spirit of Langevin dynamics applied on the adjusted conditional likelihood  p ~  ( x t | y , s ) ~ p conditional subscript x t y s \\tilde{p}(\\mathbf{x}_{t}|\\mathbf{y},\\mathbf{s}) over~ start_ARG italic_p end_ARG ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_y , bold_s ) . We note that Langevin dynamics can generate new samples from a probability density  p p p italic_p  by virtue of its score function (i.e., the gradient of the logarithm of the probability density w.r.t. the sample,   x log  p subscript  x p \\nabla_{\\mathbf{x}}{\\log p}  start_POSTSUBSCRIPT bold_x end_POSTSUBSCRIPT roman_log italic_p ). Motivated by this observation, we aim to find the score function of the adjusted likelihood for sample generation. Specifically, taking the logarithm and the gradient w.r.t.  x x \\mathbf{x} bold_x  on both sides of Eq. ( 6 ) yields",
            "Benchmarks:  The performance of face recognition models is evaluated on various benchmark datasets: LFW   ( Huang et al. ,  2008 ) , CFP-FP   ( Sengupta et al. ,  2016 ) , CPLFW  ( Zheng and Deng ,  2018 ) , AgeDB  ( Moschoglou et al. ,  2017 )  and CALFW  ( Zheng et al. ,  2017 ) . They are used to measure the impact of different factors on face image, such as pose changes and age variations.",
            "For our ID 3 , we implement the denoising network with a U-net architecture and the projection module with a three-layer perceptron (hidden-layer size  ( 512 , 256 , 768 ) 512 256 768 (512,256,768) ( 512 , 256 , 768 ) ) with ReLU activation. All models are implemented with PyTorch and trained from scratch using 8 NVIDIA Tesla V100 GPUs. Specifically, we set   t  x t = 0.5  ( 1  1 / ( 1 + exp (  t / T ) ) \\lambda_{t}\\kappa_{\\mathbf{x}_{t}}=0.5\\cdot(1-1/(1+\\exp{(-t/T)}) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT = 0.5  ( 1 - 1 / ( 1 + roman_exp ( - italic_t / italic_T ) )  for the loss coefficients in Eq. ( 3 ), and use  T = 1 , 000 T 1 000 T=1,000 italic_T = 1 , 000  for the diffusion model; training batch size is set to  16 16 16 16  and the total training steps  500 , 000 500 000 500,000 500 , 000 . We directly use a pre-trained face recognition (FR) model sourced from pSp  ( Richardson et al. ,  2021 )  as the identity feature extractor. Throughout the entire training process, these pre-trained models are frozen. In addition, we set # of identity embeddings  m = 25 m 25 m=25 italic_m = 25  in Eq. ( 9 ) for each ID and match their embeddings with randomly selected attributes as conditioning signals for the diffusion model. For face recognition, we use LResNet50-IR  ( Deng et al. ,  2019 ) , a variant of ResNet  ( He et al. ,  2016 ) , as the backbone framework and follow the original configurations.",
            "Face Recognition (FR) is the task of matching query imagery to an enrolled identity database. SoTA FR models are trained using margin-based softmax losses  ( Wang et al. ,  2018 ;  Deng et al. ,  2019 )  on large-scale web-crawled datasets   ( Guo et al. ,  2016 ;  Zhu et al. ,  2021 ) . These datasets encompasses three characteristics in common (as mentioned in the introduction): (i) sufficient inter-class diversity; (ii) intra-class diversity; (iii) intra-class identity preservation. However, due to the introduction of various regulations restricing the use of authentic face data, researchers switch their attention to synthetic face recognition (SFR). We argue that the crux of SFR is to generate a training dataset that inherits the three characteristics above."
        ]
    }
}