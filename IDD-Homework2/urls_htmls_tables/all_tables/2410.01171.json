{
    "id_table_1": {
        "caption": "Table 1:  Statistics for the  BordIRlines  dataset. The first two rows are over the territories, while the others are over the articles.",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": [
            "We formalize the task of cross-lingual retrieval-augmented generation ( xlRAG ) which focuses on retrieving balanced information from diverse sources to answer queries that refer to topics of mutual interest across multiple languages and cultures. This is depicted in Figure  1 .",
            "We classify  xlRAG  into two settings.  Bilingual  xlRAG  has passages are in one language while the query is in another. A practical example is a user speaking a lower-resource language who wants their system to access information from a higher-resource one; i.e. from English Wikipedia.  Multilingual  xlRAG  allows the passages and queries to be in any language. Its primary use-case is to include information from  sources of various languages and cultural backgrounds, and see how LLMs reconcile the often-conflicting viewpoints within them. Figure  1  compares setups of RAG and Multilingual  xlRAG .",
            "Table  1  provides aggregated statistics on the  BordIRlines  dataset. A given territory corresponds to 3.11 queries on average, and to 8.46 articles on average. 2 2 2 For intuitions on these averages, consider the typical case of a territory with 2 claimants. It will have 3 queries in languages {en, l1, l2}, and there will be 9 articles (3*3). The averages are close to this typical case.    We see that en articles are on average, 34% longer than non-en articles by characters, and 51% by words."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Statistics for the relevant documents from the  BordIRlines  dataset. For each language, we report the retrieved number of Wikipedia pages, and the resulting number of passages.",
        "table": "A1.T2.1",
        "footnotes": [],
        "references": [
            "Appendix Table  2  depicts the per-language statistics for Wikipedia articles. English is most represented by design, as we include English articles for every territory and country. Also well-represented are Traditional Chinese, Arabic, Simplified Chinese, and Spanish, as those languages countries are involved with the most territorial disputes.",
            "We performed a information retrieval process to collect the relevant passages.  Figure  2  shows an example entry from the  BordIRlines  dataset, and an overview of the process used to obtain the set of relevant passages. On the first column, we will have a  BorderLines  entry, which consists of a  territory , its  claimant countries , and  queries  written in the language of each claimant. Columns 2 and 3 show the already-described process of considering the query-specific and language-specific Wikipedia articles for a query. On the 4th column are the top-k most  relevant passages  to the query, as retrieved by an IR system.",
            "Figure  2  gives per-language statistics for  BordIRlines  passages."
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "A1.T2.1.3.2.2.1",
        "footnotes": [],
        "references": [
            "To take a closer look at IR performance of this system, we consider a case study. The Falkland Islands have been the subject of long-standing sovereignty disputes. Figure  3  shows the three high-scoring passages over English Wikipedia articles, their scores, and our manual annotation of the passages viewpoint. We see that all passages are relevant, and in terms of viewpoint, 2 of 3 articles support UKs claim, while 1 is mixed."
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "A1.T2.1.5.4.2.1",
        "footnotes": [],
        "references": [
            "In the  xlRAG  setting, the language of the query, and each passage, can be varied, resulting in many possible degrees-of-freedom (DoF). Therefore, we systematically organize the experiments, such that each setting affects a specific DoF that we can base insights from. Figure  4  illustrates the 6 experimental settings we study, and assigns them numbers 0, I, II, III, IV, and V."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "A1.T2.1.19.18.6.1",
        "footnotes": [],
        "references": [
            "Figure  5  shows the queries and passages used for the case study on  xlRAG  results, on Crimea."
        ]
    },
    "global_footnotes": [
        "For intuitions on these averages, consider the typical case of a territory with 2 claimants. It will have 3 queries in languages {en, l1, l2}, and there will be 9 articles (3*3). The averages are close to this typical case.",
        ",",
        "In this work, we use",
        "for simplicity.",
        "As a simple, English-only experiment, we tried including a false fact the Spratly Islands were annexed by",
        "following a 2024 international decree. For all 6 countries, the response accordingly switched to that country."
    ]
}