{
    "id_table_1": {
        "caption": "Table 1:  Results for predicting unseen environment responses given a goal and tactic, for transitions from miniF2F-valid. The  No Tactic  result forms a baseline to assess the impact of the tactic representation. We observe that any tactic representation enables far better predictions, and constraining these to a single vector ( Combined  and  Separate ) does not hurt the performance gain. This demonstrates tactic representations which capture their effect on the environment, enabling our filtering model in Section  3 . Comparing the  Combined  and  Separate  models, allowing the representation to attend to the goal leads to a large improvement.",
        "table": "S2.T1.1",
        "footnotes": [
            ""
        ],
        "references": [
            "Many of the generated tactics are equivalent, modulo variable renaming and other semantics-preserving transformations. See Figure  1  for a sample search tree from the ReProver  (Yang et al.,  2023 )  system, where several semantically similar paths are explored, wasting valuable resources. Simple lexical similarity scores fail to cover the semantics (meaning) of a tactic, as captured by the effect of the tactic on the environment. For example, an expression and its negation vary by only a single character, but have a large semantic difference. It is therefore desirable to filter tactics by their semantic rather than syntactic diversity. In addition, many tactics lead to an execution error from the prover. From our experiments with miniF2F, we find approximately 75% of tactics result in an execution error (Section  2.2 ). With the execution of tactics in the environment being expensive, this further restricts the space of proofs which can be explored efficiently.",
            "We assume a dataset  D D \\mathcal{D} caligraphic_D  of transition tuples  { ( g k , t k  i , s k  i ,  k  i , o k  i ) } subscript g k subscript t k i subscript s k i subscript  k i subscript o k i \\{(g_{k},t_{ki},s_{ki},\\tau_{ki},o_{ki})\\} { ( italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ) } , as defined in  1.2 . We learn a  transition model    : S  T  { 0 , 1 }  R  O :   S T 0 1 R O \\xi:\\mathcal{S}\\times\\mathcal{T}\\to\\{0,1\\}\\times\\mathbb{R}\\times\\mathcal{O} italic_ : caligraphic_S  caligraphic_T  { 0 , 1 }  blackboard_R  caligraphic_O  which maps a goal  g k subscript g k g_{k} italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT  and tactic  t k  i subscript t k i t_{ki} italic_t start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT  to an estimate of the status  s k  i subscript s k i s_{ki} italic_s start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , time   k  i subscript  k i \\tau_{ki} italic_ start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT  and output  o k  i subscript o k i o_{ki} italic_o start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT . We construct our transition model    \\xi italic_  with three components. For  d  N d N d\\in\\mathbb{N} italic_d  blackboard_N , the Encoder  E : S  T  R d : E  S T superscript R d E:{\\mathcal{S}}\\times{\\mathcal{T}}\\to{\\mathbb{R}}^{d} italic_E : caligraphic_S  caligraphic_T  blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT  takes the goal  g k subscript g k g_{k} italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT  and tactic  t k  i subscript t k i t_{ki} italic_t start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT  as input, and outputs a single embedding vector with unit norm,  E  ( g k , t k  i ) = e k  i E subscript g k subscript t k i subscript e k i E(g_{k},t_{ki})={\\bm{e}}_{ki} italic_E ( italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ) = bold_italic_e start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ,   e k  i  = 1 norm subscript e k i 1 ||{\\bm{e}}_{ki}||=1 | | bold_italic_e start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT | | = 1 . The Predictor  P : R d  [ 0 , 1 ]  R : P  superscript R d 0 1 R P:{\\mathbb{R}}^{d}\\to[0,1]\\times{\\mathbb{R}} italic_P : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT  [ 0 , 1 ]  blackboard_R  maps this embedding to a score for the time prediction and an error probability for the status, with  P  ( e k  i ) = ( s ^ k  i ,  ^ k  i ) P subscript e k i subscript ^ s k i subscript ^  k i P({\\bm{e}}_{ki})=(\\hat{s}_{ki},\\hat{\\tau}_{ki}) italic_P ( bold_italic_e start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ) = ( over^ start_ARG italic_s end_ARG start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ) . The Decoder  D : R d  S  O : D  superscript R d S O D:{\\mathbb{R}}^{d}\\times{\\mathcal{S}}\\to{\\mathcal{O}} italic_D : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT  caligraphic_S  caligraphic_O  maps the embedding and goal to the output prediction, such that  D  ( e k  i , g k ) = o ^ k  i D subscript e k i subscript g k subscript ^ o k i D({\\bm{e}}_{ki},g_{k})=\\hat{o}_{ki} italic_D ( bold_italic_e start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) = over^ start_ARG italic_o end_ARG start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT . The transition model is then",
            "We obtain the dataset  D D {\\mathcal{D}} caligraphic_D  from a vanilla ReProver attempt on miniF2F-valid, which results in 498,236 transitions, which we split randomly into 95% training, 5% testing. There is the possibility of dependence between the splits, as the test set includes goals seen in training with different tactics. The  No Tactic  baseline should capture any of this, with our results in Section  3.3.1  showing our representations generalise from miniF2F-valid to miniF2F-test. For the error prediction task, we reweight classes to account for imbalance, which is approximately 75% error, 25% success. We use the AdamW optimizer, with a learning rate of  10  5 superscript 10 5 10^{-5} 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT  and a batch size of 1. We train each model for 2 epochs on a single RTX4090, and report the results on the test set.",
            "Table  1  summarises the performance of our transition models on the test set. Our results suggest tactic representations which capture useful information about their effect on the environment, which we can see by the clear improvement across all approaches compared to the  No Tactic  baseline. The higher scores across all metrics of the  Combined  versus the  Separate  model support our hypothesis that we can better predict transitions when the tactic embedding attends to the goal. The  All Tokens  model, where we allow the Decoder to attend to the full tactic, does not increase performance in comparison to the  Combined  model. This shows that we can effectively represent the tactic as a single embedding without any loss of information. Our results demonstrate the feasibility of learning the environment dynamics of proving systems, which is a difficult task. To illustrate this, we include all prediction examples for the  Combined  model, along with their ground truth, in the supplementary material.",
            "Algorithm  1  defines our filtering model, 3D-Prover, which maps a list of tactics  T T T italic_T  from the underlying tactic policy   0 subscript  0 \\pi_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  to a subset  T  superscript T  T^{\\prime} italic_T start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  of size  K K K italic_K . We use the Encoder  E E E italic_E  and Predictor  P P P italic_P  defined in Section  1.2  to generate unit norm tactic embeddings   i subscript bold-italic- i \\bm{\\phi}_{i} bold_italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and predict the time and error likelihood. The embeddings   i subscript bold-italic- i \\bm{\\phi}_{i} bold_italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  encode the predicted environment response through their direction only, as they are unit norm (Figure  3 ). The quality scores  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  then scale these tactics based on the underlying model logits  m i subscript m i m_{i} italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , as well as the predicted error likelihood  s i subscript s i s_{i} italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and execution time   i subscript  i \\tau_{i} italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . We have hyperparameters for the normalisation temperature    \\theta italic_ , as well as the error and time weights   s ,   subscript  s subscript   \\lambda_{s},\\lambda_{\\tau} italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT . The parameter    \\theta italic_  controls the scaling temperature of the model logits, with a higher temperature flattening out the distribution. It therefore adjusts the diversity bias of the filtering model by reducing the impact of the quality scores when sampling. We then compute the kernel  L L L italic_L  from  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and   i subscript bold-italic- i \\bm{\\phi}_{i} bold_italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , and sample a subset of tactics  T  superscript T  T^{\\prime} italic_T start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  using the  k k k italic_k -DPP algorithm  (Kulesza & Taskar,  2011 ) .",
            "To test the performance of 3D-Prover, we use ReProver  (Yang et al.,  2023 )  as the underlying tactic policy   0 subscript  0 \\pi_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , with the Encoder  E E E italic_E  and Predictor  P P P italic_P  components as defined in Section  1.2 . We chose ReProver as it is a small (  similar-to \\sim   300M parameters), popular and performant open source model, allowing us to run our experiments in a reasonable timeframe. We run our experiments in Lean 3  (De Moura et al.,  2015 )  using the BAIT  (Lamont et al.,  2024 )  platform with a modified LeanDojo  (Yang et al.,  2023 )  environment, where we set an environment timeout of 600 seconds per proof attempt. We train a combined transition model on the miniF2F-valid benchmark, and use the Encoder and Predictor components to generate tactic embeddings and quality scores as per Algorithm  1 . We first examine the performance of 3D-Prover without any hyperparameter tuning, setting   s =   = 0 subscript  s subscript   0 \\lambda_{s}=\\lambda_{\\tau}=0 italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT = 0 ,   = 1  1 \\theta=1 italic_ = 1 . We then perform ablation studies using miniF2F-valid to examine the influence of the hyperparameters on the tactic success rate, execution time and diversity of the environment response. For miniF2F-test, we allow the model four attempts per proof to increase confidence in the results, while for miniF2F-valid we allow one attempt per configuration to facilitate a wider set of ablations.",
            "We set the search policy for all experiments to be Best First Search (BestFS), where nodes are expanded in order of their cumulative log probability. For each node selected for expansion, we generate  N = 64 N 64 N=64 italic_N = 64  candidate tactics from the underlying ReProver model using beam search with default settings, as done in the original ReProver implementation. This forms the ground set for the node, to be sub-sampled by the filtering algorithm. We use beam search decoding because it is deterministic and so ensures that the ground set for a given node remains fixed across runs, allowing us to isolate and compare the effect of the filtering algorithm. The filtering algorithm returns  K K K italic_K  tactics, which are then executed in the environment and used to update the proof tree, as outlined in  1.2 . We test three different levels of filtering, with  K  { 8 , 16 , 32 } K 8 16 32 K\\in\\{8,16,32\\} italic_K  { 8 , 16 , 32 } . Lower values of  K K K italic_K  correspond to more filtering, for which the choice of filtering algorithm will have a greater impact. We compare the filtering approach of 3D-Prover, as outlined in Algorithm  1 , with two baselines. The  Top- K K \\mathbf{K} bold_K  baseline takes the top  K K K italic_K  tactics from the ground set as judged by their log probabilities, corresponding to the top  K K K italic_K  beams. We take  K K K italic_K  tactics at random from the ground set to form the  Random  baseline, as an exploration-focused comparison.",
            "Table   2  shows the Pass@1 results of our experiments on miniF2F, which is the number of proofs successfully found after a single attempt. We observe that 3D-Prover significantly outperforms both baseline approaches. We also note that Top- K K K italic_K  selection performs better than the Random approach, which is unsurprising. The influence of the filtering algorithm becomes more apparent as  K K K italic_K  is decreased, as there are more tactics filtered out. Our results are consistent with this, with the magnitude of improvement given by 3D-Prover increasing for lower values of  K K K italic_K . 3D-Prover is able to outperform both baselines by providing a tradeoff between the quality, as represented by Top- K K K italic_K , and the diversity of the tactics. The choice of  K K K italic_K  also controls the depth of the proof search, with larger  K K K italic_K  giving broader search, and smaller  K K K italic_K  deeper search. As most discovered proofs are short (favouring broad search), the Pass@1 performance for lower values of  K K K italic_K  is generally lower, however over multiple attempts it can be beneficial to use deeper searches (see Appendix  A.1 ). Finding deep proofs has to date been a significant challenge (  e.g.   Polu et al. ( 2022 ) ), with the search tree growing exponentially with the proof depth. The improvement given by 3D-Prover, particularly for deeper search configurations, is a step towards addressing this.",
            "As outlined in Section  2 , we train our embeddings to be reflective of the tactic semantics across all three components of Status, Time and Output. Hence 3D-Prover, which selects diverse embeddings, may lead to tactics predicted to have errors, where the errors are diverse in terms of their predicted message. The hyperparameter   s subscript  s \\lambda_{s} italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT  can alleviate this by weighting the scores based on their likelihood of success. From our experiments (Table  9 ), there is not necessarily a benefit to Pass@1 by filtering out strongly based on the predicted error likelihood. To speculate, the error prediction, although quite good, is imperfect with many false negatives (Table  1 ). This can lead to potentially useful tactics being ignored if the error prediction is overly trusted, even though there is a higher tactic success rate overall as in Table  4 . Given these prediction errors, it may be the case that selecting goals which are predicted to lead to (diverse) errors may be preferable, given the possibility they result in successful new subgoals. These subgoals may be be quite different from those previously selected, as they are mispredicted, so are clearly outside the space of tactics where the transition model is confident about the outcome. Further analysis could be worthwhile to investigate this. An embedding architecture trained only on successful tactics could be used, however given the high error rate of tactics, this would ignore a large proportion of the transition data."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Percentage of proofs found after one attempt (Pass@1) on miniF2F, with  K K K italic_K  tactics selected per node, using tactics generated from ReProver. 3D-Prover uses a transition model trained from miniF2F-valid transitions. For miniF2F-test, we report the mean   plus-or-minus \\pm   standard error over four runs, with Top- K K K italic_K  being deterministic. The Gain column reports the relative improvement over the Top- K K K italic_K  baseline. We observe a clear improvement using 3D-Prover, which increases as more filtering is applied (lower  K K K italic_K ). Our results on miniF2F-test show that 3D-Prover can improve search even for proofs out of distribution of the transition model.",
        "table": "S3.T2.9",
        "footnotes": [],
        "references": [
            "Many of the generated tactics are equivalent, modulo variable renaming and other semantics-preserving transformations. See Figure  1  for a sample search tree from the ReProver  (Yang et al.,  2023 )  system, where several semantically similar paths are explored, wasting valuable resources. Simple lexical similarity scores fail to cover the semantics (meaning) of a tactic, as captured by the effect of the tactic on the environment. For example, an expression and its negation vary by only a single character, but have a large semantic difference. It is therefore desirable to filter tactics by their semantic rather than syntactic diversity. In addition, many tactics lead to an execution error from the prover. From our experiments with miniF2F, we find approximately 75% of tactics result in an execution error (Section  2.2 ). With the execution of tactics in the environment being expensive, this further restricts the space of proofs which can be explored efficiently.",
            "We assume a dataset  D D \\mathcal{D} caligraphic_D  of transition tuples  { ( g k , t k  i , s k  i ,  k  i , o k  i ) } subscript g k subscript t k i subscript s k i subscript  k i subscript o k i \\{(g_{k},t_{ki},s_{ki},\\tau_{ki},o_{ki})\\} { ( italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ) } , as defined in  1.2 . We learn a  transition model    : S  T  { 0 , 1 }  R  O :   S T 0 1 R O \\xi:\\mathcal{S}\\times\\mathcal{T}\\to\\{0,1\\}\\times\\mathbb{R}\\times\\mathcal{O} italic_ : caligraphic_S  caligraphic_T  { 0 , 1 }  blackboard_R  caligraphic_O  which maps a goal  g k subscript g k g_{k} italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT  and tactic  t k  i subscript t k i t_{ki} italic_t start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT  to an estimate of the status  s k  i subscript s k i s_{ki} italic_s start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , time   k  i subscript  k i \\tau_{ki} italic_ start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT  and output  o k  i subscript o k i o_{ki} italic_o start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT . We construct our transition model    \\xi italic_  with three components. For  d  N d N d\\in\\mathbb{N} italic_d  blackboard_N , the Encoder  E : S  T  R d : E  S T superscript R d E:{\\mathcal{S}}\\times{\\mathcal{T}}\\to{\\mathbb{R}}^{d} italic_E : caligraphic_S  caligraphic_T  blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT  takes the goal  g k subscript g k g_{k} italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT  and tactic  t k  i subscript t k i t_{ki} italic_t start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT  as input, and outputs a single embedding vector with unit norm,  E  ( g k , t k  i ) = e k  i E subscript g k subscript t k i subscript e k i E(g_{k},t_{ki})={\\bm{e}}_{ki} italic_E ( italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ) = bold_italic_e start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ,   e k  i  = 1 norm subscript e k i 1 ||{\\bm{e}}_{ki}||=1 | | bold_italic_e start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT | | = 1 . The Predictor  P : R d  [ 0 , 1 ]  R : P  superscript R d 0 1 R P:{\\mathbb{R}}^{d}\\to[0,1]\\times{\\mathbb{R}} italic_P : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT  [ 0 , 1 ]  blackboard_R  maps this embedding to a score for the time prediction and an error probability for the status, with  P  ( e k  i ) = ( s ^ k  i ,  ^ k  i ) P subscript e k i subscript ^ s k i subscript ^  k i P({\\bm{e}}_{ki})=(\\hat{s}_{ki},\\hat{\\tau}_{ki}) italic_P ( bold_italic_e start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ) = ( over^ start_ARG italic_s end_ARG start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ) . The Decoder  D : R d  S  O : D  superscript R d S O D:{\\mathbb{R}}^{d}\\times{\\mathcal{S}}\\to{\\mathcal{O}} italic_D : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT  caligraphic_S  caligraphic_O  maps the embedding and goal to the output prediction, such that  D  ( e k  i , g k ) = o ^ k  i D subscript e k i subscript g k subscript ^ o k i D({\\bm{e}}_{ki},g_{k})=\\hat{o}_{ki} italic_D ( bold_italic_e start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) = over^ start_ARG italic_o end_ARG start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT . The transition model is then",
            "We investigate four instances of the transition model    \\xi italic_ . For the  Combined  model (Figure   2 ), the tactic is concatenated with the goal, and the embeddings from the Encoder are computed for all tokens. We then generate a single tactic embedding by mean-pooling over the tactic tokens. We compare this with the  Separate  model which encodes the tactic without attending to the goal. We hypothesise that allowing the tactic tokens to attend to the goal will allow the Encoder to better represent the semantics of the tactic. To form a naive baseline, we implement a  No Tactic  model which does not use the tactic at all, and instead uses only the goal tokens. We do this to account for any inherent patterns in the goal which may be predictive of the outcome, for example a particular goal which has a high error rate. This allows us to ground our results in the performance of this baseline, so we can observe the direct effect of the tactic in predictive performance. We also compare with an  All Tokens  model which uses all tactic tokens for the Decoder without reducing to a single embedding. We maintain the pooling operation over the tactic tokens for the status and time prediction tasks, but allow the Decoder to attend to all tokens for the output prediction. We implement this comparison to see the degree of information loss induced by reducing tactics to a single vector.",
            "Algorithm  1  defines our filtering model, 3D-Prover, which maps a list of tactics  T T T italic_T  from the underlying tactic policy   0 subscript  0 \\pi_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  to a subset  T  superscript T  T^{\\prime} italic_T start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  of size  K K K italic_K . We use the Encoder  E E E italic_E  and Predictor  P P P italic_P  defined in Section  1.2  to generate unit norm tactic embeddings   i subscript bold-italic- i \\bm{\\phi}_{i} bold_italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and predict the time and error likelihood. The embeddings   i subscript bold-italic- i \\bm{\\phi}_{i} bold_italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  encode the predicted environment response through their direction only, as they are unit norm (Figure  3 ). The quality scores  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  then scale these tactics based on the underlying model logits  m i subscript m i m_{i} italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , as well as the predicted error likelihood  s i subscript s i s_{i} italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and execution time   i subscript  i \\tau_{i} italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . We have hyperparameters for the normalisation temperature    \\theta italic_ , as well as the error and time weights   s ,   subscript  s subscript   \\lambda_{s},\\lambda_{\\tau} italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT . The parameter    \\theta italic_  controls the scaling temperature of the model logits, with a higher temperature flattening out the distribution. It therefore adjusts the diversity bias of the filtering model by reducing the impact of the quality scores when sampling. We then compute the kernel  L L L italic_L  from  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and   i subscript bold-italic- i \\bm{\\phi}_{i} bold_italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , and sample a subset of tactics  T  superscript T  T^{\\prime} italic_T start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  using the  k k k italic_k -DPP algorithm  (Kulesza & Taskar,  2011 ) .",
            "To test the performance of 3D-Prover, we use ReProver  (Yang et al.,  2023 )  as the underlying tactic policy   0 subscript  0 \\pi_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , with the Encoder  E E E italic_E  and Predictor  P P P italic_P  components as defined in Section  1.2 . We chose ReProver as it is a small (  similar-to \\sim   300M parameters), popular and performant open source model, allowing us to run our experiments in a reasonable timeframe. We run our experiments in Lean 3  (De Moura et al.,  2015 )  using the BAIT  (Lamont et al.,  2024 )  platform with a modified LeanDojo  (Yang et al.,  2023 )  environment, where we set an environment timeout of 600 seconds per proof attempt. We train a combined transition model on the miniF2F-valid benchmark, and use the Encoder and Predictor components to generate tactic embeddings and quality scores as per Algorithm  1 . We first examine the performance of 3D-Prover without any hyperparameter tuning, setting   s =   = 0 subscript  s subscript   0 \\lambda_{s}=\\lambda_{\\tau}=0 italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT = 0 ,   = 1  1 \\theta=1 italic_ = 1 . We then perform ablation studies using miniF2F-valid to examine the influence of the hyperparameters on the tactic success rate, execution time and diversity of the environment response. For miniF2F-test, we allow the model four attempts per proof to increase confidence in the results, while for miniF2F-valid we allow one attempt per configuration to facilitate a wider set of ablations.",
            "We set the search policy for all experiments to be Best First Search (BestFS), where nodes are expanded in order of their cumulative log probability. For each node selected for expansion, we generate  N = 64 N 64 N=64 italic_N = 64  candidate tactics from the underlying ReProver model using beam search with default settings, as done in the original ReProver implementation. This forms the ground set for the node, to be sub-sampled by the filtering algorithm. We use beam search decoding because it is deterministic and so ensures that the ground set for a given node remains fixed across runs, allowing us to isolate and compare the effect of the filtering algorithm. The filtering algorithm returns  K K K italic_K  tactics, which are then executed in the environment and used to update the proof tree, as outlined in  1.2 . We test three different levels of filtering, with  K  { 8 , 16 , 32 } K 8 16 32 K\\in\\{8,16,32\\} italic_K  { 8 , 16 , 32 } . Lower values of  K K K italic_K  correspond to more filtering, for which the choice of filtering algorithm will have a greater impact. We compare the filtering approach of 3D-Prover, as outlined in Algorithm  1 , with two baselines. The  Top- K K \\mathbf{K} bold_K  baseline takes the top  K K K italic_K  tactics from the ground set as judged by their log probabilities, corresponding to the top  K K K italic_K  beams. We take  K K K italic_K  tactics at random from the ground set to form the  Random  baseline, as an exploration-focused comparison.",
            "Table   2  shows the Pass@1 results of our experiments on miniF2F, which is the number of proofs successfully found after a single attempt. We observe that 3D-Prover significantly outperforms both baseline approaches. We also note that Top- K K K italic_K  selection performs better than the Random approach, which is unsurprising. The influence of the filtering algorithm becomes more apparent as  K K K italic_K  is decreased, as there are more tactics filtered out. Our results are consistent with this, with the magnitude of improvement given by 3D-Prover increasing for lower values of  K K K italic_K . 3D-Prover is able to outperform both baselines by providing a tradeoff between the quality, as represented by Top- K K K italic_K , and the diversity of the tactics. The choice of  K K K italic_K  also controls the depth of the proof search, with larger  K K K italic_K  giving broader search, and smaller  K K K italic_K  deeper search. As most discovered proofs are short (favouring broad search), the Pass@1 performance for lower values of  K K K italic_K  is generally lower, however over multiple attempts it can be beneficial to use deeper searches (see Appendix  A.1 ). Finding deep proofs has to date been a significant challenge (  e.g.   Polu et al. ( 2022 ) ), with the search tree growing exponentially with the proof depth. The improvement given by 3D-Prover, particularly for deeper search configurations, is a step towards addressing this.",
            "We introduce 3D-Prover, a method to augment proof search by filtering candidate tactics to generate diverse and high quality subsets. By generating tactic representations which reflect the response of the proving environment, 3D-Prover is able to filter tactics based on their likely outcome. We evaluate 3D-Prover by augmenting the ReProver LLM on the standard miniF2F benchmark, where we find an improvement in the overall proof success rate (Table  2 ), particularly for deeper searches. Our ablation studies confirm the utility of our tactic representations, which allow the selection of tactics with improved success rates, diversity, and/or execution time. By effectively pruning the search space, 3D-Prover is a step towards enabling deeper automated proofs.",
            "Table  8  shows the Pass@4 results for miniF2F-test, which is the number of proofs found at least once over four attempts. We compare 3D-Prover to the Random baseline, taking the same four runs from Table  2 , where   s =   = 0 subscript  s subscript   0 \\lambda_{s}=\\lambda_{\\tau}=0 italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT = 0 ,   = 1  1 \\theta=1 italic_ = 1 . With Top- K K K italic_K  being deterministic, the Pass@ k k k italic_k  rate is the same as the Pass@1 rate. Given several attempts,  K = 16 K 16 K=16 italic_K = 16  appears to provide a good tradeoff between breadth and depth, performing the best overall. 3D-Prover maintains a large improvement for  K = 8 K 8 K=8 italic_K = 8 , with a modest improvement for  K = 16 K 16 K=16 italic_K = 16 .",
            "We now investigate whether the transition model (Figure  2 ) captures tactic semantics rather than syntax in its tactic embeddings. To test this, we examine the cosine similarity of tactic embeddings which lead to unique subgoals. Figure  4  takes an example node, examining all tactics which lead to a unique subgoal. The upper value displays the cosine similarity given by the transition model, while the lower value displays that given by the Autoencoder in Section  3.3.2 . We observe that in most cases, the similarity given by the transition model is much lower than that given by the Autoencoder, which is only considering the syntax of the tactic. For example, the similarity between tactic 3 and 4 is very high for the Autoencoder, given the similar syntax between the two as they use the same lemma. Despite this similar syntax, the transition model embeddings show a high degree of dissimilarity, reflecting the different outcome they have on the environment. We present additional examples in the supplementary code. To generalise beyond these examples, we ran this comparison over the tactic embeddings which lead to unique subgoals for all 244 root nodes in minF2F-valid. Figure  5  shows the distribution of the average cosine similarity for each node, for both the transition model and the Autoencoder. The average cosine similarity for the transition model embeddings was 0.44 while the Autoencoder gave 0.57. While this comparison does not account for similarity between the unique subgoals, it is still clear that the transition model embeddings better separate unique tactics than Autoencoder embeddings which are based on syntax alone. The result of this is a higher likelihood of 3D-Prover selecting tactics which give unique subgoals, which as we show in Section  3.3.2 , results in the transition model outperforming the Autoencoder for proof discovery.",
            "As outlined in Section  2 , we train our embeddings to be reflective of the tactic semantics across all three components of Status, Time and Output. Hence 3D-Prover, which selects diverse embeddings, may lead to tactics predicted to have errors, where the errors are diverse in terms of their predicted message. The hyperparameter   s subscript  s \\lambda_{s} italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT  can alleviate this by weighting the scores based on their likelihood of success. From our experiments (Table  9 ), there is not necessarily a benefit to Pass@1 by filtering out strongly based on the predicted error likelihood. To speculate, the error prediction, although quite good, is imperfect with many false negatives (Table  1 ). This can lead to potentially useful tactics being ignored if the error prediction is overly trusted, even though there is a higher tactic success rate overall as in Table  4 . Given these prediction errors, it may be the case that selecting goals which are predicted to lead to (diverse) errors may be preferable, given the possibility they result in successful new subgoals. These subgoals may be be quite different from those previously selected, as they are mispredicted, so are clearly outside the space of tactics where the transition model is confident about the outcome. Further analysis could be worthwhile to investigate this. An embedding architecture trained only on successful tactics could be used, however given the high error rate of tactics, this would ignore a large proportion of the transition data.",
            "On our hardware, we found 3D-Prover adds a constant overhead, taking approximately 2x as long for tactic generation. The majority of this is in generating embeddings for the 64 tactics, which we were unable to batch on our hardware due to memory constraints. The DPP algorithm itself added almost no overhead once the embeddings were generated. This could be sped up by batching (if memory permits), or through a different architecture. For example, the  Separate  model in Section  2.2  could be used, where tactics can be batched with much less memory. An augmented architecture which embeds the goal in isolation, which is then given to the tactic encoder as a single vector, could be used. This would provide a speed up while allowing some attention between the tactic and the goal, although not to the degree allowed for by our  Combined  model. As a proof of concept, we used the  Combined  model as it provides the most goal-aware embeddings to test our filtering algorithm."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Percentage of proofs found after one attempt (Pass@1) on miniF2F-valid, comparing 3D-Prover with a Transition Model Encoder to an Autoencoder trained to reconstruct the original tactics. We see that 3D-Prover with the Transition Model gives a clear improvement in proof success over the Autoencoder, demonstrating the utility of our representation architecture in Section  2 .",
        "table": "S3.T3.1",
        "footnotes": [
            ""
        ],
        "references": [
            "One proof attempt can generate a rather large amount of data. A single pass of the miniF2F-valid benchmark of 244 proofs results in approximately 500,000 transitions, capturing rich information about the error likelihood, execution time and resulting proof state or error message. This section explores the feasibility of using this transition data to learn how tactics affect the environment. We operationalise this as a supervised learning task: given a goal and tactic, we predict the error status, execution time and environment output. We effectively learn these targets from only this synthetic data, and further embed this information into a compact tactic representation. The upshot, as we show in Section  3 , is that these representations can be utilised to improve the performance of subsequent proof attempts.",
            "We obtain the dataset  D D {\\mathcal{D}} caligraphic_D  from a vanilla ReProver attempt on miniF2F-valid, which results in 498,236 transitions, which we split randomly into 95% training, 5% testing. There is the possibility of dependence between the splits, as the test set includes goals seen in training with different tactics. The  No Tactic  baseline should capture any of this, with our results in Section  3.3.1  showing our representations generalise from miniF2F-valid to miniF2F-test. For the error prediction task, we reweight classes to account for imbalance, which is approximately 75% error, 25% success. We use the AdamW optimizer, with a learning rate of  10  5 superscript 10 5 10^{-5} 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT  and a batch size of 1. We train each model for 2 epochs on a single RTX4090, and report the results on the test set.",
            "The probability of sampling a subset  A  Y A Y A\\subseteq\\mathcal{Y} italic_A  caligraphic_Y  from a DPP is then proportional to the determinant of the submatrix of  L L L italic_L  indexed by  A A A italic_A ,  P  ( A )  det  ( L A ) = (  i  A q i 2 )  det  ( S A ) proportional-to P A det subscript L A subscript product i A superscript subscript q i 2 det subscript S A \\mathbb{P}(A)\\propto\\text{det}(L_{A})=(\\prod_{i\\in A}q_{i}^{2})\\text{det}(S_{A}) blackboard_P ( italic_A )  det ( italic_L start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ) = (  start_POSTSUBSCRIPT italic_i  italic_A end_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) det ( italic_S start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ) . Geometrically, this determinant is the volume of the parallelepiped spanned by the submatrix  L A subscript L A L_{A} italic_L start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , which as we see in Figure  3 , is maximised based on a combination of the similarity and length (quality) of the chosen elements. In this way, DPPs elegantly trade off between the quality and diversity of elements. Normally the size of the sampled subset  | A | A |A| | italic_A |  is variable, however  Kulesza & Taskar ( 2011 )  introduce  k k k italic_k -DPPs which restricts the size of the subset to a fixed  k  N k N k\\in\\mathbb{N} italic_k  blackboard_N , and where the probability of sampling  A A A italic_A  is normalised over subsets of size  k k k italic_k . That is, for a  k k k italic_k -DPP,  P  ( A )  det  ( L A ) /  | A  | = k det  ( L A  ) proportional-to P A det subscript L A subscript superscript A  k det subscript L superscript A  \\mathbb{P}(A)\\propto\\text{det}(L_{A})/\\sum_{|A^{\\prime}|=k}\\text{det}(L_{A^{% \\prime}}) blackboard_P ( italic_A )  det ( italic_L start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ) /  start_POSTSUBSCRIPT | italic_A start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT | = italic_k end_POSTSUBSCRIPT det ( italic_L start_POSTSUBSCRIPT italic_A start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) .",
            "Algorithm  1  defines our filtering model, 3D-Prover, which maps a list of tactics  T T T italic_T  from the underlying tactic policy   0 subscript  0 \\pi_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  to a subset  T  superscript T  T^{\\prime} italic_T start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  of size  K K K italic_K . We use the Encoder  E E E italic_E  and Predictor  P P P italic_P  defined in Section  1.2  to generate unit norm tactic embeddings   i subscript bold-italic- i \\bm{\\phi}_{i} bold_italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and predict the time and error likelihood. The embeddings   i subscript bold-italic- i \\bm{\\phi}_{i} bold_italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  encode the predicted environment response through their direction only, as they are unit norm (Figure  3 ). The quality scores  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  then scale these tactics based on the underlying model logits  m i subscript m i m_{i} italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , as well as the predicted error likelihood  s i subscript s i s_{i} italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and execution time   i subscript  i \\tau_{i} italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . We have hyperparameters for the normalisation temperature    \\theta italic_ , as well as the error and time weights   s ,   subscript  s subscript   \\lambda_{s},\\lambda_{\\tau} italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT . The parameter    \\theta italic_  controls the scaling temperature of the model logits, with a higher temperature flattening out the distribution. It therefore adjusts the diversity bias of the filtering model by reducing the impact of the quality scores when sampling. We then compute the kernel  L L L italic_L  from  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and   i subscript bold-italic- i \\bm{\\phi}_{i} bold_italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , and sample a subset of tactics  T  superscript T  T^{\\prime} italic_T start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  using the  k k k italic_k -DPP algorithm  (Kulesza & Taskar,  2011 ) .",
            "To demonstrate the utility of our transition model representations, we compare to an ablated 3D-Prover where the transition model Encoder is replaced by an Autoencoder of the same size. The Autoencoder is trained to reconstruct the original tactic, and therefore generates representations which reflect only the syntax of the tactic. In this way, we can test our hypothesis that semantically aware tactic representations are useful for proofs, justifying the inclusion of the transition model. As we observe in Table  3 , the performance of 3D-Prover with the transition model embeddings is indeed superior to that of the Autoencoder across all values of  K K K italic_K . This shows that selecting for diversity with respect to the predicted semantics, rather than the syntax, leads to a direct improvement in proof performance.",
            "We now investigate whether the transition model (Figure  2 ) captures tactic semantics rather than syntax in its tactic embeddings. To test this, we examine the cosine similarity of tactic embeddings which lead to unique subgoals. Figure  4  takes an example node, examining all tactics which lead to a unique subgoal. The upper value displays the cosine similarity given by the transition model, while the lower value displays that given by the Autoencoder in Section  3.3.2 . We observe that in most cases, the similarity given by the transition model is much lower than that given by the Autoencoder, which is only considering the syntax of the tactic. For example, the similarity between tactic 3 and 4 is very high for the Autoencoder, given the similar syntax between the two as they use the same lemma. Despite this similar syntax, the transition model embeddings show a high degree of dissimilarity, reflecting the different outcome they have on the environment. We present additional examples in the supplementary code. To generalise beyond these examples, we ran this comparison over the tactic embeddings which lead to unique subgoals for all 244 root nodes in minF2F-valid. Figure  5  shows the distribution of the average cosine similarity for each node, for both the transition model and the Autoencoder. The average cosine similarity for the transition model embeddings was 0.44 while the Autoencoder gave 0.57. While this comparison does not account for similarity between the unique subgoals, it is still clear that the transition model embeddings better separate unique tactics than Autoencoder embeddings which are based on syntax alone. The result of this is a higher likelihood of 3D-Prover selecting tactics which give unique subgoals, which as we show in Section  3.3.2 , results in the transition model outperforming the Autoencoder for proof discovery."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Tactic success percentage per node for miniF2F-valid (Mean   plus-or-minus \\pm   Standard Error), where   s subscript  s \\lambda_{s} italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT  controls the error weight of quality score in 3D-Prover. These results demonstrate that 3D-Prover leads to fewer errors on average, which can be controlled by increasing   s subscript  s \\lambda_{s} italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT .",
        "table": "S3.T4.16",
        "footnotes": [],
        "references": [
            "We observe from Table  4  that the success rate of tactics chosen by 3D-Prover is significantly improved compared to both baselines. We also note that as  K K K italic_K  decreases, this improvement increases in magnitude, reflecting the heightened influence of the filtering model. We see that this improvement increases with the error weight   s subscript  s \\lambda_{s} italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , which scales the quality scores of tactics by their predicted probability of success. This suggests the error weight term is directly influencing the tactic success rate, showing that it is working as intended.",
            "To examine the diversity of a proof attempt, we consider two metrics. For the first, as in Table  5 , we look at the percentage of unique environment responses to tactics executed per node, including responses with unique errors. As it is difficult to select tactics guaranteed to be successful (see Table  4 ), an exploratory policy should generate tactics which result in more varied outputs, so as to better explore the space. Table  6  quantifies the likelihood of a successful tactic resulting in a new proof path, where we restrict only to successful tactics to account for the discrepancy in success rate between approaches. This gives a direct metric measuring the effectiveness of tactics in providing distinct proof paths to explore. We first observe that the Random baseline leads to higher diversity, as expected. 3D-Prover outperforms both baselines, giving more diverse responses for both valid and invalid tactics. As intended, increasing the parameter    \\theta italic_  results in further improvements to diversity under these metrics.",
            "We now investigate whether the transition model (Figure  2 ) captures tactic semantics rather than syntax in its tactic embeddings. To test this, we examine the cosine similarity of tactic embeddings which lead to unique subgoals. Figure  4  takes an example node, examining all tactics which lead to a unique subgoal. The upper value displays the cosine similarity given by the transition model, while the lower value displays that given by the Autoencoder in Section  3.3.2 . We observe that in most cases, the similarity given by the transition model is much lower than that given by the Autoencoder, which is only considering the syntax of the tactic. For example, the similarity between tactic 3 and 4 is very high for the Autoencoder, given the similar syntax between the two as they use the same lemma. Despite this similar syntax, the transition model embeddings show a high degree of dissimilarity, reflecting the different outcome they have on the environment. We present additional examples in the supplementary code. To generalise beyond these examples, we ran this comparison over the tactic embeddings which lead to unique subgoals for all 244 root nodes in minF2F-valid. Figure  5  shows the distribution of the average cosine similarity for each node, for both the transition model and the Autoencoder. The average cosine similarity for the transition model embeddings was 0.44 while the Autoencoder gave 0.57. While this comparison does not account for similarity between the unique subgoals, it is still clear that the transition model embeddings better separate unique tactics than Autoencoder embeddings which are based on syntax alone. The result of this is a higher likelihood of 3D-Prover selecting tactics which give unique subgoals, which as we show in Section  3.3.2 , results in the transition model outperforming the Autoencoder for proof discovery.",
            "As outlined in Section  2 , we train our embeddings to be reflective of the tactic semantics across all three components of Status, Time and Output. Hence 3D-Prover, which selects diverse embeddings, may lead to tactics predicted to have errors, where the errors are diverse in terms of their predicted message. The hyperparameter   s subscript  s \\lambda_{s} italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT  can alleviate this by weighting the scores based on their likelihood of success. From our experiments (Table  9 ), there is not necessarily a benefit to Pass@1 by filtering out strongly based on the predicted error likelihood. To speculate, the error prediction, although quite good, is imperfect with many false negatives (Table  1 ). This can lead to potentially useful tactics being ignored if the error prediction is overly trusted, even though there is a higher tactic success rate overall as in Table  4 . Given these prediction errors, it may be the case that selecting goals which are predicted to lead to (diverse) errors may be preferable, given the possibility they result in successful new subgoals. These subgoals may be be quite different from those previously selected, as they are mispredicted, so are clearly outside the space of tactics where the transition model is confident about the outcome. Further analysis could be worthwhile to investigate this. An embedding architecture trained only on successful tactics could be used, however given the high error rate of tactics, this would ignore a large proportion of the transition data."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Percentage of unique environment responses per node in miniF2F-valid (Mean   plus-or-minus \\pm   Standard Error). Unique defines either syntactically distinct error messages or responses including at least one previously unseen subgoal.    \\theta italic_  controls the temperature of the model scores when calculating quality. We see that 3D-Prover gives a higher diversity of environment responses, increasing with    \\theta italic_ .",
        "table": "S3.T5.16",
        "footnotes": [],
        "references": [
            "To examine the diversity of a proof attempt, we consider two metrics. For the first, as in Table  5 , we look at the percentage of unique environment responses to tactics executed per node, including responses with unique errors. As it is difficult to select tactics guaranteed to be successful (see Table  4 ), an exploratory policy should generate tactics which result in more varied outputs, so as to better explore the space. Table  6  quantifies the likelihood of a successful tactic resulting in a new proof path, where we restrict only to successful tactics to account for the discrepancy in success rate between approaches. This gives a direct metric measuring the effectiveness of tactics in providing distinct proof paths to explore. We first observe that the Random baseline leads to higher diversity, as expected. 3D-Prover outperforms both baselines, giving more diverse responses for both valid and invalid tactics. As intended, increasing the parameter    \\theta italic_  results in further improvements to diversity under these metrics.",
            "We now investigate whether the transition model (Figure  2 ) captures tactic semantics rather than syntax in its tactic embeddings. To test this, we examine the cosine similarity of tactic embeddings which lead to unique subgoals. Figure  4  takes an example node, examining all tactics which lead to a unique subgoal. The upper value displays the cosine similarity given by the transition model, while the lower value displays that given by the Autoencoder in Section  3.3.2 . We observe that in most cases, the similarity given by the transition model is much lower than that given by the Autoencoder, which is only considering the syntax of the tactic. For example, the similarity between tactic 3 and 4 is very high for the Autoencoder, given the similar syntax between the two as they use the same lemma. Despite this similar syntax, the transition model embeddings show a high degree of dissimilarity, reflecting the different outcome they have on the environment. We present additional examples in the supplementary code. To generalise beyond these examples, we ran this comparison over the tactic embeddings which lead to unique subgoals for all 244 root nodes in minF2F-valid. Figure  5  shows the distribution of the average cosine similarity for each node, for both the transition model and the Autoencoder. The average cosine similarity for the transition model embeddings was 0.44 while the Autoencoder gave 0.57. While this comparison does not account for similarity between the unique subgoals, it is still clear that the transition model embeddings better separate unique tactics than Autoencoder embeddings which are based on syntax alone. The result of this is a higher likelihood of 3D-Prover selecting tactics which give unique subgoals, which as we show in Section  3.3.2 , results in the transition model outperforming the Autoencoder for proof discovery."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Percentage of successful tactics per node resulting in unique subgoal(s) over miniF2F-valid (Mean   plus-or-minus \\pm   Standard Error).    \\theta italic_  controls the temperature of the model scores in 3D-Prover when calculating quality. We observe 3D-Prover gives a higher number of unique subgoals per tactic, leading to a more diverse set of proof paths, with larger    \\theta italic_  controlling this.",
        "table": "S3.T6.16",
        "footnotes": [],
        "references": [
            "To examine the diversity of a proof attempt, we consider two metrics. For the first, as in Table  5 , we look at the percentage of unique environment responses to tactics executed per node, including responses with unique errors. As it is difficult to select tactics guaranteed to be successful (see Table  4 ), an exploratory policy should generate tactics which result in more varied outputs, so as to better explore the space. Table  6  quantifies the likelihood of a successful tactic resulting in a new proof path, where we restrict only to successful tactics to account for the discrepancy in success rate between approaches. This gives a direct metric measuring the effectiveness of tactics in providing distinct proof paths to explore. We first observe that the Random baseline leads to higher diversity, as expected. 3D-Prover outperforms both baselines, giving more diverse responses for both valid and invalid tactics. As intended, increasing the parameter    \\theta italic_  results in further improvements to diversity under these metrics."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Tactic execution time in milliseconds over miniF2F-valid proof attempts (Mean   plus-or-minus \\pm   Standard Error).    subscript   \\lambda_{\\tau} italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  controls the time weighting of the quality score in 3D-Prover. 3D-Prover selects faster tactics on average, with larger    subscript   \\lambda_{\\tau} italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  magnifying this.",
        "table": "S3.T7.16",
        "footnotes": [],
        "references": [
            "Table  7  shows the execution time for tactics over miniF2F-valid transitions. Again we see that 3D-Prover outperforms both baselines, with the improvement increasing with more filtering. Increasing the time weight    subscript   \\lambda_{\\tau} italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  results in further reductions to the average execution time, demonstrating the accuracy of the predictions, and that they can directly result in faster tactics when filtering."
        ]
    },
    "id_table_8": {
        "caption": "Table 8:  Percentage of proofs found after four attempts (Pass@4) on miniF2F-test, with  K K K italic_K  tactics selected per node.",
        "table": "A1.T8.1",
        "footnotes": [],
        "references": [
            "Table  8  shows the Pass@4 results for miniF2F-test, which is the number of proofs found at least once over four attempts. We compare 3D-Prover to the Random baseline, taking the same four runs from Table  2 , where   s =   = 0 subscript  s subscript   0 \\lambda_{s}=\\lambda_{\\tau}=0 italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT = 0 ,   = 1  1 \\theta=1 italic_ = 1 . With Top- K K K italic_K  being deterministic, the Pass@ k k k italic_k  rate is the same as the Pass@1 rate. Given several attempts,  K = 16 K 16 K=16 italic_K = 16  appears to provide a good tradeoff between breadth and depth, performing the best overall. 3D-Prover maintains a large improvement for  K = 8 K 8 K=8 italic_K = 8 , with a modest improvement for  K = 16 K 16 K=16 italic_K = 16 ."
        ]
    },
    "id_table_9": {
        "caption": "Table 9:  Pass@1 results on miniF2F-valid, over different hyperparameter configurations for 3D-Prover.",
        "table": "A1.T9.4",
        "footnotes": [],
        "references": [
            "Table  9  shows the Pass@1 results on miniF2F-valid for 3D-Prover for our limited hyperparameter sweep. These results suggest that a lower time weight    subscript   \\lambda_{\\tau} italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  leads to better proving results. The diversity parameter    \\theta italic_  hinders performance for the larger value, consistent with what was observed by  Chen et al. ( 2021 ) , where they observe a tradeoff between exploration and Pass@1. Although these parameters may not improve Pass@1, different proofs may favour different configurations, with some requiring  e.g.  more depth or exploration than others. As discussed above, a higher Pass@ k k k italic_k  can usually be obtained by sampling a wide set of these parameters. For the set of hyperparameters we tested here, we found a cumulative proof rate (or Pass@15) of 32.8% on miniF2F-valid.",
            "As outlined in Section  2 , we train our embeddings to be reflective of the tactic semantics across all three components of Status, Time and Output. Hence 3D-Prover, which selects diverse embeddings, may lead to tactics predicted to have errors, where the errors are diverse in terms of their predicted message. The hyperparameter   s subscript  s \\lambda_{s} italic_ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT  can alleviate this by weighting the scores based on their likelihood of success. From our experiments (Table  9 ), there is not necessarily a benefit to Pass@1 by filtering out strongly based on the predicted error likelihood. To speculate, the error prediction, although quite good, is imperfect with many false negatives (Table  1 ). This can lead to potentially useful tactics being ignored if the error prediction is overly trusted, even though there is a higher tactic success rate overall as in Table  4 . Given these prediction errors, it may be the case that selecting goals which are predicted to lead to (diverse) errors may be preferable, given the possibility they result in successful new subgoals. These subgoals may be be quite different from those previously selected, as they are mispredicted, so are clearly outside the space of tactics where the transition model is confident about the outcome. Further analysis could be worthwhile to investigate this. An embedding architecture trained only on successful tactics could be used, however given the high error rate of tactics, this would ignore a large proportion of the transition data."
        ]
    }
}