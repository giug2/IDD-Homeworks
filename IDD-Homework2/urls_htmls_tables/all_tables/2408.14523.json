{
    "id_table_1": {
        "caption": "Table 1:  Dataset statistics.",
        "table": "S5.T1.1",
        "footnotes": [],
        "references": [
            "Despite significant advancements in dynamic graph modeling, current approaches heavily depend on isolated historical contexts of the target nodes, limiting each nodes perspective to its ego network. The limited context makes it difficult to quickly adapt to diverse emerging patterns. For example, in a social network, when users transit to new behavioral patterns or when new users with minimal historical interactions are introduced, traditional models that focus on the historical contexts of individual nodes might not respond effectively to these changes. To overcome these limitations, we draw inspiration from the Retrieval-Augmented Generation (RAG) technique originated from the Natural Language Processing (NLP) field  (Gao et al.  2023 ) . As shown in Fig.  1(a) , RAG broadens the context through the retrieval of additional demonstrations, achieving considerable success in NLP. In this work, we aim to integrate RAG into dynamic graph modeling to incorporate a broader and more relevant contextual understanding beyond the historical interactions of individual nodes. However, leveraging RAG for dynamic graph modeling presents two critical challenges.",
            "First,  how do we harvest high-quality demonstrations for dynamic graphs?   This involves selecting the most contextually and temporally relevant samples to enrich the current state of a target node. Unlike RAG for NLP, where external textual data and a pre-trained language model (LM) naturally support demonstration retrieval as shown in Fig.  1(a) , dynamic graph modeling requires careful consideration of the data sources and the ability to handle complex structural and temporal patterns as shown in Fig.  1(b) . To address this, we introduce a novel time-aware contrastive learning strategy that leverages internal training data for demonstration retrieval.  Following SimpleDyG  (Wu, Fang, and Liao  2024 ) , we regard dynamic graph modeling as a sequence modeling task and the prediction of future events as a sequence generation problem. Hence, we define a  query sequence  for a target node as its historical interaction sequence. Next, we automatically annotate the retrieval training pool by assessing the similarity to the query. Given the training pool, our model consists of two contrastive modules: time-aware and context-aware contrastive learning. The former utilizes a time decay function to prioritize samples that are temporally close to the query, while the latter incorporates data augmentation techniques such as masking and cropping to improve the models ability to retrieve complex structural patterns.",
            "Second,  how do we effectively integrate the retrieved demonstrations into the dynamic graph model?  This involves fusing the retrieved demonstrations to enrich the historical context of each target node and enhance subsequent predictions. Directly concatenating the retrieved demonstrations with the query sequence not only results in a lengthy sequence unsuited for generative predictions but also overlooks the structural patterns among the retrieved demonstrations. To address this, we propose graph fusion, leveraging the graph structures inherent to the demonstrations and fusing them into a summary graph, as shown in Fig.  1(b) . We then apply a GNN-based readout to learn the representation of the fused summary graph, which is prepended to the query sequence before being fed into the sequence generation model.",
            "Dynamic graph modeling aims to learn a model that can predict the future interactions of a target node  v i subscript v i v_{i} italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , given its historical interactions. That is, given  x i subscript x i x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  in Eq. ( 1 ), the task is to predict  y i subscript y i y_{i} italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  in Eq. ( 2 ).",
            "Next, given a query sequence  x q subscript x q x_{q} italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  and a retrieval pool  D D D italic_D , a time- and context-aware retriever is designed to retrieve demonstrations for  x q subscript x q x_{q} italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  from  D D D italic_D , as shown in Fig.  2 (b). The retriever fine-tunes its encoder ( i.e. , the sequence model) to jointly optimize two contrastive losses: a time-aware loss that employs a time decay function, and a context-aware loss that employs sequence augmentation. (Sect.  4.1 )",
            "During testing, we first apply the retriever model to retrieve top- K  demonstrations for each query as introduced in Sect.  4.1 . Then we perform graph fusion on these demonstrations and concatenate the fused graph representation with the query sequence as illustrated in Eqs. ( 9 ) and ( 10 ). The concatenated sequence is subsequently fed into the trained sequence model for link prediction.",
            "We evaluate the performance of the proposed model on three datasets from different domains including the communication network UCI  (Panzarasa, Opsahl, and Carley  2009 ) , the citation network Hepth  (Leskovec, Kleinberg, and Faloutsos  2005 ) , and the multi-turn task-oriented conversation dataset MMConv  (Liao et al.  2021 ) . We follow the same dataset preprocessing as SimpleDyG  (Wu, Fang, and Liao  2024 ) . It is important to note that the ML-10M dataset was not used because it is not suitable for RAG; we observed no performance enhancement even when the query was augmented with ground-truth demonstrations.  We summarize the statistics of the three datasets in Table  1 ."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:   Performance comparison for dynamic link prediction. (Best results are bolded; runners-up are underlined.)",
        "table": "S5.T2.1",
        "footnotes": [],
        "references": [
            "Dynamic graph modeling aims to learn a model that can predict the future interactions of a target node  v i subscript v i v_{i} italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , given its historical interactions. That is, given  x i subscript x i x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  in Eq. ( 1 ), the task is to predict  y i subscript y i y_{i} italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  in Eq. ( 2 ).",
            "Our proposed RAG4DyG framework, depicted in Fig.  2 , first trains a generative sequence model for dynamic graphs in Fig.  2 (a). We use SimpleDyG  (Wu, Fang, and Liao  2024 )  as the backbone for this task. As described in Sect.  3 , a dynamic graph  G G G italic_G  is represented as sequences of node interaction records, which are then used to train a Transformer-based sequence model.",
            "Next, given a query sequence  x q subscript x q x_{q} italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  and a retrieval pool  D D D italic_D , a time- and context-aware retriever is designed to retrieve demonstrations for  x q subscript x q x_{q} italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  from  D D D italic_D , as shown in Fig.  2 (b). The retriever fine-tunes its encoder ( i.e. , the sequence model) to jointly optimize two contrastive losses: a time-aware loss that employs a time decay function, and a context-aware loss that employs sequence augmentation. (Sect.  4.1 )",
            "Finally, given top- K  demonstrations retrieved from the retrieval pool, we design a graph fusion module as illustrated in Fig.  2 (c). Specifically, we fuse the  K  demonstrations into a summary graph, leveraging the graph structures inherent to the retrieved demonstrations. The summary graph is further encoded by a GNN, serving as an augmented context that is prepended to the original query sequence. The augmented sequence is subsequently input to the sequence model to predict future events. (Sect.  4.2 )",
            "To facilitate contrastive training, we automatically annotate the samples in the retrieval pool  D D D italic_D . For each query sequence  x q subscript x q x_{q} italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , we annotate its positive sample  x p + superscript subscript x p x_{p}^{+} italic_x start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT  from the pool  D D D italic_D  based on their contextual similarity.  Specifically, we adopt the sequence model pre-trained in Fig.  2 (a) as the encoder and apply mean pooling to obtain sequence representations. Given a query sequence  x q subscript x q x_{q} italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  and a candidate sequence  x p  D subscript x p D x_{p}\\in D italic_x start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT  italic_D , we define their contextual similarity as the dot product of their representations:",
            "We adopt the same sequence model with the same training objective  (Wu, Fang, and Liao  2024 )  as in Fig.  2 (a). During training, we freeze the parameters of the sequence model, except for the output layer which is updated along with the GCN parameters used for graph fusion.",
            "We evaluate the performance of RAG4DyG for the dynamic link prediction task, and the results compared to the state-of-the-art baselines are presented in Table  2 . We make the following observations."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Retrieval performance of various retrieval methods.",
        "table": "S5.T3.1",
        "footnotes": [],
        "references": [
            "Our proposed RAG4DyG framework, depicted in Fig.  2 , first trains a generative sequence model for dynamic graphs in Fig.  2 (a). We use SimpleDyG  (Wu, Fang, and Liao  2024 )  as the backbone for this task. As described in Sect.  3 , a dynamic graph  G G G italic_G  is represented as sequences of node interaction records, which are then used to train a Transformer-based sequence model.",
            "To evaluate the effectiveness of different modules in the retrieval model, we compare RAG4DyG with two variants  w/o CCL  and  w/o Decay  which exclude the context-aware contrastive learning and time decay component in the retrieval model. We evaluate the performance for both retrieval and link prediction tasks. We use HR@ k  (Hit Ratio@ k ) metrics for the retrieval model, measuring the proportion of cases where at least one of the top- k  retrieved items is relevant. As shown in Fig.  3  and  4 , the full model outperforms the two variants, underscoring the benefits of incorporating context-aware contrastive learning and time decay modulation.",
            "To further investigate the effectiveness of the retrieval model, we compare our model with two different retrieval methods, namely, BM25 and Jaccard, in Table  3  and  4 .  In Table  4 , we only report NDCG@5 and present the remaining metrics in Appendix C.  BM25  (Fang, Tao, and Zhai  2004 )  is an extension of the Term Frequency-Inverse Document Frequency (TF-IDF) model, which calculates a relevance score between the query sequence and each candidate sequence in the retrieval pool. The relevance score is derived from the occurrence frequency of the nodes in the query and the retrieval pool.  Jaccard  (Jaccard  1901 )  measures the similarity between two sets by comparing the size of their intersection to the size of their union. Note that in the citation dataset Hepth, all queries in the test set only contain unseen target nodes that never appear in the retrieval pool and have no historical interactions. As a result, the BM25 and Jaccard scores between the queries and the candidates in the retrieval pool are always zeros. On the other hand, our retrieval model is trained based on the sequence representations. For a query sequence containing only the target node, we can still obtain its representation using the sequence model trained for the retrieval model, and further calculate its contextual similarity with the candidate sequences in the retrieval pool.",
            "In Table  3 , we analyze the retrieval performance of different retrieval methods. Our retrieval model shows better performance than other retrieval strategies. Notably, in inductive scenarios like the Hepth dataset, BM25 and Jaccard fail to work with new query nodes lacking historical interactions. In contrast, our model can handle them effectively and achieve solid performance. The high  H  R  @  3 H R @ 3 HR@3 italic_H italic_R @ 3  performance of BM25 and Jaccard on the MMConv dataset can be attributed to the nature of the dialogue dataset, where temporal order is less critical, and certain nodes associated with specific slot values are more discriminative."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Generative accuracy of various retrieval methods.",
        "table": "S5.T4.1",
        "footnotes": [],
        "references": [
            "Next, given a query sequence  x q subscript x q x_{q} italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  and a retrieval pool  D D D italic_D , a time- and context-aware retriever is designed to retrieve demonstrations for  x q subscript x q x_{q} italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  from  D D D italic_D , as shown in Fig.  2 (b). The retriever fine-tunes its encoder ( i.e. , the sequence model) to jointly optimize two contrastive losses: a time-aware loss that employs a time decay function, and a context-aware loss that employs sequence augmentation. (Sect.  4.1 )",
            "Finally, given top- K  demonstrations retrieved from the retrieval pool, we design a graph fusion module as illustrated in Fig.  2 (c). Specifically, we fuse the  K  demonstrations into a summary graph, leveraging the graph structures inherent to the retrieved demonstrations. The summary graph is further encoded by a GNN, serving as an augmented context that is prepended to the original query sequence. The augmented sequence is subsequently input to the sequence model to predict future events. (Sect.  4.2 )",
            "During testing, we first apply the retriever model to retrieve top- K  demonstrations for each query as introduced in Sect.  4.1 . Then we perform graph fusion on these demonstrations and concatenate the fused graph representation with the query sequence as illustrated in Eqs. ( 9 ) and ( 10 ). The concatenated sequence is subsequently fed into the trained sequence model for link prediction.",
            "To evaluate the effectiveness of different modules in the retrieval model, we compare RAG4DyG with two variants  w/o CCL  and  w/o Decay  which exclude the context-aware contrastive learning and time decay component in the retrieval model. We evaluate the performance for both retrieval and link prediction tasks. We use HR@ k  (Hit Ratio@ k ) metrics for the retrieval model, measuring the proportion of cases where at least one of the top- k  retrieved items is relevant. As shown in Fig.  3  and  4 , the full model outperforms the two variants, underscoring the benefits of incorporating context-aware contrastive learning and time decay modulation.",
            "To further investigate the effectiveness of the retrieval model, we compare our model with two different retrieval methods, namely, BM25 and Jaccard, in Table  3  and  4 .  In Table  4 , we only report NDCG@5 and present the remaining metrics in Appendix C.  BM25  (Fang, Tao, and Zhai  2004 )  is an extension of the Term Frequency-Inverse Document Frequency (TF-IDF) model, which calculates a relevance score between the query sequence and each candidate sequence in the retrieval pool. The relevance score is derived from the occurrence frequency of the nodes in the query and the retrieval pool.  Jaccard  (Jaccard  1901 )  measures the similarity between two sets by comparing the size of their intersection to the size of their union. Note that in the citation dataset Hepth, all queries in the test set only contain unseen target nodes that never appear in the retrieval pool and have no historical interactions. As a result, the BM25 and Jaccard scores between the queries and the candidates in the retrieval pool are always zeros. On the other hand, our retrieval model is trained based on the sequence representations. For a query sequence containing only the target node, we can still obtain its representation using the sequence model trained for the retrieval model, and further calculate its contextual similarity with the candidate sequences in the retrieval pool.",
            "Table  4  shows the generative performance of different retrieval methods in the dynamic link prediction task. During testing, we apply the retrieval results obtained from different retrieval methods. We also train a model using the ground-truth retrieval results for a more comprehensive comparison. The GroundTruth row represents an upper bound on the performance when using ground-truth retrieval results on the testing data, which, as expected, provides the highest performance metrics. Generally speaking, all retrieval methods show better performance compared to the backbone SimpleDyG without using RAG, demonstrating the effectiveness of the RAG technique for dynamic graph modeling. Our method performs better compared to other retrieval strategies, indicating the effectiveness of contrastive learning in the retrieval model.",
            "To further investigate the effectiveness of the fusion strategy for the top- K  demonstrations, we conduct experiments with different fusion strategies in Table  5  for  K   = 7 absent 7 =7 = 7 . We report NDCG@5 in Table  4  and present the other metrics in Appendix C. Concatenation denotes we directly concatenate the sequences of retrieved demonstrations and prepend them with the query sample sequence and then feed it into the pre-trained SimpleDyG model. MLP means we do not consider the graph structure of the demonstrations and replace the graph fusion as an MLP layer (we set the number of the MLP layer as 2). By using the MLP layer, We map the concatenated demonstrations into shorter  m -dimensional embeddings (we empirically set  m  to be 15) and then concatenate it with the query sample. Like graph fusion, we only fine-tune the parameters of the MLP and output layer. The results in Table  5  show that directly concatenating the retrieved demonstrations with the query sample leads to lower performance compared with other strategies. This is because simple concatenation introduces a lengthy context, which can overwhelm the model with irrelevant information, and it neglects the structural relationships inherent in the demonstrations. The MLP strategy improves upon this by mapping the concatenated demonstrations into a shorter feature space, effectively reducing noise and emphasizing more relevant features. This approach yields better results than simple concatenation but still falls short compared to the GraphFusion strategy. The superior performance of the GraphFusion strategy highlights the importance of considering both the content and the structure of the demonstrations in the fusion process.",
            "For the effect of different retrieval methods for generative performance in Sec. 5.3, we report the NDCG@5 score in Table  4 . Here we report the remaining metrics in Table  6 . The results show that RAG4DyG performs better than BM25 and Jaccard on Recall@5 and Jaccard metrics, which are consistent with the performance of NDCG@5."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Effect of different fusion strategies.",
        "table": "S5.T5.1",
        "footnotes": [],
        "references": [
            "To investigate the influence of the number of demonstrations, we conduct experiments across varying values  K  { 1 , 3 , 5 , 7 , 9 } K 1 3 5 7 9 K\\in\\{1,3,5,7,9\\} italic_K  { 1 , 3 , 5 , 7 , 9 } . As shown in Fig.  5 , a higher number of  K K K italic_K  yields better prediction performance, thats because more demonstrations provide richer contextual information, especially in the UCI dataset. However, including too many cases may introduce more noise, which can harm the performance.",
            "To further investigate the effectiveness of the fusion strategy for the top- K  demonstrations, we conduct experiments with different fusion strategies in Table  5  for  K   = 7 absent 7 =7 = 7 . We report NDCG@5 in Table  4  and present the other metrics in Appendix C. Concatenation denotes we directly concatenate the sequences of retrieved demonstrations and prepend them with the query sample sequence and then feed it into the pre-trained SimpleDyG model. MLP means we do not consider the graph structure of the demonstrations and replace the graph fusion as an MLP layer (we set the number of the MLP layer as 2). By using the MLP layer, We map the concatenated demonstrations into shorter  m -dimensional embeddings (we empirically set  m  to be 15) and then concatenate it with the query sample. Like graph fusion, we only fine-tune the parameters of the MLP and output layer. The results in Table  5  show that directly concatenating the retrieved demonstrations with the query sample leads to lower performance compared with other strategies. This is because simple concatenation introduces a lengthy context, which can overwhelm the model with irrelevant information, and it neglects the structural relationships inherent in the demonstrations. The MLP strategy improves upon this by mapping the concatenated demonstrations into a shorter feature space, effectively reducing noise and emphasizing more relevant features. This approach yields better results than simple concatenation but still falls short compared to the GraphFusion strategy. The superior performance of the GraphFusion strategy highlights the importance of considering both the content and the structure of the demonstrations in the fusion process."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Generative performance of retrieval methods.",
        "table": "A3.T6.1.1",
        "footnotes": [],
        "references": [
            "For the effect of different retrieval methods for generative performance in Sec. 5.3, we report the NDCG@5 score in Table  4 . Here we report the remaining metrics in Table  6 . The results show that RAG4DyG performs better than BM25 and Jaccard on Recall@5 and Jaccard metrics, which are consistent with the performance of NDCG@5."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Effect of different fusion strategies.",
        "table": "A3.T7.1.1",
        "footnotes": [],
        "references": [
            "For the effect of different fusion strategies in Sec. 5.3, the performance of the remaining metrics is shown in Table  7 . Similarly, the GraphFusion strategy outperforms direct concatenation and MLP, indicating the effectiveness of the graph structure among demonstrations."
        ]
    },
    "global_footnotes": [
        "In the annotated training data, the query time",
        "may precede the candidate time",
        ". However, in the validation and test sets,",
        "always precedes",
        ", preventing leakage from a future time."
    ]
}