{
    "PAPER'S NUMBER OF TABLES": 11,
    "S5.T1": {
        "caption": "Table 1: Results of NeFL for CIFAR-10 dataset under IID (left) and non-IID (right) settings are presented: Top-1 classification accuracies (%) for the worst-case submodel and the average of the performance of five submodels.",
        "table": "<table id=\"S5.T1.32.32\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.32.32.33\" class=\"ltx_tr\">\n<td id=\"S5.T1.32.32.33.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T1.32.32.33.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S5.T1.32.32.33.2\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T1.32.32.33.2.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"S5.T1.32.32.33.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S5.T1.32.32.33.3.1\" class=\"ltx_text ltx_font_bold\">IID</span></td>\n<td id=\"S5.T1.32.32.33.4\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S5.T1.32.32.33.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S5.T1.32.32.33.5.1\" class=\"ltx_text ltx_font_bold\">non-IID</span></td>\n</tr>\n<tr id=\"S5.T1.32.32.34\" class=\"ltx_tr\">\n<td id=\"S5.T1.32.32.34.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.32.32.34.1.1\" class=\"ltx_text ltx_font_bold\">Worst</span></td>\n<td id=\"S5.T1.32.32.34.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.32.32.34.2.1\" class=\"ltx_text ltx_font_bold\">Avg</span></td>\n<td id=\"S5.T1.32.32.34.3\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T1.32.32.34.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.32.32.34.4.1\" class=\"ltx_text ltx_font_bold\">Worst</span></td>\n<td id=\"S5.T1.32.32.34.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.32.32.34.5.1\" class=\"ltx_text ltx_font_bold\">Avg</span></td>\n</tr>\n<tr id=\"S5.T1.4.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"4\"><span id=\"S5.T1.4.4.4.5.1\" class=\"ltx_text\">ResNet18</span></td>\n<td id=\"S5.T1.4.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_tt\">HeteroFL</td>\n<td id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">80.62 (<math id=\"S5.T1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.1.1.1.1.m1.1a\"><mo id=\"S5.T1.1.1.1.1.m1.1.1\" xref=\"S5.T1.1.1.1.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.1.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.1.1.1.1.m1.1c\">\\pm</annotation></semantics></math> 0.24)</td>\n<td id=\"S5.T1.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">84.26 (<math id=\"S5.T1.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.2.2.2.2.m1.1a\"><mo id=\"S5.T1.2.2.2.2.m1.1.1\" xref=\"S5.T1.2.2.2.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.2.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.2.2.2.2.m1.1.1.cmml\" xref=\"S5.T1.2.2.2.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.2.2.2.2.m1.1c\">\\pm</annotation></semantics></math> 1.95)</td>\n<td id=\"S5.T1.4.4.4.7\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S5.T1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">76.25 (<math id=\"S5.T1.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.3.3.3.3.m1.1a\"><mo id=\"S5.T1.3.3.3.3.m1.1.1\" xref=\"S5.T1.3.3.3.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.3.3.3.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.3.3.3.3.m1.1.1.cmml\" xref=\"S5.T1.3.3.3.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.3.3.3.3.m1.1c\">\\pm</annotation></semantics></math> 1.05)</td>\n<td id=\"S5.T1.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">80.11 (<math id=\"S5.T1.4.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.4.4.4.4.m1.1a\"><mo id=\"S5.T1.4.4.4.4.m1.1.1\" xref=\"S5.T1.4.4.4.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.4.4.4.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.4.4.4.4.m1.1.1.cmml\" xref=\"S5.T1.4.4.4.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.4.4.4.4.m1.1c\">\\pm</annotation></semantics></math> 2.03)</td>\n</tr>\n<tr id=\"S5.T1.8.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T1.8.8.8.5\" class=\"ltx_td ltx_align_left ltx_border_t\">FjORD</td>\n<td id=\"S5.T1.5.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_t\">85.12 (<math id=\"S5.T1.5.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.5.5.5.1.m1.1a\"><mo id=\"S5.T1.5.5.5.1.m1.1.1\" xref=\"S5.T1.5.5.5.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.5.5.5.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.5.5.5.1.m1.1.1.cmml\" xref=\"S5.T1.5.5.5.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.5.5.5.1.m1.1c\">\\pm</annotation></semantics></math> 0.22)</td>\n<td id=\"S5.T1.6.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">87.32 (<math id=\"S5.T1.6.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.6.6.6.2.m1.1a\"><mo id=\"S5.T1.6.6.6.2.m1.1.1\" xref=\"S5.T1.6.6.6.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.6.6.6.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.6.6.6.2.m1.1.1.cmml\" xref=\"S5.T1.6.6.6.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.6.6.6.2.m1.1c\">\\pm</annotation></semantics></math> 1.21)</td>\n<td id=\"S5.T1.8.8.8.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T1.7.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">75.81 (<math id=\"S5.T1.7.7.7.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.7.7.7.3.m1.1a\"><mo id=\"S5.T1.7.7.7.3.m1.1.1\" xref=\"S5.T1.7.7.7.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.7.7.7.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.7.7.7.3.m1.1.1.cmml\" xref=\"S5.T1.7.7.7.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.7.7.7.3.m1.1c\">\\pm</annotation></semantics></math> 5.65)</td>\n<td id=\"S5.T1.8.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">77.99 (<math id=\"S5.T1.8.8.8.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.8.8.8.4.m1.1a\"><mo id=\"S5.T1.8.8.8.4.m1.1.1\" xref=\"S5.T1.8.8.8.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.8.8.8.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.8.8.8.4.m1.1.1.cmml\" xref=\"S5.T1.8.8.8.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.8.8.8.4.m1.1c\">\\pm</annotation></semantics></math> 6.50)</td>\n</tr>\n<tr id=\"S5.T1.12.12.12\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.12.12.5\" class=\"ltx_td ltx_align_left ltx_border_t\">DepthFL</td>\n<td id=\"S5.T1.9.9.9.1\" class=\"ltx_td ltx_align_center ltx_border_t\">64.80 (<math id=\"S5.T1.9.9.9.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.9.9.9.1.m1.1a\"><mo id=\"S5.T1.9.9.9.1.m1.1.1\" xref=\"S5.T1.9.9.9.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.9.9.9.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.9.9.9.1.m1.1.1.cmml\" xref=\"S5.T1.9.9.9.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.9.9.9.1.m1.1c\">\\pm</annotation></semantics></math> 10.49)</td>\n<td id=\"S5.T1.10.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_t\">82.44 (<math id=\"S5.T1.10.10.10.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.10.10.10.2.m1.1a\"><mo id=\"S5.T1.10.10.10.2.m1.1.1\" xref=\"S5.T1.10.10.10.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.10.10.10.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.10.10.10.2.m1.1.1.cmml\" xref=\"S5.T1.10.10.10.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.10.10.10.2.m1.1c\">\\pm</annotation></semantics></math> 10.17)</td>\n<td id=\"S5.T1.12.12.12.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T1.11.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_t\">59.61 (<math id=\"S5.T1.11.11.11.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.11.11.11.3.m1.1a\"><mo id=\"S5.T1.11.11.11.3.m1.1.1\" xref=\"S5.T1.11.11.11.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.11.11.11.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.11.11.11.3.m1.1.1.cmml\" xref=\"S5.T1.11.11.11.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.11.11.11.3.m1.1c\">\\pm</annotation></semantics></math> 5.16)</td>\n<td id=\"S5.T1.12.12.12.4\" class=\"ltx_td ltx_align_center ltx_border_t\">76.89 (<math id=\"S5.T1.12.12.12.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.12.12.12.4.m1.1a\"><mo id=\"S5.T1.12.12.12.4.m1.1.1\" xref=\"S5.T1.12.12.12.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.12.12.12.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.12.12.12.4.m1.1.1.cmml\" xref=\"S5.T1.12.12.12.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.12.12.12.4.m1.1c\">\\pm</annotation></semantics></math> 9.60)</td>\n</tr>\n<tr id=\"S5.T1.16.16.16\" class=\"ltx_tr\">\n<td id=\"S5.T1.16.16.16.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T1.16.16.16.5.1\" class=\"ltx_text ltx_font_bold\">NeFL (ours)</span></td>\n<td id=\"S5.T1.13.13.13.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.13.13.13.1.1\" class=\"ltx_text ltx_font_bold\">86.86 (<math id=\"S5.T1.13.13.13.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.13.13.13.1.1.m1.1a\"><mo id=\"S5.T1.13.13.13.1.1.m1.1.1\" xref=\"S5.T1.13.13.13.1.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.13.13.13.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.13.13.13.1.1.m1.1.1.cmml\" xref=\"S5.T1.13.13.13.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.13.13.13.1.1.m1.1c\">\\pm</annotation></semantics></math> 0.22)</span></td>\n<td id=\"S5.T1.14.14.14.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.14.14.14.2.1\" class=\"ltx_text ltx_font_bold\">87.88 (<math id=\"S5.T1.14.14.14.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.14.14.14.2.1.m1.1a\"><mo id=\"S5.T1.14.14.14.2.1.m1.1.1\" xref=\"S5.T1.14.14.14.2.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.14.14.14.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.14.14.14.2.1.m1.1.1.cmml\" xref=\"S5.T1.14.14.14.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.14.14.14.2.1.m1.1c\">\\pm</annotation></semantics></math> 0.68)</span></td>\n<td id=\"S5.T1.16.16.16.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T1.15.15.15.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.15.15.15.3.1\" class=\"ltx_text ltx_font_bold\">81.26 (<math id=\"S5.T1.15.15.15.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.15.15.15.3.1.m1.1a\"><mo id=\"S5.T1.15.15.15.3.1.m1.1.1\" xref=\"S5.T1.15.15.15.3.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.15.15.15.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.15.15.15.3.1.m1.1.1.cmml\" xref=\"S5.T1.15.15.15.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.15.15.15.3.1.m1.1c\">\\pm</annotation></semantics></math> 2.44)</span></td>\n<td id=\"S5.T1.16.16.16.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.16.16.16.4.1\" class=\"ltx_text ltx_font_bold\">81.71 (<math id=\"S5.T1.16.16.16.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.16.16.16.4.1.m1.1a\"><mo id=\"S5.T1.16.16.16.4.1.m1.1.1\" xref=\"S5.T1.16.16.16.4.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.16.16.16.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.16.16.16.4.1.m1.1.1.cmml\" xref=\"S5.T1.16.16.16.4.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.16.16.16.4.1.m1.1c\">\\pm</annotation></semantics></math> 3.14)</span></td>\n</tr>\n<tr id=\"S5.T1.20.20.20\" class=\"ltx_tr\">\n<td id=\"S5.T1.20.20.20.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"6\"><span id=\"S5.T1.20.20.20.5.1\" class=\"ltx_text\">ResNet34</span></td>\n<td id=\"S5.T1.20.20.20.6\" class=\"ltx_td ltx_align_left ltx_border_t\">HeteroFL</td>\n<td id=\"S5.T1.17.17.17.1\" class=\"ltx_td ltx_align_center ltx_border_t\">79.51 (<math id=\"S5.T1.17.17.17.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.17.17.17.1.m1.1a\"><mo id=\"S5.T1.17.17.17.1.m1.1.1\" xref=\"S5.T1.17.17.17.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.17.17.17.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.17.17.17.1.m1.1.1.cmml\" xref=\"S5.T1.17.17.17.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.17.17.17.1.m1.1c\">\\pm</annotation></semantics></math> 0.44)</td>\n<td id=\"S5.T1.18.18.18.2\" class=\"ltx_td ltx_align_center ltx_border_t\">83.16 (<math id=\"S5.T1.18.18.18.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.18.18.18.2.m1.1a\"><mo id=\"S5.T1.18.18.18.2.m1.1.1\" xref=\"S5.T1.18.18.18.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.18.18.18.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.18.18.18.2.m1.1.1.cmml\" xref=\"S5.T1.18.18.18.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.18.18.18.2.m1.1c\">\\pm</annotation></semantics></math> 1.96)</td>\n<td id=\"S5.T1.20.20.20.7\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T1.19.19.19.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.03 (<math id=\"S5.T1.19.19.19.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.19.19.19.3.m1.1a\"><mo id=\"S5.T1.19.19.19.3.m1.1.1\" xref=\"S5.T1.19.19.19.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.19.19.19.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.19.19.19.3.m1.1.1.cmml\" xref=\"S5.T1.19.19.19.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.19.19.19.3.m1.1c\">\\pm</annotation></semantics></math> 1.34)</td>\n<td id=\"S5.T1.20.20.20.4\" class=\"ltx_td ltx_align_center ltx_border_t\">79.63 (<math id=\"S5.T1.20.20.20.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.20.20.20.4.m1.1a\"><mo id=\"S5.T1.20.20.20.4.m1.1.1\" xref=\"S5.T1.20.20.20.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.20.20.20.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.20.20.20.4.m1.1.1.cmml\" xref=\"S5.T1.20.20.20.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.20.20.20.4.m1.1c\">\\pm</annotation></semantics></math> 5.24)</td>\n</tr>\n<tr id=\"S5.T1.24.24.24\" class=\"ltx_tr\">\n<td id=\"S5.T1.24.24.24.5\" class=\"ltx_td ltx_align_left ltx_border_t\">FjORD</td>\n<td id=\"S5.T1.21.21.21.1\" class=\"ltx_td ltx_align_center ltx_border_t\">85.12 (<math id=\"S5.T1.21.21.21.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.21.21.21.1.m1.1a\"><mo id=\"S5.T1.21.21.21.1.m1.1.1\" xref=\"S5.T1.21.21.21.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.21.21.21.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.21.21.21.1.m1.1.1.cmml\" xref=\"S5.T1.21.21.21.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.21.21.21.1.m1.1c\">\\pm</annotation></semantics></math> 0.25)</td>\n<td id=\"S5.T1.22.22.22.2\" class=\"ltx_td ltx_align_center ltx_border_t\">87.36 (<math id=\"S5.T1.22.22.22.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.22.22.22.2.m1.1a\"><mo id=\"S5.T1.22.22.22.2.m1.1.1\" xref=\"S5.T1.22.22.22.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.22.22.22.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.22.22.22.2.m1.1.1.cmml\" xref=\"S5.T1.22.22.22.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.22.22.22.2.m1.1c\">\\pm</annotation></semantics></math> 1.19)</td>\n<td id=\"S5.T1.24.24.24.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T1.23.23.23.3\" class=\"ltx_td ltx_align_center ltx_border_t\">74.70 (<math id=\"S5.T1.23.23.23.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.23.23.23.3.m1.1a\"><mo id=\"S5.T1.23.23.23.3.m1.1.1\" xref=\"S5.T1.23.23.23.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.23.23.23.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.23.23.23.3.m1.1.1.cmml\" xref=\"S5.T1.23.23.23.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.23.23.23.3.m1.1c\">\\pm</annotation></semantics></math> 3.66)</td>\n<td id=\"S5.T1.24.24.24.4\" class=\"ltx_td ltx_align_center ltx_border_t\">76.01 (<math id=\"S5.T1.24.24.24.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.24.24.24.4.m1.1a\"><mo id=\"S5.T1.24.24.24.4.m1.1.1\" xref=\"S5.T1.24.24.24.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.24.24.24.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.24.24.24.4.m1.1.1.cmml\" xref=\"S5.T1.24.24.24.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.24.24.24.4.m1.1c\">\\pm</annotation></semantics></math> 5.24)</td>\n</tr>\n<tr id=\"S5.T1.28.28.28\" class=\"ltx_tr\">\n<td id=\"S5.T1.28.28.28.5\" class=\"ltx_td ltx_align_left ltx_border_t\">DepthFL</td>\n<td id=\"S5.T1.25.25.25.1\" class=\"ltx_td ltx_align_center ltx_border_t\">25.73 (<math id=\"S5.T1.25.25.25.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.25.25.25.1.m1.1a\"><mo id=\"S5.T1.25.25.25.1.m1.1.1\" xref=\"S5.T1.25.25.25.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.25.25.25.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.25.25.25.1.m1.1.1.cmml\" xref=\"S5.T1.25.25.25.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.25.25.25.1.m1.1c\">\\pm</annotation></semantics></math> 4.25)</td>\n<td id=\"S5.T1.26.26.26.2\" class=\"ltx_td ltx_align_center ltx_border_t\">75.30 (<math id=\"S5.T1.26.26.26.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.26.26.26.2.m1.1a\"><mo id=\"S5.T1.26.26.26.2.m1.1.1\" xref=\"S5.T1.26.26.26.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.26.26.26.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.26.26.26.2.m1.1.1.cmml\" xref=\"S5.T1.26.26.26.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.26.26.26.2.m1.1c\">\\pm</annotation></semantics></math> 24.88)</td>\n<td id=\"S5.T1.28.28.28.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T1.27.27.27.3\" class=\"ltx_td ltx_align_center ltx_border_t\">30.42 (<math id=\"S5.T1.27.27.27.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.27.27.27.3.m1.1a\"><mo id=\"S5.T1.27.27.27.3.m1.1.1\" xref=\"S5.T1.27.27.27.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.27.27.27.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.27.27.27.3.m1.1.1.cmml\" xref=\"S5.T1.27.27.27.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.27.27.27.3.m1.1c\">\\pm</annotation></semantics></math> 9.34)</td>\n<td id=\"S5.T1.28.28.28.4\" class=\"ltx_td ltx_align_center ltx_border_t\">70.76 (<math id=\"S5.T1.28.28.28.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.28.28.28.4.m1.1a\"><mo id=\"S5.T1.28.28.28.4.m1.1.1\" xref=\"S5.T1.28.28.28.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.28.28.28.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.28.28.28.4.m1.1.1.cmml\" xref=\"S5.T1.28.28.28.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.28.28.28.4.m1.1c\">\\pm</annotation></semantics></math> 21.04)</td>\n</tr>\n<tr id=\"S5.T1.32.32.32\" class=\"ltx_tr\">\n<td id=\"S5.T1.32.32.32.5\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span id=\"S5.T1.32.32.32.5.1\" class=\"ltx_text ltx_font_bold\">NeFL (ours)</span></td>\n<td id=\"S5.T1.29.29.29.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T1.29.29.29.1.1\" class=\"ltx_text ltx_font_bold\">87.71 (<math id=\"S5.T1.29.29.29.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.29.29.29.1.1.m1.1a\"><mo id=\"S5.T1.29.29.29.1.1.m1.1.1\" xref=\"S5.T1.29.29.29.1.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.29.29.29.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.29.29.29.1.1.m1.1.1.cmml\" xref=\"S5.T1.29.29.29.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.29.29.29.1.1.m1.1c\">\\pm</annotation></semantics></math> 0.37)</span></td>\n<td id=\"S5.T1.30.30.30.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T1.30.30.30.2.1\" class=\"ltx_text ltx_font_bold\">89.02 (<math id=\"S5.T1.30.30.30.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.30.30.30.2.1.m1.1a\"><mo id=\"S5.T1.30.30.30.2.1.m1.1.1\" xref=\"S5.T1.30.30.30.2.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.30.30.30.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.30.30.30.2.1.m1.1.1.cmml\" xref=\"S5.T1.30.30.30.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.30.30.30.2.1.m1.1c\">\\pm</annotation></semantics></math> 0.80)</span></td>\n<td id=\"S5.T1.32.32.32.6\" class=\"ltx_td ltx_border_bb ltx_border_t\"></td>\n<td id=\"S5.T1.31.31.31.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T1.31.31.31.3.1\" class=\"ltx_text ltx_font_bold\">80.76 (<math id=\"S5.T1.31.31.31.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.31.31.31.3.1.m1.1a\"><mo id=\"S5.T1.31.31.31.3.1.m1.1.1\" xref=\"S5.T1.31.31.31.3.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.31.31.31.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.31.31.31.3.1.m1.1.1.cmml\" xref=\"S5.T1.31.31.31.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.31.31.31.3.1.m1.1c\">\\pm</annotation></semantics></math> 2.82)</span></td>\n<td id=\"S5.T1.32.32.32.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T1.32.32.32.4.1\" class=\"ltx_text ltx_font_bold\">83.31 (<math id=\"S5.T1.32.32.32.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T1.32.32.32.4.1.m1.1a\"><mo id=\"S5.T1.32.32.32.4.1.m1.1.1\" xref=\"S5.T1.32.32.32.4.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.32.32.32.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.32.32.32.4.1.m1.1.1.cmml\" xref=\"S5.T1.32.32.32.4.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.32.32.32.4.1.m1.1c\">\\pm</annotation></semantics></math> 2.94)</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The experiments in Table 1 and Table 2 are evaluated with five submodels (Ns=5subscript𝑁𝑠5N_{s}=5 where γ1=0.2,γ2=0.4,γ3=0.6,γ4=0.8,γ5=1formulae-sequencesubscript𝛾10.2formulae-sequencesubscript𝛾20.4formulae-sequencesubscript𝛾30.6formulae-sequencesubscript𝛾40.8subscript𝛾51\\gamma_{1}=0.2,\\gamma_{2}=0.4,\\gamma_{3}=0.6,\\gamma_{4}=0.8,\\gamma_{5}=1) and the experiments in Table 3 are evaluated with three submodels (Ns=3subscript𝑁𝑠3N_{s}=3 where γ1=0.5,γ2=0.75,γ3=1formulae-sequencesubscript𝛾10.5formulae-sequencesubscript𝛾20.75subscript𝛾31\\gamma_{1}=0.5,\\gamma_{2}=0.75,\\gamma_{3}=1).\nPre-trained models we use for evaluation are trained on the ImageNet-1k dataset(Deng et al., 2009; Pyt, 2023). The pre-trained weights trained on ImageNet-1k dataset (Deng et al., 2009) are loaded on the initial global models and subsequently NeFL was performed.\nTo take system heterogeneity into account, each client is assigned one of the submodels at each iteration, and statistical heterogeneity was implemented by label distribution skew following the Dirichlet distribution with concentration parameter 0.50.50.5 (Yurochkin et al., 2019; Li et al., 2021a).\nTraining details are provided in Appendix B.1.",
            "For fair comparison across different baselines, we designed each submodel to have similar number of parameters (Table 8 in Appendix A). As illustrated in Table 1, NeFL outperforms baselines in terms of both the performance of the worst-case submodel (γ=0.2𝛾0.2\\gamma=0.2) and the average performance across five submodels in IID and non-IID settings. Notably, the performance gain is greater in non-IID settings, which belong to practical FL scenarios. It is worth noting that our proposed depthwise scaling method has performance gain over depthwise scaling baselines, while our proposed widthwise scaling method also has performance gain over widthwise scaling baselines (refer to the Appendix A).\nFurthermore, beyond the performance gain from using depthwise or widthwise scaled submodels, NeFL provides a federated averaging method that can incorporate widthwise or/and depthwise scaled submodels. This characteristic of embracing any submodel with different architecture extracted from a single global model enhances flexibility, enabling more clients to participate in the FL pipeline.",
            "For analyzing and experiments for ablation study we refer NeFL-W that all submodels are scaled widthwise, NeFL-D that all submodels are scaled depthwise and NeFL-WD that submodels are scaled both widthwise and depthwise.\nWe further refer to NeFL-DO that has different initial step sizes with NeFL-D.\nReferring to Table 13, NeFL-DO has larger magnitude step sizes aligning with the principles of ODE solver, compared to NeFL-D.\nNeFL-D scales submodels by skipping a subset of blocks of a global model, thus reducing the depth of the model. NeFL-D does not compensate for the skipped blocks by using larger step sizes. For example, a submodel in NeFL-D is given the initial step sizes as s0=1,s1=1,s2=0formulae-sequencesubscript𝑠01formulae-sequencesubscript𝑠11subscript𝑠20s_{0}=1,s_{1}=1,s_{2}=0 and output after Block 222 without Block 222 is 𝐘3=𝐘0+F0+F1subscript𝐘3subscript𝐘0subscript𝐹0subscript𝐹1\\mathbf{Y}_{3}=\\mathbf{Y}_{0}+F_{0}+F_{1}.\nMeanwhile, NeFL-DO reduces the size of the global model by skipping a subset of block functions F​(⋅)𝐹⋅F(\\cdot) and gives larger initial step sizes to compensate it. The step sizes are determined based on the number of blocks that are skipped. For a submodel without Block 222, initial output after Block 222 is initially computed as 𝐘3=𝐘0+F0+2​F1subscript𝐘3subscript𝐘0subscript𝐹02subscript𝐹1\\mathbf{Y}_{3}=\\mathbf{Y}_{0}+F_{0}+2F_{1} given s0=1,s1=2,s2=0formulae-sequencesubscript𝑠01formulae-sequencesubscript𝑠12subscript𝑠20s_{0}=1,s_{1}=2,s_{2}=0. We also refer that submodel with no learnable step sizes by N/L (i.e., constant step sizes are kept with given intial values).",
            "The experiments in Table 1, Table 2, Table 4, Table 5 and Table 6 are evaluated by a total 500 communication rounds (T𝑇T) with 100 clients (M𝑀M). At each round, a fraction rate of 0.10.10.1 is used, indicating that 10 clients (|𝒞t|=10subscript𝒞𝑡10|\\mathcal{C}_{t}|=10) transmit their weights to the server.\nDuring the training process of clients, local batch size of 323232 and a local epoch of E=5𝐸5E=5 are used.\nFor training, we employ SGD optimizer (Ruder, 2016) without momentum and weight decay. The initial learning rate is set to 0.10.10.1 and decreases by a factor of 110110\\frac{1}{10} at the halfway point and 3434\\frac{3}{4} of the total communication rounds.\nThe experiments in Table 3 are evaluated with the number of clients is M=10𝑀10M=10, all of whom participate in the NeFL pipeline (with a fraction rate of 111). The experiment consists of T=100𝑇100T=100 communication rounds, and each client performs local training for a single epoch (E=1𝐸1E=1). We use a cosine annealing learning rate scheduling (Loshchilov & Hutter, 2017) with 500 steps of warmup and an initial learning rate 0.03. The input images are resized to a size of 256256256 and randomly cropped to a size of 224224224 with a padding size of 282828. Note that utilizing layer normalization layers as consistent parameters, as opposed to BN layers that are inconsistent parameters, yields better performance.",
            "For the experiments presented in Table 1, Table 2, Table 4, Table 5 and Table 6, we consider five submodels with 𝜸=[γ1,γ2,γ3,γ4,γ5]=[0.2,0.4,0.6,0.8,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾3subscript𝛾4subscript𝛾50.20.40.60.81\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3},\\gamma_{4},\\gamma_{5}\\right]=\\left[0.2,0.4,0.6,0.8,1\\right] and 𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=\\left[0.04,0.16,0.36,0.64,1\\right] for Table 9. Additionally, for Table 3, we use three submodels with 𝜸=[γ1,γ2,γ3]=[0.5,0.75,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾30.50.751\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3}\\right]=\\left[0.5,0.75,1\\right]. Submodel details for ResNets and ViTs are detailed in Table 10 (ResNet18), Table 11 (ResNet34), Table 13 (ResNet56), Table 15 (ResNet110), Table 15 (Wide ResNet101_2) and Table 13 (ViT-B/16\nIn the tables, 1’s and 0’s denote the initial values of step sizes. A step size of zero indicates that a submodel does not include the corresponding block.\nNote that ResNets have a step size parameters for each block while ViTs have different step size parameters to be multiplied with SA and FFN.\nSubmodels in NeFL-W are characterized by 𝜸D=[1,…,1]subscript𝜸𝐷1…1\\bm{\\gamma}_{D}=[1,\\dots,1] and 𝜸Wsubscript𝜸𝑊\\bm{\\gamma}_{W} with a target size, while submodels in NeFL-D are characterized by 𝜸W=[1,…,1]subscript𝜸𝑊1…1\\bm{\\gamma}_{W}=[1,\\dots,1] and 𝜸Dsubscript𝜸𝐷\\bm{\\gamma}_{D} with a target size. Submodels in NeFL-WD are characterized by target size 𝜸W​𝜸Dsubscript𝜸𝑊subscript𝜸𝐷\\bm{\\gamma}_{W}\\bm{\\gamma}_{D}.\nCorresponding number of parameters and FLOPs are provided in Table 8.",
            "We simulate a dynamic environment by randomly selecting which submodel to be trained by each client during every communication round. In our experiments for Table 1, Table 2, Table 4, Table 5 and Table 6, we have an equal number of five tiers of clients (M/Ns=20𝑀subscript𝑁𝑠20M/N_{s}=20 for all tiers of clients). The resource-constrained clients (tier 1) randomly select models between 𝜸=0.2,0.4,0.6𝜸0.20.40.6\\bm{\\gamma}=0.2,0.4,0.6, clients in tier 2 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8𝜸0.20.40.60.8\\bm{\\gamma}=0.2,0.4,0.6,0.8, clients in tier 3 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8,1𝜸0.20.40.60.81\\bm{\\gamma}=0.2,0.4,0.6,0.8,1, clients in tier 4 randomly select models from the set 𝜸=0.4,0.6,0.8,1𝜸0.40.60.81\\bm{\\gamma}=0.4,0.6,0.8,1, and the resource-richest clients (tier 5) randomly select models from the set 𝜸=0.6,0.8,1𝜸0.60.81\\bm{\\gamma}=0.6,0.8,1. In our experiments for Table 3 involving three submodels and 10 clients, the tier 1 clients (3 out of 10 total clients) select 𝜸=0.5𝜸0.5\\bm{\\gamma}=0.5, tier 2 clients (3 out of 10 total clients) select 𝜸=0.75𝜸0.75\\bm{\\gamma}=0.75 and tier 3 clients (4 out of 10 total clients) select 𝜸=1𝜸1\\bm{\\gamma}=1. By allowing clients to randomly choose from the available submodels, our setup reflects the dynamic nature in which clients may encounter communication computing bottlenecks during each iteration."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Results of NeFL employing pre-trained models as initial weights for CIFAR-10 dataset under IID (left) and non-IID (right) settings are presented: Top-1 classification accuracies (%) for the worst-case submodel and the average of the performance of five submodels.",
        "table": "<table id=\"S5.T2.32.32\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T2.32.32.33\" class=\"ltx_tr\">\n<td id=\"S5.T2.32.32.33.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T2.32.32.33.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S5.T2.32.32.33.2\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T2.32.32.33.2.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"S5.T2.32.32.33.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S5.T2.32.32.33.3.1\" class=\"ltx_text ltx_font_bold\">IID</span></td>\n<td id=\"S5.T2.32.32.33.4\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S5.T2.32.32.33.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S5.T2.32.32.33.5.1\" class=\"ltx_text ltx_font_bold\">non-IID</span></td>\n</tr>\n<tr id=\"S5.T2.32.32.34\" class=\"ltx_tr\">\n<td id=\"S5.T2.32.32.34.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.32.32.34.1.1\" class=\"ltx_text ltx_font_bold\">Worst</span></td>\n<td id=\"S5.T2.32.32.34.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.32.32.34.2.1\" class=\"ltx_text ltx_font_bold\">Avg</span></td>\n<td id=\"S5.T2.32.32.34.3\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T2.32.32.34.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.32.32.34.4.1\" class=\"ltx_text ltx_font_bold\">Worst</span></td>\n<td id=\"S5.T2.32.32.34.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.32.32.34.5.1\" class=\"ltx_text ltx_font_bold\">Avg</span></td>\n</tr>\n<tr id=\"S5.T2.4.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"4\">\n<span id=\"S5.T2.4.4.4.5.1\" class=\"ltx_text\"></span> <span id=\"S5.T2.4.4.4.5.2\" class=\"ltx_text\">\n<span id=\"S5.T2.4.4.4.5.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S5.T2.4.4.4.5.2.1.1\" class=\"ltx_tr\">\n<span id=\"S5.T2.4.4.4.5.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Pre-trained</span></span>\n<span id=\"S5.T2.4.4.4.5.2.1.2\" class=\"ltx_tr\">\n<span id=\"S5.T2.4.4.4.5.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">ResNet18</span></span>\n</span></span><span id=\"S5.T2.4.4.4.5.3\" class=\"ltx_text\"></span>\n</td>\n<td id=\"S5.T2.4.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_tt\">HeteroFL</td>\n<td id=\"S5.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">78.26 (<math id=\"S5.T2.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.1.1.1.1.m1.1a\"><mo id=\"S5.T2.1.1.1.1.m1.1.1\" xref=\"S5.T2.1.1.1.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T2.1.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.1.1.1.1.m1.1c\">\\pm</annotation></semantics></math> 0.15)</td>\n<td id=\"S5.T2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">84.48 (<math id=\"S5.T2.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.2.2.2.2.m1.1a\"><mo id=\"S5.T2.2.2.2.2.m1.1.1\" xref=\"S5.T2.2.2.2.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.2.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.2.2.2.2.m1.1.1.cmml\" xref=\"S5.T2.2.2.2.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.2.2.2.2.m1.1c\">\\pm</annotation></semantics></math> 3.04)</td>\n<td id=\"S5.T2.4.4.4.7\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S5.T2.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">71.95 (<math id=\"S5.T2.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.3.3.3.3.m1.1a\"><mo id=\"S5.T2.3.3.3.3.m1.1.1\" xref=\"S5.T2.3.3.3.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.3.3.3.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.3.3.3.3.m1.1.1.cmml\" xref=\"S5.T2.3.3.3.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.3.3.3.3.m1.1c\">\\pm</annotation></semantics></math> 1.32)</td>\n<td id=\"S5.T2.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">76.17 (<math id=\"S5.T2.4.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.4.4.4.4.m1.1a\"><mo id=\"S5.T2.4.4.4.4.m1.1.1\" xref=\"S5.T2.4.4.4.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.4.4.4.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.4.4.4.4.m1.1.1.cmml\" xref=\"S5.T2.4.4.4.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.4.4.4.4.m1.1c\">\\pm</annotation></semantics></math> 3.39)</td>\n</tr>\n<tr id=\"S5.T2.8.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T2.8.8.8.5\" class=\"ltx_td ltx_align_left ltx_border_t\">FjORD</td>\n<td id=\"S5.T2.5.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_t\">86.37 (<math id=\"S5.T2.5.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.5.5.5.1.m1.1a\"><mo id=\"S5.T2.5.5.5.1.m1.1.1\" xref=\"S5.T2.5.5.5.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.5.5.5.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.5.5.5.1.m1.1.1.cmml\" xref=\"S5.T2.5.5.5.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.5.5.5.1.m1.1c\">\\pm</annotation></semantics></math> 0.18)</td>\n<td id=\"S5.T2.6.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">88.91 (<math id=\"S5.T2.6.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.6.6.6.2.m1.1a\"><mo id=\"S5.T2.6.6.6.2.m1.1.1\" xref=\"S5.T2.6.6.6.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.6.6.6.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.6.6.6.2.m1.1.1.cmml\" xref=\"S5.T2.6.6.6.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.6.6.6.2.m1.1c\">\\pm</annotation></semantics></math> 1.37)</td>\n<td id=\"S5.T2.8.8.8.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T2.7.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">81.81 (<math id=\"S5.T2.7.7.7.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.7.7.7.3.m1.1a\"><mo id=\"S5.T2.7.7.7.3.m1.1.1\" xref=\"S5.T2.7.7.7.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.7.7.7.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.7.7.7.3.m1.1.1.cmml\" xref=\"S5.T2.7.7.7.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.7.7.7.3.m1.1c\">\\pm</annotation></semantics></math> 1.10)</td>\n<td id=\"S5.T2.8.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">81.96 (<math id=\"S5.T2.8.8.8.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.8.8.8.4.m1.1a\"><mo id=\"S5.T2.8.8.8.4.m1.1.1\" xref=\"S5.T2.8.8.8.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.8.8.8.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.8.8.8.4.m1.1.1.cmml\" xref=\"S5.T2.8.8.8.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.8.8.8.4.m1.1c\">\\pm</annotation></semantics></math> 5.76)</td>\n</tr>\n<tr id=\"S5.T2.12.12.12\" class=\"ltx_tr\">\n<td id=\"S5.T2.12.12.12.5\" class=\"ltx_td ltx_align_left ltx_border_t\">DepthFL</td>\n<td id=\"S5.T2.9.9.9.1\" class=\"ltx_td ltx_align_center ltx_border_t\">47.76 (<math id=\"S5.T2.9.9.9.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.9.9.9.1.m1.1a\"><mo id=\"S5.T2.9.9.9.1.m1.1.1\" xref=\"S5.T2.9.9.9.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.9.9.9.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.9.9.9.1.m1.1.1.cmml\" xref=\"S5.T2.9.9.9.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.9.9.9.1.m1.1c\">\\pm</annotation></semantics></math> 8.54)</td>\n<td id=\"S5.T2.10.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_t\">82.86 (<math id=\"S5.T2.10.10.10.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.10.10.10.2.m1.1a\"><mo id=\"S5.T2.10.10.10.2.m1.1.1\" xref=\"S5.T2.10.10.10.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.10.10.10.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.10.10.10.2.m1.1.1.cmml\" xref=\"S5.T2.10.10.10.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.10.10.10.2.m1.1c\">\\pm</annotation></semantics></math> 17.98)</td>\n<td id=\"S5.T2.12.12.12.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T2.11.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_t\">39.78 (<math id=\"S5.T2.11.11.11.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.11.11.11.3.m1.1a\"><mo id=\"S5.T2.11.11.11.3.m1.1.1\" xref=\"S5.T2.11.11.11.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.11.11.11.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.11.11.11.3.m1.1.1.cmml\" xref=\"S5.T2.11.11.11.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.11.11.11.3.m1.1c\">\\pm</annotation></semantics></math> 3.74)</td>\n<td id=\"S5.T2.12.12.12.4\" class=\"ltx_td ltx_align_center ltx_border_t\">67.71 (<math id=\"S5.T2.12.12.12.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.12.12.12.4.m1.1a\"><mo id=\"S5.T2.12.12.12.4.m1.1.1\" xref=\"S5.T2.12.12.12.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.12.12.12.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.12.12.12.4.m1.1.1.cmml\" xref=\"S5.T2.12.12.12.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.12.12.12.4.m1.1c\">\\pm</annotation></semantics></math> 16.88)</td>\n</tr>\n<tr id=\"S5.T2.16.16.16\" class=\"ltx_tr\">\n<td id=\"S5.T2.16.16.16.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T2.16.16.16.5.1\" class=\"ltx_text ltx_font_bold\">NeFL (ours)</span></td>\n<td id=\"S5.T2.13.13.13.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.13.13.13.1.1\" class=\"ltx_text ltx_font_bold\">88.61 (<math id=\"S5.T2.13.13.13.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.13.13.13.1.1.m1.1a\"><mo id=\"S5.T2.13.13.13.1.1.m1.1.1\" xref=\"S5.T2.13.13.13.1.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.13.13.13.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.13.13.13.1.1.m1.1.1.cmml\" xref=\"S5.T2.13.13.13.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.13.13.13.1.1.m1.1c\">\\pm</annotation></semantics></math> 0.08)</span></td>\n<td id=\"S5.T2.14.14.14.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.14.14.14.2.1\" class=\"ltx_text ltx_font_bold\">89.60 (<math id=\"S5.T2.14.14.14.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.14.14.14.2.1.m1.1a\"><mo id=\"S5.T2.14.14.14.2.1.m1.1.1\" xref=\"S5.T2.14.14.14.2.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.14.14.14.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.14.14.14.2.1.m1.1.1.cmml\" xref=\"S5.T2.14.14.14.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.14.14.14.2.1.m1.1c\">\\pm</annotation></semantics></math> 0.70)</span></td>\n<td id=\"S5.T2.16.16.16.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T2.15.15.15.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.15.15.15.3.1\" class=\"ltx_text ltx_font_bold\">82.91 (<math id=\"S5.T2.15.15.15.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.15.15.15.3.1.m1.1a\"><mo id=\"S5.T2.15.15.15.3.1.m1.1.1\" xref=\"S5.T2.15.15.15.3.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.15.15.15.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.15.15.15.3.1.m1.1.1.cmml\" xref=\"S5.T2.15.15.15.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.15.15.15.3.1.m1.1c\">\\pm</annotation></semantics></math> 0.47)</span></td>\n<td id=\"S5.T2.16.16.16.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.16.16.16.4.1\" class=\"ltx_text ltx_font_bold\">85.85 (<math id=\"S5.T2.16.16.16.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.16.16.16.4.1.m1.1a\"><mo id=\"S5.T2.16.16.16.4.1.m1.1.1\" xref=\"S5.T2.16.16.16.4.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.16.16.16.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.16.16.16.4.1.m1.1.1.cmml\" xref=\"S5.T2.16.16.16.4.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.16.16.16.4.1.m1.1c\">\\pm</annotation></semantics></math> 2.43)</span></td>\n</tr>\n<tr id=\"S5.T2.20.20.20\" class=\"ltx_tr\">\n<td id=\"S5.T2.20.20.20.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"6\">\n<span id=\"S5.T2.20.20.20.5.1\" class=\"ltx_text\"></span> <span id=\"S5.T2.20.20.20.5.2\" class=\"ltx_text\">\n<span id=\"S5.T2.20.20.20.5.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S5.T2.20.20.20.5.2.1.1\" class=\"ltx_tr\">\n<span id=\"S5.T2.20.20.20.5.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Pre-trained</span></span>\n<span id=\"S5.T2.20.20.20.5.2.1.2\" class=\"ltx_tr\">\n<span id=\"S5.T2.20.20.20.5.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">ResNet34</span></span>\n</span></span><span id=\"S5.T2.20.20.20.5.3\" class=\"ltx_text\"></span>\n</td>\n<td id=\"S5.T2.20.20.20.6\" class=\"ltx_td ltx_align_left ltx_border_t\">HeteroFL</td>\n<td id=\"S5.T2.17.17.17.1\" class=\"ltx_td ltx_align_center ltx_border_t\">79.97 (<math id=\"S5.T2.17.17.17.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.17.17.17.1.m1.1a\"><mo id=\"S5.T2.17.17.17.1.m1.1.1\" xref=\"S5.T2.17.17.17.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.17.17.17.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.17.17.17.1.m1.1.1.cmml\" xref=\"S5.T2.17.17.17.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.17.17.17.1.m1.1c\">\\pm</annotation></semantics></math> 0.53)</td>\n<td id=\"S5.T2.18.18.18.2\" class=\"ltx_td ltx_align_center ltx_border_t\">84.34 (<math id=\"S5.T2.18.18.18.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.18.18.18.2.m1.1a\"><mo id=\"S5.T2.18.18.18.2.m1.1.1\" xref=\"S5.T2.18.18.18.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.18.18.18.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.18.18.18.2.m1.1.1.cmml\" xref=\"S5.T2.18.18.18.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.18.18.18.2.m1.1c\">\\pm</annotation></semantics></math> 2.33)</td>\n<td id=\"S5.T2.20.20.20.7\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T2.19.19.19.3\" class=\"ltx_td ltx_align_center ltx_border_t\">72.33 (<math id=\"S5.T2.19.19.19.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.19.19.19.3.m1.1a\"><mo id=\"S5.T2.19.19.19.3.m1.1.1\" xref=\"S5.T2.19.19.19.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.19.19.19.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.19.19.19.3.m1.1.1.cmml\" xref=\"S5.T2.19.19.19.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.19.19.19.3.m1.1c\">\\pm</annotation></semantics></math> 1.59)</td>\n<td id=\"S5.T2.20.20.20.4\" class=\"ltx_td ltx_align_center ltx_border_t\">78.2 (<math id=\"S5.T2.20.20.20.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.20.20.20.4.m1.1a\"><mo id=\"S5.T2.20.20.20.4.m1.1.1\" xref=\"S5.T2.20.20.20.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.20.20.20.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.20.20.20.4.m1.1.1.cmml\" xref=\"S5.T2.20.20.20.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.20.20.20.4.m1.1c\">\\pm</annotation></semantics></math> 3.29)</td>\n</tr>\n<tr id=\"S5.T2.24.24.24\" class=\"ltx_tr\">\n<td id=\"S5.T2.24.24.24.5\" class=\"ltx_td ltx_align_left ltx_border_t\">FjORD</td>\n<td id=\"S5.T2.21.21.21.1\" class=\"ltx_td ltx_align_center ltx_border_t\">87.08 (<math id=\"S5.T2.21.21.21.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.21.21.21.1.m1.1a\"><mo id=\"S5.T2.21.21.21.1.m1.1.1\" xref=\"S5.T2.21.21.21.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.21.21.21.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.21.21.21.1.m1.1.1.cmml\" xref=\"S5.T2.21.21.21.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.21.21.21.1.m1.1c\">\\pm</annotation></semantics></math> 0.29)</td>\n<td id=\"S5.T2.22.22.22.2\" class=\"ltx_td ltx_align_center ltx_border_t\">89.37 (<math id=\"S5.T2.22.22.22.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.22.22.22.2.m1.1a\"><mo id=\"S5.T2.22.22.22.2.m1.1.1\" xref=\"S5.T2.22.22.22.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.22.22.22.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.22.22.22.2.m1.1.1.cmml\" xref=\"S5.T2.22.22.22.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.22.22.22.2.m1.1c\">\\pm</annotation></semantics></math> 1.30)</td>\n<td id=\"S5.T2.24.24.24.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T2.23.23.23.3\" class=\"ltx_td ltx_align_center ltx_border_t\">78.2 (<math id=\"S5.T2.23.23.23.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.23.23.23.3.m1.1a\"><mo id=\"S5.T2.23.23.23.3.m1.1.1\" xref=\"S5.T2.23.23.23.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.23.23.23.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.23.23.23.3.m1.1.1.cmml\" xref=\"S5.T2.23.23.23.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.23.23.23.3.m1.1c\">\\pm</annotation></semantics></math> 4.39)</td>\n<td id=\"S5.T2.24.24.24.4\" class=\"ltx_td ltx_align_center ltx_border_t\">78.90 (<math id=\"S5.T2.24.24.24.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.24.24.24.4.m1.1a\"><mo id=\"S5.T2.24.24.24.4.m1.1.1\" xref=\"S5.T2.24.24.24.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.24.24.24.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.24.24.24.4.m1.1.1.cmml\" xref=\"S5.T2.24.24.24.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.24.24.24.4.m1.1c\">\\pm</annotation></semantics></math> 6.23)</td>\n</tr>\n<tr id=\"S5.T2.28.28.28\" class=\"ltx_tr\">\n<td id=\"S5.T2.28.28.28.5\" class=\"ltx_td ltx_align_left ltx_border_t\">DepthFL</td>\n<td id=\"S5.T2.25.25.25.1\" class=\"ltx_td ltx_align_center ltx_border_t\">52.08 (<math id=\"S5.T2.25.25.25.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.25.25.25.1.m1.1a\"><mo id=\"S5.T2.25.25.25.1.m1.1.1\" xref=\"S5.T2.25.25.25.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.25.25.25.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.25.25.25.1.m1.1.1.cmml\" xref=\"S5.T2.25.25.25.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.25.25.25.1.m1.1c\">\\pm</annotation></semantics></math> 5.30)</td>\n<td id=\"S5.T2.26.26.26.2\" class=\"ltx_td ltx_align_center ltx_border_t\">83.63 (<math id=\"S5.T2.26.26.26.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.26.26.26.2.m1.1a\"><mo id=\"S5.T2.26.26.26.2.m1.1.1\" xref=\"S5.T2.26.26.26.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.26.26.26.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.26.26.26.2.m1.1.1.cmml\" xref=\"S5.T2.26.26.26.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.26.26.26.2.m1.1c\">\\pm</annotation></semantics></math> 15.97)</td>\n<td id=\"S5.T2.28.28.28.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T2.27.27.27.3\" class=\"ltx_td ltx_align_center ltx_border_t\">42.09 (<math id=\"S5.T2.27.27.27.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.27.27.27.3.m1.1a\"><mo id=\"S5.T2.27.27.27.3.m1.1.1\" xref=\"S5.T2.27.27.27.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.27.27.27.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.27.27.27.3.m1.1.1.cmml\" xref=\"S5.T2.27.27.27.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.27.27.27.3.m1.1c\">\\pm</annotation></semantics></math> 2.79)</td>\n<td id=\"S5.T2.28.28.28.4\" class=\"ltx_td ltx_align_center ltx_border_t\">79.86 (<math id=\"S5.T2.28.28.28.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.28.28.28.4.m1.1a\"><mo id=\"S5.T2.28.28.28.4.m1.1.1\" xref=\"S5.T2.28.28.28.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.28.28.28.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.28.28.28.4.m1.1.1.cmml\" xref=\"S5.T2.28.28.28.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.28.28.28.4.m1.1c\">\\pm</annotation></semantics></math> 18.13)</td>\n</tr>\n<tr id=\"S5.T2.32.32.32\" class=\"ltx_tr\">\n<td id=\"S5.T2.32.32.32.5\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span id=\"S5.T2.32.32.32.5.1\" class=\"ltx_text ltx_font_bold\">NeFL (ours)</span></td>\n<td id=\"S5.T2.29.29.29.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T2.29.29.29.1.1\" class=\"ltx_text ltx_font_bold\">88.36 (<math id=\"S5.T2.29.29.29.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.29.29.29.1.1.m1.1a\"><mo id=\"S5.T2.29.29.29.1.1.m1.1.1\" xref=\"S5.T2.29.29.29.1.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.29.29.29.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.29.29.29.1.1.m1.1.1.cmml\" xref=\"S5.T2.29.29.29.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.29.29.29.1.1.m1.1c\">\\pm</annotation></semantics></math> 0.11)</span></td>\n<td id=\"S5.T2.30.30.30.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T2.30.30.30.2.1\" class=\"ltx_text ltx_font_bold\">91.14 (<math id=\"S5.T2.30.30.30.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.30.30.30.2.1.m1.1a\"><mo id=\"S5.T2.30.30.30.2.1.m1.1.1\" xref=\"S5.T2.30.30.30.2.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.30.30.30.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.30.30.30.2.1.m1.1.1.cmml\" xref=\"S5.T2.30.30.30.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.30.30.30.2.1.m1.1c\">\\pm</annotation></semantics></math> 1.42)</span></td>\n<td id=\"S5.T2.32.32.32.6\" class=\"ltx_td ltx_border_bb ltx_border_t\"></td>\n<td id=\"S5.T2.31.31.31.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T2.31.31.31.3.1\" class=\"ltx_text ltx_font_bold\">83.62 (<math id=\"S5.T2.31.31.31.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.31.31.31.3.1.m1.1a\"><mo id=\"S5.T2.31.31.31.3.1.m1.1.1\" xref=\"S5.T2.31.31.31.3.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.31.31.31.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.31.31.31.3.1.m1.1.1.cmml\" xref=\"S5.T2.31.31.31.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.31.31.31.3.1.m1.1c\">\\pm</annotation></semantics></math> 0.68)</span></td>\n<td id=\"S5.T2.32.32.32.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T2.32.32.32.4.1\" class=\"ltx_text ltx_font_bold\">86.48 (<math id=\"S5.T2.32.32.32.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T2.32.32.32.4.1.m1.1a\"><mo id=\"S5.T2.32.32.32.4.1.m1.1.1\" xref=\"S5.T2.32.32.32.4.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.32.32.32.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T2.32.32.32.4.1.m1.1.1.cmml\" xref=\"S5.T2.32.32.32.4.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.32.32.32.4.1.m1.1c\">\\pm</annotation></semantics></math> 2.18)</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The experiments in Table 1 and Table 2 are evaluated with five submodels (Ns=5subscript𝑁𝑠5N_{s}=5 where γ1=0.2,γ2=0.4,γ3=0.6,γ4=0.8,γ5=1formulae-sequencesubscript𝛾10.2formulae-sequencesubscript𝛾20.4formulae-sequencesubscript𝛾30.6formulae-sequencesubscript𝛾40.8subscript𝛾51\\gamma_{1}=0.2,\\gamma_{2}=0.4,\\gamma_{3}=0.6,\\gamma_{4}=0.8,\\gamma_{5}=1) and the experiments in Table 3 are evaluated with three submodels (Ns=3subscript𝑁𝑠3N_{s}=3 where γ1=0.5,γ2=0.75,γ3=1formulae-sequencesubscript𝛾10.5formulae-sequencesubscript𝛾20.75subscript𝛾31\\gamma_{1}=0.5,\\gamma_{2}=0.75,\\gamma_{3}=1).\nPre-trained models we use for evaluation are trained on the ImageNet-1k dataset(Deng et al., 2009; Pyt, 2023). The pre-trained weights trained on ImageNet-1k dataset (Deng et al., 2009) are loaded on the initial global models and subsequently NeFL was performed.\nTo take system heterogeneity into account, each client is assigned one of the submodels at each iteration, and statistical heterogeneity was implemented by label distribution skew following the Dirichlet distribution with concentration parameter 0.50.50.5 (Yurochkin et al., 2019; Li et al., 2021a).\nTraining details are provided in Appendix B.1.",
            "We investigate the performance improvement from incorporating pre-trained models into NeFL and verify that NeFL is still effective when employing pre-trained models. Recent studies on FL have figured out that FL gets benefits from pre-trained models even more than centralized learning (Kolesnikov et al., 2020; Chen et al., 2023). It motivates us to evaluate the performance of NeFL on pre-trained models. The pre-trained model that is trained in a common way using ImageNet-1k is loaded from PyTorch (Paszke et al., 2019).\nEven when a pre-trained model was trained as a full model without any submodel being trained, NeFL made better performance with these pre-trained models.\nThe results in Table 2 show that the performance of NeFL has been enhanced through pre-training in both IID and non-IID settings following the results of the recent studies. Meanwhile, baselines such as HeteroFL and DepthFL, which do not have any inconsistent parameters, have no effective performance gain when trained with pre-trained models compared to to models trained from scratch.",
            "The experiments in Table 1, Table 2, Table 4, Table 5 and Table 6 are evaluated by a total 500 communication rounds (T𝑇T) with 100 clients (M𝑀M). At each round, a fraction rate of 0.10.10.1 is used, indicating that 10 clients (|𝒞t|=10subscript𝒞𝑡10|\\mathcal{C}_{t}|=10) transmit their weights to the server.\nDuring the training process of clients, local batch size of 323232 and a local epoch of E=5𝐸5E=5 are used.\nFor training, we employ SGD optimizer (Ruder, 2016) without momentum and weight decay. The initial learning rate is set to 0.10.10.1 and decreases by a factor of 110110\\frac{1}{10} at the halfway point and 3434\\frac{3}{4} of the total communication rounds.\nThe experiments in Table 3 are evaluated with the number of clients is M=10𝑀10M=10, all of whom participate in the NeFL pipeline (with a fraction rate of 111). The experiment consists of T=100𝑇100T=100 communication rounds, and each client performs local training for a single epoch (E=1𝐸1E=1). We use a cosine annealing learning rate scheduling (Loshchilov & Hutter, 2017) with 500 steps of warmup and an initial learning rate 0.03. The input images are resized to a size of 256256256 and randomly cropped to a size of 224224224 with a padding size of 282828. Note that utilizing layer normalization layers as consistent parameters, as opposed to BN layers that are inconsistent parameters, yields better performance.",
            "For the experiments presented in Table 1, Table 2, Table 4, Table 5 and Table 6, we consider five submodels with 𝜸=[γ1,γ2,γ3,γ4,γ5]=[0.2,0.4,0.6,0.8,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾3subscript𝛾4subscript𝛾50.20.40.60.81\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3},\\gamma_{4},\\gamma_{5}\\right]=\\left[0.2,0.4,0.6,0.8,1\\right] and 𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=\\left[0.04,0.16,0.36,0.64,1\\right] for Table 9. Additionally, for Table 3, we use three submodels with 𝜸=[γ1,γ2,γ3]=[0.5,0.75,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾30.50.751\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3}\\right]=\\left[0.5,0.75,1\\right]. Submodel details for ResNets and ViTs are detailed in Table 10 (ResNet18), Table 11 (ResNet34), Table 13 (ResNet56), Table 15 (ResNet110), Table 15 (Wide ResNet101_2) and Table 13 (ViT-B/16\nIn the tables, 1’s and 0’s denote the initial values of step sizes. A step size of zero indicates that a submodel does not include the corresponding block.\nNote that ResNets have a step size parameters for each block while ViTs have different step size parameters to be multiplied with SA and FFN.\nSubmodels in NeFL-W are characterized by 𝜸D=[1,…,1]subscript𝜸𝐷1…1\\bm{\\gamma}_{D}=[1,\\dots,1] and 𝜸Wsubscript𝜸𝑊\\bm{\\gamma}_{W} with a target size, while submodels in NeFL-D are characterized by 𝜸W=[1,…,1]subscript𝜸𝑊1…1\\bm{\\gamma}_{W}=[1,\\dots,1] and 𝜸Dsubscript𝜸𝐷\\bm{\\gamma}_{D} with a target size. Submodels in NeFL-WD are characterized by target size 𝜸W​𝜸Dsubscript𝜸𝑊subscript𝜸𝐷\\bm{\\gamma}_{W}\\bm{\\gamma}_{D}.\nCorresponding number of parameters and FLOPs are provided in Table 8.",
            "The pre-trained models on Table 2 and Table 3 are trained on ImageNet-1k (Deng et al., 2009) as following recipes (Pyt, 2023):",
            "We simulate a dynamic environment by randomly selecting which submodel to be trained by each client during every communication round. In our experiments for Table 1, Table 2, Table 4, Table 5 and Table 6, we have an equal number of five tiers of clients (M/Ns=20𝑀subscript𝑁𝑠20M/N_{s}=20 for all tiers of clients). The resource-constrained clients (tier 1) randomly select models between 𝜸=0.2,0.4,0.6𝜸0.20.40.6\\bm{\\gamma}=0.2,0.4,0.6, clients in tier 2 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8𝜸0.20.40.60.8\\bm{\\gamma}=0.2,0.4,0.6,0.8, clients in tier 3 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8,1𝜸0.20.40.60.81\\bm{\\gamma}=0.2,0.4,0.6,0.8,1, clients in tier 4 randomly select models from the set 𝜸=0.4,0.6,0.8,1𝜸0.40.60.81\\bm{\\gamma}=0.4,0.6,0.8,1, and the resource-richest clients (tier 5) randomly select models from the set 𝜸=0.6,0.8,1𝜸0.60.81\\bm{\\gamma}=0.6,0.8,1. In our experiments for Table 3 involving three submodels and 10 clients, the tier 1 clients (3 out of 10 total clients) select 𝜸=0.5𝜸0.5\\bm{\\gamma}=0.5, tier 2 clients (3 out of 10 total clients) select 𝜸=0.75𝜸0.75\\bm{\\gamma}=0.75 and tier 3 clients (4 out of 10 total clients) select 𝜸=1𝜸1\\bm{\\gamma}=1. By allowing clients to randomly choose from the available submodels, our setup reflects the dynamic nature in which clients may encounter communication computing bottlenecks during each iteration."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Results of NeFL with three submodels for CIFAR-10 dataset under IID (left) and non-IID (right) settings. A initial weights for global model was given with the pre-trained model with ImageNet-1k. We report Top-1 classification accuracies (%) for the submodels.",
        "table": "<table id=\"S5.T3.8.8\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T3.8.8.9\" class=\"ltx_tr\">\n<td id=\"S5.T3.8.8.9.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T3.8.8.9.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S5.T3.8.8.9.2\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T3.8.8.9.2.1\" class=\"ltx_text ltx_font_bold\">Param. #</span></td>\n<td id=\"S5.T3.8.8.9.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S5.T3.8.8.9.3.1\" class=\"ltx_text ltx_font_bold\">IID</span></td>\n<td id=\"S5.T3.8.8.9.4\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S5.T3.8.8.9.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S5.T3.8.8.9.5.1\" class=\"ltx_text ltx_font_bold\">non-IID</span></td>\n</tr>\n<tr id=\"S5.T3.8.8.10\" class=\"ltx_tr\">\n<td id=\"S5.T3.8.8.10.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.8.8.10.1.1\" class=\"ltx_text ltx_font_bold\">Worst</span></td>\n<td id=\"S5.T3.8.8.10.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.8.8.10.2.1\" class=\"ltx_text ltx_font_bold\">Avg</span></td>\n<td id=\"S5.T3.8.8.10.3\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T3.8.8.10.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.8.8.10.4.1\" class=\"ltx_text ltx_font_bold\">Worst</span></td>\n<td id=\"S5.T3.8.8.10.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.8.8.10.5.1\" class=\"ltx_text ltx_font_bold\">Avg</span></td>\n</tr>\n<tr id=\"S5.T3.4.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T3.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">Pre-trained ViT</td>\n<td id=\"S5.T3.4.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_tt\">86.4M</td>\n<td id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">93.02 (<math id=\"S5.T3.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T3.1.1.1.1.m1.1a\"><mo id=\"S5.T3.1.1.1.1.m1.1.1\" xref=\"S5.T3.1.1.1.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T3.1.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.1.1.1.1.m1.1c\">\\pm</annotation></semantics></math> 0.06)</td>\n<td id=\"S5.T3.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">95.96 (<math id=\"S5.T3.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T3.2.2.2.2.m1.1a\"><mo id=\"S5.T3.2.2.2.2.m1.1.1\" xref=\"S5.T3.2.2.2.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.2.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T3.2.2.2.2.m1.1.1.cmml\" xref=\"S5.T3.2.2.2.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.2.2.2.2.m1.1c\">\\pm</annotation></semantics></math> 2.10)</td>\n<td id=\"S5.T3.4.4.4.7\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S5.T3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">87.56 (<math id=\"S5.T3.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T3.3.3.3.3.m1.1a\"><mo id=\"S5.T3.3.3.3.3.m1.1.1\" xref=\"S5.T3.3.3.3.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.3.3.3.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T3.3.3.3.3.m1.1.1.cmml\" xref=\"S5.T3.3.3.3.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.3.3.3.3.m1.1c\">\\pm</annotation></semantics></math> 0.16)</td>\n<td id=\"S5.T3.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">92.74 (<math id=\"S5.T3.4.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T3.4.4.4.4.m1.1a\"><mo id=\"S5.T3.4.4.4.4.m1.1.1\" xref=\"S5.T3.4.4.4.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.4.4.4.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T3.4.4.4.4.m1.1.1.cmml\" xref=\"S5.T3.4.4.4.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.4.4.4.4.m1.1c\">\\pm</annotation></semantics></math> 3.95)</td>\n</tr>\n<tr id=\"S5.T3.8.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T3.8.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">Pre-trained Wide ResNet101</td>\n<td id=\"S5.T3.8.8.8.6\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">124.8M</td>\n<td id=\"S5.T3.5.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">90.9 (<math id=\"S5.T3.5.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T3.5.5.5.1.m1.1a\"><mo id=\"S5.T3.5.5.5.1.m1.1.1\" xref=\"S5.T3.5.5.5.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.5.5.5.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T3.5.5.5.1.m1.1.1.cmml\" xref=\"S5.T3.5.5.5.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.5.5.5.1.m1.1c\">\\pm</annotation></semantics></math> 0.16)</td>\n<td id=\"S5.T3.6.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">91.35 (<math id=\"S5.T3.6.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T3.6.6.6.2.m1.1a\"><mo id=\"S5.T3.6.6.6.2.m1.1.1\" xref=\"S5.T3.6.6.6.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.6.6.6.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T3.6.6.6.2.m1.1.1.cmml\" xref=\"S5.T3.6.6.6.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.6.6.6.2.m1.1c\">\\pm</annotation></semantics></math> 0.39)</td>\n<td id=\"S5.T3.8.8.8.7\" class=\"ltx_td ltx_border_bb ltx_border_t\"></td>\n<td id=\"S5.T3.7.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">87.17 (<math id=\"S5.T3.7.7.7.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T3.7.7.7.3.m1.1a\"><mo id=\"S5.T3.7.7.7.3.m1.1.1\" xref=\"S5.T3.7.7.7.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.7.7.7.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T3.7.7.7.3.m1.1.1.cmml\" xref=\"S5.T3.7.7.7.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.7.7.7.3.m1.1c\">\\pm</annotation></semantics></math> 0.04)</td>\n<td id=\"S5.T3.8.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">87.74 (<math id=\"S5.T3.8.8.8.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S5.T3.8.8.8.4.m1.1a\"><mo id=\"S5.T3.8.8.8.4.m1.1.1\" xref=\"S5.T3.8.8.8.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.8.8.8.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T3.8.8.8.4.m1.1.1.cmml\" xref=\"S5.T3.8.8.8.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.8.8.8.4.m1.1c\">\\pm</annotation></semantics></math> 1.06)</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The experiments in Table 1 and Table 2 are evaluated with five submodels (Ns=5subscript𝑁𝑠5N_{s}=5 where γ1=0.2,γ2=0.4,γ3=0.6,γ4=0.8,γ5=1formulae-sequencesubscript𝛾10.2formulae-sequencesubscript𝛾20.4formulae-sequencesubscript𝛾30.6formulae-sequencesubscript𝛾40.8subscript𝛾51\\gamma_{1}=0.2,\\gamma_{2}=0.4,\\gamma_{3}=0.6,\\gamma_{4}=0.8,\\gamma_{5}=1) and the experiments in Table 3 are evaluated with three submodels (Ns=3subscript𝑁𝑠3N_{s}=3 where γ1=0.5,γ2=0.75,γ3=1formulae-sequencesubscript𝛾10.5formulae-sequencesubscript𝛾20.75subscript𝛾31\\gamma_{1}=0.5,\\gamma_{2}=0.75,\\gamma_{3}=1).\nPre-trained models we use for evaluation are trained on the ImageNet-1k dataset(Deng et al., 2009; Pyt, 2023). The pre-trained weights trained on ImageNet-1k dataset (Deng et al., 2009) are loaded on the initial global models and subsequently NeFL was performed.\nTo take system heterogeneity into account, each client is assigned one of the submodels at each iteration, and statistical heterogeneity was implemented by label distribution skew following the Dirichlet distribution with concentration parameter 0.50.50.5 (Yurochkin et al., 2019; Li et al., 2021a).\nTraining details are provided in Appendix B.1.",
            "We now present an experiment using ViTs and Wide ResNet (Zagoruyko & Komodakis, 2016) on NeFL.\nPrevious studies have examined the effectiveness of ViTs in FL scenarios, and it has been observed that ViTs can effectively alleviate the adverse effects of statistical heterogeneity due to their inherent robustness to distribution shifts (Qu et al., 2022). Building upon this line of research, Table 3 demonstrates that ViTs outperform ResNets in our framework, with the larger number of parameters, in both IID and non-IID settings. Particularly in non-IID settings, ViTs exhibit less performance degradation of average performance when compared to IID settings. Note that when comparing the performance gap between IID and non-IID settings, the worst-case ViT submodel experiences more degradation than the worst-case ResNet submodel. Nevertheless, despite this degradation, ViT still maintains higher performance than ResNet. Consequently, we verify that ViT on NeFL is also effective following the results in Qu et al. (2022).",
            "The experiments in Table 1, Table 2, Table 4, Table 5 and Table 6 are evaluated by a total 500 communication rounds (T𝑇T) with 100 clients (M𝑀M). At each round, a fraction rate of 0.10.10.1 is used, indicating that 10 clients (|𝒞t|=10subscript𝒞𝑡10|\\mathcal{C}_{t}|=10) transmit their weights to the server.\nDuring the training process of clients, local batch size of 323232 and a local epoch of E=5𝐸5E=5 are used.\nFor training, we employ SGD optimizer (Ruder, 2016) without momentum and weight decay. The initial learning rate is set to 0.10.10.1 and decreases by a factor of 110110\\frac{1}{10} at the halfway point and 3434\\frac{3}{4} of the total communication rounds.\nThe experiments in Table 3 are evaluated with the number of clients is M=10𝑀10M=10, all of whom participate in the NeFL pipeline (with a fraction rate of 111). The experiment consists of T=100𝑇100T=100 communication rounds, and each client performs local training for a single epoch (E=1𝐸1E=1). We use a cosine annealing learning rate scheduling (Loshchilov & Hutter, 2017) with 500 steps of warmup and an initial learning rate 0.03. The input images are resized to a size of 256256256 and randomly cropped to a size of 224224224 with a padding size of 282828. Note that utilizing layer normalization layers as consistent parameters, as opposed to BN layers that are inconsistent parameters, yields better performance.",
            "For the experiments presented in Table 1, Table 2, Table 4, Table 5 and Table 6, we consider five submodels with 𝜸=[γ1,γ2,γ3,γ4,γ5]=[0.2,0.4,0.6,0.8,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾3subscript𝛾4subscript𝛾50.20.40.60.81\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3},\\gamma_{4},\\gamma_{5}\\right]=\\left[0.2,0.4,0.6,0.8,1\\right] and 𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=\\left[0.04,0.16,0.36,0.64,1\\right] for Table 9. Additionally, for Table 3, we use three submodels with 𝜸=[γ1,γ2,γ3]=[0.5,0.75,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾30.50.751\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3}\\right]=\\left[0.5,0.75,1\\right]. Submodel details for ResNets and ViTs are detailed in Table 10 (ResNet18), Table 11 (ResNet34), Table 13 (ResNet56), Table 15 (ResNet110), Table 15 (Wide ResNet101_2) and Table 13 (ViT-B/16\nIn the tables, 1’s and 0’s denote the initial values of step sizes. A step size of zero indicates that a submodel does not include the corresponding block.\nNote that ResNets have a step size parameters for each block while ViTs have different step size parameters to be multiplied with SA and FFN.\nSubmodels in NeFL-W are characterized by 𝜸D=[1,…,1]subscript𝜸𝐷1…1\\bm{\\gamma}_{D}=[1,\\dots,1] and 𝜸Wsubscript𝜸𝑊\\bm{\\gamma}_{W} with a target size, while submodels in NeFL-D are characterized by 𝜸W=[1,…,1]subscript𝜸𝑊1…1\\bm{\\gamma}_{W}=[1,\\dots,1] and 𝜸Dsubscript𝜸𝐷\\bm{\\gamma}_{D} with a target size. Submodels in NeFL-WD are characterized by target size 𝜸W​𝜸Dsubscript𝜸𝑊subscript𝜸𝐷\\bm{\\gamma}_{W}\\bm{\\gamma}_{D}.\nCorresponding number of parameters and FLOPs are provided in Table 8.",
            "The pre-trained models on Table 2 and Table 3 are trained on ImageNet-1k (Deng et al., 2009) as following recipes (Pyt, 2023):",
            "We simulate a dynamic environment by randomly selecting which submodel to be trained by each client during every communication round. In our experiments for Table 1, Table 2, Table 4, Table 5 and Table 6, we have an equal number of five tiers of clients (M/Ns=20𝑀subscript𝑁𝑠20M/N_{s}=20 for all tiers of clients). The resource-constrained clients (tier 1) randomly select models between 𝜸=0.2,0.4,0.6𝜸0.20.40.6\\bm{\\gamma}=0.2,0.4,0.6, clients in tier 2 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8𝜸0.20.40.60.8\\bm{\\gamma}=0.2,0.4,0.6,0.8, clients in tier 3 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8,1𝜸0.20.40.60.81\\bm{\\gamma}=0.2,0.4,0.6,0.8,1, clients in tier 4 randomly select models from the set 𝜸=0.4,0.6,0.8,1𝜸0.40.60.81\\bm{\\gamma}=0.4,0.6,0.8,1, and the resource-richest clients (tier 5) randomly select models from the set 𝜸=0.6,0.8,1𝜸0.60.81\\bm{\\gamma}=0.6,0.8,1. In our experiments for Table 3 involving three submodels and 10 clients, the tier 1 clients (3 out of 10 total clients) select 𝜸=0.5𝜸0.5\\bm{\\gamma}=0.5, tier 2 clients (3 out of 10 total clients) select 𝜸=0.75𝜸0.75\\bm{\\gamma}=0.75 and tier 3 clients (4 out of 10 total clients) select 𝜸=1𝜸1\\bm{\\gamma}=1. By allowing clients to randomly choose from the available submodels, our setup reflects the dynamic nature in which clients may encounter communication computing bottlenecks during each iteration."
        ]
    },
    "A1.T4": {
        "caption": "Table 4: Results of NeFL with five submodels for CIFAR-100 (left), CINIC10 (center) and SVHN (right) dataset under IID settings. We report Top-1 classification accuracies (%) for the worst-case submodel and the average of the performance of five submodels.",
        "table": "<table id=\"A1.T4.7.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T4.7.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T4.7.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"A1.T4.7.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"A1.T4.7.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"A1.T4.7.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"A1.T4.7.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"A1.T4.7.1.1.3.1\" class=\"ltx_text ltx_font_bold\">CIFAR-100</span></td>\n<td id=\"A1.T4.7.1.1.4\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A1.T4.7.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"A1.T4.7.1.1.5.1\" class=\"ltx_text ltx_font_bold\">CINIC-10</span></td>\n<td id=\"A1.T4.7.1.1.6\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A1.T4.7.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"A1.T4.7.1.1.7.1\" class=\"ltx_text ltx_font_bold\">SVHN</span></td>\n</tr>\n<tr id=\"A1.T4.7.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T4.7.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Worst</td>\n<td id=\"A1.T4.7.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Avg</td>\n<td id=\"A1.T4.7.1.2.3\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Worst</td>\n<td id=\"A1.T4.7.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Avg</td>\n<td id=\"A1.T4.7.1.2.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">Worst</td>\n<td id=\"A1.T4.7.1.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\">Avg</td>\n</tr>\n<tr id=\"A1.T4.7.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T4.7.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"4\"><span id=\"A1.T4.7.1.3.1.1\" class=\"ltx_text\">ResNet18</span></td>\n<td id=\"A1.T4.7.1.3.2\" class=\"ltx_td ltx_align_left ltx_border_tt\">HeteroFL</td>\n<td id=\"A1.T4.7.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">41.33</td>\n<td id=\"A1.T4.7.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">47.09</td>\n<td id=\"A1.T4.7.1.3.5\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A1.T4.7.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">67.55</td>\n<td id=\"A1.T4.7.1.3.7\" class=\"ltx_td ltx_align_center ltx_border_tt\">70.40</td>\n<td id=\"A1.T4.7.1.3.8\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A1.T4.7.1.3.9\" class=\"ltx_td ltx_align_center ltx_border_tt\">91.82</td>\n<td id=\"A1.T4.7.1.3.10\" class=\"ltx_td ltx_align_center ltx_border_tt\">93.46</td>\n</tr>\n<tr id=\"A1.T4.7.1.4\" class=\"ltx_tr\">\n<td id=\"A1.T4.7.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FjORD</td>\n<td id=\"A1.T4.7.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">49.29</td>\n<td id=\"A1.T4.7.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">52.67</td>\n<td id=\"A1.T4.7.1.4.4\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">71.95</td>\n<td id=\"A1.T4.7.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\">74.98</td>\n<td id=\"A1.T4.7.1.4.7\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.4.8\" class=\"ltx_td ltx_align_center ltx_border_t\">94.31</td>\n<td id=\"A1.T4.7.1.4.9\" class=\"ltx_td ltx_align_center ltx_border_t\">93.97</td>\n</tr>\n<tr id=\"A1.T4.7.1.5\" class=\"ltx_tr\">\n<td id=\"A1.T4.7.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">DepthFL</td>\n<td id=\"A1.T4.7.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">31.68</td>\n<td id=\"A1.T4.7.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">49.56</td>\n<td id=\"A1.T4.7.1.5.4\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">54.51</td>\n<td id=\"A1.T4.7.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\">71.42</td>\n<td id=\"A1.T4.7.1.5.7\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.5.8\" class=\"ltx_td ltx_align_center ltx_border_t\">91.54</td>\n<td id=\"A1.T4.7.1.5.9\" class=\"ltx_td ltx_align_center ltx_border_t\">93.97</td>\n</tr>\n<tr id=\"A1.T4.7.1.6\" class=\"ltx_tr\">\n<td id=\"A1.T4.7.1.6.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T4.7.1.6.1.1\" class=\"ltx_text ltx_font_bold\">NeFL (ours)</span></td>\n<td id=\"A1.T4.7.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T4.7.1.6.2.1\" class=\"ltx_text ltx_font_bold\">52.63</span></td>\n<td id=\"A1.T4.7.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T4.7.1.6.3.1\" class=\"ltx_text ltx_font_bold\">53.62</span></td>\n<td id=\"A1.T4.7.1.6.4\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T4.7.1.6.5.1\" class=\"ltx_text ltx_font_bold\">74.16</span></td>\n<td id=\"A1.T4.7.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T4.7.1.6.6.1\" class=\"ltx_text ltx_font_bold\">75.29</span></td>\n<td id=\"A1.T4.7.1.6.7\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.6.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T4.7.1.6.8.1\" class=\"ltx_text ltx_font_bold\">94.45</span></td>\n<td id=\"A1.T4.7.1.6.9\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T4.7.1.6.9.1\" class=\"ltx_text ltx_font_bold\">94.94</span></td>\n</tr>\n<tr id=\"A1.T4.7.1.7\" class=\"ltx_tr\">\n<td id=\"A1.T4.7.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"6\"><span id=\"A1.T4.7.1.7.1.1\" class=\"ltx_text\">ResNet34</span></td>\n<td id=\"A1.T4.7.1.7.2\" class=\"ltx_td ltx_align_left ltx_border_t\">HeteroFL</td>\n<td id=\"A1.T4.7.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">34.96</td>\n<td id=\"A1.T4.7.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">39.75</td>\n<td id=\"A1.T4.7.1.7.5\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\">67.39</td>\n<td id=\"A1.T4.7.1.7.7\" class=\"ltx_td ltx_align_center ltx_border_t\">69.62</td>\n<td id=\"A1.T4.7.1.7.8\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.7.9\" class=\"ltx_td ltx_align_center ltx_border_t\">89.86</td>\n<td id=\"A1.T4.7.1.7.10\" class=\"ltx_td ltx_align_center ltx_border_t\">92.39</td>\n</tr>\n<tr id=\"A1.T4.7.1.8\" class=\"ltx_tr\">\n<td id=\"A1.T4.7.1.8.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FjORD</td>\n<td id=\"A1.T4.7.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">47.59</td>\n<td id=\"A1.T4.7.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">50.7</td>\n<td id=\"A1.T4.7.1.8.4\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\">71.58</td>\n<td id=\"A1.T4.7.1.8.6\" class=\"ltx_td ltx_align_center ltx_border_t\">74.19</td>\n<td id=\"A1.T4.7.1.8.7\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.8.8\" class=\"ltx_td ltx_align_center ltx_border_t\">93.83</td>\n<td id=\"A1.T4.7.1.8.9\" class=\"ltx_td ltx_align_center ltx_border_t\">94.63</td>\n</tr>\n<tr id=\"A1.T4.7.1.9\" class=\"ltx_tr\">\n<td id=\"A1.T4.7.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">DepthFL</td>\n<td id=\"A1.T4.7.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\">14.51</td>\n<td id=\"A1.T4.7.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\">46.79</td>\n<td id=\"A1.T4.7.1.9.4\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.9.5\" class=\"ltx_td ltx_align_center ltx_border_t\">32.05</td>\n<td id=\"A1.T4.7.1.9.6\" class=\"ltx_td ltx_align_center ltx_border_t\">67.04</td>\n<td id=\"A1.T4.7.1.9.7\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.9.8\" class=\"ltx_td ltx_align_center ltx_border_t\">74.33</td>\n<td id=\"A1.T4.7.1.9.9\" class=\"ltx_td ltx_align_center ltx_border_t\">89.96</td>\n</tr>\n<tr id=\"A1.T4.7.1.10\" class=\"ltx_tr\">\n<td id=\"A1.T4.7.1.10.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span id=\"A1.T4.7.1.10.1.1\" class=\"ltx_text ltx_font_bold\">NeFL (ours)</span></td>\n<td id=\"A1.T4.7.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A1.T4.7.1.10.2.1\" class=\"ltx_text ltx_font_bold\">55.22</span></td>\n<td id=\"A1.T4.7.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A1.T4.7.1.10.3.1\" class=\"ltx_text ltx_font_bold\">56.26</span></td>\n<td id=\"A1.T4.7.1.10.4\" class=\"ltx_td ltx_border_bb ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.10.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A1.T4.7.1.10.5.1\" class=\"ltx_text ltx_font_bold\">75.02</span></td>\n<td id=\"A1.T4.7.1.10.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A1.T4.7.1.10.6.1\" class=\"ltx_text ltx_font_bold\">76.68</span></td>\n<td id=\"A1.T4.7.1.10.7\" class=\"ltx_td ltx_border_bb ltx_border_t\"></td>\n<td id=\"A1.T4.7.1.10.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A1.T4.7.1.10.8.1\" class=\"ltx_text ltx_font_bold\">94.72</span></td>\n<td id=\"A1.T4.7.1.10.9\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A1.T4.7.1.10.9.1\" class=\"ltx_text ltx_font_bold\">95.22</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We evaluate the performance for other dataset such as CIFAR-100 (Krizhevsky et al., ), CINIC-10 (Darlow et al., 2018) SVHN (Netzer et al., 2011) and we observe a similar tendency in terms of Top-1 accuracy of the worst-case submodel and average accuracy over submodels. Note that we set total communication round T=100𝑇100T=100 for training SVHN. The results are presented in Table 4.",
            "The experiments in Table 1, Table 2, Table 4, Table 5 and Table 6 are evaluated by a total 500 communication rounds (T𝑇T) with 100 clients (M𝑀M). At each round, a fraction rate of 0.10.10.1 is used, indicating that 10 clients (|𝒞t|=10subscript𝒞𝑡10|\\mathcal{C}_{t}|=10) transmit their weights to the server.\nDuring the training process of clients, local batch size of 323232 and a local epoch of E=5𝐸5E=5 are used.\nFor training, we employ SGD optimizer (Ruder, 2016) without momentum and weight decay. The initial learning rate is set to 0.10.10.1 and decreases by a factor of 110110\\frac{1}{10} at the halfway point and 3434\\frac{3}{4} of the total communication rounds.\nThe experiments in Table 3 are evaluated with the number of clients is M=10𝑀10M=10, all of whom participate in the NeFL pipeline (with a fraction rate of 111). The experiment consists of T=100𝑇100T=100 communication rounds, and each client performs local training for a single epoch (E=1𝐸1E=1). We use a cosine annealing learning rate scheduling (Loshchilov & Hutter, 2017) with 500 steps of warmup and an initial learning rate 0.03. The input images are resized to a size of 256256256 and randomly cropped to a size of 224224224 with a padding size of 282828. Note that utilizing layer normalization layers as consistent parameters, as opposed to BN layers that are inconsistent parameters, yields better performance.",
            "For the experiments presented in Table 1, Table 2, Table 4, Table 5 and Table 6, we consider five submodels with 𝜸=[γ1,γ2,γ3,γ4,γ5]=[0.2,0.4,0.6,0.8,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾3subscript𝛾4subscript𝛾50.20.40.60.81\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3},\\gamma_{4},\\gamma_{5}\\right]=\\left[0.2,0.4,0.6,0.8,1\\right] and 𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=\\left[0.04,0.16,0.36,0.64,1\\right] for Table 9. Additionally, for Table 3, we use three submodels with 𝜸=[γ1,γ2,γ3]=[0.5,0.75,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾30.50.751\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3}\\right]=\\left[0.5,0.75,1\\right]. Submodel details for ResNets and ViTs are detailed in Table 10 (ResNet18), Table 11 (ResNet34), Table 13 (ResNet56), Table 15 (ResNet110), Table 15 (Wide ResNet101_2) and Table 13 (ViT-B/16\nIn the tables, 1’s and 0’s denote the initial values of step sizes. A step size of zero indicates that a submodel does not include the corresponding block.\nNote that ResNets have a step size parameters for each block while ViTs have different step size parameters to be multiplied with SA and FFN.\nSubmodels in NeFL-W are characterized by 𝜸D=[1,…,1]subscript𝜸𝐷1…1\\bm{\\gamma}_{D}=[1,\\dots,1] and 𝜸Wsubscript𝜸𝑊\\bm{\\gamma}_{W} with a target size, while submodels in NeFL-D are characterized by 𝜸W=[1,…,1]subscript𝜸𝑊1…1\\bm{\\gamma}_{W}=[1,\\dots,1] and 𝜸Dsubscript𝜸𝐷\\bm{\\gamma}_{D} with a target size. Submodels in NeFL-WD are characterized by target size 𝜸W​𝜸Dsubscript𝜸𝑊subscript𝜸𝐷\\bm{\\gamma}_{W}\\bm{\\gamma}_{D}.\nCorresponding number of parameters and FLOPs are provided in Table 8.",
            "We simulate a dynamic environment by randomly selecting which submodel to be trained by each client during every communication round. In our experiments for Table 1, Table 2, Table 4, Table 5 and Table 6, we have an equal number of five tiers of clients (M/Ns=20𝑀subscript𝑁𝑠20M/N_{s}=20 for all tiers of clients). The resource-constrained clients (tier 1) randomly select models between 𝜸=0.2,0.4,0.6𝜸0.20.40.6\\bm{\\gamma}=0.2,0.4,0.6, clients in tier 2 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8𝜸0.20.40.60.8\\bm{\\gamma}=0.2,0.4,0.6,0.8, clients in tier 3 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8,1𝜸0.20.40.60.81\\bm{\\gamma}=0.2,0.4,0.6,0.8,1, clients in tier 4 randomly select models from the set 𝜸=0.4,0.6,0.8,1𝜸0.40.60.81\\bm{\\gamma}=0.4,0.6,0.8,1, and the resource-richest clients (tier 5) randomly select models from the set 𝜸=0.6,0.8,1𝜸0.60.81\\bm{\\gamma}=0.6,0.8,1. In our experiments for Table 3 involving three submodels and 10 clients, the tier 1 clients (3 out of 10 total clients) select 𝜸=0.5𝜸0.5\\bm{\\gamma}=0.5, tier 2 clients (3 out of 10 total clients) select 𝜸=0.75𝜸0.75\\bm{\\gamma}=0.75 and tier 3 clients (4 out of 10 total clients) select 𝜸=1𝜸1\\bm{\\gamma}=1. By allowing clients to randomly choose from the available submodels, our setup reflects the dynamic nature in which clients may encounter communication computing bottlenecks during each iteration."
        ]
    },
    "A1.T5": {
        "caption": "Table 5: Results of NeFL of five submodels with a global model ResNet18 for CIFAR-10 dataset under IID settings across different number of clients. We report Top-1 classification accuracies (%) for the worst-case submodel and the average of the performance of five submodels..",
        "table": "<table id=\"A1.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T5.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.1.1\" class=\"ltx_td ltx_align_right ltx_border_tt\" rowspan=\"2\"><span id=\"A1.T5.1.1.1.1\" class=\"ltx_text ltx_font_bold\"># of Clients</span></td>\n<td id=\"A1.T5.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"A1.T5.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Model size</span></td>\n<td id=\"A1.T5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\"><span id=\"A1.T5.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n</tr>\n<tr id=\"A1.T5.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T5.1.2.1.1\" class=\"ltx_text ltx_font_bold\">NeFL (ours)</span></td>\n<td id=\"A1.T5.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">FjORD</td>\n<td id=\"A1.T5.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">HeteroFL</td>\n<td id=\"A1.T5.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">DepthFL</td>\n</tr>\n<tr id=\"A1.T5.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"A1.T5.1.3.1.1\" class=\"ltx_text\">100</span></td>\n<td id=\"A1.T5.1.3.2\" class=\"ltx_td ltx_align_left ltx_border_tt\">Worst</td>\n<td id=\"A1.T5.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A1.T5.1.3.3.1\" class=\"ltx_text ltx_font_bold\">86.86</span></td>\n<td id=\"A1.T5.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">85.12</td>\n<td id=\"A1.T5.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">80.62</td>\n<td id=\"A1.T5.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">64.8</td>\n</tr>\n<tr id=\"A1.T5.1.4\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Avg</td>\n<td id=\"A1.T5.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T5.1.4.2.1\" class=\"ltx_text ltx_font_bold\">87.88</span></td>\n<td id=\"A1.T5.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">87.32</td>\n<td id=\"A1.T5.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">84.62</td>\n<td id=\"A1.T5.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">82.44</td>\n</tr>\n<tr id=\"A1.T5.1.5\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"2\"><span id=\"A1.T5.1.5.1.1\" class=\"ltx_text\">50</span></td>\n<td id=\"A1.T5.1.5.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Worst</td>\n<td id=\"A1.T5.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T5.1.5.3.1\" class=\"ltx_text ltx_font_bold\">88.42</span></td>\n<td id=\"A1.T5.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">86.19</td>\n<td id=\"A1.T5.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">84.67</td>\n<td id=\"A1.T5.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\">52.07</td>\n</tr>\n<tr id=\"A1.T5.1.6\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.6.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Avg</td>\n<td id=\"A1.T5.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T5.1.6.2.1\" class=\"ltx_text ltx_font_bold\">89.14</span></td>\n<td id=\"A1.T5.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">88.43</td>\n<td id=\"A1.T5.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\">87.23</td>\n<td id=\"A1.T5.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\">82.04</td>\n</tr>\n<tr id=\"A1.T5.1.7\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" rowspan=\"2\"><span id=\"A1.T5.1.7.1.1\" class=\"ltx_text\">20</span></td>\n<td id=\"A1.T5.1.7.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Worst</td>\n<td id=\"A1.T5.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T5.1.7.3.1\" class=\"ltx_text ltx_font_bold\">89.2</span></td>\n<td id=\"A1.T5.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">87.76</td>\n<td id=\"A1.T5.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">88.74</td>\n<td id=\"A1.T5.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\">24.94</td>\n</tr>\n<tr id=\"A1.T5.1.8\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.8.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">Avg</td>\n<td id=\"A1.T5.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A1.T5.1.8.2.1\" class=\"ltx_text ltx_font_bold\">89.88</span></td>\n<td id=\"A1.T5.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">89.6</td>\n<td id=\"A1.T5.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">88.71</td>\n<td id=\"A1.T5.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">76.54</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We conduct further experiments across different numbers of clients. In Table 5, we observe that as the number of clients increases, the performance of NeFL as well as baselines degrades. The results align with previous studies (Kim et al., 2023; Thapa et al., 2022; Wang et al., 2020). The more the number of clients, trained weights deviates further from the weights trained by IID data. While the IID sampling of the training data ensures the stochastic gradient to be an unbiased estimate of the full gradient, the non-IID sampling leads to non-guaranteed convergence and model weight divergence in FL (Li et al., 2020b; 2021b; Zhao et al., 2018). The local clients train their own network with multiple epochs and upload the weights so that the uploaded weights get more deviated.\nIn this regard, our proposed algorithm remains effective across different numbers of clients; however, the performance (e.g., accuracy and convergence) degrades by the data distribution among clients varies more as their number increases.",
            "The experiments in Table 1, Table 2, Table 4, Table 5 and Table 6 are evaluated by a total 500 communication rounds (T𝑇T) with 100 clients (M𝑀M). At each round, a fraction rate of 0.10.10.1 is used, indicating that 10 clients (|𝒞t|=10subscript𝒞𝑡10|\\mathcal{C}_{t}|=10) transmit their weights to the server.\nDuring the training process of clients, local batch size of 323232 and a local epoch of E=5𝐸5E=5 are used.\nFor training, we employ SGD optimizer (Ruder, 2016) without momentum and weight decay. The initial learning rate is set to 0.10.10.1 and decreases by a factor of 110110\\frac{1}{10} at the halfway point and 3434\\frac{3}{4} of the total communication rounds.\nThe experiments in Table 3 are evaluated with the number of clients is M=10𝑀10M=10, all of whom participate in the NeFL pipeline (with a fraction rate of 111). The experiment consists of T=100𝑇100T=100 communication rounds, and each client performs local training for a single epoch (E=1𝐸1E=1). We use a cosine annealing learning rate scheduling (Loshchilov & Hutter, 2017) with 500 steps of warmup and an initial learning rate 0.03. The input images are resized to a size of 256256256 and randomly cropped to a size of 224224224 with a padding size of 282828. Note that utilizing layer normalization layers as consistent parameters, as opposed to BN layers that are inconsistent parameters, yields better performance.",
            "For the experiments presented in Table 1, Table 2, Table 4, Table 5 and Table 6, we consider five submodels with 𝜸=[γ1,γ2,γ3,γ4,γ5]=[0.2,0.4,0.6,0.8,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾3subscript𝛾4subscript𝛾50.20.40.60.81\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3},\\gamma_{4},\\gamma_{5}\\right]=\\left[0.2,0.4,0.6,0.8,1\\right] and 𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=\\left[0.04,0.16,0.36,0.64,1\\right] for Table 9. Additionally, for Table 3, we use three submodels with 𝜸=[γ1,γ2,γ3]=[0.5,0.75,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾30.50.751\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3}\\right]=\\left[0.5,0.75,1\\right]. Submodel details for ResNets and ViTs are detailed in Table 10 (ResNet18), Table 11 (ResNet34), Table 13 (ResNet56), Table 15 (ResNet110), Table 15 (Wide ResNet101_2) and Table 13 (ViT-B/16\nIn the tables, 1’s and 0’s denote the initial values of step sizes. A step size of zero indicates that a submodel does not include the corresponding block.\nNote that ResNets have a step size parameters for each block while ViTs have different step size parameters to be multiplied with SA and FFN.\nSubmodels in NeFL-W are characterized by 𝜸D=[1,…,1]subscript𝜸𝐷1…1\\bm{\\gamma}_{D}=[1,\\dots,1] and 𝜸Wsubscript𝜸𝑊\\bm{\\gamma}_{W} with a target size, while submodels in NeFL-D are characterized by 𝜸W=[1,…,1]subscript𝜸𝑊1…1\\bm{\\gamma}_{W}=[1,\\dots,1] and 𝜸Dsubscript𝜸𝐷\\bm{\\gamma}_{D} with a target size. Submodels in NeFL-WD are characterized by target size 𝜸W​𝜸Dsubscript𝜸𝑊subscript𝜸𝐷\\bm{\\gamma}_{W}\\bm{\\gamma}_{D}.\nCorresponding number of parameters and FLOPs are provided in Table 8.",
            "We simulate a dynamic environment by randomly selecting which submodel to be trained by each client during every communication round. In our experiments for Table 1, Table 2, Table 4, Table 5 and Table 6, we have an equal number of five tiers of clients (M/Ns=20𝑀subscript𝑁𝑠20M/N_{s}=20 for all tiers of clients). The resource-constrained clients (tier 1) randomly select models between 𝜸=0.2,0.4,0.6𝜸0.20.40.6\\bm{\\gamma}=0.2,0.4,0.6, clients in tier 2 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8𝜸0.20.40.60.8\\bm{\\gamma}=0.2,0.4,0.6,0.8, clients in tier 3 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8,1𝜸0.20.40.60.81\\bm{\\gamma}=0.2,0.4,0.6,0.8,1, clients in tier 4 randomly select models from the set 𝜸=0.4,0.6,0.8,1𝜸0.40.60.81\\bm{\\gamma}=0.4,0.6,0.8,1, and the resource-richest clients (tier 5) randomly select models from the set 𝜸=0.6,0.8,1𝜸0.60.81\\bm{\\gamma}=0.6,0.8,1. In our experiments for Table 3 involving three submodels and 10 clients, the tier 1 clients (3 out of 10 total clients) select 𝜸=0.5𝜸0.5\\bm{\\gamma}=0.5, tier 2 clients (3 out of 10 total clients) select 𝜸=0.75𝜸0.75\\bm{\\gamma}=0.75 and tier 3 clients (4 out of 10 total clients) select 𝜸=1𝜸1\\bm{\\gamma}=1. By allowing clients to randomly choose from the available submodels, our setup reflects the dynamic nature in which clients may encounter communication computing bottlenecks during each iteration."
        ]
    },
    "A1.T6": {
        "caption": "Table 6: Ablation study by NeFL with five submodels for CIFAR-10 dataset under IID settings. We report Top-1 classification accuracies (%) for the worst-case submodel and the average of the performance of five submodels.",
        "table": "<table id=\"A1.T6.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T6.1.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A1.T6.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"A1.T6.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"A1.T6.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"A1.T6.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A1.T6.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Worst</span></td>\n<td id=\"A1.T6.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A1.T6.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Avg</span></td>\n</tr>\n<tr id=\"A1.T6.1.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_tt\" rowspan=\"14\"><span id=\"A1.T6.1.1.2.1.1\" class=\"ltx_text\">ResNet18</span></td>\n<td id=\"A1.T6.1.1.2.2\" class=\"ltx_td ltx_align_left ltx_border_tt\">HeteroFL</td>\n<td id=\"A1.T6.1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">80.62</td>\n<td id=\"A1.T6.1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">84.26</td>\n</tr>\n<tr id=\"A1.T6.1.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FjORD</td>\n<td id=\"A1.T6.1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">85.12</td>\n<td id=\"A1.T6.1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">87.32</td>\n</tr>\n<tr id=\"A1.T6.1.1.4\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T6.1.1.4.1.1\" class=\"ltx_text ltx_font_bold\">NeFL-W</span></td>\n<td id=\"A1.T6.1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T6.1.1.4.2.1\" class=\"ltx_text ltx_font_bold\">85.13</span></td>\n<td id=\"A1.T6.1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T6.1.1.4.3.1\" class=\"ltx_text ltx_font_bold\">87.36</span></td>\n</tr>\n<tr id=\"A1.T6.1.1.5\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">DepthFL</td>\n<td id=\"A1.T6.1.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">64.80</td>\n<td id=\"A1.T6.1.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">82.44</td>\n</tr>\n<tr id=\"A1.T6.1.1.6\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.6.1\" class=\"ltx_td ltx_align_left ltx_border_t\">NeFL-D (N/L)</td>\n<td id=\"A1.T6.1.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">86.29</td>\n<td id=\"A1.T6.1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">88.12</td>\n</tr>\n<tr id=\"A1.T6.1.1.7\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">NeFL-D<sub id=\"A1.T6.1.1.7.1.1\" class=\"ltx_sub\">O</sub> (N/L)</td>\n<td id=\"A1.T6.1.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">86.24</td>\n<td id=\"A1.T6.1.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">88.22</td>\n</tr>\n<tr id=\"A1.T6.1.1.8\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.8.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T6.1.1.8.1.1\" class=\"ltx_text ltx_font_bold\">NeFL-D</span></td>\n<td id=\"A1.T6.1.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T6.1.1.8.2.1\" class=\"ltx_text ltx_font_bold\">86.06</span></td>\n<td id=\"A1.T6.1.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T6.1.1.8.3.1\" class=\"ltx_text ltx_font_bold\">87.94</span></td>\n</tr>\n<tr id=\"A1.T6.1.1.9\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">NeFL-D<sub id=\"A1.T6.1.1.9.1.1\" class=\"ltx_sub\">O</sub>\n</td>\n<td id=\"A1.T6.1.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\">85.98</td>\n<td id=\"A1.T6.1.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\">88.20</td>\n</tr>\n<tr id=\"A1.T6.1.1.10\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.10.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T6.1.1.10.1.1\" class=\"ltx_text ltx_font_bold\">NeFL-WD</span></td>\n<td id=\"A1.T6.1.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T6.1.1.10.2.1\" class=\"ltx_text ltx_font_bold\">86.86</span></td>\n<td id=\"A1.T6.1.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T6.1.1.10.3.1\" class=\"ltx_text ltx_font_bold\">87.88</span></td>\n</tr>\n<tr id=\"A1.T6.1.1.11\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.11.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">NeFL-WD (N/L)</td>\n<td id=\"A1.T6.1.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">86.85</td>\n<td id=\"A1.T6.1.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">88.21</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Referring to the Table 6, the performance improvements of NeFL-WD over NeFL-WD (N/L), NeFL-W over FjORD (Horváth et al., 2021) and NeFL-D over NeFL-D (N/L) provide the effectiveness of learnable step sizes. The effectiveness of the inconsistent parameters including learn step sizes is also verified by NeFL-D over DepthFL (Kim et al., 2023) and NeFL-W over HeteroFL (Diao et al., 2021).\nWe also observe that NeFL-D and NeFL-WD have better performance over widthwise scaling. The performance gap of depthwise scaling over widthwise scaling gets larger for narrow and deep networks. Note that ResNet56 and ResNet110 has smaller (i.e., narrower) channel sizes with more layers (i.e., deeper) than ResNet18 and ResNet34 He et al. (2016).\nFurthermore, we have a finding that NeFL-D outperforms NeFL-DO in most cases. The rationale comes from the empirical results that trained step sizes are not as large as initial value for NeFL-DO that large initial values for NeFL-DO degrades the trainability of depthwise-scaled submodels.",
            "It is worth noting that beyond the performance improvement (including that our proposed scaling method NeFL-W and NeFL-D over baselines in Table 6), NeFL provides the more DoF for widthwise/depthwise scaling that can be determined by the requirements of clients. It results in more clients to be participate in the FL pipeline.\nAlso refer to Table 9 that has different scaling ratio γ𝛾\\gamma. Note that in this case, FjORD (Horváth et al., 2021) outperforms NeFL-W. In this case with severe scaling factors (the worst model has 4% parameters of a global model), step sizes could not compensate the limited number of parameters and degraded the trainability with auxiliary parameters. However, NeFL-WD shows the best performance over other baselines that verify the well-balanced submodels show the better performance than ill-conditioned (too shallow or too narrow) submodels.",
            "The experiments in Table 1, Table 2, Table 4, Table 5 and Table 6 are evaluated by a total 500 communication rounds (T𝑇T) with 100 clients (M𝑀M). At each round, a fraction rate of 0.10.10.1 is used, indicating that 10 clients (|𝒞t|=10subscript𝒞𝑡10|\\mathcal{C}_{t}|=10) transmit their weights to the server.\nDuring the training process of clients, local batch size of 323232 and a local epoch of E=5𝐸5E=5 are used.\nFor training, we employ SGD optimizer (Ruder, 2016) without momentum and weight decay. The initial learning rate is set to 0.10.10.1 and decreases by a factor of 110110\\frac{1}{10} at the halfway point and 3434\\frac{3}{4} of the total communication rounds.\nThe experiments in Table 3 are evaluated with the number of clients is M=10𝑀10M=10, all of whom participate in the NeFL pipeline (with a fraction rate of 111). The experiment consists of T=100𝑇100T=100 communication rounds, and each client performs local training for a single epoch (E=1𝐸1E=1). We use a cosine annealing learning rate scheduling (Loshchilov & Hutter, 2017) with 500 steps of warmup and an initial learning rate 0.03. The input images are resized to a size of 256256256 and randomly cropped to a size of 224224224 with a padding size of 282828. Note that utilizing layer normalization layers as consistent parameters, as opposed to BN layers that are inconsistent parameters, yields better performance.",
            "For the experiments presented in Table 1, Table 2, Table 4, Table 5 and Table 6, we consider five submodels with 𝜸=[γ1,γ2,γ3,γ4,γ5]=[0.2,0.4,0.6,0.8,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾3subscript𝛾4subscript𝛾50.20.40.60.81\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3},\\gamma_{4},\\gamma_{5}\\right]=\\left[0.2,0.4,0.6,0.8,1\\right] and 𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=\\left[0.04,0.16,0.36,0.64,1\\right] for Table 9. Additionally, for Table 3, we use three submodels with 𝜸=[γ1,γ2,γ3]=[0.5,0.75,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾30.50.751\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3}\\right]=\\left[0.5,0.75,1\\right]. Submodel details for ResNets and ViTs are detailed in Table 10 (ResNet18), Table 11 (ResNet34), Table 13 (ResNet56), Table 15 (ResNet110), Table 15 (Wide ResNet101_2) and Table 13 (ViT-B/16\nIn the tables, 1’s and 0’s denote the initial values of step sizes. A step size of zero indicates that a submodel does not include the corresponding block.\nNote that ResNets have a step size parameters for each block while ViTs have different step size parameters to be multiplied with SA and FFN.\nSubmodels in NeFL-W are characterized by 𝜸D=[1,…,1]subscript𝜸𝐷1…1\\bm{\\gamma}_{D}=[1,\\dots,1] and 𝜸Wsubscript𝜸𝑊\\bm{\\gamma}_{W} with a target size, while submodels in NeFL-D are characterized by 𝜸W=[1,…,1]subscript𝜸𝑊1…1\\bm{\\gamma}_{W}=[1,\\dots,1] and 𝜸Dsubscript𝜸𝐷\\bm{\\gamma}_{D} with a target size. Submodels in NeFL-WD are characterized by target size 𝜸W​𝜸Dsubscript𝜸𝑊subscript𝜸𝐷\\bm{\\gamma}_{W}\\bm{\\gamma}_{D}.\nCorresponding number of parameters and FLOPs are provided in Table 8.",
            "We simulate a dynamic environment by randomly selecting which submodel to be trained by each client during every communication round. In our experiments for Table 1, Table 2, Table 4, Table 5 and Table 6, we have an equal number of five tiers of clients (M/Ns=20𝑀subscript𝑁𝑠20M/N_{s}=20 for all tiers of clients). The resource-constrained clients (tier 1) randomly select models between 𝜸=0.2,0.4,0.6𝜸0.20.40.6\\bm{\\gamma}=0.2,0.4,0.6, clients in tier 2 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8𝜸0.20.40.60.8\\bm{\\gamma}=0.2,0.4,0.6,0.8, clients in tier 3 randomly select models from the set 𝜸=0.2,0.4,0.6,0.8,1𝜸0.20.40.60.81\\bm{\\gamma}=0.2,0.4,0.6,0.8,1, clients in tier 4 randomly select models from the set 𝜸=0.4,0.6,0.8,1𝜸0.40.60.81\\bm{\\gamma}=0.4,0.6,0.8,1, and the resource-richest clients (tier 5) randomly select models from the set 𝜸=0.6,0.8,1𝜸0.60.81\\bm{\\gamma}=0.6,0.8,1. In our experiments for Table 3 involving three submodels and 10 clients, the tier 1 clients (3 out of 10 total clients) select 𝜸=0.5𝜸0.5\\bm{\\gamma}=0.5, tier 2 clients (3 out of 10 total clients) select 𝜸=0.75𝜸0.75\\bm{\\gamma}=0.75 and tier 3 clients (4 out of 10 total clients) select 𝜸=1𝜸1\\bm{\\gamma}=1. By allowing clients to randomly choose from the available submodels, our setup reflects the dynamic nature in which clients may encounter communication computing bottlenecks during each iteration."
        ]
    },
    "A1.T7": {
        "caption": "Table 7: Summarization of NeFL and baselines for ablation study",
        "table": "<table id=\"A1.T7.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T7.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A1.T7.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A1.T7.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Depthwise scaling</span></td>\n<td id=\"A1.T7.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A1.T7.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Widthwise scaling</span></td>\n<td id=\"A1.T7.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"A1.T7.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Adaptive step sizes</span></td>\n</tr>\n<tr id=\"A1.T7.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">DepthFL</td>\n<td id=\"A1.T7.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">✓</td>\n<td id=\"A1.T7.1.2.3\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A1.T7.1.2.4\" class=\"ltx_td ltx_border_tt\"></td>\n</tr>\n<tr id=\"A1.T7.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FjORD, HeteroFL</td>\n<td id=\"A1.T7.1.3.2\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T7.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">✓</td>\n<td id=\"A1.T7.1.3.4\" class=\"ltx_td ltx_border_t\"></td>\n</tr>\n<tr id=\"A1.T7.1.4\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\">NeFL-D</td>\n<td id=\"A1.T7.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">✓</td>\n<td id=\"A1.T7.1.4.3\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T7.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">✓</td>\n</tr>\n<tr id=\"A1.T7.1.5\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">NeFL-W</td>\n<td id=\"A1.T7.1.5.2\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"A1.T7.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">✓</td>\n<td id=\"A1.T7.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">✓</td>\n</tr>\n<tr id=\"A1.T7.1.6\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.6.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">NeFL-WD</td>\n<td id=\"A1.T7.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">✓</td>\n<td id=\"A1.T7.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">✓</td>\n<td id=\"A1.T7.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">✓</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The performance comparison between NeFL-WD and NeFL-WD (N/L) as well as the comparison between NeFL-W and FjORD (Horváth et al., 2021) provides the effectiveness of learnable step sizes and comparison between NeFL-W and HeteroFL (Diao et al., 2021) provides the effectiveness of inconsistent parameters including learnable step sizes.\nSimilarly, the comparison between NeFL-D and NeFL-D (N/L) provides the effectiveness of learnables step sizes and comparison between NeFL-D and DepthFL (Kim et al., 2023) provides the effectiveness of inconsistent parameters including learnable step sizes.\nWe summarized the NeFL with various scaled submodels in Table 7. We also provide the parameter sizes and average FLOPs of submodels by scaling in Table 8."
        ]
    },
    "A1.T8": {
        "caption": "Table 8: Details of average FLOPs of submodels of 𝜸=[0.2,0.4,0.6,0.8,1]𝜸0.20.40.60.81\\bm{\\gamma}=[0.2,0.4,0.6,0.8,1]",
        "table": "<table id=\"A1.T8.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T8.3.1\" class=\"ltx_tr\">\n<td id=\"A1.T8.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"A1.T8.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"A1.T8.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"A1.T8.3.1.2.1\" class=\"ltx_text ltx_font_bold\">Metric</span></td>\n<td id=\"A1.T8.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\"><span id=\"A1.T8.3.1.3.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n</tr>\n<tr id=\"A1.T8.3.2\" class=\"ltx_tr\">\n<td id=\"A1.T8.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T8.3.2.1.1\" class=\"ltx_text ltx_font_bold\">Width/Depthwise scaling</span></td>\n<td id=\"A1.T8.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T8.3.2.2.1\" class=\"ltx_text ltx_font_bold\">Widthwise scaling</span></td>\n<td id=\"A1.T8.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T8.3.2.3.1\" class=\"ltx_text ltx_font_bold\">Depthwise scaling</span></td>\n</tr>\n<tr id=\"A1.T8.3.3\" class=\"ltx_tr\">\n<td id=\"A1.T8.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"A1.T8.3.3.1.1\" class=\"ltx_text\">ResNet18</span></td>\n<td id=\"A1.T8.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_tt\">Param #</td>\n<td id=\"A1.T8.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">6.71M</td>\n<td id=\"A1.T8.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">6.71M</td>\n<td id=\"A1.T8.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">6.68M</td>\n</tr>\n<tr id=\"A1.T8.3.4\" class=\"ltx_tr\">\n<td id=\"A1.T8.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FLOPs</td>\n<td id=\"A1.T8.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">87.8M</td>\n<td id=\"A1.T8.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">85M</td>\n<td id=\"A1.T8.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">102M</td>\n</tr>\n<tr id=\"A1.T8.3.5\" class=\"ltx_tr\">\n<td id=\"A1.T8.3.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"2\"><span id=\"A1.T8.3.5.1.1\" class=\"ltx_text\">ResNet34</span></td>\n<td id=\"A1.T8.3.5.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Param #</td>\n<td id=\"A1.T8.3.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">12.6M</td>\n<td id=\"A1.T8.3.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">12.8M</td>\n<td id=\"A1.T8.3.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">12.9M</td>\n</tr>\n<tr id=\"A1.T8.3.6\" class=\"ltx_tr\">\n<td id=\"A1.T8.3.6.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FLOPs</td>\n<td id=\"A1.T8.3.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">181M</td>\n<td id=\"A1.T8.3.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">176M</td>\n<td id=\"A1.T8.3.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\">193M</td>\n</tr>\n<tr id=\"A1.T8.3.7\" class=\"ltx_tr\">\n<td id=\"A1.T8.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"2\"><span id=\"A1.T8.3.7.1.1\" class=\"ltx_text\">ResNet56</span></td>\n<td id=\"A1.T8.3.7.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Param #</td>\n<td id=\"A1.T8.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.51M</td>\n<td id=\"A1.T8.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.52M</td>\n<td id=\"A1.T8.3.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.51M</td>\n</tr>\n<tr id=\"A1.T8.3.8\" class=\"ltx_tr\">\n<td id=\"A1.T8.3.8.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FLOPs</td>\n<td id=\"A1.T8.3.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">530M</td>\n<td id=\"A1.T8.3.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">534M</td>\n<td id=\"A1.T8.3.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">526M</td>\n</tr>\n<tr id=\"A1.T8.3.9\" class=\"ltx_tr\">\n<td id=\"A1.T8.3.9.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" rowspan=\"3\"><span id=\"A1.T8.3.9.1.1\" class=\"ltx_text\">ResNet110</span></td>\n<td id=\"A1.T8.3.9.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Param #</td>\n<td id=\"A1.T8.3.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1.05M</td>\n<td id=\"A1.T8.3.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.06M</td>\n<td id=\"A1.T8.3.9.5\" class=\"ltx_td ltx_align_center ltx_border_t\">1.04M</td>\n</tr>\n<tr id=\"A1.T8.3.10\" class=\"ltx_tr\">\n<td id=\"A1.T8.3.10.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">FLOPs</td>\n<td id=\"A1.T8.3.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">158M</td>\n<td id=\"A1.T8.3.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">159M</td>\n<td id=\"A1.T8.3.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">234M</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "For fair comparison across different baselines, we designed each submodel to have similar number of parameters (Table 8 in Appendix A). As illustrated in Table 1, NeFL outperforms baselines in terms of both the performance of the worst-case submodel (γ=0.2𝛾0.2\\gamma=0.2) and the average performance across five submodels in IID and non-IID settings. Notably, the performance gain is greater in non-IID settings, which belong to practical FL scenarios. It is worth noting that our proposed depthwise scaling method has performance gain over depthwise scaling baselines, while our proposed widthwise scaling method also has performance gain over widthwise scaling baselines (refer to the Appendix A).\nFurthermore, beyond the performance gain from using depthwise or widthwise scaled submodels, NeFL provides a federated averaging method that can incorporate widthwise or/and depthwise scaled submodels. This characteristic of embracing any submodel with different architecture extracted from a single global model enhances flexibility, enabling more clients to participate in the FL pipeline.",
            "The performance comparison between NeFL-WD and NeFL-WD (N/L) as well as the comparison between NeFL-W and FjORD (Horváth et al., 2021) provides the effectiveness of learnable step sizes and comparison between NeFL-W and HeteroFL (Diao et al., 2021) provides the effectiveness of inconsistent parameters including learnable step sizes.\nSimilarly, the comparison between NeFL-D and NeFL-D (N/L) provides the effectiveness of learnables step sizes and comparison between NeFL-D and DepthFL (Kim et al., 2023) provides the effectiveness of inconsistent parameters including learnable step sizes.\nWe summarized the NeFL with various scaled submodels in Table 7. We also provide the parameter sizes and average FLOPs of submodels by scaling in Table 8.",
            "For the experiments presented in Table 1, Table 2, Table 4, Table 5 and Table 6, we consider five submodels with 𝜸=[γ1,γ2,γ3,γ4,γ5]=[0.2,0.4,0.6,0.8,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾3subscript𝛾4subscript𝛾50.20.40.60.81\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3},\\gamma_{4},\\gamma_{5}\\right]=\\left[0.2,0.4,0.6,0.8,1\\right] and 𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=\\left[0.04,0.16,0.36,0.64,1\\right] for Table 9. Additionally, for Table 3, we use three submodels with 𝜸=[γ1,γ2,γ3]=[0.5,0.75,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾30.50.751\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3}\\right]=\\left[0.5,0.75,1\\right]. Submodel details for ResNets and ViTs are detailed in Table 10 (ResNet18), Table 11 (ResNet34), Table 13 (ResNet56), Table 15 (ResNet110), Table 15 (Wide ResNet101_2) and Table 13 (ViT-B/16\nIn the tables, 1’s and 0’s denote the initial values of step sizes. A step size of zero indicates that a submodel does not include the corresponding block.\nNote that ResNets have a step size parameters for each block while ViTs have different step size parameters to be multiplied with SA and FFN.\nSubmodels in NeFL-W are characterized by 𝜸D=[1,…,1]subscript𝜸𝐷1…1\\bm{\\gamma}_{D}=[1,\\dots,1] and 𝜸Wsubscript𝜸𝑊\\bm{\\gamma}_{W} with a target size, while submodels in NeFL-D are characterized by 𝜸W=[1,…,1]subscript𝜸𝑊1…1\\bm{\\gamma}_{W}=[1,\\dots,1] and 𝜸Dsubscript𝜸𝐷\\bm{\\gamma}_{D} with a target size. Submodels in NeFL-WD are characterized by target size 𝜸W​𝜸Dsubscript𝜸𝑊subscript𝜸𝐷\\bm{\\gamma}_{W}\\bm{\\gamma}_{D}.\nCorresponding number of parameters and FLOPs are provided in Table 8."
        ]
    },
    "A1.T9": {
        "caption": "Table 9: Results of NeFL with five submodels (𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=[0.04,0.16,0.36,0.64,1]) for CIFAR-10 dataset on ResNet110. Results of NeFL with five submodels for CIFAR-10 dataset under IID settings. We report Top-1 classification accuracies (%) for the worst-case submodel and the average of the performance of five submodels.",
        "table": "<table id=\"A1.T9.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T9.3.1\" class=\"ltx_tr\">\n<td id=\"A1.T9.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"A1.T9.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"A1.T9.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"A1.T9.3.1.2.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"A1.T9.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"A1.T9.3.1.3.1\" class=\"ltx_text ltx_font_bold\">Model size</span></td>\n</tr>\n<tr id=\"A1.T9.3.2\" class=\"ltx_tr\">\n<td id=\"A1.T9.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T9.3.2.1.1\" class=\"ltx_text ltx_font_bold\">Worst</span></td>\n<td id=\"A1.T9.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T9.3.2.2.1\" class=\"ltx_text ltx_font_bold\">Avg</span></td>\n</tr>\n<tr id=\"A1.T9.3.3\" class=\"ltx_tr\">\n<td id=\"A1.T9.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_tt\" rowspan=\"8\"><span id=\"A1.T9.3.3.1.1\" class=\"ltx_text\">ResNet110</span></td>\n<td id=\"A1.T9.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_tt\">HeteroFL</td>\n<td id=\"A1.T9.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">46.58</td>\n<td id=\"A1.T9.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">63.62</td>\n</tr>\n<tr id=\"A1.T9.3.4\" class=\"ltx_tr\">\n<td id=\"A1.T9.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FjORD</td>\n<td id=\"A1.T9.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">69.61</td>\n<td id=\"A1.T9.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">81.46</td>\n</tr>\n<tr id=\"A1.T9.3.5\" class=\"ltx_tr\">\n<td id=\"A1.T9.3.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T9.3.5.1.1\" class=\"ltx_text ltx_font_bold\">NeFL-W</span></td>\n<td id=\"A1.T9.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">68.27</td>\n<td id=\"A1.T9.3.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">80.98</td>\n</tr>\n<tr id=\"A1.T9.3.6\" class=\"ltx_tr\">\n<td id=\"A1.T9.3.6.1\" class=\"ltx_td ltx_align_left ltx_border_t\">DepthFL</td>\n<td id=\"A1.T9.3.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">11.00</td>\n<td id=\"A1.T9.3.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">53.91</td>\n</tr>\n<tr id=\"A1.T9.3.7\" class=\"ltx_tr\">\n<td id=\"A1.T9.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T9.3.7.1.1\" class=\"ltx_text ltx_font_bold\">NeFL-D</span></td>\n<td id=\"A1.T9.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T9.3.7.2.1\" class=\"ltx_text ltx_font_bold\">75.4</span></td>\n<td id=\"A1.T9.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T9.3.7.3.1\" class=\"ltx_text ltx_font_bold\">84.31</span></td>\n</tr>\n<tr id=\"A1.T9.3.8\" class=\"ltx_tr\">\n<td id=\"A1.T9.3.8.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span id=\"A1.T9.3.8.1.1\" class=\"ltx_text ltx_font_bold\">NeFL-WD</span></td>\n<td id=\"A1.T9.3.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A1.T9.3.8.2.1\" class=\"ltx_text ltx_font_bold\">76.60</span></td>\n<td id=\"A1.T9.3.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A1.T9.3.8.3.1\" class=\"ltx_text ltx_font_bold\">84.02</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "It is worth noting that beyond the performance improvement (including that our proposed scaling method NeFL-W and NeFL-D over baselines in Table 6), NeFL provides the more DoF for widthwise/depthwise scaling that can be determined by the requirements of clients. It results in more clients to be participate in the FL pipeline.\nAlso refer to Table 9 that has different scaling ratio γ𝛾\\gamma. Note that in this case, FjORD (Horváth et al., 2021) outperforms NeFL-W. In this case with severe scaling factors (the worst model has 4% parameters of a global model), step sizes could not compensate the limited number of parameters and degraded the trainability with auxiliary parameters. However, NeFL-WD shows the best performance over other baselines that verify the well-balanced submodels show the better performance than ill-conditioned (too shallow or too narrow) submodels.",
            "For the experiments presented in Table 1, Table 2, Table 4, Table 5 and Table 6, we consider five submodels with 𝜸=[γ1,γ2,γ3,γ4,γ5]=[0.2,0.4,0.6,0.8,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾3subscript𝛾4subscript𝛾50.20.40.60.81\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3},\\gamma_{4},\\gamma_{5}\\right]=\\left[0.2,0.4,0.6,0.8,1\\right] and 𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=\\left[0.04,0.16,0.36,0.64,1\\right] for Table 9. Additionally, for Table 3, we use three submodels with 𝜸=[γ1,γ2,γ3]=[0.5,0.75,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾30.50.751\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3}\\right]=\\left[0.5,0.75,1\\right]. Submodel details for ResNets and ViTs are detailed in Table 10 (ResNet18), Table 11 (ResNet34), Table 13 (ResNet56), Table 15 (ResNet110), Table 15 (Wide ResNet101_2) and Table 13 (ViT-B/16\nIn the tables, 1’s and 0’s denote the initial values of step sizes. A step size of zero indicates that a submodel does not include the corresponding block.\nNote that ResNets have a step size parameters for each block while ViTs have different step size parameters to be multiplied with SA and FFN.\nSubmodels in NeFL-W are characterized by 𝜸D=[1,…,1]subscript𝜸𝐷1…1\\bm{\\gamma}_{D}=[1,\\dots,1] and 𝜸Wsubscript𝜸𝑊\\bm{\\gamma}_{W} with a target size, while submodels in NeFL-D are characterized by 𝜸W=[1,…,1]subscript𝜸𝑊1…1\\bm{\\gamma}_{W}=[1,\\dots,1] and 𝜸Dsubscript𝜸𝐷\\bm{\\gamma}_{D} with a target size. Submodels in NeFL-WD are characterized by target size 𝜸W​𝜸Dsubscript𝜸𝑊subscript𝜸𝐷\\bm{\\gamma}_{W}\\bm{\\gamma}_{D}.\nCorresponding number of parameters and FLOPs are provided in Table 8."
        ]
    },
    "A2.T10": {
        "caption": "Table 10: Details of 𝜸𝜸\\bm{\\gamma} of NeFL-D and NeFL-WD on ResNet18",
        "table": "<table id=\"A2.T10.5\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle\">\n<tr id=\"A2.T10.5.3\" class=\"ltx_tr\">\n<td id=\"A2.T10.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\">\n<span id=\"A2.T10.5.3.4.1\" class=\"ltx_text\"></span> <span id=\"A2.T10.5.3.4.2\" class=\"ltx_text\">\n<span id=\"A2.T10.5.3.4.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"A2.T10.5.3.4.2.1.1\" class=\"ltx_tr\">\n<span id=\"A2.T10.5.3.4.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Model</span></span>\n<span id=\"A2.T10.5.3.4.2.1.2\" class=\"ltx_tr\">\n<span id=\"A2.T10.5.3.4.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">index</span></span>\n</span></span><span id=\"A2.T10.5.3.4.3\" class=\"ltx_text\"></span>\n</td>\n<td id=\"A2.T10.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\">\n<span id=\"A2.T10.3.1.1.2\" class=\"ltx_text\"></span> <span id=\"A2.T10.3.1.1.1\" class=\"ltx_text\">\n<span id=\"A2.T10.3.1.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"A2.T10.3.1.1.1.1.1.2\" class=\"ltx_tr\">\n<span id=\"A2.T10.3.1.1.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Model size</span></span>\n<span id=\"A2.T10.3.1.1.1.1.1.1\" class=\"ltx_tr\">\n<span id=\"A2.T10.3.1.1.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"A2.T10.3.1.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma\" display=\"inline\"><semantics id=\"A2.T10.3.1.1.1.1.1.1.1.m1.1a\"><mi id=\"A2.T10.3.1.1.1.1.1.1.1.m1.1.1\" xref=\"A2.T10.3.1.1.1.1.1.1.1.m1.1.1.cmml\">γ</mi><annotation-xml encoding=\"MathML-Content\" id=\"A2.T10.3.1.1.1.1.1.1.1.m1.1b\"><ci id=\"A2.T10.3.1.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"A2.T10.3.1.1.1.1.1.1.1.m1.1.1\">𝛾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T10.3.1.1.1.1.1.1.1.m1.1c\">\\gamma</annotation></semantics></math></span></span>\n</span></span><span id=\"A2.T10.3.1.1.3\" class=\"ltx_text\"></span>\n</td>\n<td id=\"A2.T10.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"A2.T10.4.2.2.1\" class=\"ltx_text\"><math id=\"A2.T10.4.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma_{W}\" display=\"inline\"><semantics id=\"A2.T10.4.2.2.1.m1.1a\"><msub id=\"A2.T10.4.2.2.1.m1.1.1\" xref=\"A2.T10.4.2.2.1.m1.1.1.cmml\"><mi id=\"A2.T10.4.2.2.1.m1.1.1.2\" xref=\"A2.T10.4.2.2.1.m1.1.1.2.cmml\">γ</mi><mi id=\"A2.T10.4.2.2.1.m1.1.1.3\" xref=\"A2.T10.4.2.2.1.m1.1.1.3.cmml\">W</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"A2.T10.4.2.2.1.m1.1b\"><apply id=\"A2.T10.4.2.2.1.m1.1.1.cmml\" xref=\"A2.T10.4.2.2.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A2.T10.4.2.2.1.m1.1.1.1.cmml\" xref=\"A2.T10.4.2.2.1.m1.1.1\">subscript</csymbol><ci id=\"A2.T10.4.2.2.1.m1.1.1.2.cmml\" xref=\"A2.T10.4.2.2.1.m1.1.1.2\">𝛾</ci><ci id=\"A2.T10.4.2.2.1.m1.1.1.3.cmml\" xref=\"A2.T10.4.2.2.1.m1.1.1.3\">𝑊</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T10.4.2.2.1.m1.1c\">\\gamma_{W}</annotation></semantics></math></span></td>\n<td id=\"A2.T10.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"A2.T10.5.3.3.1\" class=\"ltx_text\"><math id=\"A2.T10.5.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma_{D}\" display=\"inline\"><semantics id=\"A2.T10.5.3.3.1.m1.1a\"><msub id=\"A2.T10.5.3.3.1.m1.1.1\" xref=\"A2.T10.5.3.3.1.m1.1.1.cmml\"><mi id=\"A2.T10.5.3.3.1.m1.1.1.2\" xref=\"A2.T10.5.3.3.1.m1.1.1.2.cmml\">γ</mi><mi id=\"A2.T10.5.3.3.1.m1.1.1.3\" xref=\"A2.T10.5.3.3.1.m1.1.1.3.cmml\">D</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"A2.T10.5.3.3.1.m1.1b\"><apply id=\"A2.T10.5.3.3.1.m1.1.1.cmml\" xref=\"A2.T10.5.3.3.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A2.T10.5.3.3.1.m1.1.1.1.cmml\" xref=\"A2.T10.5.3.3.1.m1.1.1\">subscript</csymbol><ci id=\"A2.T10.5.3.3.1.m1.1.1.2.cmml\" xref=\"A2.T10.5.3.3.1.m1.1.1.2\">𝛾</ci><ci id=\"A2.T10.5.3.3.1.m1.1.1.3.cmml\" xref=\"A2.T10.5.3.3.1.m1.1.1.3\">𝐷</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T10.5.3.3.1.m1.1c\">\\gamma_{D}</annotation></semantics></math></span></td>\n<td id=\"A2.T10.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\">NeFL-D (ResNet18)</td>\n</tr>\n<tr id=\"A2.T10.5.4\" class=\"ltx_tr\">\n<td id=\"A2.T10.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Layer 1 (64)</td>\n<td id=\"A2.T10.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Layer 2 (128)</td>\n<td id=\"A2.T10.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Layer3 (256)</td>\n<td id=\"A2.T10.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Layer 4 (512)</td>\n</tr>\n<tr id=\"A2.T10.5.5\" class=\"ltx_tr\">\n<td id=\"A2.T10.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A2.T10.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.20</td>\n<td id=\"A2.T10.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A2.T10.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.20</td>\n<td id=\"A2.T10.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1</td>\n<td id=\"A2.T10.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0,0</td>\n<td id=\"A2.T10.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1</td>\n<td id=\"A2.T10.5.5.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0,0</td>\n</tr>\n<tr id=\"A2.T10.5.6\" class=\"ltx_tr\">\n<td id=\"A2.T10.5.6.1\" class=\"ltx_td ltx_align_center ltx_border_t\">2</td>\n<td id=\"A2.T10.5.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.38</td>\n<td id=\"A2.T10.5.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A2.T10.5.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.38</td>\n<td id=\"A2.T10.5.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,0</td>\n<td id=\"A2.T10.5.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0,0</td>\n<td id=\"A2.T10.5.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,0</td>\n<td id=\"A2.T10.5.6.8\" class=\"ltx_td ltx_align_center ltx_border_t\">1,0</td>\n</tr>\n<tr id=\"A2.T10.5.7\" class=\"ltx_tr\">\n<td id=\"A2.T10.5.7.1\" class=\"ltx_td ltx_align_center ltx_border_t\">3</td>\n<td id=\"A2.T10.5.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.57</td>\n<td id=\"A2.T10.5.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A2.T10.5.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.57</td>\n<td id=\"A2.T10.5.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1</td>\n<td id=\"A2.T10.5.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1</td>\n<td id=\"A2.T10.5.7.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1</td>\n<td id=\"A2.T10.5.7.8\" class=\"ltx_td ltx_align_center ltx_border_t\">1,0</td>\n</tr>\n<tr id=\"A2.T10.5.8\" class=\"ltx_tr\">\n<td id=\"A2.T10.5.8.1\" class=\"ltx_td ltx_align_center ltx_border_t\">4</td>\n<td id=\"A2.T10.5.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.81</td>\n<td id=\"A2.T10.5.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A2.T10.5.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.81</td>\n<td id=\"A2.T10.5.8.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,0</td>\n<td id=\"A2.T10.5.8.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1</td>\n<td id=\"A2.T10.5.8.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0,0</td>\n<td id=\"A2.T10.5.8.8\" class=\"ltx_td ltx_align_center ltx_border_t\">1,1</td>\n</tr>\n<tr id=\"A2.T10.5.9\" class=\"ltx_tr\">\n<td id=\"A2.T10.5.9.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">5</td>\n<td id=\"A2.T10.5.9.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">1</td>\n<td id=\"A2.T10.5.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">1</td>\n<td id=\"A2.T10.5.9.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">1</td>\n<td id=\"A2.T10.5.9.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">1,1</td>\n<td id=\"A2.T10.5.9.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">1,1</td>\n<td id=\"A2.T10.5.9.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">1, 1</td>\n<td id=\"A2.T10.5.9.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">1,1</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "For the experiments presented in Table 1, Table 2, Table 4, Table 5 and Table 6, we consider five submodels with 𝜸=[γ1,γ2,γ3,γ4,γ5]=[0.2,0.4,0.6,0.8,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾3subscript𝛾4subscript𝛾50.20.40.60.81\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3},\\gamma_{4},\\gamma_{5}\\right]=\\left[0.2,0.4,0.6,0.8,1\\right] and 𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=\\left[0.04,0.16,0.36,0.64,1\\right] for Table 9. Additionally, for Table 3, we use three submodels with 𝜸=[γ1,γ2,γ3]=[0.5,0.75,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾30.50.751\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3}\\right]=\\left[0.5,0.75,1\\right]. Submodel details for ResNets and ViTs are detailed in Table 10 (ResNet18), Table 11 (ResNet34), Table 13 (ResNet56), Table 15 (ResNet110), Table 15 (Wide ResNet101_2) and Table 13 (ViT-B/16\nIn the tables, 1’s and 0’s denote the initial values of step sizes. A step size of zero indicates that a submodel does not include the corresponding block.\nNote that ResNets have a step size parameters for each block while ViTs have different step size parameters to be multiplied with SA and FFN.\nSubmodels in NeFL-W are characterized by 𝜸D=[1,…,1]subscript𝜸𝐷1…1\\bm{\\gamma}_{D}=[1,\\dots,1] and 𝜸Wsubscript𝜸𝑊\\bm{\\gamma}_{W} with a target size, while submodels in NeFL-D are characterized by 𝜸W=[1,…,1]subscript𝜸𝑊1…1\\bm{\\gamma}_{W}=[1,\\dots,1] and 𝜸Dsubscript𝜸𝐷\\bm{\\gamma}_{D} with a target size. Submodels in NeFL-WD are characterized by target size 𝜸W​𝜸Dsubscript𝜸𝑊subscript𝜸𝐷\\bm{\\gamma}_{W}\\bm{\\gamma}_{D}.\nCorresponding number of parameters and FLOPs are provided in Table 8."
        ]
    },
    "A2.T11": {
        "caption": "Table 11: Details of 𝜸𝜸\\bm{\\gamma} of NeFL-D and NeFL-WD on ResNet34",
        "table": "<table id=\"A2.T11.5\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle\">\n<tr id=\"A2.T11.5.3\" class=\"ltx_tr\">\n<td id=\"A2.T11.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\">\n<span id=\"A2.T11.5.3.4.1\" class=\"ltx_text\"></span> <span id=\"A2.T11.5.3.4.2\" class=\"ltx_text\">\n<span id=\"A2.T11.5.3.4.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"A2.T11.5.3.4.2.1.1\" class=\"ltx_tr\">\n<span id=\"A2.T11.5.3.4.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Model</span></span>\n<span id=\"A2.T11.5.3.4.2.1.2\" class=\"ltx_tr\">\n<span id=\"A2.T11.5.3.4.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">index</span></span>\n</span></span><span id=\"A2.T11.5.3.4.3\" class=\"ltx_text\"></span>\n</td>\n<td id=\"A2.T11.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\">\n<span id=\"A2.T11.3.1.1.2\" class=\"ltx_text\"></span> <span id=\"A2.T11.3.1.1.1\" class=\"ltx_text\">\n<span id=\"A2.T11.3.1.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"A2.T11.3.1.1.1.1.1.2\" class=\"ltx_tr\">\n<span id=\"A2.T11.3.1.1.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Model size</span></span>\n<span id=\"A2.T11.3.1.1.1.1.1.1\" class=\"ltx_tr\">\n<span id=\"A2.T11.3.1.1.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"A2.T11.3.1.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma\" display=\"inline\"><semantics id=\"A2.T11.3.1.1.1.1.1.1.1.m1.1a\"><mi id=\"A2.T11.3.1.1.1.1.1.1.1.m1.1.1\" xref=\"A2.T11.3.1.1.1.1.1.1.1.m1.1.1.cmml\">γ</mi><annotation-xml encoding=\"MathML-Content\" id=\"A2.T11.3.1.1.1.1.1.1.1.m1.1b\"><ci id=\"A2.T11.3.1.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"A2.T11.3.1.1.1.1.1.1.1.m1.1.1\">𝛾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T11.3.1.1.1.1.1.1.1.m1.1c\">\\gamma</annotation></semantics></math></span></span>\n</span></span><span id=\"A2.T11.3.1.1.3\" class=\"ltx_text\"></span>\n</td>\n<td id=\"A2.T11.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"A2.T11.4.2.2.1\" class=\"ltx_text\"><math id=\"A2.T11.4.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma_{W}\" display=\"inline\"><semantics id=\"A2.T11.4.2.2.1.m1.1a\"><msub id=\"A2.T11.4.2.2.1.m1.1.1\" xref=\"A2.T11.4.2.2.1.m1.1.1.cmml\"><mi id=\"A2.T11.4.2.2.1.m1.1.1.2\" xref=\"A2.T11.4.2.2.1.m1.1.1.2.cmml\">γ</mi><mi id=\"A2.T11.4.2.2.1.m1.1.1.3\" xref=\"A2.T11.4.2.2.1.m1.1.1.3.cmml\">W</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"A2.T11.4.2.2.1.m1.1b\"><apply id=\"A2.T11.4.2.2.1.m1.1.1.cmml\" xref=\"A2.T11.4.2.2.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A2.T11.4.2.2.1.m1.1.1.1.cmml\" xref=\"A2.T11.4.2.2.1.m1.1.1\">subscript</csymbol><ci id=\"A2.T11.4.2.2.1.m1.1.1.2.cmml\" xref=\"A2.T11.4.2.2.1.m1.1.1.2\">𝛾</ci><ci id=\"A2.T11.4.2.2.1.m1.1.1.3.cmml\" xref=\"A2.T11.4.2.2.1.m1.1.1.3\">𝑊</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T11.4.2.2.1.m1.1c\">\\gamma_{W}</annotation></semantics></math></span></td>\n<td id=\"A2.T11.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"A2.T11.5.3.3.1\" class=\"ltx_text\"><math id=\"A2.T11.5.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma_{D}\" display=\"inline\"><semantics id=\"A2.T11.5.3.3.1.m1.1a\"><msub id=\"A2.T11.5.3.3.1.m1.1.1\" xref=\"A2.T11.5.3.3.1.m1.1.1.cmml\"><mi id=\"A2.T11.5.3.3.1.m1.1.1.2\" xref=\"A2.T11.5.3.3.1.m1.1.1.2.cmml\">γ</mi><mi id=\"A2.T11.5.3.3.1.m1.1.1.3\" xref=\"A2.T11.5.3.3.1.m1.1.1.3.cmml\">D</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"A2.T11.5.3.3.1.m1.1b\"><apply id=\"A2.T11.5.3.3.1.m1.1.1.cmml\" xref=\"A2.T11.5.3.3.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A2.T11.5.3.3.1.m1.1.1.1.cmml\" xref=\"A2.T11.5.3.3.1.m1.1.1\">subscript</csymbol><ci id=\"A2.T11.5.3.3.1.m1.1.1.2.cmml\" xref=\"A2.T11.5.3.3.1.m1.1.1.2\">𝛾</ci><ci id=\"A2.T11.5.3.3.1.m1.1.1.3.cmml\" xref=\"A2.T11.5.3.3.1.m1.1.1.3\">𝐷</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T11.5.3.3.1.m1.1c\">\\gamma_{D}</annotation></semantics></math></span></td>\n<td id=\"A2.T11.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\">NeFL-D (ResNet34)</td>\n</tr>\n<tr id=\"A2.T11.5.4\" class=\"ltx_tr\">\n<td id=\"A2.T11.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Layer 1 (64)</td>\n<td id=\"A2.T11.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Layer 2 (128)</td>\n<td id=\"A2.T11.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Layer3 (256)</td>\n<td id=\"A2.T11.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Layer 4 (512)</td>\n</tr>\n<tr id=\"A2.T11.5.5\" class=\"ltx_tr\">\n<td id=\"A2.T11.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A2.T11.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.23</td>\n<td id=\"A2.T11.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A2.T11.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.23</td>\n<td id=\"A2.T11.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,0,0</td>\n<td id=\"A2.T11.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,0,0,0</td>\n<td id=\"A2.T11.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,0,0,0,0,0</td>\n<td id=\"A2.T11.5.5.8\" class=\"ltx_td ltx_align_center ltx_border_t\">1,0,0</td>\n</tr>\n<tr id=\"A2.T11.5.6\" class=\"ltx_tr\">\n<td id=\"A2.T11.5.6.1\" class=\"ltx_td ltx_align_center ltx_border_t\">2</td>\n<td id=\"A2.T11.5.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.39</td>\n<td id=\"A2.T11.5.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A2.T11.5.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.39</td>\n<td id=\"A2.T11.5.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1,1</td>\n<td id=\"A2.T11.5.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1,1,1</td>\n<td id=\"A2.T11.5.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1,0,0,0,1</td>\n<td id=\"A2.T11.5.6.8\" class=\"ltx_td ltx_align_center ltx_border_t\">1,0,0</td>\n</tr>\n<tr id=\"A2.T11.5.7\" class=\"ltx_tr\">\n<td id=\"A2.T11.5.7.1\" class=\"ltx_td ltx_align_center ltx_border_t\">3</td>\n<td id=\"A2.T11.5.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.61</td>\n<td id=\"A2.T11.5.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A2.T11.5.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.61</td>\n<td id=\"A2.T11.5.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1,1</td>\n<td id=\"A2.T11.5.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1,1,1</td>\n<td id=\"A2.T11.5.7.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1,0,0,0,1</td>\n<td id=\"A2.T11.5.7.8\" class=\"ltx_td ltx_align_center ltx_border_t\">1,0,1</td>\n</tr>\n<tr id=\"A2.T11.5.8\" class=\"ltx_tr\">\n<td id=\"A2.T11.5.8.1\" class=\"ltx_td ltx_align_center ltx_border_t\">4</td>\n<td id=\"A2.T11.5.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.81</td>\n<td id=\"A2.T11.5.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A2.T11.5.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.81</td>\n<td id=\"A2.T11.5.8.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1,1</td>\n<td id=\"A2.T11.5.8.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,0,0,1</td>\n<td id=\"A2.T11.5.8.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,1,0,0,0,1</td>\n<td id=\"A2.T11.5.8.8\" class=\"ltx_td ltx_align_center ltx_border_t\">1,1,1</td>\n</tr>\n<tr id=\"A2.T11.5.9\" class=\"ltx_tr\">\n<td id=\"A2.T11.5.9.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">5</td>\n<td id=\"A2.T11.5.9.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">1</td>\n<td id=\"A2.T11.5.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">1</td>\n<td id=\"A2.T11.5.9.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">1</td>\n<td id=\"A2.T11.5.9.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">1,1,1</td>\n<td id=\"A2.T11.5.9.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">1,1,1,1</td>\n<td id=\"A2.T11.5.9.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">1,1,1,1,1,1</td>\n<td id=\"A2.T11.5.9.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">1,1,1</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "For the experiments presented in Table 1, Table 2, Table 4, Table 5 and Table 6, we consider five submodels with 𝜸=[γ1,γ2,γ3,γ4,γ5]=[0.2,0.4,0.6,0.8,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾3subscript𝛾4subscript𝛾50.20.40.60.81\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3},\\gamma_{4},\\gamma_{5}\\right]=\\left[0.2,0.4,0.6,0.8,1\\right] and 𝜸=[0.04,0.16,0.36,0.64,1]𝜸0.040.160.360.641\\bm{\\gamma}=\\left[0.04,0.16,0.36,0.64,1\\right] for Table 9. Additionally, for Table 3, we use three submodels with 𝜸=[γ1,γ2,γ3]=[0.5,0.75,1]𝜸subscript𝛾1subscript𝛾2subscript𝛾30.50.751\\bm{\\gamma}=\\left[\\gamma_{1},\\gamma_{2},\\gamma_{3}\\right]=\\left[0.5,0.75,1\\right]. Submodel details for ResNets and ViTs are detailed in Table 10 (ResNet18), Table 11 (ResNet34), Table 13 (ResNet56), Table 15 (ResNet110), Table 15 (Wide ResNet101_2) and Table 13 (ViT-B/16\nIn the tables, 1’s and 0’s denote the initial values of step sizes. A step size of zero indicates that a submodel does not include the corresponding block.\nNote that ResNets have a step size parameters for each block while ViTs have different step size parameters to be multiplied with SA and FFN.\nSubmodels in NeFL-W are characterized by 𝜸D=[1,…,1]subscript𝜸𝐷1…1\\bm{\\gamma}_{D}=[1,\\dots,1] and 𝜸Wsubscript𝜸𝑊\\bm{\\gamma}_{W} with a target size, while submodels in NeFL-D are characterized by 𝜸W=[1,…,1]subscript𝜸𝑊1…1\\bm{\\gamma}_{W}=[1,\\dots,1] and 𝜸Dsubscript𝜸𝐷\\bm{\\gamma}_{D} with a target size. Submodels in NeFL-WD are characterized by target size 𝜸W​𝜸Dsubscript𝜸𝑊subscript𝜸𝐷\\bm{\\gamma}_{W}\\bm{\\gamma}_{D}.\nCorresponding number of parameters and FLOPs are provided in Table 8."
        ]
    }
}