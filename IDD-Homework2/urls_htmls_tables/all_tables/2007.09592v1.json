{
    "S4.T1": {
        "caption": "Table 1: Performance and ablation studies on VQAv2.0. All models listed here are single model, which trained on the training set to report Val scores and trained on training and validation sets to report Test-dev and Test-std scores. The first row represents the vanilla trained baseline model. The rows begin with ++ represents the data augmentation method added to the first row. EDA-3 represents that we generate three augmented questions per original questions using EDA [40]. ††\\dagger This method is implemented based on a stronger BUTD (see [35]) and obtains a relatively small improvement (0.48%) on validation score, even so, its test-dev score is surpassed by our method.",
        "table": "<table id=\"S4.T1.13.13\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.13.13.10.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.13.13.10.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" style=\"padding-left:4.5pt;padding-right:4.5pt;\" rowspan=\"2\"><span id=\"S4.T1.13.13.10.1.1.1\" class=\"ltx_text\">Method</span></th>\n<td id=\"S4.T1.13.13.10.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.5pt;padding-right:4.5pt;\" rowspan=\"2\"><span id=\"S4.T1.13.13.10.1.2.1\" class=\"ltx_text\">Val</span></td>\n<td id=\"S4.T1.13.13.10.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.5pt;padding-right:4.5pt;\" colspan=\"4\">Test-dev</td>\n<td id=\"S4.T1.13.13.10.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.5pt;padding-right:4.5pt;\" rowspan=\"2\"><span id=\"S4.T1.13.13.10.1.4.1\" class=\"ltx_text\">Test-std</span></td>\n</tr>\n<tr id=\"S4.T1.13.13.11.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.13.13.11.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">Overall</td>\n<td id=\"S4.T1.13.13.11.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">Yes/no</td>\n<td id=\"S4.T1.13.13.11.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">Number</td>\n<td id=\"S4.T1.13.13.11.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">Others</td>\n</tr>\n<tr id=\"S4.T1.13.13.12.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.13.13.12.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">BUTD <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\">2</a>]</cite>\n</th>\n<td id=\"S4.T1.13.13.12.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">63.32</td>\n<td id=\"S4.T1.13.13.12.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">65.23</td>\n<td id=\"S4.T1.13.13.12.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">81.82</td>\n<td id=\"S4.T1.13.13.12.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">44.21</td>\n<td id=\"S4.T1.13.13.12.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">56.05</td>\n<td id=\"S4.T1.13.13.12.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">65.67</td>\n</tr>\n<tr id=\"S4.T1.13.13.13.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.13.13.13.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">+Noise</th>\n<td id=\"S4.T1.13.13.13.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">63.28</td>\n<td id=\"S4.T1.13.13.13.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">64.80</td>\n<td id=\"S4.T1.13.13.13.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">81.03</td>\n<td id=\"S4.T1.13.13.13.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">43.96</td>\n<td id=\"S4.T1.13.13.13.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">55.70</td>\n<td id=\"S4.T1.13.13.13.4.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n</tr>\n<tr id=\"S4.T1.13.13.14.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.13.13.14.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">+EDA-3 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib40\" title=\"\" class=\"ltx_ref\">40</a>]</cite>\n</th>\n<td id=\"S4.T1.13.13.14.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">62.73</td>\n<td id=\"S4.T1.13.13.14.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n<td id=\"S4.T1.13.13.14.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n<td id=\"S4.T1.13.13.14.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n<td id=\"S4.T1.13.13.14.5.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n<td id=\"S4.T1.13.13.14.5.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n</tr>\n<tr id=\"S4.T1.5.5.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.5.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">+CC <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib35\" title=\"\" class=\"ltx_ref\">35</a>]</cite><math id=\"S4.T1.5.5.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\dagger\" display=\"inline\"><semantics id=\"S4.T1.5.5.1.1.m1.1a\"><mo id=\"S4.T1.5.5.1.1.m1.1.1\" xref=\"S4.T1.5.5.1.1.m1.1.1.cmml\">†</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.5.5.1.1.m1.1b\"><ci id=\"S4.T1.5.5.1.1.m1.1.1.cmml\" xref=\"S4.T1.5.5.1.1.m1.1.1\">†</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.5.5.1.1.m1.1c\">\\dagger</annotation></semantics></math>\n</th>\n<td id=\"S4.T1.5.5.1.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">65.53</td>\n<td id=\"S4.T1.5.5.1.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">67.55</td>\n<td id=\"S4.T1.5.5.1.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n<td id=\"S4.T1.5.5.1.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n<td id=\"S4.T1.5.5.1.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n<td id=\"S4.T1.5.5.1.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n</tr>\n<tr id=\"S4.T1.11.11.7\" class=\"ltx_tr\">\n<th id=\"S4.T1.11.11.7.7\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">+Ours</th>\n<td id=\"S4.T1.6.6.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><math id=\"S4.T1.6.6.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{65.16}\" display=\"inline\"><semantics id=\"S4.T1.6.6.2.1.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T1.6.6.2.1.m1.1.1\" xref=\"S4.T1.6.6.2.1.m1.1.1.cmml\">65.16</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.6.6.2.1.m1.1b\"><cn type=\"float\" id=\"S4.T1.6.6.2.1.m1.1.1.cmml\" xref=\"S4.T1.6.6.2.1.m1.1.1\">65.16</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.6.6.2.1.m1.1c\">\\mathbf{65.16}</annotation></semantics></math></td>\n<td id=\"S4.T1.7.7.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><math id=\"S4.T1.7.7.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{67.78}\" display=\"inline\"><semantics id=\"S4.T1.7.7.3.2.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T1.7.7.3.2.m1.1.1\" xref=\"S4.T1.7.7.3.2.m1.1.1.cmml\">67.78</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.7.7.3.2.m1.1b\"><cn type=\"float\" id=\"S4.T1.7.7.3.2.m1.1.1.cmml\" xref=\"S4.T1.7.7.3.2.m1.1.1\">67.78</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.7.7.3.2.m1.1c\">\\mathbf{67.78}</annotation></semantics></math></td>\n<td id=\"S4.T1.8.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><math id=\"S4.T1.8.8.4.3.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{84.08}\" display=\"inline\"><semantics id=\"S4.T1.8.8.4.3.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T1.8.8.4.3.m1.1.1\" xref=\"S4.T1.8.8.4.3.m1.1.1.cmml\">84.08</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.8.8.4.3.m1.1b\"><cn type=\"float\" id=\"S4.T1.8.8.4.3.m1.1.1.cmml\" xref=\"S4.T1.8.8.4.3.m1.1.1\">84.08</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.8.8.4.3.m1.1c\">\\mathbf{84.08}</annotation></semantics></math></td>\n<td id=\"S4.T1.9.9.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><math id=\"S4.T1.9.9.5.4.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{47.55}\" display=\"inline\"><semantics id=\"S4.T1.9.9.5.4.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T1.9.9.5.4.m1.1.1\" xref=\"S4.T1.9.9.5.4.m1.1.1.cmml\">47.55</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.9.9.5.4.m1.1b\"><cn type=\"float\" id=\"S4.T1.9.9.5.4.m1.1.1.cmml\" xref=\"S4.T1.9.9.5.4.m1.1.1\">47.55</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.9.9.5.4.m1.1c\">\\mathbf{47.55}</annotation></semantics></math></td>\n<td id=\"S4.T1.10.10.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><math id=\"S4.T1.10.10.6.5.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{58.48}\" display=\"inline\"><semantics id=\"S4.T1.10.10.6.5.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T1.10.10.6.5.m1.1.1\" xref=\"S4.T1.10.10.6.5.m1.1.1.cmml\">58.48</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.10.10.6.5.m1.1b\"><cn type=\"float\" id=\"S4.T1.10.10.6.5.m1.1.1.cmml\" xref=\"S4.T1.10.10.6.5.m1.1.1\">58.48</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.10.10.6.5.m1.1c\">\\mathbf{58.48}</annotation></semantics></math></td>\n<td id=\"S4.T1.11.11.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.5pt;padding-right:4.5pt;\"><math id=\"S4.T1.11.11.7.6.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{68.27}\" display=\"inline\"><semantics id=\"S4.T1.11.11.7.6.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T1.11.11.7.6.m1.1.1\" xref=\"S4.T1.11.11.7.6.m1.1.1.cmml\">68.27</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.11.11.7.6.m1.1b\"><cn type=\"float\" id=\"S4.T1.11.11.7.6.m1.1.1.cmml\" xref=\"S4.T1.11.11.7.6.m1.1.1\">68.27</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.11.11.7.6.m1.1c\">\\mathbf{68.27}</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T1.12.12.8\" class=\"ltx_tr\">\n<th id=\"S4.T1.12.12.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">+Ours <math id=\"S4.T1.12.12.8.1.m1.1\" class=\"ltx_Math\" alttext=\"w/o\" display=\"inline\"><semantics id=\"S4.T1.12.12.8.1.m1.1a\"><mrow id=\"S4.T1.12.12.8.1.m1.1.1\" xref=\"S4.T1.12.12.8.1.m1.1.1.cmml\"><mi id=\"S4.T1.12.12.8.1.m1.1.1.2\" xref=\"S4.T1.12.12.8.1.m1.1.1.2.cmml\">w</mi><mo id=\"S4.T1.12.12.8.1.m1.1.1.1\" xref=\"S4.T1.12.12.8.1.m1.1.1.1.cmml\">/</mo><mi id=\"S4.T1.12.12.8.1.m1.1.1.3\" xref=\"S4.T1.12.12.8.1.m1.1.1.3.cmml\">o</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.12.12.8.1.m1.1b\"><apply id=\"S4.T1.12.12.8.1.m1.1.1.cmml\" xref=\"S4.T1.12.12.8.1.m1.1.1\"><divide id=\"S4.T1.12.12.8.1.m1.1.1.1.cmml\" xref=\"S4.T1.12.12.8.1.m1.1.1.1\"></divide><ci id=\"S4.T1.12.12.8.1.m1.1.1.2.cmml\" xref=\"S4.T1.12.12.8.1.m1.1.1.2\">𝑤</ci><ci id=\"S4.T1.12.12.8.1.m1.1.1.3.cmml\" xref=\"S4.T1.12.12.8.1.m1.1.1.3\">𝑜</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.12.12.8.1.m1.1c\">w/o</annotation></semantics></math> Aug-Q</th>\n<td id=\"S4.T1.12.12.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">65.05</td>\n<td id=\"S4.T1.12.12.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">67.58</td>\n<td id=\"S4.T1.12.12.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">83.85</td>\n<td id=\"S4.T1.12.12.8.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">47.34</td>\n<td id=\"S4.T1.12.12.8.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">58.31</td>\n<td id=\"S4.T1.12.12.8.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n</tr>\n<tr id=\"S4.T1.13.13.9\" class=\"ltx_tr\">\n<th id=\"S4.T1.13.13.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">+Ours <math id=\"S4.T1.13.13.9.1.m1.1\" class=\"ltx_Math\" alttext=\"w/o\" display=\"inline\"><semantics id=\"S4.T1.13.13.9.1.m1.1a\"><mrow id=\"S4.T1.13.13.9.1.m1.1.1\" xref=\"S4.T1.13.13.9.1.m1.1.1.cmml\"><mi id=\"S4.T1.13.13.9.1.m1.1.1.2\" xref=\"S4.T1.13.13.9.1.m1.1.1.2.cmml\">w</mi><mo id=\"S4.T1.13.13.9.1.m1.1.1.1\" xref=\"S4.T1.13.13.9.1.m1.1.1.1.cmml\">/</mo><mi id=\"S4.T1.13.13.9.1.m1.1.1.3\" xref=\"S4.T1.13.13.9.1.m1.1.1.3.cmml\">o</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.13.13.9.1.m1.1b\"><apply id=\"S4.T1.13.13.9.1.m1.1.1.cmml\" xref=\"S4.T1.13.13.9.1.m1.1.1\"><divide id=\"S4.T1.13.13.9.1.m1.1.1.1.cmml\" xref=\"S4.T1.13.13.9.1.m1.1.1.1\"></divide><ci id=\"S4.T1.13.13.9.1.m1.1.1.2.cmml\" xref=\"S4.T1.13.13.9.1.m1.1.1.2\">𝑤</ci><ci id=\"S4.T1.13.13.9.1.m1.1.1.3.cmml\" xref=\"S4.T1.13.13.9.1.m1.1.1.3\">𝑜</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.13.13.9.1.m1.1c\">w/o</annotation></semantics></math> Aug-V</th>\n<td id=\"S4.T1.13.13.9.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">64.69</td>\n<td id=\"S4.T1.13.13.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">67.45</td>\n<td id=\"S4.T1.13.13.9.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">83.55</td>\n<td id=\"S4.T1.13.13.9.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">46.96</td>\n<td id=\"S4.T1.13.13.9.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">58.37</td>\n<td id=\"S4.T1.13.13.9.7\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.5pt;padding-right:4.5pt;\">-</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Table 1 shows the results on VQAv2 validation, test-dev and test-std sets. We compare our method with the BUTD vanilla training setting. Our method outperforms vanilla trained baseline, making gains of 1.82%, 2.55%, 2.6% on validation, test-dev and test-std set, respectively. Furthermore, our adversarial training method only consumes a small amount of additional time (4 min for an epoch) while allows for a considerable increase in standard accuracy.",
            "We compare our method with related VQA data augmentation method CC [35], and NLP data augmentation method EDA [40] and report the results on VQAv2 in Table 1.\nThe model of CC is trained to predict the same (correct) answer for a question and its rephrasing, which are generated by a VQG module in their training scheme. Their outperforming validation accuracy is in contrast to the less competitive accuracy on the test-dev set. It reveals CC is less capable of generalizing on unseen data. Other related studies (e.g., CausalVQA [1], CTM[33]) explore VQA data augmentation as a complementary result for constructing a new VQA dataset, and they evaluate their data augmentation method on the new dataset instead of VQAv2, so it is hard to compare our method with them.\nEDA is a text editing technique boosting model performance on the text classification task. We implement it to generate three augmented questions per original question and set the percent of words in a question that are changed α=0.1𝛼0.1\\alpha=0.1. However, results (see Table 1) show that EDA could degrade the performance on clean data and make a 0.59% accuracy drop. It demonstrates that text editing techniques for generating question are not applicable as large numbers of questions are too short that could not be allowed to insert, delete or swap words. Moreover, sometimes the text editing may change the original semantic meaning of the question, which leads to noisy and even incorrect data.",
            "Since our augmented data might be regarded as injecting noise to original data, we also set comparison by injecting random noise with a standard deviation of 0.3 (same as our ϵitalic-ϵ\\epsilon in reported results) to visual data. Random noise, as well, could be regarded as a naive attacker that causes a 0.9% absolute accuracy drop on the vanilla model. However, jointly training with clean and noising data could not boost the performance on clean data, as reported in Table 1. It proves that our generated data are drawn from the proper distribution that let the model take full advantage of the regularization power of adversarial examples.",
            "Results from ablation studies to test the contributions of our method’s components are given in Table 1. The augmentation on visual and textual (question) data both make their individual contribution to improve the accuracy. We observe that visual adversarial examples are critical to our performance, and removing it causes a 0.47% accuracy drop (see Ours w/o𝑤𝑜w/o Aug-V) on the validation set. The question augmentation also leads to comparable improvements, see the model of Ours w/o𝑤𝑜w/o Aug-V."
        ]
    },
    "S4.T3": {
        "caption": "Table 2: Validation accuracy (%) across BUTD with and without our framework on different training set sizes.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Training set size</th>\n<th id=\"S4.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">BUTD</th>\n<th id=\"S4.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">+Ours</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.3.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">80%</td>\n<td id=\"S4.T3.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">62.77</td>\n<td id=\"S4.T3.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">64.27 <span id=\"S4.T3.1.3.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(+1.50)</span>\n</td>\n</tr>\n<tr id=\"S4.T3.1.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.4.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">60%</td>\n<td id=\"S4.T3.1.4.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">61.55</td>\n<td id=\"S4.T3.1.4.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">63.11 <span id=\"S4.T3.1.4.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(+1.56)</span>\n</td>\n</tr>\n<tr id=\"S4.T3.1.5.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.5.3.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">40%</td>\n<td id=\"S4.T3.1.5.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">59.47</td>\n<td id=\"S4.T3.1.5.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">61.35 <span id=\"S4.T3.1.5.3.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">(+1.88)</span>\n</td>\n</tr>\n<tr id=\"S4.T3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">20%</td>\n<td id=\"S4.T3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">55.45</td>\n<td id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">57.39 <span id=\"S4.T3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">(<math id=\"S4.T3.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{+1.94}\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.1.m1.1a\"><mrow id=\"S4.T3.1.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.1.m1.1.1.cmml\"><mo id=\"S4.T3.1.1.1.1.m1.1.1a\" xref=\"S4.T3.1.1.1.1.m1.1.1.cmml\">+</mo><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T3.1.1.1.1.m1.1.1.2\" xref=\"S4.T3.1.1.1.1.m1.1.1.2.cmml\">1.94</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.1.m1.1b\"><apply id=\"S4.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1\"><plus id=\"S4.T3.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1\"></plus><cn type=\"float\" id=\"S4.T3.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1.2\">1.94</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.1.m1.1c\">\\mathbf{+1.94}</annotation></semantics></math>)</span>\n</td>\n</tr>\n</tbody>\n</table>\n<table id=\"S4.T3.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S4.T3.2.1.1.m1.2\" class=\"ltx_Math\" alttext=\"(start,end)\" display=\"inline\"><semantics id=\"S4.T3.2.1.1.m1.2a\"><mrow id=\"S4.T3.2.1.1.m1.2.2.2\" xref=\"S4.T3.2.1.1.m1.2.2.3.cmml\"><mo stretchy=\"false\" id=\"S4.T3.2.1.1.m1.2.2.2.3\" xref=\"S4.T3.2.1.1.m1.2.2.3.cmml\">(</mo><mrow id=\"S4.T3.2.1.1.m1.1.1.1.1\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.cmml\"><mi id=\"S4.T3.2.1.1.m1.1.1.1.1.2\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.2.cmml\">s</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.2.1.1.m1.1.1.1.1.1\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.1.cmml\">​</mo><mi id=\"S4.T3.2.1.1.m1.1.1.1.1.3\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.3.cmml\">t</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.2.1.1.m1.1.1.1.1.1a\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.1.cmml\">​</mo><mi id=\"S4.T3.2.1.1.m1.1.1.1.1.4\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.4.cmml\">a</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.2.1.1.m1.1.1.1.1.1b\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.1.cmml\">​</mo><mi id=\"S4.T3.2.1.1.m1.1.1.1.1.5\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.5.cmml\">r</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.2.1.1.m1.1.1.1.1.1c\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.1.cmml\">​</mo><mi id=\"S4.T3.2.1.1.m1.1.1.1.1.6\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.6.cmml\">t</mi></mrow><mo id=\"S4.T3.2.1.1.m1.2.2.2.4\" xref=\"S4.T3.2.1.1.m1.2.2.3.cmml\">,</mo><mrow id=\"S4.T3.2.1.1.m1.2.2.2.2\" xref=\"S4.T3.2.1.1.m1.2.2.2.2.cmml\"><mi id=\"S4.T3.2.1.1.m1.2.2.2.2.2\" xref=\"S4.T3.2.1.1.m1.2.2.2.2.2.cmml\">e</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.2.1.1.m1.2.2.2.2.1\" xref=\"S4.T3.2.1.1.m1.2.2.2.2.1.cmml\">​</mo><mi id=\"S4.T3.2.1.1.m1.2.2.2.2.3\" xref=\"S4.T3.2.1.1.m1.2.2.2.2.3.cmml\">n</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.2.1.1.m1.2.2.2.2.1a\" xref=\"S4.T3.2.1.1.m1.2.2.2.2.1.cmml\">​</mo><mi id=\"S4.T3.2.1.1.m1.2.2.2.2.4\" xref=\"S4.T3.2.1.1.m1.2.2.2.2.4.cmml\">d</mi></mrow><mo stretchy=\"false\" id=\"S4.T3.2.1.1.m1.2.2.2.5\" xref=\"S4.T3.2.1.1.m1.2.2.3.cmml\">)</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.1.1.m1.2b\"><interval closure=\"open\" id=\"S4.T3.2.1.1.m1.2.2.3.cmml\" xref=\"S4.T3.2.1.1.m1.2.2.2\"><apply id=\"S4.T3.2.1.1.m1.1.1.1.1.cmml\" xref=\"S4.T3.2.1.1.m1.1.1.1.1\"><times id=\"S4.T3.2.1.1.m1.1.1.1.1.1.cmml\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.1\"></times><ci id=\"S4.T3.2.1.1.m1.1.1.1.1.2.cmml\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.2\">𝑠</ci><ci id=\"S4.T3.2.1.1.m1.1.1.1.1.3.cmml\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.3\">𝑡</ci><ci id=\"S4.T3.2.1.1.m1.1.1.1.1.4.cmml\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.4\">𝑎</ci><ci id=\"S4.T3.2.1.1.m1.1.1.1.1.5.cmml\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.5\">𝑟</ci><ci id=\"S4.T3.2.1.1.m1.1.1.1.1.6.cmml\" xref=\"S4.T3.2.1.1.m1.1.1.1.1.6\">𝑡</ci></apply><apply id=\"S4.T3.2.1.1.m1.2.2.2.2.cmml\" xref=\"S4.T3.2.1.1.m1.2.2.2.2\"><times id=\"S4.T3.2.1.1.m1.2.2.2.2.1.cmml\" xref=\"S4.T3.2.1.1.m1.2.2.2.2.1\"></times><ci id=\"S4.T3.2.1.1.m1.2.2.2.2.2.cmml\" xref=\"S4.T3.2.1.1.m1.2.2.2.2.2\">𝑒</ci><ci id=\"S4.T3.2.1.1.m1.2.2.2.2.3.cmml\" xref=\"S4.T3.2.1.1.m1.2.2.2.2.3\">𝑛</ci><ci id=\"S4.T3.2.1.1.m1.2.2.2.2.4.cmml\" xref=\"S4.T3.2.1.1.m1.2.2.2.2.4\">𝑑</ci></apply></interval></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.1.1.m1.2c\">(start,end)</annotation></semantics></math></th>\n<th id=\"S4.T3.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Accuracy</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.3.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">(5,25)</th>\n<td id=\"S4.T3.3.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">63.93</td>\n</tr>\n<tr id=\"S4.T3.3.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">(10,25)</th>\n<td id=\"S4.T3.3.4.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">64.08</td>\n</tr>\n<tr id=\"S4.T3.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">(10,15)</th>\n<td id=\"S4.T3.3.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S4.T3.3.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{65.16}\" display=\"inline\"><semantics id=\"S4.T3.3.2.1.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T3.3.2.1.m1.1.1\" xref=\"S4.T3.3.2.1.m1.1.1.cmml\">65.16</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.3.2.1.m1.1b\"><cn type=\"float\" id=\"S4.T3.3.2.1.m1.1.1.cmml\" xref=\"S4.T3.3.2.1.m1.1.1\">65.16</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.3.2.1.m1.1c\">\\mathbf{65.16}</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T3.3.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">(15,20)</th>\n<td id=\"S4.T3.3.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">64.18</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Furthermore, we conduct experiments using a fraction of the available data in the training set. As overfitting tends to be more severe when training on smaller datasets, we show that our method has more significant improvements for smaller training sets. We run both vanilla training and our method for the following training set fractions (%): {20,40,60,80}20406080\\left\\{20,40,60,80\\right\\}. Performances are shown in Table 3. The best accuracy without augmentation, 63.32%, was achieved using 100% of the training data. Our method surpasses it with 80% of the training data, achieving 64.27%.",
            "We empirically find that the time when the adversarial examples are injected into training has an effect on accuracy. We demonstrate this via ablation studies in Table 3.\nWe try several adversarial training period (5,25)525(5,25), (10,25)1025(10,25), (10,15)1015(10,15) (15,20)1520(15,20). They respectively evaluate the effect of delaying injecting additional training data after different epochs and prove the advantage gained from fine-tuning with clean data in the last few epochs. Results show that (10,15)1015(10,15) is the optimal adversarial training period, and it surpasses the baseline model and achieves 65.16% accuracy. One explanation is that adversarial examples have different underlying distributions to normal examples, and if boosting model performance on clean examples is our main goal, the fitting ability of model on clean examples need to be retrieved at the beginning and the end of the training process. It is inappropriate to inject the perturbed examples at an early stage where the model has not warm up. We fix the adversarial training period as (10,15)1015(10,15) and reuse the same partially trained (for 10 epochs) model as a starting point for the other ablation experiments."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Validation accuracy (%) of vanilla and adversarially trained (using IFGSM ϵ=0.3,α=0.0625,n=2formulae-sequenceitalic-ϵ0.3formulae-sequence𝛼0.0625𝑛2\\epsilon=0.3,\\alpha=0.0625,n=2) network on clean and adversarial examples with various test-time attackers. Parap. represents the generated paraphrases in our method. Note that the IFGSM and PGD still act as the white-box attacker when testing.",
        "table": "<table id=\"S4.T4.4.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.3.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.3.1.2\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\"></th>\n<th id=\"S4.T4.3.3.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">Clean</th>\n<th id=\"S4.T4.3.3.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">IFGSM</th>\n<th id=\"S4.T4.3.3.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">Parap.</th>\n<th id=\"S4.T4.3.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">IFGSM <math id=\"S4.T4.3.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\&amp;\" display=\"inline\"><semantics id=\"S4.T4.3.3.1.1.m1.1a\"><mo id=\"S4.T4.3.3.1.1.m1.1.1\" xref=\"S4.T4.3.3.1.1.m1.1.1.cmml\">&amp;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.3.3.1.1.m1.1b\"><and id=\"S4.T4.3.3.1.1.m1.1.1.cmml\" xref=\"S4.T4.3.3.1.1.m1.1.1\"></and></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.3.3.1.1.m1.1c\">\\&amp;</annotation></semantics></math> Parap.</th>\n<th id=\"S4.T4.3.3.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">PGD</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.4.4.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.4.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">BUTD <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\">2</a>]</cite>\n</th>\n<th id=\"S4.T4.4.4.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">63.32</th>\n<td id=\"S4.T4.4.4.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">30.83</td>\n<td id=\"S4.T4.4.4.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">54.03</td>\n<td id=\"S4.T4.4.4.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">22.09</td>\n<td id=\"S4.T4.4.4.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">18.05</td>\n</tr>\n<tr id=\"S4.T4.4.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.4.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">     +Ours</th>\n<th id=\"S4.T4.4.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\"><math id=\"S4.T4.4.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{65.16}\" display=\"inline\"><semantics id=\"S4.T4.4.4.2.1.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T4.4.4.2.1.m1.1.1\" xref=\"S4.T4.4.4.2.1.m1.1.1.cmml\">65.16</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.4.4.2.1.m1.1b\"><cn type=\"float\" id=\"S4.T4.4.4.2.1.m1.1.1.cmml\" xref=\"S4.T4.4.4.2.1.m1.1.1\">65.16</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.4.4.2.1.m1.1c\">\\mathbf{65.16}</annotation></semantics></math></th>\n<td id=\"S4.T4.4.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">44.57</td>\n<td id=\"S4.T4.4.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">63.18</td>\n<td id=\"S4.T4.4.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">43.64</td>\n<td id=\"S4.T4.4.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">22.64</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Furthermore, we conduct experiments using a fraction of the available data in the training set. As overfitting tends to be more severe when training on smaller datasets, we show that our method has more significant improvements for smaller training sets. We run both vanilla training and our method for the following training set fractions (%): {20,40,60,80}20406080\\left\\{20,40,60,80\\right\\}. Performances are shown in Table 3. The best accuracy without augmentation, 63.32%, was achieved using 100% of the training data. Our method surpasses it with 80% of the training data, achieving 64.27%.",
            "We empirically find that the time when the adversarial examples are injected into training has an effect on accuracy. We demonstrate this via ablation studies in Table 3.\nWe try several adversarial training period (5,25)525(5,25), (10,25)1025(10,25), (10,15)1015(10,15) (15,20)1520(15,20). They respectively evaluate the effect of delaying injecting additional training data after different epochs and prove the advantage gained from fine-tuning with clean data in the last few epochs. Results show that (10,15)1015(10,15) is the optimal adversarial training period, and it surpasses the baseline model and achieves 65.16% accuracy. One explanation is that adversarial examples have different underlying distributions to normal examples, and if boosting model performance on clean examples is our main goal, the fitting ability of model on clean examples need to be retrieved at the beginning and the end of the training process. It is inappropriate to inject the perturbed examples at an early stage where the model has not warm up. We fix the adversarial training period as (10,15)1015(10,15) and reuse the same partially trained (for 10 epochs) model as a starting point for the other ablation experiments.",
            "Improvement of model robustness against adversarial attacks is a reward of our adversarial training scheme.\nAs shown in Table 4, we are able to significantly increase accuracy on visual adversarial examples by 13.74%, when using the training attacker at test-time. Following [8], we test a stronger PGD attacker (ϵ=0.5,α=0.125,n=6formulae-sequenceitalic-ϵ0.5formulae-sequence𝛼0.125𝑛6\\epsilon=0.5,\\alpha=0.125,n=6) and our model could beat the baseline by 4.59%.\nOn the textual side, the accuracy of the vanilla model on qa​d​vsubscript𝑞𝑎𝑑𝑣q_{adv} is 54.03% and the flip rate (the rate of changing the original answers, lower is better) is 36.72% while our adversarially trained model obtained an accuracy of 63.18% and a flip rate of 18.8% on qa​d​vsubscript𝑞𝑎𝑑𝑣q_{adv}. When attacking both visual and textual sides in test-time, our model beats the vanilla model by 21.55%.\nThese results indicate that our model is capable of defending against both visual and textual common attackers."
        ]
    }
}