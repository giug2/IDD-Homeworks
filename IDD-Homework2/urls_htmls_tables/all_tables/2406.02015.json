{
    "PAPER'S NUMBER OF TABLES": 1,
    "S5.T1": {
        "caption": "Table 1: System and hyperparameters used in ‘small’ and ‘scale’ experiments. All experiments were run on ‘e2-standard-8’ nodes.",
        "table": "<table id=\"S5.T1.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.4.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S5.T1.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\">System</th>\n<th id=\"S5.T1.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">Federator (F)</th>\n<th id=\"S5.T1.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">Clients (C)</th>\n</tr>\n<tr id=\"S5.T1.4.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.2.2.1\" class=\"ltx_td\"></td>\n<th id=\"S5.T1.4.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Nodes</th>\n<th id=\"S5.T1.4.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">#C</th>\n<th id=\"S5.T1.4.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">\n<table id=\"S5.T1.4.2.2.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.4.2.2.4.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.2.2.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">CPU</td>\n</tr>\n<tr id=\"S5.T1.4.2.2.4.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.2.2.4.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(F/C)</td>\n</tr>\n</table>\n</th>\n<th id=\"S5.T1.4.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">\n<table id=\"S5.T1.4.2.2.5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.4.2.2.5.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.2.2.5.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Memory</td>\n</tr>\n<tr id=\"S5.T1.4.2.2.5.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.2.2.5.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(F/C)</td>\n</tr>\n</table>\n</th>\n<th id=\"S5.T1.4.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Strategy</th>\n<th id=\"S5.T1.4.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">\n<table id=\"S5.T1.4.2.2.7.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.4.2.2.7.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.2.2.7.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">#Rounds</td>\n</tr>\n<tr id=\"S5.T1.4.2.2.7.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.2.2.7.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(R)</td>\n</tr>\n</table>\n</th>\n<th id=\"S5.T1.4.2.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">#C/R</th>\n<th id=\"S5.T1.4.2.2.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Model</th>\n<th id=\"S5.T1.4.2.2.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Data</th>\n<th id=\"S5.T1.4.2.2.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\">BS</th>\n</tr>\n<tr id=\"S5.T1.4.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Small</td>\n<td id=\"S5.T1.4.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">2,2,3</td>\n<td id=\"S5.T1.4.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">5,10,20</td>\n<td id=\"S5.T1.4.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.4.3.3.4.1\" class=\"ltx_text\">2/1</span></td>\n<td id=\"S5.T1.4.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">2/2G</td>\n<td id=\"S5.T1.4.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.4.3.3.6.1\" class=\"ltx_text\">FedAvg</span></td>\n<td id=\"S5.T1.4.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\">100</td>\n<td id=\"S5.T1.4.3.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">5</td>\n<td id=\"S5.T1.4.3.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\">LeNet</td>\n<td id=\"S5.T1.4.3.3.10\" class=\"ltx_td ltx_align_center ltx_border_t\">CIFAR10</td>\n<td id=\"S5.T1.4.3.3.11\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.4.3.3.11.1\" class=\"ltx_text\">64</span></td>\n</tr>\n<tr id=\"S5.T1.4.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Scale</td>\n<td id=\"S5.T1.4.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">4,12</td>\n<td id=\"S5.T1.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">25,75</td>\n<td id=\"S5.T1.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">2/2,6G</td>\n<td id=\"S5.T1.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">85</td>\n<td id=\"S5.T1.4.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">all</td>\n<td id=\"S5.T1.4.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">ResNet</td>\n<td id=\"S5.T1.4.4.4.8\" class=\"ltx_td ltx_align_center ltx_border_bb\">CIFAR100</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We demonstrate some features of ",
                "Freddie",
                " through experiments. For this purpose, we use the overlapping CIFAR100 dataset. The labels that already exist in CIFAR100 are used to partition the data into different tasks for FCL, following the same steps as in ",
                "[",
                "18",
                "]",
                ".\nFL can be viewed as a corner case of FCL where there is a single task consisting of the whole dataset. We first consider a FL scenario with the default version of CIFAR100, and then consider the overlapping CIFAR100 split into 10 separate tasks in a FCL scenario. We use the average accuracy metric following the CL literature ",
                "[",
                "2",
                ", ",
                "13",
                "]",
                ".\n",
                "Scalability.",
                " To investigate ",
                "Freddie",
                "’s emulation capability, we perform a ",
                "small",
                " and ",
                "large",
                " scale experiment on a Google Kubernetes Engine (GKE) cluster to cover possible use cases.\nDuring deployment, the pods of the federation and clients were run on a separate node pool scaled to meet each experiment’s requirements.\nWe study the performance of an FL experiment emulated on a CPU-enabled Kubernetes cluster, where multiple clients may run on a single Kubernetes node.\nParameters of the experiments are provided in Tab. ",
                "1",
                ".",
                "The ",
                "small",
                " experiment in Fig. ",
                "3(a)",
                " depicts the spread round times of clients (scaled) and the federator, with 5 selected clients per round.\nThe client round duration is scaled by the number of clients (World Size WS) (",
                "|",
                "𝒟",
                "C",
                "​",
                "i",
                "​",
                "f",
                "​",
                "a",
                "​",
                "r",
                "|",
                "/",
                "WS",
                "subscript",
                "𝒟",
                "𝐶",
                "𝑖",
                "𝑓",
                "𝑎",
                "𝑟",
                "WS",
                "|\\mathcal{D}_{Cifar}|/\\text{WS}",
                ") to account for differences in clients’ datasets as the WS increases.\nThe outliers in the plots originate from the first epoch run on clients, which are inherently slower due to loading data into memory.\nNevertheless, it is expected that the scaled client duration stays relatively constant, while the result shows an increase as the number of clients increases (from 115 to 123 s, and from 136 to 138 s).\nSimilarly, the federator sees a positive correlation between round duration and WS.\nThe number of co-scheduled clients on the same node can explain this trend, as the networking overhead stays the same.",
                "For the ",
                "scale",
                " experiments, we provide the round time density estimate in Fig. ",
                "3(b)",
                ". The client round times exhibit the same range of processing times that were observed in the ‘small’ setting.\nIn both settings, participating clients in each round may run on the same node, varying from 3 to 7 clients per node.\nWe use similar settings in the ‘small’ configuration that involves 20 clients, where 4 nodes are used.\nAs such, confirming that resource contingencies due to co-scheduling will likely cause the increased client round time with 20 clients.\nThe different modes within the client’s round duration can be explained by imperfect data splits and the imbalanced assignment of the number of clients to be co-scheduled with the federator.\nThe federator’s density estimate shows a similar pattern with two distinct modes.\nWith the cluster configurations employed, i.e., 4 and 12 nodes, it is possible for the federator to be co-scheduled on a machine with different numbers of clients.\nAs a result, the federator experiences a variable level of resource contingency.\nHowever, an increase in the two modes is visible as the number of clients increases, which is expected due to the increased communication volumes. \n",
                "Task-IL vs Domain-IL.",
                "\nAssuming that the model knows the ID of the task it is currently training on, or evaluating, increases its accuracy.\nFor FCL, Task-Interactive Learning and Domain-Interactive Learning are implemented using the sliding and expanding-window, respectively. Let us recall that sliding-windows use task IDs, contrary to expanding-windows.\nFor the overlapping CIFAR100 dataset, if one assumes that the task ID is known, then the number of output classes is restricted to only the five sub-classes within that task.\nThus leading to higher average task probabilities for Task-IL scenarios.\nThis difference is prevalent in Fig. ",
                "4(a)",
                ".\nUnder the expanding window scheme, classification outputs one of ",
                "5",
                "​",
                "T",
                "5",
                "𝑇",
                "5T",
                " classes, where ",
                "T",
                "𝑇",
                "T",
                " is the number of tasks learned until evaluation time.\nTherefore, the probability of classifying correctly is even lower than in the sliding window scenario.\nFig. ",
                "4(a)",
                " shows the positive impact of using a task ID on accuracy.\nUsing sliding-window results in higher accuracy than expanding-window, which sometimes has to be used because of the application use case.\nBecause of this difference, ",
                "Freddie",
                " supports both Task-IL and Domain-IL.",
                "FCL Task Heterogeneity.",
                "\nAs discussed in Section ",
                "3",
                ", tasks can be processed in different orders at each client.\nTo demonstrate the different effects that different sequences of tasks produce, we implement the Overlapped-CIFAR100 dataset with 20 tasks that can be used for FCL ",
                "[",
                "18",
                "]",
                ".\nThe accuracy in Fig. ",
                "4(b)",
                " is calculated as the average accuracy of all tasks seen until that point, resulting in expected ‘drops’ in accuracy as new tasks are introduced.\nIndeed, the learning curves in Fig. ",
                "4(b)",
                " show noticeable drops over time.\nHowever, different trends are visible between workloads. The column scheme suffers more from more pronounced ",
                "catastrophic forgetting",
                " than the shuffled and balanced scheme, resulting in lower accuracy.\nWe observe that the column scheme, on average, results in a 4% test accuracy drop compared to the column and shuffled schemes."
            ]
        ]
    }
}