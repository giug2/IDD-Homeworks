{
    "Ch3.T1.2.2": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"Ch3.T1.2.2\">\n<tr class=\"ltx_tr\" id=\"Ch3.T1.2.2.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T1.2.2.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T1.2.2.3.1.1\">Source</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T1.2.2.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T1.2.2.3.2.1\">System</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T1.2.2.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T1.2.2.3.3.1\">Range to Object</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T1.2.2.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T1.2.2.3.4.1\">Error (m)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T1.2.2.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T1.2.2.4.1\"><cite class=\"ltx_cite ltx_citemacro_cite\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#bib.bib97\" title=\"\">naus2021assessment </a></cite></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T1.2.2.4.2\">Radar Antenna + GPS*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T1.2.2.4.3\">1000 m</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T1.2.2.4.4\">6.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T1.1.1.1\">\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.1.1.1.2\"><cite class=\"ltx_cite ltx_citemacro_cite\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#bib.bib98\" title=\"\">livingstone2014ship </a></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.1.1.1.3\">Synthetic Aperture Radar</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.1.1.1.4\">800 km</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.1.1.1.1\">13&#160;<math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"Ch3.T1.1.1.1.1.m1.1\"><semantics id=\"Ch3.T1.1.1.1.1.m1.1a\"><mo id=\"Ch3.T1.1.1.1.1.m1.1.1\" xref=\"Ch3.T1.1.1.1.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch3.T1.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Ch3.T1.1.1.1.1.m1.1.1.cmml\" xref=\"Ch3.T1.1.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch3.T1.1.1.1.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch3.T1.1.1.1.1.m1.1d\">&#177;</annotation></semantics></math>&#160;23</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T1.2.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.2.2.2.2\"><cite class=\"ltx_cite ltx_citemacro_cite\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#bib.bib99\" title=\"\">wei2020geolocation </a></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.2.2.2.3\">Opt. Remote Sensing</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.2.2.2.4\">36000 km</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.2.2.2.1\">165&#160;<math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"Ch3.T1.2.2.2.1.m1.1\"><semantics id=\"Ch3.T1.2.2.2.1.m1.1a\"><mo id=\"Ch3.T1.2.2.2.1.m1.1.1\" xref=\"Ch3.T1.2.2.2.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch3.T1.2.2.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Ch3.T1.2.2.2.1.m1.1.1.cmml\" xref=\"Ch3.T1.2.2.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch3.T1.2.2.2.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch3.T1.2.2.2.1.m1.1d\">&#177;</annotation></semantics></math>&#160;109</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T1.2.2.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.2.2.5.1\"><cite class=\"ltx_cite ltx_citemacro_cite\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#bib.bib24\" title=\"\">helgesen2020low </a></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.2.2.5.2\">Opt. Camera + GPS + IMU**</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.2.2.5.3\">400 m</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T1.2.2.5.4\">20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T1.2.2.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"4\" id=\"Ch3.T1.2.2.6.1\"><span class=\"ltx_text\" id=\"Ch3.T1.2.2.6.1.1\" style=\"font-size:80%;\">*Global Positioning System, **Inertial Measurement Unit</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 3.1 :  Ship georeferencing accuracy in existing literature. Note: Some entries lack reported uncertainty values for the positioning error.",
        "footnotes": [
            "(97) \nK. Naus, M. W, P. Szymak, L. Gucma, and M. Gucma, “Assessment of ship position\nestimation accuracy based on radar navigation mark echoes identified in an\nelectronic navigational chart,”  Measurement , vol. 169, p. 108630,\n2020.\n\n",
            "(98) \nC. E. Livingstone, M. Dragosevic, S. Chu, and I. Sikaneta,  Ship detection\nand measurement of ship motion by multi-aperture Synthetic Aperture\nRadar .   Defence Research and\nDevelopment Canada, 2014.\n\n",
            "(99) \nY. Wei, Z. Zhang, B. Mu, Y. Li, Q. Wang, and R. Liu, “Geolocation accuracy\nevaluation of gf-4 geostationary high-resolution optical images over coastal\nzones and offshore areas,”  Journal of Coastal Research , vol. 102,\nno. SI, pp. 326–333, 2020.\n\n",
            "(24) \nØ. K. Helgesen, E. F. Brekke, A. Stahl, and Ø. Engelhardtsen, “Low\naltitude georeferencing for imaging sensors in maritime tracking,”\n IFAC-PapersOnLine , vol. 53, no. 2, pp. 14 476–14 481, 2020.\n\n"
        ],
        "references": [
            "To transition from terrestrial to maritime applications, as discussed in Chapter 1, ship georeferencing is a critical aspect. This process involves the assignment of geographic coordinates to ships detected in various data sources. Table 3.1 shows a summary of ship georeferencing accuracies in the literature using different technologies.\nRadar technologies have been a cornerstone in this field, providing real-time georeferencing at a speed of 1 Hz, as detailed in naus2021assessment . Despite their accuracy, radar systems often involve high costs and complex deployment requirements.\nParallel to radar, satellite technologies including optical remote sensing wei2020geolocation  and synthetic aperture radar (SAR) livingstone2014ship , extend georeferencing capabilities over larger coverage areas. However, the effectiveness of these methods is constrained by their data cycle times (∼similar-to\\sim∼minutes) and the satellite revisit schedules, limiting their temporal resolution.\nRecent advancements have explored the use of video sequences for ship georeferencing. The work in helgesen2020low  proposed a method which relies on the pinhole camera model calibration matrix zhang2000flexible  to georeference ships detected in video frames. This approach, while innovative, requires prior knowledge of camera calibration, and its application has been limited to controlled conditions with a single video sequence of two small ships.",
            "Given the absence of directly comparable methodologies that simultaneously address the use of monocular cameras without prior camera pose knowledge for fast ship georeferencing, this approach establishes a benchmark in the literature. A comparison of the obtained results with existing ship georeferencing accuracies that use other technologies can be seen in Table 7.1, which is an updated version of Table 3.1 for ship georeferencing. The most comparable set-up and result is given by helgesen2020low , that utilizes prior knowledge of camera calibration, and its application was limited to controlled conditions with a single video sequence of a two small ships. Our method obtains similar positioning error, however providing a much more comprehensive study: results using two views, longer ranges, uncertainties, a large variety of ships of different categories and sizes, and does not need prior camera pose knowledge."
        ]
    },
    "Ch3.T2.4.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"Ch3.T2.4.1\">\n<tr class=\"ltx_tr\" id=\"Ch3.T2.4.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T2.4.1.1.1.1\">System Type</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T2.4.1.1.2.1\">Module</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T2.4.1.1.3.1\">CUDA Cores</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T2.4.1.1.4.1\">Memory</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T2.4.1.1.5\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"Ch3.T2.4.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"Ch3.T2.4.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Ch3.T2.4.1.1.5.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T2.4.1.1.5.1.1.1.1\">Max Power</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T2.4.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Ch3.T2.4.1.1.5.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T2.4.1.1.5.1.2.1.1\">Consumption</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T2.4.1.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.2.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"Ch3.T2.4.1.2.1.1\">Edge Computing Device</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.2.2\">Jetson Nano</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.2.3\">128</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.2.4\">4 GB</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T2.4.1.2.5\">10 W</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T2.4.1.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch3.T2.4.1.3.1\">Jetson TX2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch3.T2.4.1.3.2\">256</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch3.T2.4.1.3.3\">8 GB</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T2.4.1.3.4\">15 W</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T2.4.1.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch3.T2.4.1.4.1\">Jetson AGX Xavier</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch3.T2.4.1.4.2\">512</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch3.T2.4.1.4.3\">16GB</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T2.4.1.4.4\">30 W</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T2.4.1.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.5.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"Ch3.T2.4.1.5.1.1\">High-End Device</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.5.2\">GV100</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.5.3\">5120</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch3.T2.4.1.5.4\">32 GB</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch3.T2.4.1.5.5\">250 W</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T2.4.1.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch3.T2.4.1.6.1\">A100</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch3.T2.4.1.6.2\">6912</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch3.T2.4.1.6.3\">80 GB</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch3.T2.4.1.6.4\">400 W</td>\n</tr>\n</table>\n\n",
        "caption": "Table 3.2 :  Comparison of NVIDIA GPU modules, with focus on the Jetson family and high-end GPU-powered systems.",
        "footnotes": [],
        "references": [
            "Within the spectrum of embedded systems widely utilized for deep learning and computer vision, the NVIDIA Jetson family222https://developer.nvidia.com/embedded/jetson-modules stands out in the literature, offering both mobile and energy-efficient embedded GPU-systems chen2019deep . Table 3.2 shows a comparison of three modules of the Jetson family compared against high-end server-based GPU systems to contextualize their capabilities. We observe that the Jetson modules provide optimized balance between performance and energy efficiency, marking them as an optimal solution for vision-based systems where the on-site deployment is a requirement. Larger servers, are typically used for the training of the models that are later deployed on the Jetson."
        ]
    },
    "Ch3.T2.4.1.1.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"Ch3.T2.4.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"Ch3.T2.4.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Ch3.T2.4.1.1.5.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T2.4.1.1.5.1.1.1.1\">Max Power</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch3.T2.4.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Ch3.T2.4.1.1.5.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch3.T2.4.1.1.5.1.2.1.1\">Consumption</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 3.2 :  Comparison of NVIDIA GPU modules, with focus on the Jetson family and high-end GPU-powered systems.",
        "footnotes": [],
        "references": [
            "Within the spectrum of embedded systems widely utilized for deep learning and computer vision, the NVIDIA Jetson family222https://developer.nvidia.com/embedded/jetson-modules stands out in the literature, offering both mobile and energy-efficient embedded GPU-systems chen2019deep . Table 3.2 shows a comparison of three modules of the Jetson family compared against high-end server-based GPU systems to contextualize their capabilities. We observe that the Jetson modules provide optimized balance between performance and energy efficiency, marking them as an optimal solution for vision-based systems where the on-site deployment is a requirement. Larger servers, are typically used for the training of the models that are later deployed on the Jetson."
        ]
    },
    "Ch5.T1.6": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"Ch5.T1.6\">\n<tr class=\"ltx_tr\" id=\"Ch5.T1.6.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"Ch5.T1.6.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch5.T1.6.7.1.1\" style=\"font-size:80%;\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"Ch5.T1.6.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch5.T1.6.7.2.1\" style=\"font-size:80%;\">Input Size (Pixel)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"Ch5.T1.6.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch5.T1.6.7.3.1\" style=\"font-size:80%;\">Backbone</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"Ch5.T1.6.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch5.T1.6.7.4.1\" style=\"font-size:80%;\">Number of Epochs</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch5.T1.1.1.2\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.1.1.2.1\" style=\"font-size:80%;\">Mask R-CNN</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T1.1.1.1\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T1.1.1.1.1\" style=\"font-size:80%;\">1333&#160;</span><math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"Ch5.T1.1.1.1.m1.1\"><semantics id=\"Ch5.T1.1.1.1.m1.1a\"><mo id=\"Ch5.T1.1.1.1.m1.1.1\" mathsize=\"80%\" xref=\"Ch5.T1.1.1.1.m1.1.1.cmml\">&#215;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch5.T1.1.1.1.m1.1b\"><times id=\"Ch5.T1.1.1.1.m1.1.1.cmml\" xref=\"Ch5.T1.1.1.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch5.T1.1.1.1.m1.1c\">\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch5.T1.1.1.1.m1.1d\">&#215;</annotation></semantics></math><span class=\"ltx_text\" id=\"Ch5.T1.1.1.1.2\" style=\"font-size:80%;\">&#160;800</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T1.1.1.3\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.1.1.3.1\" style=\"font-size:80%;\">ResNeXt-101</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T1.1.1.4\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.1.1.4.1\" style=\"font-size:80%;\">11</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T1.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch5.T1.2.2.2\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.2.2.2.1\" style=\"font-size:80%;\">DetectoRS</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.2.2.1\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T1.2.2.1.1\" style=\"font-size:80%;\">1333&#160;</span><math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"Ch5.T1.2.2.1.m1.1\"><semantics id=\"Ch5.T1.2.2.1.m1.1a\"><mo id=\"Ch5.T1.2.2.1.m1.1.1\" mathsize=\"80%\" xref=\"Ch5.T1.2.2.1.m1.1.1.cmml\">&#215;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch5.T1.2.2.1.m1.1b\"><times id=\"Ch5.T1.2.2.1.m1.1.1.cmml\" xref=\"Ch5.T1.2.2.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch5.T1.2.2.1.m1.1c\">\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch5.T1.2.2.1.m1.1d\">&#215;</annotation></semantics></math><span class=\"ltx_text\" id=\"Ch5.T1.2.2.1.2\" style=\"font-size:80%;\">&#160;800</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.2.2.3\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.2.2.3.1\" style=\"font-size:80%;\">ResNet-50</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.2.2.4\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.2.2.4.1\" style=\"font-size:80%;\">11</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T1.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch5.T1.3.3.2\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T1.3.3.2.1\" style=\"font-size:80%;\">YOLACT</span><sub class=\"ltx_sub\" id=\"Ch5.T1.3.3.2.2\"><span class=\"ltx_text\" id=\"Ch5.T1.3.3.2.2.1\" style=\"font-size:80%;\">550</span></sub>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.3.3.1\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T1.3.3.1.1\" style=\"font-size:80%;\">550&#160;</span><math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"Ch5.T1.3.3.1.m1.1\"><semantics id=\"Ch5.T1.3.3.1.m1.1a\"><mo id=\"Ch5.T1.3.3.1.m1.1.1\" mathsize=\"80%\" xref=\"Ch5.T1.3.3.1.m1.1.1.cmml\">&#215;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch5.T1.3.3.1.m1.1b\"><times id=\"Ch5.T1.3.3.1.m1.1.1.cmml\" xref=\"Ch5.T1.3.3.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch5.T1.3.3.1.m1.1c\">\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch5.T1.3.3.1.m1.1d\">&#215;</annotation></semantics></math><span class=\"ltx_text\" id=\"Ch5.T1.3.3.1.2\" style=\"font-size:80%;\">&#160;550</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.3.3.3\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.3.3.3.1\" style=\"font-size:80%;\">ResNet-50</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.3.3.4\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.3.3.4.1\" style=\"font-size:80%;\">18</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T1.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch5.T1.4.4.2\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T1.4.4.2.1\" style=\"font-size:80%;\">YOLACT</span><sub class=\"ltx_sub\" id=\"Ch5.T1.4.4.2.2\"><span class=\"ltx_text\" id=\"Ch5.T1.4.4.2.2.1\" style=\"font-size:80%;\">700</span></sub>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.4.4.1\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T1.4.4.1.1\" style=\"font-size:80%;\">700&#160;</span><math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"Ch5.T1.4.4.1.m1.1\"><semantics id=\"Ch5.T1.4.4.1.m1.1a\"><mo id=\"Ch5.T1.4.4.1.m1.1.1\" mathsize=\"80%\" xref=\"Ch5.T1.4.4.1.m1.1.1.cmml\">&#215;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch5.T1.4.4.1.m1.1b\"><times id=\"Ch5.T1.4.4.1.m1.1.1.cmml\" xref=\"Ch5.T1.4.4.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch5.T1.4.4.1.m1.1c\">\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch5.T1.4.4.1.m1.1d\">&#215;</annotation></semantics></math><span class=\"ltx_text\" id=\"Ch5.T1.4.4.1.2\" style=\"font-size:80%;\">&#160;700</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.4.4.3\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.4.4.3.1\" style=\"font-size:80%;\">ResNet-101</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.4.4.4\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.4.4.4.1\" style=\"font-size:80%;\">16</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T1.5.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch5.T1.5.5.2\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T1.5.5.2.1\" style=\"font-size:80%;\">Centermask-Lite</span><sub class=\"ltx_sub\" id=\"Ch5.T1.5.5.2.2\"><span class=\"ltx_text\" id=\"Ch5.T1.5.5.2.2.1\" style=\"font-size:80%;\">V19</span></sub>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.5.5.1\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T1.5.5.1.1\" style=\"font-size:80%;\">800&#160;</span><math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"Ch5.T1.5.5.1.m1.1\"><semantics id=\"Ch5.T1.5.5.1.m1.1a\"><mo id=\"Ch5.T1.5.5.1.m1.1.1\" mathsize=\"80%\" xref=\"Ch5.T1.5.5.1.m1.1.1.cmml\">&#215;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch5.T1.5.5.1.m1.1b\"><times id=\"Ch5.T1.5.5.1.m1.1.1.cmml\" xref=\"Ch5.T1.5.5.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch5.T1.5.5.1.m1.1c\">\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch5.T1.5.5.1.m1.1d\">&#215;</annotation></semantics></math><span class=\"ltx_text\" id=\"Ch5.T1.5.5.1.2\" style=\"font-size:80%;\">&#160;600</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.5.5.3\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.5.5.3.1\" style=\"font-size:80%;\">Vovnet-19</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T1.5.5.4\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T1.5.5.4.1\" style=\"font-size:80%;\">17</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T1.6.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"Ch5.T1.6.6.2\">\n<span class=\"ltx_text\" id=\"Ch5.T1.6.6.2.1\" style=\"font-size:80%;\">Centermask-Lite</span><sub class=\"ltx_sub\" id=\"Ch5.T1.6.6.2.2\"><span class=\"ltx_text\" id=\"Ch5.T1.6.6.2.2.1\" style=\"font-size:80%;\">V39</span></sub>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Ch5.T1.6.6.1\">\n<span class=\"ltx_text\" id=\"Ch5.T1.6.6.1.1\" style=\"font-size:80%;\">800&#160;</span><math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"Ch5.T1.6.6.1.m1.1\"><semantics id=\"Ch5.T1.6.6.1.m1.1a\"><mo id=\"Ch5.T1.6.6.1.m1.1.1\" mathsize=\"80%\" xref=\"Ch5.T1.6.6.1.m1.1.1.cmml\">&#215;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch5.T1.6.6.1.m1.1b\"><times id=\"Ch5.T1.6.6.1.m1.1.1.cmml\" xref=\"Ch5.T1.6.6.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch5.T1.6.6.1.m1.1c\">\\times</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch5.T1.6.6.1.m1.1d\">&#215;</annotation></semantics></math><span class=\"ltx_text\" id=\"Ch5.T1.6.6.1.2\" style=\"font-size:80%;\">&#160;600</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Ch5.T1.6.6.3\"><span class=\"ltx_text\" id=\"Ch5.T1.6.6.3.1\" style=\"font-size:80%;\">Vovnet-39</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Ch5.T1.6.6.4\"><span class=\"ltx_text\" id=\"Ch5.T1.6.6.4.1\" style=\"font-size:80%;\">17</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 5.1 :  Configurations during training for each instance segmentation method evaluated in  [BCP-II] . (CC BY 4.0)",
        "footnotes": [],
        "references": [
            "The creation of the ShipSG dataset (see Chapter 4), provided a comprehensive basis to perform an evaluation of robust instance segmentation methods like Mask R-CNN he2017mask  and DetectoRS qiao2021detectors , as well as real-time methods including YOLACT bolya2019yolact  and Centermask-Lite lee2020centermask .\nThe latter evaluations seeking real-time performance involved configurations that sought to balance inference speed with mAP.\nTherefore, two configurations for each were selected, one deeper and another one lighter, as can be seen in Tables 5.1 and 5.2.\nAll methods initiated training on ShipSG with COCO pre-trained weights.\nIt is notable that in [BCP-II], inference speed was measured using the NVIDIA GV100, a high-end GPU, boasts Tensor Cores for AI acceleration, 32 GB of memory, and over 5000 Compute Unified Device Architecture (CUDA) cores for unparalleled computational performance.\nEmbedded system based deployment will be discussed in Chapter 6."
        ]
    },
    "Ch5.T2.4": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"Ch5.T2.4\">\n<tr class=\"ltx_tr\" id=\"Ch5.T2.4.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" id=\"Ch5.T2.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch5.T2.4.1.1.1\" style=\"font-size:80%;\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"Ch5.T2.4.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch5.T2.4.1.2.1\" style=\"font-size:80%;\">mAP (%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"Ch5.T2.4.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch5.T2.4.1.3.1\" style=\"font-size:80%;\">mAP<sub class=\"ltx_sub\" id=\"Ch5.T2.4.1.3.1.1\">s</sub> (%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"Ch5.T2.4.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch5.T2.4.1.4.1\" style=\"font-size:80%;\">mAP<sub class=\"ltx_sub\" id=\"Ch5.T2.4.1.4.1.1\">m</sub> (%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"Ch5.T2.4.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch5.T2.4.1.5.1\" style=\"font-size:80%;\">mAP<sub class=\"ltx_sub\" id=\"Ch5.T2.4.1.5.1.1\">l</sub> (%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"Ch5.T2.4.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch5.T2.4.1.6.1\" style=\"font-size:80%;\">Inference (ms)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T2.4.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch5.T2.4.2.1\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.2.1.1\" style=\"font-size:80%;\">Mask R-CNN</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T2.4.2.2\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.2.2.1\" style=\"font-size:80%;\">73.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T2.4.2.3\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.2.3.1\" style=\"font-size:80%;\">50.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T2.4.2.4\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.2.4.1\" style=\"font-size:80%;\">75.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T2.4.2.5\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.2.5.1\" style=\"font-size:80%;\">77.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T2.4.2.6\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.2.6.1\" style=\"font-size:80%;\">117</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T2.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch5.T2.4.3.1\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.3.1.1\" style=\"font-size:80%;\">DetectoRS</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.3.2\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.3.2.1\" style=\"font-size:80%;\">74.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.3.3\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.3.3.1\" style=\"font-size:80%;\">55.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.3.4\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.3.4.1\" style=\"font-size:80%;\">75.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.3.5\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.3.5.1\" style=\"font-size:80%;\">79.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.3.6\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.3.6.1\" style=\"font-size:80%;\">151</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T2.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"Ch5.T2.4.4.1\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T2.4.4.1.1\" style=\"font-size:80%;\">YOLACT</span><sub class=\"ltx_sub\" id=\"Ch5.T2.4.4.1.2\"><span class=\"ltx_text\" id=\"Ch5.T2.4.4.1.2.1\" style=\"font-size:80%;\">550</span></sub>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T2.4.4.2\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.4.2.1\" style=\"font-size:80%;\">52.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T2.4.4.3\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.4.3.1\" style=\"font-size:80%;\">8.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T2.4.4.4\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.4.4.1\" style=\"font-size:80%;\">51.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T2.4.4.5\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.4.5.1\" style=\"font-size:80%;\">70.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch5.T2.4.4.6\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.4.6.1\" style=\"font-size:80%;\">28</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T2.4.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch5.T2.4.5.1\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T2.4.5.1.1\" style=\"font-size:80%;\">YOLACT</span><sub class=\"ltx_sub\" id=\"Ch5.T2.4.5.1.2\"><span class=\"ltx_text\" id=\"Ch5.T2.4.5.1.2.1\" style=\"font-size:80%;\">700</span></sub>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.5.2\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.5.2.1\" style=\"font-size:80%;\">58.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.5.3\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.5.3.1\" style=\"font-size:80%;\">14.0</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.5.4\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.5.4.1\" style=\"font-size:80%;\">58.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.5.5\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.5.5.1\" style=\"font-size:80%;\">75.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.5.6\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.5.6.1\" style=\"font-size:80%;\">36</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T2.4.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch5.T2.4.6.1\" style=\"padding-bottom:2.84544pt;\">\n<span class=\"ltx_text\" id=\"Ch5.T2.4.6.1.1\" style=\"font-size:80%;\">Centermask-Lite</span><sub class=\"ltx_sub\" id=\"Ch5.T2.4.6.1.2\"><span class=\"ltx_text\" id=\"Ch5.T2.4.6.1.2.1\" style=\"font-size:80%;\">V19</span></sub>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.6.2\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.6.2.1\" style=\"font-size:80%;\">63.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.6.3\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.6.3.1\" style=\"font-size:80%;\">45.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.6.4\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.6.4.1\" style=\"font-size:80%;\">64.0</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.6.5\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.6.5.1\" style=\"font-size:80%;\">65.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch5.T2.4.6.6\" style=\"padding-bottom:2.84544pt;\"><span class=\"ltx_text\" id=\"Ch5.T2.4.6.6.1\" style=\"font-size:80%;\">24</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch5.T2.4.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"Ch5.T2.4.7.1\">\n<span class=\"ltx_text\" id=\"Ch5.T2.4.7.1.1\" style=\"font-size:80%;\">Centermask-Lite</span><sub class=\"ltx_sub\" id=\"Ch5.T2.4.7.1.2\"><span class=\"ltx_text\" id=\"Ch5.T2.4.7.1.2.1\" style=\"font-size:80%;\">V39</span></sub>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Ch5.T2.4.7.2\"><span class=\"ltx_text\" id=\"Ch5.T2.4.7.2.1\" style=\"font-size:80%;\">64.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Ch5.T2.4.7.3\"><span class=\"ltx_text\" id=\"Ch5.T2.4.7.3.1\" style=\"font-size:80%;\">46.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Ch5.T2.4.7.4\"><span class=\"ltx_text\" id=\"Ch5.T2.4.7.4.1\" style=\"font-size:80%;\">64.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Ch5.T2.4.7.5\"><span class=\"ltx_text\" id=\"Ch5.T2.4.7.5.1\" style=\"font-size:80%;\">66.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"Ch5.T2.4.7.6\"><span class=\"ltx_text\" id=\"Ch5.T2.4.7.6.1\" style=\"font-size:80%;\">28</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 5.2 :  Resulting instance segmentation APs and inference speed per method evaluated. Inference times are measured on a high-end NVIDIA GV100  GPU . Adapted from [BCP-II] (CC BY 4.0).",
        "footnotes": [],
        "references": [
            "The creation of the ShipSG dataset (see Chapter 4), provided a comprehensive basis to perform an evaluation of robust instance segmentation methods like Mask R-CNN he2017mask  and DetectoRS qiao2021detectors , as well as real-time methods including YOLACT bolya2019yolact  and Centermask-Lite lee2020centermask .\nThe latter evaluations seeking real-time performance involved configurations that sought to balance inference speed with mAP.\nTherefore, two configurations for each were selected, one deeper and another one lighter, as can be seen in Tables 5.1 and 5.2.\nAll methods initiated training on ShipSG with COCO pre-trained weights.\nIt is notable that in [BCP-II], inference speed was measured using the NVIDIA GV100, a high-end GPU, boasts Tensor Cores for AI acceleration, 32 GB of memory, and over 5000 Compute Unified Device Architecture (CUDA) cores for unparalleled computational performance.\nEmbedded system based deployment will be discussed in Chapter 6.",
            "As shown in Table 5.2, the robust methods, Mask R-CNN and DetectoRS, demonstrated superior mask mAP across all categories when compared to their real-time counterparts. DetectoRS, in particular, achieved the highest overall mAP, underscoring its effectiveness in accurate ship segmentation, however at the highest computational cost, even when using a high-end server.",
            "In Chapter 5, we observed a mAP decrease in segmenting small and distant ships, especially for the initially considered as real-time methods (see Table 5.2).\nAs motivated in Chapter 1, the recognition of small and distant ships in maritime footage holds significant implications for navigation, safety, and security.\nTypically, object detectors and instance segmentation methods reduce image size for quicker inference, losing critical details in the image.\nOn the other hand, high-resolution deep learning approaches strain memory and computational resources, particularly on embedded systems with limited capacity.\nInnovating segmentation architectures for such systems is crucial to overcome these challenges.\nIn [BCP-VI], the proposed batch-processed Slicing Aided Hyper Inference (SAHI), combined with the optimized version of ScatYOLOv8+CBAM, advance the state-of-the-art in small ship segmentation using embedded platforms.",
            "Table 6.3 presents the results of the analysis on small ship segmentation across different model sizes.\nThe optimized ScatYOLOv8+CBAM outperforms the standard YOLOv8 for small objects across all sizes.\nSAHI significantly boosts performance for both standard YOLOv8 and the optimized ScatYOLOv8+CBAM, showing gains between 8%percent88\\%8 % and 11%percent1111\\%11 % over configurations without SAHI. Specifically, the optimized ScatYOLOv8+CBAM with SAHI achieves the highest mAP improvements for small objects, ranging from 1.4%percent1.41.4\\%1.4 % to 3.2%percent3.23.2\\%3.2 % over standard YOLOv8 equipped with SAHI. Moreover, the advantage of integrating our optimized model with SAHI becomes more pronounced with model depth, highlighting a scalable improvement in small ship segmentation with increased network complexity.\nWhen comparing to the small ship segmentation performance provided in Chapter 5, Table 5.2, the optimized ScatYOLOv8+CBAM with SAHI in model size s𝑠sitalic_s onwards performs as good or better than the best one from the initial study, DetectoRS. It is important to recall that DetectoRS was not compatible with embedded system deployment, which underlines another superiority of the customized architecture."
        ]
    },
    "Ch6.T1.2": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"Ch6.T1.2\">\n<tr class=\"ltx_tr\" id=\"Ch6.T1.2.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Ch6.T1.2.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T1.2.3.1.1\">Segmentation model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T1.2.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T1.2.3.2.1\">mAP (%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T1.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Ch6.T1.2.4.1\">Mask R-CNN</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T1.2.4.2\">73.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T1.2.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T1.2.5.1\">DetectoRS</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T1.2.5.2\">74.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T1.1.1.1\">YOLACT<sub class=\"ltx_sub\" id=\"Ch6.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_italic\" id=\"Ch6.T1.1.1.1.1.1\">700</span></sub>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T1.1.1.2\">58.20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T1.2.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T1.2.2.1\">Centermask-Lite<sub class=\"ltx_sub\" id=\"Ch6.T1.2.2.1.1\"><span class=\"ltx_text ltx_font_italic\" id=\"Ch6.T1.2.2.1.1.1\">V39</span></sub>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T1.2.2.2\">64.40</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T1.2.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Ch6.T1.2.6.1\">YOLOv8n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T1.2.6.2\">70.15</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T1.2.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"Ch6.T1.2.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T1.2.7.1.1\">ScatYOLOv8n + CBAM</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"Ch6.T1.2.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T1.2.7.2.1\">75.46</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 6.1 :  Comparison of state-of-the-art segmentation performances on ShipSG with YOLOv8n and ScatYOLOv8n+CBAM. Adapted from  [BCP-V] . ©2023 IEEE.",
        "footnotes": [],
        "references": [
            "In [BCP-V], I focused on the lightest version of YOLOv8 for the implementation ScatYOLOv8+CBAM, version n𝑛nitalic_n, due to its potential for real-time operation.\nAs seen in Table 6.1, the baseline YOLOv8n shows improvement compared to the mAP of previous real-time approaches for ship segmentation on ShipSG studied in Chapter 5, YOLACT and Centermask-Lite. Yet, it does not show advantage against more robust methods like Mask R-CNN and DetectoRS.\nScatYOLOv8n+CBAM achieves 5.31% improvement with respect to standard YOLOv8n, 11.06% improvement compared to Centermask-Lite and 0.76% with respect to the most robust of the previous study, DetectoRS.\nWhile the mAP increase is modest when compared to DetectoRS, DetectoRS provided an inference time of 151 ms using a high-end GPU.\nAs discussed in Chapter 5, the deployment of instance segmentation on GPU-powered embedded systems was not reported for the methods presented in the initial study due to the incompatibility between deep learning and the Advanced Reduced instruction set computer Machine (ARM) architectures of GPU-powered embedded systems.\nThe advantage of YOLOv8-like architectures, such as ScatYOLOv8+CBAM, is the deployability on embedded systems. In [BCP-V], the NVIDIA Jetson AGX Xavier was selected as the target embedded system for deployment.\nThe ScatYOLOv8+CBAM model was deployed using native Pytorch weights.\nThis allow us to measure inference times of the new architecture on the system, which will show a great advantage against the previously studied instance segmentation methods."
        ]
    },
    "Ch6.T2.14": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"Ch6.T2.14\">\n<tr class=\"ltx_tr\" id=\"Ch6.T2.14.15\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"Ch6.T2.14.15.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T2.14.15.1.1\">Segmentation model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\" id=\"Ch6.T2.14.15.2\">\n<a href=\"https://arxiv.org/html/2410.04946v1#glo.acronym.map\"><span class=\"ltx_glossaryref ltx_font_bold\" href=\"https://arxiv.org/html/2410.04946v1#glo.acronym.map\" title=\"mean Average Precision\">mAP</span></a><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T2.14.15.2.1\"> (%)</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\" id=\"Ch6.T2.14.15.3\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T2.14.15.3.1\">Inference (ms)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T2.14.16\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"Ch6.T2.14.16.1\">YOLOv8n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Ch6.T2.14.16.2\">70.35</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"Ch6.T2.14.16.3\">-</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Ch6.T2.14.16.4\">28.7</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Ch6.T2.14.16.5\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T2.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Ch6.T2.2.2.3\">YOLOv8s</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.2.2.4\">71.99</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Ch6.T2.1.1.1\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.1.1.1.m1.1\"><semantics id=\"Ch6.T2.1.1.1.m1.1a\"><mo id=\"Ch6.T2.1.1.1.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.1.1.1.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.1.1.1.m1.1b\"><ci id=\"Ch6.T2.1.1.1.m1.1.1.cmml\" xref=\"Ch6.T2.1.1.1.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.1.1.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.1.1.1.m1.1d\">&#8593;</annotation></semantics></math>1.64)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.2.2.5\">32.2</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.2.2.2\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.2.2.2.m1.1\"><semantics id=\"Ch6.T2.2.2.2.m1.1a\"><mo id=\"Ch6.T2.2.2.2.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.2.2.2.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.2.2.2.m1.1b\"><ci id=\"Ch6.T2.2.2.2.m1.1.1.cmml\" xref=\"Ch6.T2.2.2.2.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.2.2.2.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.2.2.2.m1.1d\">&#8593;</annotation></semantics></math>3.5)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T2.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Ch6.T2.4.4.3\">YOLOv8m</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.4.4.4\">74.84</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Ch6.T2.3.3.1\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.3.3.1.m1.1\"><semantics id=\"Ch6.T2.3.3.1.m1.1a\"><mo id=\"Ch6.T2.3.3.1.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.3.3.1.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.3.3.1.m1.1b\"><ci id=\"Ch6.T2.3.3.1.m1.1.1.cmml\" xref=\"Ch6.T2.3.3.1.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.3.3.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.3.3.1.m1.1d\">&#8593;</annotation></semantics></math>4.49)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.4.4.5\">72.4</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.4.4.2\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.4.4.2.m1.1\"><semantics id=\"Ch6.T2.4.4.2.m1.1a\"><mo id=\"Ch6.T2.4.4.2.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.4.4.2.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.4.4.2.m1.1b\"><ci id=\"Ch6.T2.4.4.2.m1.1.1.cmml\" xref=\"Ch6.T2.4.4.2.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.4.4.2.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.4.4.2.m1.1d\">&#8593;</annotation></semantics></math>43.7)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T2.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Ch6.T2.6.6.3\">YOLOv8l</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.6.6.4\">75.89</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"Ch6.T2.5.5.1\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.5.5.1.m1.1\"><semantics id=\"Ch6.T2.5.5.1.m1.1a\"><mo id=\"Ch6.T2.5.5.1.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.5.5.1.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.5.5.1.m1.1b\"><ci id=\"Ch6.T2.5.5.1.m1.1.1.cmml\" xref=\"Ch6.T2.5.5.1.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.5.5.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.5.5.1.m1.1d\">&#8593;</annotation></semantics></math>5.54)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.6.6.5\">127.1</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.6.6.2\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.6.6.2.m1.1\"><semantics id=\"Ch6.T2.6.6.2.m1.1a\"><mo id=\"Ch6.T2.6.6.2.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.6.6.2.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.6.6.2.m1.1b\"><ci id=\"Ch6.T2.6.6.2.m1.1.1.cmml\" xref=\"Ch6.T2.6.6.2.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.6.6.2.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.6.6.2.m1.1d\">&#8593;</annotation></semantics></math>98.4)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T2.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Ch6.T2.8.8.3\">YOLOv8x</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.8.8.4\">76.45</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"Ch6.T2.7.7.1\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.7.7.1.m1.1\"><semantics id=\"Ch6.T2.7.7.1.m1.1a\"><mo id=\"Ch6.T2.7.7.1.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.7.7.1.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.7.7.1.m1.1b\"><ci id=\"Ch6.T2.7.7.1.m1.1.1.cmml\" xref=\"Ch6.T2.7.7.1.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.7.7.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.7.7.1.m1.1d\">&#8593;</annotation></semantics></math>6.10)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.8.8.5\">196.6</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.8.8.2\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.8.8.2.m1.1\"><semantics id=\"Ch6.T2.8.8.2.m1.1a\"><mo id=\"Ch6.T2.8.8.2.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.8.8.2.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.8.8.2.m1.1b\"><ci id=\"Ch6.T2.8.8.2.m1.1.1.cmml\" xref=\"Ch6.T2.8.8.2.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.8.8.2.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.8.8.2.m1.1d\">&#8593;</annotation></semantics></math>167.9)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T2.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"Ch6.T2.10.10.3\">ScatYOLOv8n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Ch6.T2.10.10.4\">74.42</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"Ch6.T2.9.9.1\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.9.9.1.m1.1\"><semantics id=\"Ch6.T2.9.9.1.m1.1a\"><mo id=\"Ch6.T2.9.9.1.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.9.9.1.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.9.9.1.m1.1b\"><ci id=\"Ch6.T2.9.9.1.m1.1.1.cmml\" xref=\"Ch6.T2.9.9.1.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.9.9.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.9.9.1.m1.1d\">&#8593;</annotation></semantics></math>4.07)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Ch6.T2.10.10.5\">58.2</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Ch6.T2.10.10.2\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.10.10.2.m1.1\"><semantics id=\"Ch6.T2.10.10.2.m1.1a\"><mo id=\"Ch6.T2.10.10.2.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.10.10.2.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.10.10.2.m1.1b\"><ci id=\"Ch6.T2.10.10.2.m1.1.1.cmml\" xref=\"Ch6.T2.10.10.2.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.10.10.2.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.10.10.2.m1.1d\">&#8593;</annotation></semantics></math>29.5)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T2.12.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Ch6.T2.12.12.3\">YOLOv8n + CBAM</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.12.12.4\">70.75</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"Ch6.T2.11.11.1\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.11.11.1.m1.1\"><semantics id=\"Ch6.T2.11.11.1.m1.1a\"><mo id=\"Ch6.T2.11.11.1.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.11.11.1.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.11.11.1.m1.1b\"><ci id=\"Ch6.T2.11.11.1.m1.1.1.cmml\" xref=\"Ch6.T2.11.11.1.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.11.11.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.11.11.1.m1.1d\">&#8593;</annotation></semantics></math>0.40)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.12.12.5\">29.9</td>\n<td class=\"ltx_td ltx_align_left\" id=\"Ch6.T2.12.12.2\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.12.12.2.m1.1\"><semantics id=\"Ch6.T2.12.12.2.m1.1a\"><mo id=\"Ch6.T2.12.12.2.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.12.12.2.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.12.12.2.m1.1b\"><ci id=\"Ch6.T2.12.12.2.m1.1.1.cmml\" xref=\"Ch6.T2.12.12.2.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.12.12.2.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.12.12.2.m1.1d\">&#8593;</annotation></semantics></math>1.2)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T2.14.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"Ch6.T2.14.14.3\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T2.14.14.3.1\">ScatYOLOv8n + CBAM</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"Ch6.T2.14.14.4\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T2.14.14.4.1\">75.46</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r\" id=\"Ch6.T2.13.13.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T2.13.13.1.1\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.13.13.1.1.m1.1\"><semantics id=\"Ch6.T2.13.13.1.1.m1.1a\"><mo id=\"Ch6.T2.13.13.1.1.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.13.13.1.1.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.13.13.1.1.m1.1b\"><ci id=\"Ch6.T2.13.13.1.1.m1.1.1.cmml\" xref=\"Ch6.T2.13.13.1.1.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.13.13.1.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.13.13.1.1.m1.1d\">&#8593;</annotation></semantics></math>5.11)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"Ch6.T2.14.14.5\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T2.14.14.5.1\">59.3</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"Ch6.T2.14.14.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T2.14.14.2.1\">(<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Ch6.T2.14.14.2.1.m1.1\"><semantics id=\"Ch6.T2.14.14.2.1.m1.1a\"><mo id=\"Ch6.T2.14.14.2.1.m1.1.1\" stretchy=\"false\" xref=\"Ch6.T2.14.14.2.1.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch6.T2.14.14.2.1.m1.1b\"><ci id=\"Ch6.T2.14.14.2.1.m1.1.1.cmml\" xref=\"Ch6.T2.14.14.2.1.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch6.T2.14.14.2.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch6.T2.14.14.2.1.m1.1d\">&#8593;</annotation></semantics></math>30.6)</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 6.2 :  Ablation study of YOLOv8 segmentation models and ScatYOLOv8+CBAM additions after training on ShipSG and inference times on the NVIDIA Jetson AGX Xavier. Reprinted from  [BCP-V] . ©2023 IEEE.",
        "footnotes": [],
        "references": [
            "In assessing the inference times on the embedded system for the proposed enhancements within ScatYOLOv8+CBAM, specifically the ScatBlock and CBAM, their individual impacts were also examined in the ablation study presented in Table 6.2. The first part of the table outlines the performance metrics of each YOLOv8 model variant. The second part provides the individual and combined contributions of the enhancements introduced in this work. The increments are noted in comparison to the baseline performance of the YOLOv8n model.\nIt can be seen in Table 6.2 that the addition of CBAM produces an increased mAP at a very minimal computational cost.\nThe proposed architecture ScatYOLOv8+CBAM, in the lightest version n𝑛nitalic_n, provides a mAP comparable to the deeper and heavier YOLOv8l (75.46% vs 75.89%).\nHowever, the proposed model demonstrates a substantially faster inference speed (59.3 ms versus 127.1 ms) on the NVIDIA Jetson AGX Xavier. This marks a significant improvement over the preliminary findings discussed in Chapter 5, Section 5.2."
        ]
    },
    "Ch6.T3.4": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"Ch6.T3.4\">\n<tr class=\"ltx_tr\" id=\"Ch6.T3.4.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Ch6.T3.4.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.1.1.1\">Model</span></td>\n<td class=\"ltx_td ltx_align_center\" colspan=\"5\" id=\"Ch6.T3.4.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.1.2.1\">mAP small objects (%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T3.4.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.2.1.1\">n</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.2.2.1\">s</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.2.3.1\">m</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.2.4.1\">l</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.2.5.1\">x</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T3.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"Ch6.T3.4.3.1\">\n<span class=\"ltx_rule\" style=\"width:0.0pt;height:10.8pt;background:black;display:inline-block;\"/>YOLOv8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.3.2\">39.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.3.3\">40.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.3.4\">41.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.3.5\">42.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.3.6\">43.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T3.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Ch6.T3.4.4.1\">Opt. ScatYOLOv8+CBAM</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T3.4.4.2\">45.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T3.4.4.3\">47.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T3.4.4.4\">47.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T3.4.4.5\">47.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T3.4.4.6\">48.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T3.4.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"Ch6.T3.4.5.1\">\n<span class=\"ltx_rule\" style=\"width:0.0pt;height:10.8pt;background:black;display:inline-block;\"/>YOLOv8 &amp; <a href=\"https://arxiv.org/html/2410.04946v1#glo.acronym.sahi\"><span class=\"ltx_glossaryref\" href=\"https://arxiv.org/html/2410.04946v1#glo.acronym.sahi\" title=\"Slicing Aided Hyper Inference\">SAHI</span></a>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.5.2\">53.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.5.3\">54.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.5.4\">55.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.5.5\">55.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch6.T3.4.5.6\">55.7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch6.T3.4.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"Ch6.T3.4.6.1\">Opt. ScatYOLOv8+CBAM &amp; <a href=\"https://arxiv.org/html/2410.04946v1#glo.acronym.sahi\"><span class=\"ltx_glossaryref\" href=\"https://arxiv.org/html/2410.04946v1#glo.acronym.sahi\" title=\"Slicing Aided Hyper Inference\">SAHI</span></a>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T3.4.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.6.2.1\">54.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T3.4.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.6.3.1\">55.6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T3.4.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.6.4.1\">56.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T3.4.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.6.5.1\">57.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch6.T3.4.6.6\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch6.T3.4.6.6.1\">58.9</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 6.3 :  Comparison of  mAP  scores for small objects with all model sizes using standard YOLOv8, our proposed optimized ScatYOLOv8+CBAM, and the addition of  SAHI . Reprinted from  [BCP-VI] . ©2024 IEEE.",
        "footnotes": [],
        "references": [
            "Table 6.3 presents the results of the analysis on small ship segmentation across different model sizes.\nThe optimized ScatYOLOv8+CBAM outperforms the standard YOLOv8 for small objects across all sizes.\nSAHI significantly boosts performance for both standard YOLOv8 and the optimized ScatYOLOv8+CBAM, showing gains between 8%percent88\\%8 % and 11%percent1111\\%11 % over configurations without SAHI. Specifically, the optimized ScatYOLOv8+CBAM with SAHI achieves the highest mAP improvements for small objects, ranging from 1.4%percent1.41.4\\%1.4 % to 3.2%percent3.23.2\\%3.2 % over standard YOLOv8 equipped with SAHI. Moreover, the advantage of integrating our optimized model with SAHI becomes more pronounced with model depth, highlighting a scalable improvement in small ship segmentation with increased network complexity.\nWhen comparing to the small ship segmentation performance provided in Chapter 5, Table 5.2, the optimized ScatYOLOv8+CBAM with SAHI in model size s𝑠sitalic_s onwards performs as good or better than the best one from the initial study, DetectoRS. It is important to recall that DetectoRS was not compatible with embedded system deployment, which underlines another superiority of the customized architecture.",
            "Compared to its own non-SAHI version, the optimized ScatYOLOv8+CBAM with SAHI in n𝑛nitalic_n size shows equivalent mAP to a the m𝑚mitalic_m model without SAHI, albeit with increased computation time of ∼similar-to\\sim∼170 ms, significantly enhancing small ship segmentation by 7.5%, as shown in Table 6.3.\nThis shows that the benefits of SAHI in densely populated maritime areas where monitoring small, distant ships in real-time is crucial for safety and security, carry considerable associated computational costs."
        ]
    },
    "Ch7.T1.6.6": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"Ch7.T1.6.6\">\n<tr class=\"ltx_tr\" id=\"Ch7.T1.6.6.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch7.T1.6.6.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch7.T1.6.6.7.1.1\">Source</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch7.T1.6.6.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch7.T1.6.6.7.2.1\">System</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch7.T1.6.6.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch7.T1.6.6.7.3.1\">Range to Object</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch7.T1.6.6.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"Ch7.T1.6.6.7.4.1\">Error (m)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch7.T1.6.6.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch7.T1.6.6.8.1\"><cite class=\"ltx_cite ltx_citemacro_cite\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#bib.bib97\" title=\"\">naus2021assessment </a></cite></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch7.T1.6.6.8.2\">Radar Antenna + GPS</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch7.T1.6.6.8.3\">1000 m</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"Ch7.T1.6.6.8.4\">6.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch7.T1.1.1.1\">\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.1.1.1.2\"><cite class=\"ltx_cite ltx_citemacro_cite\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#bib.bib98\" title=\"\">livingstone2014ship </a></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.1.1.1.3\">Synthetic Aperture Radar</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.1.1.1.4\">800 km</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.1.1.1.1\">13&#160;<math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"Ch7.T1.1.1.1.1.m1.1\"><semantics id=\"Ch7.T1.1.1.1.1.m1.1a\"><mo id=\"Ch7.T1.1.1.1.1.m1.1.1\" xref=\"Ch7.T1.1.1.1.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch7.T1.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Ch7.T1.1.1.1.1.m1.1.1.cmml\" xref=\"Ch7.T1.1.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch7.T1.1.1.1.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch7.T1.1.1.1.1.m1.1d\">&#177;</annotation></semantics></math>&#160;23</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch7.T1.2.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.2.2.2.2\"><cite class=\"ltx_cite ltx_citemacro_cite\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#bib.bib99\" title=\"\">wei2020geolocation </a></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.2.2.2.3\">Opt. Remote Sensing</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.2.2.2.4\">36000 km</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.2.2.2.1\">165&#160;<math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"Ch7.T1.2.2.2.1.m1.1\"><semantics id=\"Ch7.T1.2.2.2.1.m1.1a\"><mo id=\"Ch7.T1.2.2.2.1.m1.1.1\" xref=\"Ch7.T1.2.2.2.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch7.T1.2.2.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Ch7.T1.2.2.2.1.m1.1.1.cmml\" xref=\"Ch7.T1.2.2.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch7.T1.2.2.2.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch7.T1.2.2.2.1.m1.1d\">&#177;</annotation></semantics></math>&#160;109</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch7.T1.6.6.9\">\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.6.6.9.1\"><cite class=\"ltx_cite ltx_citemacro_cite\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#bib.bib24\" title=\"\">helgesen2020low </a></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.6.6.9.2\">Opt. Camera + GPS + IMU</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.6.6.9.3\">400 m</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.6.6.9.4\">20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch7.T1.3.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.3.3.3.2\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#Ch10.S2\" title=\"[BCP-II] &#8227; Chapter 10 Publications by the Author for this Thesis &#8227; Real-time Ship Recognition and Georeferencing for the Improvement of Maritime Situational Awareness\"><span class=\"ltx_text ltx_ref_tag\">[BCP-II]</span></a></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.3.3.3.3\">Opt. Camera</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.3.3.3.4\">400 m</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.3.3.3.1\">22<math alttext=\"\\leavevmode\\nobreak\\ \\pm\\leavevmode\\nobreak\\ \" class=\"ltx_Math\" display=\"inline\" id=\"Ch7.T1.3.3.3.1.m1.1\"><semantics id=\"Ch7.T1.3.3.3.1.m1.1a\"><mo id=\"Ch7.T1.3.3.3.1.m1.1.1\" xref=\"Ch7.T1.3.3.3.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch7.T1.3.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Ch7.T1.3.3.3.1.m1.1.1.cmml\" xref=\"Ch7.T1.3.3.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch7.T1.3.3.3.1.m1.1c\">\\leavevmode\\nobreak\\ \\pm\\leavevmode\\nobreak\\ </annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch7.T1.3.3.3.1.m1.1d\">&#177;</annotation></semantics></math>10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch7.T1.4.4.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.4.4.4.2\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#Ch10.S2\" title=\"[BCP-II] &#8227; Chapter 10 Publications by the Author for this Thesis &#8227; Real-time Ship Recognition and Georeferencing for the Improvement of Maritime Situational Awareness\"><span class=\"ltx_text ltx_ref_tag\">[BCP-II]</span></a></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.4.4.4.3\">Opt. Camera</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.4.4.4.4\">1200 m</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.4.4.4.1\">53<math alttext=\"\\leavevmode\\nobreak\\ \\pm\\leavevmode\\nobreak\\ \" class=\"ltx_Math\" display=\"inline\" id=\"Ch7.T1.4.4.4.1.m1.1\"><semantics id=\"Ch7.T1.4.4.4.1.m1.1a\"><mo id=\"Ch7.T1.4.4.4.1.m1.1.1\" xref=\"Ch7.T1.4.4.4.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch7.T1.4.4.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Ch7.T1.4.4.4.1.m1.1.1.cmml\" xref=\"Ch7.T1.4.4.4.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch7.T1.4.4.4.1.m1.1c\">\\leavevmode\\nobreak\\ \\pm\\leavevmode\\nobreak\\ </annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch7.T1.4.4.4.1.m1.1d\">&#177;</annotation></semantics></math>24</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch7.T1.5.5.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.5.5.5.2\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#Ch10.S5\" title=\"[BCP-V] &#8227; Chapter 10 Publications by the Author for this Thesis &#8227; Real-time Ship Recognition and Georeferencing for the Improvement of Maritime Situational Awareness\"><span class=\"ltx_text ltx_ref_tag\">[BCP-V]</span></a></td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.5.5.5.3\">Opt. Camera</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.5.5.5.4\">400 m</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.5.5.5.1\">18<math alttext=\"\\leavevmode\\nobreak\\ \\pm\\leavevmode\\nobreak\\ \" class=\"ltx_Math\" display=\"inline\" id=\"Ch7.T1.5.5.5.1.m1.1\"><semantics id=\"Ch7.T1.5.5.5.1.m1.1a\"><mo id=\"Ch7.T1.5.5.5.1.m1.1.1\" xref=\"Ch7.T1.5.5.5.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch7.T1.5.5.5.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Ch7.T1.5.5.5.1.m1.1.1.cmml\" xref=\"Ch7.T1.5.5.5.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch7.T1.5.5.5.1.m1.1c\">\\leavevmode\\nobreak\\ \\pm\\leavevmode\\nobreak\\ </annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch7.T1.5.5.5.1.m1.1d\">&#177;</annotation></semantics></math>10</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch7.T1.6.6.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.6.6.6.2\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#Ch10.S5\" title=\"[BCP-V] &#8227; Chapter 10 Publications by the Author for this Thesis &#8227; Real-time Ship Recognition and Georeferencing for the Improvement of Maritime Situational Awareness\"><span class=\"ltx_text ltx_ref_tag\">[BCP-V]</span></a>*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.6.6.6.3\">Opt. Camera</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.6.6.6.4\">1200 m</td>\n<td class=\"ltx_td ltx_align_center\" id=\"Ch7.T1.6.6.6.1\">44<math alttext=\"\\leavevmode\\nobreak\\ \\pm\\leavevmode\\nobreak\\ \" class=\"ltx_Math\" display=\"inline\" id=\"Ch7.T1.6.6.6.1.m1.1\"><semantics id=\"Ch7.T1.6.6.6.1.m1.1a\"><mo id=\"Ch7.T1.6.6.6.1.m1.1.1\" xref=\"Ch7.T1.6.6.6.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"Ch7.T1.6.6.6.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Ch7.T1.6.6.6.1.m1.1.1.cmml\" xref=\"Ch7.T1.6.6.6.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Ch7.T1.6.6.6.1.m1.1c\">\\leavevmode\\nobreak\\ \\pm\\leavevmode\\nobreak\\ </annotation><annotation encoding=\"application/x-llamapun\" id=\"Ch7.T1.6.6.6.1.m1.1d\">&#177;</annotation></semantics></math>27</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Ch7.T1.6.6.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"4\" id=\"Ch7.T1.6.6.10.1\"><span class=\"ltx_text\" id=\"Ch7.T1.6.6.10.1.1\" style=\"font-size:80%;\">*Value not reported in <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.04946v1#Ch10.S5\" title=\"[BCP-V] &#8227; Chapter 10 Publications by the Author for this Thesis &#8227; Real-time Ship Recognition and Georeferencing for the Improvement of Maritime Situational Awareness\"><span class=\"ltx_text ltx_ref_tag\">[BCP-V]</span></a> but calculated for this table.</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 7.1 :  Comparison of the proposed method for ship georeferencing accuracy with existing works.",
        "footnotes": [
            "(97) \nK. Naus, M. W, P. Szymak, L. Gucma, and M. Gucma, “Assessment of ship position\nestimation accuracy based on radar navigation mark echoes identified in an\nelectronic navigational chart,”  Measurement , vol. 169, p. 108630,\n2020.\n\n",
            "(98) \nC. E. Livingstone, M. Dragosevic, S. Chu, and I. Sikaneta,  Ship detection\nand measurement of ship motion by multi-aperture Synthetic Aperture\nRadar .   Defence Research and\nDevelopment Canada, 2014.\n\n",
            "(99) \nY. Wei, Z. Zhang, B. Mu, Y. Li, Q. Wang, and R. Liu, “Geolocation accuracy\nevaluation of gf-4 geostationary high-resolution optical images over coastal\nzones and offshore areas,”  Journal of Coastal Research , vol. 102,\nno. SI, pp. 326–333, 2020.\n\n",
            "(24) \nØ. K. Helgesen, E. F. Brekke, A. Stahl, and Ø. Engelhardtsen, “Low\naltitude georeferencing for imaging sensors in maritime tracking,”\n IFAC-PapersOnLine , vol. 53, no. 2, pp. 14 476–14 481, 2020.\n\n"
        ],
        "references": [
            "Given the absence of directly comparable methodologies that simultaneously address the use of monocular cameras without prior camera pose knowledge for fast ship georeferencing, this approach establishes a benchmark in the literature. A comparison of the obtained results with existing ship georeferencing accuracies that use other technologies can be seen in Table 7.1, which is an updated version of Table 3.1 for ship georeferencing. The most comparable set-up and result is given by helgesen2020low , that utilizes prior knowledge of camera calibration, and its application was limited to controlled conditions with a single video sequence of a two small ships. Our method obtains similar positioning error, however providing a much more comprehensive study: results using two views, longer ranges, uncertainties, a large variety of ships of different categories and sizes, and does not need prior camera pose knowledge."
        ]
    }
}