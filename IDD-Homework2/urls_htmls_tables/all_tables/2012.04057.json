{
    "PAPER'S NUMBER OF TABLES": 1,
    "S6.T1": {
        "caption": "TABLE I: Performance of simultaneous quantization on both uplink and downlink.",
        "table": "<table id=\"S6.T1.1\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Dataset</td>\n<td id=\"S6.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Downlink</td>\n<td id=\"S6.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Uplink</td>\n<td id=\"S6.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Accuracy (Baseline)</td>\n<td id=\"S6.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Percentage*</td>\n</tr>\n<tr id=\"S6.T1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"5\">i.i.d.</td>\n</tr>\n<tr id=\"S6.T1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">MNIST</td>\n<td id=\"S6.T1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">2-bit</td>\n<td id=\"S6.T1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">2-bit</td>\n<td id=\"S6.T1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">98.46% (99.11%)</td>\n<td id=\"S6.T1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">99.34%</td>\n</tr>\n<tr id=\"S6.T1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.4.4.1\" class=\"ltx_td ltx_align_center\">CIFAR-10</td>\n<td id=\"S6.T1.1.4.4.2\" class=\"ltx_td ltx_align_center\">5-bit</td>\n<td id=\"S6.T1.1.4.4.3\" class=\"ltx_td ltx_align_center\">2-bit</td>\n<td id=\"S6.T1.1.4.4.4\" class=\"ltx_td ltx_align_center\">78.43% (79.93%)</td>\n<td id=\"S6.T1.1.4.4.5\" class=\"ltx_td ltx_align_center\">98.12%</td>\n</tr>\n<tr id=\"S6.T1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.5.5.1\" class=\"ltx_td ltx_align_center\">Shakespeare</td>\n<td id=\"S6.T1.1.5.5.2\" class=\"ltx_td ltx_align_center\">5-bit</td>\n<td id=\"S6.T1.1.5.5.3\" class=\"ltx_td ltx_align_center\">2-bit</td>\n<td id=\"S6.T1.1.5.5.4\" class=\"ltx_td ltx_align_center\">56.17% (57.25%)</td>\n<td id=\"S6.T1.1.5.5.5\" class=\"ltx_td ltx_align_center\">98.11%</td>\n</tr>\n<tr id=\"S6.T1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"5\">Non-i.i.d.</td>\n</tr>\n<tr id=\"S6.T1.1.7.7\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_t\">MNIST</td>\n<td id=\"S6.T1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">2-bit</td>\n<td id=\"S6.T1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">2-bit</td>\n<td id=\"S6.T1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">97.41% (99.10%)</td>\n<td id=\"S6.T1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">98.29%</td>\n</tr>\n<tr id=\"S6.T1.1.8.8\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.8.8.1\" class=\"ltx_td ltx_align_center\">CIFAR-10</td>\n<td id=\"S6.T1.1.8.8.2\" class=\"ltx_td ltx_align_center\">6-bit</td>\n<td id=\"S6.T1.1.8.8.3\" class=\"ltx_td ltx_align_center\">4-bit</td>\n<td id=\"S6.T1.1.8.8.4\" class=\"ltx_td ltx_align_center\">61.67% (62.61%)</td>\n<td id=\"S6.T1.1.8.8.5\" class=\"ltx_td ltx_align_center\">98.50%</td>\n</tr>\n<tr id=\"S6.T1.1.9.9\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.9.9.1\" class=\"ltx_td ltx_align_center\">Shakespeare</td>\n<td id=\"S6.T1.1.9.9.2\" class=\"ltx_td ltx_align_center\">5-bit</td>\n<td id=\"S6.T1.1.9.9.3\" class=\"ltx_td ltx_align_center\">3-bit</td>\n<td id=\"S6.T1.1.9.9.4\" class=\"ltx_td ltx_align_center\">55.16% (56.16%)</td>\n<td id=\"S6.T1.1.9.9.5\" class=\"ltx_td ltx_align_center\">98.22%</td>\n</tr>\n<tr id=\"S6.T1.1.10.10\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_b\">F-EMNIST</td>\n<td id=\"S6.T1.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_b\">5-bit</td>\n<td id=\"S6.T1.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_b\">3-bit</td>\n<td id=\"S6.T1.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_b\">80.24% (81.82%)</td>\n<td id=\"S6.T1.1.10.10.5\" class=\"ltx_td ltx_align_center ltx_border_b\">98.07%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "*: The last column represents the percentage of FL accuracy against the baseline accuracy.",
        "references": [
            "Lastly, we carry out experiment with simultaneous quantization on both uplink and downlink communications. The experimental results on different datasets are reported in Table I. We run 1000 rounds for MNIST and average the final 100 rounds as the final (convergence) accuracy (the fourth column). As for CIFAR-10, Shakespeare and F-EMNIST, we run 500 rounds and average the final 50 rounds. The last column shows the percentage of the baseline (using 32-bit float) can be achieved by the learning with quantized communications in both uplink and downlink. For all experiments, layered quantization with TQ and SR is used for downlink while DT with TQ and SR is used for uplink.",
            "We evaluate how much communication payload can be reduced while maintaining a small accuracy loss (defined as less than 2%). The results in Table I show that well designed quantization schemes are important to improve the communication efficiency. Take MNIST (i.i.d.) as an example, 2-bit for both downlink or uplink are sufficiently good, which can reduce (from the baseline) 93.75% in communications for both uplink and downlink. Even for the more complex cases such as CIFAR-10 (non-i.i.d.), 6-bit for downlink and 4-bit for uplink have very good performance, reducing 81.25% and 87.5% of the communication bandwidth for each client on downlink and uplink respectively. Overall, we conclude that the proposed designs are effective in addressing the communication bottleneck of federated learning."
        ]
    }
}