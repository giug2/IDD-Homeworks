{
    "Sx1.T1": {
        "caption": "Table 1: Predefined meta-paths of real-world datasets.\nIn this table, it can be noticed that most of ℛℛ\\mathcal{R} are inter-type relations and 𝒫𝒫\\mathcal{P} target on intra-type relations by setting the same type of nodes at both ends of 𝒫𝒫\\mathcal{P}.",
        "table": null,
        "footnotes": [],
        "references": [
            "A meta-path (Sun et al. 2011) 𝒫𝒫\\mathcal{P} is defined as a path that has a form of A1→R1A2→R2⋯→RlAl+1subscript𝑅1→subscript𝐴1subscript𝐴2subscript𝑅2→⋯subscript𝑅𝑙→subscript𝐴𝑙1A_{1}\\xrightarrow{\\mbox{{$R_{1}$}}}A_{2}\\xrightarrow{\\mbox{{$R_{2}$}}}\\cdots\\xrightarrow{\\mbox{{$R_{l}$}}}A_{l+1} (abbreviated as A1​A2​⋯​Al+1subscript𝐴1subscript𝐴2⋯subscript𝐴𝑙1A_{1}A_{2}\\cdots A_{l+1}) which describes relations between A1subscript𝐴1A_{1} and Al+1∈𝒜subscript𝐴𝑙1𝒜A_{l+1}\\in\\mathcal{A} with a composition of relations R1,R2,…,Rl∈ℛsubscript𝑅1subscript𝑅2…subscript𝑅𝑙ℛR_{1},R_{2},\\ldots,R_{l}\\in\\mathcal{R}, where 𝒜𝒜\\mathcal{A} and ℛℛ\\mathcal{R} denote sets of node types and edge types of heterogeneous graphs, respectively.\nEach meta-path can describe a semantic relation between nodes at both ends of the meta-path.\nFor instance, in Figure 1 (c), the meta-path of movie-director-movie can describe the relationship between two movies by which the director filmed them.\nNearly all meta-paths of the real-world datasets (Wang et al. 2019; Fu et al. 2020; Wang et al. 2020, 2021) are implicitly composed for intra-type relations by setting the same type of nodes at both ends of 𝒫𝒫\\mathcal{P} using given inter-type relations ℛℛ\\mathcal{R} as shown in Table 1."
        ]
    },
    "Sx4.T2": {
        "caption": "Table 2: Statistics of datasets. The target node type of each dataset is shown in bold.",
        "table": null,
        "footnotes": [],
        "references": [
            "We validated the contrastive learning model based on our MN-MPL using four real-world heterogeneous graph datasets.\nThe statistics of datasets are presented in Table 2.\nThe details and download links of datasets are presented in the supplementary material.",
            "If there are few inter-type relations, then existing heterogeneous models cannot learn the intra-type relations well due to the limited number of meta-paths that are composed of inter-type relations.\nTo show the effectiveness of meta-nodes compared to meta-paths, we make the graphs of ACM, DBLP, and AMiner sparse by randomly removing a fraction of the edges.\nThen, we measured the node classification performances of three models: i) the proposed model (MN), ii) aggregating only messages of each node and direct heterogeneous neighbors without using meta-node representation (without MN), and iii) HeCo which relies on meta-paths.\nThe results are presented in Figure 4.\nIn the results of ACM and DBLP, by comparing MN and without MN, it can be noticed that the proposed meta-node message passing scheme enables learning enriched relational knowledge by leveraging both inter- and intra-type relations effectively.\nAlso, due to the decreased number of meta-paths by sparsifying graphs, the performance of HeCo deteriorated severely.\nIn the case of ACM, the performance of without MN is better than that of HeCo.\nWe conjecture that both view masking mechanism and positive sample mining that utilize meta-paths in HeCo are significantly affected by the reduced number of meta-paths in some cases.\nOn the other hand, every method shows similar performances on AMiner.\nThis is because, as shown in Table 2, all the given edges are connected to the target node type and are abundant compared to the number of target nodes.\nTherefore, if the inter-type relations connecting the target type nodes are abundant, target nodes can aggregate enough information, or one can create a sufficient number of meta-path."
        ]
    },
    "Sx4.T3": {
        "caption": "Table 3: Summary of node classification results (%±σ\\%\\pm\\sigma).",
        "table": null,
        "footnotes": [],
        "references": [
            "We conducted node classification to see how useful the learned representation from the meta-node message passing encoder of contrastive learning is.\nFor each dataset, we selected 20,40,6020406020,40,60 nodes per class for training set, 1,00010001,000 nodes for validation set, and 1,00010001,000 nodes for test set.\nWe trained and tested a single layer of logistic regression classifier, and used Macro-F1, Micro-F1, and AUC for evaluation metrics.\nThe average value and standard deviation after executing each model 101010 times are reported in Table 3.\nThe results demonstrate that our method (MN) can achieve outstanding results compared to the existing homogeneous models and heterogeneous models even without any predefined composition of heterogeneous nodes such as meta-paths.\nEspecially, in most cases, the proposed method shows outperforming results compared to state-of-the-art heterogeneous models (mp2vec, DMGI, HeCo, etc.) that rely on the pre-configured meta-paths.\nAlso, it can be seen that our method shows outstanding performances compared to contrastive learning models including DGI, DMGI, and HeCo.\nWe have also observed that, for AMiner and Freebase datasets where the node feature does not have proper information about the semantics of the node, homogeneous models can achieve similar performances to heterogeneous models.\nSpecifically, n2vec and GAE show classification performances close to those of several heterogeneous models such as mp2vec, HERec, HetGNN.\nWe conjecture that the node feature with rich semantics plays an important role in distinguishing different types of nodes of heterogeneous graphs."
        ]
    },
    "Sx4.T4": {
        "caption": "Table 4: Summary of node clustering results (%percent\\%).",
        "table": null,
        "footnotes": [],
        "references": [
            "We conducted node clustering by applying k-means clustering algorithm to the learned representation of each model.\nThe clustering performance is measured by Normalized Mutual Information (NMI) and Adjusted Rand Index (ARI).\nTable 4 reports the average value after executing each model 101010 times to consider random initialization of k-means clustering algorithm.\nFor most cases, the proposed method shows outstanding performance compared to the state-of-the-art.\nThe results of DMGI, HeCo, and our method demonstrate that the contrastive learning framework is effective to learn representations of heterogeneous graphs in unsupervised environments.\nWe observed that every model shows poor performance on Freebase compared to other datasets.\nSimilar to (Fu et al. 2020)’s analysis on IMDB movie dataset, we guess the cause of this result comes from the noisy labels of the movie genres.\nEvery movie can have multiple genres, but for the classification task, only one genre was selected as a label among them.\nAs evidence for this conjecture, we found that another paper (Li et al. 2016) used different movie genre labels, Action, Adventure, and Crime for the Freebase dataset, while, in our experiments, we used Action, Comedy and Drama labels."
        ]
    }
}