{
    "id_table_1": {
        "caption": "Table 1:  Models Average ranking for  h = 1 h 1 h=1 italic_h = 1 .",
        "table": "S4.Ex1",
        "footnotes": [],
        "references": [
            "Kunsch [ 1989 ]  proposed the so-called Moving Block Bootstrap (MBB). Here, the time series is first divided into  B B B italic_B  overlapping blocks of length  l l \\ell roman_l ,  B = T  l + 1 B T l 1 B=T-\\ell+1 italic_B = italic_T - roman_l + 1 , where the block  b i = ( Y i , ... , Y i + l  1 ) subscript b i subscript Y i ... subscript Y i l 1 b_{i}=(Y_{i},\\ldots,Y_{i+\\ell-1}) italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = ( italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , ... , italic_Y start_POSTSUBSCRIPT italic_i + roman_l - 1 end_POSTSUBSCRIPT )  starts at time index  i i i italic_i ,  i = 1 , ... , B i 1 ... B i=1,\\ldots,B italic_i = 1 , ... , italic_B . Then  k =  T l  k T l k=\\left\\lfloor\\frac{T}{\\ell}\\right\\rfloor italic_k =  divide start_ARG italic_T end_ARG start_ARG roman_l end_ARG   blocks are drawn independently with replacement and joined together in the order in which they were drawn to recover the original length of the time series. Figure  1  illustrates this strategy for a time series of length  T = 9 T 9 T=9 italic_T = 9  using a block length of  l = 2 l 2 \\ell=2 roman_l = 2 .",
            "We observe an improvement for the new RF of up to 13% and 16% for one-step and five-step ahead prediction, respectively (Figure  3 ) for the median of MSEs compared to the other RF variants. ARSB successfully creates more diverse trees than its counterparts. The new RFs performance is comparable with that of the YW estimator. This similarity shows that the properties of the fitted AR model have been conserved during tree construction with ARSB. However, it performs less good if the DGP has a high value on the MA part of Equation  2  (Figures  15 - 16 ,  22 - 24 ) but still performs better than the other RF models.",
            "The models performances were also ranked (tables  1  and  2 ) on each of the 72 simulation configurations and DGP. Ties were resolved using mean ranks.",
            "Although the new RF was not the best performing model overall, the results are still encouraging given that no parameter tuning was done. Moreover, different to the classical YW time series approach, RF can also support exogenous variables. It also performs better on long-term (h=5) than short-term prediction (h=1) and when the AR part dominates the DGP (figures  9  -  10 )."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Models Average ranking for  h = 5 h 5 h=5 italic_h = 5 .",
        "table": "S4.T1.3",
        "footnotes": [],
        "references": [
            "We start with a brief introduction to RF in Section  2  and its different bootstrap strategies used in the literature. We then present the new approach with the ARSB and compare its computational complexity with that of the other bootstrap methods in Section  3 . Section  4  concludes with the results and an outlook.",
            "Block bootstrap methods are all index-based. Only the samples indices need to be known for a bootstrap dataset to be created, making block bootstrapping strategies efficient. They typically perform in  O  ( T ) O T \\mathcal{O}(T) caligraphic_O ( italic_T )  time and only need  O  ( T ) O T \\mathcal{O}(T) caligraphic_O ( italic_T )  space (Figure  2 , right) for each tree to be built.",
            "The AR-Sieve strategy also requires more memory space. The bootstrap time series and its first  p p p italic_p  lags need to be stored (Figure  2 , left), requiring  O  ( T  p ) O T p \\mathcal{O}(T*p) caligraphic_O ( italic_T  italic_p )  space. However, the additional effort required by the ARSB may prove beneficial as it helps to create more diverse trees, which may increase the RFs accuracy. Whether this intuition is really true will be evaluated in the following section.",
            "We observe an improvement for the new RF of up to 13% and 16% for one-step and five-step ahead prediction, respectively (Figure  3 ) for the median of MSEs compared to the other RF variants. ARSB successfully creates more diverse trees than its counterparts. The new RFs performance is comparable with that of the YW estimator. This similarity shows that the properties of the fitted AR model have been conserved during tree construction with ARSB. However, it performs less good if the DGP has a high value on the MA part of Equation  2  (Figures  15 - 16 ,  22 - 24 ) but still performs better than the other RF models.",
            "The models performances were also ranked (tables  1  and  2 ) on each of the 72 simulation configurations and DGP. Ties were resolved using mean ranks."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Models Average runtime per model.",
        "table": "S4.T2.3",
        "footnotes": [],
        "references": [
            "In this paper, we propose to use the AR-Sieve Bootstrap (ARSB)  [Buhlmann,  1997 , Kreiss,  1988 ]  instead of the IID bootstrap to construct the trees of the RF. The ARSB draws the bootstrap samples from a fitted autoregressive (AR) model and has already been shown to perform well for other time series models such as ARMA (AutoRegressive Moving Average) models  [Kreiss et al.,  2011 ] . To assess the performance of this new RF model, we compare its predictive accuracy with that of five RFs variants and a benchmark model for time series forecasting based on an autoregressive model fit in extensive simulations. For this purpose, we consider six different classes for the DGP: AR-  [Jurgen Franke and Hafner,  2008a ] , MA- (Moving Average,  [Jurgen Franke and Hafner,  2008a ] ), ARMA-  [Jurgen Franke and Hafner,  2008a ] , ARIMA- (AutoRegressive Integrated Moving Average,  [Jurgen Franke and Hafner,  2008a ] ), ARFIMA- (AutoRegressive Fractionally Integrated Moving Average,  [Granger and Joyeux,  1980 ] ), and GARCH (Generalized AutoRegressive Conditional Heteroskedastic,  [Jurgen Franke and Hafner,  2008b ] ) processes, see sections  3  and  4  for the explicit definition of the DGPs.",
            "We start with a brief introduction to RF in Section  2  and its different bootstrap strategies used in the literature. We then present the new approach with the ARSB and compare its computational complexity with that of the other bootstrap methods in Section  3 . Section  4  concludes with the results and an outlook.",
            "We thus consider twenty-five (25) time series DGPs, each in three different sizes  T  T absent T\\in italic_T   {100, 500 and 1000}, yielding a total of  75 75 75 75  parameters configurations. For each configuration, we find the Yule-Walker estimates for the ARSB coefficients and train RFs with the bootstrap strategies presented in Section  3 . One-step ( h = 1 h 1 h=1 italic_h = 1 ) and five-step ahead ( h = 5 h 5 h=5 italic_h = 5 ) predictions are then made using the recursive multi-step forecast  [Taieb et al.,  2012 ]  method. At each iteration, data is generated, the different models are fitted, and their performances are evaluated via the Mean Square Error (MSE). To obtain a unified metric over the  M M M italic_M  iterations, we use the median of all MSEs  [Tyralis and Papacharalampous,  2017 ] .",
            "We observe an improvement for the new RF of up to 13% and 16% for one-step and five-step ahead prediction, respectively (Figure  3 ) for the median of MSEs compared to the other RF variants. ARSB successfully creates more diverse trees than its counterparts. The new RFs performance is comparable with that of the YW estimator. This similarity shows that the properties of the fitted AR model have been conserved during tree construction with ARSB. However, it performs less good if the DGP has a high value on the MA part of Equation  2  (Figures  15 - 16 ,  22 - 24 ) but still performs better than the other RF models.",
            "Regarding the running time, RF with ARSB has the highest value (Figure  4 ) as expected and was approximately up to two times slower than the other RF models. Nevertheless, its running time does not increase linearly with the order of the fitted model (table  3 ). It remains low enough with an average value of  0.06 0.06 0.06 0.06  seconds for an average time series length of  T = 533 T 533 T=533 italic_T = 533  and an average fitted order of  p = 3.4 p 3.4 p=3.4 italic_p = 3.4 ."
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "S4.T3.1",
        "footnotes": [],
        "references": [
            "In this paper, we propose to use the AR-Sieve Bootstrap (ARSB)  [Buhlmann,  1997 , Kreiss,  1988 ]  instead of the IID bootstrap to construct the trees of the RF. The ARSB draws the bootstrap samples from a fitted autoregressive (AR) model and has already been shown to perform well for other time series models such as ARMA (AutoRegressive Moving Average) models  [Kreiss et al.,  2011 ] . To assess the performance of this new RF model, we compare its predictive accuracy with that of five RFs variants and a benchmark model for time series forecasting based on an autoregressive model fit in extensive simulations. For this purpose, we consider six different classes for the DGP: AR-  [Jurgen Franke and Hafner,  2008a ] , MA- (Moving Average,  [Jurgen Franke and Hafner,  2008a ] ), ARMA-  [Jurgen Franke and Hafner,  2008a ] , ARIMA- (AutoRegressive Integrated Moving Average,  [Jurgen Franke and Hafner,  2008a ] ), ARFIMA- (AutoRegressive Fractionally Integrated Moving Average,  [Granger and Joyeux,  1980 ] ), and GARCH (Generalized AutoRegressive Conditional Heteroskedastic,  [Jurgen Franke and Hafner,  2008b ] ) processes, see sections  3  and  4  for the explicit definition of the DGPs.",
            "We start with a brief introduction to RF in Section  2  and its different bootstrap strategies used in the literature. We then present the new approach with the ARSB and compare its computational complexity with that of the other bootstrap methods in Section  3 . Section  4  concludes with the results and an outlook.",
            "Although the fitted model is linear with Gaussian errors, the approach is theoretically valid for more general DGPs, see  Kreiss et al. [ 2011 ]  for details. We evaluate the use of ARSB in the RF for forecasting different type of linear and non-linear processes in the simulation study in Section  4 . Before that we shortly discuss the computational complexity of all bootstrap methods.",
            "We observe an improvement for the new RF of up to 13% and 16% for one-step and five-step ahead prediction, respectively (Figure  3 ) for the median of MSEs compared to the other RF variants. ARSB successfully creates more diverse trees than its counterparts. The new RFs performance is comparable with that of the YW estimator. This similarity shows that the properties of the fitted AR model have been conserved during tree construction with ARSB. However, it performs less good if the DGP has a high value on the MA part of Equation  2  (Figures  15 - 16 ,  22 - 24 ) but still performs better than the other RF models.",
            "Regarding the running time, RF with ARSB has the highest value (Figure  4 ) as expected and was approximately up to two times slower than the other RF models. Nevertheless, its running time does not increase linearly with the order of the fitted model (table  3 ). It remains low enough with an average value of  0.06 0.06 0.06 0.06  seconds for an average time series length of  T = 533 T 533 T=533 italic_T = 533  and an average fitted order of  p = 3.4 p 3.4 p=3.4 italic_p = 3.4 ."
        ]
    }
}