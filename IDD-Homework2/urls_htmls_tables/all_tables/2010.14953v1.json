{
    "S4.T1": {
        "caption": "Table 1: Results on the COCO test dataset. First row contains scores for real images (excluding VQA Acc.) as reported in [Hinz et al., 2019]. We re-train and re-evaluate the baseline AttnGAN (second row). Third and fourth row are our naive extensions in which we simply append a VQA model for an external VQA loss for images generated from QA pairs. In the last row, we change the discriminator and generator losses to also encourage images generated from QA pairs to look realistic and match the input (similar to standard AttnGAN losses for images generated from captions). We train each model for 120 epochs, select the checkpoint with the best IS and report corresponding FID, R-prec., and VQA accuracy.",
        "table": "<table id=\"S4.T1.4.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.4.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.4.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S4.T1.4.4.4.5.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">IS <math id=\"S4.T1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.1.1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.1.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.1.1.m1.1b\"><ci id=\"S4.T1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.1.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.1.1.m1.1c\">\\uparrow</annotation></semantics></math></span></th>\n<th id=\"S4.T1.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T1.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">FID <math id=\"S4.T1.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T1.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.2.2.2.2.1.m1.1.1\" xref=\"S4.T1.2.2.2.2.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.2.2.2.2.1.m1.1b\"><ci id=\"S4.T1.2.2.2.2.1.m1.1.1.cmml\" xref=\"S4.T1.2.2.2.2.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.2.2.2.2.1.m1.1c\">\\downarrow</annotation></semantics></math></span></th>\n<th id=\"S4.T1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T1.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">R-prec. <math id=\"S4.T1.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T1.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.3.3.3.3.1.m1.1.1\" xref=\"S4.T1.3.3.3.3.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.3.3.3.3.1.m1.1b\"><ci id=\"S4.T1.3.3.3.3.1.m1.1.1.cmml\" xref=\"S4.T1.3.3.3.3.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></th>\n<th id=\"S4.T1.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T1.4.4.4.4.1\" class=\"ltx_text ltx_font_bold\">VQA Acc. <math id=\"S4.T1.4.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T1.4.4.4.4.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.4.4.4.4.1.m1.1.1\" xref=\"S4.T1.4.4.4.4.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.4.4.4.4.1.m1.1b\"><ci id=\"S4.T1.4.4.4.4.1.m1.1.1.cmml\" xref=\"S4.T1.4.4.4.4.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.4.4.4.4.1.m1.1c\">\\uparrow</annotation></semantics></math></span></th>\n</tr>\n<tr id=\"S4.T1.4.4.5.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Real Images</th>\n<th id=\"S4.T1.4.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">34.88</th>\n<th id=\"S4.T1.4.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">6.09</th>\n<th id=\"S4.T1.4.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">68.58</th>\n<th id=\"S4.T1.4.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">60.00</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.4.4.6.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.6.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">AttnGAN <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bibx23\" title=\"\" class=\"ltx_ref\">Xu et al., 2017</a>]</cite>\n</th>\n<td id=\"S4.T1.4.4.6.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.4.4.6.1.2.1\" class=\"ltx_text ltx_font_bold\">26.66</span></td>\n<td id=\"S4.T1.4.4.6.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">27.84</td>\n<td id=\"S4.T1.4.4.6.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">83.82</td>\n<td id=\"S4.T1.4.4.6.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">43.00</td>\n</tr>\n<tr id=\"S4.T1.4.4.7.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.7.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">AttnGAN + end-to-end VQA</th>\n<td id=\"S4.T1.4.4.7.2.2\" class=\"ltx_td ltx_align_center\">25.22</td>\n<td id=\"S4.T1.4.4.7.2.3\" class=\"ltx_td ltx_align_center\">30.68</td>\n<td id=\"S4.T1.4.4.7.2.4\" class=\"ltx_td ltx_align_center\">82.68</td>\n<td id=\"S4.T1.4.4.7.2.5\" class=\"ltx_td ltx_align_center\">42.85</td>\n</tr>\n<tr id=\"S4.T1.4.4.8.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.8.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">AttnGAN + pre-trained VQA</th>\n<td id=\"S4.T1.4.4.8.3.2\" class=\"ltx_td ltx_align_center\">26.02</td>\n<td id=\"S4.T1.4.4.8.3.3\" class=\"ltx_td ltx_align_center\">28.72</td>\n<td id=\"S4.T1.4.4.8.3.4\" class=\"ltx_td ltx_align_center\">84.25</td>\n<td id=\"S4.T1.4.4.8.3.5\" class=\"ltx_td ltx_align_center\">42.83</td>\n</tr>\n<tr id=\"S4.T1.4.4.9.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.9.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\">AttnGAN + pre-trained VQA + adapted loss</th>\n<td id=\"S4.T1.4.4.9.4.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.4.4.9.4.2.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">26.64</span></td>\n<td id=\"S4.T1.4.4.9.4.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.4.4.9.4.3.1\" class=\"ltx_text ltx_font_bold\">25.38</span></td>\n<td id=\"S4.T1.4.4.9.4.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.4.4.9.4.4.1\" class=\"ltx_text ltx_font_bold\">84.79</span></td>\n<td id=\"S4.T1.4.4.9.4.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.4.4.9.4.5.1\" class=\"ltx_text ltx_font_bold\">43.75</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "As can be seen in Table 1, merely adding the external VQA loss to the generator impairs the performance, regardless of using a pre-trained VQA model or training it as part of the pipeline in an end-to-end way.\nWe hypothesize this is due to the images produced from QA pairs not being encouraged to look realistic during training and the generator struggling to minimize the external VQA loss for images generated from QA pairs, on the one hand, and standard AttnGAN losses for images generated from captions, on the other hand."
        ]
    }
}