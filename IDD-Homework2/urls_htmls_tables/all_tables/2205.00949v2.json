{
    "S5.T1": {
        "caption": "Table 1: Zero-shot performance of multi-task Answer-Me for mixtures of tasks. The mixtures do not include the task that is being tested on (we make sure there is no ‘leakage’ to the test set for each experiment). As seen, the mixture improves zero-shot performance over pretraining. Increasing the Answer-Me mixture set (number of tasks in the mixture) leads to better ZS performance. Scaling the model (last row) is additionally beneficial across all tasks.",
        "table": "<table id=\"S5.T1.3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Approach</th>\n<th id=\"S5.T1.3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VQA</th>\n<th id=\"S5.T1.3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">NLVR2</th>\n<th id=\"S5.T1.3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">SNLI-VE</th>\n<th id=\"S5.T1.3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">GQA</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Pretrained only</th>\n<td id=\"S5.T1.3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">25.3</td>\n<td id=\"S5.T1.3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">32.5</td>\n<td id=\"S5.T1.3.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">22.7</td>\n<td id=\"S5.T1.3.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">40.9</td>\n</tr>\n<tr id=\"S5.T1.3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Answer-Me 4-ZS-tasks</th>\n<td id=\"S5.T1.3.1.3.2.2\" class=\"ltx_td ltx_align_center\">30.0</td>\n<td id=\"S5.T1.3.1.3.2.3\" class=\"ltx_td ltx_align_center\">42.5</td>\n<td id=\"S5.T1.3.1.3.2.4\" class=\"ltx_td ltx_align_center\">34.1</td>\n<td id=\"S5.T1.3.1.3.2.5\" class=\"ltx_td ltx_align_center\">42.3</td>\n</tr>\n<tr id=\"S5.T1.3.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Answer-Me 8-ZS-tasks</th>\n<td id=\"S5.T1.3.1.4.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.3.1.4.3.2.1\" class=\"ltx_text ltx_font_bold\">35.0</span></td>\n<td id=\"S5.T1.3.1.4.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.3.1.4.3.3.1\" class=\"ltx_text ltx_font_bold\">44.7</span></td>\n<td id=\"S5.T1.3.1.4.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.3.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">37.3</span></td>\n<td id=\"S5.T1.3.1.4.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.3.1.4.3.5.1\" class=\"ltx_text ltx_font_bold\">44.2</span></td>\n</tr>\n<tr id=\"S5.T1.3.1.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">Answer-Me 8-ZS-tasks, 3x</th>\n<td id=\"S5.T1.3.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.3.1.5.4.2.1\" class=\"ltx_text ltx_font_bold\">39.2</span></td>\n<td id=\"S5.T1.3.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.3.1.5.4.3.1\" class=\"ltx_text ltx_font_bold\">48.3</span></td>\n<td id=\"S5.T1.3.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.3.1.5.4.4.1\" class=\"ltx_text ltx_font_bold\">41.1</span></td>\n<td id=\"S5.T1.3.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.3.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\">47.2</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In Table 1, we evaluate Answer-Me when training on a mix of tasks in a Zero-Shot (ZS) setting, i.e., on unseen tasks. This is important as it is not always feasible to obtain full labeling of examples for new tasks. The mixture training is able to give better answers than just the pretrained model. Our results also indicate that larger mixtures lead to better zero-shot results, which shows an important ability to perform new skills.",
            "We evaluate in zero-shot manner on VQA2.0, SNLI-VE, GQA and NLVR2. NLVR2 needs two images as input, unlike all other datasets, so here it is only used as a zero-shot evaluation. Table 1 shows the zero-shot results, using the pretrained only, 4-task and 8-task model. The 8-task mix improves by almost 10% on VQA2.0.\nWe also find that 8 tasks mixture produces consistently better results across all datasets than 4 tasks, even though the additional 4 tasks are less related to VQA data. When scaling, we observe even higher results on VQA and consistent improvements on all datasets.\nFor comparison, a single model from scratch trained on VQA2.0 only achieves 49% accuracy. The multi-task learning by leveraging other image-text datasets is able to reduce the gap to supervised training. This is very promising as it demonstrates a level of generalization to novel/unseen tasks. This further improves upon the results in Frozen [64] which got 29.5% for ZS on VQA.",
            "As seen in Table 1, Table 2 and Table 4, there is progressive improvement with adding more tasks in the mixture and scaling the model, here 3X, produces consistently higher accuracies."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Experiments comparing Answer-Me multi-task learning, evaluated on several datasets. As seen, more tasks improve performance across all datasets; scaling the model, which is easy in our framework, brings in further consistent improvements. Results from models, fine-tuned to individual tasks, are shown in the top portion of the table, multi-task models (a single one per evaluation), are shown in the bottom portion.",
        "table": "<table id=\"S5.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\">Approach</th>\n<td id=\"S5.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Num Models</td>\n<td id=\"S5.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">VQA2.0</td>\n<td id=\"S5.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">NLVR2</td>\n<td id=\"S5.T2.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">SNLI-VE</td>\n<td id=\"S5.T2.1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">GQA</td>\n</tr>\n<tr id=\"S5.T2.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Single-Task (random init)</th>\n<td id=\"S5.T2.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Mult</td>\n<td id=\"S5.T2.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">49.05</td>\n<td id=\"S5.T2.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">53.5</td>\n<td id=\"S5.T2.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">73.1</td>\n<td id=\"S5.T2.1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">68.9</td>\n</tr>\n<tr id=\"S5.T2.1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Single-task, pretrained (PT)</th>\n<td id=\"S5.T2.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Mult</td>\n<td id=\"S5.T2.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">65.2</td>\n<td id=\"S5.T2.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">70.2</td>\n<td id=\"S5.T2.1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">77.72</td>\n<td id=\"S5.T2.1.1.3.3.6\" class=\"ltx_td ltx_align_center\">73.03</td>\n</tr>\n<tr id=\"S5.T2.1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Single-Task, PT, 3x scaled</th>\n<td id=\"S5.T2.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Mult</td>\n<td id=\"S5.T2.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">71.2</td>\n<td id=\"S5.T2.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">72.0</td>\n<td id=\"S5.T2.1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.1.4.4.5.1\" class=\"ltx_text ltx_font_bold\">85.8</span></td>\n<td id=\"S5.T2.1.1.4.4.6\" class=\"ltx_td ltx_align_center\">77.2</td>\n</tr>\n<tr id=\"S5.T2.1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Answer-Me, PT, Zero-shot</th>\n<td id=\"S5.T2.1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Single</td>\n<td id=\"S5.T2.1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">25.3</td>\n<td id=\"S5.T2.1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.5</td>\n<td id=\"S5.T2.1.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">22.7</td>\n<td id=\"S5.T2.1.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\">40.9</td>\n</tr>\n<tr id=\"S5.T2.1.1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Answer-Me, PT, 4 tasks</th>\n<td id=\"S5.T2.1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Single</td>\n<td id=\"S5.T2.1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.8</td>\n<td id=\"S5.T2.1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">71.5</td>\n<td id=\"S5.T2.1.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\">77.2</td>\n<td id=\"S5.T2.1.1.6.6.6\" class=\"ltx_td ltx_align_center\">72.1</td>\n</tr>\n<tr id=\"S5.T2.1.1.7.7\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Answer-Me, PT, 8 tasks</th>\n<td id=\"S5.T2.1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Single</td>\n<td id=\"S5.T2.1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">65.1</td>\n<td id=\"S5.T2.1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r\">71.7</td>\n<td id=\"S5.T2.1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_r\">77.5</td>\n<td id=\"S5.T2.1.1.7.7.6\" class=\"ltx_td ltx_align_center\">72.8</td>\n</tr>\n<tr id=\"S5.T2.1.1.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">Answer-Me, PT, 8 tasks, 3x</th>\n<td id=\"S5.T2.1.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">Single</td>\n<td id=\"S5.T2.1.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.1.8.8.3.1\" class=\"ltx_text ltx_font_bold\">73.6</span></td>\n<td id=\"S5.T2.1.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.1.8.8.4.1\" class=\"ltx_text ltx_font_bold\">73.9</span></td>\n<td id=\"S5.T2.1.1.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.1.8.8.5.1\" class=\"ltx_text ltx_font_bold\">85.8</span></td>\n<td id=\"S5.T2.1.1.8.8.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.1.8.8.6.1\" class=\"ltx_text ltx_font_bold\">77.5</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In this section we test the capabilities of the Answer-Me models and their potential for skill transfer. I.e., we compare how a model performs when a task is included in the training mix vs. a task outside the mix. Table 2 compares Answer-Me trained on single tasks vs. different task mixtures. We observe that the mixtures provide competitive results to single pretrained and fine-tuned (FT) models, and that more tasks in the mixture improve the performance across all datasets. When scaling the model, we see consistent improvements. In Table 3 we compare single-task vs. multi-task training, then evaluating on all 4 different VQA datasets. We see that when fine-tuning on a single task, the model does well on that task, but poorly on the others, but when trained on a mix of all 5 VQA datasets in the table, the model does nearly the same as the single task training. Together, these tables show robustness to forgetting and generalization ability to a variety of question types.",
            "As seen in Table 1, Table 2 and Table 4, there is progressive improvement with adding more tasks in the mixture and scaling the model, here 3X, produces consistently higher accuracies."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Comparing mixture training vs. individual task FT.",
        "table": "<table id=\"S5.T3.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Tasks</th>\n<th id=\"S5.T3.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VQA2.0</th>\n<th id=\"S5.T3.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">NLVR2</th>\n<th id=\"S5.T3.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">SNLI-VE</th>\n<th id=\"S5.T3.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">GQA</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">VQA2.0-only</th>\n<td id=\"S5.T3.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">65.2</span></td>\n<td id=\"S5.T3.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">34.2</td>\n<td id=\"S5.T3.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">24.3</td>\n<td id=\"S5.T3.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">41.3</td>\n</tr>\n<tr id=\"S5.T3.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">NLVR2-only</th>\n<td id=\"S5.T3.1.1.3.2.2\" class=\"ltx_td ltx_align_center\">23.4</td>\n<td id=\"S5.T3.1.1.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\">70.2</span></td>\n<td id=\"S5.T3.1.1.3.2.4\" class=\"ltx_td ltx_align_center\">21.3</td>\n<td id=\"S5.T3.1.1.3.2.5\" class=\"ltx_td ltx_align_center\">36.7</td>\n</tr>\n<tr id=\"S5.T3.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">SNLI-VE-only</th>\n<td id=\"S5.T3.1.1.4.3.2\" class=\"ltx_td ltx_align_center\">24.3</td>\n<td id=\"S5.T3.1.1.4.3.3\" class=\"ltx_td ltx_align_center\">34.6</td>\n<td id=\"S5.T3.1.1.4.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">77.7</span></td>\n<td id=\"S5.T3.1.1.4.3.5\" class=\"ltx_td ltx_align_center\">38.5</td>\n</tr>\n<tr id=\"S5.T3.1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">GQA-only</th>\n<td id=\"S5.T3.1.1.5.4.2\" class=\"ltx_td ltx_align_center\">28.6</td>\n<td id=\"S5.T3.1.1.5.4.3\" class=\"ltx_td ltx_align_center\">33.5</td>\n<td id=\"S5.T3.1.1.5.4.4\" class=\"ltx_td ltx_align_center\">23.4</td>\n<td id=\"S5.T3.1.1.5.4.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\">73.0</span></td>\n</tr>\n<tr id=\"S5.T3.1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">VG-QA-only (ZS)</th>\n<td id=\"S5.T3.1.1.6.5.2\" class=\"ltx_td ltx_align_center\">29.4</td>\n<td id=\"S5.T3.1.1.6.5.3\" class=\"ltx_td ltx_align_center\">33.7</td>\n<td id=\"S5.T3.1.1.6.5.4\" class=\"ltx_td ltx_align_center\">27.5</td>\n<td id=\"S5.T3.1.1.6.5.5\" class=\"ltx_td ltx_align_center\">40.8</td>\n</tr>\n<tr id=\"S5.T3.1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\">5-task mix</th>\n<td id=\"S5.T3.1.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">65.1</td>\n<td id=\"S5.T3.1.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">71.5</td>\n<td id=\"S5.T3.1.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">77.4</td>\n<td id=\"S5.T3.1.1.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">72.8</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In this section we test the capabilities of the Answer-Me models and their potential for skill transfer. I.e., we compare how a model performs when a task is included in the training mix vs. a task outside the mix. Table 2 compares Answer-Me trained on single tasks vs. different task mixtures. We observe that the mixtures provide competitive results to single pretrained and fine-tuned (FT) models, and that more tasks in the mixture improve the performance across all datasets. When scaling the model, we see consistent improvements. In Table 3 we compare single-task vs. multi-task training, then evaluating on all 4 different VQA datasets. We see that when fine-tuning on a single task, the model does well on that task, but poorly on the others, but when trained on a mix of all 5 VQA datasets in the table, the model does nearly the same as the single task training. Together, these tables show robustness to forgetting and generalization ability to a variety of question types."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Experiments comparing to SOTA: specialized models (top section), and multi-task models, including ours (middle large section). Answer-Me largely outperforms other multi-task models despite working in the open-vocabulary generative setting. For reference we include pre-trained and fine-tuned models which are further advantaged by fine-tuning to each individual dataset (bottom section). As seen, Answer-Me still outperforms these on GQA and it even outperforms the Large version of SimVLM model [66] and it is close to its SimVLM-Huge on SNLI-VE. The best results among the pre-trained fine-tuned models are marked in italics.",
        "table": "<table id=\"S5.T4.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">Approach</td>\n<td id=\"S5.T4.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">VQA2.0 (dev)</td>\n<td id=\"S5.T4.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">NLVR2</td>\n<td id=\"S5.T4.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">SNLI-VE</td>\n<td id=\"S5.T4.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">GQA</td>\n</tr>\n<tr id=\"S5.T4.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">DFAF <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib45\" title=\"\" class=\"ltx_ref\">45</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">70.22</td>\n<td id=\"S5.T4.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T4.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T4.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Specialized from  <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">60.1</td>\n<td id=\"S5.T4.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.3.3.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Suhr et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">61</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">53.5</td>\n<td id=\"S5.T4.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.4.4.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Xie et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">69</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">71.56</td>\n<td id=\"S5.T4.1.1.5.5.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Hudson &amp; Manning <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">24</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.6.6.5\" class=\"ltx_td ltx_align_center\">57.5</td>\n</tr>\n<tr id=\"S5.T4.1.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Frozen <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib64\" title=\"\" class=\"ltx_ref\">64</a>]</cite> (VQA+pretraining)</td>\n<td id=\"S5.T4.1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">48.4</td>\n<td id=\"S5.T4.1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T4.1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T4.1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Nguyen et al <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib44\" title=\"\" class=\"ltx_ref\">44</a>]</cite> (VQA2.0+VG)</td>\n<td id=\"S5.T4.1.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">66.35</td>\n<td id=\"S5.T4.1.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T4.1.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T4.1.1.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.9.9\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Multi-task GPV  <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_r\">62.5</td>\n<td id=\"S5.T4.1.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.9.9.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.10.10\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_border_r\">VL-BART <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">10</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">71.3</td>\n<td id=\"S5.T4.1.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">70.3</td>\n<td id=\"S5.T4.1.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.10.10.5\" class=\"ltx_td ltx_align_center\">60.5</td>\n</tr>\n<tr id=\"S5.T4.1.1.11.11\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.11.11.1\" class=\"ltx_td ltx_align_left ltx_border_r\">VL-T5 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">10</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">70.3</td>\n<td id=\"S5.T4.1.1.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">73.6</td>\n<td id=\"S5.T4.1.1.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.11.11.5\" class=\"ltx_td ltx_align_center\">60.8</td>\n</tr>\n<tr id=\"S5.T4.1.1.12.12\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.12.12.1\" class=\"ltx_td ltx_align_left ltx_border_r\">12-in-1 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib41\" title=\"\" class=\"ltx_ref\">41</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.12.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">72.57</td>\n<td id=\"S5.T4.1.1.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.1.12.12.3.1\" class=\"ltx_text ltx_font_bold\">78.4</span></td>\n<td id=\"S5.T4.1.1.12.12.4\" class=\"ltx_td ltx_align_center ltx_border_r\">76.78</td>\n<td id=\"S5.T4.1.1.12.12.5\" class=\"ltx_td ltx_align_center\">60.12</td>\n</tr>\n<tr id=\"S5.T4.1.1.13.13\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.13.13.1\" class=\"ltx_td ltx_align_left ltx_border_r\">UniT (Coco init.) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib21\" title=\"\" class=\"ltx_ref\">21</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.13.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">66.97</td>\n<td id=\"S5.T4.1.1.13.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.13.13.4\" class=\"ltx_td ltx_align_center ltx_border_r\">73.16</td>\n<td id=\"S5.T4.1.1.13.13.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.14.14\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.14.14.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">\n<span id=\"S5.T4.1.1.14.14.1.1\" class=\"ltx_text ltx_font_bold\">Answer-Me</span>, 8 tasks (Ours)</td>\n<td id=\"S5.T4.1.1.14.14.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.1</td>\n<td id=\"S5.T4.1.1.14.14.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">71.7</td>\n<td id=\"S5.T4.1.1.14.14.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">77.5</td>\n<td id=\"S5.T4.1.1.14.14.5\" class=\"ltx_td ltx_align_center ltx_border_t\">72.8</td>\n</tr>\n<tr id=\"S5.T4.1.1.15.15\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.15.15.1\" class=\"ltx_td ltx_align_left ltx_border_r\">\n<span id=\"S5.T4.1.1.15.15.1.1\" class=\"ltx_text ltx_font_bold\">Answer-Me</span>, 8 tasks, 3x scaling (Ours)</td>\n<td id=\"S5.T4.1.1.15.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.1.15.15.2.1\" class=\"ltx_text ltx_font_bold\">73.6</span></td>\n<td id=\"S5.T4.1.1.15.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">73.9</td>\n<td id=\"S5.T4.1.1.15.15.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.1.15.15.4.1\" class=\"ltx_text ltx_font_bold\">85.8</span></td>\n<td id=\"S5.T4.1.1.15.15.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.1.1.15.15.5.1\" class=\"ltx_text ltx_font_bold\">77.5</span></td>\n</tr>\n<tr id=\"S5.T4.1.1.16.16\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.16.16.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">VisualBERT (pretr+FT) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib31\" title=\"\" class=\"ltx_ref\">31</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.16.16.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">67.36</td>\n<td id=\"S5.T4.1.1.16.16.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">66.7</td>\n<td id=\"S5.T4.1.1.16.16.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">75.69</td>\n<td id=\"S5.T4.1.1.16.16.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.17.17\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.17.17.1\" class=\"ltx_td ltx_align_left ltx_border_r\">ViLBERT (pretr+FT) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib40\" title=\"\" class=\"ltx_ref\">40</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.17.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">70.55</td>\n<td id=\"S5.T4.1.1.17.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.17.17.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.17.17.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.18.18\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.18.18.1\" class=\"ltx_td ltx_align_left ltx_border_r\">LXMERT (pretr+FT) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib63\" title=\"\" class=\"ltx_ref\">63</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.18.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">69.9</td>\n<td id=\"S5.T4.1.1.18.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">74.9</td>\n<td id=\"S5.T4.1.1.18.18.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.18.18.5\" class=\"ltx_td ltx_align_center\">60.0</td>\n</tr>\n<tr id=\"S5.T4.1.1.19.19\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.19.19.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Oscar (pretr+FT) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\">32</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.19.19.2\" class=\"ltx_td ltx_align_center ltx_border_r\">73.61</td>\n<td id=\"S5.T4.1.1.19.19.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.19.19.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.19.19.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.20.20\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.20.20.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Uniter (pretr+FT) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">9</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.20.20.2\" class=\"ltx_td ltx_align_center ltx_border_r\">73.82</td>\n<td id=\"S5.T4.1.1.20.20.3\" class=\"ltx_td ltx_align_center ltx_border_r\">79.12</td>\n<td id=\"S5.T4.1.1.20.20.4\" class=\"ltx_td ltx_align_center ltx_border_r\">79.39</td>\n<td id=\"S5.T4.1.1.20.20.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.21.21\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.21.21.1\" class=\"ltx_td ltx_align_left ltx_border_r\">VinVL (pretr+FT) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib78\" title=\"\" class=\"ltx_ref\">78</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.21.21.2\" class=\"ltx_td ltx_align_center ltx_border_r\">75.95</td>\n<td id=\"S5.T4.1.1.21.21.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.1.21.21.3.1\" class=\"ltx_text ltx_font_italic\">82.05</span></td>\n<td id=\"S5.T4.1.1.21.21.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T4.1.1.21.21.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.1.1.21.21.5.1\" class=\"ltx_text ltx_font_italic\">65.05</span></td>\n</tr>\n<tr id=\"S5.T4.1.1.22.22\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.22.22.1\" class=\"ltx_td ltx_align_left ltx_border_r\">SimVLM (Large) (pretr+FT) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">9</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.22.22.2\" class=\"ltx_td ltx_align_center ltx_border_r\">79.32</td>\n<td id=\"S5.T4.1.1.22.22.3\" class=\"ltx_td ltx_align_center ltx_border_r\">84.13</td>\n<td id=\"S5.T4.1.1.22.22.4\" class=\"ltx_td ltx_align_center ltx_border_r\">85.68</td>\n<td id=\"S5.T4.1.1.22.22.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T4.1.1.23.23\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.23.23.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">SimVLM (Huge) (pretr+FT) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">9</a>]</cite>\n</td>\n<td id=\"S5.T4.1.1.23.23.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T4.1.1.23.23.2.1\" class=\"ltx_text ltx_font_italic\">80.03</span></td>\n<td id=\"S5.T4.1.1.23.23.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T4.1.1.23.23.3.1\" class=\"ltx_text ltx_font_italic\">84.53</span></td>\n<td id=\"S5.T4.1.1.23.23.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T4.1.1.23.23.4.1\" class=\"ltx_text ltx_font_italic\">86.21</span></td>\n<td id=\"S5.T4.1.1.23.23.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">-</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In Table 4 we compare to the state-of-the-art (SOTA) results.\nWe compare to other multi-task state-of-the-art methods, such as UniT [21], 12-in-1 [41], GPV [19], and others.",
            "As seen in Table 1, Table 2 and Table 4, there is progressive improvement with adding more tasks in the mixture and scaling the model, here 3X, produces consistently higher accuracies."
        ]
    },
    "S5.T5": {
        "caption": "Table 5:  The pretrained base model trained on the 3 VQA (GQA, VG-QA) mix plus either VQA2.0 or SNLI-VE. This is evaluated on VQA2.0 and SNLI-VE. We further train the model on one of the tasks and repeat the evaluations. The results show that fine tuned models tend to forget (first/second rows), even if original mix shows good within-data and out-of sample generalization (first rows). Additional fine-tuning seems to recover the losses within a task (first/third rows), but costs N𝑁N times the cost in training, and performance on the other task deteriorates again. Interestingly, this model performs even worse than the original out-of-sample mixture on the second task. Training on many tasks in the mix maintains performance (last row).",
        "table": "<table id=\"S5.T5.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">Approach</td>\n<td id=\"S5.T5.3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Num</td>\n<td id=\"S5.T5.3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_tt\">VQA2.0</td>\n<td id=\"S5.T5.3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">SNLI-VE</td>\n</tr>\n<tr id=\"S5.T5.3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">3-task + VQA2.0 (ours)</td>\n<td id=\"S5.T5.3.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Single</td>\n<td id=\"S5.T5.3.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\">64.3</td>\n<td id=\"S5.T5.3.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">33.8</td>\n</tr>\n<tr id=\"S5.T5.3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\">3-task + VQAv, FT on SNLI</td>\n<td id=\"S5.T5.3.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Multiple</td>\n<td id=\"S5.T5.3.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_rr\">35.5</td>\n<td id=\"S5.T5.3.1.3.3.4\" class=\"ltx_td ltx_align_center\">76.9</td>\n</tr>\n<tr id=\"S5.T5.3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_r\">3-task + VQA2.0, FT on VQA2.0 (ours)</td>\n<td id=\"S5.T5.3.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Multiple</td>\n<td id=\"S5.T5.3.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_rr\">65.2</td>\n<td id=\"S5.T5.3.1.4.4.4\" class=\"ltx_td ltx_align_center\">26.7</td>\n</tr>\n<tr id=\"S5.T5.3.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">3-task + SNLI-VE (ours)</td>\n<td id=\"S5.T5.3.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Single</td>\n<td id=\"S5.T5.3.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\">33.2</td>\n<td id=\"S5.T5.3.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">76.5</td>\n</tr>\n<tr id=\"S5.T5.3.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_r\">3-task + SNLI-VE, FT on VQA2.0</td>\n<td id=\"S5.T5.3.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Multiple</td>\n<td id=\"S5.T5.3.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_rr\">64.8</td>\n<td id=\"S5.T5.3.1.6.6.4\" class=\"ltx_td ltx_align_center\">24.5</td>\n</tr>\n<tr id=\"S5.T5.3.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_r\">3-task + SNLI-VE, FT on SNLI (ours)</td>\n<td id=\"S5.T5.3.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Multiple</td>\n<td id=\"S5.T5.3.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_rr\">29.4</td>\n<td id=\"S5.T5.3.1.7.7.4\" class=\"ltx_td ltx_align_center\">77.2</td>\n</tr>\n<tr id=\"S5.T5.3.1.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Multi-task (w/o VQA2.0 or SN) Zero-Shot (ours)</td>\n<td id=\"S5.T5.3.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Single</td>\n<td id=\"S5.T5.3.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\">27.3</td>\n<td id=\"S5.T5.3.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">24.2</td>\n</tr>\n<tr id=\"S5.T5.3.1.9.9\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">5-task (ours)</td>\n<td id=\"S5.T5.3.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">Single</td>\n<td id=\"S5.T5.3.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_rr\">65.1</td>\n<td id=\"S5.T5.3.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">77.4</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "While pretraining and fine-tuning, as is customarily done in previous works, produces accurate models, it tends to overfit to the new data and to immediately forget other datasets or tasks, even when it was previously trained on them. We show that Answer-Me, through the mixture training, is more robust, as it is able to sustain good performance across tasks. In Table 5, we find that when training on one task, then finetuning on a second (as commonly done in previous works), the model does well on the new task, but performs poorly on the first as it ‘forgets’, achieving accuracies close to the zero-shot model; additional fine-tuning on the first task actually makes the performance on the second one even worse than zero-shot. In contrast, when using the mixture training for Answer-Me, the model maintains the single-task performance for both datasets."
        ]
    },
    "S5.T6": {
        "caption": "Table 6: ‘Detection’ task, conveyed by text, where the desired outcome is to list (in text) all objects present in the image. This evaluation is on the MsCoco detection dataset [34]. As seen, Answer-Me mixture of question-answering tasks helps boost this new detection task beyond MsCoco. The Zero-Shot portion does not use MsCoco data for training. The (A) and (B) task mix are different 4-task mixtures; they both have VQA2.0, SNLI-VE, GQA, 4-task(A) has VG-QA, whereas 4-task(B) has VG region descriptions instead, which is clearly much more advantageous.",
        "table": "<table id=\"S5.T6.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T6.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T6.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\">Train Data</th>\n<td id=\"S5.T6.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Recall</td>\n<td id=\"S5.T6.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Precision</td>\n<td id=\"S5.T6.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">F1</td>\n</tr>\n<tr id=\"S5.T6.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T6.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">MsCoco (from scratch)</th>\n<td id=\"S5.T6.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.25</td>\n<td id=\"S5.T6.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.21</td>\n<td id=\"S5.T6.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.22</td>\n</tr>\n<tr id=\"S5.T6.1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T6.1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">MsCoco</th>\n<td id=\"S5.T6.1.1.3.3.2\" class=\"ltx_td ltx_align_center\">0.31</td>\n<td id=\"S5.T6.1.1.3.3.3\" class=\"ltx_td ltx_align_center\">0.24</td>\n<td id=\"S5.T6.1.1.3.3.4\" class=\"ltx_td ltx_align_center\">0.27</td>\n</tr>\n<tr id=\"S5.T6.1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T6.1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">4-task (A) mix + MsCoco</th>\n<td id=\"S5.T6.1.1.4.4.2\" class=\"ltx_td ltx_align_center\">0.34</td>\n<td id=\"S5.T6.1.1.4.4.3\" class=\"ltx_td ltx_align_center\">0.30</td>\n<td id=\"S5.T6.1.1.4.4.4\" class=\"ltx_td ltx_align_center\">0.31</td>\n</tr>\n<tr id=\"S5.T6.1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T6.1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">4-task (B) mix + MsCoco</th>\n<td id=\"S5.T6.1.1.5.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.1.1.5.5.2.1\" class=\"ltx_text ltx_font_bold\">0.55</span></td>\n<td id=\"S5.T6.1.1.5.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.1.1.5.5.3.1\" class=\"ltx_text ltx_font_bold\">0.52</span></td>\n<td id=\"S5.T6.1.1.5.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.1.1.5.5.4.1\" class=\"ltx_text ltx_font_bold\">0.53</span></td>\n</tr>\n<tr id=\"S5.T6.1.1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T6.1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"3\">Zero-shot</th>\n<td id=\"S5.T6.1.1.6.6.2\" class=\"ltx_td ltx_border_t\"></td>\n</tr>\n<tr id=\"S5.T6.1.1.7.7\" class=\"ltx_tr\">\n<th id=\"S5.T6.1.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">pretraining</th>\n<td id=\"S5.T6.1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.03</td>\n<td id=\"S5.T6.1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.02</td>\n<td id=\"S5.T6.1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.02</td>\n</tr>\n<tr id=\"S5.T6.1.1.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T6.1.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">4-task (A) mix</th>\n<td id=\"S5.T6.1.1.8.8.2\" class=\"ltx_td ltx_align_center\">0.06</td>\n<td id=\"S5.T6.1.1.8.8.3\" class=\"ltx_td ltx_align_center\">0.04</td>\n<td id=\"S5.T6.1.1.8.8.4\" class=\"ltx_td ltx_align_center\">0.05</td>\n</tr>\n<tr id=\"S5.T6.1.1.9.9\" class=\"ltx_tr\">\n<th id=\"S5.T6.1.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">4-task (B) mix</th>\n<td id=\"S5.T6.1.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T6.1.1.9.9.2.1\" class=\"ltx_text ltx_font_bold\">0.20</span></td>\n<td id=\"S5.T6.1.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T6.1.1.9.9.3.1\" class=\"ltx_text ltx_font_bold\">0.14</span></td>\n<td id=\"S5.T6.1.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T6.1.1.9.9.4.1\" class=\"ltx_text ltx_font_bold\">0.16</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "We also examine Answer-Me’s ability to ‘detect’ objects through language. This is quite different from the other tasks presented in the paper, and it shows the model’s ability to understand the whole image and many objects present in it, even in a zero-shot setting. The task is to output as text the names of all the objects in the image. If an object appears multiple times, e.g., 3 times, then the model should output the name 3 times. We evaluate this on the standard MsCoco detection dataset [34] and compute the precision, recall and F1subscript𝐹1F_{1} values based on how many output object names match the ground truth objects. This is challenging as it requires localization awareness of the models, but without extra box regression layers and training that are not part of Answer-Me. It is also unique with respect to other question-answering tasks. We here evaluate this task in a zero-shot and full mixture scenarios. Table 6 shows that the Answer-Me model and training is able to do well both in zero-shot and FT settings."
        ]
    },
    "S5.T7": {
        "caption": "Table 7: Study on different tasks for pretraining (individually fine-tuned). Using all four pretraining tasks is best, and outperforms any one of them used alone, in some cases by large margins.",
        "table": "<table id=\"S5.T7.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T7.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T7.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">PT Task</th>\n<th id=\"S5.T7.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VQA2.0</th>\n<th id=\"S5.T7.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">SNLI-VE</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T7.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T7.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Captioning</th>\n<td id=\"S5.T7.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">62.3</td>\n<td id=\"S5.T7.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">75.2</td>\n</tr>\n<tr id=\"S5.T7.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T7.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">CapCompletion</th>\n<td id=\"S5.T7.1.1.3.2.2\" class=\"ltx_td ltx_align_center\">60.1</td>\n<td id=\"S5.T7.1.1.3.2.3\" class=\"ltx_td ltx_align_center\">73.8</td>\n</tr>\n<tr id=\"S5.T7.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T7.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">ITM</th>\n<td id=\"S5.T7.1.1.4.3.2\" class=\"ltx_td ltx_align_center\">54.5</td>\n<td id=\"S5.T7.1.1.4.3.3\" class=\"ltx_td ltx_align_center\">74.2</td>\n</tr>\n<tr id=\"S5.T7.1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T7.1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">MLM</th>\n<td id=\"S5.T7.1.1.5.4.2\" class=\"ltx_td ltx_align_center\">58.3</td>\n<td id=\"S5.T7.1.1.5.4.3\" class=\"ltx_td ltx_align_center\">72.4</td>\n</tr>\n<tr id=\"S5.T7.1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S5.T7.1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">All 4</th>\n<td id=\"S5.T7.1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.1.1.6.5.2.1\" class=\"ltx_text ltx_font_bold\">65.2</span></td>\n<td id=\"S5.T7.1.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.1.1.6.5.3.1\" class=\"ltx_text ltx_font_bold\">77.7</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Taken together, these tasks allow the encoder and decoder to see all, part of, or none of the caption, and experimentally we find this pretraining method results in a stronger model than any individual pretraining task (see Table 7).",
            "Table 7 shows the performance of various tasks for pretraining. We find that using all 4 tasks provides the best model, as it is able to better train all parts of the model, including the decoder which is often ignored in contrastive-style pretraining and the encoder ignored in captioning pretraining. Adding these tasks is simple as they all use the same loss, just slightly different preprocessing."
        ]
    },
    "S5.T8": {
        "caption": "Table 8: Study on different fusion layer types. Both approaches behave similarly but encoder fusion has fewer parameters. The experiment is done with no pretraining, so the numbers are lower.",
        "table": "<table id=\"S5.T8.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T8.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T8.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Fusion Approach</th>\n<th id=\"S5.T8.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VQA2.0</th>\n<th id=\"S5.T8.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">SNLI-VE</th>\n<th id=\"S5.T8.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Num Params</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T8.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T8.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Encoder</th>\n<td id=\"S5.T8.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">49.05</td>\n<td id=\"S5.T8.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">73.1</td>\n<td id=\"S5.T8.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">332M</td>\n</tr>\n<tr id=\"S5.T8.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T8.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">Encoder/Decoder</th>\n<td id=\"S5.T8.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">48.9</td>\n<td id=\"S5.T8.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">73.3</td>\n<td id=\"S5.T8.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">346M</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "We also experiment with an alternative architectural choice for fusion in which a transformer encoder/decoder layer is used instead of concatenation and transformer encoders. In this alternative approach, the queries come from the text input and the key/value comes from the image input.\nTable 8 shows that using the encoder/decoder fusion style has little to no effect on the benchmark metrics but the number of parameters is higher compared to the encoder-only fusion. We therefore opted to use concatenation and transformer encoders for fusion."
        ]
    }
}