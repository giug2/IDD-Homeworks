{
    "id_table_1": {
        "caption": "Table 1:  The number of collected questions and instances in  DynamicQA  ( 3 ) for each fact type. We also report general model behaviour (i.e. percentage of persuaded instances given context), as further described in  5.2 .",
        "table": "S5.T1.1.1",
        "footnotes": [],
        "references": [
            "Language models (LMs) have been useful in a variety of downstream applications from summarization to fact-checking, often relying on the factual knowledge memorized during pre-training and stored in their parameters, known as  parametric knowledge   Yu et al. ( 2024 ) . However, this internal memory is not infallible; it may contain misinformation, biases or simply outdated data, causing LMs to produce factually incorrect output, occasionally termed hallucinations Huang et al. ( 2023 ) . Furthermore, conflicting representations of a fact may exist within training data, given conflicting viewpoints (disputable facts) or temporal changes (temporal facts) (See Figure  1 ). We refer to this superposition of fact representation as the facts  dynamicity . In contrast, a  static  fact has only one possible representation. This can lead to  intra-memory conflicts , which can contribute to LMs uncertainty and instability in factual recall. This intra-memory conflict can be likened to a semantic expression of aleatoric uncertainty, noise inherent in training data  Kendall and Gal ( 2017 ) .",
            "To evaluate the intra-memory conflicts, we present a dataset of 11,378 question-answer pairs featuring facts with varying levels of dynamicity (see Figure  1 ). The dynamicity of a fact is difficult to determine via the pretraining dataset, so we use easily measured proxy scores as a reflection of the property. The question and answer pairs, alongside their proxy scores, are sourced from Wikidata and Wikipedia and have not previously been employed in similar datasets nor for approximating the degree of knowledge conflicts in general. We approximate temporality via the number of edits ( 3.1 ) and disputability via the number of reversions ( 3.2 ). For each question and answer pair, we obtain answer-specific context snippets from Wikipedia, alongside their popularity scores, estimated from Wikipedia page views. For static and temporal facts, we also create counter-memory from these snippets using similar object replacements, to simulate realistic knowledge conflict scenarios.",
            "We estimate the  temporality  of a triplet via the number of edits on Wikidata for the given subject and relation as a proxy. We initialize our dataset from PopularQA  Mallen et al. ( 2023 ) , which is a collection of 14k question-answer pairs sampled from Wikipedia, with a  popularity  score determined by the monthly Wikipedia page views of the subject and object of the triplets. This popularity score is often used as a proxy for the triplets prevalence in the unsearchable pre-training corpora of models  Mallen et al. ( 2023 ); Fierro et al. ( 2024 ) . Given the sampling method, this dataset has a long-tailed distribution, meaning most triplets have very low popularity and low temporality. We identify relevant snippets from the triplets subject current Wikipedia page that also mention the triplets object and use them as context to provide to the LM. We discard 2k pairs where we cannot find the intended object and relation mentioned on the subjects Wikipedia page. To construct counter-memory contexts, we replace the object in context with a replacement token. We identify relevant replacement entities using the most similar entity for the original object as identified using the Wembedder tool  Arup Nielsen ( 2017 ) .  All facts with more than 1 edit are labelled as temporal facts, though they vary in their degree of temporality (with a maximum score of 23 edits). This leaves us with 2495 questions (Table  1 ). We randomly subsample 2500 of the remaining static questions (triplets with 0 edits on Wikidata).",
            "Questions are generated using an LM 2 2 2 https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct ( A.2 ) by providing the context  e l subscript e l e_{l} italic_e start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT  and the corresponding ground-truth answer within the prompt (see Table  5  in the Appendix). After obtaining the question and answer pair with the context, three annotators manually annotated the dataset to ensure its quality. Two annotators annotated each data point, and conflicts were resolved by the third annotator. We obtain a Krippendorfs alpha of 0.44 and provide further details in Appendix  A.3 . For the real-world proxy score of disputability, we count the number of reversions on  ( e l , e l + 1 ) subscript e l subscript e l 1 (e_{l},e_{l+1}) ( italic_e start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT , italic_e start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT ) . As a result, we obtain 694 questions with two possible disputable answers and their corresponding real-world proxy scores (Table  1 ).",
            "In the pretraining stage, LMs learn a conditional distribution to predict the next tokens given a preceding context; in this process, they also obtain world knowledge into their parametric memory  Chang et al. ( 2024 ) . For example, in Figure  1 , given a question (e.g., Who is the father of Queen Elizabeth II?), the conditional probability of the correct answer George IV is expected to be greater than similar objects, owing to the frequent co-occurrence of the subject, object and relation in the training corpus. One important element impacting fact acquisition and recall is the frequency of the fact in the training data. It can be assumed that high frequency (often approximated via fact popularity  Mallen et al. ( 2023 ) ) leads to a greater strength of association between the subject and the object, resulting in greater probability being attributed to the relevant tokens (Figure  1 b). However, as information evolves over time, multiple different representations of a factual triplet may appear in a training corpus; meaning, given a subject and relation, there can exist a superposition of object representations  Shanahan et al. ( 2023 )  depending on the temporal and situational context. Rather than a singular object being assigned a high probability, for such facts, we expect several competing answers in the output distribution (Figure  1 c).",
            "Entropy allows us to measure the amount of information within a distribution and is a common measure for model uncertainty. Both lack of information (Figure  1 a) and competing information (Figure  1 c) can contribute to uncertainty and lead to more uniform output distributions. We propose semantic entropy as an estimator of intra-memory conflict, given its use of high-temperature sampling to elicit diverse answers contained within parametric memory. We validate this measure through the lens of a facts dynamicity (defined in  3 ).",
            "The semantic entropy is then estimated by the entropy between the semantic sets. First, we obtain  p  ( g v | x i ) p conditional subscript g v subscript x i p(g_{v}|x_{i}) italic_p ( italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , the conditional token probabilities output by the model generating the answers in  g v subscript g v g_{v} italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT  given the input  x i subscript x i x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  via Equation  1 .",
            "We posit that the decreased context utilization in the case of highly popular facts  Mallen et al. ( 2023 ); Du et al. ( 2024 )  owes to the greater likelihood attributed to the learned answer in the unconditioned output distribution (given  x i ; q subscript x i q x_{i;q} italic_x start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT ). Therefore, greater effort, either via parameter updates or contextual knowledge, is required to shift this output distribution to match the new answer provided in the context ( a c subscript a c a_{c} italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) in the conditioned instance (given  x i ; q , c subscript x i q c x_{i;q,c} italic_x start_POSTSUBSCRIPT italic_i ; italic_q , italic_c end_POSTSUBSCRIPT , Figure  1 b). This is further exacerbated when there is a superposition of competing answers (Figure  1 c). The amount of effort that must be enacted on the model parameters to output  a c subscript a c a_{c} italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  can be approximated by the loss, which also reflects the LMs perplexity to the output. We also measure the observed magnitude of this shift in output distribution via our novel Coherent Persuasion ( C  P C P CP italic_C italic_P ) score. This score quantifies that actual efficacy of the context in shifting an LMs output distribution.",
            "We identify the difficulty of updating dynamic facts by identifying two model behaviours of interest:  Persuaded  instances are instances where the model is persuaded by the provided context, meaning that  y i ; q = a c subscript y i q subscript a c y_{i;q}\\neq a_{c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  but  y i ; q , c = a c subscript y i q c subscript a c y_{i;q,c}=a_{c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q , italic_c end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT .  Stubborn  instances are instances where the model is impassive to the provided context, meaning  y i ; q = y i ; q , c subscript y i q subscript y i q c y_{i;q}=y_{i;q,c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT = italic_y start_POSTSUBSCRIPT italic_i ; italic_q , italic_c end_POSTSUBSCRIPT  and  y i ; q = a c subscript y i q subscript a c y_{i;q}\\neq a_{c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT . These are exceptional instances of RAG context usage failure. We compare the obtained  C  P C P CP italic_C italic_P  and  S  E S E SE italic_S italic_E  scores across the entire dataset and also highlight the behaviour of the persuaded and stubborn instances ( 6.1 ). To further explain the difficulty of retrieval-guided model updates, we observe the differences in loss ( 6.2 ).",
            "Table  1  shows the percentage of stubborn and persuaded instances and Table  2  shows the performance of our three investigated models across the three partitions of our dataset with and without additional context. Semantic Entropy ( S  E S E SE italic_S italic_E ) reflects the semantic variety of model output, which can indicate internal memory conflict ( 4.2 ). Lower  S  E S E SE italic_S italic_E  can be interpreted as more consistent, and less conflicted, output. On the other hand, our Coherent Persuasion ( C  P C P CP italic_C italic_P ) score quantifies the actual efficacy of the context in shifting an LMs output distribution ( 4.3 ).",
            "In our previous investigations, we see that the semantic entropy of a contextless question is not a meaningful indicator of model persuasion, though we do see stronger relationships for popularity and temporality. Furthermore, dataset partitions with anticipated increase in intra-memory conflict (i.e., temporal and disputable data) show lower persuasion than static facts. Therefore, we assess the strength of each relation to persuasion itself. We show the results of our logistic regression test in Table  3 . Though we do not find a very strong fit to the data, given its volatility ( R 2 = 0.139 superscript R 2 0.139 R^{2}=0.139 italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.139 ), we do find several significant predictors.  The strongest predictor of persuasion is the number of edits of a fact, where it shows an inverse relationship to a facts persuasion . This aligns with the behaviour we have seen in our comparison of temporal and static facts in Table  1 . Furthermore, while object popularity ( o p  o  p subscript o p o p o_{pop} italic_o start_POSTSUBSCRIPT italic_p italic_o italic_p end_POSTSUBSCRIPT ) significantly affects a facts persuasion score (previously shown by  Du et al. ( 2024 ) ) the magnitude of this effect is smaller than that of the number of edits of a fact. These findings typically hold across other models (see Appendix  B ), where we show that  S  E q S subscript E q SE_{q} italic_S italic_E start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  typically shows the weakest relation to model persuasion, and the number of edits to have one of the strongest relationships.  Taken together, we can see that  fact dynamicity, or intra-memory conflict, plays a bigger role in eliciting knowledge conflicts than fact popularity   Mallen et al. ( 2023 ); Du et al. ( 2024 ) . We also find  an inverse effect of intra-memory conflict on an LMs susceptibility to persuasion for a given instance . Facts that change regularly are less likely to be updated with context-retrieval, yet facts that never change are easily persuaded."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  The average accuracy, Semantic Entropy ( S  E S E SE italic_S italic_E ;  4.2 ) and Coherent Persuasion ( C  P C P CP italic_C italic_P ;  4.3 ) score of our models. We bold the best values per column, with and without context. Given the inherent subjectivity of the Disputable facts, we do not show accuracy without context.",
        "table": "S5.T2.3.3",
        "footnotes": [],
        "references": [
            "To evaluate the intra-memory conflicts, we present a dataset of 11,378 question-answer pairs featuring facts with varying levels of dynamicity (see Figure  1 ). The dynamicity of a fact is difficult to determine via the pretraining dataset, so we use easily measured proxy scores as a reflection of the property. The question and answer pairs, alongside their proxy scores, are sourced from Wikidata and Wikipedia and have not previously been employed in similar datasets nor for approximating the degree of knowledge conflicts in general. We approximate temporality via the number of edits ( 3.1 ) and disputability via the number of reversions ( 3.2 ). For each question and answer pair, we obtain answer-specific context snippets from Wikipedia, alongside their popularity scores, estimated from Wikipedia page views. For static and temporal facts, we also create counter-memory from these snippets using similar object replacements, to simulate realistic knowledge conflict scenarios.",
            "Questions are generated using an LM 2 2 2 https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct ( A.2 ) by providing the context  e l subscript e l e_{l} italic_e start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT  and the corresponding ground-truth answer within the prompt (see Table  5  in the Appendix). After obtaining the question and answer pair with the context, three annotators manually annotated the dataset to ensure its quality. Two annotators annotated each data point, and conflicts were resolved by the third annotator. We obtain a Krippendorfs alpha of 0.44 and provide further details in Appendix  A.3 . For the real-world proxy score of disputability, we count the number of reversions on  ( e l , e l + 1 ) subscript e l subscript e l 1 (e_{l},e_{l+1}) ( italic_e start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT , italic_e start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT ) . As a result, we obtain 694 questions with two possible disputable answers and their corresponding real-world proxy scores (Table  1 ).",
            "To evaluate this hypothesis, we expect to see two properties: (1) higher entropy in the output distribution of dynamic facts and (2) greater change in the output distribution to update dynamic facts. To verify (1), we look at the semantic entropy of output distributions ( 4.2 ). To investigate (2), we analyse the amount of effort required to shift the output distribution using both loss and our novel Coherent Persuasion score ( 4.3 ).  Both measures look at semantic changes in LM output, thereby limiting confounds due to syntactic inconsistencies and other issues arising from over-reliance on first-token probabilities  Wang et al. ( 2024 ) .",
            "We use  DynamicQA  to assess the performance of three recent and similarly sized state-of-the-art LMs: Mistral-7B-Instruct-v0.1 (Mistral,  Jiang et al. ( 2023 ) ), Llama-2-7b-chat-hf (Llama-2,  Touvron et al. ( 2023 ) ), and Qwen2-7B-Instruct (Qwen2,  Yang et al. ( 2024 ) ). To minimize the effect of the confounding factors, inferences are done in zero-shot manner, and, to obtain better generation results, instruction-tuned LMs are chosen. To obtain the models parametric knowledge ( y i ; q subscript y i q y_{i;q} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT ), we first query the model for each  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  without any additional context. We then query the model provided two forms of context: one is the unperturbed context  c o subscript c o c_{o} italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT  and the other is the unseen replacement  c c subscript c c c_{c} italic_c start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT . In the case of disputable instances, the choice of  c o subscript c o c_{o} italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT  and  c c subscript c c c_{c} italic_c start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  is arbitrary, as both options are equally likely. For each query, we obtain the accuracy and semantic entropy ( 4.2 ). We calculate the  C  P C P CP italic_C italic_P  score for each  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  across all queries ( 4.3 ). We calculate the accuracy of each model on each fact type as",
            "We identify the difficulty of updating dynamic facts by identifying two model behaviours of interest:  Persuaded  instances are instances where the model is persuaded by the provided context, meaning that  y i ; q = a c subscript y i q subscript a c y_{i;q}\\neq a_{c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  but  y i ; q , c = a c subscript y i q c subscript a c y_{i;q,c}=a_{c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q , italic_c end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT .  Stubborn  instances are instances where the model is impassive to the provided context, meaning  y i ; q = y i ; q , c subscript y i q subscript y i q c y_{i;q}=y_{i;q,c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT = italic_y start_POSTSUBSCRIPT italic_i ; italic_q , italic_c end_POSTSUBSCRIPT  and  y i ; q = a c subscript y i q subscript a c y_{i;q}\\neq a_{c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT . These are exceptional instances of RAG context usage failure. We compare the obtained  C  P C P CP italic_C italic_P  and  S  E S E SE italic_S italic_E  scores across the entire dataset and also highlight the behaviour of the persuaded and stubborn instances ( 6.1 ). To further explain the difficulty of retrieval-guided model updates, we observe the differences in loss ( 6.2 ).",
            "Table  1  shows the percentage of stubborn and persuaded instances and Table  2  shows the performance of our three investigated models across the three partitions of our dataset with and without additional context. Semantic Entropy ( S  E S E SE italic_S italic_E ) reflects the semantic variety of model output, which can indicate internal memory conflict ( 4.2 ). Lower  S  E S E SE italic_S italic_E  can be interpreted as more consistent, and less conflicted, output. On the other hand, our Coherent Persuasion ( C  P C P CP italic_C italic_P ) score quantifies the actual efficacy of the context in shifting an LMs output distribution ( 4.3 ).",
            "To further investigate why dynamic facts show a greater proportion of stubborn instances yet a smaller divergence in output distributions, we look at the loss when we force the target answer ( a c subscript a c a_{c} italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) for the contextless input  x i ; q subscript x i q x_{i;q} italic_x start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT . The loss reflects the likelihood of an output given the models trained parameters. A higher loss, thereby, also indicates greater change required to steer the LM to output the target answer. Thus, we expect higher loss on dynamic facts.  Figure  2  shows the distribution of loss for each partition of the dataset. We construct the input only with the question and calculate the losses for all the tokens in the target answer ( a c subscript a c a_{c} italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ). The losses from the tokens in the target answer are averaged for each question. In Figure  2 , we observe that losses for temporal and disputable questions are greater than the loss for static questions; the significance is confirmed with a Welchs  t t t italic_t -test ( p = 9.2  e  64 p 9.2 e 64 p=9.2e-64 italic_p = 9.2 italic_e - 64 ,  p = 3.4  e  18 p 3.4 e 18 p=3.4e-18 italic_p = 3.4 italic_e - 18 ). Therefore, while static questions show a greater  C  P C P CP italic_C italic_P  score in Table  2 , we find  there is more effort involved in updating the LMs parameters for dynamic facts, which may be unachievable with only additional context .",
            "For a NLI model that is used to determine the semantic similarity score between two generated answers ( 4.2 ), we use a Deberta-large model that is finetuned on the NLI dataset called MNLI  4 4 4 https://huggingface.co/microsoft/deberta-large-mnli . With two generated answers ( a i , k  1 subscript a i k 1 a_{i,k-1} italic_a start_POSTSUBSCRIPT italic_i , italic_k - 1 end_POSTSUBSCRIPT ,  a i , k subscript a i k a_{i,k} italic_a start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT ), an input is constructed as  [ C  L  S ]  a i , k  1  [ S  E  P ]  a i , k  [ S  E  P ] delimited-[] C L S subscript a i k 1 delimited-[] S E P subscript a i k delimited-[] S E P [CLS]a_{i,k-1}[SEP]a_{i,k}[SEP] [ italic_C italic_L italic_S ] italic_a start_POSTSUBSCRIPT italic_i , italic_k - 1 end_POSTSUBSCRIPT [ italic_S italic_E italic_P ] italic_a start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT [ italic_S italic_E italic_P ] . To ensure that A1, A2 entail each other, we perform two forward passes with two different inputs by changing the order of the answer within the input ( [ C  L  S ]  a i , k  1  [ S  E  P ]  a i , k  [ S  E  P ] delimited-[] C L S subscript a i k 1 delimited-[] S E P subscript a i k delimited-[] S E P [CLS]a_{i,k-1}[SEP]a_{i,k}[SEP] [ italic_C italic_L italic_S ] italic_a start_POSTSUBSCRIPT italic_i , italic_k - 1 end_POSTSUBSCRIPT [ italic_S italic_E italic_P ] italic_a start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT [ italic_S italic_E italic_P ] ). They are regarded as semantically similar when both predictions of two inputs are entailment. For the grouping of semantically similar answers, the  k k k italic_k -th generated answer  a i , k subscript a i k a_{i,k} italic_a start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT  from an input  x i subscript x i x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is assigned to the group  g v subscript g v g_{v} italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT  if  a i , k subscript a i k a_{i,k} italic_a start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT  entails other answers within the  g v subscript g v g_{v} italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT . See  Kuhn et al. ( 2023 )  for more details.",
            "For the semantic similarity model used in  3.2 , we use the transformer encoder model 5 5 5 https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2  that is trained in a contrastive manner to distinguish the similarity between two sentences.",
            "Here we present the results for additional models for the analyses in   6 . Figure  4  shows that the analysis on the loss ( 6.2 ) holds the same across the different models. Figures  5  and  6  show that temporality has a consistently negative and relatively strong relationship with the  C  P C P CP italic_C italic_P  score across models. While semantic entropy can also be a relatively strong correlate, it changes sign between models, showing that this relationship is inconsistent; meaning uncertain models may be more or less likely to utilise context. Tables  6  and  7  show that we continually see a strong effect of number of edits as a predictor of persuasion across models."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  The estimated coefficients (  ^ ^  \\hat{\\beta} over^ start_ARG italic_ end_ARG ) and  p p p italic_p -values of the linear model predicting the persuasion score. ( R 2 = 0.1386 superscript R 2 0.1386 R^{2}=0.1386 italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.1386 ).   ^ ^  \\hat{\\beta} over^ start_ARG italic_ end_ARG  values reflect the magnitude of each predictors effect on the dependent variable, the persuasion score, and the  p p p italic_p -value denotes the statistical significance of the effect.",
        "table": "S6.T3.14",
        "footnotes": [],
        "references": [
            "There have been several approaches to quantify or approximate the degree of a knowledge conflict; however, these works only focus on context-memory conflicts.  Pezeshkpour ( 2023 )  focus on the entropy of the LMs probability distribution for an answer; the difference in entropy depending on the presence or absence of additional context indicates the LMs prior knowledge on a certain fact. On the other hand,  Du et al. ( 2024 )  propose a susceptibility and a persuasion score to investigate the LM when the given context contradicts the LMs parametric knowledge, based on the first token probabilities. The susceptibility score of an entity shows how easy it is to shift an LMs probability distribution of an answer regarding an entity. The persuasion score of a context represents how effective the context is at changing an LMs probability distribution of an answer. Given known issues in the reliance on first-token probabilities  Wang et al. ( 2024 ) , we  reformulate this score with consideration of semantic consistency  in  4.3 . Furthermore, given the lack of measures for intra-memory conflict, we  assess semantic entropy  Kuhn et al. ( 2023 )  as an indicator of intra-memory conflict  Gao et al. ( 2024 ) .",
            "To evaluate the intra-memory conflicts, we present a dataset of 11,378 question-answer pairs featuring facts with varying levels of dynamicity (see Figure  1 ). The dynamicity of a fact is difficult to determine via the pretraining dataset, so we use easily measured proxy scores as a reflection of the property. The question and answer pairs, alongside their proxy scores, are sourced from Wikidata and Wikipedia and have not previously been employed in similar datasets nor for approximating the degree of knowledge conflicts in general. We approximate temporality via the number of edits ( 3.1 ) and disputability via the number of reversions ( 3.2 ). For each question and answer pair, we obtain answer-specific context snippets from Wikipedia, alongside their popularity scores, estimated from Wikipedia page views. For static and temporal facts, we also create counter-memory from these snippets using similar object replacements, to simulate realistic knowledge conflict scenarios.",
            "Since a reverted edit does not necessarily imply the disputability of a fact, we apply additional rules to filter out cases of vandalism, paraphrasing, or synonyms. For vandalism, we remove the pair if one of the users involved in that edit did not disclose their identity, for example, anonymous users or if the user ID is an IP address. For the pairs that are synonyms or paraphrasing, we feed them to a semantic similarity model ( A.3 ) and remove the pairs whose similarity scores are bigger than 0.98. The selected pairs of reverted edits and the text snippets they are located in serve correspondingly as answers and contexts in our dataset.",
            "Questions are generated using an LM 2 2 2 https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct ( A.2 ) by providing the context  e l subscript e l e_{l} italic_e start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT  and the corresponding ground-truth answer within the prompt (see Table  5  in the Appendix). After obtaining the question and answer pair with the context, three annotators manually annotated the dataset to ensure its quality. Two annotators annotated each data point, and conflicts were resolved by the third annotator. We obtain a Krippendorfs alpha of 0.44 and provide further details in Appendix  A.3 . For the real-world proxy score of disputability, we count the number of reversions on  ( e l , e l + 1 ) subscript e l subscript e l 1 (e_{l},e_{l+1}) ( italic_e start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT , italic_e start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT ) . As a result, we obtain 694 questions with two possible disputable answers and their corresponding real-world proxy scores (Table  1 ).",
            "To evaluate this hypothesis, we expect to see two properties: (1) higher entropy in the output distribution of dynamic facts and (2) greater change in the output distribution to update dynamic facts. To verify (1), we look at the semantic entropy of output distributions ( 4.2 ). To investigate (2), we analyse the amount of effort required to shift the output distribution using both loss and our novel Coherent Persuasion score ( 4.3 ).  Both measures look at semantic changes in LM output, thereby limiting confounds due to syntactic inconsistencies and other issues arising from over-reliance on first-token probabilities  Wang et al. ( 2024 ) .",
            "Entropy allows us to measure the amount of information within a distribution and is a common measure for model uncertainty. Both lack of information (Figure  1 a) and competing information (Figure  1 c) can contribute to uncertainty and lead to more uniform output distributions. We propose semantic entropy as an estimator of intra-memory conflict, given its use of high-temperature sampling to elicit diverse answers contained within parametric memory. We validate this measure through the lens of a facts dynamicity (defined in  3 ).",
            "To do so, we use  Kuhn et al. ( 2023 ) s approach in our simulated knowledge conflict setting. Given any input  x i subscript x i x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , which contains a universal prompt and a question  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  (and optional context  c i subscript c i c_{i} italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), we generate  K K K italic_K  model outputs  Y = [ y i , 1 , ... , y i , K ] Y subscript y i 1 ... subscript y i K Y=[y_{i,1},\\dots,y_{i,K}] italic_Y = [ italic_y start_POSTSUBSCRIPT italic_i , 1 end_POSTSUBSCRIPT , ... , italic_y start_POSTSUBSCRIPT italic_i , italic_K end_POSTSUBSCRIPT ] . Next, we group the generated answers according to their semantic similarity. The semantic similarity between two sampled answers is calculated using a DeBERTA Natural Language Inference (NLI) model. 3 3 3 https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2  Details about answer generation and semantic grouping can be found in Appendix  A.3 . The grouping according to the semantic similarity results in the  V V V italic_V  groups  G = [ g 1 , g 2 , ... , g v , ... , g V ] G subscript g 1 subscript g 2 ... subscript g v ... subscript g V G=[g_{1},g_{2},\\dots,g_{v},\\dots,g_{V}] italic_G = [ italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT , ... , italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ] , where  1  V  K 1 V K 1\\leq V\\leq K 1  italic_V  italic_K .",
            "We use  DynamicQA  to assess the performance of three recent and similarly sized state-of-the-art LMs: Mistral-7B-Instruct-v0.1 (Mistral,  Jiang et al. ( 2023 ) ), Llama-2-7b-chat-hf (Llama-2,  Touvron et al. ( 2023 ) ), and Qwen2-7B-Instruct (Qwen2,  Yang et al. ( 2024 ) ). To minimize the effect of the confounding factors, inferences are done in zero-shot manner, and, to obtain better generation results, instruction-tuned LMs are chosen. To obtain the models parametric knowledge ( y i ; q subscript y i q y_{i;q} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT ), we first query the model for each  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  without any additional context. We then query the model provided two forms of context: one is the unperturbed context  c o subscript c o c_{o} italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT  and the other is the unseen replacement  c c subscript c c c_{c} italic_c start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT . In the case of disputable instances, the choice of  c o subscript c o c_{o} italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT  and  c c subscript c c c_{c} italic_c start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  is arbitrary, as both options are equally likely. For each query, we obtain the accuracy and semantic entropy ( 4.2 ). We calculate the  C  P C P CP italic_C italic_P  score for each  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  across all queries ( 4.3 ). We calculate the accuracy of each model on each fact type as",
            "To identify factors contributing to persuasion (or RAG context usage success), we look at three characteristics of interest on the temporal dataset: semantic entropy, temporality (the number of edits), and popularity (approximated by pageviews). We analyse the Pearson correlation between these three values and our  C  P C P CP italic_C italic_P  score to identify the strongest correlates of persuasion ( 6.3 ). To further understand the influence of the various potential predictors of an instances persuasion, we implement a logistic regression model on stubborn and persuaded instances. We take as dependent variables the popularity of the subject and object, the number of edits to the fact, and the semantic entropy before and after context is provided ( 6.4 ). We standardise each parameter with a  z z z italic_z -score transformation for interpretable comparison.",
            "Table  1  shows the percentage of stubborn and persuaded instances and Table  2  shows the performance of our three investigated models across the three partitions of our dataset with and without additional context. Semantic Entropy ( S  E S E SE italic_S italic_E ) reflects the semantic variety of model output, which can indicate internal memory conflict ( 4.2 ). Lower  S  E S E SE italic_S italic_E  can be interpreted as more consistent, and less conflicted, output. On the other hand, our Coherent Persuasion ( C  P C P CP italic_C italic_P ) score quantifies the actual efficacy of the context in shifting an LMs output distribution ( 4.3 ).",
            "We now analyse the interaction between the persuasion ( C  P C P CP italic_C italic_P ) and semantic entropy ( S  E S E SE italic_S italic_E ) scores, subject popularity, and object temporality in Figure  3  and highlight the persuaded and stubborn instances. In general, we can see that stubborn instances (orange) have lower  C  P C P CP italic_C italic_P  scores than persuaded (blue) and generic (i.e. all remaining) instances (gray). We do not see a particular correlation between the  C  P C P CP italic_C italic_P  score and  S  E S E SE italic_S italic_E  ( r  ( 2494 ) = 0.003 , p > .05 formulae-sequence r 2494 0.003 p .05 r(2494)=0.003,p>.05 italic_r ( 2494 ) = 0.003 , italic_p > .05 ): meaning,  instances with high initial entropy are not necessarily more likely to be persuaded to match the given context . The distribution of persuaded instances and generic instances are identical, and there is a strong overlap with the distribution of stubborn instances. Therefore, it is difficult to determine if a retrieved context will be used by the model based on semantic entropy.",
            "Furthermore, given the strong differences in the distributions in Figure  3 , we can see that semantic entropy does not indicate epistemic uncertainty (which is approximated by subject popularity) nor aleatoric uncertainty (approximated by temporality) (though semantic entropy was previously used as a measure of aleatoric uncertainty in other work  Gao et al. ( 2024 ) ). This suggests that other factors may contribute to semantic entropy, outside of exclusively intra-memory conflict. While knowledge conflicts are a straightforward way to elicit meaningful semantic inconsistencies, they can come from other effects of model training (i.e., overlaps of objects in model memory space, spurious signals, common word co-occurrences), which may be picked up by the semantic entropy measure in addition to intra-memory conflict.",
            "In our previous investigations, we see that the semantic entropy of a contextless question is not a meaningful indicator of model persuasion, though we do see stronger relationships for popularity and temporality. Furthermore, dataset partitions with anticipated increase in intra-memory conflict (i.e., temporal and disputable data) show lower persuasion than static facts. Therefore, we assess the strength of each relation to persuasion itself. We show the results of our logistic regression test in Table  3 . Though we do not find a very strong fit to the data, given its volatility ( R 2 = 0.139 superscript R 2 0.139 R^{2}=0.139 italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.139 ), we do find several significant predictors.  The strongest predictor of persuasion is the number of edits of a fact, where it shows an inverse relationship to a facts persuasion . This aligns with the behaviour we have seen in our comparison of temporal and static facts in Table  1 . Furthermore, while object popularity ( o p  o  p subscript o p o p o_{pop} italic_o start_POSTSUBSCRIPT italic_p italic_o italic_p end_POSTSUBSCRIPT ) significantly affects a facts persuasion score (previously shown by  Du et al. ( 2024 ) ) the magnitude of this effect is smaller than that of the number of edits of a fact. These findings typically hold across other models (see Appendix  B ), where we show that  S  E q S subscript E q SE_{q} italic_S italic_E start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  typically shows the weakest relation to model persuasion, and the number of edits to have one of the strongest relationships.  Taken together, we can see that  fact dynamicity, or intra-memory conflict, plays a bigger role in eliciting knowledge conflicts than fact popularity   Mallen et al. ( 2023 ); Du et al. ( 2024 ) . We also find  an inverse effect of intra-memory conflict on an LMs susceptibility to persuasion for a given instance . Facts that change regularly are less likely to be updated with context-retrieval, yet facts that never change are easily persuaded.",
            "For the semantic similarity model used in  3.2 , we use the transformer encoder model 5 5 5 https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2  that is trained in a contrastive manner to distinguish the similarity between two sentences."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Example of a prompt according to the presence of the context  c i subscript c i c_{i} italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  in the input. The example here is the question that asks about the producer of the movie Titanic with the answer-specific context which mentions answer (James Cameron) in the context.",
        "table": "A1.T4.3.3",
        "footnotes": [],
        "references": [
            "There have been several approaches to quantify or approximate the degree of a knowledge conflict; however, these works only focus on context-memory conflicts.  Pezeshkpour ( 2023 )  focus on the entropy of the LMs probability distribution for an answer; the difference in entropy depending on the presence or absence of additional context indicates the LMs prior knowledge on a certain fact. On the other hand,  Du et al. ( 2024 )  propose a susceptibility and a persuasion score to investigate the LM when the given context contradicts the LMs parametric knowledge, based on the first token probabilities. The susceptibility score of an entity shows how easy it is to shift an LMs probability distribution of an answer regarding an entity. The persuasion score of a context represents how effective the context is at changing an LMs probability distribution of an answer. Given known issues in the reliance on first-token probabilities  Wang et al. ( 2024 ) , we  reformulate this score with consideration of semantic consistency  in  4.3 . Furthermore, given the lack of measures for intra-memory conflict, we  assess semantic entropy  Kuhn et al. ( 2023 )  as an indicator of intra-memory conflict  Gao et al. ( 2024 ) .",
            "To evaluate this hypothesis, we expect to see two properties: (1) higher entropy in the output distribution of dynamic facts and (2) greater change in the output distribution to update dynamic facts. To verify (1), we look at the semantic entropy of output distributions ( 4.2 ). To investigate (2), we analyse the amount of effort required to shift the output distribution using both loss and our novel Coherent Persuasion score ( 4.3 ).  Both measures look at semantic changes in LM output, thereby limiting confounds due to syntactic inconsistencies and other issues arising from over-reliance on first-token probabilities  Wang et al. ( 2024 ) .",
            "where  W  { R , U } W R U W\\in\\{R,U\\} italic_W  { italic_R , italic_U }  and  p y w subscript p subscript y w p_{y_{w}} italic_p start_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT end_POSTSUBSCRIPT  is the averaged softmax probability distribution of all the tokens in the answer  a w subscript a w a_{w} italic_a start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT . Our final proposed  C  P C P CP italic_C italic_P  score can be acquired by Equation  4 .",
            "We use  DynamicQA  to assess the performance of three recent and similarly sized state-of-the-art LMs: Mistral-7B-Instruct-v0.1 (Mistral,  Jiang et al. ( 2023 ) ), Llama-2-7b-chat-hf (Llama-2,  Touvron et al. ( 2023 ) ), and Qwen2-7B-Instruct (Qwen2,  Yang et al. ( 2024 ) ). To minimize the effect of the confounding factors, inferences are done in zero-shot manner, and, to obtain better generation results, instruction-tuned LMs are chosen. To obtain the models parametric knowledge ( y i ; q subscript y i q y_{i;q} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT ), we first query the model for each  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  without any additional context. We then query the model provided two forms of context: one is the unperturbed context  c o subscript c o c_{o} italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT  and the other is the unseen replacement  c c subscript c c c_{c} italic_c start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT . In the case of disputable instances, the choice of  c o subscript c o c_{o} italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT  and  c c subscript c c c_{c} italic_c start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  is arbitrary, as both options are equally likely. For each query, we obtain the accuracy and semantic entropy ( 4.2 ). We calculate the  C  P C P CP italic_C italic_P  score for each  q i subscript q i q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  across all queries ( 4.3 ). We calculate the accuracy of each model on each fact type as",
            "To identify factors contributing to persuasion (or RAG context usage success), we look at three characteristics of interest on the temporal dataset: semantic entropy, temporality (the number of edits), and popularity (approximated by pageviews). We analyse the Pearson correlation between these three values and our  C  P C P CP italic_C italic_P  score to identify the strongest correlates of persuasion ( 6.3 ). To further understand the influence of the various potential predictors of an instances persuasion, we implement a logistic regression model on stubborn and persuaded instances. We take as dependent variables the popularity of the subject and object, the number of edits to the fact, and the semantic entropy before and after context is provided ( 6.4 ). We standardise each parameter with a  z z z italic_z -score transformation for interpretable comparison.",
            "Table  1  shows the percentage of stubborn and persuaded instances and Table  2  shows the performance of our three investigated models across the three partitions of our dataset with and without additional context. Semantic Entropy ( S  E S E SE italic_S italic_E ) reflects the semantic variety of model output, which can indicate internal memory conflict ( 4.2 ). Lower  S  E S E SE italic_S italic_E  can be interpreted as more consistent, and less conflicted, output. On the other hand, our Coherent Persuasion ( C  P C P CP italic_C italic_P ) score quantifies the actual efficacy of the context in shifting an LMs output distribution ( 4.3 ).",
            "For a NLI model that is used to determine the semantic similarity score between two generated answers ( 4.2 ), we use a Deberta-large model that is finetuned on the NLI dataset called MNLI  4 4 4 https://huggingface.co/microsoft/deberta-large-mnli . With two generated answers ( a i , k  1 subscript a i k 1 a_{i,k-1} italic_a start_POSTSUBSCRIPT italic_i , italic_k - 1 end_POSTSUBSCRIPT ,  a i , k subscript a i k a_{i,k} italic_a start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT ), an input is constructed as  [ C  L  S ]  a i , k  1  [ S  E  P ]  a i , k  [ S  E  P ] delimited-[] C L S subscript a i k 1 delimited-[] S E P subscript a i k delimited-[] S E P [CLS]a_{i,k-1}[SEP]a_{i,k}[SEP] [ italic_C italic_L italic_S ] italic_a start_POSTSUBSCRIPT italic_i , italic_k - 1 end_POSTSUBSCRIPT [ italic_S italic_E italic_P ] italic_a start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT [ italic_S italic_E italic_P ] . To ensure that A1, A2 entail each other, we perform two forward passes with two different inputs by changing the order of the answer within the input ( [ C  L  S ]  a i , k  1  [ S  E  P ]  a i , k  [ S  E  P ] delimited-[] C L S subscript a i k 1 delimited-[] S E P subscript a i k delimited-[] S E P [CLS]a_{i,k-1}[SEP]a_{i,k}[SEP] [ italic_C italic_L italic_S ] italic_a start_POSTSUBSCRIPT italic_i , italic_k - 1 end_POSTSUBSCRIPT [ italic_S italic_E italic_P ] italic_a start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT [ italic_S italic_E italic_P ] ). They are regarded as semantically similar when both predictions of two inputs are entailment. For the grouping of semantically similar answers, the  k k k italic_k -th generated answer  a i , k subscript a i k a_{i,k} italic_a start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT  from an input  x i subscript x i x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is assigned to the group  g v subscript g v g_{v} italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT  if  a i , k subscript a i k a_{i,k} italic_a start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT  entails other answers within the  g v subscript g v g_{v} italic_g start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT . See  Kuhn et al. ( 2023 )  for more details.",
            "Table  4  showcases the prompts used to inference the model. For Mistral, Llama-2, we apply chat template to our input since they were trained with the chat template format. To generate, we follow sampling approach and set the maximum number of generated tokens to 20.",
            "Here we present the results for additional models for the analyses in   6 . Figure  4  shows that the analysis on the loss ( 6.2 ) holds the same across the different models. Figures  5  and  6  show that temporality has a consistently negative and relatively strong relationship with the  C  P C P CP italic_C italic_P  score across models. While semantic entropy can also be a relatively strong correlate, it changes sign between models, showing that this relationship is inconsistent; meaning uncertain models may be more or less likely to utilise context. Tables  6  and  7  show that we continually see a strong effect of number of edits as a predictor of persuasion across models."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Example of a prompt for question generation. The LM is asked to generate the question about KFC. The expected answer of the question is burger\".",
        "table": "A1.T4.2.2.2.2.1",
        "footnotes": [],
        "references": [
            "Questions are generated using an LM 2 2 2 https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct ( A.2 ) by providing the context  e l subscript e l e_{l} italic_e start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT  and the corresponding ground-truth answer within the prompt (see Table  5  in the Appendix). After obtaining the question and answer pair with the context, three annotators manually annotated the dataset to ensure its quality. Two annotators annotated each data point, and conflicts were resolved by the third annotator. We obtain a Krippendorfs alpha of 0.44 and provide further details in Appendix  A.3 . For the real-world proxy score of disputability, we count the number of reversions on  ( e l , e l + 1 ) subscript e l subscript e l 1 (e_{l},e_{l+1}) ( italic_e start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT , italic_e start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT ) . As a result, we obtain 694 questions with two possible disputable answers and their corresponding real-world proxy scores (Table  1 ).",
            "For automatic generation of the questions for disputable facts, we feed the context and answer to the Meta-Llama-3-8B-Instruct model with the prompt that contains the example of the expected behaviour. The prompt used for the question generation is presented in Table  5 .  During the generation, the hyperparameter top_p is set to 0.9 and the temperature is 0.6. We remove the question if the generated question contains the intended answer.",
            "Here we present the results for additional models for the analyses in   6 . Figure  4  shows that the analysis on the loss ( 6.2 ) holds the same across the different models. Figures  5  and  6  show that temporality has a consistently negative and relatively strong relationship with the  C  P C P CP italic_C italic_P  score across models. While semantic entropy can also be a relatively strong correlate, it changes sign between models, showing that this relationship is inconsistent; meaning uncertain models may be more or less likely to utilise context. Tables  6  and  7  show that we continually see a strong effect of number of edits as a predictor of persuasion across models."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Results of the Logistic Regression model on Mistral Temporal Results. ( R 2 = 0.116 superscript R 2 0.116 R^{2}=0.116 italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.116 )",
        "table": "A1.T4.3.3.3.2.1",
        "footnotes": [],
        "references": [
            "We identify the difficulty of updating dynamic facts by identifying two model behaviours of interest:  Persuaded  instances are instances where the model is persuaded by the provided context, meaning that  y i ; q = a c subscript y i q subscript a c y_{i;q}\\neq a_{c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  but  y i ; q , c = a c subscript y i q c subscript a c y_{i;q,c}=a_{c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q , italic_c end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT .  Stubborn  instances are instances where the model is impassive to the provided context, meaning  y i ; q = y i ; q , c subscript y i q subscript y i q c y_{i;q}=y_{i;q,c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT = italic_y start_POSTSUBSCRIPT italic_i ; italic_q , italic_c end_POSTSUBSCRIPT  and  y i ; q = a c subscript y i q subscript a c y_{i;q}\\neq a_{c} italic_y start_POSTSUBSCRIPT italic_i ; italic_q end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT . These are exceptional instances of RAG context usage failure. We compare the obtained  C  P C P CP italic_C italic_P  and  S  E S E SE italic_S italic_E  scores across the entire dataset and also highlight the behaviour of the persuaded and stubborn instances ( 6.1 ). To further explain the difficulty of retrieval-guided model updates, we observe the differences in loss ( 6.2 ).",
            "To identify factors contributing to persuasion (or RAG context usage success), we look at three characteristics of interest on the temporal dataset: semantic entropy, temporality (the number of edits), and popularity (approximated by pageviews). We analyse the Pearson correlation between these three values and our  C  P C P CP italic_C italic_P  score to identify the strongest correlates of persuasion ( 6.3 ). To further understand the influence of the various potential predictors of an instances persuasion, we implement a logistic regression model on stubborn and persuaded instances. We take as dependent variables the popularity of the subject and object, the number of edits to the fact, and the semantic entropy before and after context is provided ( 6.4 ). We standardise each parameter with a  z z z italic_z -score transformation for interpretable comparison.",
            "Here we present the results for additional models for the analyses in   6 . Figure  4  shows that the analysis on the loss ( 6.2 ) holds the same across the different models. Figures  5  and  6  show that temporality has a consistently negative and relatively strong relationship with the  C  P C P CP italic_C italic_P  score across models. While semantic entropy can also be a relatively strong correlate, it changes sign between models, showing that this relationship is inconsistent; meaning uncertain models may be more or less likely to utilise context. Tables  6  and  7  show that we continually see a strong effect of number of edits as a predictor of persuasion across models."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Results of the Logistic Regression model on Qwen2 Temporal Results. ( R 2 = 0.197 superscript R 2 0.197 R^{2}=0.197 italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.197 )",
        "table": "A1.T5.1.1",
        "footnotes": [],
        "references": [
            "Here we present the results for additional models for the analyses in   6 . Figure  4  shows that the analysis on the loss ( 6.2 ) holds the same across the different models. Figures  5  and  6  show that temporality has a consistently negative and relatively strong relationship with the  C  P C P CP italic_C italic_P  score across models. While semantic entropy can also be a relatively strong correlate, it changes sign between models, showing that this relationship is inconsistent; meaning uncertain models may be more or less likely to utilise context. Tables  6  and  7  show that we continually see a strong effect of number of edits as a predictor of persuasion across models."
        ]
    },
    "id_table_8": {
        "caption": "",
        "table": "A2.T6.13",
        "footnotes": [],
        "references": []
    },
    "id_table_9": {
        "caption": "",
        "table": "A2.T7.14",
        "footnotes": [],
        "references": []
    },
    "global_footnotes": [
        "Equal contribution. Corresponding authors."
    ]
}