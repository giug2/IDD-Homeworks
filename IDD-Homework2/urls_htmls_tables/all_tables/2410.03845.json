{
    "id_table_1": {
        "caption": "TABLE I:  Distribution of GitHub Issues and Discussions by Category",
        "table": "S2.T1.1",
        "footnotes": [],
        "references": [
            "As illustrated in Figure  1 , the retriever function searches its input knowledge base to identify document chunks most relevant to a given query. It employs multiple vector search techniques, including similarity search and maximal marginal relevance (MMR) search. In similarity search, chunks with the highest cosine similarity to the input are selected, while MMR search introduces diversity by minimizing redundancy in the retrieved chunks. Additionally, a classical text-based search is performed on the BM25 index to retrieve documents containing the exact keywords specified in the query. A re-ranking model then processes these search results, adjusting the document ranking to provide a top- k k k italic_k  selection of the most relevant documents, ensuring both precision and diversity in the final output."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Evaluation Metrics for Model Answers",
        "table": "S5.T2.1.1",
        "footnotes": [],
        "references": [
            "ORAssistants knowledge base encompasses a wide range of information from various applications in the OpenROAD flow. Subsets of this knowledge base relevant to specific applications are provided to the hybrid retriever function to form domain specific retriever tools, as listed in Figure  2 . A custom prompt guides the base LLM in selecting the appropriate retriever tools for each query. For instance, the  OR Commands  tool retrieves information specific to the OpenROAD frameworks commands, while the  Installation  tool focuses on documentation related to installation procedures. In contrast to using a single retriever function on a pooled knowledge base, the modular approach significantly reduces the chances of incorrect document retrieval. Additionally, the architecture allows for future integration with other open-source tools and flow runners within the OpenROAD ecosystem.",
            "The tool-based RAG architecture ensures that responses are context-correct by leveraging both the conversation history and domain-specific knowledge sources. These sources enable the system to provide responses with precise citations and hyperlinks for each query. Figure  2  depicts the tool-based RAG system operating in two distinct stages:"
        ]
    },
    "id_table_3": {
        "caption": "TABLE III:  Evaluation Results on EDA Corpus (100 Questions) and Human Eval (50 Questions) Datasets.",
        "table": "S5.T3.1.1",
        "footnotes": [],
        "references": [
            "ORAssistant can be accessed on a  Next.js [ 22 ]  based web front-end [ 7 ] . The hosted version uses Gemini 1.5 Flash  [ 23 ]  as its base LLM alongside the  text-embedding-004 [ 24 ]  model for generating vector embeddings. The web application supports the creation of multiple conversation threads, each retaining its own history. This allows users to switch between threads while keeping each discussion focused and relevant to specific topics. Figure  3  shows an ORAssistant-generated, composite response for a user query about floorplan creation options in OpenROAD-flow-scripts."
        ]
    },
    "global_footnotes": [
        "Palaniappan R and Aviral Kaintura contributed equally to this project under the mentorship of Indira Iyer and Jack Luar."
    ]
}