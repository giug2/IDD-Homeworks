{
    "PAPER'S NUMBER OF TABLES": 3,
    "S3.T1": {
        "caption": "Table 1: F1subscriptùêπ1F_{1}-scores (%) obtained by FedAvg and MOON algorithms with different architectures under DS1 and DS2.",
        "table": "<table id=\"S3.T1.6\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.6.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.6.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 13.0pt;\">Algorithms</td>\n<td id=\"S3.T1.6.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 13.0pt;\">Architectures</td>\n<td id=\"S3.T1.6.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 13.0pt;\">DS1</td>\n<td id=\"S3.T1.6.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 13.0pt;\">DS2</td>\n</tr>\n<tr id=\"S3.T1.6.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.6.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:0.5pt 13.0pt;\" rowspan=\"4\"><span id=\"S3.T1.6.2.2.1.1\" class=\"ltx_text\"><span id=\"S3.T1.6.2.2.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.T1.6.2.2.1.1.2\" class=\"ltx_text\">\n<span id=\"S3.T1.6.2.2.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S3.T1.6.2.2.1.1.2.1.1\" class=\"ltx_tr\">\n<span id=\"S3.T1.6.2.2.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\" style=\"padding:0.5pt 13.0pt;\"><span id=\"S3.T1.6.2.2.1.1.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">FedAvg </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S3.T1.6.2.2.1.1.2.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">[</span><a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a><span id=\"S3.T1.6.2.2.1.1.2.1.1.1.3.2\" class=\"ltx_text\" style=\"font-size:80%;\">]</span></cite></span></span>\n</span></span> <span id=\"S3.T1.6.2.2.1.1.3\" class=\"ltx_text\"></span></span></th>\n<td id=\"S3.T1.6.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 13.0pt;\">ResNet-50</td>\n<td id=\"S3.T1.6.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 13.0pt;\">75.24</td>\n<td id=\"S3.T1.6.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 13.0pt;\">47.32</td>\n</tr>\n<tr id=\"S3.T1.6.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.6.3.3.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.5pt 13.0pt;\">MLP-Mixer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite>\n</td>\n<td id=\"S3.T1.6.3.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 13.0pt;\">73.87</td>\n<td id=\"S3.T1.6.3.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 13.0pt;\">59.79</td>\n</tr>\n<tr id=\"S3.T1.6.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.6.4.4.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.5pt 13.0pt;\">ConvMixer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>\n</td>\n<td id=\"S3.T1.6.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 13.0pt;\">72.47</td>\n<td id=\"S3.T1.6.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 13.0pt;\">53.66</td>\n</tr>\n<tr id=\"S3.T1.6.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.6.5.5.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.5pt 13.0pt;\">PoolFormer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">24</a>]</cite>\n</td>\n<td id=\"S3.T1.6.5.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 13.0pt;\">74.09</td>\n<td id=\"S3.T1.6.5.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 13.0pt;\">59.85</td>\n</tr>\n<tr id=\"S3.T1.6.6.6\" class=\"ltx_tr\">\n<th id=\"S3.T1.6.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_b ltx_border_t\" style=\"padding:0.5pt 13.0pt;\" rowspan=\"4\"><span id=\"S3.T1.6.6.6.1.1\" class=\"ltx_text\"><span id=\"S3.T1.6.6.6.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.T1.6.6.6.1.1.2\" class=\"ltx_text\">\n<span id=\"S3.T1.6.6.6.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S3.T1.6.6.6.1.1.2.1.1\" class=\"ltx_tr\">\n<span id=\"S3.T1.6.6.6.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\" style=\"padding:0.5pt 13.0pt;\"><span id=\"S3.T1.6.6.6.1.1.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">MOON </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S3.T1.6.6.6.1.1.2.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">[</span><a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a><span id=\"S3.T1.6.6.6.1.1.2.1.1.1.3.2\" class=\"ltx_text\" style=\"font-size:80%;\">]</span></cite></span></span>\n</span></span> <span id=\"S3.T1.6.6.6.1.1.3\" class=\"ltx_text\"></span></span></th>\n<td id=\"S3.T1.6.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 13.0pt;\">ResNet-50</td>\n<td id=\"S3.T1.6.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 13.0pt;\">72.82</td>\n<td id=\"S3.T1.6.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 13.0pt;\">54.83</td>\n</tr>\n<tr id=\"S3.T1.6.7.7\" class=\"ltx_tr\">\n<td id=\"S3.T1.6.7.7.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.5pt 13.0pt;\">MLP-Mixer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite>\n</td>\n<td id=\"S3.T1.6.7.7.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 13.0pt;\">74.83</td>\n<td id=\"S3.T1.6.7.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 13.0pt;\">60.05</td>\n</tr>\n<tr id=\"S3.T1.6.8.8\" class=\"ltx_tr\">\n<td id=\"S3.T1.6.8.8.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.5pt 13.0pt;\">ConvMixer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>\n</td>\n<td id=\"S3.T1.6.8.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 13.0pt;\">73.28</td>\n<td id=\"S3.T1.6.8.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 13.0pt;\">58.76</td>\n</tr>\n<tr id=\"S3.T1.6.9.9\" class=\"ltx_tr\">\n<td id=\"S3.T1.6.9.9.1\" class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding:0.5pt 13.0pt;\">PoolFormer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">24</a>]</cite>\n</td>\n<td id=\"S3.T1.6.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 13.0pt;\">74.47</td>\n<td id=\"S3.T1.6.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 13.0pt;\">60.26</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Since the images are randomly distributed to the clients in DS1, the level of non-IID in DS1 is lower than that of DS2. We have compared the results of MLP-Mixer [22], ConvMixer [23] and PoolFormer [24] architectures with those of the ResNet-50 in the context of FedAvg [25] and MOON [5] algorithms for RS MLC. The models were trained for 30 communication rounds and three epochs using Adam optimizer with the learning rate of 0.001, mini-batch size of 128. We compare the performance of architectures in terms of MLC accuracy (in F1subscriptùêπ1F_{1}-Score), local training complexity, and aggregation complexity. Table 1 shows the F1subscriptùêπ1F_{1}-scores (%) under both scenarios. One can see from the table that the results under DS1 are higher than those under DS2. This is due to the fact that the level of training data heterogeneity of DS1 is lower than that of DS2. According to the results obtained using FedAvg algorithm, the highest accuracy was obtained by ResNet-50, which is 2.77% higher than that obtained by the worst performing architecture (i.e., ConvMixer) under DS1. In detail, the results obtained with MLP-Mixer and PoolFormer architectures are similar to each other and higher than those of ConvMixer by almost 1.5%. Unlike the results obtained under DS1, the lowest accuracy was obtained with ResNet-50 under DS2. This indicates that the transformer architectures more effectively handle the challenges of training data heterogeneity and increase the accuracy of the global model. The highest accuracy was achieved with PoolFormer under DS2, which is 12.53% higher than the results obtained with ResNet-50. According to the results obtained using MOON algorithm, the F1subscriptùêπ1F_{1}-scores obtained under DS2 are higher than those obtained with FedAvg due to the capability of the MOON algorithm to address the limitations of training data heterogeneity. However, this increase is less prominent with transformer architectures. As an example, although MOON algorithm outperforms FedAvg algorithm by 7.51% higher F1subscriptùêπ1F_{1}-score with Resnet-50, MOON algorithm does not significantly increase the F1subscriptùêπ1F_{1}-score with PoolFormer. This shows that the transformer architectures already alleviate the effects of training data heterogeneity. Therefore, it is feasible to achieve high F1subscriptùêπ1F_{1}-score without employing an FL method that specifically tackles non-IID data."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Computational times (in seconds) and number of parameters shared by each client with different architectures obtained by FedAvg and MOON algorithms.",
        "table": "<table id=\"S3.T2.4\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.4.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 7.5pt;\">Algorithms</td>\n<td id=\"S3.T2.4.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 7.5pt;\">Architectures</td>\n<th id=\"S3.T2.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:0.5pt 7.5pt;\">\n<span id=\"S3.T2.4.1.1.3.1\" class=\"ltx_text\"></span> <span id=\"S3.T2.4.1.1.3.2\" class=\"ltx_text\">\n<span id=\"S3.T2.4.1.1.3.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S3.T2.4.1.1.3.2.1.1\" class=\"ltx_tr\">\n<span id=\"S3.T2.4.1.1.3.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 7.5pt;\"><span id=\"S3.T2.4.1.1.3.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Computational</span></span></span>\n<span id=\"S3.T2.4.1.1.3.2.1.2\" class=\"ltx_tr\">\n<span id=\"S3.T2.4.1.1.3.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 7.5pt;\"><span id=\"S3.T2.4.1.1.3.2.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Time</span></span></span>\n</span></span><span id=\"S3.T2.4.1.1.3.3\" class=\"ltx_text\"></span>\n</th>\n<th id=\"S3.T2.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:0.5pt 7.5pt;\">\n<span id=\"S3.T2.4.1.1.4.1\" class=\"ltx_text\"></span> <span id=\"S3.T2.4.1.1.4.2\" class=\"ltx_text\">\n<span id=\"S3.T2.4.1.1.4.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S3.T2.4.1.1.4.2.1.1\" class=\"ltx_tr\">\n<span id=\"S3.T2.4.1.1.4.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 7.5pt;\"><span id=\"S3.T2.4.1.1.4.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Number of</span></span></span>\n<span id=\"S3.T2.4.1.1.4.2.1.2\" class=\"ltx_tr\">\n<span id=\"S3.T2.4.1.1.4.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 7.5pt;\"><span id=\"S3.T2.4.1.1.4.2.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Shared</span></span></span>\n<span id=\"S3.T2.4.1.1.4.2.1.3\" class=\"ltx_tr\">\n<span id=\"S3.T2.4.1.1.4.2.1.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 7.5pt;\"><span id=\"S3.T2.4.1.1.4.2.1.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Parameters</span></span></span>\n</span></span><span id=\"S3.T2.4.1.1.4.3\" class=\"ltx_text\"></span>\n</th>\n</tr>\n<tr id=\"S3.T2.4.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.4.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:0.5pt 7.5pt;\" rowspan=\"4\"><span id=\"S3.T2.4.2.2.1.1\" class=\"ltx_text\"><span id=\"S3.T2.4.2.2.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.T2.4.2.2.1.1.2\" class=\"ltx_text\">\n<span id=\"S3.T2.4.2.2.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S3.T2.4.2.2.1.1.2.1.1\" class=\"ltx_tr\">\n<span id=\"S3.T2.4.2.2.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\" style=\"padding:0.5pt 7.5pt;\"><span id=\"S3.T2.4.2.2.1.1.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">FedAvg </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S3.T2.4.2.2.1.1.2.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">[</span><a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a><span id=\"S3.T2.4.2.2.1.1.2.1.1.1.3.2\" class=\"ltx_text\" style=\"font-size:80%;\">]</span></cite></span></span>\n</span></span> <span id=\"S3.T2.4.2.2.1.1.3\" class=\"ltx_text\"></span></span></th>\n<td id=\"S3.T2.4.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 7.5pt;\">ResNet-50</td>\n<td id=\"S3.T2.4.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 7.5pt;\">767</td>\n<td id=\"S3.T2.4.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 7.5pt;\">23.60M</td>\n</tr>\n<tr id=\"S3.T2.4.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.4.3.3.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.5pt 7.5pt;\">MLP-Mixer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite>\n</td>\n<td id=\"S3.T2.4.3.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 7.5pt;\">1092</td>\n<td id=\"S3.T2.4.3.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 7.5pt;\">18.34M</td>\n</tr>\n<tr id=\"S3.T2.4.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.4.4.4.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.5pt 7.5pt;\">ConvMixer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>\n</td>\n<td id=\"S3.T2.4.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 7.5pt;\">2432</td>\n<td id=\"S3.T2.4.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 7.5pt;\">20.62M</td>\n</tr>\n<tr id=\"S3.T2.4.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.4.5.5.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.5pt 7.5pt;\">PoolFormer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">24</a>]</cite>\n</td>\n<td id=\"S3.T2.4.5.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 7.5pt;\">1231</td>\n<td id=\"S3.T2.4.5.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 7.5pt;\">11.24M</td>\n</tr>\n<tr id=\"S3.T2.4.6.6\" class=\"ltx_tr\">\n<th id=\"S3.T2.4.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_b ltx_border_t\" style=\"padding:0.5pt 7.5pt;\" rowspan=\"4\"><span id=\"S3.T2.4.6.6.1.1\" class=\"ltx_text\"><span id=\"S3.T2.4.6.6.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.T2.4.6.6.1.1.2\" class=\"ltx_text\">\n<span id=\"S3.T2.4.6.6.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S3.T2.4.6.6.1.1.2.1.1\" class=\"ltx_tr\">\n<span id=\"S3.T2.4.6.6.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\" style=\"padding:0.5pt 7.5pt;\"><span id=\"S3.T2.4.6.6.1.1.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">MOON </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S3.T2.4.6.6.1.1.2.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">[</span><a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a><span id=\"S3.T2.4.6.6.1.1.2.1.1.1.3.2\" class=\"ltx_text\" style=\"font-size:80%;\">]</span></cite></span></span>\n</span></span> <span id=\"S3.T2.4.6.6.1.1.3\" class=\"ltx_text\"></span></span></th>\n<td id=\"S3.T2.4.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 7.5pt;\">ResNet-50</td>\n<td id=\"S3.T2.4.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 7.5pt;\">972</td>\n<td id=\"S3.T2.4.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 7.5pt;\">23.60M</td>\n</tr>\n<tr id=\"S3.T2.4.7.7\" class=\"ltx_tr\">\n<td id=\"S3.T2.4.7.7.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.5pt 7.5pt;\">MLP-Mixer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite>\n</td>\n<td id=\"S3.T2.4.7.7.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 7.5pt;\">1323</td>\n<td id=\"S3.T2.4.7.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 7.5pt;\">18.34M</td>\n</tr>\n<tr id=\"S3.T2.4.8.8\" class=\"ltx_tr\">\n<td id=\"S3.T2.4.8.8.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.5pt 7.5pt;\">ConvMixer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>\n</td>\n<td id=\"S3.T2.4.8.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 7.5pt;\">2683</td>\n<td id=\"S3.T2.4.8.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding:0.5pt 7.5pt;\">20.62M</td>\n</tr>\n<tr id=\"S3.T2.4.9.9\" class=\"ltx_tr\">\n<td id=\"S3.T2.4.9.9.1\" class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding:0.5pt 7.5pt;\">PoolFormer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">24</a>]</cite>\n</td>\n<td id=\"S3.T2.4.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 7.5pt;\">1447</td>\n<td id=\"S3.T2.4.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:0.5pt 7.5pt;\">11.24M</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We also assess the effectiveness of the architectures in terms of local training complexity and aggregation complexity. Table 2 shows the computational times (in seconds) to complete a single communication round of local training. By analyzing the table, one can see that the computational time of MOON algorithm is higher than that of FedAvg algorithm for all selected architectures. This is because of the fact that the MOON algorithm requires extra forward passes to extract image feature vectors. One can observe from the table that the computational time required with ResNet-50 is the lowest. The local training complexity of MLP-Mixer and PoolFormer are similar and lower than that of ConvMixer. Table 2 shows the number of model parameters shared by clients. According to the results, PoolFormer is the most efficient architecture among all the selected architectures in terms of aggregation complexity. As an example, the number of parameters of a model that is trained by PoolFormer is less than that of other selected architectures."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Comparison of the selected architectures. Three marks ‚ÄùH‚Äù (High), ‚ÄùM‚Äù (Medium), or ‚ÄúL‚Äù (Low) are given for the considered criteria.",
        "table": "<table id=\"S4.T3.4\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.4.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">Architectures</td>\n<td id=\"S4.T3.4.1.1.2\" class=\"ltx_td ltx_border_t\" style=\"padding:0.5pt 5.3pt;\"></td>\n<th id=\"S4.T3.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">\n<span id=\"S4.T3.4.1.1.3.1\" class=\"ltx_text\"></span> <span id=\"S4.T3.4.1.1.3.2\" class=\"ltx_text\">\n<span id=\"S4.T3.4.1.1.3.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.T3.4.1.1.3.2.1.1\" class=\"ltx_tr\">\n<span id=\"S4.T3.4.1.1.3.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 5.3pt;\"><span id=\"S4.T3.4.1.1.3.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Accuracy</span></span></span>\n</span></span><span id=\"S4.T3.4.1.1.3.3\" class=\"ltx_text\"></span>\n</th>\n<th id=\"S4.T3.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">\n<span id=\"S4.T3.4.1.1.4.1\" class=\"ltx_text\"></span> <span id=\"S4.T3.4.1.1.4.2\" class=\"ltx_text\">\n<span id=\"S4.T3.4.1.1.4.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.T3.4.1.1.4.2.1.1\" class=\"ltx_tr\">\n<span id=\"S4.T3.4.1.1.4.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 5.3pt;\"><span id=\"S4.T3.4.1.1.4.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Local Training</span></span></span>\n<span id=\"S4.T3.4.1.1.4.2.1.2\" class=\"ltx_tr\">\n<span id=\"S4.T3.4.1.1.4.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 5.3pt;\"><span id=\"S4.T3.4.1.1.4.2.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Complexity</span></span></span>\n</span></span><span id=\"S4.T3.4.1.1.4.3\" class=\"ltx_text\"></span>\n</th>\n<th id=\"S4.T3.4.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">\n<span id=\"S4.T3.4.1.1.5.1\" class=\"ltx_text\"></span> <span id=\"S4.T3.4.1.1.5.2\" class=\"ltx_text\">\n<span id=\"S4.T3.4.1.1.5.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.T3.4.1.1.5.2.1.1\" class=\"ltx_tr\">\n<span id=\"S4.T3.4.1.1.5.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 5.3pt;\"><span id=\"S4.T3.4.1.1.5.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Aggregation</span></span></span>\n<span id=\"S4.T3.4.1.1.5.2.1.2\" class=\"ltx_tr\">\n<span id=\"S4.T3.4.1.1.5.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 5.3pt;\"><span id=\"S4.T3.4.1.1.5.2.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Complexity</span></span></span>\n</span></span><span id=\"S4.T3.4.1.1.5.3\" class=\"ltx_text\"></span>\n</th>\n</tr>\n<tr id=\"S4.T3.4.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">ResNet-50</td>\n<td id=\"S4.T3.4.2.2.2\" class=\"ltx_td ltx_border_t\" style=\"padding:0.5pt 5.3pt;\"></td>\n<td id=\"S4.T3.4.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">L</td>\n<td id=\"S4.T3.4.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">L</td>\n<td id=\"S4.T3.4.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">H</td>\n</tr>\n<tr id=\"S4.T3.4.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">MLP-Mixer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite>\n</td>\n<td id=\"S4.T3.4.3.3.2\" class=\"ltx_td ltx_border_t\" style=\"padding:0.5pt 5.3pt;\"></td>\n<td id=\"S4.T3.4.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">H</td>\n<td id=\"S4.T3.4.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">M</td>\n<td id=\"S4.T3.4.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">H</td>\n</tr>\n<tr id=\"S4.T3.4.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">ConvMixer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>\n</td>\n<td id=\"S4.T3.4.4.4.2\" class=\"ltx_td ltx_border_t\" style=\"padding:0.5pt 5.3pt;\"></td>\n<td id=\"S4.T3.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">M</td>\n<td id=\"S4.T3.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">H</td>\n<td id=\"S4.T3.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">H</td>\n</tr>\n<tr id=\"S4.T3.4.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">PoolFormer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">24</a>]</cite>\n</td>\n<td id=\"S4.T3.4.5.5.2\" class=\"ltx_td ltx_border_b ltx_border_t\" style=\"padding:0.5pt 5.3pt;\"></td>\n<td id=\"S4.T3.4.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">H</td>\n<td id=\"S4.T3.4.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">M</td>\n<td id=\"S4.T3.4.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding:0.5pt 5.3pt;\">L</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "This paper analyzes and compares different transformer-based architectures (MLP-Mixer, ConvMixer, PoolFormer) under different non-IID levels in the framework of FL for MLC problems in RS. The selected architectures have been compared in term of their: 1) robustness to training data heterogeneity; 2) local training complexity; and 3) aggregation complexity (see Table 3). Through an experimental comparison of these architectures, we have derived a guideline for selecting appropriate architectures in the context of FL for RS MLC problems as follows:"
        ]
    }
}