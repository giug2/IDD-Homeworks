{
    "S3.T1.3": {
        "caption": [
            "Details of fMRI-3D Dataset."
        ],
        "table": "<table id=\"S3.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"></th>\n<th id=\"S3.T1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">Participant</th>\n<th id=\"S3.T1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">Males/Females</th>\n<th id=\"S3.T1.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">Category</th>\n<th id=\"S3.T1.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">Objects</th>\n<th id=\"S3.T1.3.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">Frames</th>\n</tr>\n<tr id=\"S3.T1.3.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">fMRI-Shape</th>\n<th id=\"S3.T1.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">14</th>\n<th id=\"S3.T1.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">7/7</th>\n<th id=\"S3.T1.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">55</th>\n<th id=\"S3.T1.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">1624</th>\n<th id=\"S3.T1.3.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">123200</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.3.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">     Core Set</th>\n<th id=\"S3.T1.3.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">8</th>\n<th id=\"S3.T1.3.3.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">4/4</th>\n<td id=\"S3.T1.3.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">13</td>\n<td id=\"S3.T1.3.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">1404</td>\n<td id=\"S3.T1.3.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">14040</td>\n</tr>\n<tr id=\"S3.T1.3.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">     AP Set</th>\n<th id=\"S3.T1.3.4.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">2</th>\n<th id=\"S3.T1.3.4.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">1/1</th>\n<td id=\"S3.T1.3.4.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">13</td>\n<td id=\"S3.T1.3.4.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">104</td>\n<td id=\"S3.T1.3.4.2.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">1040</td>\n</tr>\n<tr id=\"S3.T1.3.5.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">     APAC Set</th>\n<th id=\"S3.T1.3.5.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">4</th>\n<th id=\"S3.T1.3.5.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">2/2</th>\n<td id=\"S3.T1.3.5.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">55</td>\n<td id=\"S3.T1.3.5.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">220</td>\n<td id=\"S3.T1.3.5.3.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">2200</td>\n</tr>\n<tr id=\"S3.T1.3.6.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">fMRI-Objaverse</th>\n<th id=\"S3.T1.3.6.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">5</th>\n<th id=\"S3.T1.3.6.4.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">2/3</th>\n<td id=\"S3.T1.3.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">117</td>\n<td id=\"S3.T1.3.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">3142</td>\n<td id=\"S3.T1.3.6.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">125680</td>\n</tr>\n<tr id=\"S3.T1.3.7.5\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">fMRI-3D (Total)</th>\n<th id=\"S3.T1.3.7.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">15</th>\n<th id=\"S3.T1.3.7.5.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">7/8</th>\n<td id=\"S3.T1.3.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">172</td>\n<td id=\"S3.T1.3.7.5.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">4768</td>\n<td id=\"S3.T1.3.7.5.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">248880</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "In this section, we detail the procedures for collecting the proposed fMRI-3D dataset, which consists of two components: fMRI-Shape and fMRI-Objaverse. The scale of fMRI-3D is compared to other benchmark datasets, including NSD [16], BOLD5000 [35], GOD [18], and Video-fMRI [19], as illustrated in Fig. 4. Specific details about fMRI-Shape and fMRI-Objaverse are provided in Tab. I. For all experiments, written informed consent was obtained from each participant, and the study was approved by the ethical review board.\nTo better illustrate brain activation patterns and demonstrate the utility of the fMRI-3D dataset, we analyze and visualize responses to three distinct objects across six subjects, as shown in Fig. 3. Note that only voxels with activation levels above the 50th percentile are displayed. We also compute the variation across subjects and objects, with red and blue regions indicating higher activation values, respectively, reflecting areas in the human brain sensitive to the stimuli. This visualization highlights significant individual differences in brain activation across subjects, which are more pronounced than the variations in responses to different objects. These findings emphasize the inherent challenges and underscore the importance of the AP and APAC settings.\nAll participants had normal or corrected-to-normal vision. The fMRI-3D dataset will be made publicly available to support further research in Recon3DMind."
        ]
    }
}{
    "S5.T2.7": {
        "caption": [
            "Performance Comparison on fMRI-Shape."
        ],
        "table": "<table id=\"S5.T2.7\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.7.8.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.7.8.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\" rowspan=\"2\"><span id=\"S5.T2.7.8.1.1.1\" class=\"ltx_text ltx_font_smallcaps\">Methods</span></th>\n<th id=\"S5.T2.7.8.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\" colspan=\"3\">Semantic-Level</th>\n<th id=\"S5.T2.7.8.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\" colspan=\"4\">Structure-Level</th>\n</tr>\n<tr id=\"S5.T2.7.7\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">2-way<math id=\"S5.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S5.T2.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S5.T2.1.1.1.m1.1.1\" xref=\"S5.T2.1.1.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.1.1.1.m1.1b\"><ci id=\"S5.T2.1.1.1.m1.1.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.1.1.1.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"S5.T2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">10-way<math id=\"S5.T2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S5.T2.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S5.T2.2.2.2.m1.1.1\" xref=\"S5.T2.2.2.2.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.2.2.2.m1.1b\"><ci id=\"S5.T2.2.2.2.m1.1.1.cmml\" xref=\"S5.T2.2.2.2.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.2.2.2.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"S5.T2.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">LPIPS<math id=\"S5.T2.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T2.3.3.3.m1.1a\"><mo stretchy=\"false\" id=\"S5.T2.3.3.3.m1.1.1\" xref=\"S5.T2.3.3.3.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.3.3.3.m1.1b\"><ci id=\"S5.T2.3.3.3.m1.1.1.cmml\" xref=\"S5.T2.3.3.3.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.3.3.3.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S5.T2.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">SSIM<math id=\"S5.T2.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S5.T2.4.4.4.m1.1a\"><mo stretchy=\"false\" id=\"S5.T2.4.4.4.m1.1.1\" xref=\"S5.T2.4.4.4.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.4.4.4.m1.1b\"><ci id=\"S5.T2.4.4.4.m1.1.1.cmml\" xref=\"S5.T2.4.4.4.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.4.4.4.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"S5.T2.5.5.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">FPD<math id=\"S5.T2.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T2.5.5.5.m1.1a\"><mo stretchy=\"false\" id=\"S5.T2.5.5.5.m1.1.1\" xref=\"S5.T2.5.5.5.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.5.5.5.m1.1b\"><ci id=\"S5.T2.5.5.5.m1.1.1.cmml\" xref=\"S5.T2.5.5.5.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.5.5.5.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S5.T2.6.6.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">CD<math id=\"S5.T2.6.6.6.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T2.6.6.6.m1.1a\"><mo stretchy=\"false\" id=\"S5.T2.6.6.6.m1.1.1\" xref=\"S5.T2.6.6.6.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.6.6.6.m1.1b\"><ci id=\"S5.T2.6.6.6.m1.1.1.cmml\" xref=\"S5.T2.6.6.6.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.6.6.6.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S5.T2.7.7.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">EMD<math id=\"S5.T2.7.7.7.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T2.7.7.7.m1.1a\"><mo stretchy=\"false\" id=\"S5.T2.7.7.7.m1.1.1\" xref=\"S5.T2.7.7.7.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.7.7.7.m1.1b\"><ci id=\"S5.T2.7.7.7.m1.1.1.cmml\" xref=\"S5.T2.7.7.7.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.7.7.7.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.7.9.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.7.9.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">LEA-3D <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">6</a>]</cite>\n</td>\n<td id=\"S5.T2.7.9.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.787</td>\n<td id=\"S5.T2.7.9.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.371</td>\n<td id=\"S5.T2.7.9.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.527</td>\n<td id=\"S5.T2.7.9.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.562</td>\n<td id=\"S5.T2.7.9.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">4.229</td>\n<td id=\"S5.T2.7.9.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">2.291</td>\n<td id=\"S5.T2.7.9.1.8\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">5.347</td>\n</tr>\n<tr id=\"S5.T2.7.10.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.7.10.2.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">fMRI-PTE-3D <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a>]</cite>\n</td>\n<td id=\"S5.T2.7.10.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.815</td>\n<td id=\"S5.T2.7.10.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.392</td>\n<td id=\"S5.T2.7.10.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.433</td>\n<td id=\"S5.T2.7.10.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.694</td>\n<td id=\"S5.T2.7.10.2.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">3.571</td>\n<td id=\"S5.T2.7.10.2.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">1.992</td>\n<td id=\"S5.T2.7.10.2.8\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">4.621</td>\n</tr>\n<tr id=\"S5.T2.7.11.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.7.11.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">w/o Both</td>\n<td id=\"S5.T2.7.11.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.789</td>\n<td id=\"S5.T2.7.11.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.367</td>\n<td id=\"S5.T2.7.11.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.479</td>\n<td id=\"S5.T2.7.11.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.616</td>\n<td id=\"S5.T2.7.11.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">3.694</td>\n<td id=\"S5.T2.7.11.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">2.205</td>\n<td id=\"S5.T2.7.11.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">5.073</td>\n</tr>\n<tr id=\"S5.T2.7.12.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.7.12.4.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">w/o Diffusion</td>\n<td id=\"S5.T2.7.12.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.801</td>\n<td id=\"S5.T2.7.12.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.385</td>\n<td id=\"S5.T2.7.12.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.423</td>\n<td id=\"S5.T2.7.12.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.669</td>\n<td id=\"S5.T2.7.12.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">3.526</td>\n<td id=\"S5.T2.7.12.4.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">2.071</td>\n<td id=\"S5.T2.7.12.4.8\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">4.625</td>\n</tr>\n<tr id=\"S5.T2.7.13.5\" class=\"ltx_tr\">\n<td id=\"S5.T2.7.13.5.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">w/o Contrastive</td>\n<td id=\"S5.T2.7.13.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.823</td>\n<td id=\"S5.T2.7.13.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.419</td>\n<td id=\"S5.T2.7.13.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.319</td>\n<td id=\"S5.T2.7.13.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">0.701</td>\n<td id=\"S5.T2.7.13.5.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">3.315</td>\n<td id=\"S5.T2.7.13.5.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">1.826</td>\n<td id=\"S5.T2.7.13.5.8\" class=\"ltx_td ltx_align_center\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">4.027</td>\n</tr>\n<tr id=\"S5.T2.7.14.6\" class=\"ltx_tr\">\n<td id=\"S5.T2.7.14.6.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-left:11.4pt;padding-right:11.4pt;\">MinD-3D (full)</td>\n<td id=\"S5.T2.7.14.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:11.4pt;padding-right:11.4pt;\"><span id=\"S5.T2.7.14.6.2.1\" class=\"ltx_text ltx_font_bold\">0.839</span></td>\n<td id=\"S5.T2.7.14.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:11.4pt;padding-right:11.4pt;\"><span id=\"S5.T2.7.14.6.3.1\" class=\"ltx_text ltx_font_bold\">0.432</span></td>\n<td id=\"S5.T2.7.14.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:11.4pt;padding-right:11.4pt;\"><span id=\"S5.T2.7.14.6.4.1\" class=\"ltx_text ltx_font_bold\">0.230</span></td>\n<td id=\"S5.T2.7.14.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:11.4pt;padding-right:11.4pt;\"><span id=\"S5.T2.7.14.6.5.1\" class=\"ltx_text ltx_font_bold\">0.734</span></td>\n<td id=\"S5.T2.7.14.6.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:11.4pt;padding-right:11.4pt;\"><span id=\"S5.T2.7.14.6.6.1\" class=\"ltx_text ltx_font_bold\">3.157</span></td>\n<td id=\"S5.T2.7.14.6.7\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:11.4pt;padding-right:11.4pt;\"><span id=\"S5.T2.7.14.6.7.1\" class=\"ltx_text ltx_font_bold\">1.742</span></td>\n<td id=\"S5.T2.7.14.6.8\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:11.4pt;padding-right:11.4pt;\"><span id=\"S5.T2.7.14.6.8.1\" class=\"ltx_text ltx_font_bold\">3.833</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Semantic Level. To assess the semantic quality of our model, we adopt standard metrics commonly used in prior 2D fMRI studies [2, 3, 51, 52, 23], specifically N-way top-K accuracy. We report 2-way-top-1 and 10-way-top-1 accuracy, as shown in Table II. Additionally, we calculate the Learned Perceptual Image Patch Similarity (LPIPS) [53] to evaluate the perceptual quality of the semantic information. These metrics are computed by comparing the reconstructed images with the ground truth (GT) images. Both the reconstructed and GT objects are rendered into images at every 60-degree rotation, and the metrics are calculated for each frame. The final score is derived by averaging the values across frames.",
            "Tab. II reports the averaged metrics at both the structural and semantic levels for all subjects. MinD-3D demonstrates superior performance across all metrics, achieving approximately 83.9% accuracy in 2-way-top-1, 43.2% accuracy in 10-way-top-1, and scores of 0.734, 0.230, 3.157, 1.742, and 3.833 in other metrics. These results indicate that our model not only excels in generating objects with high semantic accuracy but also performs exceptionally well in preserving structural similarity, outperforming baseline methods. Tab. II also highlights the effectiveness of both the diffusion model and the contrastive learning module, which play critical roles in the success of MinD-3D."
        ]
    }
}{
    "S6.T3.6": {
        "caption": [],
        "table": "<table id=\"S6.T3.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T3.6.7.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.6.7.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S6.T3.6.7.1.1.1\" class=\"ltx_text ltx_font_smallcaps\">Methods</span></th>\n<th id=\"S6.T3.6.7.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"3\">APT</th>\n<th id=\"S6.T3.6.7.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">APACT</th>\n</tr>\n<tr id=\"S6.T3.6.6\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">FPD<math id=\"S6.T3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T3.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S6.T3.1.1.1.m1.1.1\" xref=\"S6.T3.1.1.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.1.1.1.m1.1b\"><ci id=\"S6.T3.1.1.1.m1.1.1.cmml\" xref=\"S6.T3.1.1.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S6.T3.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">CD<math id=\"S6.T3.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T3.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S6.T3.2.2.2.m1.1.1\" xref=\"S6.T3.2.2.2.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.2.2.2.m1.1b\"><ci id=\"S6.T3.2.2.2.m1.1.1.cmml\" xref=\"S6.T3.2.2.2.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.2.2.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S6.T3.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">EMD<math id=\"S6.T3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T3.3.3.3.m1.1a\"><mo stretchy=\"false\" id=\"S6.T3.3.3.3.m1.1.1\" xref=\"S6.T3.3.3.3.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.3.3.3.m1.1b\"><ci id=\"S6.T3.3.3.3.m1.1.1.cmml\" xref=\"S6.T3.3.3.3.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.3.3.3.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S6.T3.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">FPD<math id=\"S6.T3.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T3.4.4.4.m1.1a\"><mo stretchy=\"false\" id=\"S6.T3.4.4.4.m1.1.1\" xref=\"S6.T3.4.4.4.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.4.4.4.m1.1b\"><ci id=\"S6.T3.4.4.4.m1.1.1.cmml\" xref=\"S6.T3.4.4.4.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.4.4.4.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S6.T3.5.5.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">CD<math id=\"S6.T3.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T3.5.5.5.m1.1a\"><mo stretchy=\"false\" id=\"S6.T3.5.5.5.m1.1.1\" xref=\"S6.T3.5.5.5.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.5.5.5.m1.1b\"><ci id=\"S6.T3.5.5.5.m1.1.1.cmml\" xref=\"S6.T3.5.5.5.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.5.5.5.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S6.T3.6.6.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">EMD<math id=\"S6.T3.6.6.6.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T3.6.6.6.m1.1a\"><mo stretchy=\"false\" id=\"S6.T3.6.6.6.m1.1.1\" xref=\"S6.T3.6.6.6.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.6.6.6.m1.1b\"><ci id=\"S6.T3.6.6.6.m1.1.1.cmml\" xref=\"S6.T3.6.6.6.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.6.6.6.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T3.6.8.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.6.8.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\">LEA-3D</th>\n<td id=\"S6.T3.6.8.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">5.362</td>\n<td id=\"S6.T3.6.8.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">3.627</td>\n<td id=\"S6.T3.6.8.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">6.174</td>\n<td id=\"S6.T3.6.8.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">6.958</td>\n<td id=\"S6.T3.6.8.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">4.944</td>\n<td id=\"S6.T3.6.8.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\">8.107</td>\n</tr>\n<tr id=\"S6.T3.6.9.2\" class=\"ltx_tr\">\n<th id=\"S6.T3.6.9.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">fMRI-PTE-3D</th>\n<td id=\"S6.T3.6.9.2.2\" class=\"ltx_td ltx_align_center\">4.501</td>\n<td id=\"S6.T3.6.9.2.3\" class=\"ltx_td ltx_align_center\">2.956</td>\n<td id=\"S6.T3.6.9.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">5.772</td>\n<td id=\"S6.T3.6.9.2.5\" class=\"ltx_td ltx_align_center\">6.261</td>\n<td id=\"S6.T3.6.9.2.6\" class=\"ltx_td ltx_align_center\">4.570</td>\n<td id=\"S6.T3.6.9.2.7\" class=\"ltx_td ltx_align_center\">7.843</td>\n</tr>\n<tr id=\"S6.T3.6.10.3\" class=\"ltx_tr\">\n<th id=\"S6.T3.6.10.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">MinD-3D</th>\n<td id=\"S6.T3.6.10.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S6.T3.6.10.3.2.1\" class=\"ltx_text ltx_font_bold\">3.838</span></td>\n<td id=\"S6.T3.6.10.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S6.T3.6.10.3.3.1\" class=\"ltx_text ltx_font_bold\">2.415</span></td>\n<td id=\"S6.T3.6.10.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S6.T3.6.10.3.4.1\" class=\"ltx_text ltx_font_bold\">5.117</span></td>\n<td id=\"S6.T3.6.10.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S6.T3.6.10.3.5.1\" class=\"ltx_text ltx_font_bold\">5.689</span></td>\n<td id=\"S6.T3.6.10.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S6.T3.6.10.3.6.1\" class=\"ltx_text ltx_font_bold\">4.181</span></td>\n<td id=\"S6.T3.6.10.3.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S6.T3.6.10.3.7.1\" class=\"ltx_text ltx_font_bold\">7.194</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "To effectively utilize a subset of the fMRI-Shape dataset and further assess the generalization capabilities of our proposed MinD-3D model, we conduct two Out-Of-Distribution (OOD) experiments under challenging settings:\n1) Across-Person Testing (APT): In APT, we evaluate our model, which was trained only on Subject 1, using the data from Subject 9. We compare the results with the baselines and report the metrics in Tab. III.\n2) Across-Person & Across-Class Testing (APACT): In APACT, we similarly evaluate our model, trained solely on Subject 1, with the data from Subject 11. We also compare with the baselines and report the metrics in Tab. III."
        ]
    }
}{
    "id3.1": {
        "caption": [],
        "table": "<table id=\"id3.1\" class=\"ltx_tabular\">\n<tr id=\"id3.1.1\" class=\"ltx_tr\">\n<td id=\"id3.1.1.1\" class=\"ltx_td\"><img src=\"/html/2409.11315/assets/bio/gjx.jpg\" id=\"id3.1.1.1.g1\" class=\"ltx_graphics ltx_img_portrait\" width=\"89\" height=\"125\" alt=\"[Uncaptioned image]\"></td>\n<td id=\"id3.1.1.2\" class=\"ltx_td\">\n<span id=\"id3.1.1.2.1\" class=\"ltx_inline-block\">\n<span id=\"id3.1.1.2.1.1\" class=\"ltx_p\"><span id=\"id3.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Jianxiong Gao</span>  received the B.S. degree in Statistics from Shandong University in 2022.\nHe is currently pursuing a Ph.D. degree in Biomedical Engineering at the Institute of Science and Technology for Brain-Inspired Intelligence, Fudan University, under the supervision of Dr. Yanwei Fu and Dr. Jianfeng Feng. His research interests include amodal segmentation and neural decoding.</span>\n</span>\n</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": []
    }
}{
    "id4.1": {
        "caption": [],
        "table": "<table id=\"id4.1\" class=\"ltx_tabular\">\n<tr id=\"id4.1.1\" class=\"ltx_tr\">\n<td id=\"id4.1.1.1\" class=\"ltx_td\"><img src=\"/html/2409.11315/assets/bio/fyq.jpg\" id=\"id4.1.1.1.g1\" class=\"ltx_graphics ltx_img_portrait\" width=\"89\" height=\"125\" alt=\"[Uncaptioned image]\"></td>\n<td id=\"id4.1.1.2\" class=\"ltx_td\">\n<span id=\"id4.1.1.2.1\" class=\"ltx_inline-block\">\n<span id=\"id4.1.1.2.1.1\" class=\"ltx_p\"><span id=\"id4.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Yuqian Fu</span>  is currently a postdoc researcher at INSAIT, Bulgaria. Previously, she worked as a postdoc researcher at Computer Vision Lab (CVL), ETH Zürich, Switzerland. She received her Ph.D. degree from the School of Computer Science, Fudan University, China, in June 2023. Her research topics are vision and deep learning, especially transfer learning, domain adaptation, and multimodal learning.</span>\n</span>\n</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": []
    }
}{
    "id5.1": {
        "caption": [],
        "table": "<table id=\"id5.1\" class=\"ltx_tabular\">\n<tr id=\"id5.1.1\" class=\"ltx_tr\">\n<td id=\"id5.1.1.1\" class=\"ltx_td\"><img src=\"/html/2409.11315/assets/bio/wy.jpg\" id=\"id5.1.1.1.g1\" class=\"ltx_graphics ltx_img_portrait\" width=\"100\" height=\"125\" alt=\"[Uncaptioned image]\"></td>\n<td id=\"id5.1.1.2\" class=\"ltx_td\">\n<span id=\"id5.1.1.2.1\" class=\"ltx_inline-block\">\n<span id=\"id5.1.1.2.1.1\" class=\"ltx_p\"><span id=\"id5.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Yun Wang</span>  received the B.S. and M.S. degrees in electrical engineering from Wuhan University, Hubei Province, China, in 2011 and is currently pursuing a Ph.D. degree in the Institute of Science and Technology for Brain-Inspired Intelligence at Fudan University. From 2011 to 2017, he was a Research Engineer in State Grid Electric Power Research Institute. His current research interests include computational neuroscience and brain-inspired intelligence.</span>\n</span>\n</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": []
    }
}{
    "id6.1": {
        "caption": [],
        "table": "<table id=\"id6.1\" class=\"ltx_tabular\">\n<tr id=\"id6.1.1\" class=\"ltx_tr\">\n<td id=\"id6.1.1.1\" class=\"ltx_td\"><img src=\"/html/2409.11315/assets/bio/qxl.jpg\" id=\"id6.1.1.1.g1\" class=\"ltx_graphics ltx_img_portrait\" width=\"97\" height=\"125\" alt=\"[Uncaptioned image]\"></td>\n<td id=\"id6.1.1.2\" class=\"ltx_td\">\n<span id=\"id6.1.1.2.1\" class=\"ltx_inline-block\">\n<span id=\"id6.1.1.2.1.1\" class=\"ltx_p\"><span id=\"id6.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Xuelin Qian</span>  (Member, IEEE) is an Associate Professor in the School of Automation, Northwestern Polytechnical University (NWPU). Before that, he held a post-doctoral position with Fudan University from 2022 to 2024. He received the Ph.D. degree from Fudan University in 2021, and the B.S. degree from Xidian University in 2015. He has published over 15 papers in top-tier conferences and journals, and served as a reviewer for CVPR, ICCV, TPAMI, IJCV <span id=\"id6.1.1.2.1.1.2\" class=\"ltx_text ltx_font_italic\">etc</span>. His research interests are image retrieval, multi-modal generation, and medical image analysis.</span>\n</span>\n</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": []
    }
}{
    "id7.1": {
        "caption": [],
        "table": "<table id=\"id7.1\" class=\"ltx_tabular\">\n<tr id=\"id7.1.1\" class=\"ltx_tr\">\n<td id=\"id7.1.1.1\" class=\"ltx_td\"><img src=\"/html/2409.11315/assets/bio/fjf.jpg\" id=\"id7.1.1.1.g1\" class=\"ltx_graphics ltx_img_portrait\" width=\"100\" height=\"125\" alt=\"[Uncaptioned image]\"></td>\n<td id=\"id7.1.1.2\" class=\"ltx_td\">\n<span id=\"id7.1.1.2.1\" class=\"ltx_inline-block\">\n<span id=\"id7.1.1.2.1.1\" class=\"ltx_p\"><span id=\"id7.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Jianfeng Feng</span>  (Senior Member, IEEE) received the\nBS, MS, and PhD degrees from the Department of Probability and Statistics, Peking University, China. He is the chair professor with the Shanghai National Centre for Mathematic Sciences and the dean with the Brain-Inspired AI Institute, Fudan University. He leads the DTB project. He has been developing new mathematical, statistical, and computational theories and methods to meet the challenges raised in neuroscience and mental health research.</span>\n</span>\n</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": []
    }
}{
    "id8.1": {
        "caption": [],
        "table": "<table id=\"id8.1\" class=\"ltx_tabular\">\n<tr id=\"id8.1.1\" class=\"ltx_tr\">\n<td id=\"id8.1.1.1\" class=\"ltx_td\"><img src=\"/html/2409.11315/assets/x16.png\" id=\"id8.1.1.1.g1\" class=\"ltx_graphics ltx_img_portrait\" width=\"77\" height=\"96\" alt=\"[Uncaptioned image]\"></td>\n<td id=\"id8.1.1.2\" class=\"ltx_td\">\n<span id=\"id8.1.1.2.1\" class=\"ltx_inline-block\">\n<span id=\"id8.1.1.2.1.1\" class=\"ltx_p\"><span id=\"id8.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Yanwei Fu</span>  received the MEng degree from the Department of Computer Science and Technology, Nanjing University, China, in 2011, and the PhD degree from the Queen Mary University of London, in 2014. He held a post-doctoral position at Disney Research, Pittsburgh, PA, from 2015 to 2016. He is currently a tenure-track professor at Fudan University.\nHe was appointed as the Professor of Special Appointment\n(Eastern Scholar) at Shanghai Institutions\nof Higher Learning in 2017, and awarded\nthe 1000 Young talent scholar in 2018.\nHis work has led to many awards, including the IEEE ICME 2019 best paper.\nHe published more than 110 journal/conference papers including IEEE TPAMI, TMM, ECCV, and CVPR. His research interests are one-shot learning, learning-based 3D reconstruction, and learning-based robotic grasping.</span>\n</span>\n</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": []
    }
}