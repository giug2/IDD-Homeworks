{
    "PAPER'S NUMBER OF TABLES": 13,
    "S3.T1": {
        "caption": "TABLE I: Comparison of average accuracy across three independent runs for different datasets under clean and noisy client data scenarios. For the noisy data scenario, we consider 5 clean clients and 15 noisy clients with 100% noise level. Models are trained with FedAvg.",
        "table": "<table id=\"S3.T1.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T1.5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Data</span></th>\n<th id=\"S3.T1.5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S3.T1.5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">CIFAR10</span></th>\n<th id=\"S3.T1.5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S3.T1.5.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">CIFAR100</span></th>\n<th id=\"S3.T1.5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S3.T1.5.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">PathMNIST</span></th>\n<th id=\"S3.T1.5.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S3.T1.5.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">FMNIST</span></th>\n<th id=\"S3.T1.5.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S3.T1.5.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">EuroSAT</span></th>\n<th id=\"S3.T1.5.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S3.T1.5.1.1.1.7.1\" class=\"ltx_text ltx_font_bold\">Tiny-ImageNet</span></th>\n</tr>\n<tr id=\"S3.T1.5.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.5.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S3.T1.5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S3.T1.5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S3.T1.5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S3.T1.5.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S3.T1.5.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.6.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S3.T1.5.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.7.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S3.T1.5.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.8.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S3.T1.5.1.2.2.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.9.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S3.T1.5.1.2.2.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.10.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S3.T1.5.1.2.2.11\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.11.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S3.T1.5.1.2.2.12\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.5.1.2.2.12.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.5.1.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.5.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Clean</th>\n<td id=\"S3.T1.5.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">90.14%</td>\n<td id=\"S3.T1.5.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">85.52%</td>\n<td id=\"S3.T1.5.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">64.79%</td>\n<td id=\"S3.T1.5.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">62.36%</td>\n<td id=\"S3.T1.5.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">87.74%</td>\n<td id=\"S3.T1.5.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">82.55%</td>\n<td id=\"S3.T1.5.1.3.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">92.34%</td>\n<td id=\"S3.T1.5.1.3.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">89.37%</td>\n<td id=\"S3.T1.5.1.3.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\">94.72%</td>\n<td id=\"S3.T1.5.1.3.1.11\" class=\"ltx_td ltx_align_center ltx_border_t\">95.12%</td>\n<td id=\"S3.T1.5.1.3.1.12\" class=\"ltx_td ltx_align_center ltx_border_t\">53.26%</td>\n<td id=\"S3.T1.5.1.3.1.13\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">52.88%</td>\n</tr>\n<tr id=\"S3.T1.5.1.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.5.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Noisy</th>\n<td id=\"S3.T1.5.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">78.62%</td>\n<td id=\"S3.T1.5.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">73.51%</td>\n<td id=\"S3.T1.5.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">44.58%</td>\n<td id=\"S3.T1.5.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">42.10%</td>\n<td id=\"S3.T1.5.1.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">54.80%</td>\n<td id=\"S3.T1.5.1.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">52.14%</td>\n<td id=\"S3.T1.5.1.4.2.8\" class=\"ltx_td ltx_align_center ltx_border_bb\">88.14%</td>\n<td id=\"S3.T1.5.1.4.2.9\" class=\"ltx_td ltx_align_center ltx_border_bb\">84.67%</td>\n<td id=\"S3.T1.5.1.4.2.10\" class=\"ltx_td ltx_align_center ltx_border_bb\">67.39%</td>\n<td id=\"S3.T1.5.1.4.2.11\" class=\"ltx_td ltx_align_center ltx_border_bb\">75.06%</td>\n<td id=\"S3.T1.5.1.4.2.12\" class=\"ltx_td ltx_align_center ltx_border_bb\">24.32%</td>\n<td id=\"S3.T1.5.1.4.2.13\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">22.90%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In FL, the formulation of the global model normally involves the aggregation of local models from each client, weighted based on the total count of data samples in their respective local datasets [1, 2]. When applying an average aggregation strategy when clients‚Äô data follows the IID setting, the contribution of each client‚Äôs model parameters to the server is equivalent. Consequently, in scenarios of noisy federated learning, the contribution of noisy clients can seriously degrade the generalization quality of the server-side aggregated model, as detailed in Table I.",
            "Participation of noisy clients deteriorates the performance of the global model. To validate the efficacy of our proposed method, we first conduct an experiment for model training with clean and noisy input across all the datasets and utilize the same noise configuration for our further empirical evaluation. With this, we aim to evaluate the upper-bound performance that can be achieved when learning from a mixture of noisy and clean clients. Table I presents the comparative results of average accuracy for all considered datasets. We focus on three specific distortions (i.e., defocus blur, Gaussian blur, contrast) due to their significant impact on degrading the model‚Äôs generalization capability to simulate the worst case in noisy FL.\nFor the generation of distorted data used in the experiments summarized in Table II, each noisy sample was produced by randomly selecting a distortion type with the configuration characterized by the noise severity level Œæ=h‚Äãi‚Äãg‚Äãhùúâ‚Ñéùëñùëî‚Ñé\\xi=high. We set the noise level to NLm=100%subscriptNLùëöpercent100\\emph{NL}_{m}=100\\% for every client mùëöm for the experiments of both Table II and Figure 6. We see the participation of noisy clients leads to a significant degradation in the model‚Äôs generalization capability across all tasks, indicating the detrimental impact of noisy data in the FL environment. Furthermore, due to the inherent lack of visibility into the data from these federated clients, the resultant global model tends to be of low quality and it may become challenging in a real-world setting to identify the underlying reasons for its poor performance."
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Comparison of top-1 accuracy across datasets in IID and Non-IID settings. We evaluate the performance of FedNS¬†with various federated aggregation methods for learning under the noisy environment.",
        "table": "<table id=\"S4.T2.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T2.5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Methods</span></th>\n<th id=\"S4.T2.5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T2.5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">CIFAR-10</span></th>\n<th id=\"S4.T2.5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T2.5.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">CIFAR-100</span></th>\n<th id=\"S4.T2.5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T2.5.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">PathMNIST</span></th>\n<th id=\"S4.T2.5.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T2.5.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">FMNIST</span></th>\n<th id=\"S4.T2.5.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T2.5.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">EuroSAT</span></th>\n<th id=\"S4.T2.5.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T2.5.1.1.1.7.1\" class=\"ltx_text ltx_font_bold\">Tiny-ImageNet</span></th>\n</tr>\n<tr id=\"S4.T2.5.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T2.5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T2.5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T2.5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T2.5.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T2.5.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.6.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T2.5.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.7.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T2.5.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.8.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T2.5.1.2.2.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.9.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T2.5.1.2.2.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.10.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T2.5.1.2.2.11\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.11.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T2.5.1.2.2.12\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.5.1.2.2.12.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.5.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedAvg<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\">2</a>]</cite>\n</th>\n<td id=\"S4.T2.5.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">78.62%</td>\n<td id=\"S4.T2.5.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">73.51%</td>\n<td id=\"S4.T2.5.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">44.58%</td>\n<td id=\"S4.T2.5.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">42.10%</td>\n<td id=\"S4.T2.5.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">54.80%</td>\n<td id=\"S4.T2.5.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">52.14%</td>\n<td id=\"S4.T2.5.1.3.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">88.14%</td>\n<td id=\"S4.T2.5.1.3.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">84.67%</td>\n<td id=\"S4.T2.5.1.3.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\">67.39%</td>\n<td id=\"S4.T2.5.1.3.1.11\" class=\"ltx_td ltx_align_center ltx_border_t\">75.06%</td>\n<td id=\"S4.T2.5.1.3.1.12\" class=\"ltx_td ltx_align_center ltx_border_t\">24.32%</td>\n<td id=\"S4.T2.5.1.3.1.13\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">22.90%</td>\n</tr>\n<tr id=\"S4.T2.5.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">+ NS (Ours)</th>\n<td id=\"S4.T2.5.1.4.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.2.1\" class=\"ltx_text ltx_font_bold\">81.67%</span></td>\n<td id=\"S4.T2.5.1.4.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.3.1\" class=\"ltx_text ltx_font_bold\">78.44%</span></td>\n<td id=\"S4.T2.5.1.4.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.4.1\" class=\"ltx_text ltx_font_bold\">48.14%</span></td>\n<td id=\"S4.T2.5.1.4.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.5.1\" class=\"ltx_text ltx_font_bold\">45.94%</span></td>\n<td id=\"S4.T2.5.1.4.2.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.6.1\" class=\"ltx_text ltx_font_bold\">63.89%</span></td>\n<td id=\"S4.T2.5.1.4.2.7\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.7.1\" class=\"ltx_text ltx_font_bold\">62.92%</span></td>\n<td id=\"S4.T2.5.1.4.2.8\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.8.1\" class=\"ltx_text ltx_font_bold\">89.61%</span></td>\n<td id=\"S4.T2.5.1.4.2.9\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.9.1\" class=\"ltx_text ltx_font_bold\">88.53%</span></td>\n<td id=\"S4.T2.5.1.4.2.10\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.10.1\" class=\"ltx_text ltx_font_bold\">78.22%</span></td>\n<td id=\"S4.T2.5.1.4.2.11\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.11.1\" class=\"ltx_text ltx_font_bold\">80.12%</span></td>\n<td id=\"S4.T2.5.1.4.2.12\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.4.2.12.1\" class=\"ltx_text ltx_font_bold\">27.85%</span></td>\n<td id=\"S4.T2.5.1.4.2.13\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.5.1.4.2.13.1\" class=\"ltx_text ltx_font_bold\">25.93%</span></td>\n</tr>\n<tr id=\"S4.T2.5.1.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedProx<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">9</a>]</cite>\n</th>\n<td id=\"S4.T2.5.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">79.89%</td>\n<td id=\"S4.T2.5.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">78.13%</td>\n<td id=\"S4.T2.5.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">46.75%</td>\n<td id=\"S4.T2.5.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">45.17%</td>\n<td id=\"S4.T2.5.1.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">57.28%</td>\n<td id=\"S4.T2.5.1.5.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\">56.27%</td>\n<td id=\"S4.T2.5.1.5.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">87.15%</td>\n<td id=\"S4.T2.5.1.5.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\">86.96%</td>\n<td id=\"S4.T2.5.1.5.3.10\" class=\"ltx_td ltx_align_center ltx_border_t\">70.83%</td>\n<td id=\"S4.T2.5.1.5.3.11\" class=\"ltx_td ltx_align_center ltx_border_t\">76.64%</td>\n<td id=\"S4.T2.5.1.5.3.12\" class=\"ltx_td ltx_align_center ltx_border_t\">24.90%</td>\n<td id=\"S4.T2.5.1.5.3.13\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">23.76%</td>\n</tr>\n<tr id=\"S4.T2.5.1.6.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">+ NS (Ours)</th>\n<td id=\"S4.T2.5.1.6.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.2.1\" class=\"ltx_text ltx_font_bold\">82.31%</span></td>\n<td id=\"S4.T2.5.1.6.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.3.1\" class=\"ltx_text ltx_font_bold\">81.18%</span></td>\n<td id=\"S4.T2.5.1.6.4.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.4.1\" class=\"ltx_text ltx_font_bold\">48.27%</span></td>\n<td id=\"S4.T2.5.1.6.4.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.5.1\" class=\"ltx_text ltx_font_bold\">46.80%</span></td>\n<td id=\"S4.T2.5.1.6.4.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.6.1\" class=\"ltx_text ltx_font_bold\">60.18%</span></td>\n<td id=\"S4.T2.5.1.6.4.7\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.7.1\" class=\"ltx_text ltx_font_bold\">63.11%</span></td>\n<td id=\"S4.T2.5.1.6.4.8\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.8.1\" class=\"ltx_text ltx_font_bold\">89.12%</span></td>\n<td id=\"S4.T2.5.1.6.4.9\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.9.1\" class=\"ltx_text ltx_font_bold\">87.48%</span></td>\n<td id=\"S4.T2.5.1.6.4.10\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.10.1\" class=\"ltx_text ltx_font_bold\">76.94%</span></td>\n<td id=\"S4.T2.5.1.6.4.11\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.11.1\" class=\"ltx_text ltx_font_bold\">81.20%</span></td>\n<td id=\"S4.T2.5.1.6.4.12\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.6.4.12.1\" class=\"ltx_text ltx_font_bold\">26.48%</span></td>\n<td id=\"S4.T2.5.1.6.4.13\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.5.1.6.4.13.1\" class=\"ltx_text ltx_font_bold\">25.98%</span></td>\n</tr>\n<tr id=\"S4.T2.5.1.7.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedTrimmedAvg<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">10</a>]</cite>\n</th>\n<td id=\"S4.T2.5.1.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">78.92%</td>\n<td id=\"S4.T2.5.1.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">77.24%</td>\n<td id=\"S4.T2.5.1.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">41.81%</td>\n<td id=\"S4.T2.5.1.7.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">41.25%</td>\n<td id=\"S4.T2.5.1.7.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\">56.34%</td>\n<td id=\"S4.T2.5.1.7.5.7\" class=\"ltx_td ltx_align_center ltx_border_t\">54.50%</td>\n<td id=\"S4.T2.5.1.7.5.8\" class=\"ltx_td ltx_align_center ltx_border_t\">90.09%</td>\n<td id=\"S4.T2.5.1.7.5.9\" class=\"ltx_td ltx_align_center ltx_border_t\">89.95%</td>\n<td id=\"S4.T2.5.1.7.5.10\" class=\"ltx_td ltx_align_center ltx_border_t\">68.30%</td>\n<td id=\"S4.T2.5.1.7.5.11\" class=\"ltx_td ltx_align_center ltx_border_t\">74.39%</td>\n<td id=\"S4.T2.5.1.7.5.12\" class=\"ltx_td ltx_align_center ltx_border_t\">16.97%</td>\n<td id=\"S4.T2.5.1.7.5.13\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">15.48%</td>\n</tr>\n<tr id=\"S4.T2.5.1.8.6\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">+ NS (Ours)</th>\n<td id=\"S4.T2.5.1.8.6.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.2.1\" class=\"ltx_text ltx_font_bold\">82.63%</span></td>\n<td id=\"S4.T2.5.1.8.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.3.1\" class=\"ltx_text ltx_font_bold\">82.47%</span></td>\n<td id=\"S4.T2.5.1.8.6.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.4.1\" class=\"ltx_text ltx_font_bold\">49.11%</span></td>\n<td id=\"S4.T2.5.1.8.6.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.5.1\" class=\"ltx_text ltx_font_bold\">48.32%</span></td>\n<td id=\"S4.T2.5.1.8.6.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.6.1\" class=\"ltx_text ltx_font_bold\">64.27%</span></td>\n<td id=\"S4.T2.5.1.8.6.7\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.7.1\" class=\"ltx_text ltx_font_bold\">63.04%</span></td>\n<td id=\"S4.T2.5.1.8.6.8\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.8.1\" class=\"ltx_text ltx_font_bold\">90.29%</span></td>\n<td id=\"S4.T2.5.1.8.6.9\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.9.1\" class=\"ltx_text ltx_font_bold\">91.57%</span></td>\n<td id=\"S4.T2.5.1.8.6.10\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.10.1\" class=\"ltx_text ltx_font_bold\">83.81%</span></td>\n<td id=\"S4.T2.5.1.8.6.11\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.11.1\" class=\"ltx_text ltx_font_bold\">80.50%</span></td>\n<td id=\"S4.T2.5.1.8.6.12\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.5.1.8.6.12.1\" class=\"ltx_text ltx_font_bold\">29.43%</span></td>\n<td id=\"S4.T2.5.1.8.6.13\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.5.1.8.6.13.1\" class=\"ltx_text ltx_font_bold\">27.46%</span></td>\n</tr>\n<tr id=\"S4.T2.5.1.9.7\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.9.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedNova<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">11</a>]</cite>\n</th>\n<td id=\"S4.T2.5.1.9.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">81.45%</td>\n<td id=\"S4.T2.5.1.9.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">82.16%</td>\n<td id=\"S4.T2.5.1.9.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">49.48%</td>\n<td id=\"S4.T2.5.1.9.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">48.24%</td>\n<td id=\"S4.T2.5.1.9.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\">55.36%</td>\n<td id=\"S4.T2.5.1.9.7.7\" class=\"ltx_td ltx_align_center ltx_border_t\">51.04%</td>\n<td id=\"S4.T2.5.1.9.7.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.5.1.9.7.8.1\" class=\"ltx_text ltx_font_bold\">90.65%</span></td>\n<td id=\"S4.T2.5.1.9.7.9\" class=\"ltx_td ltx_align_center ltx_border_t\">89.68%</td>\n<td id=\"S4.T2.5.1.9.7.10\" class=\"ltx_td ltx_align_center ltx_border_t\">73.54%</td>\n<td id=\"S4.T2.5.1.9.7.11\" class=\"ltx_td ltx_align_center ltx_border_t\">66.29%</td>\n<td id=\"S4.T2.5.1.9.7.12\" class=\"ltx_td ltx_align_center ltx_border_t\">28.62%</td>\n<td id=\"S4.T2.5.1.9.7.13\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">27.24%</td>\n</tr>\n<tr id=\"S4.T2.5.1.10.8\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.1.10.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">+ NS (Ours)</th>\n<td id=\"S4.T2.5.1.10.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.2.1\" class=\"ltx_text ltx_font_bold\">88.65%</span></td>\n<td id=\"S4.T2.5.1.10.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.3.1\" class=\"ltx_text ltx_font_bold\">88.34%</span></td>\n<td id=\"S4.T2.5.1.10.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.4.1\" class=\"ltx_text ltx_font_bold\">59.19%</span></td>\n<td id=\"S4.T2.5.1.10.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.5.1\" class=\"ltx_text ltx_font_bold\">59.17%</span></td>\n<td id=\"S4.T2.5.1.10.8.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.6.1\" class=\"ltx_text ltx_font_bold\">80.82%</span></td>\n<td id=\"S4.T2.5.1.10.8.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.7.1\" class=\"ltx_text ltx_font_bold\">81.89%</span></td>\n<td id=\"S4.T2.5.1.10.8.8\" class=\"ltx_td ltx_align_center ltx_border_bb\">90.57%</td>\n<td id=\"S4.T2.5.1.10.8.9\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.9.1\" class=\"ltx_text ltx_font_bold\">91.50%</span></td>\n<td id=\"S4.T2.5.1.10.8.10\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.10.1\" class=\"ltx_text ltx_font_bold\">93.31%</span></td>\n<td id=\"S4.T2.5.1.10.8.11\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.11.1\" class=\"ltx_text ltx_font_bold\">92.70%</span></td>\n<td id=\"S4.T2.5.1.10.8.12\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.12.1\" class=\"ltx_text ltx_font_bold\">48.50%</span></td>\n<td id=\"S4.T2.5.1.10.8.13\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S4.T2.5.1.10.8.13.1\" class=\"ltx_text ltx_font_bold\">46.16%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Participation of noisy clients deteriorates the performance of the global model. To validate the efficacy of our proposed method, we first conduct an experiment for model training with clean and noisy input across all the datasets and utilize the same noise configuration for our further empirical evaluation. With this, we aim to evaluate the upper-bound performance that can be achieved when learning from a mixture of noisy and clean clients. Table I presents the comparative results of average accuracy for all considered datasets. We focus on three specific distortions (i.e., defocus blur, Gaussian blur, contrast) due to their significant impact on degrading the model‚Äôs generalization capability to simulate the worst case in noisy FL.\nFor the generation of distorted data used in the experiments summarized in Table II, each noisy sample was produced by randomly selecting a distortion type with the configuration characterized by the noise severity level Œæ=h‚Äãi‚Äãg‚Äãhùúâ‚Ñéùëñùëî‚Ñé\\xi=high. We set the noise level to NLm=100%subscriptNLùëöpercent100\\emph{NL}_{m}=100\\% for every client mùëöm for the experiments of both Table II and Figure 6. We see the participation of noisy clients leads to a significant degradation in the model‚Äôs generalization capability across all tasks, indicating the detrimental impact of noisy data in the FL environment. Furthermore, due to the inherent lack of visibility into the data from these federated clients, the resultant global model tends to be of low quality and it may become challenging in a real-world setting to identify the underlying reasons for its poor performance.",
            "FedNS significantly improves standard federated aggregation methods. We investigate the robustness of our proposed method by applying FedNS on six image datasets with different settings under the noisy scenario. As shown in Table II, the performance of all aggregation methods exhibits a general trend of improvement by simply plugging FedNS to the considered strategies. In particular, we consider the worst-case with heterogeneous data setting in Table II, where 15 out of 20 noisy clients participate in the federated training with high noise severity and 100100100% noise level. Adding FedNS to FL strategies yields better overall performance among all the datasets, especially for some vulnerable datasets (e.g., Path-MNIST) that are sensitive to data corruption. Additionally, we demonstrate the efficacy of FedNS in dealing with patch-based noise on CIFAR-10 and Path-MNIST as presented in Figure 6. From Figure 6, we observe that FedNS consistently boosts the performance of the aggregation method across all the datasets and settings. This further shows that FedNS is capable of handling various types of noises a model can encounter in a real-world setting."
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: Top-1 accuracy of the ConvMixer-256/8 model using FedNova aggregation strategy in a high-noise environment.",
        "table": "<table id=\"S4.T3.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T3.5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Methods</span></th>\n<th id=\"S4.T3.5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T3.5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">CIFAR-10</span></th>\n<th id=\"S4.T3.5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T3.5.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">CIFAR-100</span></th>\n<th id=\"S4.T3.5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T3.5.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">PathMNIST</span></th>\n<th id=\"S4.T3.5.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T3.5.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">FMNIST</span></th>\n<th id=\"S4.T3.5.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T3.5.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">EuroSAT</span></th>\n<th id=\"S4.T3.5.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T3.5.1.1.1.7.1\" class=\"ltx_text ltx_font_bold\">Tiny-ImageNet</span></th>\n</tr>\n<tr id=\"S4.T3.5.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T3.5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T3.5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T3.5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T3.5.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T3.5.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.6.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T3.5.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.7.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T3.5.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.8.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T3.5.1.2.2.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.9.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T3.5.1.2.2.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.10.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T3.5.1.2.2.11\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.11.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T3.5.1.2.2.12\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T3.5.1.2.2.12.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.5.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedNova</th>\n<td id=\"S4.T3.5.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">71.76%</td>\n<td id=\"S4.T3.5.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">64.50%</td>\n<td id=\"S4.T3.5.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">37.31%</td>\n<td id=\"S4.T3.5.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">36.23%</td>\n<td id=\"S4.T3.5.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">54.15%</td>\n<td id=\"S4.T3.5.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">49.75%</td>\n<td id=\"S4.T3.5.1.3.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">84.43%</td>\n<td id=\"S4.T3.5.1.3.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">86.31%</td>\n<td id=\"S4.T3.5.1.3.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\">61.70%</td>\n<td id=\"S4.T3.5.1.3.1.11\" class=\"ltx_td ltx_align_center ltx_border_t\">56.28%</td>\n<td id=\"S4.T3.5.1.3.1.12\" class=\"ltx_td ltx_align_center ltx_border_t\">21.04%</td>\n<td id=\"S4.T3.5.1.3.1.13\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">19.43%</td>\n</tr>\n<tr id=\"S4.T3.5.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">+ NS (Ours)</th>\n<td id=\"S4.T3.5.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.2.1\" class=\"ltx_text ltx_font_bold\">77.05%</span></td>\n<td id=\"S4.T3.5.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.3.1\" class=\"ltx_text ltx_font_bold\">70.51%</span></td>\n<td id=\"S4.T3.5.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.4.1\" class=\"ltx_text ltx_font_bold\">44.17%</span></td>\n<td id=\"S4.T3.5.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.5.1\" class=\"ltx_text ltx_font_bold\">43.07%</span></td>\n<td id=\"S4.T3.5.1.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.6.1\" class=\"ltx_text ltx_font_bold\">79.76%</span></td>\n<td id=\"S4.T3.5.1.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.7.1\" class=\"ltx_text ltx_font_bold\">80.82%</span></td>\n<td id=\"S4.T3.5.1.4.2.8\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.8.1\" class=\"ltx_text ltx_font_bold\">85.68%</span></td>\n<td id=\"S4.T3.5.1.4.2.9\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.9.1\" class=\"ltx_text ltx_font_bold\">86.71%</span></td>\n<td id=\"S4.T3.5.1.4.2.10\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.10.1\" class=\"ltx_text ltx_font_bold\">88.59%</span></td>\n<td id=\"S4.T3.5.1.4.2.11\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.11.1\" class=\"ltx_text ltx_font_bold\">87.80%</span></td>\n<td id=\"S4.T3.5.1.4.2.12\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.12.1\" class=\"ltx_text ltx_font_bold\">33.66%</span></td>\n<td id=\"S4.T3.5.1.4.2.13\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S4.T3.5.1.4.2.13.1\" class=\"ltx_text ltx_font_bold\">31.80%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Baselines and Implementation. We apply FedNS¬†in conjunction with four widely used FL strategies to evaluate its effectiveness, namely FedAvg [2], FedProx [9], FedTrimmedAvg [10], and FedNova [11]. We employ ResNet-18 as the main model architecture, utilizing the mini-batch SGD as the universal local optimizer for all FL strategies. Moreover, we further evaluate FedNS¬†on a different neural architecture ConvMixer-256/8 in Table III. The optimizer is characterized by a learning rate of 0.010.010.01, an SGD momentum of 0.90.90.9, and the weight decay is set to 10‚àí4superscript10410^{-4}. We set the number of local training epochs to 555 and the global communication rounds to 150150150 across all datasets.\nWe consider a setup with N=20ùëÅ20N=20 clients for our experiments unless mentioned otherwise. This choice aligns with standard practices in FL and accommodates our computational limitations. The training set is distributed under both IID and non-IID settings. For the main experiments, we divide the client set into 151515 noisy clients and 555 clean clients, with full client participation rp=1.0subscriptùëüùëù1.0r_{p}=1.0. We compute L1subscriptùêø1L_{1}-norm of the gradient of last layer for noisy client detection in all the cases, see Table¬†IX(b) for comparison between the effectiveness of L1subscriptùêø1L_{1} and L2subscriptùêø2L_{2} norms, as well as the impact of batch size on the detection performance. We conducted all experiments on NVIDIA A10 GPUs.",
            "Evaluating FedNS¬†with alternative model architecture. In this experiment, we investigate the robustness of FedNS¬†when applied to a different model architecture. We employ the ConvMixer-256/8 [46] model and train it using FedNova on a range of datasets. The noise configuration remains consistent with the details provided in Section IV-B, and we evaluate the model‚Äôs performance under both IID and non-IID settings. As shown in Table III, the federated aggregation method, when paired with FedNS, achieves enhanced performance across all considered datasets. These improvements, observed consistently across tasks, demonstrate the adaptability and effectiveness of FedNS¬†when integrated with alternative architectural paradigms. The results highlight the versatility of our approach in enhancing the performance of different federated model regardless of the neural architecture, further emphasizing its potential as a robust and flexible method for FL."
        ]
    },
    "S4.T4": {
        "caption": "TABLE IV: Top-1 accuracy of the FedNova aggregation method (+FedNS) in an IID setting on selected datasets when noisy clients‚Äô data is a mixture of all noise types.",
        "table": "<table id=\"S4.T4.4.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.4.4.5.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T4.4.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\">Noise Setting</span></th>\n<th id=\"S4.T4.4.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T4.4.4.5.1.2.1\" class=\"ltx_text ltx_font_bold\">Clean</span></th>\n<th id=\"S4.T4.4.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T4.4.4.5.1.3.1\" class=\"ltx_text ltx_font_bold\">Noisy</span></th>\n</tr>\n<tr id=\"S4.T4.4.4.6.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.4.6.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"S4.T4.4.4.6.2.1.1\" class=\"ltx_text ltx_font_bold\">Methods</span></th>\n<th id=\"S4.T4.4.4.6.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T4.4.4.6.2.2.1\" class=\"ltx_text ltx_font_bold\">FedNova</span></th>\n<th id=\"S4.T4.4.4.6.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T4.4.4.6.2.3.1\" class=\"ltx_text ltx_font_bold\">FedNova</span></th>\n<th id=\"S4.T4.4.4.6.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T4.4.4.6.2.4.1\" class=\"ltx_text ltx_font_bold\">FedNova+NS</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">CIFAR-10</td>\n<td id=\"S4.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">90.14%</td>\n<td id=\"S4.T4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">80.10%</td>\n<td id=\"S4.T4.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">85.83% (<math id=\"S4.T4.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T4.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.1.1.1.1.m1.1.1\" xref=\"S4.T4.1.1.1.1.m1.1.1.cmml\">‚Üë</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.1.1.1.1.m1.1b\"><ci id=\"S4.T4.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T4.1.1.1.1.m1.1.1\">‚Üë</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.1.1.1.1.m1.1c\">\\uparrow</annotation></semantics></math><span id=\"S4.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\"> 5.73%</span>)</td>\n</tr>\n<tr id=\"S4.T4.2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">CIFAR-100</td>\n<td id=\"S4.T4.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">64.79%</td>\n<td id=\"S4.T4.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">45.28%</td>\n<td id=\"S4.T4.2.2.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">51.47% (<math id=\"S4.T4.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T4.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.2.2.2.1.m1.1.1\" xref=\"S4.T4.2.2.2.1.m1.1.1.cmml\">‚Üë</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.2.2.2.1.m1.1b\"><ci id=\"S4.T4.2.2.2.1.m1.1.1.cmml\" xref=\"S4.T4.2.2.2.1.m1.1.1\">‚Üë</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math><span id=\"S4.T4.2.2.2.1.1\" class=\"ltx_text ltx_font_bold\"> 6.19%</span>)</td>\n</tr>\n<tr id=\"S4.T4.3.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.3.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Path-MNIST</td>\n<td id=\"S4.T4.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">92.34%</td>\n<td id=\"S4.T4.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">65.19%</td>\n<td id=\"S4.T4.3.3.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">87.81% (<math id=\"S4.T4.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T4.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.3.3.3.1.m1.1.1\" xref=\"S4.T4.3.3.3.1.m1.1.1.cmml\">‚Üë</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.3.3.3.1.m1.1b\"><ci id=\"S4.T4.3.3.3.1.m1.1.1.cmml\" xref=\"S4.T4.3.3.3.1.m1.1.1\">‚Üë</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math><span id=\"S4.T4.3.3.3.1.1\" class=\"ltx_text ltx_font_bold\"> 22.62%</span>)</td>\n</tr>\n<tr id=\"S4.T4.4.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T4.4.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">Tiny-ImageNet</td>\n<td id=\"S4.T4.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">53.26%</td>\n<td id=\"S4.T4.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">29.26%</td>\n<td id=\"S4.T4.4.4.4.1\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\">43.30% (<math id=\"S4.T4.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T4.4.4.4.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.4.4.4.1.m1.1.1\" xref=\"S4.T4.4.4.4.1.m1.1.1.cmml\">‚Üë</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.4.4.4.1.m1.1b\"><ci id=\"S4.T4.4.4.4.1.m1.1.1.cmml\" xref=\"S4.T4.4.4.4.1.m1.1.1\">‚Üë</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.4.4.4.1.m1.1c\">\\uparrow</annotation></semantics></math><span id=\"S4.T4.4.4.4.1.1\" class=\"ltx_text ltx_font_bold\"> 14.04%</span>)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Robustness of FedNS¬†on mixed noise conditions. Next, we investigate the robustness of FedNS¬†under complex noise conditions that involve a combination of different noise types, including the distortions and patch-based noises as described in Section IV-A. Table IV shows the performance gains achieved by FedNS¬†are particularly significant in high-variance datasets such as Path-MNIST and Tiny-ImageNet, where FedNova+NS demonstrates substantial improvements over standard aggregation. Notably, FedNS¬†consistently enhances the global model‚Äôs performance across all evaluated datasets, showcasing its robustness in handling intricate noise scenarios. Our results highlight the effectiveness of FedNS¬†in mitigating the impact of complex noise conditions, where decentralized data may be subject to various types of distortions at the same time."
        ]
    },
    "S4.T5": {
        "caption": "TABLE V: Ablation on the weight factor Œ≤ùõΩ\\beta for noisy clients. We evaluate this parameter on the CIFAR-10 dataset with IID and non-IID settings, and the weight factor of clean clients Œ±ùõº\\alpha is set to 2.02.02.0.",
        "table": "<table id=\"S4.T5.13.7\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.7.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.7.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T5.7.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Setting</span></th>\n<td id=\"S4.T5.7.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"6\"><span id=\"S4.T5.7.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Weight Factor <math id=\"S4.T5.7.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\beta\" display=\"inline\"><semantics id=\"S4.T5.7.1.1.1.1.m1.1a\"><mi id=\"S4.T5.7.1.1.1.1.m1.1.1\" xref=\"S4.T5.7.1.1.1.1.m1.1.1.cmml\">Œ≤</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.7.1.1.1.1.m1.1b\"><ci id=\"S4.T5.7.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T5.7.1.1.1.1.m1.1.1\">ùõΩ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.7.1.1.1.1.m1.1c\">\\beta</annotation></semantics></math> of Noisy Client</span></td>\n</tr>\n<tr id=\"S4.T5.13.7.7\" class=\"ltx_tr\">\n<td id=\"S4.T5.8.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T5.8.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{0.0}\" display=\"inline\"><semantics id=\"S4.T5.8.2.2.1.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T5.8.2.2.1.m1.1.1\" xref=\"S4.T5.8.2.2.1.m1.1.1.cmml\">0.0</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.8.2.2.1.m1.1b\"><cn type=\"float\" id=\"S4.T5.8.2.2.1.m1.1.1.cmml\" xref=\"S4.T5.8.2.2.1.m1.1.1\">0.0</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.8.2.2.1.m1.1c\">\\mathbf{0.0}</annotation></semantics></math></td>\n<td id=\"S4.T5.9.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T5.9.3.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{0.1}\" display=\"inline\"><semantics id=\"S4.T5.9.3.3.2.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T5.9.3.3.2.m1.1.1\" xref=\"S4.T5.9.3.3.2.m1.1.1.cmml\">0.1</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.9.3.3.2.m1.1b\"><cn type=\"float\" id=\"S4.T5.9.3.3.2.m1.1.1.cmml\" xref=\"S4.T5.9.3.3.2.m1.1.1\">0.1</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.9.3.3.2.m1.1c\">\\mathbf{0.1}</annotation></semantics></math></td>\n<td id=\"S4.T5.10.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T5.10.4.4.3.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{0.3}\" display=\"inline\"><semantics id=\"S4.T5.10.4.4.3.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T5.10.4.4.3.m1.1.1\" xref=\"S4.T5.10.4.4.3.m1.1.1.cmml\">0.3</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.10.4.4.3.m1.1b\"><cn type=\"float\" id=\"S4.T5.10.4.4.3.m1.1.1.cmml\" xref=\"S4.T5.10.4.4.3.m1.1.1\">0.3</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.10.4.4.3.m1.1c\">\\mathbf{0.3}</annotation></semantics></math></td>\n<td id=\"S4.T5.11.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T5.11.5.5.4.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{0.5}\" display=\"inline\"><semantics id=\"S4.T5.11.5.5.4.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T5.11.5.5.4.m1.1.1\" xref=\"S4.T5.11.5.5.4.m1.1.1.cmml\">0.5</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.11.5.5.4.m1.1b\"><cn type=\"float\" id=\"S4.T5.11.5.5.4.m1.1.1.cmml\" xref=\"S4.T5.11.5.5.4.m1.1.1\">0.5</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.11.5.5.4.m1.1c\">\\mathbf{0.5}</annotation></semantics></math></td>\n<td id=\"S4.T5.12.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T5.12.6.6.5.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{0.7}\" display=\"inline\"><semantics id=\"S4.T5.12.6.6.5.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T5.12.6.6.5.m1.1.1\" xref=\"S4.T5.12.6.6.5.m1.1.1.cmml\">0.7</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.12.6.6.5.m1.1b\"><cn type=\"float\" id=\"S4.T5.12.6.6.5.m1.1.1.cmml\" xref=\"S4.T5.12.6.6.5.m1.1.1\">0.7</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.12.6.6.5.m1.1c\">\\mathbf{0.7}</annotation></semantics></math></td>\n<td id=\"S4.T5.13.7.7.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><math id=\"S4.T5.13.7.7.6.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{1.0}\" display=\"inline\"><semantics id=\"S4.T5.13.7.7.6.m1.1a\"><mn class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" id=\"S4.T5.13.7.7.6.m1.1.1\" xref=\"S4.T5.13.7.7.6.m1.1.1.cmml\">1.0</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.13.7.7.6.m1.1b\"><cn type=\"float\" id=\"S4.T5.13.7.7.6.m1.1.1.cmml\" xref=\"S4.T5.13.7.7.6.m1.1.1\">1.0</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.13.7.7.6.m1.1c\">\\mathbf{1.0}</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T5.13.7.8.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.13.7.8.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">IID</th>\n<td id=\"S4.T5.13.7.8.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">82.82</td>\n<td id=\"S4.T5.13.7.8.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">87.17</td>\n<td id=\"S4.T5.13.7.8.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">88.65</td>\n<td id=\"S4.T5.13.7.8.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">87.53</td>\n<td id=\"S4.T5.13.7.8.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">86.28</td>\n<td id=\"S4.T5.13.7.8.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">84.33</td>\n</tr>\n<tr id=\"S4.T5.13.7.9.2\" class=\"ltx_tr\">\n<th id=\"S4.T5.13.7.9.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">non-IID</th>\n<td id=\"S4.T5.13.7.9.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">75.31</td>\n<td id=\"S4.T5.13.7.9.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">82.49</td>\n<td id=\"S4.T5.13.7.9.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">88.34</td>\n<td id=\"S4.T5.13.7.9.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">84.05</td>\n<td id=\"S4.T5.13.7.9.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">83.44</td>\n<td id=\"S4.T5.13.7.9.2.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">81.27</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Evaluation on Weight Factor(Œ≤ùõΩ\\beta) of Noisy Client. We further investigate the effect of weight factor Œ≤ùõΩ\\beta on overall performance in FedNS. The weight factor Œ≤ùõΩ\\beta controls the weights of aggregated noisy client local models, as described in Equation 6. We considered various values of Œ≤‚àà{0,0.1,0.3,0.5,0.7,1.0}ùõΩ00.10.30.50.71.0\\beta\\in\\{0,0.1,0.3,0.5,0.7,1.0\\}, where Œ≤=0ùõΩ0\\beta=0 signifies the exclusion of noisy model weights, and Œ≤=1.0ùõΩ1.0\\beta=1.0 indicates the direct aggregation of model weights. As shown in Table V, the setting of Œ≤=0.3ùõΩ0.3\\beta=0.3 yields the best performance, suggesting an optimal trade-off. Interestingly, the exclusion of noisy model weights (Œ≤=0.0ùõΩ0.0\\beta=0.0) leads to a degradation in the generalization capability of the global model. This observation suggests that incorporating mitigated noisy data enhances the robustness of the global model."
        ]
    },
    "S4.T6": {
        "caption": "TABLE VI: Performance of FedNS on datasets with noisy labels. We evaluate FedNS on CIFAR-10/100N [45] datasets.",
        "table": "<table id=\"S4.T6.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T6.5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T6.5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T6.5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Methods</span></th>\n<th id=\"S4.T6.5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T6.5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">CIFAR-10N</span></th>\n<th id=\"S4.T6.5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S4.T6.5.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">CIFAR-100N</span></th>\n</tr>\n<tr id=\"S4.T6.5.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T6.5.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T6.5.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T6.5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T6.5.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n<th id=\"S4.T6.5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T6.5.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">IID</span></th>\n<th id=\"S4.T6.5.1.2.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T6.5.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">Non-IID</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T6.5.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T6.5.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedAvg</th>\n<td id=\"S4.T6.5.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">76.06%</td>\n<td id=\"S4.T6.5.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">69.52%</td>\n<td id=\"S4.T6.5.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">52.61%</td>\n<td id=\"S4.T6.5.1.3.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">52.57%</td>\n</tr>\n<tr id=\"S4.T6.5.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T6.5.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">+ NS (Ours)</th>\n<td id=\"S4.T6.5.1.4.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T6.5.1.4.2.2.1\" class=\"ltx_text ltx_font_bold\">78.87%</span></td>\n<td id=\"S4.T6.5.1.4.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T6.5.1.4.2.3.1\" class=\"ltx_text ltx_font_bold\">71.14%</span></td>\n<td id=\"S4.T6.5.1.4.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T6.5.1.4.2.4.1\" class=\"ltx_text ltx_font_bold\">54.06%</span></td>\n<td id=\"S4.T6.5.1.4.2.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T6.5.1.4.2.5.1\" class=\"ltx_text ltx_font_bold\">53.85%</span></td>\n</tr>\n<tr id=\"S4.T6.5.1.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T6.5.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedNova</th>\n<td id=\"S4.T6.5.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">76.06%</td>\n<td id=\"S4.T6.5.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">69.26%</td>\n<td id=\"S4.T6.5.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">53.32%</td>\n<td id=\"S4.T6.5.1.5.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">52.41%</td>\n</tr>\n<tr id=\"S4.T6.5.1.6.4\" class=\"ltx_tr\">\n<th id=\"S4.T6.5.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">+ NS (Ours)</th>\n<td id=\"S4.T6.5.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T6.5.1.6.4.2.1\" class=\"ltx_text ltx_font_bold\">84.38%</span></td>\n<td id=\"S4.T6.5.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T6.5.1.6.4.3.1\" class=\"ltx_text ltx_font_bold\">78.65%</span></td>\n<td id=\"S4.T6.5.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T6.5.1.6.4.4.1\" class=\"ltx_text ltx_font_bold\">55.54%</span></td>\n<td id=\"S4.T6.5.1.6.4.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S4.T6.5.1.6.4.5.1\" class=\"ltx_text ltx_font_bold\">54.80%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "FedNS on Real-world Human Annotation Errors. In this experiment, we extend our investigation to assess the efficacy of FedNS in addressing real-world data quality issues, specifically human annotation errors. While this work focuses on mitigating data corruption in the input space, we identify that FedNS can effectively handle label noise - a well-studied problem in noisy FL. Label noise occurs when data labels are incorrectly assigned while the input features remain unaltered. Specifically, we assessed FedNS on CIFAR-10/100N, two benchmark datasets featuring real-world noisy labels resulting from human annotation errors [45]. We employed FedAvg and FedNova as baseline approaches, adhering to the training configuration outlined in Section IV-A. From Table VI, we observe that FedNS consistently improved the performance across all the experiments. Our findings demonstrate that FedNS not only excels in mitigating input space corruption but also shows promising results in handling label noise. The ability to address both input space corruption and label noise positions FedNS as a valuable tool for practitioners dealing with real-world datasets, where multiple types of data imperfections may coexist."
        ]
    },
    "S4.T7": {
        "caption": "TABLE VII: FedNS performance on CIFAR-10 and CIFAR-100: Classification accuracy with 10%, 50%, and 100% client participation in the first round, i.e., partially warmed-up clients.",
        "table": "<table id=\"S4.T7.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T7.5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T7.5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T7.5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Methods</span></th>\n<th id=\"S4.T7.5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\"><span id=\"S4.T7.5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">CIFAR-10</span></th>\n<th id=\"S4.T7.5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\"><span id=\"S4.T7.5.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">CIFAR-100</span></th>\n</tr>\n<tr id=\"S4.T7.5.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T7.5.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\"><span id=\"S4.T7.5.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">First-Round Participation</span></th>\n<th id=\"S4.T7.5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T7.5.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">10%</span></th>\n<th id=\"S4.T7.5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T7.5.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">50%</span></th>\n<th id=\"S4.T7.5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T7.5.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">100%</span></th>\n<th id=\"S4.T7.5.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T7.5.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">10%</span></th>\n<th id=\"S4.T7.5.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T7.5.1.2.2.6.1\" class=\"ltx_text ltx_font_bold\">50%</span></th>\n<th id=\"S4.T7.5.1.2.2.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T7.5.1.2.2.7.1\" class=\"ltx_text ltx_font_bold\">100%</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T7.5.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T7.5.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedNova</th>\n<td id=\"S4.T7.5.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">80.46%</td>\n<td id=\"S4.T7.5.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">81.14%</td>\n<td id=\"S4.T7.5.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">81.45%</td>\n<td id=\"S4.T7.5.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">48.63%</td>\n<td id=\"S4.T7.5.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">48.46%</td>\n<td id=\"S4.T7.5.1.3.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">49.48%</td>\n</tr>\n<tr id=\"S4.T7.5.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T7.5.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">+ NS (Ours)</th>\n<td id=\"S4.T7.5.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T7.5.1.4.2.2.1\" class=\"ltx_text ltx_font_bold\">86.13%</span></td>\n<td id=\"S4.T7.5.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T7.5.1.4.2.3.1\" class=\"ltx_text ltx_font_bold\">86.76%</span></td>\n<td id=\"S4.T7.5.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T7.5.1.4.2.4.1\" class=\"ltx_text ltx_font_bold\">88.65%</span></td>\n<td id=\"S4.T7.5.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T7.5.1.4.2.5.1\" class=\"ltx_text ltx_font_bold\">54.13%</span></td>\n<td id=\"S4.T7.5.1.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T7.5.1.4.2.6.1\" class=\"ltx_text ltx_font_bold\">54.27%</span></td>\n<td id=\"S4.T7.5.1.4.2.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S4.T7.5.1.4.2.7.1\" class=\"ltx_text ltx_font_bold\">59.19%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Impact of Initial-Round Client Participation on FedNS Performance. In FL, the assumption that all clients must be warmed up and participate from the very first training round may not always hold true, as some clients may only participate in later rounds. To address this, we explore the scenario where only a subset of clients participates in the initial round. Instead of collecting gradient norms solely in the first round, we iteratively apply FedNS until all clients have been engaged. We evaluate this approach by setting the first-round participation rates to 10%, 50%, and 100%, with 100% representing full client participation. The results, presented in Table VII, highlight the robustness of FedNS across varying levels of initial-round client participation."
        ]
    },
    "S4.T8": {
        "caption": "TABLE VIII: Ablation for different noise level and noise severity with IID setting on CIFAR-10/100 datasets. We employ FedNova as the aggregation method and ablate the noise level and noise severity.",
        "table": "<table id=\"S4.T8.st1.4.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T8.st1.4.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T8.st1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T8.st1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Noise Level(<span id=\"S4.T8.st1.1.1.1.1.1.1\" class=\"ltx_text ltx_markedasmath ltx_font_italic\">NL</span>)</span></th>\n<th id=\"S4.T8.st1.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><math id=\"S4.T8.st1.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\emph{NL}=\\mathbf{50}\\textbf{\\%}\" display=\"inline\"><semantics id=\"S4.T8.st1.2.2.2.2.m1.1a\"><mrow id=\"S4.T8.st1.2.2.2.2.m1.1.1\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.2\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.2b.cmml\"><em id=\"S4.T8.st1.2.2.2.2.m1.1.1.2.1nest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext><mo id=\"S4.T8.st1.2.2.2.2.m1.1.1.1\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.1.cmml\">=</mo><mrow id=\"S4.T8.st1.2.2.2.2.m1.1.1.3\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.cmml\"><mn id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.2\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.2.cmml\">ùüìùüé</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.1\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.1.cmml\">‚Äã</mo><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3a.cmml\">%</mtext></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.st1.2.2.2.2.m1.1b\"><apply id=\"S4.T8.st1.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1\"><eq id=\"S4.T8.st1.2.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.1\"></eq><ci id=\"S4.T8.st1.2.2.2.2.m1.1.1.2b.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.2\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.2\"><em id=\"S4.T8.st1.2.2.2.2.m1.1.1.2.1anest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext></ci><apply id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3\"><times id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.1.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.1\"></times><cn type=\"integer\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.2.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.2\">50</cn><ci id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3a.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3\">%</mtext></ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T8.st1.2.2.2.2.m1.1c\">\\emph{NL}=\\mathbf{50}\\textbf{\\%}</annotation></semantics></math></th>\n<th id=\"S4.T8.st1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><math id=\"S4.T8.st1.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\emph{NL}=\\mathbf{80}\\textbf{\\%}\" display=\"inline\"><semantics id=\"S4.T8.st1.3.3.3.3.m1.1a\"><mrow id=\"S4.T8.st1.3.3.3.3.m1.1.1\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.2\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.2b.cmml\"><em id=\"S4.T8.st1.3.3.3.3.m1.1.1.2.1nest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext><mo id=\"S4.T8.st1.3.3.3.3.m1.1.1.1\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.1.cmml\">=</mo><mrow id=\"S4.T8.st1.3.3.3.3.m1.1.1.3\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.cmml\"><mn id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.2\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.2.cmml\">ùüñùüé</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.1\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.1.cmml\">‚Äã</mo><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3a.cmml\">%</mtext></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.st1.3.3.3.3.m1.1b\"><apply id=\"S4.T8.st1.3.3.3.3.m1.1.1.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1\"><eq id=\"S4.T8.st1.3.3.3.3.m1.1.1.1.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.1\"></eq><ci id=\"S4.T8.st1.3.3.3.3.m1.1.1.2b.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.2\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.2.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.2\"><em id=\"S4.T8.st1.3.3.3.3.m1.1.1.2.1anest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext></ci><apply id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3\"><times id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.1.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.1\"></times><cn type=\"integer\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.2.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.2\">80</cn><ci id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3a.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3\">%</mtext></ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T8.st1.3.3.3.3.m1.1c\">\\emph{NL}=\\mathbf{80}\\textbf{\\%}</annotation></semantics></math></th>\n<th id=\"S4.T8.st1.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><math id=\"S4.T8.st1.4.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\emph{NL}=\\mathbf{100}\\textbf{\\%}\" display=\"inline\"><semantics id=\"S4.T8.st1.4.4.4.4.m1.1a\"><mrow id=\"S4.T8.st1.4.4.4.4.m1.1.1\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.2\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.2b.cmml\"><em id=\"S4.T8.st1.4.4.4.4.m1.1.1.2.1nest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext><mo id=\"S4.T8.st1.4.4.4.4.m1.1.1.1\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.1.cmml\">=</mo><mrow id=\"S4.T8.st1.4.4.4.4.m1.1.1.3\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.cmml\"><mn id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.2\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.2.cmml\">ùüèùüéùüé</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.1\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.1.cmml\">‚Äã</mo><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3a.cmml\">%</mtext></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.st1.4.4.4.4.m1.1b\"><apply id=\"S4.T8.st1.4.4.4.4.m1.1.1.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1\"><eq id=\"S4.T8.st1.4.4.4.4.m1.1.1.1.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.1\"></eq><ci id=\"S4.T8.st1.4.4.4.4.m1.1.1.2b.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.2\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.2.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.2\"><em id=\"S4.T8.st1.4.4.4.4.m1.1.1.2.1anest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext></ci><apply id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3\"><times id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.1.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.1\"></times><cn type=\"integer\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.2.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.2\">100</cn><ci id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3a.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3\">%</mtext></ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T8.st1.4.4.4.4.m1.1c\">\\emph{NL}=\\mathbf{100}\\textbf{\\%}</annotation></semantics></math></th>\n</tr>\n<tr id=\"S4.T8.st1.4.4.5.1\" class=\"ltx_tr\">\n<th id=\"S4.T8.st1.4.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\"><span id=\"S4.T8.st1.4.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\">Noise Severity</span></th>\n<th id=\"S4.T8.st1.4.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Medium</th>\n<th id=\"S4.T8.st1.4.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">High</th>\n<th id=\"S4.T8.st1.4.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Medium</th>\n<th id=\"S4.T8.st1.4.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">High</th>\n<th id=\"S4.T8.st1.4.4.5.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Medium</th>\n<th id=\"S4.T8.st1.4.4.5.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\">High</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T8.st1.4.4.6.1\" class=\"ltx_tr\">\n<th id=\"S4.T8.st1.4.4.6.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedNova</th>\n<td id=\"S4.T8.st1.4.4.6.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">89.95%</td>\n<td id=\"S4.T8.st1.4.4.6.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">89.02%</td>\n<td id=\"S4.T8.st1.4.4.6.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">90.02%</td>\n<td id=\"S4.T8.st1.4.4.6.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">88.90%</td>\n<td id=\"S4.T8.st1.4.4.6.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">87.95%</td>\n<td id=\"S4.T8.st1.4.4.6.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">81.45%</td>\n</tr>\n<tr id=\"S4.T8.st1.4.4.7.2\" class=\"ltx_tr\">\n<th id=\"S4.T8.st1.4.4.7.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">+ NS (Ours)</th>\n<td id=\"S4.T8.st1.4.4.7.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.2.1\" class=\"ltx_text ltx_font_bold\">90.56%</span></td>\n<td id=\"S4.T8.st1.4.4.7.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.3.1\" class=\"ltx_text ltx_font_bold\">90.11%</span></td>\n<td id=\"S4.T8.st1.4.4.7.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.4.1\" class=\"ltx_text ltx_font_bold\">90.35%</span></td>\n<td id=\"S4.T8.st1.4.4.7.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.5.1\" class=\"ltx_text ltx_font_bold\">90.12%</span></td>\n<td id=\"S4.T8.st1.4.4.7.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.6.1\" class=\"ltx_text ltx_font_bold\">90.35%</span></td>\n<td id=\"S4.T8.st1.4.4.7.2.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.7.1\" class=\"ltx_text ltx_font_bold\">88.65%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "FedNS on Different Noise Level (NL) of Client Data. In Table VIII, we examine the performance of FedNS¬†across various noise configurations. Specifically, we consider noise levels NL‚àà{50%,80%,100%}NLpercent50percent80percent100\\emph{NL}\\in\\{50\\%,80\\%,100\\%\\} and noise severity Œæ‚àà{M‚Äãe‚Äãd‚Äãi‚Äãu‚Äãm,H‚Äãi‚Äãg‚Äãh}ùúâùëÄùëíùëëùëñùë¢ùëöùêªùëñùëî‚Ñé\\xi\\in\\{Medium,High\\}. These results demonstrate that FedNS¬†substantially enhances model generalization under high noise conditions, especially when clients‚Äô data is completely corrupted (i.e., 100100100% noise level and high severity). Conversely, in scenarios with milder noise where the impact on federated models is minimal, the implementation of FedNS¬†does not negatively affect the generalization process. Hence, we limit our experiments to noise levels at or above 50%, as noise levels below this threshold have negligible impact on model performance."
        ]
    },
    "S4.T8.st1": {
        "caption": "(a) CIFAR-10",
        "table": "<table id=\"S4.T8.st1.4.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T8.st1.4.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T8.st1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T8.st1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Noise Level(<span id=\"S4.T8.st1.1.1.1.1.1.1\" class=\"ltx_text ltx_markedasmath ltx_font_italic\">NL</span>)</span></th>\n<th id=\"S4.T8.st1.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><math id=\"S4.T8.st1.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\emph{NL}=\\mathbf{50}\\textbf{\\%}\" display=\"inline\"><semantics id=\"S4.T8.st1.2.2.2.2.m1.1a\"><mrow id=\"S4.T8.st1.2.2.2.2.m1.1.1\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.2\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.2b.cmml\"><em id=\"S4.T8.st1.2.2.2.2.m1.1.1.2.1nest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext><mo id=\"S4.T8.st1.2.2.2.2.m1.1.1.1\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.1.cmml\">=</mo><mrow id=\"S4.T8.st1.2.2.2.2.m1.1.1.3\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.cmml\"><mn id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.2\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.2.cmml\">ùüìùüé</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.1\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.1.cmml\">‚Äã</mo><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3a.cmml\">%</mtext></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.st1.2.2.2.2.m1.1b\"><apply id=\"S4.T8.st1.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1\"><eq id=\"S4.T8.st1.2.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.1\"></eq><ci id=\"S4.T8.st1.2.2.2.2.m1.1.1.2b.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.2\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.2\"><em id=\"S4.T8.st1.2.2.2.2.m1.1.1.2.1anest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext></ci><apply id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3\"><times id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.1.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.1\"></times><cn type=\"integer\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.2.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.2\">50</cn><ci id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3a.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3.cmml\" xref=\"S4.T8.st1.2.2.2.2.m1.1.1.3.3\">%</mtext></ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T8.st1.2.2.2.2.m1.1c\">\\emph{NL}=\\mathbf{50}\\textbf{\\%}</annotation></semantics></math></th>\n<th id=\"S4.T8.st1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><math id=\"S4.T8.st1.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\emph{NL}=\\mathbf{80}\\textbf{\\%}\" display=\"inline\"><semantics id=\"S4.T8.st1.3.3.3.3.m1.1a\"><mrow id=\"S4.T8.st1.3.3.3.3.m1.1.1\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.2\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.2b.cmml\"><em id=\"S4.T8.st1.3.3.3.3.m1.1.1.2.1nest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext><mo id=\"S4.T8.st1.3.3.3.3.m1.1.1.1\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.1.cmml\">=</mo><mrow id=\"S4.T8.st1.3.3.3.3.m1.1.1.3\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.cmml\"><mn id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.2\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.2.cmml\">ùüñùüé</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.1\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.1.cmml\">‚Äã</mo><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3a.cmml\">%</mtext></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.st1.3.3.3.3.m1.1b\"><apply id=\"S4.T8.st1.3.3.3.3.m1.1.1.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1\"><eq id=\"S4.T8.st1.3.3.3.3.m1.1.1.1.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.1\"></eq><ci id=\"S4.T8.st1.3.3.3.3.m1.1.1.2b.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.2\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.2.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.2\"><em id=\"S4.T8.st1.3.3.3.3.m1.1.1.2.1anest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext></ci><apply id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3\"><times id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.1.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.1\"></times><cn type=\"integer\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.2.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.2\">80</cn><ci id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3a.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3.cmml\" xref=\"S4.T8.st1.3.3.3.3.m1.1.1.3.3\">%</mtext></ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T8.st1.3.3.3.3.m1.1c\">\\emph{NL}=\\mathbf{80}\\textbf{\\%}</annotation></semantics></math></th>\n<th id=\"S4.T8.st1.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><math id=\"S4.T8.st1.4.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\emph{NL}=\\mathbf{100}\\textbf{\\%}\" display=\"inline\"><semantics id=\"S4.T8.st1.4.4.4.4.m1.1a\"><mrow id=\"S4.T8.st1.4.4.4.4.m1.1.1\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.2\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.2b.cmml\"><em id=\"S4.T8.st1.4.4.4.4.m1.1.1.2.1nest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext><mo id=\"S4.T8.st1.4.4.4.4.m1.1.1.1\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.1.cmml\">=</mo><mrow id=\"S4.T8.st1.4.4.4.4.m1.1.1.3\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.cmml\"><mn id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.2\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.2.cmml\">ùüèùüéùüé</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.1\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.1.cmml\">‚Äã</mo><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3a.cmml\">%</mtext></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.st1.4.4.4.4.m1.1b\"><apply id=\"S4.T8.st1.4.4.4.4.m1.1.1.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1\"><eq id=\"S4.T8.st1.4.4.4.4.m1.1.1.1.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.1\"></eq><ci id=\"S4.T8.st1.4.4.4.4.m1.1.1.2b.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.2\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.2.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.2\"><em id=\"S4.T8.st1.4.4.4.4.m1.1.1.2.1anest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext></ci><apply id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3\"><times id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.1.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.1\"></times><cn type=\"integer\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.2.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.2\">100</cn><ci id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3a.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3.cmml\" xref=\"S4.T8.st1.4.4.4.4.m1.1.1.3.3\">%</mtext></ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T8.st1.4.4.4.4.m1.1c\">\\emph{NL}=\\mathbf{100}\\textbf{\\%}</annotation></semantics></math></th>\n</tr>\n<tr id=\"S4.T8.st1.4.4.5.1\" class=\"ltx_tr\">\n<th id=\"S4.T8.st1.4.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\"><span id=\"S4.T8.st1.4.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\">Noise Severity</span></th>\n<th id=\"S4.T8.st1.4.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Medium</th>\n<th id=\"S4.T8.st1.4.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">High</th>\n<th id=\"S4.T8.st1.4.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Medium</th>\n<th id=\"S4.T8.st1.4.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">High</th>\n<th id=\"S4.T8.st1.4.4.5.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Medium</th>\n<th id=\"S4.T8.st1.4.4.5.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\">High</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T8.st1.4.4.6.1\" class=\"ltx_tr\">\n<th id=\"S4.T8.st1.4.4.6.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedNova</th>\n<td id=\"S4.T8.st1.4.4.6.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">89.95%</td>\n<td id=\"S4.T8.st1.4.4.6.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">89.02%</td>\n<td id=\"S4.T8.st1.4.4.6.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">90.02%</td>\n<td id=\"S4.T8.st1.4.4.6.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">88.90%</td>\n<td id=\"S4.T8.st1.4.4.6.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">87.95%</td>\n<td id=\"S4.T8.st1.4.4.6.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">81.45%</td>\n</tr>\n<tr id=\"S4.T8.st1.4.4.7.2\" class=\"ltx_tr\">\n<th id=\"S4.T8.st1.4.4.7.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">+ NS (Ours)</th>\n<td id=\"S4.T8.st1.4.4.7.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.2.1\" class=\"ltx_text ltx_font_bold\">90.56%</span></td>\n<td id=\"S4.T8.st1.4.4.7.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.3.1\" class=\"ltx_text ltx_font_bold\">90.11%</span></td>\n<td id=\"S4.T8.st1.4.4.7.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.4.1\" class=\"ltx_text ltx_font_bold\">90.35%</span></td>\n<td id=\"S4.T8.st1.4.4.7.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.5.1\" class=\"ltx_text ltx_font_bold\">90.12%</span></td>\n<td id=\"S4.T8.st1.4.4.7.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.6.1\" class=\"ltx_text ltx_font_bold\">90.35%</span></td>\n<td id=\"S4.T8.st1.4.4.7.2.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st1.4.4.7.2.7.1\" class=\"ltx_text ltx_font_bold\">88.65%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Recent works in FL mainly focus on addressing the data quality issues pertaining to the label space. Many strategies have been developed to deal with the disparity of label quality in FL. These methods mitigate the impact of label noise by conducting either client selection to re-weight model updates [22, 23, 24] or data sampling for label correction or exclusion [25, 26, 27, 28, 29]. Additionally, other works tackle this challenge by correcting the label error. [28] perform label noise correction using consensus-derived class-wise information for dynamic noise identification and label correction. [26] tackles label noise in federated learning by updating local models with globally aligned centroids and correcting labels through global model insights. In spite of the progress that has been made in resolving label noise, data subset selection¬†[7], data valuation¬†[30, 31], dealing with low-quality data in input space (i.e., when noise is in the samples like in images) in the federated setting still remains unexplored. Furthermore, we recognize that client data may be susceptible to backdoor attacks via adversarial methods during both inference and training time [32, 33]; these concerns fall outside the scope of our investigation. To this end, our method aims for a flexible and efficient solution suitable for a range of FL strategies to learn robust models using decentralized data.",
            "In FL, the formulation of the global model normally involves the aggregation of local models from each client, weighted based on the total count of data samples in their respective local datasets [1, 2]. When applying an average aggregation strategy when clients‚Äô data follows the IID setting, the contribution of each client‚Äôs model parameters to the server is equivalent. Consequently, in scenarios of noisy federated learning, the contribution of noisy clients can seriously degrade the generalization quality of the server-side aggregated model, as detailed in Table I.",
            "Baselines and Implementation. We apply FedNS¬†in conjunction with four widely used FL strategies to evaluate its effectiveness, namely FedAvg [2], FedProx [9], FedTrimmedAvg [10], and FedNova [11]. We employ ResNet-18 as the main model architecture, utilizing the mini-batch SGD as the universal local optimizer for all FL strategies. Moreover, we further evaluate FedNS¬†on a different neural architecture ConvMixer-256/8 in Table III. The optimizer is characterized by a learning rate of 0.010.010.01, an SGD momentum of 0.90.90.9, and the weight decay is set to 10‚àí4superscript10410^{-4}. We set the number of local training epochs to 555 and the global communication rounds to 150150150 across all datasets.\nWe consider a setup with N=20ùëÅ20N=20 clients for our experiments unless mentioned otherwise. This choice aligns with standard practices in FL and accommodates our computational limitations. The training set is distributed under both IID and non-IID settings. For the main experiments, we divide the client set into 151515 noisy clients and 555 clean clients, with full client participation rp=1.0subscriptùëüùëù1.0r_{p}=1.0. We compute L1subscriptùêø1L_{1}-norm of the gradient of last layer for noisy client detection in all the cases, see Table¬†IX(b) for comparison between the effectiveness of L1subscriptùêø1L_{1} and L2subscriptùêø2L_{2} norms, as well as the impact of batch size on the detection performance. We conducted all experiments on NVIDIA A10 GPUs.",
            "Participation of noisy clients deteriorates the performance of the global model. To validate the efficacy of our proposed method, we first conduct an experiment for model training with clean and noisy input across all the datasets and utilize the same noise configuration for our further empirical evaluation. With this, we aim to evaluate the upper-bound performance that can be achieved when learning from a mixture of noisy and clean clients. Table I presents the comparative results of average accuracy for all considered datasets. We focus on three specific distortions (i.e., defocus blur, Gaussian blur, contrast) due to their significant impact on degrading the model‚Äôs generalization capability to simulate the worst case in noisy FL.\nFor the generation of distorted data used in the experiments summarized in Table II, each noisy sample was produced by randomly selecting a distortion type with the configuration characterized by the noise severity level Œæ=h‚Äãi‚Äãg‚Äãhùúâ‚Ñéùëñùëî‚Ñé\\xi=high. We set the noise level to NLm=100%subscriptNLùëöpercent100\\emph{NL}_{m}=100\\% for every client mùëöm for the experiments of both Table II and Figure 6. We see the participation of noisy clients leads to a significant degradation in the model‚Äôs generalization capability across all tasks, indicating the detrimental impact of noisy data in the FL environment. Furthermore, due to the inherent lack of visibility into the data from these federated clients, the resultant global model tends to be of low quality and it may become challenging in a real-world setting to identify the underlying reasons for its poor performance.",
            "FedNS significantly improves standard federated aggregation methods. We investigate the robustness of our proposed method by applying FedNS on six image datasets with different settings under the noisy scenario. As shown in Table II, the performance of all aggregation methods exhibits a general trend of improvement by simply plugging FedNS to the considered strategies. In particular, we consider the worst-case with heterogeneous data setting in Table II, where 15 out of 20 noisy clients participate in the federated training with high noise severity and 100100100% noise level. Adding FedNS to FL strategies yields better overall performance among all the datasets, especially for some vulnerable datasets (e.g., Path-MNIST) that are sensitive to data corruption. Additionally, we demonstrate the efficacy of FedNS in dealing with patch-based noise on CIFAR-10 and Path-MNIST as presented in Figure 6. From Figure 6, we observe that FedNS consistently boosts the performance of the aggregation method across all the datasets and settings. This further shows that FedNS is capable of handling various types of noises a model can encounter in a real-world setting.",
            "Robustness of FedNS¬†on mixed noise conditions. Next, we investigate the robustness of FedNS¬†under complex noise conditions that involve a combination of different noise types, including the distortions and patch-based noises as described in Section IV-A. Table IV shows the performance gains achieved by FedNS¬†are particularly significant in high-variance datasets such as Path-MNIST and Tiny-ImageNet, where FedNova+NS demonstrates substantial improvements over standard aggregation. Notably, FedNS¬†consistently enhances the global model‚Äôs performance across all evaluated datasets, showcasing its robustness in handling intricate noise scenarios. Our results highlight the effectiveness of FedNS¬†in mitigating the impact of complex noise conditions, where decentralized data may be subject to various types of distortions at the same time.",
            "Evaluation on Weight Factor(Œ≤ùõΩ\\beta) of Noisy Client. We further investigate the effect of weight factor Œ≤ùõΩ\\beta on overall performance in FedNS. The weight factor Œ≤ùõΩ\\beta controls the weights of aggregated noisy client local models, as described in Equation 6. We considered various values of Œ≤‚àà{0,0.1,0.3,0.5,0.7,1.0}ùõΩ00.10.30.50.71.0\\beta\\in\\{0,0.1,0.3,0.5,0.7,1.0\\}, where Œ≤=0ùõΩ0\\beta=0 signifies the exclusion of noisy model weights, and Œ≤=1.0ùõΩ1.0\\beta=1.0 indicates the direct aggregation of model weights. As shown in Table V, the setting of Œ≤=0.3ùõΩ0.3\\beta=0.3 yields the best performance, suggesting an optimal trade-off. Interestingly, the exclusion of noisy model weights (Œ≤=0.0ùõΩ0.0\\beta=0.0) leads to a degradation in the generalization capability of the global model. This observation suggests that incorporating mitigated noisy data enhances the robustness of the global model.",
            "FedNS on Real-world Human Annotation Errors. In this experiment, we extend our investigation to assess the efficacy of FedNS in addressing real-world data quality issues, specifically human annotation errors. While this work focuses on mitigating data corruption in the input space, we identify that FedNS can effectively handle label noise - a well-studied problem in noisy FL. Label noise occurs when data labels are incorrectly assigned while the input features remain unaltered. Specifically, we assessed FedNS on CIFAR-10/100N, two benchmark datasets featuring real-world noisy labels resulting from human annotation errors [45]. We employed FedAvg and FedNova as baseline approaches, adhering to the training configuration outlined in Section IV-A. From Table VI, we observe that FedNS consistently improved the performance across all the experiments. Our findings demonstrate that FedNS not only excels in mitigating input space corruption but also shows promising results in handling label noise. The ability to address both input space corruption and label noise positions FedNS as a valuable tool for practitioners dealing with real-world datasets, where multiple types of data imperfections may coexist.",
            "Impact of Initial-Round Client Participation on FedNS Performance. In FL, the assumption that all clients must be warmed up and participate from the very first training round may not always hold true, as some clients may only participate in later rounds. To address this, we explore the scenario where only a subset of clients participates in the initial round. Instead of collecting gradient norms solely in the first round, we iteratively apply FedNS until all clients have been engaged. We evaluate this approach by setting the first-round participation rates to 10%, 50%, and 100%, with 100% representing full client participation. The results, presented in Table VII, highlight the robustness of FedNS across varying levels of initial-round client participation.",
            "FedNS on Different Noise Level (NL) of Client Data. In Table VIII, we examine the performance of FedNS¬†across various noise configurations. Specifically, we consider noise levels NL‚àà{50%,80%,100%}NLpercent50percent80percent100\\emph{NL}\\in\\{50\\%,80\\%,100\\%\\} and noise severity Œæ‚àà{M‚Äãe‚Äãd‚Äãi‚Äãu‚Äãm,H‚Äãi‚Äãg‚Äãh}ùúâùëÄùëíùëëùëñùë¢ùëöùêªùëñùëî‚Ñé\\xi\\in\\{Medium,High\\}. These results demonstrate that FedNS¬†substantially enhances model generalization under high noise conditions, especially when clients‚Äô data is completely corrupted (i.e., 100100100% noise level and high severity). Conversely, in scenarios with milder noise where the impact on federated models is minimal, the implementation of FedNS¬†does not negatively affect the generalization process. Hence, we limit our experiments to noise levels at or above 50%, as noise levels below this threshold have negligible impact on model performance.",
            "Hyperparameters Selections for Noisy Clients Detection. One of the essential components of FedNS¬†is using gradient norms to identify noisy clients. We investigate several factors that may affect the performance of detecting noisy clients, specifically the selection of the LpsubscriptùêøùëùL_{p}-norm and the batch size of gradient norms for clustering. This ablation experiment is performed on the CIFAR-10 and Path-MNIST datasets, as presented in Table IX(b).",
            "The comparison between the L1subscriptùêø1L_{1}-norm and L2subscriptùêø2L_{2}-norm shows that the L1subscriptùêø1L_{1}-norm generally outperforms higher-order norms. Moreover, we evaluate the impact of batch size by setting the mini-batch size to range from 1 to 128. Our experiments suggest that a larger batch size effectively reduces the variance of the gradient estimates. The results, shown in Table IX(b), indicate that a batch size selection around 16‚àº64similar-to166416\\sim 64 yields better performance across all settings.",
            "Evaluating FedNS¬†with alternative model architecture. In this experiment, we investigate the robustness of FedNS¬†when applied to a different model architecture. We employ the ConvMixer-256/8 [46] model and train it using FedNova on a range of datasets. The noise configuration remains consistent with the details provided in Section IV-B, and we evaluate the model‚Äôs performance under both IID and non-IID settings. As shown in Table III, the federated aggregation method, when paired with FedNS, achieves enhanced performance across all considered datasets. These improvements, observed consistently across tasks, demonstrate the adaptability and effectiveness of FedNS¬†when integrated with alternative architectural paradigms. The results highlight the versatility of our approach in enhancing the performance of different federated model regardless of the neural architecture, further emphasizing its potential as a robust and flexible method for FL."
        ]
    },
    "S4.T8.st2": {
        "caption": "(b) CIFAR-100",
        "table": "<table id=\"S4.T8.st2.4.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T8.st2.4.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T8.st2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T8.st2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Noise Level(<span id=\"S4.T8.st2.1.1.1.1.1.1\" class=\"ltx_text ltx_markedasmath ltx_font_italic\">NL</span>)</span></th>\n<th id=\"S4.T8.st2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><math id=\"S4.T8.st2.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\emph{NL}=\\mathbf{50}\\textbf{\\%}\" display=\"inline\"><semantics id=\"S4.T8.st2.2.2.2.2.m1.1a\"><mrow id=\"S4.T8.st2.2.2.2.2.m1.1.1\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st2.2.2.2.2.m1.1.1.2\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.2b.cmml\"><em id=\"S4.T8.st2.2.2.2.2.m1.1.1.2.1nest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext><mo id=\"S4.T8.st2.2.2.2.2.m1.1.1.1\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.1.cmml\">=</mo><mrow id=\"S4.T8.st2.2.2.2.2.m1.1.1.3\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.3.cmml\"><mn id=\"S4.T8.st2.2.2.2.2.m1.1.1.3.2\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.3.2.cmml\">ùüìùüé</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T8.st2.2.2.2.2.m1.1.1.3.1\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.3.1.cmml\">‚Äã</mo><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st2.2.2.2.2.m1.1.1.3.3\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.3.3a.cmml\">%</mtext></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.st2.2.2.2.2.m1.1b\"><apply id=\"S4.T8.st2.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1\"><eq id=\"S4.T8.st2.2.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.1\"></eq><ci id=\"S4.T8.st2.2.2.2.2.m1.1.1.2b.cmml\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.2\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st2.2.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.2\"><em id=\"S4.T8.st2.2.2.2.2.m1.1.1.2.1anest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext></ci><apply id=\"S4.T8.st2.2.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.3\"><times id=\"S4.T8.st2.2.2.2.2.m1.1.1.3.1.cmml\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.3.1\"></times><cn type=\"integer\" id=\"S4.T8.st2.2.2.2.2.m1.1.1.3.2.cmml\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.3.2\">50</cn><ci id=\"S4.T8.st2.2.2.2.2.m1.1.1.3.3a.cmml\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.3.3\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st2.2.2.2.2.m1.1.1.3.3.cmml\" xref=\"S4.T8.st2.2.2.2.2.m1.1.1.3.3\">%</mtext></ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T8.st2.2.2.2.2.m1.1c\">\\emph{NL}=\\mathbf{50}\\textbf{\\%}</annotation></semantics></math></th>\n<th id=\"S4.T8.st2.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><math id=\"S4.T8.st2.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\emph{NL}=\\mathbf{80}\\textbf{\\%}\" display=\"inline\"><semantics id=\"S4.T8.st2.3.3.3.3.m1.1a\"><mrow id=\"S4.T8.st2.3.3.3.3.m1.1.1\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st2.3.3.3.3.m1.1.1.2\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.2b.cmml\"><em id=\"S4.T8.st2.3.3.3.3.m1.1.1.2.1nest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext><mo id=\"S4.T8.st2.3.3.3.3.m1.1.1.1\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.1.cmml\">=</mo><mrow id=\"S4.T8.st2.3.3.3.3.m1.1.1.3\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.3.cmml\"><mn id=\"S4.T8.st2.3.3.3.3.m1.1.1.3.2\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.3.2.cmml\">ùüñùüé</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T8.st2.3.3.3.3.m1.1.1.3.1\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.3.1.cmml\">‚Äã</mo><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st2.3.3.3.3.m1.1.1.3.3\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.3.3a.cmml\">%</mtext></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.st2.3.3.3.3.m1.1b\"><apply id=\"S4.T8.st2.3.3.3.3.m1.1.1.cmml\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1\"><eq id=\"S4.T8.st2.3.3.3.3.m1.1.1.1.cmml\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.1\"></eq><ci id=\"S4.T8.st2.3.3.3.3.m1.1.1.2b.cmml\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.2\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st2.3.3.3.3.m1.1.1.2.cmml\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.2\"><em id=\"S4.T8.st2.3.3.3.3.m1.1.1.2.1anest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext></ci><apply id=\"S4.T8.st2.3.3.3.3.m1.1.1.3.cmml\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.3\"><times id=\"S4.T8.st2.3.3.3.3.m1.1.1.3.1.cmml\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.3.1\"></times><cn type=\"integer\" id=\"S4.T8.st2.3.3.3.3.m1.1.1.3.2.cmml\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.3.2\">80</cn><ci id=\"S4.T8.st2.3.3.3.3.m1.1.1.3.3a.cmml\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.3.3\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st2.3.3.3.3.m1.1.1.3.3.cmml\" xref=\"S4.T8.st2.3.3.3.3.m1.1.1.3.3\">%</mtext></ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T8.st2.3.3.3.3.m1.1c\">\\emph{NL}=\\mathbf{80}\\textbf{\\%}</annotation></semantics></math></th>\n<th id=\"S4.T8.st2.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><math id=\"S4.T8.st2.4.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\emph{NL}=\\mathbf{100}\\textbf{\\%}\" display=\"inline\"><semantics id=\"S4.T8.st2.4.4.4.4.m1.1a\"><mrow id=\"S4.T8.st2.4.4.4.4.m1.1.1\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st2.4.4.4.4.m1.1.1.2\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.2b.cmml\"><em id=\"S4.T8.st2.4.4.4.4.m1.1.1.2.1nest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext><mo id=\"S4.T8.st2.4.4.4.4.m1.1.1.1\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.1.cmml\">=</mo><mrow id=\"S4.T8.st2.4.4.4.4.m1.1.1.3\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.3.cmml\"><mn id=\"S4.T8.st2.4.4.4.4.m1.1.1.3.2\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.3.2.cmml\">ùüèùüéùüé</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T8.st2.4.4.4.4.m1.1.1.3.1\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.3.1.cmml\">‚Äã</mo><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st2.4.4.4.4.m1.1.1.3.3\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.3.3a.cmml\">%</mtext></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.st2.4.4.4.4.m1.1b\"><apply id=\"S4.T8.st2.4.4.4.4.m1.1.1.cmml\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1\"><eq id=\"S4.T8.st2.4.4.4.4.m1.1.1.1.cmml\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.1\"></eq><ci id=\"S4.T8.st2.4.4.4.4.m1.1.1.2b.cmml\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.2\"><mtext class=\"ltx_mathvariant_italic\" id=\"S4.T8.st2.4.4.4.4.m1.1.1.2.cmml\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.2\"><em id=\"S4.T8.st2.4.4.4.4.m1.1.1.2.1anest\" class=\"ltx_emph ltx_font_italic\">NL</em></mtext></ci><apply id=\"S4.T8.st2.4.4.4.4.m1.1.1.3.cmml\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.3\"><times id=\"S4.T8.st2.4.4.4.4.m1.1.1.3.1.cmml\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.3.1\"></times><cn type=\"integer\" id=\"S4.T8.st2.4.4.4.4.m1.1.1.3.2.cmml\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.3.2\">100</cn><ci id=\"S4.T8.st2.4.4.4.4.m1.1.1.3.3a.cmml\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.3.3\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T8.st2.4.4.4.4.m1.1.1.3.3.cmml\" xref=\"S4.T8.st2.4.4.4.4.m1.1.1.3.3\">%</mtext></ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T8.st2.4.4.4.4.m1.1c\">\\emph{NL}=\\mathbf{100}\\textbf{\\%}</annotation></semantics></math></th>\n</tr>\n<tr id=\"S4.T8.st2.4.4.5.1\" class=\"ltx_tr\">\n<th id=\"S4.T8.st2.4.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\"><span id=\"S4.T8.st2.4.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\">Noise Severity</span></th>\n<th id=\"S4.T8.st2.4.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Medium</th>\n<th id=\"S4.T8.st2.4.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">High</th>\n<th id=\"S4.T8.st2.4.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Medium</th>\n<th id=\"S4.T8.st2.4.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">High</th>\n<th id=\"S4.T8.st2.4.4.5.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Medium</th>\n<th id=\"S4.T8.st2.4.4.5.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\">High</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T8.st2.4.4.6.1\" class=\"ltx_tr\">\n<th id=\"S4.T8.st2.4.4.6.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedNova</th>\n<td id=\"S4.T8.st2.4.4.6.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T8.st2.4.4.6.1.2.1\" class=\"ltx_text ltx_font_bold\">65.51%</span></td>\n<td id=\"S4.T8.st2.4.4.6.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">62.70%</td>\n<td id=\"S4.T8.st2.4.4.6.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">64.18%</td>\n<td id=\"S4.T8.st2.4.4.6.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">60.96%</td>\n<td id=\"S4.T8.st2.4.4.6.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">60.85%</td>\n<td id=\"S4.T8.st2.4.4.6.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">49.48%</td>\n</tr>\n<tr id=\"S4.T8.st2.4.4.7.2\" class=\"ltx_tr\">\n<th id=\"S4.T8.st2.4.4.7.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">+ NS (Ours)</th>\n<td id=\"S4.T8.st2.4.4.7.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">65.03%</td>\n<td id=\"S4.T8.st2.4.4.7.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st2.4.4.7.2.3.1\" class=\"ltx_text ltx_font_bold\">62.83%</span></td>\n<td id=\"S4.T8.st2.4.4.7.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st2.4.4.7.2.4.1\" class=\"ltx_text ltx_font_bold\">65.17%</span></td>\n<td id=\"S4.T8.st2.4.4.7.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st2.4.4.7.2.5.1\" class=\"ltx_text ltx_font_bold\">62.14%</span></td>\n<td id=\"S4.T8.st2.4.4.7.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st2.4.4.7.2.6.1\" class=\"ltx_text ltx_font_bold\">62.76%</span></td>\n<td id=\"S4.T8.st2.4.4.7.2.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S4.T8.st2.4.4.7.2.7.1\" class=\"ltx_text ltx_font_bold\">59.19%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Recent works in FL mainly focus on addressing the data quality issues pertaining to the label space. Many strategies have been developed to deal with the disparity of label quality in FL. These methods mitigate the impact of label noise by conducting either client selection to re-weight model updates [22, 23, 24] or data sampling for label correction or exclusion [25, 26, 27, 28, 29]. Additionally, other works tackle this challenge by correcting the label error. [28] perform label noise correction using consensus-derived class-wise information for dynamic noise identification and label correction. [26] tackles label noise in federated learning by updating local models with globally aligned centroids and correcting labels through global model insights. In spite of the progress that has been made in resolving label noise, data subset selection¬†[7], data valuation¬†[30, 31], dealing with low-quality data in input space (i.e., when noise is in the samples like in images) in the federated setting still remains unexplored. Furthermore, we recognize that client data may be susceptible to backdoor attacks via adversarial methods during both inference and training time [32, 33]; these concerns fall outside the scope of our investigation. To this end, our method aims for a flexible and efficient solution suitable for a range of FL strategies to learn robust models using decentralized data.",
            "In FL, the formulation of the global model normally involves the aggregation of local models from each client, weighted based on the total count of data samples in their respective local datasets [1, 2]. When applying an average aggregation strategy when clients‚Äô data follows the IID setting, the contribution of each client‚Äôs model parameters to the server is equivalent. Consequently, in scenarios of noisy federated learning, the contribution of noisy clients can seriously degrade the generalization quality of the server-side aggregated model, as detailed in Table I.",
            "Baselines and Implementation. We apply FedNS¬†in conjunction with four widely used FL strategies to evaluate its effectiveness, namely FedAvg [2], FedProx [9], FedTrimmedAvg [10], and FedNova [11]. We employ ResNet-18 as the main model architecture, utilizing the mini-batch SGD as the universal local optimizer for all FL strategies. Moreover, we further evaluate FedNS¬†on a different neural architecture ConvMixer-256/8 in Table III. The optimizer is characterized by a learning rate of 0.010.010.01, an SGD momentum of 0.90.90.9, and the weight decay is set to 10‚àí4superscript10410^{-4}. We set the number of local training epochs to 555 and the global communication rounds to 150150150 across all datasets.\nWe consider a setup with N=20ùëÅ20N=20 clients for our experiments unless mentioned otherwise. This choice aligns with standard practices in FL and accommodates our computational limitations. The training set is distributed under both IID and non-IID settings. For the main experiments, we divide the client set into 151515 noisy clients and 555 clean clients, with full client participation rp=1.0subscriptùëüùëù1.0r_{p}=1.0. We compute L1subscriptùêø1L_{1}-norm of the gradient of last layer for noisy client detection in all the cases, see Table¬†IX(b) for comparison between the effectiveness of L1subscriptùêø1L_{1} and L2subscriptùêø2L_{2} norms, as well as the impact of batch size on the detection performance. We conducted all experiments on NVIDIA A10 GPUs.",
            "Participation of noisy clients deteriorates the performance of the global model. To validate the efficacy of our proposed method, we first conduct an experiment for model training with clean and noisy input across all the datasets and utilize the same noise configuration for our further empirical evaluation. With this, we aim to evaluate the upper-bound performance that can be achieved when learning from a mixture of noisy and clean clients. Table I presents the comparative results of average accuracy for all considered datasets. We focus on three specific distortions (i.e., defocus blur, Gaussian blur, contrast) due to their significant impact on degrading the model‚Äôs generalization capability to simulate the worst case in noisy FL.\nFor the generation of distorted data used in the experiments summarized in Table II, each noisy sample was produced by randomly selecting a distortion type with the configuration characterized by the noise severity level Œæ=h‚Äãi‚Äãg‚Äãhùúâ‚Ñéùëñùëî‚Ñé\\xi=high. We set the noise level to NLm=100%subscriptNLùëöpercent100\\emph{NL}_{m}=100\\% for every client mùëöm for the experiments of both Table II and Figure 6. We see the participation of noisy clients leads to a significant degradation in the model‚Äôs generalization capability across all tasks, indicating the detrimental impact of noisy data in the FL environment. Furthermore, due to the inherent lack of visibility into the data from these federated clients, the resultant global model tends to be of low quality and it may become challenging in a real-world setting to identify the underlying reasons for its poor performance.",
            "FedNS significantly improves standard federated aggregation methods. We investigate the robustness of our proposed method by applying FedNS on six image datasets with different settings under the noisy scenario. As shown in Table II, the performance of all aggregation methods exhibits a general trend of improvement by simply plugging FedNS to the considered strategies. In particular, we consider the worst-case with heterogeneous data setting in Table II, where 15 out of 20 noisy clients participate in the federated training with high noise severity and 100100100% noise level. Adding FedNS to FL strategies yields better overall performance among all the datasets, especially for some vulnerable datasets (e.g., Path-MNIST) that are sensitive to data corruption. Additionally, we demonstrate the efficacy of FedNS in dealing with patch-based noise on CIFAR-10 and Path-MNIST as presented in Figure 6. From Figure 6, we observe that FedNS consistently boosts the performance of the aggregation method across all the datasets and settings. This further shows that FedNS is capable of handling various types of noises a model can encounter in a real-world setting.",
            "Robustness of FedNS¬†on mixed noise conditions. Next, we investigate the robustness of FedNS¬†under complex noise conditions that involve a combination of different noise types, including the distortions and patch-based noises as described in Section IV-A. Table IV shows the performance gains achieved by FedNS¬†are particularly significant in high-variance datasets such as Path-MNIST and Tiny-ImageNet, where FedNova+NS demonstrates substantial improvements over standard aggregation. Notably, FedNS¬†consistently enhances the global model‚Äôs performance across all evaluated datasets, showcasing its robustness in handling intricate noise scenarios. Our results highlight the effectiveness of FedNS¬†in mitigating the impact of complex noise conditions, where decentralized data may be subject to various types of distortions at the same time.",
            "Evaluation on Weight Factor(Œ≤ùõΩ\\beta) of Noisy Client. We further investigate the effect of weight factor Œ≤ùõΩ\\beta on overall performance in FedNS. The weight factor Œ≤ùõΩ\\beta controls the weights of aggregated noisy client local models, as described in Equation 6. We considered various values of Œ≤‚àà{0,0.1,0.3,0.5,0.7,1.0}ùõΩ00.10.30.50.71.0\\beta\\in\\{0,0.1,0.3,0.5,0.7,1.0\\}, where Œ≤=0ùõΩ0\\beta=0 signifies the exclusion of noisy model weights, and Œ≤=1.0ùõΩ1.0\\beta=1.0 indicates the direct aggregation of model weights. As shown in Table V, the setting of Œ≤=0.3ùõΩ0.3\\beta=0.3 yields the best performance, suggesting an optimal trade-off. Interestingly, the exclusion of noisy model weights (Œ≤=0.0ùõΩ0.0\\beta=0.0) leads to a degradation in the generalization capability of the global model. This observation suggests that incorporating mitigated noisy data enhances the robustness of the global model.",
            "FedNS on Real-world Human Annotation Errors. In this experiment, we extend our investigation to assess the efficacy of FedNS in addressing real-world data quality issues, specifically human annotation errors. While this work focuses on mitigating data corruption in the input space, we identify that FedNS can effectively handle label noise - a well-studied problem in noisy FL. Label noise occurs when data labels are incorrectly assigned while the input features remain unaltered. Specifically, we assessed FedNS on CIFAR-10/100N, two benchmark datasets featuring real-world noisy labels resulting from human annotation errors [45]. We employed FedAvg and FedNova as baseline approaches, adhering to the training configuration outlined in Section IV-A. From Table VI, we observe that FedNS consistently improved the performance across all the experiments. Our findings demonstrate that FedNS not only excels in mitigating input space corruption but also shows promising results in handling label noise. The ability to address both input space corruption and label noise positions FedNS as a valuable tool for practitioners dealing with real-world datasets, where multiple types of data imperfections may coexist.",
            "Impact of Initial-Round Client Participation on FedNS Performance. In FL, the assumption that all clients must be warmed up and participate from the very first training round may not always hold true, as some clients may only participate in later rounds. To address this, we explore the scenario where only a subset of clients participates in the initial round. Instead of collecting gradient norms solely in the first round, we iteratively apply FedNS until all clients have been engaged. We evaluate this approach by setting the first-round participation rates to 10%, 50%, and 100%, with 100% representing full client participation. The results, presented in Table VII, highlight the robustness of FedNS across varying levels of initial-round client participation.",
            "FedNS on Different Noise Level (NL) of Client Data. In Table VIII, we examine the performance of FedNS¬†across various noise configurations. Specifically, we consider noise levels NL‚àà{50%,80%,100%}NLpercent50percent80percent100\\emph{NL}\\in\\{50\\%,80\\%,100\\%\\} and noise severity Œæ‚àà{M‚Äãe‚Äãd‚Äãi‚Äãu‚Äãm,H‚Äãi‚Äãg‚Äãh}ùúâùëÄùëíùëëùëñùë¢ùëöùêªùëñùëî‚Ñé\\xi\\in\\{Medium,High\\}. These results demonstrate that FedNS¬†substantially enhances model generalization under high noise conditions, especially when clients‚Äô data is completely corrupted (i.e., 100100100% noise level and high severity). Conversely, in scenarios with milder noise where the impact on federated models is minimal, the implementation of FedNS¬†does not negatively affect the generalization process. Hence, we limit our experiments to noise levels at or above 50%, as noise levels below this threshold have negligible impact on model performance.",
            "Hyperparameters Selections for Noisy Clients Detection. One of the essential components of FedNS¬†is using gradient norms to identify noisy clients. We investigate several factors that may affect the performance of detecting noisy clients, specifically the selection of the LpsubscriptùêøùëùL_{p}-norm and the batch size of gradient norms for clustering. This ablation experiment is performed on the CIFAR-10 and Path-MNIST datasets, as presented in Table IX(b).",
            "The comparison between the L1subscriptùêø1L_{1}-norm and L2subscriptùêø2L_{2}-norm shows that the L1subscriptùêø1L_{1}-norm generally outperforms higher-order norms. Moreover, we evaluate the impact of batch size by setting the mini-batch size to range from 1 to 128. Our experiments suggest that a larger batch size effectively reduces the variance of the gradient estimates. The results, shown in Table IX(b), indicate that a batch size selection around 16‚àº64similar-to166416\\sim 64 yields better performance across all settings.",
            "Evaluating FedNS¬†with alternative model architecture. In this experiment, we investigate the robustness of FedNS¬†when applied to a different model architecture. We employ the ConvMixer-256/8 [46] model and train it using FedNova on a range of datasets. The noise configuration remains consistent with the details provided in Section IV-B, and we evaluate the model‚Äôs performance under both IID and non-IID settings. As shown in Table III, the federated aggregation method, when paired with FedNS, achieves enhanced performance across all considered datasets. These improvements, observed consistently across tasks, demonstrate the adaptability and effectiveness of FedNS¬†when integrated with alternative architectural paradigms. The results highlight the versatility of our approach in enhancing the performance of different federated model regardless of the neural architecture, further emphasizing its potential as a robust and flexible method for FL."
        ]
    },
    "S4.T9": {
        "caption": "TABLE IX: Hyperparameter impact on noisy client detection: CIFAR-10 and Path-MNIST, FedNova, 5 clean + 15 noisy clients (100% noise), IID, full participation in first round, 5 local epochs. Values show noisy client detection accuracy.",
        "table": "<table id=\"S4.T9.st1.8.8\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T9.st1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T9.st1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T9.st1.1.1.1.1.1\" class=\"ltx_text\"><math id=\"S4.T9.st1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"L_{p}\" display=\"inline\"><semantics id=\"S4.T9.st1.1.1.1.1.1.m1.1a\"><msub id=\"S4.T9.st1.1.1.1.1.1.m1.1.1\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.2\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1.2.cmml\">L</mi><mi id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.3\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1.3.cmml\">p</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.1.1.1.1.1.m1.1b\"><apply id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1.2\">ùêø</ci><ci id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1.3\">ùëù</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.1.1.1.1.1.m1.1c\">L_{p}</annotation></semantics></math><span id=\"S4.T9.st1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">-Norm</span></span></th>\n<td id=\"S4.T9.st1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"5\"><span id=\"S4.T9.st1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Batch Size of Gradient Norm</span></td>\n</tr>\n<tr id=\"S4.T9.st1.6.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T9.st1.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st1.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{1}\" display=\"inline\"><semantics id=\"S4.T9.st1.2.2.2.1.m1.1a\"><mn id=\"S4.T9.st1.2.2.2.1.m1.1.1\" xref=\"S4.T9.st1.2.2.2.1.m1.1.1.cmml\">ùüè</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.2.2.2.1.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st1.2.2.2.1.m1.1.1.cmml\" xref=\"S4.T9.st1.2.2.2.1.m1.1.1\">1</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.2.2.2.1.m1.1c\">\\mathbf{1}</annotation></semantics></math></td>\n<td id=\"S4.T9.st1.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st1.3.3.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{16}\" display=\"inline\"><semantics id=\"S4.T9.st1.3.3.3.2.m1.1a\"><mn id=\"S4.T9.st1.3.3.3.2.m1.1.1\" xref=\"S4.T9.st1.3.3.3.2.m1.1.1.cmml\">ùüèùüî</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.3.3.3.2.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st1.3.3.3.2.m1.1.1.cmml\" xref=\"S4.T9.st1.3.3.3.2.m1.1.1\">16</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.3.3.3.2.m1.1c\">\\mathbf{16}</annotation></semantics></math></td>\n<td id=\"S4.T9.st1.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st1.4.4.4.3.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{32}\" display=\"inline\"><semantics id=\"S4.T9.st1.4.4.4.3.m1.1a\"><mn id=\"S4.T9.st1.4.4.4.3.m1.1.1\" xref=\"S4.T9.st1.4.4.4.3.m1.1.1.cmml\">ùüëùüê</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.4.4.4.3.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st1.4.4.4.3.m1.1.1.cmml\" xref=\"S4.T9.st1.4.4.4.3.m1.1.1\">32</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.4.4.4.3.m1.1c\">\\mathbf{32}</annotation></semantics></math></td>\n<td id=\"S4.T9.st1.5.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st1.5.5.5.4.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{64}\" display=\"inline\"><semantics id=\"S4.T9.st1.5.5.5.4.m1.1a\"><mn id=\"S4.T9.st1.5.5.5.4.m1.1.1\" xref=\"S4.T9.st1.5.5.5.4.m1.1.1.cmml\">ùüîùüí</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.5.5.5.4.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st1.5.5.5.4.m1.1.1.cmml\" xref=\"S4.T9.st1.5.5.5.4.m1.1.1\">64</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.5.5.5.4.m1.1c\">\\mathbf{64}</annotation></semantics></math></td>\n<td id=\"S4.T9.st1.6.6.6.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><math id=\"S4.T9.st1.6.6.6.5.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{128}\" display=\"inline\"><semantics id=\"S4.T9.st1.6.6.6.5.m1.1a\"><mn id=\"S4.T9.st1.6.6.6.5.m1.1.1\" xref=\"S4.T9.st1.6.6.6.5.m1.1.1.cmml\">ùüèùüêùüñ</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.6.6.6.5.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st1.6.6.6.5.m1.1.1.cmml\" xref=\"S4.T9.st1.6.6.6.5.m1.1.1\">128</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.6.6.6.5.m1.1c\">\\mathbf{128}</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T9.st1.7.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T9.st1.7.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">\n<math id=\"S4.T9.st1.7.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"L_{1}\" display=\"inline\"><semantics id=\"S4.T9.st1.7.7.7.1.m1.1a\"><msub id=\"S4.T9.st1.7.7.7.1.m1.1.1\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1.cmml\"><mi id=\"S4.T9.st1.7.7.7.1.m1.1.1.2\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1.2.cmml\">L</mi><mn id=\"S4.T9.st1.7.7.7.1.m1.1.1.3\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1.3.cmml\">1</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.7.7.7.1.m1.1b\"><apply id=\"S4.T9.st1.7.7.7.1.m1.1.1.cmml\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T9.st1.7.7.7.1.m1.1.1.1.cmml\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T9.st1.7.7.7.1.m1.1.1.2.cmml\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1.2\">ùêø</ci><cn type=\"integer\" id=\"S4.T9.st1.7.7.7.1.m1.1.1.3.cmml\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.7.7.7.1.m1.1c\">L_{1}</annotation></semantics></math>-Norm</th>\n<td id=\"S4.T9.st1.7.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.85</td>\n<td id=\"S4.T9.st1.7.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1.00</td>\n<td id=\"S4.T9.st1.7.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.00</td>\n<td id=\"S4.T9.st1.7.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.95</td>\n<td id=\"S4.T9.st1.7.7.7.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">0.90</td>\n</tr>\n<tr id=\"S4.T9.st1.8.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T9.st1.8.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">\n<math id=\"S4.T9.st1.8.8.8.1.m1.1\" class=\"ltx_Math\" alttext=\"L_{2}\" display=\"inline\"><semantics id=\"S4.T9.st1.8.8.8.1.m1.1a\"><msub id=\"S4.T9.st1.8.8.8.1.m1.1.1\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1.cmml\"><mi id=\"S4.T9.st1.8.8.8.1.m1.1.1.2\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1.2.cmml\">L</mi><mn id=\"S4.T9.st1.8.8.8.1.m1.1.1.3\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1.3.cmml\">2</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.8.8.8.1.m1.1b\"><apply id=\"S4.T9.st1.8.8.8.1.m1.1.1.cmml\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T9.st1.8.8.8.1.m1.1.1.1.cmml\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T9.st1.8.8.8.1.m1.1.1.2.cmml\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1.2\">ùêø</ci><cn type=\"integer\" id=\"S4.T9.st1.8.8.8.1.m1.1.1.3.cmml\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.8.8.8.1.m1.1c\">L_{2}</annotation></semantics></math>-Norm</th>\n<td id=\"S4.T9.st1.8.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.90</td>\n<td id=\"S4.T9.st1.8.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.95</td>\n<td id=\"S4.T9.st1.8.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.90</td>\n<td id=\"S4.T9.st1.8.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.90</td>\n<td id=\"S4.T9.st1.8.8.8.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">0.95</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Baselines and Implementation. We apply FedNS¬†in conjunction with four widely used FL strategies to evaluate its effectiveness, namely FedAvg [2], FedProx [9], FedTrimmedAvg [10], and FedNova [11]. We employ ResNet-18 as the main model architecture, utilizing the mini-batch SGD as the universal local optimizer for all FL strategies. Moreover, we further evaluate FedNS¬†on a different neural architecture ConvMixer-256/8 in Table III. The optimizer is characterized by a learning rate of 0.010.010.01, an SGD momentum of 0.90.90.9, and the weight decay is set to 10‚àí4superscript10410^{-4}. We set the number of local training epochs to 555 and the global communication rounds to 150150150 across all datasets.\nWe consider a setup with N=20ùëÅ20N=20 clients for our experiments unless mentioned otherwise. This choice aligns with standard practices in FL and accommodates our computational limitations. The training set is distributed under both IID and non-IID settings. For the main experiments, we divide the client set into 151515 noisy clients and 555 clean clients, with full client participation rp=1.0subscriptùëüùëù1.0r_{p}=1.0. We compute L1subscriptùêø1L_{1}-norm of the gradient of last layer for noisy client detection in all the cases, see Table¬†IX(b) for comparison between the effectiveness of L1subscriptùêø1L_{1} and L2subscriptùêø2L_{2} norms, as well as the impact of batch size on the detection performance. We conducted all experiments on NVIDIA A10 GPUs.",
            "Hyperparameters Selections for Noisy Clients Detection. One of the essential components of FedNS¬†is using gradient norms to identify noisy clients. We investigate several factors that may affect the performance of detecting noisy clients, specifically the selection of the LpsubscriptùêøùëùL_{p}-norm and the batch size of gradient norms for clustering. This ablation experiment is performed on the CIFAR-10 and Path-MNIST datasets, as presented in Table IX(b).",
            "The comparison between the L1subscriptùêø1L_{1}-norm and L2subscriptùêø2L_{2}-norm shows that the L1subscriptùêø1L_{1}-norm generally outperforms higher-order norms. Moreover, we evaluate the impact of batch size by setting the mini-batch size to range from 1 to 128. Our experiments suggest that a larger batch size effectively reduces the variance of the gradient estimates. The results, shown in Table IX(b), indicate that a batch size selection around 16‚àº64similar-to166416\\sim 64 yields better performance across all settings."
        ]
    },
    "S4.T9.st1": {
        "caption": "(a) CIFAR-10",
        "table": "<table id=\"S4.T9.st1.8.8\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T9.st1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T9.st1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T9.st1.1.1.1.1.1\" class=\"ltx_text\"><math id=\"S4.T9.st1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"L_{p}\" display=\"inline\"><semantics id=\"S4.T9.st1.1.1.1.1.1.m1.1a\"><msub id=\"S4.T9.st1.1.1.1.1.1.m1.1.1\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.2\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1.2.cmml\">L</mi><mi id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.3\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1.3.cmml\">p</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.1.1.1.1.1.m1.1b\"><apply id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1.2\">ùêø</ci><ci id=\"S4.T9.st1.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T9.st1.1.1.1.1.1.m1.1.1.3\">ùëù</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.1.1.1.1.1.m1.1c\">L_{p}</annotation></semantics></math><span id=\"S4.T9.st1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">-Norm</span></span></th>\n<td id=\"S4.T9.st1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"5\"><span id=\"S4.T9.st1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Batch Size of Gradient Norm</span></td>\n</tr>\n<tr id=\"S4.T9.st1.6.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T9.st1.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st1.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{1}\" display=\"inline\"><semantics id=\"S4.T9.st1.2.2.2.1.m1.1a\"><mn id=\"S4.T9.st1.2.2.2.1.m1.1.1\" xref=\"S4.T9.st1.2.2.2.1.m1.1.1.cmml\">ùüè</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.2.2.2.1.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st1.2.2.2.1.m1.1.1.cmml\" xref=\"S4.T9.st1.2.2.2.1.m1.1.1\">1</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.2.2.2.1.m1.1c\">\\mathbf{1}</annotation></semantics></math></td>\n<td id=\"S4.T9.st1.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st1.3.3.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{16}\" display=\"inline\"><semantics id=\"S4.T9.st1.3.3.3.2.m1.1a\"><mn id=\"S4.T9.st1.3.3.3.2.m1.1.1\" xref=\"S4.T9.st1.3.3.3.2.m1.1.1.cmml\">ùüèùüî</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.3.3.3.2.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st1.3.3.3.2.m1.1.1.cmml\" xref=\"S4.T9.st1.3.3.3.2.m1.1.1\">16</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.3.3.3.2.m1.1c\">\\mathbf{16}</annotation></semantics></math></td>\n<td id=\"S4.T9.st1.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st1.4.4.4.3.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{32}\" display=\"inline\"><semantics id=\"S4.T9.st1.4.4.4.3.m1.1a\"><mn id=\"S4.T9.st1.4.4.4.3.m1.1.1\" xref=\"S4.T9.st1.4.4.4.3.m1.1.1.cmml\">ùüëùüê</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.4.4.4.3.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st1.4.4.4.3.m1.1.1.cmml\" xref=\"S4.T9.st1.4.4.4.3.m1.1.1\">32</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.4.4.4.3.m1.1c\">\\mathbf{32}</annotation></semantics></math></td>\n<td id=\"S4.T9.st1.5.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st1.5.5.5.4.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{64}\" display=\"inline\"><semantics id=\"S4.T9.st1.5.5.5.4.m1.1a\"><mn id=\"S4.T9.st1.5.5.5.4.m1.1.1\" xref=\"S4.T9.st1.5.5.5.4.m1.1.1.cmml\">ùüîùüí</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.5.5.5.4.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st1.5.5.5.4.m1.1.1.cmml\" xref=\"S4.T9.st1.5.5.5.4.m1.1.1\">64</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.5.5.5.4.m1.1c\">\\mathbf{64}</annotation></semantics></math></td>\n<td id=\"S4.T9.st1.6.6.6.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><math id=\"S4.T9.st1.6.6.6.5.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{128}\" display=\"inline\"><semantics id=\"S4.T9.st1.6.6.6.5.m1.1a\"><mn id=\"S4.T9.st1.6.6.6.5.m1.1.1\" xref=\"S4.T9.st1.6.6.6.5.m1.1.1.cmml\">ùüèùüêùüñ</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.6.6.6.5.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st1.6.6.6.5.m1.1.1.cmml\" xref=\"S4.T9.st1.6.6.6.5.m1.1.1\">128</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.6.6.6.5.m1.1c\">\\mathbf{128}</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T9.st1.7.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T9.st1.7.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">\n<math id=\"S4.T9.st1.7.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"L_{1}\" display=\"inline\"><semantics id=\"S4.T9.st1.7.7.7.1.m1.1a\"><msub id=\"S4.T9.st1.7.7.7.1.m1.1.1\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1.cmml\"><mi id=\"S4.T9.st1.7.7.7.1.m1.1.1.2\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1.2.cmml\">L</mi><mn id=\"S4.T9.st1.7.7.7.1.m1.1.1.3\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1.3.cmml\">1</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.7.7.7.1.m1.1b\"><apply id=\"S4.T9.st1.7.7.7.1.m1.1.1.cmml\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T9.st1.7.7.7.1.m1.1.1.1.cmml\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T9.st1.7.7.7.1.m1.1.1.2.cmml\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1.2\">ùêø</ci><cn type=\"integer\" id=\"S4.T9.st1.7.7.7.1.m1.1.1.3.cmml\" xref=\"S4.T9.st1.7.7.7.1.m1.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.7.7.7.1.m1.1c\">L_{1}</annotation></semantics></math>-Norm</th>\n<td id=\"S4.T9.st1.7.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.85</td>\n<td id=\"S4.T9.st1.7.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1.00</td>\n<td id=\"S4.T9.st1.7.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.00</td>\n<td id=\"S4.T9.st1.7.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.95</td>\n<td id=\"S4.T9.st1.7.7.7.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">0.90</td>\n</tr>\n<tr id=\"S4.T9.st1.8.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T9.st1.8.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">\n<math id=\"S4.T9.st1.8.8.8.1.m1.1\" class=\"ltx_Math\" alttext=\"L_{2}\" display=\"inline\"><semantics id=\"S4.T9.st1.8.8.8.1.m1.1a\"><msub id=\"S4.T9.st1.8.8.8.1.m1.1.1\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1.cmml\"><mi id=\"S4.T9.st1.8.8.8.1.m1.1.1.2\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1.2.cmml\">L</mi><mn id=\"S4.T9.st1.8.8.8.1.m1.1.1.3\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1.3.cmml\">2</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st1.8.8.8.1.m1.1b\"><apply id=\"S4.T9.st1.8.8.8.1.m1.1.1.cmml\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T9.st1.8.8.8.1.m1.1.1.1.cmml\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T9.st1.8.8.8.1.m1.1.1.2.cmml\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1.2\">ùêø</ci><cn type=\"integer\" id=\"S4.T9.st1.8.8.8.1.m1.1.1.3.cmml\" xref=\"S4.T9.st1.8.8.8.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st1.8.8.8.1.m1.1c\">L_{2}</annotation></semantics></math>-Norm</th>\n<td id=\"S4.T9.st1.8.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.90</td>\n<td id=\"S4.T9.st1.8.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.95</td>\n<td id=\"S4.T9.st1.8.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.90</td>\n<td id=\"S4.T9.st1.8.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.90</td>\n<td id=\"S4.T9.st1.8.8.8.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">0.95</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Recent works in FL mainly focus on addressing the data quality issues pertaining to the label space. Many strategies have been developed to deal with the disparity of label quality in FL. These methods mitigate the impact of label noise by conducting either client selection to re-weight model updates [22, 23, 24] or data sampling for label correction or exclusion [25, 26, 27, 28, 29]. Additionally, other works tackle this challenge by correcting the label error. [28] perform label noise correction using consensus-derived class-wise information for dynamic noise identification and label correction. [26] tackles label noise in federated learning by updating local models with globally aligned centroids and correcting labels through global model insights. In spite of the progress that has been made in resolving label noise, data subset selection¬†[7], data valuation¬†[30, 31], dealing with low-quality data in input space (i.e., when noise is in the samples like in images) in the federated setting still remains unexplored. Furthermore, we recognize that client data may be susceptible to backdoor attacks via adversarial methods during both inference and training time [32, 33]; these concerns fall outside the scope of our investigation. To this end, our method aims for a flexible and efficient solution suitable for a range of FL strategies to learn robust models using decentralized data.",
            "In FL, the formulation of the global model normally involves the aggregation of local models from each client, weighted based on the total count of data samples in their respective local datasets [1, 2]. When applying an average aggregation strategy when clients‚Äô data follows the IID setting, the contribution of each client‚Äôs model parameters to the server is equivalent. Consequently, in scenarios of noisy federated learning, the contribution of noisy clients can seriously degrade the generalization quality of the server-side aggregated model, as detailed in Table I.",
            "Baselines and Implementation. We apply FedNS¬†in conjunction with four widely used FL strategies to evaluate its effectiveness, namely FedAvg [2], FedProx [9], FedTrimmedAvg [10], and FedNova [11]. We employ ResNet-18 as the main model architecture, utilizing the mini-batch SGD as the universal local optimizer for all FL strategies. Moreover, we further evaluate FedNS¬†on a different neural architecture ConvMixer-256/8 in Table III. The optimizer is characterized by a learning rate of 0.010.010.01, an SGD momentum of 0.90.90.9, and the weight decay is set to 10‚àí4superscript10410^{-4}. We set the number of local training epochs to 555 and the global communication rounds to 150150150 across all datasets.\nWe consider a setup with N=20ùëÅ20N=20 clients for our experiments unless mentioned otherwise. This choice aligns with standard practices in FL and accommodates our computational limitations. The training set is distributed under both IID and non-IID settings. For the main experiments, we divide the client set into 151515 noisy clients and 555 clean clients, with full client participation rp=1.0subscriptùëüùëù1.0r_{p}=1.0. We compute L1subscriptùêø1L_{1}-norm of the gradient of last layer for noisy client detection in all the cases, see Table¬†IX(b) for comparison between the effectiveness of L1subscriptùêø1L_{1} and L2subscriptùêø2L_{2} norms, as well as the impact of batch size on the detection performance. We conducted all experiments on NVIDIA A10 GPUs.",
            "Participation of noisy clients deteriorates the performance of the global model. To validate the efficacy of our proposed method, we first conduct an experiment for model training with clean and noisy input across all the datasets and utilize the same noise configuration for our further empirical evaluation. With this, we aim to evaluate the upper-bound performance that can be achieved when learning from a mixture of noisy and clean clients. Table I presents the comparative results of average accuracy for all considered datasets. We focus on three specific distortions (i.e., defocus blur, Gaussian blur, contrast) due to their significant impact on degrading the model‚Äôs generalization capability to simulate the worst case in noisy FL.\nFor the generation of distorted data used in the experiments summarized in Table II, each noisy sample was produced by randomly selecting a distortion type with the configuration characterized by the noise severity level Œæ=h‚Äãi‚Äãg‚Äãhùúâ‚Ñéùëñùëî‚Ñé\\xi=high. We set the noise level to NLm=100%subscriptNLùëöpercent100\\emph{NL}_{m}=100\\% for every client mùëöm for the experiments of both Table II and Figure 6. We see the participation of noisy clients leads to a significant degradation in the model‚Äôs generalization capability across all tasks, indicating the detrimental impact of noisy data in the FL environment. Furthermore, due to the inherent lack of visibility into the data from these federated clients, the resultant global model tends to be of low quality and it may become challenging in a real-world setting to identify the underlying reasons for its poor performance.",
            "FedNS significantly improves standard federated aggregation methods. We investigate the robustness of our proposed method by applying FedNS on six image datasets with different settings under the noisy scenario. As shown in Table II, the performance of all aggregation methods exhibits a general trend of improvement by simply plugging FedNS to the considered strategies. In particular, we consider the worst-case with heterogeneous data setting in Table II, where 15 out of 20 noisy clients participate in the federated training with high noise severity and 100100100% noise level. Adding FedNS to FL strategies yields better overall performance among all the datasets, especially for some vulnerable datasets (e.g., Path-MNIST) that are sensitive to data corruption. Additionally, we demonstrate the efficacy of FedNS in dealing with patch-based noise on CIFAR-10 and Path-MNIST as presented in Figure 6. From Figure 6, we observe that FedNS consistently boosts the performance of the aggregation method across all the datasets and settings. This further shows that FedNS is capable of handling various types of noises a model can encounter in a real-world setting.",
            "Robustness of FedNS¬†on mixed noise conditions. Next, we investigate the robustness of FedNS¬†under complex noise conditions that involve a combination of different noise types, including the distortions and patch-based noises as described in Section IV-A. Table IV shows the performance gains achieved by FedNS¬†are particularly significant in high-variance datasets such as Path-MNIST and Tiny-ImageNet, where FedNova+NS demonstrates substantial improvements over standard aggregation. Notably, FedNS¬†consistently enhances the global model‚Äôs performance across all evaluated datasets, showcasing its robustness in handling intricate noise scenarios. Our results highlight the effectiveness of FedNS¬†in mitigating the impact of complex noise conditions, where decentralized data may be subject to various types of distortions at the same time.",
            "Evaluation on Weight Factor(Œ≤ùõΩ\\beta) of Noisy Client. We further investigate the effect of weight factor Œ≤ùõΩ\\beta on overall performance in FedNS. The weight factor Œ≤ùõΩ\\beta controls the weights of aggregated noisy client local models, as described in Equation 6. We considered various values of Œ≤‚àà{0,0.1,0.3,0.5,0.7,1.0}ùõΩ00.10.30.50.71.0\\beta\\in\\{0,0.1,0.3,0.5,0.7,1.0\\}, where Œ≤=0ùõΩ0\\beta=0 signifies the exclusion of noisy model weights, and Œ≤=1.0ùõΩ1.0\\beta=1.0 indicates the direct aggregation of model weights. As shown in Table V, the setting of Œ≤=0.3ùõΩ0.3\\beta=0.3 yields the best performance, suggesting an optimal trade-off. Interestingly, the exclusion of noisy model weights (Œ≤=0.0ùõΩ0.0\\beta=0.0) leads to a degradation in the generalization capability of the global model. This observation suggests that incorporating mitigated noisy data enhances the robustness of the global model.",
            "FedNS on Real-world Human Annotation Errors. In this experiment, we extend our investigation to assess the efficacy of FedNS in addressing real-world data quality issues, specifically human annotation errors. While this work focuses on mitigating data corruption in the input space, we identify that FedNS can effectively handle label noise - a well-studied problem in noisy FL. Label noise occurs when data labels are incorrectly assigned while the input features remain unaltered. Specifically, we assessed FedNS on CIFAR-10/100N, two benchmark datasets featuring real-world noisy labels resulting from human annotation errors [45]. We employed FedAvg and FedNova as baseline approaches, adhering to the training configuration outlined in Section IV-A. From Table VI, we observe that FedNS consistently improved the performance across all the experiments. Our findings demonstrate that FedNS not only excels in mitigating input space corruption but also shows promising results in handling label noise. The ability to address both input space corruption and label noise positions FedNS as a valuable tool for practitioners dealing with real-world datasets, where multiple types of data imperfections may coexist.",
            "Impact of Initial-Round Client Participation on FedNS Performance. In FL, the assumption that all clients must be warmed up and participate from the very first training round may not always hold true, as some clients may only participate in later rounds. To address this, we explore the scenario where only a subset of clients participates in the initial round. Instead of collecting gradient norms solely in the first round, we iteratively apply FedNS until all clients have been engaged. We evaluate this approach by setting the first-round participation rates to 10%, 50%, and 100%, with 100% representing full client participation. The results, presented in Table VII, highlight the robustness of FedNS across varying levels of initial-round client participation.",
            "FedNS on Different Noise Level (NL) of Client Data. In Table VIII, we examine the performance of FedNS¬†across various noise configurations. Specifically, we consider noise levels NL‚àà{50%,80%,100%}NLpercent50percent80percent100\\emph{NL}\\in\\{50\\%,80\\%,100\\%\\} and noise severity Œæ‚àà{M‚Äãe‚Äãd‚Äãi‚Äãu‚Äãm,H‚Äãi‚Äãg‚Äãh}ùúâùëÄùëíùëëùëñùë¢ùëöùêªùëñùëî‚Ñé\\xi\\in\\{Medium,High\\}. These results demonstrate that FedNS¬†substantially enhances model generalization under high noise conditions, especially when clients‚Äô data is completely corrupted (i.e., 100100100% noise level and high severity). Conversely, in scenarios with milder noise where the impact on federated models is minimal, the implementation of FedNS¬†does not negatively affect the generalization process. Hence, we limit our experiments to noise levels at or above 50%, as noise levels below this threshold have negligible impact on model performance.",
            "Hyperparameters Selections for Noisy Clients Detection. One of the essential components of FedNS¬†is using gradient norms to identify noisy clients. We investigate several factors that may affect the performance of detecting noisy clients, specifically the selection of the LpsubscriptùêøùëùL_{p}-norm and the batch size of gradient norms for clustering. This ablation experiment is performed on the CIFAR-10 and Path-MNIST datasets, as presented in Table IX(b).",
            "The comparison between the L1subscriptùêø1L_{1}-norm and L2subscriptùêø2L_{2}-norm shows that the L1subscriptùêø1L_{1}-norm generally outperforms higher-order norms. Moreover, we evaluate the impact of batch size by setting the mini-batch size to range from 1 to 128. Our experiments suggest that a larger batch size effectively reduces the variance of the gradient estimates. The results, shown in Table IX(b), indicate that a batch size selection around 16‚àº64similar-to166416\\sim 64 yields better performance across all settings.",
            "Evaluating FedNS¬†with alternative model architecture. In this experiment, we investigate the robustness of FedNS¬†when applied to a different model architecture. We employ the ConvMixer-256/8 [46] model and train it using FedNova on a range of datasets. The noise configuration remains consistent with the details provided in Section IV-B, and we evaluate the model‚Äôs performance under both IID and non-IID settings. As shown in Table III, the federated aggregation method, when paired with FedNS, achieves enhanced performance across all considered datasets. These improvements, observed consistently across tasks, demonstrate the adaptability and effectiveness of FedNS¬†when integrated with alternative architectural paradigms. The results highlight the versatility of our approach in enhancing the performance of different federated model regardless of the neural architecture, further emphasizing its potential as a robust and flexible method for FL."
        ]
    },
    "S4.T9.st2": {
        "caption": "(b) Path-MNIST",
        "table": "<table id=\"S4.T9.st2.8.8\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T9.st2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T9.st2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T9.st2.1.1.1.1.1\" class=\"ltx_text\"><math id=\"S4.T9.st2.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"L_{p}\" display=\"inline\"><semantics id=\"S4.T9.st2.1.1.1.1.1.m1.1a\"><msub id=\"S4.T9.st2.1.1.1.1.1.m1.1.1\" xref=\"S4.T9.st2.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T9.st2.1.1.1.1.1.m1.1.1.2\" xref=\"S4.T9.st2.1.1.1.1.1.m1.1.1.2.cmml\">L</mi><mi id=\"S4.T9.st2.1.1.1.1.1.m1.1.1.3\" xref=\"S4.T9.st2.1.1.1.1.1.m1.1.1.3.cmml\">p</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st2.1.1.1.1.1.m1.1b\"><apply id=\"S4.T9.st2.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T9.st2.1.1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T9.st2.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T9.st2.1.1.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T9.st2.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T9.st2.1.1.1.1.1.m1.1.1.2\">ùêø</ci><ci id=\"S4.T9.st2.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T9.st2.1.1.1.1.1.m1.1.1.3\">ùëù</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st2.1.1.1.1.1.m1.1c\">L_{p}</annotation></semantics></math><span id=\"S4.T9.st2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">-Norm</span></span></th>\n<td id=\"S4.T9.st2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"5\"><span id=\"S4.T9.st2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Batch Size of Gradient Norm</span></td>\n</tr>\n<tr id=\"S4.T9.st2.6.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T9.st2.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{1}\" display=\"inline\"><semantics id=\"S4.T9.st2.2.2.2.1.m1.1a\"><mn id=\"S4.T9.st2.2.2.2.1.m1.1.1\" xref=\"S4.T9.st2.2.2.2.1.m1.1.1.cmml\">ùüè</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st2.2.2.2.1.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st2.2.2.2.1.m1.1.1.cmml\" xref=\"S4.T9.st2.2.2.2.1.m1.1.1\">1</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st2.2.2.2.1.m1.1c\">\\mathbf{1}</annotation></semantics></math></td>\n<td id=\"S4.T9.st2.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st2.3.3.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{16}\" display=\"inline\"><semantics id=\"S4.T9.st2.3.3.3.2.m1.1a\"><mn id=\"S4.T9.st2.3.3.3.2.m1.1.1\" xref=\"S4.T9.st2.3.3.3.2.m1.1.1.cmml\">ùüèùüî</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st2.3.3.3.2.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st2.3.3.3.2.m1.1.1.cmml\" xref=\"S4.T9.st2.3.3.3.2.m1.1.1\">16</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st2.3.3.3.2.m1.1c\">\\mathbf{16}</annotation></semantics></math></td>\n<td id=\"S4.T9.st2.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st2.4.4.4.3.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{32}\" display=\"inline\"><semantics id=\"S4.T9.st2.4.4.4.3.m1.1a\"><mn id=\"S4.T9.st2.4.4.4.3.m1.1.1\" xref=\"S4.T9.st2.4.4.4.3.m1.1.1.cmml\">ùüëùüê</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st2.4.4.4.3.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st2.4.4.4.3.m1.1.1.cmml\" xref=\"S4.T9.st2.4.4.4.3.m1.1.1\">32</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st2.4.4.4.3.m1.1c\">\\mathbf{32}</annotation></semantics></math></td>\n<td id=\"S4.T9.st2.5.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T9.st2.5.5.5.4.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{64}\" display=\"inline\"><semantics id=\"S4.T9.st2.5.5.5.4.m1.1a\"><mn id=\"S4.T9.st2.5.5.5.4.m1.1.1\" xref=\"S4.T9.st2.5.5.5.4.m1.1.1.cmml\">ùüîùüí</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st2.5.5.5.4.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st2.5.5.5.4.m1.1.1.cmml\" xref=\"S4.T9.st2.5.5.5.4.m1.1.1\">64</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st2.5.5.5.4.m1.1c\">\\mathbf{64}</annotation></semantics></math></td>\n<td id=\"S4.T9.st2.6.6.6.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><math id=\"S4.T9.st2.6.6.6.5.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{128}\" display=\"inline\"><semantics id=\"S4.T9.st2.6.6.6.5.m1.1a\"><mn id=\"S4.T9.st2.6.6.6.5.m1.1.1\" xref=\"S4.T9.st2.6.6.6.5.m1.1.1.cmml\">ùüèùüêùüñ</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st2.6.6.6.5.m1.1b\"><cn type=\"integer\" id=\"S4.T9.st2.6.6.6.5.m1.1.1.cmml\" xref=\"S4.T9.st2.6.6.6.5.m1.1.1\">128</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st2.6.6.6.5.m1.1c\">\\mathbf{128}</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T9.st2.7.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T9.st2.7.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">\n<math id=\"S4.T9.st2.7.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"L_{1}\" display=\"inline\"><semantics id=\"S4.T9.st2.7.7.7.1.m1.1a\"><msub id=\"S4.T9.st2.7.7.7.1.m1.1.1\" xref=\"S4.T9.st2.7.7.7.1.m1.1.1.cmml\"><mi id=\"S4.T9.st2.7.7.7.1.m1.1.1.2\" xref=\"S4.T9.st2.7.7.7.1.m1.1.1.2.cmml\">L</mi><mn id=\"S4.T9.st2.7.7.7.1.m1.1.1.3\" xref=\"S4.T9.st2.7.7.7.1.m1.1.1.3.cmml\">1</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st2.7.7.7.1.m1.1b\"><apply id=\"S4.T9.st2.7.7.7.1.m1.1.1.cmml\" xref=\"S4.T9.st2.7.7.7.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T9.st2.7.7.7.1.m1.1.1.1.cmml\" xref=\"S4.T9.st2.7.7.7.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T9.st2.7.7.7.1.m1.1.1.2.cmml\" xref=\"S4.T9.st2.7.7.7.1.m1.1.1.2\">ùêø</ci><cn type=\"integer\" id=\"S4.T9.st2.7.7.7.1.m1.1.1.3.cmml\" xref=\"S4.T9.st2.7.7.7.1.m1.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st2.7.7.7.1.m1.1c\">L_{1}</annotation></semantics></math>-Norm</th>\n<td id=\"S4.T9.st2.7.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.75</td>\n<td id=\"S4.T9.st2.7.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1.00</td>\n<td id=\"S4.T9.st2.7.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.00</td>\n<td id=\"S4.T9.st2.7.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">1.00</td>\n<td id=\"S4.T9.st2.7.7.7.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">0.90</td>\n</tr>\n<tr id=\"S4.T9.st2.8.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T9.st2.8.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">\n<math id=\"S4.T9.st2.8.8.8.1.m1.1\" class=\"ltx_Math\" alttext=\"L_{2}\" display=\"inline\"><semantics id=\"S4.T9.st2.8.8.8.1.m1.1a\"><msub id=\"S4.T9.st2.8.8.8.1.m1.1.1\" xref=\"S4.T9.st2.8.8.8.1.m1.1.1.cmml\"><mi id=\"S4.T9.st2.8.8.8.1.m1.1.1.2\" xref=\"S4.T9.st2.8.8.8.1.m1.1.1.2.cmml\">L</mi><mn id=\"S4.T9.st2.8.8.8.1.m1.1.1.3\" xref=\"S4.T9.st2.8.8.8.1.m1.1.1.3.cmml\">2</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.st2.8.8.8.1.m1.1b\"><apply id=\"S4.T9.st2.8.8.8.1.m1.1.1.cmml\" xref=\"S4.T9.st2.8.8.8.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T9.st2.8.8.8.1.m1.1.1.1.cmml\" xref=\"S4.T9.st2.8.8.8.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T9.st2.8.8.8.1.m1.1.1.2.cmml\" xref=\"S4.T9.st2.8.8.8.1.m1.1.1.2\">ùêø</ci><cn type=\"integer\" id=\"S4.T9.st2.8.8.8.1.m1.1.1.3.cmml\" xref=\"S4.T9.st2.8.8.8.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.st2.8.8.8.1.m1.1c\">L_{2}</annotation></semantics></math>-Norm</th>\n<td id=\"S4.T9.st2.8.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.60</td>\n<td id=\"S4.T9.st2.8.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.75</td>\n<td id=\"S4.T9.st2.8.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.85</td>\n<td id=\"S4.T9.st2.8.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.90</td>\n<td id=\"S4.T9.st2.8.8.8.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">0.90</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Recent works in FL mainly focus on addressing the data quality issues pertaining to the label space. Many strategies have been developed to deal with the disparity of label quality in FL. These methods mitigate the impact of label noise by conducting either client selection to re-weight model updates [22, 23, 24] or data sampling for label correction or exclusion [25, 26, 27, 28, 29]. Additionally, other works tackle this challenge by correcting the label error. [28] perform label noise correction using consensus-derived class-wise information for dynamic noise identification and label correction. [26] tackles label noise in federated learning by updating local models with globally aligned centroids and correcting labels through global model insights. In spite of the progress that has been made in resolving label noise, data subset selection¬†[7], data valuation¬†[30, 31], dealing with low-quality data in input space (i.e., when noise is in the samples like in images) in the federated setting still remains unexplored. Furthermore, we recognize that client data may be susceptible to backdoor attacks via adversarial methods during both inference and training time [32, 33]; these concerns fall outside the scope of our investigation. To this end, our method aims for a flexible and efficient solution suitable for a range of FL strategies to learn robust models using decentralized data.",
            "In FL, the formulation of the global model normally involves the aggregation of local models from each client, weighted based on the total count of data samples in their respective local datasets [1, 2]. When applying an average aggregation strategy when clients‚Äô data follows the IID setting, the contribution of each client‚Äôs model parameters to the server is equivalent. Consequently, in scenarios of noisy federated learning, the contribution of noisy clients can seriously degrade the generalization quality of the server-side aggregated model, as detailed in Table I.",
            "Baselines and Implementation. We apply FedNS¬†in conjunction with four widely used FL strategies to evaluate its effectiveness, namely FedAvg [2], FedProx [9], FedTrimmedAvg [10], and FedNova [11]. We employ ResNet-18 as the main model architecture, utilizing the mini-batch SGD as the universal local optimizer for all FL strategies. Moreover, we further evaluate FedNS¬†on a different neural architecture ConvMixer-256/8 in Table III. The optimizer is characterized by a learning rate of 0.010.010.01, an SGD momentum of 0.90.90.9, and the weight decay is set to 10‚àí4superscript10410^{-4}. We set the number of local training epochs to 555 and the global communication rounds to 150150150 across all datasets.\nWe consider a setup with N=20ùëÅ20N=20 clients for our experiments unless mentioned otherwise. This choice aligns with standard practices in FL and accommodates our computational limitations. The training set is distributed under both IID and non-IID settings. For the main experiments, we divide the client set into 151515 noisy clients and 555 clean clients, with full client participation rp=1.0subscriptùëüùëù1.0r_{p}=1.0. We compute L1subscriptùêø1L_{1}-norm of the gradient of last layer for noisy client detection in all the cases, see Table¬†IX(b) for comparison between the effectiveness of L1subscriptùêø1L_{1} and L2subscriptùêø2L_{2} norms, as well as the impact of batch size on the detection performance. We conducted all experiments on NVIDIA A10 GPUs.",
            "Participation of noisy clients deteriorates the performance of the global model. To validate the efficacy of our proposed method, we first conduct an experiment for model training with clean and noisy input across all the datasets and utilize the same noise configuration for our further empirical evaluation. With this, we aim to evaluate the upper-bound performance that can be achieved when learning from a mixture of noisy and clean clients. Table I presents the comparative results of average accuracy for all considered datasets. We focus on three specific distortions (i.e., defocus blur, Gaussian blur, contrast) due to their significant impact on degrading the model‚Äôs generalization capability to simulate the worst case in noisy FL.\nFor the generation of distorted data used in the experiments summarized in Table II, each noisy sample was produced by randomly selecting a distortion type with the configuration characterized by the noise severity level Œæ=h‚Äãi‚Äãg‚Äãhùúâ‚Ñéùëñùëî‚Ñé\\xi=high. We set the noise level to NLm=100%subscriptNLùëöpercent100\\emph{NL}_{m}=100\\% for every client mùëöm for the experiments of both Table II and Figure 6. We see the participation of noisy clients leads to a significant degradation in the model‚Äôs generalization capability across all tasks, indicating the detrimental impact of noisy data in the FL environment. Furthermore, due to the inherent lack of visibility into the data from these federated clients, the resultant global model tends to be of low quality and it may become challenging in a real-world setting to identify the underlying reasons for its poor performance.",
            "FedNS significantly improves standard federated aggregation methods. We investigate the robustness of our proposed method by applying FedNS on six image datasets with different settings under the noisy scenario. As shown in Table II, the performance of all aggregation methods exhibits a general trend of improvement by simply plugging FedNS to the considered strategies. In particular, we consider the worst-case with heterogeneous data setting in Table II, where 15 out of 20 noisy clients participate in the federated training with high noise severity and 100100100% noise level. Adding FedNS to FL strategies yields better overall performance among all the datasets, especially for some vulnerable datasets (e.g., Path-MNIST) that are sensitive to data corruption. Additionally, we demonstrate the efficacy of FedNS in dealing with patch-based noise on CIFAR-10 and Path-MNIST as presented in Figure 6. From Figure 6, we observe that FedNS consistently boosts the performance of the aggregation method across all the datasets and settings. This further shows that FedNS is capable of handling various types of noises a model can encounter in a real-world setting.",
            "Robustness of FedNS¬†on mixed noise conditions. Next, we investigate the robustness of FedNS¬†under complex noise conditions that involve a combination of different noise types, including the distortions and patch-based noises as described in Section IV-A. Table IV shows the performance gains achieved by FedNS¬†are particularly significant in high-variance datasets such as Path-MNIST and Tiny-ImageNet, where FedNova+NS demonstrates substantial improvements over standard aggregation. Notably, FedNS¬†consistently enhances the global model‚Äôs performance across all evaluated datasets, showcasing its robustness in handling intricate noise scenarios. Our results highlight the effectiveness of FedNS¬†in mitigating the impact of complex noise conditions, where decentralized data may be subject to various types of distortions at the same time.",
            "Evaluation on Weight Factor(Œ≤ùõΩ\\beta) of Noisy Client. We further investigate the effect of weight factor Œ≤ùõΩ\\beta on overall performance in FedNS. The weight factor Œ≤ùõΩ\\beta controls the weights of aggregated noisy client local models, as described in Equation 6. We considered various values of Œ≤‚àà{0,0.1,0.3,0.5,0.7,1.0}ùõΩ00.10.30.50.71.0\\beta\\in\\{0,0.1,0.3,0.5,0.7,1.0\\}, where Œ≤=0ùõΩ0\\beta=0 signifies the exclusion of noisy model weights, and Œ≤=1.0ùõΩ1.0\\beta=1.0 indicates the direct aggregation of model weights. As shown in Table V, the setting of Œ≤=0.3ùõΩ0.3\\beta=0.3 yields the best performance, suggesting an optimal trade-off. Interestingly, the exclusion of noisy model weights (Œ≤=0.0ùõΩ0.0\\beta=0.0) leads to a degradation in the generalization capability of the global model. This observation suggests that incorporating mitigated noisy data enhances the robustness of the global model.",
            "FedNS on Real-world Human Annotation Errors. In this experiment, we extend our investigation to assess the efficacy of FedNS in addressing real-world data quality issues, specifically human annotation errors. While this work focuses on mitigating data corruption in the input space, we identify that FedNS can effectively handle label noise - a well-studied problem in noisy FL. Label noise occurs when data labels are incorrectly assigned while the input features remain unaltered. Specifically, we assessed FedNS on CIFAR-10/100N, two benchmark datasets featuring real-world noisy labels resulting from human annotation errors [45]. We employed FedAvg and FedNova as baseline approaches, adhering to the training configuration outlined in Section IV-A. From Table VI, we observe that FedNS consistently improved the performance across all the experiments. Our findings demonstrate that FedNS not only excels in mitigating input space corruption but also shows promising results in handling label noise. The ability to address both input space corruption and label noise positions FedNS as a valuable tool for practitioners dealing with real-world datasets, where multiple types of data imperfections may coexist.",
            "Impact of Initial-Round Client Participation on FedNS Performance. In FL, the assumption that all clients must be warmed up and participate from the very first training round may not always hold true, as some clients may only participate in later rounds. To address this, we explore the scenario where only a subset of clients participates in the initial round. Instead of collecting gradient norms solely in the first round, we iteratively apply FedNS until all clients have been engaged. We evaluate this approach by setting the first-round participation rates to 10%, 50%, and 100%, with 100% representing full client participation. The results, presented in Table VII, highlight the robustness of FedNS across varying levels of initial-round client participation.",
            "FedNS on Different Noise Level (NL) of Client Data. In Table VIII, we examine the performance of FedNS¬†across various noise configurations. Specifically, we consider noise levels NL‚àà{50%,80%,100%}NLpercent50percent80percent100\\emph{NL}\\in\\{50\\%,80\\%,100\\%\\} and noise severity Œæ‚àà{M‚Äãe‚Äãd‚Äãi‚Äãu‚Äãm,H‚Äãi‚Äãg‚Äãh}ùúâùëÄùëíùëëùëñùë¢ùëöùêªùëñùëî‚Ñé\\xi\\in\\{Medium,High\\}. These results demonstrate that FedNS¬†substantially enhances model generalization under high noise conditions, especially when clients‚Äô data is completely corrupted (i.e., 100100100% noise level and high severity). Conversely, in scenarios with milder noise where the impact on federated models is minimal, the implementation of FedNS¬†does not negatively affect the generalization process. Hence, we limit our experiments to noise levels at or above 50%, as noise levels below this threshold have negligible impact on model performance.",
            "Hyperparameters Selections for Noisy Clients Detection. One of the essential components of FedNS¬†is using gradient norms to identify noisy clients. We investigate several factors that may affect the performance of detecting noisy clients, specifically the selection of the LpsubscriptùêøùëùL_{p}-norm and the batch size of gradient norms for clustering. This ablation experiment is performed on the CIFAR-10 and Path-MNIST datasets, as presented in Table IX(b).",
            "The comparison between the L1subscriptùêø1L_{1}-norm and L2subscriptùêø2L_{2}-norm shows that the L1subscriptùêø1L_{1}-norm generally outperforms higher-order norms. Moreover, we evaluate the impact of batch size by setting the mini-batch size to range from 1 to 128. Our experiments suggest that a larger batch size effectively reduces the variance of the gradient estimates. The results, shown in Table IX(b), indicate that a batch size selection around 16‚àº64similar-to166416\\sim 64 yields better performance across all settings.",
            "Evaluating FedNS¬†with alternative model architecture. In this experiment, we investigate the robustness of FedNS¬†when applied to a different model architecture. We employ the ConvMixer-256/8 [46] model and train it using FedNova on a range of datasets. The noise configuration remains consistent with the details provided in Section IV-B, and we evaluate the model‚Äôs performance under both IID and non-IID settings. As shown in Table III, the federated aggregation method, when paired with FedNS, achieves enhanced performance across all considered datasets. These improvements, observed consistently across tasks, demonstrate the adaptability and effectiveness of FedNS¬†when integrated with alternative architectural paradigms. The results highlight the versatility of our approach in enhancing the performance of different federated model regardless of the neural architecture, further emphasizing its potential as a robust and flexible method for FL."
        ]
    }
}