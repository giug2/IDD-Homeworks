{
    "S4.T1": {
        "caption": "Table 1: Results on Novel Compositional Concept.",
        "table": null,
        "footnotes": [],
        "references": [
            "We report the performance under both novel and seen settings as shown in Table 1 and Table 2.\nFrom the two tables, we can see that MetaReVision does help compositional learning, especially in the novel setting.",
            "Novel Compositions.\nAs shown in Table 1, MetaReVision improves the performance on the novel setting compared to the pre-trained model and MAML models.\nThis suggests that MetaReVision captures a generic representation which is beneficial for compositional learning through meta-learning on the retrieved tasks.\nHowever, compared with seen compositions (i.e., Table 2), the performance on novel pairs drops significantly across the board.\nMetaReVision’s accuracy drops by about 20%percent2020\\% on CompCOCO dataset in novel setting compared with the seen setting. This indicates that such compositional generalization is still a very difficult and open task for current VL models."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Results on Seen Compositional Concept.",
        "table": null,
        "footnotes": [],
        "references": [
            "We report the performance under both novel and seen settings as shown in Table 1 and Table 2.\nFrom the two tables, we can see that MetaReVision does help compositional learning, especially in the novel setting.",
            "Novel Compositions.\nAs shown in Table 1, MetaReVision improves the performance on the novel setting compared to the pre-trained model and MAML models.\nThis suggests that MetaReVision captures a generic representation which is beneficial for compositional learning through meta-learning on the retrieved tasks.\nHowever, compared with seen compositions (i.e., Table 2), the performance on novel pairs drops significantly across the board.\nMetaReVision’s accuracy drops by about 20%percent2020\\% on CompCOCO dataset in novel setting compared with the seen setting. This indicates that such compositional generalization is still a very difficult and open task for current VL models.",
            "Seen Compositions.\nTable 2 shows the performance in the seen setting.\nFrom the table, we can see that all models have similar accuracy in the seen setting.\nOne possible reason is that all the models have been fully trained using the seen compositional concepts.\nMAML-based methods do not hurt the in-domain performance during this meta-learning phase."
        ]
    },
    "A2.T3": {
        "caption": "Table 3: Episode examples constructed by MetaReVison’s retrieval modules.",
        "table": null,
        "footnotes": [],
        "references": [
            "Table 3 shows episode examples constructed in MetaReVision. From the table, we can see that MetaReVision can retrieve true element concepts for target compositional concepts, such as white truck, bird fly, boy eat. But there also exist cases we can not find true element concepts in the retrieved support set, such as blue bus. In this example, MetaReVision can retrieve many similar objects, but has a challenge to retrieve the true color blue. Also, from these randomly sampled episodes, we can see that in GCCL, objects are easier to be retrieved compared to objects."
        ]
    },
    "A4.T4": {
        "caption": "Table 4: Novel Pair Statistics for both CompCOCO and CompFlickr. We use the same 242424 pairs to verify the compositional generalization.",
        "table": null,
        "footnotes": [],
        "references": [
            "Table 4 shows the statistics of the extracted novel compositional concepts. From the table, we can see that CompCOCO has more novel pairs than CompFlickr.\nAnd CompCOCO is a more reliable evaluation for novel compositional learning than And CompFlickr"
        ]
    }
}