{
    "id_table_1": {
        "caption": "Table  \\thetable :  Synthetic Data Quality Evaluation Criteria",
        "table": "section1.tab1.4",
        "footnotes": [],
        "references": [
            "The primary purpose of the annotation is to assess the quality of synthetically generated user-agent conversations. Each dialog is grounded on one or more (up to five) document passages. Evaluation should be carried out on the basis of the information available from the documents. Evaluation criteria are summarized in Table  1 . Note the relationship between query answerability and response correctness as follows:"
        ]
    },
    "id_table_2": {
        "caption": "Table  \\thetable :  Benchmark testset performances on models fined-tuned on various types of training data",
        "table": "section2.tab1.4",
        "footnotes": [],
        "references": []
    },
    "id_table_3": {
        "caption": "Table  \\thetable :  Benchmark data performance of models fined-tuned on various types of training data",
        "table": "section2.tab2.4",
        "footnotes": [],
        "references": []
    }
}