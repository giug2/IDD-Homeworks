{
    "S4.T1": {
        "caption": "Table 1. Model performance on various datasets under different few-shot settings (Accuracy).",
        "table": null,
        "footnotes": [],
        "references": [
            "The experimental results on four datasets on six distinctive settings are summarized in Table 1.\nWe have the following observations:\n1)\nIn general, TEG outperforms all the baselines that do not take the task-equivariance in embedding space into account.\nWe attribute this to the generalization ability of TEG, which is achieved by introducing the concept of equivariance into the model.\nTask-equivariance facilitates the adaptation of our model to unseen meta-tasks that have similar task-patterns by enabling the sharing of the task-adaptation strategy.\nA more detailed and intuitive analysis will be discussed in the following section.\n2)\nGenerally, increasing K𝐾K (i.e., the number of support nodes within each meta-task) improves the performance of all methods, as FSL relies on limited data.\nFSL tends to be sensitive to reference data (i.e., support set), so having more references for each class leads to a more accurate representation, reducing the impact of outliers.\n3)\nAs the number of classes within each meta-task N𝑁N increases, the overall model performance deteriorates significantly since greater challenges in generalization are posed.\nHowever, TEG, which leverages instance relationships to extract meta-knowledge, still outperforms the baseline methods, again demonstrating the generalization ability of the model.\nSpecifically, the performance gap between our model and the runner-up grows larger as N𝑁N increases across all settings.\n4)\nAdditionally, as depicted in Figure 4, our model consistently outperforms baseline methods throughout all training steps.\nEven in the initial training epochs, where all the models are trained with a limited number of meta-tasks, TEG shows a large performance improvement compared to the baseline methods.\nThis is because TEG  quickly extracts well-generalized meta-knowledge even with a small number of meta-tasks by utilizing the equivariant task embeddings.\n5)\nIt is worth noting that among the metric-based methods, the method with sophisticated task-specific embedding mechanisms to manage high variance in meta-tasks, i.e., TENT, outperforms the method with a simple graph embedder, demonstrating the importance of tasks-specific embedder.\nHowever, we find out that TENT’s performance decreases after reaching a peak in the early epochs as shown in Figure 4 (a) and (b).\nThis is because TENT’s approach of treating each meta-task independently results in reduced transferability of task-adaptation strategies, easily causing overfitting to the training class.\nOn the other hand, our task embedder is equipped with task-equivariance, allowing it to learn transferable meta-knowledge and prevent overfitting to meta-training tasks."
        ]
    },
    "S5.T2": {
        "caption": "Table 2. Statistics of evaluation datasets.",
        "table": null,
        "footnotes": [],
        "references": [
            "We use five real-world datasets, i.e., Cora-full (Bojchevski and Günnemann, 2017), Amazon Clothing (McAuley et al., 2015), Amazon Electronics (McAuley et al., 2015), DBLP (Tang et al., 2008) and Coauthor-CS (Sinha et al., 2015), to comprehensively evaluate the performance of TEG, whose details are provided in Appendix A.1.\nWe also provide statistics for the datasets in Table 2."
        ]
    },
    "S5.T3": {
        "caption": "Table 3. Model performance on the limited diversity of meta-training dataset (Accuracy).",
        "table": null,
        "footnotes": [],
        "references": [
            "In this section, we examine how the diversity of meta-train tasks affects the performance of models using an episodic meta-learning approach by conducting experiments on a limited number of classes and data instances.\nSpecifically, we train the models with the training set that contains the various portion of the whole classes and instances in each class, then evaluate them on meta-testing tasks containing all classes and instances in each class.\nThe overall results are depicted in Figure 6 and Table 3.\nWe have the following observations:\n1) In Figure 6, the performance of all models degrades as the number of classes and label availability decrease (i.e., towards bottom right corner).\nOn the other hand, we observe that when either the number of classes or label availability is sufficient, models do not suffer from performance degradation.\nThis indicates sufficient information of either one makes up for the lack of diversity of the counterpart, thereby maintaining the overall performance.\n2) Meanwhile, we observe that the performance of TEG in an extreme case, i.e., 10 classes with 1% instances each, is comparable to that of other methods in the easiest case, i.e., 50 classes with 100% instances each.\nThis highlights our model’s high generalization ability to obtain meta-knowledge for a wide range of meta-tasks with limited training meta-tasks.\n3) Moreover, our model achieves further performance improvements compared to the baseline methods as the diversity of tasks decreases as shown in Table 3 in which the diversity of tasks decreases from 50%/10% to 10%/1% in each setting.\nThis result demonstrates the real-world applicability of our model, where an abundant amount of labels and data are not provided.\nTo summarize our findings, TEG  outperforms other models when faced with limited meta-training tasks and has a strong ability to adapt to new tasks with minimal training data, which is common in real-world scenarios."
        ]
    },
    "S5.T4": {
        "caption": "Table 4. Model performance on Coauthor-CS dataset under different few-shot settings (Accuracy).",
        "table": null,
        "footnotes": [],
        "references": [
            "We further investigate the impact of diversity with Coauthor-CS dataset, which is a real-world dataset inherently having a few classes.\nSpecifically, we fix train/valid/test classes into 5/5/5, respectively, and then compare the model performance in 2 main settings: 2-way K𝐾K-shot and 555-way K𝐾K-shot settings.\nNote that, in the 2-way settings, all methods can be trained with meta-training tasks composed of 10 class combinations (i.e., C25superscriptsubscript𝐶25{}^{5}C_{2}) ensuring an acceptable level of diversity within the meta-tasks.\nIn the 5-way settings, however, only one combination (i.e., C55superscriptsubscript𝐶55{}^{5}C_{5}) of classes can be used, making it challenging for the baselines to extract meta-knowledge due to the low diversity within the meta-tasks.\nAs shown in Table 4, we find out that the performance improvements of TEG compaerd with the best-performing baseline are significantly higher in the 5-way settings (i.e., low-diversity scenarios), demonstrating the outstanding ability to extract meta-knowledge from low-diversity meta-tasks.\nTherefore, we argue that previous meta-learning baselines struggle to extract meta-knowledge when faced with the low-diversity meta-tasks, while our model effectively handles low-diversity scenarios with exceptional generalization ability."
        ]
    },
    "A1.T5": {
        "caption": "Table 5. Effect of using virtual anchor node for alleviating no-path-to-reach problem. AC and AE denotes ”Amazon Clothing” and ”Amazon Electronics”, respectively.",
        "table": null,
        "footnotes": [],
        "references": [
            "When calculating the shortest path distance ds​p​(v,u)superscript𝑑𝑠𝑝𝑣𝑢d^{sp}(v,u) between two different nodes v𝑣v and u𝑢u, if node v𝑣v is unable to reach the target node u𝑢u, the value of ds​p​(v,u)superscript𝑑𝑠𝑝𝑣𝑢d^{sp}(v,u) becomes infinity, resulting in s​(u,v)𝑠𝑢𝑣s(u,v) being equal to 0.\nHaving an excessive number of 0s in the feature can result in a lack of sufficient structural information.\nTo address this issue, we mitigate the problem by introducing virtual anchor nodes.\nSpecifically, in Table 5, we observe that when structural features are generated based on randomly selected anchor nodes (i.e., w.o. virtual anchor nodes), particularly in the case of Amazon Electronics, a severe problem arises where 98.5% of the target nodes do not have any path to reach the anchor node.\nIn other words, alternative calculation methods that utilize the original graph, such as Random Walks and PGNN (You et al., 2019), would also suffer from the same problem, as they do not consider virtual anchor nodes.\nHowever, our approach (i.e., with virtual anchor nodes) effectively mitigates this problem, reducing the zero ratio from 98.5% to 1.4% in Amazon Electronics."
        ]
    },
    "A1.T6": {
        "caption": "Table 6. Process of task-adaptation in a task embedder",
        "table": null,
        "footnotes": [],
        "references": [
            "Table 6 summarizes the task embedder process and indicates each step’s equivariance/invariance to transformations (i.e., translation, rotation, reflection)."
        ]
    }
}