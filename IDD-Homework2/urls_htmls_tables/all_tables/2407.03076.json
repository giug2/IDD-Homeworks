{
    "S3.E1": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S3.E2": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S3.E3": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S3.E4": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S3.E5": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S4.T1.1.1": {
        "caption": "Data statistics for our experiments.  ,   represent the number of sentences and documents, respectively. The numbers are shown in the Train/Validation/Test set order.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.1.1\">Data</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.2.1\"># Sent</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.1.1.3.1\"># Doc</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.1.1.2.1.1\">News</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.2.1.2\">329,000/3,004/2,998</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.2.1.3\">8,462/130/122</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.1.3.2.1\">TED</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.3.2.2\">206,112/8,967/2,271</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.3.2.3\">1,698/93/23</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.1.1.4.3.1\">Europarl</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.4.3.2\">1,666,904/3,587/5,134</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.1.4.3.3\">117,855/240/360</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We conduct experiments on WMT news-commentary, IWSLT‘17 TED, and Europarl-v7 German-English corpora. For the WMT news-commentary, we use news-commentary v14 [Barrault et al., 2019]222https://data.statmt.org/news-commentary/v14/training/ as the train set, newstest2017 as the validation set, and newstest2018 as the test set. For IWSLT‘17 TED and Europarl-v7 corpora, we follow the train, validation, and test set splits mentioned in [Maruf et al., 2019]333https://github.com/sameenmaruf/selective-attn/tree/master/data. All models are trained on German to English. Table 1 shows data statistics of the train, validation, and test sets.\n"
        ]
    },
    "S4.T2.3": {
        "caption": "BLEU scores of Vanilla-Sent, Concat-Context, and proposed MTL DocNMT models trained with different source contexts for German to English direction on News-commentary v14, IWSTL-17 TED, and Europarl corpora.   and   represent sentence-level and document-level BLEU respectively. The best results are shown in bold. ‘ ’ denotes the statistically significant results than Vanilla-Sent and Concat-Context models with  .",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.3\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.3.4.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T2.3.4.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.4.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T2.3.4.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.4.1.2.1\">News</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.3.4.1.3\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T2.3.4.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.4.1.4.1\">TED</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.3.4.1.5\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T2.3.4.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.4.1.6.1\">Europarl</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.5.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.5.2.1\">s-BLEU</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.5.2.2\">d-BLEU</th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"S4.T2.3.5.2.3\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.5.2.4\">s-BLEU</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.5.2.5\">d-BLEU</th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"S4.T2.3.5.2.6\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.5.2.7\">s-BLEU</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.5.2.8\">d-BLEU</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.6.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T2.3.6.3.1\">Vanilla-Sent</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.6.3.2\">18.3</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.6.3.3\">20.9</th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.6.3.4\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.6.3.5\">19.9</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.6.3.6\">24.9</th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.6.3.7\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.6.3.8\">32.3</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.3.6.3.9\">35.1</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.3.7.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.3.7.1.1\">Concat-Context: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.7.1.2\">18.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.7.1.3\">20.5</td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.3.7.1.4\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.7.1.5\">17.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.7.1.6\">22.4</td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.3.7.1.7\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.7.1.8\">32.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.7.1.9\">35.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.8.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.3.8.2.1\">Concat-Context: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.2.2\">18.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.2.3\">20.7</td>\n<td class=\"ltx_td\" id=\"S4.T2.3.8.2.4\"/>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.2.5\">17.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.2.6\">22.5</td>\n<td class=\"ltx_td\" id=\"S4.T2.3.8.2.7\"/>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.2.8\">32.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.8.2.9\">35.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.9.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.3.9.3.1\">Concat-Context: P@2-TGT</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.3.2\">14.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.3.3\">17.2</td>\n<td class=\"ltx_td\" id=\"S4.T2.3.9.3.4\"/>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.3.5\">15.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.3.6\">20.4</td>\n<td class=\"ltx_td\" id=\"S4.T2.3.9.3.7\"/>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.3.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.9.3.8.1\">36.4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.3.9.3.9\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.9.3.9.1\">39.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.10.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.3.10.4.1\">MTL: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.10.4.2\">19.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.10.4.3\">21.7</td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.3.10.4.4\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.10.4.5\">20.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.10.4.6\">24.8</td>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.3.10.4.7\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.10.4.8\">29.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.3.10.4.9\">32.6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.2.2.3\">MTL: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.1\"><math alttext=\"\\textbf{20.1}^{{\\dagger}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.1.1.1.m1.1\"><semantics id=\"S4.T2.1.1.1.m1.1a\"><msup id=\"S4.T2.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T2.1.1.1.m1.1.1.2\" xref=\"S4.T2.1.1.1.m1.1.1.2a.cmml\">20.1</mtext><mo id=\"S4.T2.1.1.1.m1.1.1.3\" xref=\"S4.T2.1.1.1.m1.1.1.3.cmml\">&#8224;</mo></msup><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.m1.1b\"><apply id=\"S4.T2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T2.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"S4.T2.1.1.1.m1.1.1.2a.cmml\" xref=\"S4.T2.1.1.1.m1.1.1.2\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T2.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T2.1.1.1.m1.1.1.2\">20.1</mtext></ci><ci id=\"S4.T2.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T2.1.1.1.m1.1.1.3\">&#8224;</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.m1.1c\">\\textbf{20.1}^{{\\dagger}}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.1.1.1.m1.1d\">20.1 start_POSTSUPERSCRIPT &#8224; end_POSTSUPERSCRIPT</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.2.2.4.1\">22.5</span></td>\n<td class=\"ltx_td\" id=\"S4.T2.2.2.5\"/>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.2.6\">20.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.2.7\">25.2</td>\n<td class=\"ltx_td\" id=\"S4.T2.2.2.8\"/>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.2.2\"><math alttext=\"32.5^{{\\dagger}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.2.2.2.m1.1\"><semantics id=\"S4.T2.2.2.2.m1.1a\"><msup id=\"S4.T2.2.2.2.m1.1.1\" xref=\"S4.T2.2.2.2.m1.1.1.cmml\"><mn id=\"S4.T2.2.2.2.m1.1.1.2\" xref=\"S4.T2.2.2.2.m1.1.1.2.cmml\">32.5</mn><mo id=\"S4.T2.2.2.2.m1.1.1.3\" xref=\"S4.T2.2.2.2.m1.1.1.3.cmml\">&#8224;</mo></msup><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.m1.1b\"><apply id=\"S4.T2.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T2.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1\">superscript</csymbol><cn id=\"S4.T2.2.2.2.m1.1.1.2.cmml\" type=\"float\" xref=\"S4.T2.2.2.2.m1.1.1.2\">32.5</cn><ci id=\"S4.T2.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T2.2.2.2.m1.1.1.3\">&#8224;</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.m1.1c\">32.5^{{\\dagger}}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.2.2.2.m1.1d\">32.5 start_POSTSUPERSCRIPT &#8224; end_POSTSUPERSCRIPT</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.2.2.9\">35.3</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.3.3.2\">MTL: P@2-TGT</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.3.3\">19.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.3.4\">21.7</td>\n<td class=\"ltx_td ltx_border_bb\" id=\"S4.T2.3.3.5\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.3.1\"><math alttext=\"\\textbf{20.7}^{{\\dagger}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.3.3.1.m1.1\"><semantics id=\"S4.T2.3.3.1.m1.1a\"><msup id=\"S4.T2.3.3.1.m1.1.1\" xref=\"S4.T2.3.3.1.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T2.3.3.1.m1.1.1.2\" xref=\"S4.T2.3.3.1.m1.1.1.2a.cmml\">20.7</mtext><mo id=\"S4.T2.3.3.1.m1.1.1.3\" xref=\"S4.T2.3.3.1.m1.1.1.3.cmml\">&#8224;</mo></msup><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.3.1.m1.1b\"><apply id=\"S4.T2.3.3.1.m1.1.1.cmml\" xref=\"S4.T2.3.3.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T2.3.3.1.m1.1.1.1.cmml\" xref=\"S4.T2.3.3.1.m1.1.1\">superscript</csymbol><ci id=\"S4.T2.3.3.1.m1.1.1.2a.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.2\"><mtext class=\"ltx_mathvariant_bold\" id=\"S4.T2.3.3.1.m1.1.1.2.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.2\">20.7</mtext></ci><ci id=\"S4.T2.3.3.1.m1.1.1.3.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.3\">&#8224;</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.3.1.m1.1c\">\\textbf{20.7}^{{\\dagger}}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.3.3.1.m1.1d\">20.7 start_POSTSUPERSCRIPT &#8224; end_POSTSUPERSCRIPT</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.3.3.6.1\">25.4</span></td>\n<td class=\"ltx_td ltx_border_bb\" id=\"S4.T2.3.3.7\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.3.8\">28.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.3.3.9\">31.6</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "This section discusses the results of the trained models and the context’s effect on Multi-Encoder and MTL settings. Table 2 shows the sentence-BLEU (s-BLEU) and document-BLEU (d-BLEU) [Liu et al., 2020, Bao et al., 2021] scores of the proposed multi-task learning model along with the Vanilla-Sent and Concat-Context models.\n",
            "We also report d-BLEU (document-level BLEU) scores [Liu et al., 2020, Bao et al., 2021] by converting each document into one single sequence (paragraph) by concatenating all sentences from that document and calculate BLEU scores on the resulting corpus. This results in slightly higher scores than the sentence level by matching n-grams over the whole document instead of at the sentence level. Table 2 also shows d-BLEU scores. Like s-BLEU scores, proposed MTL models achieve the best d-BLEU scores of 22.5 and 25.4 for News and TED corpora, respectively. We report the paired bootstrap resampling [Koehn, 2004] results, calculated with sacreBLEU [Post, 2018].\n"
        ]
    },
    "S5.T3.1": {
        "caption": "s-BLEU scores for the reconstruction objective of the MTL models on test set for News, TED, and Europarl corpora.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T3.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T3.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.1.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.1.1.2.1\">News</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.1.1.3.1\">TED</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.1.1.4.1\">Europarl</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T3.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T3.1.2.1.1\">MTL: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.2.1.2\">1.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.2.1.3\">1.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.2.1.4\">4.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T3.1.3.2.1\">MTL: P@2-TGT</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.1.3.2.2\">1.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.1.3.2.3\">1.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.1.3.2.4\">3.9</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T3.1.4.3.1\">MTL: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.1.4.3.2\">1.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.1.4.3.3\">1.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.1.4.3.4\">3.1</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We analyze the performance of the MTL model on the reconstruction objective on the test set to verify if the context encoder is generating noise. If the context encoder generates noise by the suboptimal encoding of context, the intermediate decoder will fail to reconstruct the source sentence from the context; otherwise, the intermediate decoder can reconstruct the source sentence to a similar extent as the final translated sentence. We perform greedy decoding on the intermediate decoder to generate the source from the context. Table 3 shows the BLEU scores of the reconstruction objective on the test set for News, TED, and Europarl corpora. The results show that the MTL models fail to reconstruct the source from the context. Based on this, we conclude that the context encoder cannot encode the context, leading to poor reconstruction performance of the models. However, we hypothesize that the model cannot reconstruct the source from the context because the corpora used to train context-aware models might not be context-aware. This observation aligns with the previous works [Kim et al., 2019, Li et al., 2020], and with enough data, vanilla sentence-level NMT models can outperform the document-level NMT models.\n"
        ]
    },
    "S5.T4.3.3": {
        "caption": "Comparison of s-BLEU scores of MTL and Inside-Context Multi-Encoder models. The best results are shown in bold. ‘ ’ denotes the statistically significant results than Vanilla-Sent and Concat-Context models with  .",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T4.3.3\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T4.3.3.4.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S5.T4.3.3.4.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.3.3.4.1.1.1\">Model</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T4.3.3.4.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.3.3.4.1.2.1\">News</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T4.3.3.4.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.3.3.4.1.3.1\">TED</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T4.3.3.4.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.3.3.4.1.4.1\">Europarl</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.3.3.5.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T4.3.3.5.2.1\">MTL: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.3.3.5.2.2\">19.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.3.3.5.2.3\">20.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.3.3.5.2.4\">29.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T4.2.2.2.3\">MTL: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.1.1.1.1\"><math alttext=\"\\textbf{20.1}^{\\dagger}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T4.1.1.1.1.m1.1\"><semantics id=\"S5.T4.1.1.1.1.m1.1a\"><msup id=\"S5.T4.1.1.1.1.m1.1.1\" xref=\"S5.T4.1.1.1.1.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_bold\" id=\"S5.T4.1.1.1.1.m1.1.1.2\" xref=\"S5.T4.1.1.1.1.m1.1.1.2a.cmml\">20.1</mtext><mo id=\"S5.T4.1.1.1.1.m1.1.1.3\" xref=\"S5.T4.1.1.1.1.m1.1.1.3.cmml\">&#8224;</mo></msup><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.1.1.1.1.m1.1b\"><apply id=\"S5.T4.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S5.T4.1.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"S5.T4.1.1.1.1.m1.1.1.2a.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1.2\"><mtext class=\"ltx_mathvariant_bold\" id=\"S5.T4.1.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1.2\">20.1</mtext></ci><ci id=\"S5.T4.1.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1.3\">&#8224;</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.1.1.1.1.m1.1c\">\\textbf{20.1}^{\\dagger}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S5.T4.1.1.1.1.m1.1d\">20.1 start_POSTSUPERSCRIPT &#8224; end_POSTSUPERSCRIPT</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.2.2.2.4\">20.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.2.2.2.2\">32.5<sup class=\"ltx_sup\" id=\"S5.T4.2.2.2.2.1\"><span class=\"ltx_text ltx_font_italic\" id=\"S5.T4.2.2.2.2.1.1\">&#8224;</span></sup>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.3.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T4.3.3.3.2\">MTL: P@2-TGT</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.3.3.3.3\">19.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.3.3.3.1\"><math alttext=\"\\textbf{20.7}^{\\dagger}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T4.3.3.3.1.m1.1\"><semantics id=\"S5.T4.3.3.3.1.m1.1a\"><msup id=\"S5.T4.3.3.3.1.m1.1.1\" xref=\"S5.T4.3.3.3.1.m1.1.1.cmml\"><mtext class=\"ltx_mathvariant_bold\" id=\"S5.T4.3.3.3.1.m1.1.1.2\" xref=\"S5.T4.3.3.3.1.m1.1.1.2a.cmml\">20.7</mtext><mo id=\"S5.T4.3.3.3.1.m1.1.1.3\" xref=\"S5.T4.3.3.3.1.m1.1.1.3.cmml\">&#8224;</mo></msup><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.3.3.3.1.m1.1b\"><apply id=\"S5.T4.3.3.3.1.m1.1.1.cmml\" xref=\"S5.T4.3.3.3.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S5.T4.3.3.3.1.m1.1.1.1.cmml\" xref=\"S5.T4.3.3.3.1.m1.1.1\">superscript</csymbol><ci id=\"S5.T4.3.3.3.1.m1.1.1.2a.cmml\" xref=\"S5.T4.3.3.3.1.m1.1.1.2\"><mtext class=\"ltx_mathvariant_bold\" id=\"S5.T4.3.3.3.1.m1.1.1.2.cmml\" xref=\"S5.T4.3.3.3.1.m1.1.1.2\">20.7</mtext></ci><ci id=\"S5.T4.3.3.3.1.m1.1.1.3.cmml\" xref=\"S5.T4.3.3.3.1.m1.1.1.3\">&#8224;</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.3.3.3.1.m1.1c\">\\textbf{20.7}^{\\dagger}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S5.T4.3.3.3.1.m1.1d\">20.7 start_POSTSUPERSCRIPT &#8224; end_POSTSUPERSCRIPT</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.3.3.3.4\">28.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.3.3.6.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T4.3.3.6.3.1\">Inside-Context: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.3.3.6.3.2\">18.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.3.3.6.3.3\">19.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.3.3.6.3.4\">33.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.3.3.7.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T4.3.3.7.4.1\">Inside-Context: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.3.3.7.4.2\">19.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.3.3.7.4.3\">19.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.3.3.7.4.4\">33.2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.3.3.8.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T4.3.3.8.5.1\">Inside-Context: P@2-TGT</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.3.3.8.5.2\">18.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.3.3.8.5.3\">20.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.3.3.8.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.3.3.8.5.4.1\">33.6</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We compare the proposed MTL approach to the existing Multi-Encoder approach to study how the model will perform in a single-task setting. Specifically, we compare our MTL approach (single-encoder multi-decoder network) with Inside-Context [Li et al., 2020] architecture. This model consists of two transformer encoders and one transformer decoder. Figure 2 shows the model’s architecture. The decoder is modified to attend to the outputs of both encoders. The model follows the transformer [Vaswani et al., 2017] architecture. An element-wise addition is performed on the outputs of both cross-attention layers before passing through layer-norm and position-wise feed-forward layers. Table 4 shows the s-BLEU scores of the MTL and Inside-Context models. We observe that the performance of multi-encoder models is similar to MTL models, with MTL models achieving +1.1 (P-N-SRC models), +0.3 (P@2-TGT models) BLEU points improvement over Inside-Context models for News and TED corpora respectively. In the case of Europarl, inside-context models achieve better performance than the MTL models, with the P@2-TGT model achieving +5.4 BLEU points improvement compared to the MTL model. Based on the results, we conclude that the MTL setting is more effective for low-resource scenarios.\n"
        ]
    },
    "S5.T5.1.1": {
        "caption": "Comparison of s-BLEU scores of MTL models tested with random context. The difference in scores over the models trained with the selected context is shown inside the parentheses.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T5.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T5.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T5.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.1.1.1.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.1.1.1.1.2.1\">News</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.1.1.1.1.3.1\">TED</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.1.1.1.1.4.1\">Europarl</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T5.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T5.1.1.2.1.1\">MTL: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.1.2.1.2\">1.2 (-17.9)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.1.2.1.3\">0.8 (-19.4)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.1.2.1.4\">4.5 (-25.0)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.1.3.2.1\">MTL: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.1.3.2.2\">1.2 (-18.9)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.1.3.2.3\">0.8 (-19.5)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.1.3.2.4\">4.0 (-28.5)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.1.4.3.1\">MTL: P@2-TGT</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.1.4.3.2\">0.5 (-18.7)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.1.4.3.3\">0.3 (-20.4)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.1.4.3.4\">3.9 (-24.3)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T5.1.1.5.4.1\">Inside-Context: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.1.5.4.2\">18.7 (-0.1)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.1.5.4.3\">19.4 (-0.2)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.1.5.4.4\">33.2 (0.0)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.1.6.5.1\">Inside-Context: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.1.6.5.2\">18.9 (-0.1)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.1.6.5.3\">19.8 (0.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.1.6.5.4\">33.2 (0.0)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T5.1.1.7.6.1\">Inside-Context: P@2-TGT</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.1.7.6.2\">18.3 (0.0)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.1.7.6.3\">20.3 (-0.1)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.1.7.6.4\">33.1 (-0.5)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Since the BLEU scores of our MTL models are almost the same for all three context settings, we check whether the MTL models are affected by the choice of context. To this end, we test the MTL models with random context. Here, random context denotes two randomly selected sentences from the entire corpus. Table 5 shows the results of MTL and Inside-Context models tested with random context. Results show that the MTL models fail to translate source sentences when the context is random. However, Inside-Context models are agnostic to context as models can translate well even if the context is random. Our findings in the case of multi-encoder models are in line with the findings of Li et al. [Li et al., 2020]. Based on the results, we conclude that MTL models are sensitive to the choice of context. Section A.1.1 describes a similar experiment where the MTL models are tested with random context. However, the architecture used in the main experiments differs slightly from the one used in the preliminary investigation. We observe that feeding the Intermediate Decoder output to the Final Decoder makes the model sensitive to the choice of context (cf. Figure 1 and Figure 3 in the Appendix A.1). We hypothesize that a weighted combination of the Context Encoder output and Intermediate Decoder output is desired as it performs slightly better than the model used in the main experimental setup. However, it also makes the model agnostic to the choice of context. We plan to explore this behaviour in detail in our future work.\n"
        ]
    },
    "S5.T6.3.1": {
        "caption": "s-BLEU scores of the MTL and Inside-Context models are tested by giving the same source sentences as context and input. The change of s-BLEU scores over the models tested with random context is shown in ( ).",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T6.3.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T6.3.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T6.3.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T6.3.1.1.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T6.3.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T6.3.1.1.1.2.1\">News</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T6.3.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T6.3.1.1.1.3.1\">TED</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T6.3.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T6.3.1.1.1.4.1\">Europarl</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T6.3.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T6.3.1.2.1.1\">MTL: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.3.1.2.1.2\">13.7 (+12.5)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.3.1.2.1.3\">11.2 (+10.4)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.3.1.2.1.4\">22.3 (+17.8)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.3.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.3.1.3.2.1\">MTL: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.3.1.3.2.2\">14.5 (+13.3)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.3.1.3.2.3\">11.3 (+10.5)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.3.1.3.2.4\">19.7 (+15.7)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.3.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T6.3.1.4.3.1\">Inside-Context: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.3.1.4.3.2\">18.7 (0.0)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.3.1.4.3.3\">19.6 (+0.2)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.3.1.4.3.4\">33.1 (-0.1)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.3.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T6.3.1.5.4.1\">Inside-Context: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T6.3.1.5.4.2\">19.0 (+0.1)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T6.3.1.5.4.3\">19.7 (-0.1)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T6.3.1.5.4.4\">33.0 (-0.2)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We conduct experiments on MTL and Inside-Context models by using the same source sentence as the context. Since the proposed MTL models fail when tested with random context (cf. Section 5.4), we observe how the MTL and Multi-Encoder models are performing when the same source sentence is given as context. This setting presents a scenario where the context is not random but also not the type of context with which the models are trained. We conduct experiments for P@2-SRC and P-N-SRC context settings only as the P@2-TGT context setting requires the current target sentence, which is unavailable during testing. We observe that MTL models can perform well compared to the random context setting, which shows that the MTL models are sensitive to the choice of context. The performance of Inside-Context models is almost the same as those tested with random context. This shows that the Inside-Context model is agnostic to the choice of the context. Table 6 shows the s-BLEU scores of the MTL and Inside-Context models.\n"
        ]
    },
    "S5.T7.1.1": {
        "caption": "Accuracy of Pronoun Translation (APT) scores. The best results are shown in bold.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S5.T7.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S5.T7.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.1.1.1.1\">Model</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T7.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.1.1.2.1\">News</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T7.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.1.1.3.1\">TED</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T7.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.1.1.4.1\">Europarl</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T7.1.1.2.2.1\">Vanilla-Sent</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.2.2.2\">40.17</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.2.2.3\">31.22</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.2.2.4\">37.22</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T7.1.1.3.3.1\">Concat-Context: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.3.3.2\">39.34</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.3.3.3\">30.01</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.3.3.4\">36.42</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.1.4.4.1\">Concat-Context: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.4.4.2\">39.99</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.4.4.3\">29.57</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.4.4.4\">36.78</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.1.5.5.1\">Concat-Context: P@2-TGT</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.5.5.2\">38.50</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.5.5.3\">28.82</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.5.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.5.5.4.1\">37.27</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T7.1.1.6.6.1\">MTL: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.6.6.2\">40.69</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.6.6.3\">31.44</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.6.6.4\">35.96</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.1.7.7.1\">MTL: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.7.7.2\">40.50</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.7.7.3\">31.24</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.7.7.4\">36.94</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T7.1.1.8.8.1\">MTL: P@2-TGT</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T7.1.1.8.8.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.8.8.2.1\">40.99</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T7.1.1.8.8.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.8.8.3.1\">31.90</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T7.1.1.8.8.4\">33.91</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We also evaluate our proposed models’ performance on pronoun translation accuracy. We calculate the pronoun translation accuracy with APT (accuracy of pronoun translation) [Miculicich Werlen and Popescu-Belis, 2017] metric666https://github.com/idiap/APT. This metric requires a list of pronouns from the source language (German) with a list of pronouns from the target language (English) as an optional argument. We use spaCy777https://spacy.io/models to tag both source and target sentences from the test set and extract pronouns. Table 7 shows the APT scores of Vanilla-Sent, Concat-Context, and MTL DocNMT models. The APT scores correlate with the s-BLEU and d-BLEU scores, achieving the highest APT score of 40.99 in MTL: P@2-TGT setting with an improvement of +0.82 over Vanilla-Sent and +1.0 over Concat-Context (P-N-SRC) models on News corpus. Similarly, the MTL: P@2-TGT model achieves the highest APT score of 31.90 with an improvement of +0.68 and +1.89 over Vanilla-Sent and Concat-Context (P@2-SRC) on TED. For the Europarl corpus, Concat-Context (P@2-TGT) achieved the highest APT score of 37.27 with an improvement of +0.05 and +0.33 over Vanilla-Sent and MTL (P-N-SRC) models respectively.\n"
        ]
    },
    "A1.EGx1": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "A1.T8.1.1": {
        "caption": "Comparison of s-BLEU scores of Baseline and proposed MTL DocNMT models trained with different source contexts for German to English direction. Differences in the scores over   are shown inside the parentheses.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A1.T8.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A1.T8.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.1.1.1.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T8.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.1.1.1.1.2.1\">Vanilla-Sent</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T8.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.1.1.1.1.3.1\">MTL: P@2-SRC</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T8.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.1.1.1.1.4.1\">MTL: P-N-SRC</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.2.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"A1.T8.1.1.2.1.1.1\">News</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.2.1.2\">Re-Src</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.2.1.3\" rowspan=\"2\"><span class=\"ltx_text\" id=\"A1.T8.1.1.2.1.3.1\">16.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.2.1.4\">20.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.2.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.1.1.2.1.5.1\">20.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.3.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.1.1.3.2.1\">Re-Cntx</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.1.1.3.2.2\">16.7 (-3.9)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.1.1.3.2.3\">17.9 (-3.0)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.4.3.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"A1.T8.1.1.4.3.1.1\">TED</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.4.3.2\">Re-Src</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.4.3.3\" rowspan=\"2\"><span class=\"ltx_text\" id=\"A1.T8.1.1.4.3.3.1\">12.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.4.3.4\">21.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.1.1.4.3.5.1\">22.0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.5.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.1.1.5.4.1\">Re-Cntx</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.1.1.5.4.2\">18.0 (-3.6)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T8.1.1.5.4.3\">17.8 (-4.2)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.6.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"A1.T8.1.1.6.5.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"A1.T8.1.1.6.5.1.1\">Europarl</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.6.5.2\">Re-Src</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"A1.T8.1.1.6.5.3\" rowspan=\"2\"><span class=\"ltx_text\" id=\"A1.T8.1.1.6.5.3.1\">35.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.6.5.4\">35.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T8.1.1.6.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.1.1.6.5.5.1\">35.8</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.7.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"A1.T8.1.1.7.6.1\">Re-Cntx</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"A1.T8.1.1.7.6.2\">33.2 (-1.9)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"A1.T8.1.1.7.6.3\">33.6 (-2.2)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": []
    },
    "A1.T9.1.1": {
        "caption": "s-BLEU scores of   and   experiments on News-commentary corpus.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A1.T9.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T9.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A1.T9.1.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.1.1.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A1.T9.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.1.1.1.2.1\">Random-Train</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.1.1.1.1.3\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"A1.T9.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.1.1.1.4.1\">Random-Infer</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.1.1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A1.T9.1.1.2.2.1\">Re-Src</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A1.T9.1.1.2.2.2\">Re-Cntx</th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"A1.T9.1.1.2.2.3\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A1.T9.1.1.2.2.4\">Re-Src</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A1.T9.1.1.2.2.5\">Re-Cntx</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T9.1.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A1.T9.1.1.3.1.1\">MTL: P@2-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T9.1.1.3.1.2\">20.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T9.1.1.3.1.3\">16.6</td>\n<td class=\"ltx_td ltx_border_t\" id=\"A1.T9.1.1.3.1.4\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T9.1.1.3.1.5\">20.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T9.1.1.3.1.6\">16.8</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.1.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A1.T9.1.1.4.2.1\">MTL: P-N-SRC</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T9.1.1.4.2.2\">20.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T9.1.1.4.2.3\">16.4</td>\n<td class=\"ltx_td ltx_border_bb\" id=\"A1.T9.1.1.4.2.4\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T9.1.1.4.2.5\">20.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T9.1.1.4.2.6\">17.8</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We also conduct experiments to study how the random context affects the MTL models. Specifically, we evaluate the MTL models in two settings. The model is trained on the random context in the Random-Train setting by concatenating two randomly sampled sentences from the train set and testing with P@2-SRC and P-N-SRC context settings. In Random-Infer setting, the model is trained on P@2-SRC and P-N-SRC context settings and tested with random context. We train the models on the news-commentary corpus. Table 9 shows the s-BLEU scores of the MTL models trained and tested in the random context setting. Based on the results, we conclude that the model trained with random context improves the robustness of the model. This observation aligns with the findings of Li et al. [Li et al., 2020], but they conducted experiments in the non-MTL setting with multiple encoders. As the model largely ignores the choice of the context, we remove this linear + ReLU combination and feed the output of the Intermediate Decoder to the Final Decoder. We hypothesize that this forces the model to consider the context while generating the target sentence.\n"
        ]
    }
}