{
    "S4.T1.1": {
        "caption": "Marking behaviors of each annotator in terms of percent of tokens marked in the trial annotation.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.1\">Annotator</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.2\">1</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.3\">2</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.4\">3</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.1\">\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.2.1.1\">Percent Marked on Average</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.2.1.2\">0.25</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.2.1.3\">0.17</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.2.1.4\">0.17</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.2\">\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.1.3.2.1\">SD of Percent Marked</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.1.3.2.2\">0.28</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.1.3.2.3\">0.18</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.1.3.2.4\">0.19</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We calculated pair-wise Krippendorff’s alpha in addition to the average agreement for both the sentence-level percentage marked and token-level annotations. The average amount of tokens marked for the unskipped sentences is visible in Table 1. Pairwise Krippendorff’s alphas for percentage marked is visible in Table 2, while pairwise agreement for token classification is in Table 3. Average agreement for the percentage marked is α=0.306𝛼0.306\\alpha=0.306italic_α = 0.306 and for token classification α=0.466𝛼0.466\\alpha=0.466italic_α = 0.466. This suggests that, while agreement about overall sentence quality is not high, the reliability of classifying each token in the hypothesis is higher. These results were used to calibrate with the annotators after looking over the annotations made by each individual.\n"
        ]
    },
    "S4.T2.1": {
        "caption": "Inter-annotator agreement for percentage marked per sentence, given by Krippendorff’s Alpha.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.2.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T2.1.2.1.1\">Annotator</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.2.1.2\">2</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.2.1.3\">3</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.3.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.3.1.1\">1</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.1.3.1.2\">0.258</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.1.3.1.3\">0.481</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.1.1.2\">2</th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T2.1.1.1\"><math alttext=\"\\emptyset\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.1.1.1.m1.1\"><semantics id=\"S4.T2.1.1.1.m1.1a\"><mi id=\"S4.T2.1.1.1.m1.1.1\" mathvariant=\"normal\" xref=\"S4.T2.1.1.1.m1.1.1.cmml\">&#8709;</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.m1.1b\"><emptyset id=\"S4.T2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.m1.1c\">\\emptyset</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T2.1.1.1.m1.1d\">&#8709;</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T2.1.1.3\">0.222</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We calculated pair-wise Krippendorff’s alpha in addition to the average agreement for both the sentence-level percentage marked and token-level annotations. The average amount of tokens marked for the unskipped sentences is visible in Table 1. Pairwise Krippendorff’s alphas for percentage marked is visible in Table 2, while pairwise agreement for token classification is in Table 3. Average agreement for the percentage marked is α=0.306𝛼0.306\\alpha=0.306italic_α = 0.306 and for token classification α=0.466𝛼0.466\\alpha=0.466italic_α = 0.466. This suggests that, while agreement about overall sentence quality is not high, the reliability of classifying each token in the hypothesis is higher. These results were used to calibrate with the annotators after looking over the annotations made by each individual.\n"
        ]
    },
    "S4.T3.1": {
        "caption": "Inter-annotator agreement for token classification, given by Krippendorff’s Alpha.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.2.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T3.1.2.1.1\">Annotator</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.2.1.2\">2</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.2.1.3\">3</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.3.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.1.3.1.1\">1</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T3.1.3.1.2\">0.445</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T3.1.3.1.3\">0.531</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T3.1.1.2\">2</th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T3.1.1.1\"><math alttext=\"\\emptyset\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T3.1.1.1.m1.1\"><semantics id=\"S4.T3.1.1.1.m1.1a\"><mi id=\"S4.T3.1.1.1.m1.1.1\" mathvariant=\"normal\" xref=\"S4.T3.1.1.1.m1.1.1.cmml\">&#8709;</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.m1.1b\"><emptyset id=\"S4.T3.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.m1.1c\">\\emptyset</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T3.1.1.1.m1.1d\">&#8709;</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T3.1.1.3\">0.433</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We calculated pair-wise Krippendorff’s alpha in addition to the average agreement for both the sentence-level percentage marked and token-level annotations. The average amount of tokens marked for the unskipped sentences is visible in Table 1. Pairwise Krippendorff’s alphas for percentage marked is visible in Table 2, while pairwise agreement for token classification is in Table 3. Average agreement for the percentage marked is α=0.306𝛼0.306\\alpha=0.306italic_α = 0.306 and for token classification α=0.466𝛼0.466\\alpha=0.466italic_α = 0.466. This suggests that, while agreement about overall sentence quality is not high, the reliability of classifying each token in the hypothesis is higher. These results were used to calibrate with the annotators after looking over the annotations made by each individual.\n"
        ]
    },
    "S4.T4.1": {
        "caption": "Marking behaviors of each annotator in terms of percent of tokens marked in the final annotation.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.1\">Annotator</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.2\">1</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.3\">2</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.4\">3</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.2.1\">\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T4.1.2.1.1\">Percent Marked on Average</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T4.1.2.1.2\">0.10</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T4.1.2.1.3\">0.19</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T4.1.2.1.4\">0.09</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.3.2\">\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"S4.T4.1.3.2.1\">SD of Percent Marked</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"S4.T4.1.3.2.2\">0.10</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"S4.T4.1.3.2.3\">0.15</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" id=\"S4.T4.1.3.2.4\">0.1</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "After calibration, we then assigned each annotator their block of 500 examples to annotate. Annotator 1 skipped 6 of the 500 sentences and annotator 2 skipped 20. Percentage marked was lower for annotators 1 and 3 during the full annotation as more sentences were left completely unmarked. Annotator 1 left 36% of sentences unmarked; annotator 2 left 23%; and annotator 3 left 38%. The percentage that was marked per sentence was also reduced after calibration, as shown in Table 4.\n"
        ]
    },
    "S5.T5.1": {
        "caption": "Results for both Llama 13B and GPT 3.5 across all metrics and translation scenarios (ME = Marking Edits, UE = Unmarking Edits, % Correct ME = Percentage of correct ME in manual evaluation).",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T5.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T5.1.1.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"S5.T5.1.1.1.1\">Condition</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.1.1.1.2\">BLEU</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.1.1.1.3\">TER</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.1.1.1.4\">ME</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.1.1.1.5\">UE</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.1.1.1.6\">% Correct ME</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.2.2\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S5.T5.1.2.2.1\">Original Hyps</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T5.1.2.2.2\">28.92</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T5.1.2.2.3\">55.12</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T5.1.2.2.4\">N.A.</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T5.1.2.2.5\">N.A.</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T5.1.2.2.6\">N.A.</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T5.1.3.1\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S5.T5.1.3.1.1\">MT (Llama/GPT)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.3.1.2\">29.83/38.61</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.3.1.3\">55.97/49.21</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.3.1.4\">N.A.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.3.1.5\">N.A.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.3.1.6\">N.A.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.4.2\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\" id=\"S5.T5.1.4.2.1\">APE (Llama/GPT)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.4.2.2\">29.79/39.09</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.4.2.3\">54.56/48.37</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.4.2.4\">7.30/76.70</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.4.2.5\">1.76/15.85</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.4.2.6\">32% / N.A.</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.5.3\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S5.T5.1.5.3.1\">MRK (Llama/GPT)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.5.3.2\">30.09/39.31</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.5.3.3\">54.70/48.32</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.5.3.4\">14.76/78.36</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.5.3.5\">3.60/13.90</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.5.3.6\">67% / N.A.</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We show results across metrics for Llama 13B and GPT-3.5 in Table 5. Including error markings as input increases the frequency with which the models edits the marked tokens. For Llama 13B, we see editing rates for marked tokens double from 7.307.307.307.30 to 14.7614.7614.7614.76. This suggests that, even after being asked to correct the hypotheses, Llama 13B finds its own outputs as acceptable translations. When errors are specifically pointed out to the model, it is much more capable of self-correcting errors.\n"
        ]
    }
}