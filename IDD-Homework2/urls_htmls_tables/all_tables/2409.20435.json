{
    "id_table_1": {
        "caption": "TABLE I :  Number of images in the ALLO dataset.",
        "table": "S3.T1.2",
        "footnotes": [],
        "references": [
            "In the Blender model, 50 unique camera poses were manually defined around the station to simulate key positions of the arm-mounted cameras. During the rendering process, random Gaussian noise was added to each pose, with a standard deviation of 1 meter for location and 0.2 radians in roll, pitch, and yaw. This process ensured that all relevant regions of the station body were captured and varied between views. The station model and some of the reference camera positions are shown in  Fig.   1 . Furthermore, to enhance the datasets generalizability, several scene parameters were modified during the rendering process. Each scene was rendered multiple times with varying sun strength intensities, which were carefully adjusted to achieve the desired effect. Each anomalous scene was also rendered with the anomaly at three different depths: the initial randomly assigned depth, as well as 1 metre closer to and 1 metre farther from the camera, resulting in a total of nine images for each anomalous scene. Furthermore, the anomalys size in each scene was randomly varied to one of three scales: its original size, 20% smaller, or 20% larger, to introduce additional diversity.",
            "The normal and anomalous images were generated from different camera positions to ensure variation between the training and testing sets. Models of thermal blankets, cables, and maintenance tools, such as those shown in  Fig.   3 , were used as anomalies. Each anomalous image contained only one anomaly, as performance on a single anomaly reflects how algorithms would perform on images with multiple anomalies. For all images, a corresponding three-class segmentation mask was generated that labelled the anomaly (none if normal image), all non-anomalous foreground objects (e.g., the station, celestial bodies), and the background (e.g. space). The rendering process for the ALLO dataset is outlined in  Algorithm   1 , with an example shown in  Fig.   2 ."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II :  The effect of tuned augmentations and normalization on FastFlows performance on the ALLO test set.",
        "table": "S4.T2.9",
        "footnotes": [],
        "references": [
            "The normal and anomalous images were generated from different camera positions to ensure variation between the training and testing sets. Models of thermal blankets, cables, and maintenance tools, such as those shown in  Fig.   3 , were used as anomalies. Each anomalous image contained only one anomaly, as performance on a single anomaly reflects how algorithms would perform on images with multiple anomalies. For all images, a corresponding three-class segmentation mask was generated that labelled the anomaly (none if normal image), all non-anomalous foreground objects (e.g., the station, celestial bodies), and the background (e.g. space). The rendering process for the ALLO dataset is outlined in  Algorithm   1 , with an example shown in  Fig.   2 ."
        ]
    },
    "id_table_3": {
        "caption": "TABLE III :  Performance of state-of-the-art anomaly detection algorithms on the ALLO and MVTEC test sets. For each metric, the algorithm that performed best and second-best on that dataset are bolded and underlined, respectively.",
        "table": "S4.T3.27",
        "footnotes": [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
        ],
        "references": [
            "The normal and anomalous images were generated from different camera positions to ensure variation between the training and testing sets. Models of thermal blankets, cables, and maintenance tools, such as those shown in  Fig.   3 , were used as anomalies. Each anomalous image contained only one anomaly, as performance on a single anomaly reflects how algorithms would perform on images with multiple anomalies. For all images, a corresponding three-class segmentation mask was generated that labelled the anomaly (none if normal image), all non-anomalous foreground objects (e.g., the station, celestial bodies), and the background (e.g. space). The rendering process for the ALLO dataset is outlined in  Algorithm   1 , with an example shown in  Fig.   2 ."
        ]
    },
    "id_table_4": {
        "caption": "TABLE IV :  Performance of best four anomaly detection algorithms from the benchmark on the secondary colour test set. For each metric, the algorithm that performed best and second-best are bolded and underlined, respectively.",
        "table": "S4.T4.15",
        "footnotes": [
            "",
            "",
            "",
            ""
        ],
        "references": [
            "All images in the ALLO dataset were rendered to a resolution of  1 , 920  1 , 080 1 920 1 080 1,920\\times 1,080 1 , 920  1 , 080  pixels. The rendering process was repeated with two seeds and the breakdown of images in the training and testing sets are shown in  Table   I . Sample images from the ALLO dataset are shown in  Fig.   4  and demonstrate how these images can be quite crowded, may contain both illuminated and shadowed structures, and have large black portions of space."
        ]
    }
}