{
    "S5.T1.1.1": {
        "caption": "English–German khresmoi set results for the MBR self-improvement approaches. All models fine-tuned with MBR self-improvement technique have shown better performance over   and   models, including the   model, which was finetuned on general-domain MBR-decoded data. The results marked with an asterisk (*) are statistically significant compared to the   model.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T1.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T1.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T1.1.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T1.1.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T1.1.1.1.3\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T1.1.1.1.4\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T1.1.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.1.1.2.2\">66.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.1.1.2.3\">0.8653</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.1.1.2.4\">0.7693</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T1.1.1.3.1\">Mix-tune</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.3.2\">66.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.3.3\">0.8682</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.3.4\">0.7749</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T1.1.1.4.1\">Base-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.4.2.1\">66.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.4.3\">0.8711*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.4.4\">0.7755</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T1.1.1.5.1\">Mix-tune-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.5.2.1\">66.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.5.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.5.3.1\">0.8728</span>*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.5.4\">0.7792*</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T1.1.1.6.1\">Mix-tune-domain-mbr-iter2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.6.2.1\">66.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.6.3\">0.8727*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.1.6.4\">0.7791*</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S5.T1.1.1.7.1\">Mix-tune-general-mbr</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T1.1.1.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.7.2.1\">66.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T1.1.1.7.3\">0.8720*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T1.1.1.7.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.7.4.1\">0.7799</span>*</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Table 1 shows the evaluation results on the in-domain test set khresmoi. All models self-improved with MBR decoding have shown enhanced performance. However, model Mix-tune-domain-mbr-iter2 did not exhibit improvement over its first iteration Mix-tune-domain-mbr, even on COMET, which was the utility metric of MBR decoding. Mix-tune-general-mbr model shows a slightly better performance on BLEURT metric compared to models fine-tuned on in-domain MBR-decoded forward translations.\n"
        ]
    },
    "S5.T2.1.1": {
        "caption": "English–German FLORES-200 test set results for the MBR self-improvement approaches.   model has shown superior performance, however, models with domain-specific forward translation maintain performance. The results marked with an asterisk (*) are statistically significant compared to the   model.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T2.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T2.1.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T2.1.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T2.1.1.1.3\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T2.1.1.1.4\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T2.1.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.1.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.2.2.1\">67.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.1.2.3\">0.8751</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T2.1.1.2.4\">0.7735</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.1.1.3.1\">Mix-tune</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.3.2.1\">67.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.3.3\">0.8756</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.3.4\">0.7744</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.1.1.4.1\">Base-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.4.2\">67.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.4.3\">0.8772</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.4.4\">0.7743</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.1.1.5.1\">Mix-tune-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.5.2\">67.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.5.3\">0.8787*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.5.4\">0.7766</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T2.1.1.6.1\">Mix-tune-domain-mbr-iter2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.6.2\">67.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.6.3\">0.8766</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T2.1.1.6.4\">0.7748</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T2.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S5.T2.1.1.7.1\">Mix-tune-general-mbr</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.1.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.7.2.1\">67.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.1.7.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.7.3.1\">0.8813</span>*</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T2.1.1.7.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T2.1.1.7.4.1\">0.7784</span>*</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Table 2 presents the evaluation results on the FLORES-200 test set. Although chrF did not increase, the neural evaluation metrics showed improvement. Similar to the khresmoi test set, the Mix-tune-domain-mbr-iter2 model showed a decrease in quality during the second iteration of self-improvement. Mix-tune-general-mbr showed superior performance over other models.\n"
        ]
    },
    "S5.T3.1": {
        "caption": "Czech–Ukrainian FLORES-200 test set results for the three MBR self-improvement approaches. All self-improved models exhibit improvements on all metrics compared to the baseline model, regardless of the fine-tuning approach used. Notably, both   and   models achieve the highest gains, demonstrating comparable performance. All self-improved models show statistical significance compared to the   model.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T3.1\">\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T3.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T3.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T3.1.1.3\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T3.1.1.4\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.2.2\">52.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.2.3\">0.8779</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.2.4\">0.7466</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T3.1.3.1\">MBR-finetuned</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.1.3.2\">52.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.1.3.3\">0.8839</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.1.3.4\">0.7522</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T3.1.4.1\">MBR-ft-high-lr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.1.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.4.2.1\">52.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.1.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.4.3.1\">0.8869</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T3.1.4.4\">0.7553</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S5.T3.1.5.1\">MBR-resumed</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.1.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.5.2.1\">52.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.1.5.3\">0.8864</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.1.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.5.4.1\">0.7557</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "The results of the three MBR self-improvement approaches described in Section 4.6 are presented in Tables 3 and 4 for the FLORES-200 and WMT22 test sets, respectively.\n"
        ]
    },
    "S5.T4.1": {
        "caption": "Czech–Ukrainian WMT22 test set results for the three MBR self-improvement approaches. Similar to the FLORES-200 results, all self-improved models exhibit improvements on all metrics compared to the baseline model. However, on the WMT22 test set, the neural metrics favour the   model over the   model. All self-improved models show statistical significance compared to the   model.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T4.1\">\n<tr class=\"ltx_tr\" id=\"S5.T4.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T4.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T4.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T4.1.1.3\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T4.1.1.4\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.1.2.2\">58.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.1.2.3\">0.8721</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.1.2.4\">0.7498</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.3.1\">MBR-finetuned</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.1.3.2\">60.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.1.3.3\">0.8803</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.1.3.4\">0.7574</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T4.1.4.1\">MBR-ft-high-lr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.1.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.1.4.2.1\">60.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.1.4.3\">0.8844</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.1.4.4\">0.7619</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S5.T4.1.5.1\">MBR-resumed</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.1.5.2\">60.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.1.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.1.5.3.1\">0.8852</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.1.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.1.5.4.1\">0.7639</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "The results of the three MBR self-improvement approaches described in Section 4.6 are presented in Tables 3 and 4 for the FLORES-200 and WMT22 test sets, respectively.\n"
        ]
    },
    "S5.T5.1": {
        "caption": "Czech–Ukrainian iterative self-improvement results on the FLORES-200 test set. While the COMET score consistently improves across all three iterations, the chrF and BLEURT scores show a decrease in the third iteration. This suggests that the model overfits to COMET, harming the quality of the translation. Results with an asterisk (*) are statistically significant in comparison with the model in the row directly above it.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T5.1\">\n<tr class=\"ltx_tr\" id=\"S5.T5.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T5.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T5.1.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T5.1.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T5.1.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T5.1.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">52.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.8779</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7466</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T5.1.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MBR-resumed</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">52.7*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.8864*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7557*</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T5.1.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MBR-resumed-iter2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.1.4.2.1\">52.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.8888*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.1.4.4.1\">0.7567</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S5.T5.1.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MBR-resumed-iter3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.5.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">52.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.5.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.1.5.3.1\">0.8901</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.5.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7557</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Tables 5 and 6 showcase the impact of iterative training with MBR decoding on the FLORES-200 and WMT22 test sets, respectively. The second iteration consistently improves scores across all metrics, demonstrating the effectiveness of the iterative self-improvement process in refining the model’s translation capabilities. However, the third iteration leads to a decrease in both chrF and BLEURT scores. This suggests potential overfitting to the MBR decoding utility metric, where the model prioritizes aspects that score well according to COMET but may not translate to overall translation quality.\n"
        ]
    },
    "S5.T6.1": {
        "caption": "Czech–Ukrainian iterative self-improvement results on the WMT22 test set. Consistent with the FLORES-200 results, the COMET score improves across all iterations, while other metrics show a decrease in the last iteration. Notably, the BLEURT score not only decreases but falls below the score achieved by the first self-improved model. Results with an asterisk (*) are statistically significant in comparison with the model in the row directly above it.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T6.1\">\n<tr class=\"ltx_tr\" id=\"S5.T6.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T6.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T6.1.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T6.1.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T6.1.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T6.1.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.1.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">58.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.1.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.8721</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.1.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7498</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T6.1.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MBR-resumed</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">60.0*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.8852*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7639*</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T6.1.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MBR-resumed-iter2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.T6.1.4.2.1\">60.3</span>*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.8885*</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T6.1.4.4.1\">0.7641</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S5.T6.1.5.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MBR-resumed-iter3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T6.1.5.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">60.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T6.1.5.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T6.1.5.3.1\">0.8896</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T6.1.5.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7578</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Tables 5 and 6 showcase the impact of iterative training with MBR decoding on the FLORES-200 and WMT22 test sets, respectively. The second iteration consistently improves scores across all metrics, demonstrating the effectiveness of the iterative self-improvement process in refining the model’s translation capabilities. However, the third iteration leads to a decrease in both chrF and BLEURT scores. This suggests potential overfitting to the MBR decoding utility metric, where the model prioritizes aspects that score well according to COMET but may not translate to overall translation quality.\n"
        ]
    },
    "S5.T7.1.1": {
        "caption": "English–Hausa FLORES-200 test set results for MBR self-improvement with different metrics. Both self-improved models achieve gains compared to the baseline model on all evaluation metrics. While the AfriCOMET-based model achieves a higher AfriCOMET score, reflecting its alignment with the specific evaluation metric, the COMET-based model surpasses it in both BLEURT and COMET scores, while showing a comparable gain on the AfriCOMET score. All self-improved models show statistical significance compared to the   model.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T7.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T7.1.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T7.1.1.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T7.1.1.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T7.1.1.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">BLEURT</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\" id=\"S5.T7.1.1.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">AfriCOMET</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T7.1.1.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">49.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7569</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7931</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T7.1.1.2.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.6984</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T7.1.1.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MBR-COMET</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">50.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.3.3.1\">0.7720</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.1.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.3.4.1\">0.8083</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T7.1.1.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7207</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S5.T7.1.1.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MBR-AfriCOMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T7.1.1.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.4.2.1\">51.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T7.1.1.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7692</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T7.1.1.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.8061</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S5.T7.1.1.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.1.4.5.1\">0.7239</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "This section compares the performance of two MBR decoding self-improvement approaches for English–Hausa translation: one utilizing the WMT22 COMET model and another using the AfriCOMET model. The results are presented in Tables 7 and 8 for the FLORES-200 and NTREX test sets, respectively.\n"
        ]
    },
    "S5.T8.1.1": {
        "caption": "English–Hausa NTREX test set results for MBR self-improvement with different metrics. Similar to the FLORES-200 results, both self-improved models using MBR decoding demonstrate improvements over the baseline model on all evaluation metrics. All self-improved models show statistical significance compared to the   model.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T8.1.1\">\n<tr class=\"ltx_tr\" id=\"S5.T8.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T8.1.1.1.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T8.1.1.1.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T8.1.1.1.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T8.1.1.1.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">BLEURT</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\" id=\"S5.T8.1.1.1.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">AfriCOMET</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T8.1.1.2.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T8.1.1.2.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">51.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T8.1.1.2.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7596</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T8.1.1.2.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7791</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S5.T8.1.1.2.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.6800</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T8.1.1.3.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MBR-COMET</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T8.1.1.3.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T8.1.1.3.2.1\">53.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T8.1.1.3.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T8.1.1.3.3.1\">0.7752</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T8.1.1.3.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T8.1.1.3.4.1\">0.7986</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S5.T8.1.1.3.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7046</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.1.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S5.T8.1.1.4.1\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">MBR-AfriCOMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T8.1.1.4.2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">53.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T8.1.1.4.3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7721</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T8.1.1.4.4\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.7956</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S5.T8.1.1.4.5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T8.1.1.4.5.1\">0.7062</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "This section compares the performance of two MBR decoding self-improvement approaches for English–Hausa translation: one utilizing the WMT22 COMET model and another using the AfriCOMET model. The results are presented in Tables 7 and 8 for the FLORES-200 and NTREX test sets, respectively.\n"
        ]
    },
    "A0.T9.1.1": {
        "caption": "English–German khresmoi set results for the MBR self-improvement approaches. All models fine-tuned with MBR self-improvement technique have shown better performance over   and   models, even   model with general forward translations.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"A0.T9.1.1\">\n<tr class=\"ltx_tr\" id=\"A0.T9.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A0.T9.1.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T9.1.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T9.1.1.1.3\">BLEU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T9.1.1.1.4\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T9.1.1.1.5\">CometKiwi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T9.1.1.1.6\">UniTE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T9.1.1.1.7\">UniTE-DA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T9.1.1.1.8\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T9.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A0.T9.1.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T9.1.1.2.2\">66.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T9.1.1.2.3\">35.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T9.1.1.2.4\">0.8653</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T9.1.1.2.5\">0.8373</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T9.1.1.2.6\">0.6441</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T9.1.1.2.7\">0.8574</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T9.1.1.2.8\">0.7693</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T9.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T9.1.1.3.1\">Mix-tune</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.3.2\">66.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.3.3.1\">35.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.3.4\">0.8682</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.3.5\">0.8397</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.3.6\">0.6594</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.3.7\">0.8602</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.3.8\">0.7749</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T9.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T9.1.1.4.1\">Base-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.4.2.1\">66.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.4.3\">35.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.4.4\">0.8711</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.4.5\">0.8416</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.4.6\">0.6694</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.4.7\">0.8621</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.4.8\">0.7755</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T9.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T9.1.1.5.1\">Mix-tune-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.5.2.1\">66.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.5.3\">35.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.5.4.1\">0.8728</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.5.5.1\">0.8423</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.5.6\">0.6766</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.5.7\">0.8631</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.5.8\">0.7792</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T9.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T9.1.1.6.1\">Mix-tune-domain-mbr-iter2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.6.2.1\">66.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.6.3\">35.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.6.4\">0.8727</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.6.5.1\">0.8423</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.6.6\">0.6757</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.6.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.6.7.1\">0.8633</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T9.1.1.6.8\">0.7791</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T9.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A0.T9.1.1.7.1\">Mix-tune-general-mbr</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T9.1.1.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.7.2.1\">66.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T9.1.1.7.3\">35.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T9.1.1.7.4\">0.8720</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T9.1.1.7.5\">0.8422</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T9.1.1.7.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.7.6.1\">0.6775</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T9.1.1.7.7\">0.8631</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T9.1.1.7.8\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T9.1.1.7.8.1\">0.7799</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Experiments demonstrated the robustness of self-improving models with the MBR decoding technique. Model fine-tuned on general forward translation had great performance on the in-domain test set and the model fine-tuned on domain-specific forward translation maintained performance on the general domain test set. We provide a broader evaluation in the Appendix Tables 9, 10, 11, 12.\n"
        ]
    },
    "A0.T10.1.1": {
        "caption": "English–German WMT22-medline set results for the MBR self-improvement approaches. All models fine-tuned with MBR self-improvement technique have shown better performance over   model except on metric BLEURT. On this specific test set,   outperformed the   model, unlike the results observed on other test sets.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"A0.T10.1.1\">\n<tr class=\"ltx_tr\" id=\"A0.T10.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A0.T10.1.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T10.1.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T10.1.1.1.3\">BLEU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T10.1.1.1.4\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T10.1.1.1.5\">CometKiwi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T10.1.1.1.6\">UniTE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T10.1.1.1.7\">UniTE-DA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T10.1.1.1.8\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T10.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A0.T10.1.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T10.1.1.2.2\">63.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T10.1.1.2.3\">35.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T10.1.1.2.4\">0.8505</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T10.1.1.2.5\">0.8336</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T10.1.1.2.6\">0.5368</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T10.1.1.2.7\">0.8470</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T10.1.1.2.8\">0.7500</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T10.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T10.1.1.3.1\">Mix-tune</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.3.2\">63.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.3.3\">35.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.3.4\">0.8525</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.3.5\">0.8360</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.3.6\">0.5418</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.3.7\">0.8495</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.3.8\">0.7541</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T10.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T10.1.1.4.1\">Base-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.4.2\">63.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.4.3\">35.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T10.1.1.4.4.1\">0.8549</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.4.5\">0.8374</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.4.6\">0.5549</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.4.7\">0.8501</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.4.8\">0.7522</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T10.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T10.1.1.5.1\">Mix-tune-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.5.2\">63.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.5.3\">35.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.5.4\">0.8540</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.5.5\">0.8379</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.5.6\">0.5552</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.5.7\">0.8508</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.5.8\">0.7530</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T10.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T10.1.1.6.1\">Mix-tune-domain-mbr-iter2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T10.1.1.6.2.1\">63.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T10.1.1.6.3.1\">35.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.6.4\">0.8543</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T10.1.1.6.5.1\">0.8383</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.6.6\">0.5575</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.6.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T10.1.1.6.7.1\">0.8510</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T10.1.1.6.8\">0.7535</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T10.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A0.T10.1.1.7.1\">Mix-tune-general-mbr</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T10.1.1.7.2\">63.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T10.1.1.7.3\">35.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T10.1.1.7.4\">0.8547</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T10.1.1.7.5\">0.8378</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T10.1.1.7.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T10.1.1.7.6.1\">0.5613</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T10.1.1.7.7\">0.8501</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T10.1.1.7.8\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T10.1.1.7.8.1\">0.7542</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Experiments demonstrated the robustness of self-improving models with the MBR decoding technique. Model fine-tuned on general forward translation had great performance on the in-domain test set and the model fine-tuned on domain-specific forward translation maintained performance on the general domain test set. We provide a broader evaluation in the Appendix Tables 9, 10, 11, 12.\n"
        ]
    },
    "A0.T11.1.1": {
        "caption": "English–German FLORES-200 test set results for the MBR self-improvement approaches.   model has shown superior performance, however, models with domain-specific forward translation maintain performance.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"A0.T11.1.1\">\n<tr class=\"ltx_tr\" id=\"A0.T11.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A0.T11.1.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T11.1.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T11.1.1.1.3\">BLEU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T11.1.1.1.4\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T11.1.1.1.5\">CometKiwi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T11.1.1.1.6\">UniTE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T11.1.1.1.7\">UniTE-DA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T11.1.1.1.8\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T11.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A0.T11.1.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T11.1.1.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T11.1.1.2.2.1\">67.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T11.1.1.2.3\">42.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T11.1.1.2.4\">0.8751</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T11.1.1.2.5\">0.8454</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T11.1.1.2.6\">0.6630</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T11.1.1.2.7\">0.8614</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T11.1.1.2.8\">0.7735</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T11.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T11.1.1.3.1\">Mix-tune</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T11.1.1.3.2.1\">67.5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T11.1.1.3.3.1\">42.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.3.4\">0.8756</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.3.5\">0.8457</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.3.6\">0.6657</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.3.7\">0.8617</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.3.8\">0.7744</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T11.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T11.1.1.4.1\">Base-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.4.2\">67.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.4.3\">41.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.4.4\">0.8772</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.4.5\">0.8469</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.4.6\">0.6677</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.4.7\">0.8632</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.4.8\">0.7743</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T11.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T11.1.1.5.1\">Mix-tune-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.5.2\">67.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.5.3\">41.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.5.4\">0.8787</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.5.5\">0.8477</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.5.6\">0.6719</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.5.7\">0.8641</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.5.8\">0.7766</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T11.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T11.1.1.6.1\">Mix-tune-domain-mbr-iter2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.6.2\">67.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.6.3\">41.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.6.4\">0.8766</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.6.5\">0.8466</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.6.6\">0.6653</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.6.7\">0.8629</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T11.1.1.6.8\">0.7748</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T11.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A0.T11.1.1.7.1\">Mix-tune-general-mbr</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T11.1.1.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T11.1.1.7.2.1\">67.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T11.1.1.7.3\">41.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T11.1.1.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T11.1.1.7.4.1\">0.8813</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T11.1.1.7.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T11.1.1.7.5.1\">0.8484</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T11.1.1.7.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T11.1.1.7.6.1\">0.6824</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T11.1.1.7.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T11.1.1.7.7.1\">0.8654</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T11.1.1.7.8\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T11.1.1.7.8.1\">0.7784</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Experiments demonstrated the robustness of self-improving models with the MBR decoding technique. Model fine-tuned on general forward translation had great performance on the in-domain test set and the model fine-tuned on domain-specific forward translation maintained performance on the general domain test set. We provide a broader evaluation in the Appendix Tables 9, 10, 11, 12.\n"
        ]
    },
    "A0.T12.1.1": {
        "caption": "English–German Statmt test set results for the MBR self-improvement approaches.   model has shown significantly improved performance on every metric, however models with domain-specific forward translation maintain performance.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"A0.T12.1.1\">\n<tr class=\"ltx_tr\" id=\"A0.T12.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A0.T12.1.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T12.1.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T12.1.1.1.3\">BLEU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T12.1.1.1.4\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T12.1.1.1.5\">CometKiwi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T12.1.1.1.6\">UniTE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T12.1.1.1.7\">UniTE-DA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T12.1.1.1.8\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T12.1.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A0.T12.1.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T12.1.1.2.2\">63.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T12.1.1.2.3\">36.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T12.1.1.2.4\">0.8428</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T12.1.1.2.5\">0.8328</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T12.1.1.2.6\">0.5308</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T12.1.1.2.7\">0.8420</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T12.1.1.2.8\">0.7106</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T12.1.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T12.1.1.3.1\">Mix-tune</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.3.2\">63.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.3.3\">36.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.3.4\">0.8427</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.3.5\">0.8322</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.3.6\">0.5283</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.3.7\">0.8414</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.3.8\">0.7107</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T12.1.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T12.1.1.4.1\">Base-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.4.2\">63.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.4.3\">35.8</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.4.4\">0.8463</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.4.5\">0.8359</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.4.6\">0.5376</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.4.7\">0.8454</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.4.8\">0.7138</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T12.1.1.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T12.1.1.5.1\">Mix-tune-domain-mbr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.5.2\">63.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.5.3\">35.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.5.4\">0.8468</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.5.5\">0.8358</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.5.6\">0.5404</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.5.7\">0.8464</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.5.8\">0.7132</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T12.1.1.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T12.1.1.6.1\">Mix-tune-domain-mbr-iter2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.6.2\">63.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.6.3\">35.5</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.6.4\">0.8460</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.6.5\">0.8345</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.6.6\">0.5348</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.6.7\">0.8455</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T12.1.1.6.8\">0.7119</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T12.1.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A0.T12.1.1.7.1\">Mix-tune-general-mbr</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T12.1.1.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T12.1.1.7.2.1\">64.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T12.1.1.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T12.1.1.7.3.1\">36.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T12.1.1.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T12.1.1.7.4.1\">0.8629</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T12.1.1.7.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T12.1.1.7.5.1\">0.8399</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T12.1.1.7.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T12.1.1.7.6.1\">0.5622</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T12.1.1.7.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T12.1.1.7.7.1\">0.8492</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T12.1.1.7.8\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T12.1.1.7.8.1\">0.7202</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Experiments demonstrated the robustness of self-improving models with the MBR decoding technique. Model fine-tuned on general forward translation had great performance on the in-domain test set and the model fine-tuned on domain-specific forward translation maintained performance on the general domain test set. We provide a broader evaluation in the Appendix Tables 9, 10, 11, 12.\n"
        ]
    },
    "A0.T13.1": {
        "caption": "Extended Czech–Ukrainian FLORES-200 test set results for the three MBR self-improvement approaches. All approaches lead to an increase in evaluation scores. Both   and   models achieve the highest gains, demonstrating comparable performance. ",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A0.T13.1\">\n<tr class=\"ltx_tr\" id=\"A0.T13.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A0.T13.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T13.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T13.1.1.3\">BLEU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T13.1.1.4\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T13.1.1.5\">CometKiwi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T13.1.1.6\">UniTE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T13.1.1.7\">UniTE-DA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T13.1.1.8\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T13.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A0.T13.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T13.1.2.2\">52.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T13.1.2.3\">22.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T13.1.2.4\">0.8779</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T13.1.2.5\">0.8449</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T13.1.2.6\">0.4441</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T13.1.2.7\">0.9017</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T13.1.2.8\">0.7466</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T13.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T13.1.3.1\">MBR-finetuned</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.3.2\">52.4</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.3.3\">22.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.3.4\">0.8839</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.3.5\">0.8513</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.3.6\">0.4715</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.3.7\">0.9063</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.3.8\">0.7522</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T13.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T13.1.4.1\">MBR-ft-high-lr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T13.1.4.2.1\">52.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.4.3\">22.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T13.1.4.4.1\">0.8869</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T13.1.4.5.1\">0.8543</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.4.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T13.1.4.6.1\">0.4829</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.4.7\">0.9085</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T13.1.4.8\">0.7553</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T13.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A0.T13.1.5.1\">MBR-resumed</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T13.1.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T13.1.5.2.1\">52.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T13.1.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T13.1.5.3.1\">22.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T13.1.5.4\">0.8864</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T13.1.5.5\">0.8540</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T13.1.5.6\">0.4824</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T13.1.5.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T13.1.5.7.1\">0.9086</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T13.1.5.8\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T13.1.5.8.1\">0.7557</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We provide extended evaluations in the Appendix in Tables 13, 14, 15, 16.\n"
        ]
    },
    "A0.T14.1": {
        "caption": "Extended Czech–Ukrainian WMT22 test set results for the three MBR self-improvement approaches. As in the case of evaluation results on the FLORES-200 test set, all approaches improve upon the baseline model, although   stands out across all neural metrics apart from UniTE.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A0.T14.1\">\n<tr class=\"ltx_tr\" id=\"A0.T14.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A0.T14.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T14.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T14.1.1.3\">BLEU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T14.1.1.4\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T14.1.1.5\">CometKiwi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T14.1.1.6\">UniTE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T14.1.1.7\">UniTE-DA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T14.1.1.8\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T14.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A0.T14.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T14.1.2.2\">58.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T14.1.2.3\">31.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T14.1.2.4\">0.8721</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T14.1.2.5\">0.8046</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T14.1.2.6\">0.3744</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T14.1.2.7\">0.8795</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T14.1.2.8\">0.7498</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T14.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T14.1.3.1\">MBR-finetuned</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.3.2\">60.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.3.3\">32.3</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.3.4\">0.8803</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.3.5\">0.8121</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.3.6\">0.4112</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.3.7\">0.8846</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.3.8\">0.7574</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T14.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T14.1.4.1\">MBR-ft-high-lr</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T14.1.4.2.1\">60.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T14.1.4.3.1\">33.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.4.4\">0.8844</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.4.5\">0.8152</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.4.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T14.1.4.6.1\">0.4246</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.4.7\">0.8880</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T14.1.4.8\">0.7619</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T14.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A0.T14.1.5.1\">MBR-resumed</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T14.1.5.2\">60.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T14.1.5.3\">33.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T14.1.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T14.1.5.4.1\">0.8852</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T14.1.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T14.1.5.5.1\">0.8162</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T14.1.5.6\">0.4236</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T14.1.5.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T14.1.5.7.1\">0.8890</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T14.1.5.8\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T14.1.5.8.1\">0.7639</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We provide extended evaluations in the Appendix in Tables 13, 14, 15, 16.\n"
        ]
    },
    "A0.T15.1": {
        "caption": "Extended Czech–Ukrainian iterative self-improvement results on the FLORES-200 test set. Models increase in quality across all neural metrics until the third iteration, when the quality measured by metrics other than COMET and CometKiwi decreases. It’s worth noticing that the BLEU score increases only in the first iteration and slowly degrades in consecutive iterations. ",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A0.T15.1\">\n<tr class=\"ltx_tr\" id=\"A0.T15.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A0.T15.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T15.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T15.1.1.3\">BLEU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T15.1.1.4\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T15.1.1.5\">CometKiwi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T15.1.1.6\">UniTE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T15.1.1.7\">UniTE-DA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T15.1.1.8\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T15.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A0.T15.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T15.1.2.2\">52.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T15.1.2.3\">22.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T15.1.2.4\">0.8779</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T15.1.2.5\">0.8449</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T15.1.2.6\">0.4441</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T15.1.2.7\">0.9017</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T15.1.2.8\">0.7466</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T15.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T15.1.3.1\">MBR-resumed</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.3.2\">52.7</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T15.1.3.3.1\">22.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.3.4\">0.8864</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.3.5\">0.8540</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.3.6\">0.4824</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.3.7\">0.9086</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.3.8\">0.7557</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T15.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T15.1.4.1\">MBR-resumed-iter2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T15.1.4.2.1\">52.8</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.4.3\">22.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.4.4\">0.8888</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.4.5\">0.8557</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.4.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T15.1.4.6.1\">0.4882</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.4.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T15.1.4.7.1\">0.9099</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T15.1.4.8\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T15.1.4.8.1\">0.7567</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T15.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A0.T15.1.5.1\">MBR-resumed-iter3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T15.1.5.2\">52.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T15.1.5.3\">22.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T15.1.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T15.1.5.4.1\">0.8901</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T15.1.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T15.1.5.5.1\">0.8562</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T15.1.5.6\">0.4873</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T15.1.5.7\">0.9097</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T15.1.5.8\">0.7557</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We provide extended evaluations in the Appendix in Tables 13, 14, 15, 16.\n"
        ]
    },
    "A0.T16.1": {
        "caption": "Extended Czech–Ukrainian iterative self-improvement results on the WMT22 test set. Evaluations across all metrics show similar tendencies as in the case of FLORES-200, except for CometKiwi which also decreases in the third iteration.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A0.T16.1\">\n<tr class=\"ltx_tr\" id=\"A0.T16.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A0.T16.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T16.1.1.2\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T16.1.1.3\">BLEU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T16.1.1.4\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T16.1.1.5\">CometKiwi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T16.1.1.6\">UniTE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T16.1.1.7\">UniTE-DA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T16.1.1.8\">BLEURT</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T16.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A0.T16.1.2.1\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T16.1.2.2\">58.4</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T16.1.2.3\">31.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T16.1.2.4\">0.8721</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T16.1.2.5\">0.8046</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T16.1.2.6\">0.3744</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T16.1.2.7\">0.8795</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T16.1.2.8\">0.7498</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T16.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T16.1.3.1\">MBR-resumed</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.3.2\">60.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T16.1.3.3.1\">33.0</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.3.4\">0.8852</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.3.5\">0.8162</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.3.6\">0.4236</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.3.7\">0.8890</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.3.8\">0.7639</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T16.1.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T16.1.4.1\">MBR-resumed-iter2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T16.1.4.2.1\">60.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.4.3\">32.6</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.4.4\">0.8885</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T16.1.4.5.1\">0.8183</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.4.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T16.1.4.6.1\">0.4349</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.4.7\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T16.1.4.7.1\">0.8900</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T16.1.4.8\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T16.1.4.8.1\">0.7641</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T16.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A0.T16.1.5.1\">MBR-resumed-iter3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T16.1.5.2\">60.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T16.1.5.3\">31.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T16.1.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T16.1.5.4.1\">0.8896</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T16.1.5.5\">0.8174</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T16.1.5.6\">0.4312</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T16.1.5.7\">0.8887</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T16.1.5.8\">0.7578</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We provide extended evaluations in the Appendix in Tables 13, 14, 15, 16.\n"
        ]
    },
    "A0.T17.1": {
        "caption": "Extended English–Hausa results on the FLORES-200 test set. According to lexical metrics and AfriCOMET, the   model shows the greatest improvement. However, other neural metrics suggest that the   model is superior.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A0.T17.1\">\n<tr class=\"ltx_tr\" id=\"A0.T17.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A0.T17.1.1.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T17.1.1.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T17.1.1.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">BLEU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T17.1.1.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T17.1.1.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CometKiwi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T17.1.1.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">UniTE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T17.1.1.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">UniTE-DA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T17.1.1.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">BLEURT</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T17.1.1.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">AfriCOMET</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T17.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A0.T17.1.2.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T17.1.2.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">49.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T17.1.2.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T17.1.2.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.7569</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T17.1.2.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.5597</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T17.1.2.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">-0.2297</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T17.1.2.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.6082</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T17.1.2.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.7931</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T17.1.2.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.6984</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T17.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T17.1.3.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MBR-COMET</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T17.1.3.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">50.9</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T17.1.3.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">23.2</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T17.1.3.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T17.1.3.4.1\">0.7720</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T17.1.3.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T17.1.3.5.1\">0.5707</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T17.1.3.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T17.1.3.6.1\">-0.1777</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T17.1.3.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T17.1.3.7.1\">0.6233</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T17.1.3.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T17.1.3.8.1\">0.8083</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T17.1.3.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.7207</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T17.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A0.T17.1.4.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MBR-AfriCOMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T17.1.4.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T17.1.4.2.1\">51.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T17.1.4.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T17.1.4.3.1\">23.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T17.1.4.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.7692</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T17.1.4.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.5638</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T17.1.4.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">-0.1878</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T17.1.4.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.6183</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T17.1.4.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.8061</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T17.1.4.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T17.1.4.9.1\">0.7239</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Additional evaluations are provided in the Appendix in Tables 17, 18.\n"
        ]
    },
    "A0.T18.1": {
        "caption": "Extended English–Hausa results on the NTREX test set. In contrast to evaluations on the FLORES-200 test set, in this case only the AfriCOMET metric favours the   model.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A0.T18.1\">\n<tr class=\"ltx_tr\" id=\"A0.T18.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"A0.T18.1.1.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Model</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T18.1.1.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">chrF</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T18.1.1.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">BLEU</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T18.1.1.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">COMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T18.1.1.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CometKiwi</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T18.1.1.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">UniTE</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T18.1.1.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">UniTE-DA</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T18.1.1.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">BLEURT</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"A0.T18.1.1.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">AfriCOMET</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T18.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A0.T18.1.2.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Baseline</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T18.1.2.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">51.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T18.1.2.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">23.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T18.1.2.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.7596</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T18.1.2.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.5704</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T18.1.2.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">-0.1763</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T18.1.2.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.6294</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T18.1.2.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.7791</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A0.T18.1.2.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.6800</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T18.1.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A0.T18.1.3.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MBR-COMET</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T18.1.3.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T18.1.3.2.1\">53.1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T18.1.3.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T18.1.3.3.1\">25.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T18.1.3.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T18.1.3.4.1\">0.7752</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T18.1.3.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T18.1.3.5.1\">0.5865</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T18.1.3.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T18.1.3.6.1\">-0.1051</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T18.1.3.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T18.1.3.7.1\">0.6484</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T18.1.3.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T18.1.3.8.1\">0.7986</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A0.T18.1.3.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.7046</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A0.T18.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A0.T18.1.4.1\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MBR-AfriCOMET</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T18.1.4.2\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">53.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T18.1.4.3\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">24.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T18.1.4.4\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.7721</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T18.1.4.5\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.5803</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T18.1.4.6\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">-0.1273</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T18.1.4.7\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.6409</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T18.1.4.8\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.7956</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A0.T18.1.4.9\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A0.T18.1.4.9.1\">0.7062</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Additional evaluations are provided in the Appendix in Tables 17, 18.\n"
        ]
    }
}