{
    "PAPER'S NUMBER OF TABLES": 3,
    "S4.T1": {
        "caption": "Table 1: Test accuracies of Fed-GraB/SGB and SOTA methods on CIFAR-10-LT with diverse imbalanced and heterogeneous data settings. More results (e.g., DPA with CL re-weighting methods and IID settings) are in the Supplementary.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nSetting\nMethod\nIFGsubscriptIFG\\text{IF}_{\\text{G}}=10\nIFGsubscriptIFG\\text{IF}_{\\text{G}}=50\nIFGsubscriptIFG\\text{IF}_{\\text{G}}=100\n\nMany\nMed\nFew\nAll\nMany\nMed\nFew\nAll\nMany\nMed\nFew\nAll\n\nCL\nSoftmax\n0.901\n0.879\n0.886\n0.893Â±0.003subscript0.893plus-or-minus0.0030.893_{\\pm 0.003}\n0.908\n0.776\n0.742\n0.817Â±0.003subscript0.817plus-or-minus0.0030.817_{\\pm 0.003}\n0.920\n0.745\n0.675\n0.767Â±0.001subscript0.767plus-or-minus0.0010.767_{\\pm 0.001}\n\nEqlv2\n0.902\n0.880\n0.874\n0.890Â±0.002subscript0.890plus-or-minus0.0020.890_{\\pm 0.002}\n0.903\n0.774\n0.774\n0.819Â±0.006subscript0.819plus-or-minus0.0060.819_{\\pm 0.006}\n0.912\n0.751\n0.679\n0.775Â±0.012subscript0.775plus-or-minus0.0120.775_{\\pm 0.012}\n\nLDAM\n0.957\n0.799\n0.854\n0.838Â±0.026subscript0.838plus-or-minus0.0260.838_{\\pm 0.026}\n0.964\n0.739\n0.685\n0.753Â±0.011subscript0.753plus-or-minus0.0110.753_{\\pm 0.011}\n0.936\n0.729\n0.610\n0.698Â±0.030subscript0.698plus-or-minus0.0300.698_{\\pm 0.030}\n\nSGB-CL\n0.897\n0.901\n0.901\n0.898Â±0.008subscript0.898plus-or-minus0.0080.898_{\\pm 0.008}\n0.891\n0.817\n0.833\n0.846Â±0.004subscript0.846plus-or-minus0.0040.846_{\\pm 0.004}\n0.901\n0.738\n0.814\n0.818Â±0.003subscript0.818plus-or-minus0.0030.818_{\\pm 0.003}\n\nÎ±ğ›¼\\alpha=1\nFedAvg\n0.896\n0.858\n0.846\n0.877Â±0.001subscript0.877plus-or-minus0.0010.877_{\\pm 0.001}\n0.888\n0.771\n0.693\n0.792Â±0.005subscript0.792plus-or-minus0.0050.792_{\\pm 0.005}\n0.922\n0.716\n0.616\n0.737Â±0.001subscript0.737plus-or-minus0.0010.737_{\\pm 0.001}\n\nFedProx\n0.898\n0.859\n0.854\n0.877Â±0.002subscript0.877plus-or-minus0.0020.877_{\\pm 0.002}\n0.891\n0.773\n0.691\n0.794Â±0.002subscript0.794plus-or-minus0.0020.794_{\\pm 0.002}\n0.921\n0.725\n0.582\n0.729Â±0.002subscript0.729plus-or-minus0.0020.729_{\\pm 0.002}\n\nFedNova\n0.912\n0.853\n0.848\n0.882Â±0.002subscript0.882plus-or-minus0.0020.882_{\\pm 0.002}\n0.903\n0.757\n0.702\n0.797Â±0.003subscript0.797plus-or-minus0.0030.797_{\\pm 0.003}\n0.934\n0.734\n0.599\n0.739Â±0.005subscript0.739plus-or-minus0.0050.739_{\\pm 0.005}\n\nFedIR\n0.966\n0.823\n0.862\n0.868Â±0.001subscript0.868plus-or-minus0.0010.868_{\\pm 0.001}\n0.972\n0.775\n0.693\n0.784Â±0.002subscript0.784plus-or-minus0.0020.784_{\\pm 0.002}\n0.969\n0.755\n0.576\n0.728Â±0.004subscript0.728plus-or-minus0.0040.728_{\\pm 0.004}\n\nCReFF\n0.911\n0.850\n0.887\n0.884Â±0.002subscript0.884plus-or-minus0.0020.884_{\\pm 0.002}\n0.896\n0.769\n0.664\n0.791Â±0.003subscript0.791plus-or-minus0.0030.791_{\\pm 0.003}\n0.935\n0.723\n0.574\n0.726Â±0.002subscript0.726plus-or-minus0.0020.726_{\\pm 0.002}\n\n\\cdashline2-14[4pt/3pt]\nÏ„ğœ\\tau-norm\n0.887\n0.871\n0.908\n0.884Â±0.003subscript0.884plus-or-minus0.0030.884_{\\pm 0.003}\n0.878\n0.790\n0.725\n0.805Â±0.002subscript0.805plus-or-minus0.0020.805_{\\pm 0.002}\n0.922\n0.726\n0.668\n0.760Â±0.004subscript0.760plus-or-minus0.0040.760_{\\pm 0.004}\n\n\nEqlv2-FL\n0.896\n0.852\n0.857\n0.878Â±0.003subscript0.878plus-or-minus0.0030.878_{\\pm 0.003}\n0.886\n0.786\n0.690\n0.790Â±0.009subscript0.790plus-or-minus0.0090.790_{\\pm 0.009}\n0.919\n0.704\n0.597\n0.729Â±0.003subscript0.729plus-or-minus0.0030.729_{\\pm 0.003}\n\n\nLDAM-FL\n0.901\n0.845\n0.825\n0.863Â±0.004subscript0.863plus-or-minus0.0040.863_{\\pm 0.004}\n0.881\n0.739\n0.662\n0.768Â±0.005subscript0.768plus-or-minus0.0050.768_{\\pm 0.005}\n0.891\n0.638\n0.495\n0.679Â±0.025subscript0.679plus-or-minus0.0250.679_{\\pm 0.025}\n\n\nFocal-FL\n0.887\n0.839\n0.834\n0.869Â±0.005subscript0.869plus-or-minus0.0050.869_{\\pm 0.005}\n0.877\n0.744\n0.665\n0.775Â±0.002subscript0.775plus-or-minus0.0020.775_{\\pm 0.002}\n0.916\n0.701\n0.558\n0.733Â±0.037subscript0.733plus-or-minus0.0370.733_{\\pm 0.037}\n\n\nGCL-FL\n0.923\n0.747\n0.781\n0.796Â±0.000subscript0.796plus-or-minus0.0000.796_{\\pm 0.000}\n0.949\n0.748\n0.689\n0.761Â±0.005subscript0.761plus-or-minus0.0050.761_{\\pm 0.005}\n0.963\n0.726\n0.608\n0.726Â±0.001subscript0.726plus-or-minus0.0010.726_{\\pm 0.001}\n\n\nFed-GraB\n0.886\n0.882\n0.893\n0.885Â±0.001subscript0.885plus-or-minus0.0010.885_{\\pm 0.001}\n0.875\n0.784\n0.775\n0.818Â±0.003subscript0.818plus-or-minus0.0030.818_{\\pm 0.003}\n0.910\n0.698\n0.713\n0.766Â±0.003subscript0.766plus-or-minus0.0030.766_{\\pm 0.003}\n\nÎ±ğ›¼\\alpha=0.5\nFedAvg\n0.890\n0.864\n0.861\n0.876Â±0.002subscript0.876plus-or-minus0.0020.876_{\\pm 0.002}\n0.865\n0.772\n0.685\n0.781Â±0.003subscript0.781plus-or-minus0.0030.781_{\\pm 0.003}\n0.906\n0.720\n0.585\n0.719Â±0.005subscript0.719plus-or-minus0.0050.719_{\\pm 0.005}\n\nFedProx\n0.883\n0.864\n0.863\n0.874Â±0.000subscript0.874plus-or-minus0.0000.874_{\\pm 0.000}\n0.857\n0.776\n0.688\n0.782Â±0.001subscript0.782plus-or-minus0.0010.782_{\\pm 0.001}\n0.892\n0.712\n0.564\n0.715Â±0.011subscript0.715plus-or-minus0.0110.715_{\\pm 0.011}\n\nFedNova\n0.903\n0.856\n0.834\n0.877Â±0.002subscript0.877plus-or-minus0.0020.877_{\\pm 0.002}\n0.888\n0.773\n0.679\n0.788Â±0.003subscript0.788plus-or-minus0.0030.788_{\\pm 0.003}\n0.924\n0.739\n0.609\n0.739Â±0.004subscript0.739plus-or-minus0.0040.739_{\\pm 0.004}\n\nFedIR\n0.955\n0.816\n0.870\n0.866Â±0.001subscript0.866plus-or-minus0.0010.866_{\\pm 0.001}\n0.961\n0.771\n0.698\n0.781Â±0.001subscript0.781plus-or-minus0.0010.781_{\\pm 0.001}\n0.976\n0.726\n0.562\n0.715Â±0.005subscript0.715plus-or-minus0.0050.715_{\\pm 0.005}\n\nCReFF\n0.900\n0.838\n0.880\n0.877Â±0.004subscript0.877plus-or-minus0.0040.877_{\\pm 0.004}\n0.878\n0.778\n0.664\n0.786Â±0.003subscript0.786plus-or-minus0.0030.786_{\\pm 0.003}\n0.932\n0.699\n0.580\n0.718Â±0.003subscript0.718plus-or-minus0.0030.718_{\\pm 0.003}\n\n\\cdashline2-14[4pt/3pt]\nÏ„ğœ\\tau-norm\n0.883\n0.863\n0.880\n0.877Â±0.004subscript0.877plus-or-minus0.0040.877_{\\pm 0.004}\n0.867\n0.759\n0.728\n0.795Â±0.003subscript0.795plus-or-minus0.0030.795_{\\pm 0.003}\n0.962\n0.726\n0.611\n0.731Â±0.011subscript0.731plus-or-minus0.0110.731_{\\pm 0.011}\n\n\nEqlv2-FL\n0.895\n0.858\n0.855\n0.877Â±0.002subscript0.877plus-or-minus0.0020.877_{\\pm 0.002}\n0.872\n0.771\n0.639\n0.775Â±0.005subscript0.775plus-or-minus0.0050.775_{\\pm 0.005}\n0.898\n0.717\n0.586\n0.714Â±0.011subscript0.714plus-or-minus0.0110.714_{\\pm 0.011}\n\n\nLDAM-FL\n0.885\n0.860\n0.848\n0.850Â±0.006subscript0.850plus-or-minus0.0060.850_{\\pm 0.006}\n0.863\n0.742\n0.673\n0.709Â±0.037subscript0.709plus-or-minus0.0370.709_{\\pm 0.037}\n0.877\n0.583\n0.490\n0.657Â±0.024subscript0.657plus-or-minus0.0240.657_{\\pm 0.024}\n\n\nFocal-FL\n0.868\n0.853\n0.858\n0.865Â±0.005subscript0.865plus-or-minus0.0050.865_{\\pm 0.005}\n0.842\n0.780\n0.661\n0.767Â±0.005subscript0.767plus-or-minus0.0050.767_{\\pm 0.005}\n0.883\n0.703\n0.581\n0.728Â±0.029subscript0.728plus-or-minus0.0290.728_{\\pm 0.029}\n\n\nGCL-FL\n0.902\n0.731\n0.813\n0.798Â±0.004subscript0.798plus-or-minus0.0040.798_{\\pm 0.004}\n0.938\n0.725\n0.725\n0.768Â±0.001subscript0.768plus-or-minus0.0010.768_{\\pm 0.001}\n0.954\n0.730\n0.623\n0.713Â±0.016subscript0.713plus-or-minus0.0160.713_{\\pm 0.016}\n\n\nFed-GraB\n0.864\n0.891\n0.897\n0.881Â±0.002subscript0.881plus-or-minus0.0020.881_{\\pm 0.002}\n0.836\n0.790\n0.783\n0.806Â±0.001subscript0.806plus-or-minus0.0010.806_{\\pm 0.001}\n0.910\n0.698\n0.713\n0.761Â±0.008subscript0.761plus-or-minus0.0080.761_{\\pm 0.008}\n\n\n",
        "references": [
            [
                "Baselines:",
                " We consider two types of SOTA baselines: (1) FL-oriented methods to tackle data heterogeneity (",
                "FedProx",
                "Â ",
                "[",
                "16",
                "]",
                ", ",
                "FedNova",
                "Â ",
                "[",
                "20",
                "]",
                ") or federated long-tailed data-oriented (",
                "FedIR",
                "Â ",
                "[",
                "4",
                "]",
                " and ",
                "CReFF",
                "Â ",
                "[",
                "8",
                "]",
                "), and ",
                "FedAvg",
                " is also included for reference;\n(2) Long-tailed learning (LT)-oriented methods (",
                "Ï„",
                "ğœ",
                "\\tau",
                "-",
                "norm",
                "Â  ",
                "[",
                "25",
                "]",
                ", ",
                "Eqlv2",
                "Â ",
                "[",
                "27",
                "]",
                ", ",
                "LDAM",
                "Â ",
                "[",
                "49",
                "]",
                ", ",
                "Focal-loss",
                "Â ",
                "[",
                "39",
                "]",
                " and ",
                "GCL-loss",
                "Â ",
                "[",
                "42",
                "]",
                ") applied at local training of each client. We also provide the results of the long-tailed methods in centralized learning (CL) settings as the oracle performance upper bound, including SGB.",
                "Datasets:",
                "\nWe conduct the experiments in three benchmark datasets for long-tailed classification, i.e., CIFAR-10/100-LTÂ ",
                "[",
                "57",
                "]",
                ", ImageNet-LTÂ ",
                "[",
                "58",
                "]",
                ". CIFAR-10/100-LT are sampled into long-tailed distribution by exponential distribution controlled by IFÂ ",
                "[",
                "49",
                "]",
                ", and we use the same configurations as in Â ",
                "[",
                "24",
                "]",
                " for ImageNet-LT with the number of images per class ranging from 5 to 1280. To evaluate the performance on real-world data, we also conduct experiments on iNaturalist-User-160k, with 160k examples of 1,023 species classes and partitioned on the basis of iNaturalist-2017Â ",
                "[",
                "59",
                "]",
                ".",
                "Federated settings:",
                " We use non-IID data partitions for all experiments, implemented via symmetric Dirichlet distributions with concentration parameter ",
                "Î±",
                "ğ›¼",
                "\\alpha",
                " to control the identicalness of local data distributions among all the clients.\nWe train a ResNet-18 over ",
                "N",
                "=",
                "40",
                "ğ‘",
                "40",
                "N=40",
                " clients on CIFAR-10-LT. ResNet-34 and ResNet-50 are used on CIFAR-100-LT and ImageNet-LT respectively with ",
                "N",
                "=",
                "20",
                "ğ‘",
                "20",
                "N=20",
                " clients. For iNaturalist-160k, we use the same settings as ImageNet-LT.",
                "Implementation of baselines:",
                "\nFor the sake of fairness, we keep consistent settings external for experiments. We conduct experiments using a starting model from ",
                "FedAvg",
                ". For ",
                "CReFF",
                ", the number of federated features is 100, we use 0.1, 0.01 as federated feature learning rate and main net learning rate respectively on CIFAR-10/100-LT.\nWe report the official result Â ",
                "[",
                "8",
                "]",
                " on ImageNet-LT.\nAs ",
                "Ï„",
                "ğœ",
                "\\tau",
                "-norm",
                " is a one-shot method, we provide a pre-trained model by ",
                "FedAvg",
                " and adjust the classifier weights on the server as post-process.\n",
                "Focal-Loss",
                " and ",
                "EQL v2",
                " do not require distribution prior. We directly replace the local cross-entropy loss with their proposed re-balancing methods. For ",
                "LDAM",
                ", we use the local data distribution for its local training."
            ]
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Test accuracies of various methods on CIFAR-100-LT, ImageNet-LT and iNaturalist-160k with non-IID data settings.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nMethod\nCIFAR-100-LT\nImageNet-LT\niNaturalist-160k\n\nMany\nMed\nFew\nAll\nMany\nMed\nFew\nAll\nMany\nMed\nFew\nAll\n\n\n\nFedAvg\n0.643\n0.410\n0.182\n0.365Â±0.001subscript0.365plus-or-minus0.0010.365_{\\pm 0.001}\n0.428\n0.258\n0.127\n0.287Â±0.006subscript0.287plus-or-minus0.0060.287_{\\pm 0.006}\n0.596\n0.425\n0.242\n0.434Â±0.002subscript0.434plus-or-minus0.0020.434_{\\pm 0.002}\n\nFedProx\n0.639\n0.416\n0.181\n0.366Â±0.000subscript0.366plus-or-minus0.0000.366_{\\pm 0.000}\n0.439\n0.268\n0.128\n0.292Â±0.002subscript0.292plus-or-minus0.0020.292_{\\pm 0.002}\n0.582\n0.424\n0.241\n0.425Â±0.011subscript0.425plus-or-minus0.0110.425_{\\pm 0.011}\n\nFedNova\n0.664\n0.429\n0.195\n0.378Â±0.009subscript0.378plus-or-minus0.0090.378_{\\pm 0.009}\n0.415\n0.234\n0.114\n0.265Â±0.002subscript0.265plus-or-minus0.0020.265_{\\pm 0.002}\n0.564\n0.403\n0.226\n0.404Â±0.006subscript0.404plus-or-minus0.0060.404_{\\pm 0.006}\n\nFedIR\n0.634\n0.410\n0.182\n0.364Â±0.000subscript0.364plus-or-minus0.0000.364_{\\pm 0.000}\n0.388\n0.206\n0.074\n0.236Â±0.012subscript0.236plus-or-minus0.0120.236_{\\pm 0.012}\n0.579\n0.387\n0.191\n0.396Â±0.003subscript0.396plus-or-minus0.0030.396_{\\pm 0.003}\n\nCReFF\n0.684\n0.440\n0.146\n0.401Â±0.002subscript0.401plus-or-minus0.0020.401_{\\pm 0.002}\n-\n-\n-\n0.263Â±0.000subscript0.263plus-or-minus0.0000.263_{\\pm 0.000}\n-\n-\n-\n-\n\n\\cdashline1-13[4pt/3pt]\nÏ„ğœ\\tau-norm\n0.459\n0.362\n0.323\n0.368Â±0.003subscript0.368plus-or-minus0.0030.368_{\\pm 0.003}\n0.347\n0.285\n0.260\n0.288Â±0.018subscript0.288plus-or-minus0.0180.288_{\\pm 0.018}\n0.537\n0.433\n0.287\n0.434Â±0.003subscript0.434plus-or-minus0.0030.434_{\\pm 0.003}\n\nEqlv2-FL\n0.652\n0.434\n0.198\n0.381Â±0.002subscript0.381plus-or-minus0.0020.381_{\\pm 0.002}\n0.433\n0.262\n0.118\n0.281Â±0.006subscript0.281plus-or-minus0.0060.281_{\\pm 0.006}\n0.570\n0.397\n0.376\n0.440Â±0.014subscript0.440plus-or-minus0.0140.440_{\\pm 0.014}\n\nLDAM-FL\n0.639\n0.409\n0.168\n0.355Â±0.005subscript0.355plus-or-minus0.0050.355_{\\pm 0.005}\n0.365\n0.216\n0.112\n0.242Â±0.002subscript0.242plus-or-minus0.0020.242_{\\pm 0.002}\n0.560\n0.409\n0.244\n0.414Â±0.003subscript0.414plus-or-minus0.0030.414_{\\pm 0.003}\n\nFocal-FL\n0.645\n0.418\n0.179\n0.367Â±0.001subscript0.367plus-or-minus0.0010.367_{\\pm 0.001}\n0.424\n0.266\n0.136\n0.283Â±0.005subscript0.283plus-or-minus0.0050.283_{\\pm 0.005}\n0.596\n0.430\n0.247\n0.430Â±0.005subscript0.430plus-or-minus0.0050.430_{\\pm 0.005}\n\nGCL-FL\n0.567\n0.346\n0.156\n0.301Â±0.012subscript0.301plus-or-minus0.0120.301_{\\pm 0.012}\n0.317\n0.209\n0.124\n0.224Â±0.001subscript0.224plus-or-minus0.0010.224_{\\pm 0.001}\n0.565\n0.375\n0.196\n0.388Â±0.007subscript0.388plus-or-minus0.0070.388_{\\pm 0.007}\n\nFed-GraB\n0.683\n0.553\n0.221\n0.411Â±0.002subscript0.411plus-or-minus0.0020.411_{\\pm 0.002}\n0.407\n0.294\n0.215\n0.311Â±0.003subscript0.311plus-or-minus0.0030.311_{\\pm 0.003}\n0.527\n0.449\n0.372\n0.451Â±0.004subscript0.451plus-or-minus0.0040.451_{\\pm 0.004}\n\n\n",
        "references": [
            [
                "Baselines:",
                " We consider two types of SOTA baselines: (1) FL-oriented methods to tackle data heterogeneity (",
                "FedProx",
                "Â ",
                "[",
                "16",
                "]",
                ", ",
                "FedNova",
                "Â ",
                "[",
                "20",
                "]",
                ") or federated long-tailed data-oriented (",
                "FedIR",
                "Â ",
                "[",
                "4",
                "]",
                " and ",
                "CReFF",
                "Â ",
                "[",
                "8",
                "]",
                "), and ",
                "FedAvg",
                " is also included for reference;\n(2) Long-tailed learning (LT)-oriented methods (",
                "Ï„",
                "ğœ",
                "\\tau",
                "-",
                "norm",
                "Â  ",
                "[",
                "25",
                "]",
                ", ",
                "Eqlv2",
                "Â ",
                "[",
                "27",
                "]",
                ", ",
                "LDAM",
                "Â ",
                "[",
                "49",
                "]",
                ", ",
                "Focal-loss",
                "Â ",
                "[",
                "39",
                "]",
                " and ",
                "GCL-loss",
                "Â ",
                "[",
                "42",
                "]",
                ") applied at local training of each client. We also provide the results of the long-tailed methods in centralized learning (CL) settings as the oracle performance upper bound, including SGB.",
                "Datasets:",
                "\nWe conduct the experiments in three benchmark datasets for long-tailed classification, i.e., CIFAR-10/100-LTÂ ",
                "[",
                "57",
                "]",
                ", ImageNet-LTÂ ",
                "[",
                "58",
                "]",
                ". CIFAR-10/100-LT are sampled into long-tailed distribution by exponential distribution controlled by IFÂ ",
                "[",
                "49",
                "]",
                ", and we use the same configurations as in Â ",
                "[",
                "24",
                "]",
                " for ImageNet-LT with the number of images per class ranging from 5 to 1280. To evaluate the performance on real-world data, we also conduct experiments on iNaturalist-User-160k, with 160k examples of 1,023 species classes and partitioned on the basis of iNaturalist-2017Â ",
                "[",
                "59",
                "]",
                ".",
                "Federated settings:",
                " We use non-IID data partitions for all experiments, implemented via symmetric Dirichlet distributions with concentration parameter ",
                "Î±",
                "ğ›¼",
                "\\alpha",
                " to control the identicalness of local data distributions among all the clients.\nWe train a ResNet-18 over ",
                "N",
                "=",
                "40",
                "ğ‘",
                "40",
                "N=40",
                " clients on CIFAR-10-LT. ResNet-34 and ResNet-50 are used on CIFAR-100-LT and ImageNet-LT respectively with ",
                "N",
                "=",
                "20",
                "ğ‘",
                "20",
                "N=20",
                " clients. For iNaturalist-160k, we use the same settings as ImageNet-LT.",
                "Implementation of baselines:",
                "\nFor the sake of fairness, we keep consistent settings external for experiments. We conduct experiments using a starting model from ",
                "FedAvg",
                ". For ",
                "CReFF",
                ", the number of federated features is 100, we use 0.1, 0.01 as federated feature learning rate and main net learning rate respectively on CIFAR-10/100-LT.\nWe report the official result Â ",
                "[",
                "8",
                "]",
                " on ImageNet-LT.\nAs ",
                "Ï„",
                "ğœ",
                "\\tau",
                "-norm",
                " is a one-shot method, we provide a pre-trained model by ",
                "FedAvg",
                " and adjust the classifier weights on the server as post-process.\n",
                "Focal-Loss",
                " and ",
                "EQL v2",
                " do not require distribution prior. We directly replace the local cross-entropy loss with their proposed re-balancing methods. For ",
                "LDAM",
                ", we use the local data distribution for its local training."
            ]
        ]
    },
    "S4.T3": {
        "caption": "Table 3: A comparison of communication efficiency on CIFAR-10, in terms of the number of required rounds, where â€œ-â€ indicate the method cannot obtain the target accuracy.",
        "table": "<table id=\"S4.T3.6.6\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.2.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" rowspan=\"2\"><span id=\"S4.T3.2.2.2.3.1\" class=\"ltx_text\">Method</span></th>\n<td id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"2\">\n<math id=\"S4.T3.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\text{IF}_{\\text{G}}\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.1.m1.1a\"><msub id=\"S4.T3.1.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.1.m1.1.1.cmml\"><mtext id=\"S4.T3.1.1.1.1.m1.1.1.2\" xref=\"S4.T3.1.1.1.1.m1.1.1.2a.cmml\">IF</mtext><mtext id=\"S4.T3.1.1.1.1.m1.1.1.3\" xref=\"S4.T3.1.1.1.1.m1.1.1.3a.cmml\">G</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.1.m1.1b\"><apply id=\"S4.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T3.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T3.1.1.1.1.m1.1.1.2a.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1.2\"><mtext id=\"S4.T3.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1.2\">IF</mtext></ci><ci id=\"S4.T3.1.1.1.1.m1.1.1.3a.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1.3\"><mtext mathsize=\"70%\" id=\"S4.T3.1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1.3\">G</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.1.m1.1c\">\\text{IF}_{\\text{G}}</annotation></semantics></math>=50</td>\n<td id=\"S4.T3.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"2\">\n<math id=\"S4.T3.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\text{IF}_{\\text{G}}\" display=\"inline\"><semantics id=\"S4.T3.2.2.2.2.m1.1a\"><msub id=\"S4.T3.2.2.2.2.m1.1.1\" xref=\"S4.T3.2.2.2.2.m1.1.1.cmml\"><mtext id=\"S4.T3.2.2.2.2.m1.1.1.2\" xref=\"S4.T3.2.2.2.2.m1.1.1.2a.cmml\">IF</mtext><mtext id=\"S4.T3.2.2.2.2.m1.1.1.3\" xref=\"S4.T3.2.2.2.2.m1.1.1.3a.cmml\">G</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.2.2.m1.1b\"><apply id=\"S4.T3.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T3.2.2.2.2.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T3.2.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T3.2.2.2.2.m1.1.1\">subscript</csymbol><ci id=\"S4.T3.2.2.2.2.m1.1.1.2a.cmml\" xref=\"S4.T3.2.2.2.2.m1.1.1.2\"><mtext id=\"S4.T3.2.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T3.2.2.2.2.m1.1.1.2\">IF</mtext></ci><ci id=\"S4.T3.2.2.2.2.m1.1.1.3a.cmml\" xref=\"S4.T3.2.2.2.2.m1.1.1.3\"><mtext mathsize=\"70%\" id=\"S4.T3.2.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T3.2.2.2.2.m1.1.1.3\">G</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.2.2.m1.1c\">\\text{IF}_{\\text{G}}</annotation></semantics></math>=100</td>\n</tr>\n<tr id=\"S4.T3.6.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><math id=\"S4.T3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=1\" display=\"inline\"><semantics id=\"S4.T3.3.3.3.1.m1.1a\"><mrow id=\"S4.T3.3.3.3.1.m1.1.1\" xref=\"S4.T3.3.3.3.1.m1.1.1.cmml\"><mi id=\"S4.T3.3.3.3.1.m1.1.1.2\" xref=\"S4.T3.3.3.3.1.m1.1.1.2.cmml\">Î±</mi><mo id=\"S4.T3.3.3.3.1.m1.1.1.1\" xref=\"S4.T3.3.3.3.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T3.3.3.3.1.m1.1.1.3\" xref=\"S4.T3.3.3.3.1.m1.1.1.3.cmml\">1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.3.3.3.1.m1.1b\"><apply id=\"S4.T3.3.3.3.1.m1.1.1.cmml\" xref=\"S4.T3.3.3.3.1.m1.1.1\"><eq id=\"S4.T3.3.3.3.1.m1.1.1.1.cmml\" xref=\"S4.T3.3.3.3.1.m1.1.1.1\"></eq><ci id=\"S4.T3.3.3.3.1.m1.1.1.2.cmml\" xref=\"S4.T3.3.3.3.1.m1.1.1.2\">ğ›¼</ci><cn type=\"integer\" id=\"S4.T3.3.3.3.1.m1.1.1.3.cmml\" xref=\"S4.T3.3.3.3.1.m1.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.3.3.3.1.m1.1c\">\\alpha=1</annotation></semantics></math></td>\n<td id=\"S4.T3.4.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><math id=\"S4.T3.4.4.4.2.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=0.5\" display=\"inline\"><semantics id=\"S4.T3.4.4.4.2.m1.1a\"><mrow id=\"S4.T3.4.4.4.2.m1.1.1\" xref=\"S4.T3.4.4.4.2.m1.1.1.cmml\"><mi id=\"S4.T3.4.4.4.2.m1.1.1.2\" xref=\"S4.T3.4.4.4.2.m1.1.1.2.cmml\">Î±</mi><mo id=\"S4.T3.4.4.4.2.m1.1.1.1\" xref=\"S4.T3.4.4.4.2.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T3.4.4.4.2.m1.1.1.3\" xref=\"S4.T3.4.4.4.2.m1.1.1.3.cmml\">0.5</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.4.4.4.2.m1.1b\"><apply id=\"S4.T3.4.4.4.2.m1.1.1.cmml\" xref=\"S4.T3.4.4.4.2.m1.1.1\"><eq id=\"S4.T3.4.4.4.2.m1.1.1.1.cmml\" xref=\"S4.T3.4.4.4.2.m1.1.1.1\"></eq><ci id=\"S4.T3.4.4.4.2.m1.1.1.2.cmml\" xref=\"S4.T3.4.4.4.2.m1.1.1.2\">ğ›¼</ci><cn type=\"float\" id=\"S4.T3.4.4.4.2.m1.1.1.3.cmml\" xref=\"S4.T3.4.4.4.2.m1.1.1.3\">0.5</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.4.4.4.2.m1.1c\">\\alpha=0.5</annotation></semantics></math></td>\n<td id=\"S4.T3.5.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><math id=\"S4.T3.5.5.5.3.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=1\" display=\"inline\"><semantics id=\"S4.T3.5.5.5.3.m1.1a\"><mrow id=\"S4.T3.5.5.5.3.m1.1.1\" xref=\"S4.T3.5.5.5.3.m1.1.1.cmml\"><mi id=\"S4.T3.5.5.5.3.m1.1.1.2\" xref=\"S4.T3.5.5.5.3.m1.1.1.2.cmml\">Î±</mi><mo id=\"S4.T3.5.5.5.3.m1.1.1.1\" xref=\"S4.T3.5.5.5.3.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T3.5.5.5.3.m1.1.1.3\" xref=\"S4.T3.5.5.5.3.m1.1.1.3.cmml\">1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.5.5.5.3.m1.1b\"><apply id=\"S4.T3.5.5.5.3.m1.1.1.cmml\" xref=\"S4.T3.5.5.5.3.m1.1.1\"><eq id=\"S4.T3.5.5.5.3.m1.1.1.1.cmml\" xref=\"S4.T3.5.5.5.3.m1.1.1.1\"></eq><ci id=\"S4.T3.5.5.5.3.m1.1.1.2.cmml\" xref=\"S4.T3.5.5.5.3.m1.1.1.2\">ğ›¼</ci><cn type=\"integer\" id=\"S4.T3.5.5.5.3.m1.1.1.3.cmml\" xref=\"S4.T3.5.5.5.3.m1.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.5.5.5.3.m1.1c\">\\alpha=1</annotation></semantics></math></td>\n<td id=\"S4.T3.6.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><math id=\"S4.T3.6.6.6.4.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=0.5\" display=\"inline\"><semantics id=\"S4.T3.6.6.6.4.m1.1a\"><mrow id=\"S4.T3.6.6.6.4.m1.1.1\" xref=\"S4.T3.6.6.6.4.m1.1.1.cmml\"><mi id=\"S4.T3.6.6.6.4.m1.1.1.2\" xref=\"S4.T3.6.6.6.4.m1.1.1.2.cmml\">Î±</mi><mo id=\"S4.T3.6.6.6.4.m1.1.1.1\" xref=\"S4.T3.6.6.6.4.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T3.6.6.6.4.m1.1.1.3\" xref=\"S4.T3.6.6.6.4.m1.1.1.3.cmml\">0.5</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.6.6.6.4.m1.1b\"><apply id=\"S4.T3.6.6.6.4.m1.1.1.cmml\" xref=\"S4.T3.6.6.6.4.m1.1.1\"><eq id=\"S4.T3.6.6.6.4.m1.1.1.1.cmml\" xref=\"S4.T3.6.6.6.4.m1.1.1.1\"></eq><ci id=\"S4.T3.6.6.6.4.m1.1.1.2.cmml\" xref=\"S4.T3.6.6.6.4.m1.1.1.2\">ğ›¼</ci><cn type=\"float\" id=\"S4.T3.6.6.6.4.m1.1.1.3.cmml\" xref=\"S4.T3.6.6.6.4.m1.1.1.3\">0.5</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.6.6.6.4.m1.1c\">\\alpha=0.5</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T3.6.6.7.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.6.6.7.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">FedAvg</th>\n<td id=\"S4.T3.6.6.7.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">96</td>\n<td id=\"S4.T3.6.6.7.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">122</td>\n<td id=\"S4.T3.6.6.7.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">88</td>\n<td id=\"S4.T3.6.6.7.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">192</td>\n</tr>\n<tr id=\"S4.T3.6.6.8.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.6.6.8.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">CReFF</th>\n<td id=\"S4.T3.6.6.8.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">285</td>\n<td id=\"S4.T3.6.6.8.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">286</td>\n<td id=\"S4.T3.6.6.8.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">309</td>\n<td id=\"S4.T3.6.6.8.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">348</td>\n</tr>\n<tr id=\"S4.T3.6.6.9.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.6.6.9.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">Eqlv2-FL</th>\n<td id=\"S4.T3.6.6.9.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">301</td>\n<td id=\"S4.T3.6.6.9.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">210</td>\n<td id=\"S4.T3.6.6.9.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">191</td>\n<td id=\"S4.T3.6.6.9.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">205</td>\n</tr>\n<tr id=\"S4.T3.6.6.10.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.6.6.10.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">LDAM-FL</th>\n<td id=\"S4.T3.6.6.10.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">483</td>\n<td id=\"S4.T3.6.6.10.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">427</td>\n<td id=\"S4.T3.6.6.10.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">-</td>\n<td id=\"S4.T3.6.6.10.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">-</td>\n</tr>\n<tr id=\"S4.T3.6.6.11.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.6.6.11.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">Focal-FL</th>\n<td id=\"S4.T3.6.6.11.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">276</td>\n<td id=\"S4.T3.6.6.11.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">174</td>\n<td id=\"S4.T3.6.6.11.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">347</td>\n<td id=\"S4.T3.6.6.11.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">257</td>\n</tr>\n<tr id=\"S4.T3.6.6.12.6\" class=\"ltx_tr\">\n<th id=\"S4.T3.6.6.12.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Fed-GBA</th>\n<td id=\"S4.T3.6.6.12.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S4.T3.6.6.12.6.2.1\" class=\"ltx_text ltx_font_bold\">59</span></td>\n<td id=\"S4.T3.6.6.12.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S4.T3.6.6.12.6.3.1\" class=\"ltx_text ltx_font_bold\">63</span></td>\n<td id=\"S4.T3.6.6.12.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S4.T3.6.6.12.6.4.1\" class=\"ltx_text ltx_font_bold\">95</span></td>\n<td id=\"S4.T3.6.6.12.6.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S4.T3.6.6.12.6.5.1\" class=\"ltx_text ltx_font_bold\">122</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "SGB for consistent gradient re-weighting across clients:",
                "\nWhen various clients employ a gradient re-weighting method on a specific class, the strength of compensating divergence is because of the diverse local distributions and local dataset sizes. Therefore, although traditional re-weighting methods can mitigate the imbalance, discrepancies still exist. We demonstrate the advantage of SGB for addressing this issue.\nSpecifically, we compute the mean and standard deviation (std) of ",
                "Î”",
                "j",
                "â€‹",
                "(",
                "t",
                ")",
                "subscript",
                "Î”",
                "ğ‘—",
                "ğ‘¡",
                "\\Delta_{j}(t)",
                " across all clients in CIFAR-10-LT for both ",
                "Eqlv2",
                " and ",
                "Fed-GraB",
                ", as illustrated in Fig.Â ",
                "4",
                " (a).",
                "We make two observations here. First, the mean of ",
                "Î”",
                "j",
                "â€‹",
                "(",
                "t",
                ")",
                "subscript",
                "Î”",
                "ğ‘—",
                "ğ‘¡",
                "\\Delta_{j}(t)",
                " in Eqlv2 keeps decreasing alongside the training process while ",
                "Fed-GraB",
                " can always align it to a near-zero value, suggesting that ",
                "Fed-GraB",
                " can better re-weight the positive and negative gradients. Second, ",
                "Eqlv2",
                " exhibits a large variance among clients during training. In contrast, ",
                "Fed-GraB",
                " maintains a very small deviation, evidently demonstrating the ",
                "Fed-GraB",
                " can consistently motivate the heterogeneous clients to converge towards a better aggregated global model.",
                "Effectiveness on global distribution and tail class estimation:",
                "\nWe evaluate DPA under three IF settings with two metrics: (1) the L2-distance between the prior vector ",
                "ğ’«",
                "c",
                "subscript",
                "ğ’«",
                "ğ‘",
                "\\mathcal{P}_{c}",
                " and ground truth distribution; (2) the tail identification accuracy (percentage of tail classes that are identified correctly by DPA).\nWe plot the two metrics on a global model with FedAvg for 200 rounds in Fig.Â ",
                "4",
                " (b). We can see that DPA converges after 70 rounds of training and captures more than 90% of the tail classes under different IFs. Moreover, the tail identification accuracy becomes more accurate with a higher IF, which is attributed to the extreme imbalance among classes (i.e., easier to distinguish).",
                "Effectiveness of global ",
                "ğ’«",
                "c",
                "subscript",
                "ğ’«",
                "ğ‘",
                "\\mathcal{P}_{c}",
                ":",
                "\nWe investigate a local version (Local-SGB) of ",
                "Fed-GraB",
                " (Global-SGB), where each client implements SGB based on their local distribution instead of the global prior vector derived by DPA. The results on CIFAR-10-LT in Fig.Â ",
                "4",
                " (c) show that Global-SGB achieves a higher test accuracy. Furthermore, we visualize the accuracies of ",
                "FedAvg",
                " and ",
                "Fed-GraB",
                " after local updates on the received global model in Fig.Â ",
                "5",
                " (a), which demonstrate that ",
                "Fed-GraB",
                " can achieve better and more balanced performance across classes, especially for tails (e.g., class 2, 3, 8, 9).",
                "Mounting strategies with SGB:",
                "\nIn ",
                "Fed-GraB",
                ", SGB is universally applied to all classifiers through the use of DPA, rather than selectively targeting specific classes without DPA. We demonstrate that a full mounting approach with DPA can more readily attain optimal performance compared to a custom-tailored tailed class (i.e., mounting on 7 to 9 classes). As depicted in Fig.Â ",
                "5",
                " (b), the model excels when SGB is employed on tail classes, while accuracy diminishes when mounting all classes or solely the exceedingly biased classes. Notably, DPA significantly bolsters overall performance."
            ]
        ]
    }
}