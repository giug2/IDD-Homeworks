{
    "id_table_1": {
        "caption": "Table 1:  The repositories utilized in our RepoGenEval benchmark. Files denotes the total number of Python source files, and Lines denotes the total number of non-empty Python code lines.",
        "table": "S4.T1.15.15",
        "footnotes": [],
        "references": [
            "In this paper, we introduce RepoGenReflex, a novel approach that enhances the RAG framework with VRL to further refine LLM-based repository-level code completion,  optimizing retrieval and generation iterations through iterative feedback.  As demonstrated in Figure  1 , RepoGenReflex iteratively retrieves relevant code snippets, generates possible code completion, evaluates the results by Evaluator, and gives detailed feedback using Reflector.  Reflector provides linguistic feedback, guiding the next iteration to improve the quality of the generated code.  Each feedback is stored in the Experience component, which helps refine future iterations, ensuring that the framework continuously improves its performance without the need for model weight updates, enabling efficient optimization across various tasks.",
            "Figure  1  depicts our framework, which consists of a Retriever, Actor (Generative LLM), Evaluator, Reflector, and Experience. Together they work iteratively to generate high-quality code.",
            "The model operates in a tightly coupled iterative loop, as illustrated in Figure  1 . The process starts with the Retriever extracting relevant snippets to generate a new prompt. The Actor uses this prompt to generate code, which is then evaluated. The Evaluators results and generated code inform the Reflector, which refines the output and feeds it back to the Retriever, repeating the cycle.",
            "To determine the optimal stopping point in this process, we implement a stopping criterion based on the stability of evaluation scores. Specifically, the process stops if the ES score does not show significant improvement (e.g., less than 1%) for a predefined number of iterations (e.g., 3 iterations) while the EM score is always 0. Algorithm  1  shows the detail.",
            "As shown in Table  1 , the new benchmark provides a robust, comprehensive benchmark, comprising 8 high-quality repositories that reflect diverse applications and complexities. This improved benchmark is instrumental in validating the enhanced capabilities of our programming models."
        ]
    },
    "global_footnotes": []
}