{
    "id_table_1": {
        "caption": "Table 1 .  Summary Statistics for the call transcript documents used in the present work.",
        "table": "S3.T1.2",
        "footnotes": [],
        "references": [
            "The schematic diagram in Figure  1  provides details on the part of RAG that generates vector database from given external documents in the traditional VectorRAG methodology where we also include explicit reference of metadata  [ 8 ] . Section  4.2  will provide implementation details for our experiments.",
            "Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM. A detailed discussion on implementation of the methodology will be provided in Section  4.1",
            "A schematic diagram of the retrieval methodology of GraphRAG is given in Figure  2 . Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section  4.1",
            "Table  1  summarizes basic statistics of the documents we will be experimenting with in the remainder of this work.",
            "Knowledge Graph Construction:-   We begin by constructing a KG from a set of knowledge triplets extracted from corporate documents using the prompt engineering based methodology as described in Section  4.1 . These triplets, stored in a pickle file, represent structured information in the form of subject-predicate-object relationships. We use the NetworkxEntityGraph class from the LangChain library to create and manage this graph structure. Each triple is added to the graph, which encapsulates the head entity, relation, tail entity, and additional metadata."
        ]
    },
    "id_table_2": {
        "caption": "Table 2 .  Entities extracted from earnings call transcripts",
        "table": "S4.T2.2.1",
        "footnotes": [],
        "references": [
            "The schematic diagram in Figure  1  provides details on the part of RAG that generates vector database from given external documents in the traditional VectorRAG methodology where we also include explicit reference of metadata  [ 8 ] . Section  4.2  will provide implementation details for our experiments.",
            "A schematic diagram of the retrieval methodology of GraphRAG is given in Figure  2 . Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section  4.1",
            "Table  2  summarizes details on entities extracted from the earning calls transcripts using our prompt based method. Concurrently, LLM identifies relationships between these entities using a curated set of verbs, capturing the nuanced interactions within the corporate narrative. A key improvement in our methodology is the enhanced prompt engineering to generate the structured output format for knowledge triplets. Each triplet is represented as a nested list [h, type, r, o, type, metadata], where h and o denote the head and object entities respectively, type specifies the entity category, r represents the relationship, and metadata encapsulates additional contextual information. This format allows for a rich, multidimensional representation of information, facilitating more nuanced downstream analysis."
        ]
    },
    "id_table_3": {
        "caption": "Table 3 .  VectorRAG Configuration",
        "table": "S4.T3.2",
        "footnotes": [],
        "references": [
            "At the core of our system is a Pinecone vector database 7 7 7 https://www.pinecone.io/ , which serves as the foundation for our information retrieval process. We employ OpenAIs text-embedding-ada-002 model to transform textual data from earnings call transcripts into high-dimensional vector representations. This vectorization process enables semantic similarity searches, significantly enhancing the relevance and accuracy of retrieved information. Table  3  provides summary of the configuration of the set up in use for our experiments."
        ]
    },
    "id_table_4": {
        "caption": "Table 4 .  GraphRAG Configuration",
        "table": "S4.T4.2",
        "footnotes": [],
        "references": [
            "The schematic diagram in Figure  1  provides details on the part of RAG that generates vector database from given external documents in the traditional VectorRAG methodology where we also include explicit reference of metadata  [ 8 ] . Section  4.2  will provide implementation details for our experiments.",
            "Both the steps are executed using carefully performed prompt engineering on a pre-trained LLM. A detailed discussion on implementation of the methodology will be provided in Section  4.1",
            "A schematic diagram of the retrieval methodology of GraphRAG is given in Figure  2 . Here we first write a prompt to clean the data and then write another prompt in the second stage to create knowledge triplets along with metadata. It will be covered in more detail in section  4.1",
            "The amalgamation of these two contexts allows us to leverage the strengths of both approaches. The VectorRAG component provides a broad, similarity-based retrieval of relevant information, while the GraphRAG element contributes structured, relationship-rich contextual data. This combined context is then utilized as input for a LLM to generate the final responses. Details on the implementation of the HybridRAG will be provided in Section  4.4 .",
            "Knowledge Graph Construction:-   We begin by constructing a KG from a set of knowledge triplets extracted from corporate documents using the prompt engineering based methodology as described in Section  4.1 . These triplets, stored in a pickle file, represent structured information in the form of subject-predicate-object relationships. We use the NetworkxEntityGraph class from the LangChain library to create and manage this graph structure. Each triple is added to the graph, which encapsulates the head entity, relation, tail entity, and additional metadata.",
            "We implement the Q&A functionality using the GraphQAChain class from LangChain. This chain combines the KG with an LLM (in our case, OpenAIs GPT-3.5-turbo) to generate responses. The GraphQAChain traverses the KG to find relevant information and uses the language model to formulate coherent answers based on the retrieved context. A summary of configuration of our LLM models and other libraries used for GraphRAG is shown in Table  4 ."
        ]
    },
    "id_table_5": {
        "caption": "Table 5 .  Performance Metrics for Different RAG Pipelines. Here, F, AR, CP and CR refer to Faithfulness, Answer Relevence, Context Precision and Context Recall.",
        "table": "S5.T5.2",
        "footnotes": [],
        "references": [
            "The results of our comparative analysis reveal notable differences in performance among VectorRAG, GraphRAG, and HybridRAG approaches as summarized in Table  5 . In terms of Faithfulness, GraphRAG and HybridRAG demonstrated superior performance, both achieving a score of 0.96, while VectorRAG trailed slightly with a score of 0.94. Answer relevancy scores varied across the methods, with HybridRAG outperforming the others at 0.96, followed by VectorRAG at 0.91, and GraphRAG at 0.89. Context precision was highest for GraphRAG at 0.96, significantly surpassing VectorRAG (0.84) and HybridRAG (0.79). However, in context recall, both VectorRAG and HybridRAG achieved perfect scores of 1, while GraphRAG lagged behind at 0.85."
        ]
    },
    "global_footnotes": []
}