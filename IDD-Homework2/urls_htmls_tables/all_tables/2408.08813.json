{
    "id_table_1": {
        "caption": "TABLE I:  Segmentation performance comparison using Dice similarity coefficient (DSC) on ACDC, CMR T1-MAP, and Fluoroscopy Image datasets. Abbreviations: RV (right ventricle), Myo (myocardium), LV (left ventricle).",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": [
            "Recently, the Segment Anything Model 2 (SAM 2) introduced enhanced capabilities for image segmentation and extended promptable segmentation to video applications  [ 17 ] . A key modification in SAM 2 for video segmentation is the memory-driven approach which leverages temporal information by encoding segmentations from previous video frames as memories and condition on those memories to produce the segmentation of subsequent frames. Such ability naturally adapts to few-shot medical image segmentation: instead of integrating information from previous frames, we can retrieval the contextual and anatomical information from similar cases to guide the segmentation process, as the Retrieval-Augmented Generation (RAG) approach used in LLMs  [ 18 ,  19 ] . This mirrors how humans learn to perform segmentation tasks: even without prior knowledge, they can observe and study a few examples, quickly understand the process, and then apply it effectively ( Figure   1 )."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Comparison of segmentation performance on the ACDC dataset between fully-supervised methods and our approach.",
        "table": "S4.T2.1",
        "footnotes": [],
        "references": [
            "The Retrieval Module is a critical component of our segmentation framework, designed to augment segmentation by efficiently retrieving relevant annotated examples from a database built from limited samples. The module begins by utilizing DINOv2  [ 20 ]  to extract high-dimensional embeddings from a set of annotated images. These embeddings capture the semantic features of the images and are then indexed using FAISS (Facebook AI Similarity Search)  [ 34 ]  ( Figure   2 (b)) which is optimized for efficient similarity search of dense vectors.",
            "Our few-shot segmentation framework, as shown in  Figure   2  (a), is designed to perform medical image segmentation with limited annotated data by leveraging a retrieval-augmented system. This framework is adapted from the Segment Anything Model 2 (SAM 2)  [ 17 ]  and operates without requiring additional training, making it highly adaptable and efficient for various medical imaging tasks."
        ]
    },
    "id_table_3": {
        "caption": "TABLE III:  Comparison of segmentation performance on the ACDC dataset using different retrieval strategies (Random vs. DINOv2) and varying numbers of queried images (#8 vs. #16).",
        "table": "S4.T3.1",
        "footnotes": [],
        "references": [
            "Figure   3  presents a qualitative comparison of segmentation performance across three datasets. In the ACDC dataset, our method closely matches the ground truth, accurately segmenting both the myocardium and ventricles. In contrast, the SAM 2 model with point prompts tends to over-segment the RV, Myo, and LV, particularly the ring-shaped myocardium. Similarly, in the CMR T1-MAP dataset, our method delivers more precise segmentation, while the SAM 2 variants often over-segment the myocardial region, incorrectly including parts of the LV and RV. For the Fluoroscopy Image dataset, our method achieves more refined and continuous vessel segmentation, whereas the SAM 2 model produces incomplete and less accurate results, missing several main and side branches. Overall, this figure clearly demonstrates the superiority of our method in achieving more accurate and reliable segmentations across diverse medical imaging modalities.",
            "For the vessel segmentation task, we also observed that the model struggles when the image contrast is low, leading to suboptimal performance. This limitation stems from the inherent capabilities of the SAM 2 model, which our method builds upon. SAM 2 tends to underperform when the contrast between foreground/background is insufficient, especially for segmenting small branches in our cases ( Figure   3 ). These low-contrast vessels are particularly challenging to delineate accurately. One potential solution to this problem could be fine-tuning SAM 2 on a large-scale medical dataset, which might enhance its ability to handle low-contrast regions and capture the fine details necessary for accurate segmentation in these challenging scenarios."
        ]
    },
    "global_footnotes": []
}