{
    "id_table_1": {
        "caption": "Table 1 :  The testing results for DP3 on various tasks, trained with varying amounts of expert data.",
        "table": "S6.T1.6",
        "footnotes": [],
        "references": [
            "The experimental results, as summarized in Table  1 , demonstrate the performance of the 3D Diffusion Policy (DP3) across six tasks, each trained with varying quantities of expert demonstration data (10, 20, and 50 sets). Notably, for the \"Block Hammer Beat\" task, the success rate improved from 24% with 10 demonstrations to 80% with 50 demonstrations. The \"Empty Cup Place\" task saw success rates soar from 10% to 96% with increased demonstrations. The \"Dual-Bottles Pick\" task success rates climbed from 10% to 74% as demonstrations increased. The \"Block Sweep\" task success improved steadily from 28% to 86%, while the \"Apple Cabinet Storage\" task showed more modest gains, from 30% to 64%. The \"Block Handover\" task achieved the most significant improvement, reaching 98% success with 50 demonstrations, up from 50%. These results suggest a strong correlation between the number of expert demonstrations and task success, highlighting the effectiveness of the automatically generated expert data in enhancing task performance on the COBOT Magic platform. The data further underscores the importance of ample training examples in the development of robust strategies for complex tasks."
        ]
    },
    "id_table_2": {
        "caption": "Table 2 :  Detailed descriptions of 6 simulation tasks we propose.",
        "table": "Pt0.A1.T2.6",
        "footnotes": [],
        "references": [
            "To further research and development in this area, as shown in Fig.  4 , we introduce a comprehensive benchmark specifically designed to assess dual-arm robots in a variety of scenarios. This benchmark encompasses a diverse set of tasks, each presenting unique challenges that are critical for assessing the dexterity, coordination, and operational efficiency of robotic arms in a simulated environment. The tasks range from simple object manipulation to complex, coordinated actions requiring synchronized movements of both arms. Appendix  0.A.2  outlines the specific tasks and their descriptions, providing a clear framework for comparative analysis and further development of advanced robotic capabilities. For each task, we provide a robust API that supports the generation of expert data across infinitely variable scenarios, such as different object placements and environmental conditions. This feature allows researchers to extensively test and refine the adaptability and precision of robotic systems under controlled yet varied conditions. Additionally, an offline dataset is available for each task, offering pre-generated expert data to facilitate offline training and benchmarking of algorithms. This benchmark aims to bridge the gap between theoretical robotic control models and their practical implementation, ensuring that the robotic systems can perform reliably in dynamic, real-world environments."
        ]
    },
    "id_table_3": {
        "caption": "Table 3 :  Detailed descriptions of 17 real-world tasks we propose.",
        "table": "Pt0.A1.T3.6",
        "footnotes": [],
        "references": [
            "To synthesize high-fidelity data through simulation, a major challenge is the creation of accurate and cost-effective digital twins. Traditional methods often depend on costly high-precision sensors, which can hinder widespread adoption. In response, we have developed a more economical approach using Artificial Intelligence Generated Content (AIGC) to construct 3D models from simple 2D RGB images powered by Deemoss Rodin platform 1 1 1 We use Deemoss 3D digital assert Generation Model (from text or image) Rodin:  https://hyperhuman.deemos.com/rodin . This technique significantly reduces the reliance on expensive sensors while achieving realistic visual effects and supporting physical simulations. Our innovative pipeline commences with generating a detailed 3D mesh and texture of the target object involved in a robots task, created from a single real-world image. This capability ensures a high-fidelity recreation of real-world scenarios within a simulated environment. The process begins by transforming a single 2D image into a 3D model that encompasses detailed geometry, surface normals, wireframes, and textures. These features enhance the visual realism and ensure compatibility with physics engines for simulations. Once the 3D model is ready, we assign specific coordinate axes to functional parts of objects within the model. For instance, as shown in Fig.  3 , for a hammer, one axis is aligned with the hammerheadidentifying the functional partwhile another axis indicates the approach direction. This strategic alignment is crucial for automating the calculation of grasp poses, which are essential for robotic manipulation and tool usage. Grasp poses are computed perpendicular to the surface normal of the functional part along the designated approach direction axis, facilitating correct and efficient tool use with minimal manual intervention.",
            "Our dataset task design features two major highlights: a focus on human-robot interaction and tool usage. As shown in Appendix  0.A.3 , we have designed 17 tasks, 9 of which emphasize tool usage, 5 involve interpersonal interactions and 6 tasks are dual-arm. We collected 30 trajectories for each task. During trajectory collection, we broke down the tasks into multiple stages and conducted slower data collection for key sub-trajectories that required precise operations, enhancing the detail of the trajectories for better model learning."
        ]
    }
}