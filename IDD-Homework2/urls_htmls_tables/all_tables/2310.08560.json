{
    "id_table_1": {
        "caption": "Comparing context lengths of commonly used models and LLM APIs (data collected 1/2024).\n*Approximate message count assuming a preprompt of 1k tokens, and an average message size of50 tokens (250 characters). ‘Open’ means the model is open-source or open-weights (vs only available behind an API).",
        "table": [
            [
                "<td class=\"ltx_td ltx_border_tt\" id=\"S2.T1.9.5.6.1.1\">\n       </td>\n       \n",
                "<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"S2.T1.9.5.6.1.2\">\n       </th>\n       \n",
                "<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S2.T1.9.5.6.1.3\">\n        <span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.9.5.6.1.3.1\" style=\"font-size:90%;\">\n         Context Window\n        </span>\n       </th>\n      \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S2.T1.5.1.1.2\">\n        <span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.2.1\" style=\"font-size:90%;\">\n         Model / API name\n        </span>\n       </th>\n       \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S2.T1.5.1.1.3\">\n        <span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.3.1\" style=\"font-size:90%;\">\n         Open?\n        </span>\n       </th>\n       \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S2.T1.5.1.1.4\">\n        <span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.4.1\" style=\"font-size:90%;\">\n         Tokens\n        </span>\n       </th>\n       \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S2.T1.5.1.1.1\">\n        <sup class=\"ltx_sup\" id=\"S2.T1.5.1.1.1.1\">\n         <span class=\"ltx_text\" id=\"S2.T1.5.1.1.1.1.1\" style=\"font-size:90%;\">\n          ∗\n         </span>\n        </sup>\n        <span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.1.2\" style=\"font-size:90%;\">\n         Messages\n        </span>\n       </th>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.9.5.7.2.1\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.7.2.1.1\" style=\"font-size:90%;\">\n         Llama (1)\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S2.T1.9.5.7.2.2\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.7.2.2.1\" style=\"font-size:90%;color:#228B22;\">\n         ✓\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S2.T1.9.5.7.2.3\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.7.2.3.1\" style=\"font-size:90%;\">\n         2k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S2.T1.9.5.7.2.4\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.7.2.4.1\" style=\"font-size:90%;\">\n         20\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.9.5.8.3.1\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.8.3.1.1\" style=\"font-size:90%;\">\n         Llama 2\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.9.5.8.3.2\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.8.3.2.1\" style=\"font-size:90%;color:#228B22;\">\n         ✓\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.8.3.3\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.8.3.3.1\" style=\"font-size:90%;\">\n         4k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.8.3.4\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.8.3.4.1\" style=\"font-size:90%;\">\n         60\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.9.5.9.4.1\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.9.4.1.1\" style=\"font-size:90%;\">\n         GPT-3.5 Turbo (release)\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.9.5.9.4.2\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.9.4.2.1\" style=\"font-size:90%;color:#FF0000;\">\n         ✗\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.9.4.3\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.9.4.3.1\" style=\"font-size:90%;\">\n         4k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.9.4.4\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.9.4.4.1\" style=\"font-size:90%;\">\n         60\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.9.5.10.5.1\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.10.5.1.1\" style=\"font-size:90%;\">\n         Mistral 7B\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.9.5.10.5.2\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.10.5.2.1\" style=\"font-size:90%;color:#228B22;\">\n         ✓\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.10.5.3\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.10.5.3.1\" style=\"font-size:90%;\">\n         8k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.10.5.4\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.10.5.4.1\" style=\"font-size:90%;\">\n         140\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.9.5.11.6.1\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.11.6.1.1\" style=\"font-size:90%;\">\n         GPT-4 (release)\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.9.5.11.6.2\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.11.6.2.1\" style=\"font-size:90%;color:#FF0000;\">\n         ✗\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.11.6.3\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.11.6.3.1\" style=\"font-size:90%;\">\n         8k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.11.6.4\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.11.6.4.1\" style=\"font-size:90%;\">\n         140\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.9.5.12.7.1\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.12.7.1.1\" style=\"font-size:90%;\">\n         GPT-3.5 Turbo\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.9.5.12.7.2\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.12.7.2.1\" style=\"font-size:90%;color:#FF0000;\">\n         ✗\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.12.7.3\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.12.7.3.1\" style=\"font-size:90%;\">\n         16k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.12.7.4\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.12.7.4.1\" style=\"font-size:90%;\">\n         300\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.6.2.2.2\">\n        <span class=\"ltx_text\" id=\"S2.T1.6.2.2.2.1\" style=\"font-size:90%;\">\n         GPT-4\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.6.2.2.3\">\n        <span class=\"ltx_text\" id=\"S2.T1.6.2.2.3.1\" style=\"font-size:90%;color:#FF0000;\">\n         ✗\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.6.2.2.4\">\n        <span class=\"ltx_text\" id=\"S2.T1.6.2.2.4.1\" style=\"font-size:90%;\">\n         32k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.6.2.2.1\">\n        <span class=\"ltx_text\" id=\"S2.T1.6.2.2.1.1\" style=\"font-size:90%;position:relative; bottom:0.7pt;\">\n         <math alttext=\"\\scriptstyle\\mathtt{\\sim}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.6.2.2.1.1.1.m1.1\">\n          <semantics id=\"S2.T1.6.2.2.1.1.1.m1.1a\">\n           <mo id=\"S2.T1.6.2.2.1.1.1.m1.1.1\" mathsize=\"70%\" xref=\"S2.T1.6.2.2.1.1.1.m1.1.1.cmml\">\n            ∼\n           </mo>\n           <annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.6.2.2.1.1.1.m1.1b\">\n            <csymbol cd=\"latexml\" id=\"S2.T1.6.2.2.1.1.1.m1.1.1.cmml\" xref=\"S2.T1.6.2.2.1.1.1.m1.1.1\">\n             similar-to\n            </csymbol>\n           </annotation-xml>\n           <annotation encoding=\"application/x-tex\" id=\"S2.T1.6.2.2.1.1.1.m1.1c\">\n            \\scriptstyle\\mathtt{\\sim}\n           </annotation>\n          </semantics>\n         </math>\n        </span>\n        <span class=\"ltx_text\" id=\"S2.T1.6.2.2.1.2\" style=\"font-size:90%;\">\n         600\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.7.3.3.2\">\n        <span class=\"ltx_text\" id=\"S2.T1.7.3.3.2.1\" style=\"font-size:90%;\">\n         Claude 2\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.7.3.3.3\">\n        <span class=\"ltx_text\" id=\"S2.T1.7.3.3.3.1\" style=\"font-size:90%;color:#FF0000;\">\n         ✗\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.7.3.3.4\">\n        <span class=\"ltx_text\" id=\"S2.T1.7.3.3.4.1\" style=\"font-size:90%;\">\n         100k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.7.3.3.1\">\n        <span class=\"ltx_text\" id=\"S2.T1.7.3.3.1.1\" style=\"font-size:90%;position:relative; bottom:0.7pt;\">\n         <math alttext=\"\\scriptstyle\\mathtt{\\sim}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.7.3.3.1.1.1.m1.1\">\n          <semantics id=\"S2.T1.7.3.3.1.1.1.m1.1a\">\n           <mo id=\"S2.T1.7.3.3.1.1.1.m1.1.1\" mathsize=\"70%\" xref=\"S2.T1.7.3.3.1.1.1.m1.1.1.cmml\">\n            ∼\n           </mo>\n           <annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.7.3.3.1.1.1.m1.1b\">\n            <csymbol cd=\"latexml\" id=\"S2.T1.7.3.3.1.1.1.m1.1.1.cmml\" xref=\"S2.T1.7.3.3.1.1.1.m1.1.1\">\n             similar-to\n            </csymbol>\n           </annotation-xml>\n           <annotation encoding=\"application/x-tex\" id=\"S2.T1.7.3.3.1.1.1.m1.1c\">\n            \\scriptstyle\\mathtt{\\sim}\n           </annotation>\n          </semantics>\n         </math>\n        </span>\n        <span class=\"ltx_text\" id=\"S2.T1.7.3.3.1.2\" style=\"font-size:90%;\">\n         2000\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.8.4.4.2\">\n        <span class=\"ltx_text\" id=\"S2.T1.8.4.4.2.1\" style=\"font-size:90%;\">\n         GPT-4 Turbo\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.8.4.4.3\">\n        <span class=\"ltx_text\" id=\"S2.T1.8.4.4.3.1\" style=\"font-size:90%;color:#FF0000;\">\n         ✗\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.8.4.4.4\">\n        <span class=\"ltx_text\" id=\"S2.T1.8.4.4.4.1\" style=\"font-size:90%;\">\n         128k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.8.4.4.1\">\n        <span class=\"ltx_text\" id=\"S2.T1.8.4.4.1.1\" style=\"font-size:90%;position:relative; bottom:0.7pt;\">\n         <math alttext=\"\\scriptstyle\\mathtt{\\sim}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.8.4.4.1.1.1.m1.1\">\n          <semantics id=\"S2.T1.8.4.4.1.1.1.m1.1a\">\n           <mo id=\"S2.T1.8.4.4.1.1.1.m1.1.1\" mathsize=\"70%\" xref=\"S2.T1.8.4.4.1.1.1.m1.1.1.cmml\">\n            ∼\n           </mo>\n           <annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.8.4.4.1.1.1.m1.1b\">\n            <csymbol cd=\"latexml\" id=\"S2.T1.8.4.4.1.1.1.m1.1.1.cmml\" xref=\"S2.T1.8.4.4.1.1.1.m1.1.1\">\n             similar-to\n            </csymbol>\n           </annotation-xml>\n           <annotation encoding=\"application/x-tex\" id=\"S2.T1.8.4.4.1.1.1.m1.1c\">\n            \\scriptstyle\\mathtt{\\sim}\n           </annotation>\n          </semantics>\n         </math>\n        </span>\n        <span class=\"ltx_text\" id=\"S2.T1.8.4.4.1.2\" style=\"font-size:90%;\">\n         2600\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.9.5.5.2\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.5.2.1\" style=\"font-size:90%;\">\n         Yi-34B-200k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.9.5.5.3\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.5.3.1\" style=\"font-size:90%;color:#228B22;\">\n         ✓\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.5.4\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.5.4.1\" style=\"font-size:90%;\">\n         200k\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S2.T1.9.5.5.1\">\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.5.1.1\" style=\"font-size:90%;position:relative; bottom:0.7pt;\">\n         <math alttext=\"\\scriptstyle\\mathtt{\\sim}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.9.5.5.1.1.1.m1.1\">\n          <semantics id=\"S2.T1.9.5.5.1.1.1.m1.1a\">\n           <mo id=\"S2.T1.9.5.5.1.1.1.m1.1.1\" mathsize=\"70%\" xref=\"S2.T1.9.5.5.1.1.1.m1.1.1.cmml\">\n            ∼\n           </mo>\n           <annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.9.5.5.1.1.1.m1.1b\">\n            <csymbol cd=\"latexml\" id=\"S2.T1.9.5.5.1.1.1.m1.1.1.cmml\" xref=\"S2.T1.9.5.5.1.1.1.m1.1.1\">\n             similar-to\n            </csymbol>\n           </annotation-xml>\n           <annotation encoding=\"application/x-tex\" id=\"S2.T1.9.5.5.1.1.1.m1.1c\">\n            \\scriptstyle\\mathtt{\\sim}\n           </annotation>\n          </semantics>\n         </math>\n        </span>\n        <span class=\"ltx_text\" id=\"S2.T1.9.5.5.1.2\" style=\"font-size:90%;\">\n         4000\n        </span>\n       </td>\n      \n"
            ]
        ],
        "footnotes": [],
        "references": [
            "Document analysis also faces challenges due to the limited context windows of today’s transformer models. As shown in Table                  1                , both open and closed source models suffer from constrained context length (up to 128k tokens for OpenAI’s models). However many documents easily surpass these lengths; for example, legal or financial documents such as Annual Reports (SEC Form 10-K) can easily pass the million token mark. Moreover, many real document analysis tasks require drawing connections across multiple such lengthy documents. Anticipating these scenarios, it becomes difficult to envision blindly scaling up context as a solution to the fixed-context problem. Recent research           (Liu et al.,             2023a            )          also raises doubts about the utility of simply scaling contexts, since they find uneven attention distributions in large context models (the model is more capable of recalling information at the beginning or end of its context window, vs tokens in the middle). To enable reasoning across documents, more flexible memory architectures like MemGPT are needed."
        ]
    },
    "id_table_2": {
        "caption": "In this task, the agent is asked a specific question about a topic discussed in a prior conversation (sessions 1–5).\nThe agent’s response is scored against the gold answer.\nMemGPT significantly outperforms the fixed-context baselines.",
        "table": [
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T2.2.2.2.3\">\n        <span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.2.2.2.3.1\">\n         Model\n        </span>\n       </th>\n       \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.1.1.1.1\">\n        <span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.1\">\n         Accuracy\n        </span>\n        <math alttext=\"\\Uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.1.1.1.1.m1.1\">\n         <semantics id=\"S3.T2.1.1.1.1.m1.1a\">\n          <mo id=\"S3.T2.1.1.1.1.m1.1.1\" stretchy=\"false\" xref=\"S3.T2.1.1.1.1.m1.1.1.cmml\">\n           ⇑\n          </mo>\n          <annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.1.1.1.1.m1.1b\">\n           <ci id=\"S3.T2.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T2.1.1.1.1.m1.1.1\">\n            ⇑\n           </ci>\n          </annotation-xml>\n          <annotation encoding=\"application/x-tex\" id=\"S3.T2.1.1.1.1.m1.1c\">\n           \\Uparrow\n          </annotation>\n         </semantics>\n        </math>\n       </th>\n       \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.2.2.2.2\">\n        <span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.2.2.2.2.1\">\n         ROUGE-L (R)\n         <math alttext=\"\\Uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.2.2.2.2.1.m1.1\">\n          <semantics id=\"S3.T2.2.2.2.2.1.m1.1a\">\n           <mo id=\"S3.T2.2.2.2.2.1.m1.1.1\" stretchy=\"false\" xref=\"S3.T2.2.2.2.2.1.m1.1.1.cmml\">\n            ⇑\n           </mo>\n           <annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.2.2.2.2.1.m1.1b\">\n            <ci id=\"S3.T2.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T2.2.2.2.2.1.m1.1.1\">\n             ⇑\n            </ci>\n           </annotation-xml>\n           <annotation encoding=\"application/x-tex\" id=\"S3.T2.2.2.2.2.1.m1.1c\">\n            \\Uparrow\n           </annotation>\n          </semantics>\n         </math>\n        </span>\n       </th>\n      \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.5.5.6.1.1\">\n        GPT-3.5 Turbo\n       </th>\n       \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T2.5.5.6.1.2\">\n        38.7%\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T2.5.5.6.1.3\">\n        0.394\n       </td>\n      \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.3.3.3.1\">\n        <math alttext=\"+\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.3.3.3.1.m1.1\">\n         <semantics id=\"S3.T2.3.3.3.1.m1.1a\">\n          <mo id=\"S3.T2.3.3.3.1.m1.1.1\" xref=\"S3.T2.3.3.3.1.m1.1.1.cmml\">\n           +\n          </mo>\n          <annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.3.3.3.1.m1.1b\">\n           <plus id=\"S3.T2.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T2.3.3.3.1.m1.1.1\">\n           </plus>\n          </annotation-xml>\n          <annotation encoding=\"application/x-tex\" id=\"S3.T2.3.3.3.1.m1.1c\">\n           +\n          </annotation>\n         </semantics>\n        </math>\n        MemGPT\n       </th>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.3.3.3.2\">\n        66.9%\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.3.3.3.3\">\n        0.629\n       </td>\n      \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.5.5.7.2.1\">\n        GPT-4\n       </th>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.5.5.7.2.2\">\n        32.1%\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.5.5.7.2.3\">\n        0.296\n       </td>\n      \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.4.4.4.1\">\n        <math alttext=\"+\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.4.4.4.1.m1.1\">\n         <semantics id=\"S3.T2.4.4.4.1.m1.1a\">\n          <mo id=\"S3.T2.4.4.4.1.m1.1.1\" xref=\"S3.T2.4.4.4.1.m1.1.1.cmml\">\n           +\n          </mo>\n          <annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.4.4.4.1.m1.1b\">\n           <plus id=\"S3.T2.4.4.4.1.m1.1.1.cmml\" xref=\"S3.T2.4.4.4.1.m1.1.1\">\n           </plus>\n          </annotation-xml>\n          <annotation encoding=\"application/x-tex\" id=\"S3.T2.4.4.4.1.m1.1c\">\n           +\n          </annotation>\n         </semantics>\n        </math>\n        MemGPT\n       </th>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.4.4.4.2\">\n        92.5%\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.4.4.4.3\">\n        0.814\n       </td>\n      \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.5.5.8.3.1\">\n        GPT-4 Turbo\n       </th>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.5.5.8.3.2\">\n        35.3%\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T2.5.5.8.3.3\">\n        0.359\n       </td>\n      \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T2.5.5.5.1\">\n        <math alttext=\"+\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.5.5.5.1.m1.1\">\n         <semantics id=\"S3.T2.5.5.5.1.m1.1a\">\n          <mo id=\"S3.T2.5.5.5.1.m1.1.1\" xref=\"S3.T2.5.5.5.1.m1.1.1.cmml\">\n           +\n          </mo>\n          <annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.5.5.5.1.m1.1b\">\n           <plus id=\"S3.T2.5.5.5.1.m1.1.1.cmml\" xref=\"S3.T2.5.5.5.1.m1.1.1\">\n           </plus>\n          </annotation-xml>\n          <annotation encoding=\"application/x-tex\" id=\"S3.T2.5.5.5.1.m1.1c\">\n           +\n          </annotation>\n         </semantics>\n        </math>\n        <span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.5.5.5.1.1\">\n         MemGPT\n        </span>\n       </th>\n       \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T2.5.5.5.2\">\n        <span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.5.5.5.2.1\">\n         93.4%\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T2.5.5.5.3\">\n        <span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.5.5.5.3.1\">\n         0.827\n        </span>\n       </td>\n      \n"
            ]
        ],
        "footnotes": [],
        "references": [
            "MemGPT utilizes memory to maintain coherence:            Table                     2                   shows the performance of MemGPT vs the fixed-memory baselines.We compare MemGPT using different underlying LLMs, and compare against using the base LLM without MemGPT as a baseline.The baselines are able to see a lossy summarization of the past five conversations to mimic an extended recursive summarization procedure, while MemGPT instead has access to the full conversation history but must access it via paginated search queries to recall memory (in order to bring them into main context).In this task, we see that MemGPT clearly improves the performance of the underlying base LLM: there is a clear drop in both accuracy and ROUGE scores when going from MemGPT to the corresponding LLM baselines."
        ]
    },
    "id_table_3": {
        "caption": "The agent’s conversation opener is evaluated using similarity scores to the gold persona labels (SIM-1/3) and to the human-created opener (SIM-H).\nMemGPT is able to exceed the performance of the human-created conversation opener with a variety of underlying models.",
        "table": [
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T3.1.1.1.2\">\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.2.1\">\n          Method\n         </span>\n        </th>\n        \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.1\">\n         <math alttext=\"\\Uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.1.1.1.1.m1.1\">\n          <semantics id=\"S3.T3.1.1.1.1.m1.1a\">\n           <mo id=\"S3.T3.1.1.1.1.m1.1.1\" stretchy=\"false\" xref=\"S3.T3.1.1.1.1.m1.1.1.cmml\">\n            ⇑\n           </mo>\n           <annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.1.1.1.1.m1.1b\">\n            <ci id=\"S3.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T3.1.1.1.1.m1.1.1\">\n             ⇑\n            </ci>\n           </annotation-xml>\n           <annotation encoding=\"application/x-tex\" id=\"S3.T3.1.1.1.1.m1.1c\">\n            \\Uparrow\n           </annotation>\n          </semantics>\n         </math>\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.1.1\">\n          SIM-1\n         </span>\n        </th>\n        \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.3\">\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.3.1\">\n          SIM-3\n         </span>\n        </th>\n        \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.4\">\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.4.1\">\n          SIM-H\n         </span>\n        </th>\n       \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S3.T3.1.1.2.1.1\">\n         Human\n        </th>\n        \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.1.1.2.1.2\">\n         0.800\n        </th>\n        \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.1.1.2.1.3\">\n         0.800\n        </th>\n        \n",
                "<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.1.1.2.1.4\">\n         1.000\n        </th>\n       \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T3.1.1.3.1.1\">\n         GPT-3.5 Turbo\n        </th>\n        \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T3.1.1.3.1.2\">\n         0.830\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T3.1.1.3.1.3\">\n         0.812\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S3.T3.1.1.3.1.4\">\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.3.1.4.1\">\n          0.817\n         </span>\n        </td>\n       \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.1.1.4.2.1\">\n         GPT-4\n        </th>\n        \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T3.1.1.4.2.2\">\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.4.2.2.1\">\n          0.868\n         </span>\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T3.1.1.4.2.3\">\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.4.2.3.1\">\n          0.843\n         </span>\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_right\" id=\"S3.T3.1.1.4.2.4\">\n         0.773\n        </td>\n       \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T3.1.1.5.3.1\">\n         GPT-4 Turbo\n        </th>\n        \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T3.1.1.5.3.2\">\n         0.857\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T3.1.1.5.3.3\">\n         0.828\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S3.T3.1.1.5.3.4\">\n         0.767\n        </td>\n       \n"
            ]
        ],
        "footnotes": [],
        "references": [
            "In the ‘conversation opener’ task we evaluate an agent’s ability to craft engaging messages to the user that draw from knowledge accumulated in prior conversations.To evaluate the ‘engagingness’ of a conversation opener using the MSC dataset, we compare the generated opener to the gold personas: an engaging conversation opener should draw from one (or several) of the data points contained in the persona, which in MSC effectively summarize the knowledge accumulated throughout all prior sessions.We also compare to the human-generated gold opener, i.e., the first response in the following session.We report the CSIM scores of MemGPT’s openers in Table                     3                   .We test several variations of MemGPT using different base LLMs.",
            "MemGPT utilizes memory to increase engagement:            As seen in Table                     3                   , MemGPT is able to craft engaging openers that perform similarly to and occasionally exceed the hand-written human openers.We observe that MemGPT tends to craft openers that are both more verbose and cover more aspects of the persona information than the human baseline.Additionally, we can see the storing information in working context is key to generating engaging openers."
        ]
    }
}