{
    "PAPER'S NUMBER OF TABLES": 1,
    "S3.tab1": {
        "caption": "Table 1: Components of the federated learning reference architecture",
        "table": "<table id=\"S3.tab1.5\" class=\"ltx_tabular ltx_figure_panel ltx_align_middle\">\n<tr id=\"S3.tab1.5.1\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.1.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.1.1.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.1.1.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">\n<span id=\"S3.tab1.5.1.1.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S3.tab1.5.1.1.1.1.2.1.1\" class=\"ltx_tr\">\n<span id=\"S3.tab1.5.1.1.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">Stages</span></span>\n</span></span><span id=\"S3.tab1.5.1.1.1.1.3\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.1.1.1.1.4\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\"></span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.1.2.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.1.2.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.1.2.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">\n<span id=\"S3.tab1.5.1.2.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S3.tab1.5.1.2.1.1.2.1.1\" class=\"ltx_tr\">\n<span id=\"S3.tab1.5.1.2.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">Types</span></span>\n</span></span><span id=\"S3.tab1.5.1.2.1.1.3\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.1.2.1.1.4\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\"></span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.1.3.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.1.3.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.1.3.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">\n<span id=\"S3.tab1.5.1.3.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S3.tab1.5.1.3.1.1.2.1.1\" class=\"ltx_tr\">\n<span id=\"S3.tab1.5.1.3.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">Components</span></span>\n</span></span><span id=\"S3.tab1.5.1.3.1.1.3\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.1.3.1.1.4\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\"></span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.1.4.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.1.4.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.1.4.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">\n<span id=\"S3.tab1.5.1.4.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S3.tab1.5.1.4.1.1.2.1.1\" class=\"ltx_tr\">\n<span id=\"S3.tab1.5.1.4.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">Responsibility</span></span>\n</span></span><span id=\"S3.tab1.5.1.4.1.1.3\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.1.4.1.1.4\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\"></span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.2\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" rowspan=\"4\">\n<span id=\"S3.tab1.5.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.2.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">\nJob creation</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.2.2.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Mandatory</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.2.3.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Job creator</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.2.4.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.2.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Initialises training job and global model</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.3\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" rowspan=\"3\">\n<span id=\"S3.tab1.5.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.3.1.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Optional</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.3.2.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.3.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Client registry</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.3.3.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Improves system’s </span><span id=\"S3.tab1.5.3.3.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">maintainability</span><span id=\"S3.tab1.5.3.3.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> and </span><span id=\"S3.tab1.5.3.3.1.1.4\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">reliability</span><span id=\"S3.tab1.5.3.3.1.1.5\" class=\"ltx_text\" style=\"font-size:70%;\"> by maintaining client’s information</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.4.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.4.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Client cluster</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.4.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.4.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Tackles </span><span id=\"S3.tab1.5.4.2.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">statistical heterogeneity</span><span id=\"S3.tab1.5.4.2.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> &amp; </span><span id=\"S3.tab1.5.4.2.1.1.4\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">system heterogeneity</span><span id=\"S3.tab1.5.4.2.1.1.5\" class=\"ltx_text\" style=\"font-size:70%;\"> by grouping clients with similar data distribution or resources before aggregation</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.5.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.5.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.5.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Client selector</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.5.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.5.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.5.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Improves </span><span id=\"S3.tab1.5.5.2.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">model &amp; system’s performance</span><span id=\"S3.tab1.5.5.2.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> by selecting high performance client devices</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.6\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.6.1\" class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt\" rowspan=\"3\">\n<span id=\"S3.tab1.5.6.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.6.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.6.1.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.6.1.1.1.2\" class=\"ltx_text\" style=\"font-size:70%;\">\nData\ncollection\n&amp;\npreprocessing</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.6.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" rowspan=\"2\">\n<span id=\"S3.tab1.5.6.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.6.2.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.6.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Mandatory</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.6.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.6.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.6.3.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.6.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Data collector</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.6.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.6.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.6.4.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.6.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Collects raw data through sensors or smart devices deployed</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.7\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.7.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.7.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.7.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.7.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Data preprocessor</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.7.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.7.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.7.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.7.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Preprocesses raw data</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.8\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.8.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.8.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.8.1.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.8.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Optional</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.8.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.8.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.8.2.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.8.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Heterogeneous Data Handler</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.8.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.8.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.8.3.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.8.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Tackles </span><span id=\"S3.tab1.5.8.3.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">statistical heterogeneity</span><span id=\"S3.tab1.5.8.3.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> through data augmentation methods</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.9\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.9.1\" class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt\" rowspan=\"10\">\n<span id=\"S3.tab1.5.9.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.9.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.9.1.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.9.1.1.1.2\" class=\"ltx_text\" style=\"font-size:70%;\">\nModel\ntraining</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.9.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" rowspan=\"3\">\n<span id=\"S3.tab1.5.9.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.9.2.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.9.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Mandatory</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.9.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.9.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.9.3.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.9.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Model trainer</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.9.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.9.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.9.4.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.9.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Trains local model</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.10\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.10.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.10.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.10.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.10.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Local model evaluator</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.10.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.10.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.10.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.10.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Evaluates local model performance after each local training round</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.11\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.11.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.11.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.11.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.11.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Model aggregator</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.11.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.11.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.11.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.11.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Aggregates local models to produce new global model</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.12\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.12.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" rowspan=\"7\">\n<span id=\"S3.tab1.5.12.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.12.1.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.12.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Optional</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.12.2\" class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.12.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.12.2.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.12.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Multi-task</span><span id=\"S3.tab1.5.12.2.1.1.2\" class=\"ltx_text\" style=\"font-size:70%;\">\nmodel trainer</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.12.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.12.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.12.3.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.12.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Improves </span><span id=\"S3.tab1.5.12.3.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">model performance</span><span id=\"S3.tab1.5.12.3.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> (personalisation) by adopting multi-task training methods</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.13\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.13.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.13.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.13.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.13.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Message compressor</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.13.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.13.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.13.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.13.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Improves </span><span id=\"S3.tab1.5.13.2.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">communication efficiency</span><span id=\"S3.tab1.5.13.2.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> through message size reduction to reduce bandwidth consumption</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.14\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.14.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.14.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.14.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.14.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Secure aggregator</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.14.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.14.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.14.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.14.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Improves </span><span id=\"S3.tab1.5.14.2.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">data privacy</span><span id=\"S3.tab1.5.14.2.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> &amp; </span><span id=\"S3.tab1.5.14.2.1.1.4\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">system security</span><span id=\"S3.tab1.5.14.2.1.1.5\" class=\"ltx_text\" style=\"font-size:70%;\"> through different secure multiparty computation protocols</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.15\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.15.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.15.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.15.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.15.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Asynchronous aggregator</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.15.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.15.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.15.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.15.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Improves </span><span id=\"S3.tab1.5.15.2.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">system performance</span><span id=\"S3.tab1.5.15.2.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> by reducing aggregation pending time of late client updates</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.16\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.16.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.16.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.16.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.16.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Decentralised aggregator</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.16.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.16.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.16.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.16.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Improves system </span><span id=\"S3.tab1.5.16.2.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">reliability</span><span id=\"S3.tab1.5.16.2.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> through the removal of single-point-of-failure</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.17\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.17.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.17.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.17.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.17.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Hierarchical aggregator</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.17.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.17.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.17.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.17.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Improves </span><span id=\"S3.tab1.5.17.2.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">system performance</span><span id=\"S3.tab1.5.17.2.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> &amp; tackle </span><span id=\"S3.tab1.5.17.2.1.1.4\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">statistical heterogeneity</span><span id=\"S3.tab1.5.17.2.1.1.5\" class=\"ltx_text\" style=\"font-size:70%;\"> &amp; </span><span id=\"S3.tab1.5.17.2.1.1.6\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">system heterogeneity</span><span id=\"S3.tab1.5.17.2.1.1.7\" class=\"ltx_text\" style=\"font-size:70%;\"> by aggregating models from similar clients before global aggregation</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.18\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.18.1\" class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.18.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.18.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.18.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Model co-versioning</span><span id=\"S3.tab1.5.18.1.1.1.2\" class=\"ltx_text\" style=\"font-size:70%;\">\nregistry</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.18.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.18.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.18.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.18.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Improves system’s </span><span id=\"S3.tab1.5.18.2.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">accountability</span><span id=\"S3.tab1.5.18.2.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> by recording the local models associated to each global models to track clients’ performances</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.19\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.19.1\" class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt\" rowspan=\"4\">\n<span id=\"S3.tab1.5.19.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.19.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.19.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Model</span><span id=\"S3.tab1.5.19.1.1.1.2\" class=\"ltx_text\" style=\"font-size:70%;\">\ndeployment</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.19.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" rowspan=\"2\">\n<span id=\"S3.tab1.5.19.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.19.2.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.19.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Mandatory</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.19.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.19.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.19.3.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.19.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Model deployer</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.19.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.19.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.19.4.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.19.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Deploys completely-trained-models</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.20\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.20.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.20.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.20.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.20.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Decision maker</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.20.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.20.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.20.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.20.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Decides model deployment</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.21\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.21.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" rowspan=\"2\">\n<span id=\"S3.tab1.5.21.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.21.1.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.21.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Optional</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.21.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.21.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.21.2.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.21.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Deployment selector</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.21.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.21.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.21.3.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.21.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Improves </span><span id=\"S3.tab1.5.21.3.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">model performance</span><span id=\"S3.tab1.5.21.3.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> (personalisation) through suitable model users selection according to data or applications</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.22\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.22.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.22.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.22.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.22.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Incentive registry</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.22.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.tab1.5.22.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.22.2.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.22.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Increases clients’ </span><span id=\"S3.tab1.5.22.2.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">motivatability</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.23\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.23.1\" class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb ltx_border_tt\" rowspan=\"2\">\n<span id=\"S3.tab1.5.23.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.23.1.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.23.1.1.1.1\" class=\"ltx_text\"></span><span id=\"S3.tab1.5.23.1.1.1.2\" class=\"ltx_text\" style=\"font-size:70%;\">\nModel\nmonitoring</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.23.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.23.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.23.2.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.23.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Mandatory</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.23.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.23.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.23.3.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.23.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Model monitor</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.23.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.tab1.5.23.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.23.4.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.23.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Monitors model’s data inference performance</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.tab1.5.24\" class=\"ltx_tr\">\n<td id=\"S3.tab1.5.24.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\">\n<span id=\"S3.tab1.5.24.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.24.1.1.1\" class=\"ltx_p\" style=\"width:65.0pt;\"><span id=\"S3.tab1.5.24.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Optional</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.24.2\" class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\">\n<span id=\"S3.tab1.5.24.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.24.2.1.1\" class=\"ltx_p\" style=\"width:86.7pt;\"><span id=\"S3.tab1.5.24.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Model replacement</span><span id=\"S3.tab1.5.24.2.1.1.2\" class=\"ltx_text\" style=\"font-size:70%;\">\ntrigger</span></span>\n</span>\n</td>\n<td id=\"S3.tab1.5.24.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\">\n<span id=\"S3.tab1.5.24.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.tab1.5.24.3.1.1\" class=\"ltx_p\" style=\"width:195.1pt;\"><span id=\"S3.tab1.5.24.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Maintains </span><span id=\"S3.tab1.5.24.3.1.1.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">system &amp; model performance</span><span id=\"S3.tab1.5.24.3.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> by replacing outdated models due to performance degrades</span></span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "The federated learning process starts with the creation of a model training job (including initial model and training configurations) via job creator on the central server. Within the job creator component, three optional components could be considered are: client registry, client cluster, client selector. In a federated learning system, client devices may be owned by different parties, constantly connect and drop out from the system. Hence, it is challenging to keep track of all the participating client devices including dropout devices and dishonest devices. This is different from distributed or centralised machine learning systems in which both clients and the server are typically owned and managed by a single party [27]. A client registry is required to maintain all the information of the client devices that are registered, (e.g., ID, resource information, number of participating rounds, local model performance, etc.) Both IBM Federated Learning Framework101010https://github.com/IBM/federated-learning-lib and doc.ai111111https://doc.ai/ adopted client registry in their design to improve maintainability and reliability of the system since the system can manage the devices effectively and quickly identify the problematic ones via the client registry component. FedML which is a federated learning benchmarking and simulation framework has also explicitly covered the client manager module in their framework that serves the same purpose as the client registry. However, the system may sacrifice client data privacy due to the recording of the device information on the central server.The non-IID121212Non-Identically and Independently Distribution: Highly-skewed and personalised data distribution that vary heavily between different clients and affects the model performance and generalisation [33]. data characteristics of local raw data and the data-sharing restriction translates to model performance challenge [18, 28, 42, 21]. When the data from client devices are non-IID, the global models aggregated is less generalised to the entire data. To improve the generalisation of the global model and speed up model convergence, a client cluster component can be added to cluster the client devices into groups according to their data distribution, gradient loss, and feature similarities. This design has been used in Google’s IFCA algorithm131313https://github.com/felisat/clustered-federated-learning, TiFL system[8], and Massachusetts General Hospital’s patient system[13]. The side effect of client cluster is the extra computation cost caused by client relationship quantification.The central servers interacts with a massive number of client devices that are both system heterogeneous and statistically heterogeneous. The magnitude of client devices number is also several times larger than that of the distributed machine learning systems [18, 24]. To increase the model and system performance, client devices can be selected every round with predefined criteria (e.g., resource, data, or performance) via client selector component. This has been integrated into Google’s FedAvg [28] algorithm and IBM’s Helios [39].Each client device gathers data using different sensors through the data collector component and process the data (i.e., feature extraction, data cleaning, labeling, augmentation, etc.) locally through the data preprocessor component, due to the data-sharing constraint. This is different from centralised or distributed machine learning systems in which the non-IID data characteristic is negligible since the data collected on client devices are usually shuffled and processed on the central server. Thus, within the data preprocessor, an optional component heterogeneous data handler is adopted to deal with the non-IID and skewed data distribution issue through data augmentation techniques. The known uses of the component include Astraea141414https://github.com/mtang724/Self-Balancing-Federated-Learning, FAug scheme [14] and Federated Distillation (FD) method [2].Once the client receives the job from the central server, the model trainer component performs model training based on configured hyperparameters (number of epochs, learning rate, etc.). In the standard federated learning training process proposed by McMahan in [28], only model parameters (i.e., weight/gradient) are mentioned to be sent from the central server, whereas in this reference architecture, the models include not only the model parameters but also the hyperparameters. For multi-task machine learning scenarios, a multi-task model trainer component can be chosen to train task-related models to improve model performance and learning efficiency. Multitask Learning is a machine learning approach to transfer and share knowledge through training of individual models. It improves model generalisation by using the domain information contained in the parameters of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better [7]. In federated learning scenarios, this technique is particularly relevant when faced with non-IID data which can produce personalised model that may outperform the best possible shared global model [18]. This best practice solution is identified based on Google’s MultiModel151515https://ai.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html architecture, and Microsoft’s MT-DNN161616https://github.com/microsoft/MT-DNN.The local model evaluator component measures the performance of the local model and uploads the model to the model aggregator on the central server if the performance requirement is met. In distributed machine learning systems, the performance evaluation on client devices is not conducted locally, and only the aggregated server model is evaluated. However, for federated learning systems, local model performance evaluation is required for system operations such as client selection, model co-versioning, contributions calculation, incentive provision, client clustering, etc.The trained local model parameters or gradients are uploaded to the central server for model aggregation. Unlike centralised machine learning systems that performs model training in a central server or distributed machine learning systems that deals with fairly small amount of client nodes, the cost for transmitting model parameters or gradients between the bandwidth-limited client devices and central server is high when the system scales up [18, 24]. A message compressor component can be added to improve communication efficiency. The embedded pattern are extracted from Google Sketched Update [20], and IBM PruneFL [16].The model aggregator formulates the new global model based on the received local models. There are four types of aggregator-related optional components within the model aggregator component: secure aggregator, asynchronous aggregator, decentralised aggregator, and hierarchical aggregator. A secure aggregator component prevents adversarial parties from accessing the models during model exchanges through multiparty computation protocols, such as differential privacy or cryptographic techniques. These techniques provide security proof to guarantee that each party knows only its input and output. For centralised and distributed machine learning settings that practice centralised system orchestration, communication security between clients and server is not the main concern. In contrast, for federated learning settings, this best practices are used in SecAgg [6], HybridAlpha  [38], and TensorFlow Privacy Library171717https://github.com/tensorflow/privacy/. Asynchronous aggregator is identified from ASO-fed [9], AFSGD-VP [12], and FedAsync [37]. The asynchronous aggregator component enables the global model aggregation to be conducted asynchronously whenever a local model update arrives. Similar technique have been adopted in distributed machine learning approaches such as iHadoop [10] and it is proven that this can effectively reduce the overall training time. The conventional design of a federated learning system that relies on a central server to orchestrate the learning process might lead to a single point of failure. A decentralise aggregator performs model exchanges and aggregation in decentralised manner to improve system reliability. The known uses of decentralised aggregator include BrainTorrent [31] and FedPGA [15]. Blockchain can be employed as a decentralised solution for federated learning systems. In distributed machine learning systems, p2p network topology is employed to in MapReduce [27] to resolve the single-point-of-failure threat on parameter servers. A hierarchical aggregator component can be selected to improve system efficiency by adding an intermediate edge layer to aggregate the model updates from related client devices partially before performing the final global aggregation. This pattern has been adopted by HierFAVG [22], Astraea, and HFL [1].In addition to aggregator-related optional components, a model co-versioning registry component can be embedded within the model aggregator component to map all the local models and their corresponding global models. This enables the model provernance and improves system accountability. The model co-versioning registry pattern is summarised and adopted from the version control methods in DVC181818https://dvc.org, Replicate.ai191919https://replicate.ai, and Pachyderm202020https://www.pachyderm.com.After the aggregation, the global model evaluator assesses the performance of the global model. One example is TensorFlow Extended (TFX)212121https://www.tensorflow.org/tfx that provides a model validator function to assess the federated learning model performance. If the global model performs well, the model deployer component deploys the global model to the client device for decision-making through the decision-maker component. For instance, TensorFlow lite222222https://www.tensorflow.org/lite prepares the final validated model for deployment to the client devices for data inference. Within the model deployer component, there are two optional components for selection: deployment selector and incentive registry. The deployment selector component examines the client devices and selects clients to receive the global model based on their data characteristics or applications. The deployment selector pattern has been applied in Azure Machine Learning232323https://docs.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment, Amazon SageMaker242424https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html, and Google Cloud252525https://cloud.google.com/ai-platform/prediction/docs/deploying-models to improve model performance. The incentive registry component maintains all the client devices’ incentives based on their contributions and agreed rates to motivate clients to contribute to the training. Blockchain has been leveraged in FLChain [3] and DeepChain [36] to build a incentive registry.After the deployment of models for the actual data inference, a model monitor keeps track of the model performance continuously. If the performance degrades below a predefined threshold value, the model replacement trigger component notifies the model trainer for local fine-tuning or sends an alert to the job creator for a new model generation. The model replacement trigger pattern is identified based on the known uses including Microsoft Azure Machine Learning Designer262626https://azure.microsoft.com/en-au/services/machine-learning/designer, Amazon SageMaker272727https://aws.amazon.com/sagemaker, Alibaba Machine Learning Platform282828https://www.alibabacloud.com/product/machine-learning.The most widely mentioned definition of a reference architecture is defined by Bass et al. [4] as “a reference model mapped onto software elements (that cooperatively implement the functionality defined in the reference model) and the data flow between them. Whereas a reference model divides the functionality, a reference architecture is the mapping of that functionality onto a system decomposition.” Nakagawa et al. collected a series of definitions of reference architectures by various researchers and summarised them as follows: “the reference architecture encompasses the knowledge about how to design system architectures of a given application domain. It must address the business rules, architectural styles (sometimes also defined as architectural patterns that address quality attributes in the reference architecture), best practices of software development (architectural decisions, domain constraints, legislation, and standards), and the software elements that support the development of systems for that domain [29].”Reference architectures for machine learning applications and big data analysis were researched comprehensively. For instance, Pääkkönen and Pakkala proposed a reference architecture of big data systems for machine learning in an edge computing environment [30]. IBM AI Infrastructure Reference Architecture is proposed to be used as a reference by data scientists and IT professionals who are defining, deploying, and integrating AI solutions into an organization [26].Reference architectures for edge computing systems are also widely studied. For example, H2020 FAR-Edge-project, Edge Computing Reference Architecture 2.0, Intel-SAP Reference Architecture, IBM Edge computing reference architecture, and Industrial Internet Reference Architecture (IIRA) are proposed by practitioners to support the development of multi-tenant edge systems.There are existing works proposed to support federated learning system and architecture design. For instance, Google was the earliest to introduce a system design approach for federated learning [5]. A scalable production system for federated learning in the domain of mobile devices, based on TensorFlow described from a high-level perspective. A collection of architectural patterns for the design of federated learning systems are summarised and presented by [25]. There are also many architectures and adoptions of federated learning systems proposed by researchers for diverse applications. For instance, Zhang et al. [40] proposed a blockchain-based federated learning architecture for industrial IoT to improve client motivatability through an incentive mechanism. Samarakoon et al. [32] have adopted federated learning to improve reliability and communication latency for vehicle-to-vehicle networks. Another real-world federated learning adoption by Zhang et al. [41] is a dynamic fusion-based federated learning approach for medical diagnostic image analysis to detect COVID-19 infections. We observed that there have been multiple studies on federated learning from different aspects and their design methods are highly diverse and isolated which makes their proposals challenging to be reproduced.Motivated by the previous works mentioned above, we intend to fill the research gap by putting forward an end-to-end reference architecture for federated learning systems development and deployment which has been distinctly lacking in the current state-of-the-art.A reference architecture can be served as a standard guideline for system designers and developers for quick selection of best practice solutions for their problems, which can be further customised as required. To the best of our knowledge, there is still no reference architecture proposed for an end-to-end federated learning system while many reusable components and patterns have been proposed. Thus, in this paper, we proposed FLRA, a pattern-oriented reference architecture for federated learning system design to increase the real-world adoption of federated learning.To design the reference architecture, we developed an empirically-grounded qualitative analysis method as the basis of design theory generation. The empirical evidence to support the reference architecture design is a collection of findings (requirements, patterns, and components) gathered and defined by our previous systematic literature review on federated learning and well-known industry practices of machine learning systems.After developing the reference architecture, we compared it with existing machine learning architectures of Google, Amazon, Microsoft, and IBM to examine its applicability. The key differences between centralised or distributed machine learning with federated learning are the non-IIDness of training data, variation in the data partitioning (e.g., vertical, horizontal, and transfer federated learning) and device partitioning (e.g., cross-device, cross-silo), the ownership and security requirements of different client devices, the system heterogeneity, and the participation of client nodes. The proposed FLRA architecture adopted many reusable machine learning and federated learning patterns while maintaining most of the mandatory machine learning pipeline components. This ensures that the reference architecture is generalised to support the basic model training tasks in the real world.While there are different constraints when developing a federated learning system for different applications and settings, the possible trade-offs and the pattern solutions to these challenges are discussed comprehensively. The confirmation of theory justified the applicability of FLRA and the patterns associated with the support of empirical evidence collected. Hence, the FLRA proposed is applicable in the real world for a general, end-to-end development of federated learning systems. Our future work will focus on developing an architecture decision model for federated learning system design. We will also work on the architecture design for trust in federated learning systems.",
        "references": [
            [
                "In this section, we present FLRA, a pattern-oriented reference architecture for federated learning systems. Fig. ",
                "3",
                " illustrates the overall reference architecture. A base version of a federated learning system consists of two main participants: (1) central server and (2) client devices. A central server initialises a machine learning job and coordinates the federated training process, whereas client devices perform model training using local data and computation resources.",
                "Underneath the two participants, there are two types of components: (1) Mandatory components and (2) optional components. The mandatory components provide the basic functions required by a federated machine learning pipeline.\nTo fulfill the different software quality requirements and design constraints in federated learning systems, we collected and defined a set of patterns based on our SLR results and the mining of some existing federated learning simulation frameworks. Each pattern is embedded as optional components to facilitate the architecture design.",
                "We summarised all the mandatory and optional components of the reference architecture and briefly highlighted the functionalities and responsibility of each component in Table ",
                "3",
                ". The table presents the details of each component associated with the federated learning pipeline stages."
            ]
        ]
    }
}