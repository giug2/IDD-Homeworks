{
    "PAPER'S NUMBER OF TABLES": 3,
    "S5.T1": {
        "caption": "Table 1: Datasets and models",
        "table": "<table id=\"S5.T1.st1.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.st1.6.7.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.st1.6.7.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Dataset</span></th>\n<th id=\"S5.T1.st1.6.7.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">Model</span></th>\n<th id=\"S5.T1.st1.6.7.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.3.1\" class=\"ltx_text\" style=\"font-size:50%;\"># Clients</span></th>\n<th id=\"S5.T1.st1.6.7.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.4.1\" class=\"ltx_text\" style=\"font-size:50%;\"># Samples</span></th>\n<th id=\"S5.T1.st1.6.7.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Task</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.st1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">CIFAR10</span></td>\n<td id=\"S5.T1.st1.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">ResNet18</span></td>\n<td id=\"S5.T1.st1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"100\" display=\"inline\"><semantics id=\"S5.T1.st1.1.1.1.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st1.1.1.1.m1.1.1\" xref=\"S5.T1.st1.1.1.1.m1.1.1.cmml\">100</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.1.1.1.m1.1b\"><cn type=\"integer\" id=\"S5.T1.st1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.st1.1.1.1.m1.1.1\">100</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.1.1.1.m1.1c\">100</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.2.2.2.m1.2\" class=\"ltx_Math\" alttext=\"50,000\" display=\"inline\"><semantics id=\"S5.T1.st1.2.2.2.m1.2a\"><mrow id=\"S5.T1.st1.2.2.2.m1.2.3.2\" xref=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.1.1\" xref=\"S5.T1.st1.2.2.2.m1.1.1.cmml\">50</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.2.3.2.1\" xref=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.2.2\" xref=\"S5.T1.st1.2.2.2.m1.2.2.cmml\">000</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.2.2.2.m1.2b\"><list id=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.2.2.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.2.2.2.m1.1.1.cmml\" xref=\"S5.T1.st1.2.2.2.m1.1.1\">50</cn><cn type=\"integer\" id=\"S5.T1.st1.2.2.2.m1.2.2.cmml\" xref=\"S5.T1.st1.2.2.2.m1.2.2\">000</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.2.2.2.m1.2c\">50,000</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Image classification</span></td>\n</tr>\n<tr id=\"S5.T1.st1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.4.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">FEMNIST</span></td>\n<td id=\"S5.T1.st1.4.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">CNN</span></td>\n<td id=\"S5.T1.st1.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.3.3.1.m1.2\" class=\"ltx_Math\" alttext=\"3,400\" display=\"inline\"><semantics id=\"S5.T1.st1.3.3.1.m1.2a\"><mrow id=\"S5.T1.st1.3.3.1.m1.2.3.2\" xref=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.1.1\" xref=\"S5.T1.st1.3.3.1.m1.1.1.cmml\">3</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.2.3.2.1\" xref=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.2.2\" xref=\"S5.T1.st1.3.3.1.m1.2.2.cmml\">400</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.3.3.1.m1.2b\"><list id=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\" xref=\"S5.T1.st1.3.3.1.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.3.3.1.m1.1.1.cmml\" xref=\"S5.T1.st1.3.3.1.m1.1.1\">3</cn><cn type=\"integer\" id=\"S5.T1.st1.3.3.1.m1.2.2.cmml\" xref=\"S5.T1.st1.3.3.1.m1.2.2\">400</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.3.3.1.m1.2c\">3,400</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.4.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.4.4.2.m1.2\" class=\"ltx_Math\" alttext=\"671,585\" display=\"inline\"><semantics id=\"S5.T1.st1.4.4.2.m1.2a\"><mrow id=\"S5.T1.st1.4.4.2.m1.2.3.2\" xref=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.1.1\" xref=\"S5.T1.st1.4.4.2.m1.1.1.cmml\">671</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.2.3.2.1\" xref=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.2.2\" xref=\"S5.T1.st1.4.4.2.m1.2.2.cmml\">585</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.4.4.2.m1.2b\"><list id=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.4.4.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.4.4.2.m1.1.1.cmml\" xref=\"S5.T1.st1.4.4.2.m1.1.1\">671</cn><cn type=\"integer\" id=\"S5.T1.st1.4.4.2.m1.2.2.cmml\" xref=\"S5.T1.st1.4.4.2.m1.2.2\">585</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.4.4.2.m1.2c\">671,585</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.4.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Image classification</span></td>\n</tr>\n<tr id=\"S5.T1.st1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.6.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">Shakespeare</span></td>\n<td id=\"S5.T1.st1.6.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">RNN</span></td>\n<td id=\"S5.T1.st1.5.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"715\" display=\"inline\"><semantics id=\"S5.T1.st1.5.5.1.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st1.5.5.1.m1.1.1\" xref=\"S5.T1.st1.5.5.1.m1.1.1.cmml\">715</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.5.5.1.m1.1b\"><cn type=\"integer\" id=\"S5.T1.st1.5.5.1.m1.1.1.cmml\" xref=\"S5.T1.st1.5.5.1.m1.1.1\">715</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.5.5.1.m1.1c\">715</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.6.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.6.6.2.m1.2\" class=\"ltx_Math\" alttext=\"38,001\" display=\"inline\"><semantics id=\"S5.T1.st1.6.6.2.m1.2a\"><mrow id=\"S5.T1.st1.6.6.2.m1.2.3.2\" xref=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.1.1\" xref=\"S5.T1.st1.6.6.2.m1.1.1.cmml\">38</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.2.3.2.1\" xref=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.2.2\" xref=\"S5.T1.st1.6.6.2.m1.2.2.cmml\">001</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.6.6.2.m1.2b\"><list id=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.6.6.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.6.6.2.m1.1.1.cmml\" xref=\"S5.T1.st1.6.6.2.m1.1.1\">38</cn><cn type=\"integer\" id=\"S5.T1.st1.6.6.2.m1.2.2.cmml\" xref=\"S5.T1.st1.6.6.2.m1.2.2\">001</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.6.6.2.m1.2c\">38,001</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.6.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Next character prediction</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "More specifically, our technique starts by sampling a value (denoted by p𝑝p) from a distribution of candidate values. Each of these values corresponds to a specific submodel, which in turn gets translated to a specific computational and memory footprint (see Table 1(b)). Such sampled values and associations are depicted in Fig. 2. Contrary to conventional dropout (RD), our technique drops adjacent components of the model instead of random neurons, which translates to computational benefits111OD, through its nested pruning scheme that requires neither additional data structures for bookkeeping nor complex and costly data layout transformations, can capitalise directly over the existing and highly optimised dense matrix multiplication libraries. in today’s linear algebra libraries and higher accuracy as shown later.",
            "Computational and Memory Implications.\n\nThe primary objective of OD is to alleviate the excessive computational and memory demands of the training and inference deployments.\nWhen a layer is shrunk through OD, there is no need to perform the forward and backward passes or gradient updates on the pruned units.\nAs a result, OD offers gains both in terms of FLOP count and model size.\nIn particular, for every fully-connected and convolutional layer, the number of FLOPs and weight parameters is reduced by K1⋅K2/⌈p⋅K1⌉⋅⌈p⋅K2⌉∼1/p2similar-to⋅subscript𝐾1subscript𝐾2⋅⋅𝑝subscript𝐾1⋅𝑝subscript𝐾21superscript𝑝2\\nicefrac{{K_{1}\\cdot K_{2}}}{{\\left\\lceil p\\cdot K_{1}\\right\\rceil\\cdot\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p^{2}}}, where K1subscript𝐾1K_{1} and K2subscript𝐾2K_{2} correspond to the number of input and output neurons/channels, respectively. Accordingly, the bias terms are reduced by a factor of K2/⌈p⋅K2⌉∼1/psimilar-tosubscript𝐾2⋅𝑝subscript𝐾21𝑝\\nicefrac{{K_{2}}}{{\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p}}. The normalisation, activation and pooling layers are compressed in terms of FLOPs and parameters similarly to the biases in fully-connected and convolutional layers. This is also evident in Table 1(b).\nFinally, smaller model size also leads to reduced memory footprint for gradients and the optimiser’s state vectors such as momentum. However, how are these submodels related to devices in the wild and how is this getting modelled?",
            "Datasets and Models.\nWe evaluate FjORD on\ntwo vision and one text prediction task, shown in Table 1(a). For CIFAR10 [36], we use the “CIFAR” version of ResNet18 [23]. We federate the dataset by randomly dividing it into equally-sized partitions, each allocated to a specific client, and thus remaining IID in nature.\nFor FEMNIST, we use a CNN with two convolutional layers followed by a\nsoftmax layer. For Shakespeare, we employ a RNN with an embedding layer (without dropout) followed by two LSTM [25] layers and a\nsoftmax layer.\nWe report the model’s performance of the last epoch on the test set which is constructed by combining the test data for each client.\nWe report top-111 accuracy vision tasks and negative perplexity for text prediction.\nFurther details, such as hyperparameters, description of datasets and models are available in the Appendix.",
            "While we do target heterogeneous devices found in the wild, such as mobile phones, we have not measured the performance of our technique on such devices, mainly due to the lack of maturity in tools for on-device training.\nHowever, we have demonstrated the performance gains in terms of FLOPs and parameters in Table 1(b), which are directly correlated with on-device performance, memory footprint and communication size. We defer on-device benchmarking and in-the-wild deployment at scale for future work."
        ]
    },
    "S5.T1.st1": {
        "caption": "(a) Datasets description",
        "table": "<table id=\"S5.T1.st1.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.st1.6.7.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.st1.6.7.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Dataset</span></th>\n<th id=\"S5.T1.st1.6.7.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">Model</span></th>\n<th id=\"S5.T1.st1.6.7.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.3.1\" class=\"ltx_text\" style=\"font-size:50%;\"># Clients</span></th>\n<th id=\"S5.T1.st1.6.7.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.4.1\" class=\"ltx_text\" style=\"font-size:50%;\"># Samples</span></th>\n<th id=\"S5.T1.st1.6.7.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Task</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.st1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">CIFAR10</span></td>\n<td id=\"S5.T1.st1.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">ResNet18</span></td>\n<td id=\"S5.T1.st1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"100\" display=\"inline\"><semantics id=\"S5.T1.st1.1.1.1.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st1.1.1.1.m1.1.1\" xref=\"S5.T1.st1.1.1.1.m1.1.1.cmml\">100</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.1.1.1.m1.1b\"><cn type=\"integer\" id=\"S5.T1.st1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.st1.1.1.1.m1.1.1\">100</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.1.1.1.m1.1c\">100</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.2.2.2.m1.2\" class=\"ltx_Math\" alttext=\"50,000\" display=\"inline\"><semantics id=\"S5.T1.st1.2.2.2.m1.2a\"><mrow id=\"S5.T1.st1.2.2.2.m1.2.3.2\" xref=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.1.1\" xref=\"S5.T1.st1.2.2.2.m1.1.1.cmml\">50</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.2.3.2.1\" xref=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.2.2\" xref=\"S5.T1.st1.2.2.2.m1.2.2.cmml\">000</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.2.2.2.m1.2b\"><list id=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.2.2.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.2.2.2.m1.1.1.cmml\" xref=\"S5.T1.st1.2.2.2.m1.1.1\">50</cn><cn type=\"integer\" id=\"S5.T1.st1.2.2.2.m1.2.2.cmml\" xref=\"S5.T1.st1.2.2.2.m1.2.2\">000</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.2.2.2.m1.2c\">50,000</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Image classification</span></td>\n</tr>\n<tr id=\"S5.T1.st1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.4.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">FEMNIST</span></td>\n<td id=\"S5.T1.st1.4.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">CNN</span></td>\n<td id=\"S5.T1.st1.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.3.3.1.m1.2\" class=\"ltx_Math\" alttext=\"3,400\" display=\"inline\"><semantics id=\"S5.T1.st1.3.3.1.m1.2a\"><mrow id=\"S5.T1.st1.3.3.1.m1.2.3.2\" xref=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.1.1\" xref=\"S5.T1.st1.3.3.1.m1.1.1.cmml\">3</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.2.3.2.1\" xref=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.2.2\" xref=\"S5.T1.st1.3.3.1.m1.2.2.cmml\">400</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.3.3.1.m1.2b\"><list id=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\" xref=\"S5.T1.st1.3.3.1.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.3.3.1.m1.1.1.cmml\" xref=\"S5.T1.st1.3.3.1.m1.1.1\">3</cn><cn type=\"integer\" id=\"S5.T1.st1.3.3.1.m1.2.2.cmml\" xref=\"S5.T1.st1.3.3.1.m1.2.2\">400</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.3.3.1.m1.2c\">3,400</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.4.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.4.4.2.m1.2\" class=\"ltx_Math\" alttext=\"671,585\" display=\"inline\"><semantics id=\"S5.T1.st1.4.4.2.m1.2a\"><mrow id=\"S5.T1.st1.4.4.2.m1.2.3.2\" xref=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.1.1\" xref=\"S5.T1.st1.4.4.2.m1.1.1.cmml\">671</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.2.3.2.1\" xref=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.2.2\" xref=\"S5.T1.st1.4.4.2.m1.2.2.cmml\">585</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.4.4.2.m1.2b\"><list id=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.4.4.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.4.4.2.m1.1.1.cmml\" xref=\"S5.T1.st1.4.4.2.m1.1.1\">671</cn><cn type=\"integer\" id=\"S5.T1.st1.4.4.2.m1.2.2.cmml\" xref=\"S5.T1.st1.4.4.2.m1.2.2\">585</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.4.4.2.m1.2c\">671,585</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.4.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Image classification</span></td>\n</tr>\n<tr id=\"S5.T1.st1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.6.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">Shakespeare</span></td>\n<td id=\"S5.T1.st1.6.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">RNN</span></td>\n<td id=\"S5.T1.st1.5.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"715\" display=\"inline\"><semantics id=\"S5.T1.st1.5.5.1.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st1.5.5.1.m1.1.1\" xref=\"S5.T1.st1.5.5.1.m1.1.1.cmml\">715</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.5.5.1.m1.1b\"><cn type=\"integer\" id=\"S5.T1.st1.5.5.1.m1.1.1.cmml\" xref=\"S5.T1.st1.5.5.1.m1.1.1\">715</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.5.5.1.m1.1c\">715</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.6.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.6.6.2.m1.2\" class=\"ltx_Math\" alttext=\"38,001\" display=\"inline\"><semantics id=\"S5.T1.st1.6.6.2.m1.2a\"><mrow id=\"S5.T1.st1.6.6.2.m1.2.3.2\" xref=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.1.1\" xref=\"S5.T1.st1.6.6.2.m1.1.1.cmml\">38</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.2.3.2.1\" xref=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.2.2\" xref=\"S5.T1.st1.6.6.2.m1.2.2.cmml\">001</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.6.6.2.m1.2b\"><list id=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.6.6.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.6.6.2.m1.1.1.cmml\" xref=\"S5.T1.st1.6.6.2.m1.1.1\">38</cn><cn type=\"integer\" id=\"S5.T1.st1.6.6.2.m1.2.2.cmml\" xref=\"S5.T1.st1.6.6.2.m1.2.2\">001</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.6.6.2.m1.2c\">38,001</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.6.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Next character prediction</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "More specifically, our technique starts by sampling a value (denoted by p𝑝p) from a distribution of candidate values. Each of these values corresponds to a specific submodel, which in turn gets translated to a specific computational and memory footprint (see Table 1(b)). Such sampled values and associations are depicted in Fig. 2. Contrary to conventional dropout (RD), our technique drops adjacent components of the model instead of random neurons, which translates to computational benefits111OD, through its nested pruning scheme that requires neither additional data structures for bookkeeping nor complex and costly data layout transformations, can capitalise directly over the existing and highly optimised dense matrix multiplication libraries. in today’s linear algebra libraries and higher accuracy as shown later.",
            "Computational and Memory Implications.\n\nThe primary objective of OD is to alleviate the excessive computational and memory demands of the training and inference deployments.\nWhen a layer is shrunk through OD, there is no need to perform the forward and backward passes or gradient updates on the pruned units.\nAs a result, OD offers gains both in terms of FLOP count and model size.\nIn particular, for every fully-connected and convolutional layer, the number of FLOPs and weight parameters is reduced by K1⋅K2/⌈p⋅K1⌉⋅⌈p⋅K2⌉∼1/p2similar-to⋅subscript𝐾1subscript𝐾2⋅⋅𝑝subscript𝐾1⋅𝑝subscript𝐾21superscript𝑝2\\nicefrac{{K_{1}\\cdot K_{2}}}{{\\left\\lceil p\\cdot K_{1}\\right\\rceil\\cdot\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p^{2}}}, where K1subscript𝐾1K_{1} and K2subscript𝐾2K_{2} correspond to the number of input and output neurons/channels, respectively. Accordingly, the bias terms are reduced by a factor of K2/⌈p⋅K2⌉∼1/psimilar-tosubscript𝐾2⋅𝑝subscript𝐾21𝑝\\nicefrac{{K_{2}}}{{\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p}}. The normalisation, activation and pooling layers are compressed in terms of FLOPs and parameters similarly to the biases in fully-connected and convolutional layers. This is also evident in Table 1(b).\nFinally, smaller model size also leads to reduced memory footprint for gradients and the optimiser’s state vectors such as momentum. However, how are these submodels related to devices in the wild and how is this getting modelled?",
            "Devices in the wild, however, can have dramatically different capabilities; a fact further exacerbated by the co-existence of previous-generation devices. Modelling discretely each device becomes quickly intractable at scale.\nTherefore, we cluster devices of similar capabilities together and subsequently associate a single pmaxisuperscriptsubscript𝑝max𝑖p_{\\text{max}}^{i} value with each cluster.\nThis clustering can be done heuristically (i.e. based on the specifications of the device) or via benchmarking of the model on the actual device and is considered a system-design decision for our paper.\nAs smartphones nowadays run a multitude of simultaneous tasks [46],\nour framework can further support modelling of transient device load by reducing its associated pmaxisuperscriptsubscript𝑝max𝑖p_{\\text{max}}^{i}, which essentially brings the capabilities of the device to a lower tier at run time, thus bringing real-time adaptability to FjORD.",
            "Datasets and Models.\nWe evaluate FjORD on\ntwo vision and one text prediction task, shown in Table 1(a). For CIFAR10 [36], we use the “CIFAR” version of ResNet18 [23]. We federate the dataset by randomly dividing it into equally-sized partitions, each allocated to a specific client, and thus remaining IID in nature.\nFor FEMNIST, we use a CNN with two convolutional layers followed by a\nsoftmax layer. For Shakespeare, we employ a RNN with an embedding layer (without dropout) followed by two LSTM [25] layers and a\nsoftmax layer.\nWe report the model’s performance of the last epoch on the test set which is constructed by combining the test data for each client.\nWe report top-111 accuracy vision tasks and negative perplexity for text prediction.\nFurther details, such as hyperparameters, description of datasets and models are available in the Appendix.",
            "Communication Optimisation.\nThe majority of existing work has focused on tackling the communication overhead in FL.\n[35] proposed using structured and sketched updates to reduce the transmitted data.\nATOMO [64] introduced a generalised gradient decomposition and sparsification technique, aiming to reduce the gradient sizes communicated upstream. [20] adaptively select the gradients’ sparsification degree based on the available bandwidth and computational power.\nBuilding upon gradient quantisation methods [47, 26, 56, 28],\n[2] proposed using quantisation in the model sharing and aggregation steps. However, their scheme requires the same clients to participate across all rounds, and is, thus, unsuitable for realistic settings where clients’ availability cannot be guaranteed.\nDespite the bandwidth savings, these communication-optimising approaches do not offer computational gains\nnor do they address device heterogeneity.\nNonetheless, they remain orthogonal to our work and can be complementarily combined to further alleviate the communication cost.",
            "While we do target heterogeneous devices found in the wild, such as mobile phones, we have not measured the performance of our technique on such devices, mainly due to the lack of maturity in tools for on-device training.\nHowever, we have demonstrated the performance gains in terms of FLOPs and parameters in Table 1(b), which are directly correlated with on-device performance, memory footprint and communication size. We defer on-device benchmarking and in-the-wild deployment at scale for future work."
        ]
    },
    "S5.T1.st2": {
        "caption": "(b) MACs and parameters per p𝑝p-reduced network",
        "table": "<table id=\"S5.T1.st2.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.st2.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.5.6\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S5.T1.st2.1.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><math id=\"S5.T1.st2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"p=0.2\" display=\"inline\"><semantics id=\"S5.T1.st2.1.1.1.m1.1a\"><mrow id=\"S5.T1.st2.1.1.1.m1.1.1\" xref=\"S5.T1.st2.1.1.1.m1.1.1.cmml\"><mi mathsize=\"50%\" id=\"S5.T1.st2.1.1.1.m1.1.1.2\" xref=\"S5.T1.st2.1.1.1.m1.1.1.2.cmml\">p</mi><mo mathsize=\"50%\" id=\"S5.T1.st2.1.1.1.m1.1.1.1\" xref=\"S5.T1.st2.1.1.1.m1.1.1.1.cmml\">=</mo><mn mathsize=\"50%\" id=\"S5.T1.st2.1.1.1.m1.1.1.3\" xref=\"S5.T1.st2.1.1.1.m1.1.1.3.cmml\">0.2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st2.1.1.1.m1.1b\"><apply id=\"S5.T1.st2.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.st2.1.1.1.m1.1.1\"><eq id=\"S5.T1.st2.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T1.st2.1.1.1.m1.1.1.1\"></eq><ci id=\"S5.T1.st2.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T1.st2.1.1.1.m1.1.1.2\">𝑝</ci><cn type=\"float\" id=\"S5.T1.st2.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T1.st2.1.1.1.m1.1.1.3\">0.2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st2.1.1.1.m1.1c\">p=0.2</annotation></semantics></math></th>\n<th id=\"S5.T1.st2.2.2.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><math id=\"S5.T1.st2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"0.4\" display=\"inline\"><semantics id=\"S5.T1.st2.2.2.2.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st2.2.2.2.m1.1.1\" xref=\"S5.T1.st2.2.2.2.m1.1.1.cmml\">0.4</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st2.2.2.2.m1.1b\"><cn type=\"float\" id=\"S5.T1.st2.2.2.2.m1.1.1.cmml\" xref=\"S5.T1.st2.2.2.2.m1.1.1\">0.4</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st2.2.2.2.m1.1c\">0.4</annotation></semantics></math></th>\n<th id=\"S5.T1.st2.3.3.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><math id=\"S5.T1.st2.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"0.6\" display=\"inline\"><semantics id=\"S5.T1.st2.3.3.3.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st2.3.3.3.m1.1.1\" xref=\"S5.T1.st2.3.3.3.m1.1.1.cmml\">0.6</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st2.3.3.3.m1.1b\"><cn type=\"float\" id=\"S5.T1.st2.3.3.3.m1.1.1.cmml\" xref=\"S5.T1.st2.3.3.3.m1.1.1\">0.6</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st2.3.3.3.m1.1c\">0.6</annotation></semantics></math></th>\n<th id=\"S5.T1.st2.4.4.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><math id=\"S5.T1.st2.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"0.8\" display=\"inline\"><semantics id=\"S5.T1.st2.4.4.4.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st2.4.4.4.m1.1.1\" xref=\"S5.T1.st2.4.4.4.m1.1.1.cmml\">0.8</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st2.4.4.4.m1.1b\"><cn type=\"float\" id=\"S5.T1.st2.4.4.4.m1.1.1.cmml\" xref=\"S5.T1.st2.4.4.4.m1.1.1\">0.8</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st2.4.4.4.m1.1c\">0.8</annotation></semantics></math></th>\n<th id=\"S5.T1.st2.5.5.5\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><math id=\"S5.T1.st2.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"1.0\" display=\"inline\"><semantics id=\"S5.T1.st2.5.5.5.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st2.5.5.5.m1.1.1\" xref=\"S5.T1.st2.5.5.5.m1.1.1.cmml\">1.0</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st2.5.5.5.m1.1b\"><cn type=\"float\" id=\"S5.T1.st2.5.5.5.m1.1.1.cmml\" xref=\"S5.T1.st2.5.5.5.m1.1.1\">1.0</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st2.5.5.5.m1.1c\">1.0</annotation></semantics></math></th>\n</tr>\n<tr id=\"S5.T1.st2.5.6.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.6.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" colspan=\"6\"><span id=\"S5.T1.st2.5.6.1.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">CIFAR10 / ResNet18</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.st2.5.7.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.7.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.st2.5.7.1.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">MACs</span></th>\n<td id=\"S5.T1.st2.5.7.1.2\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.7.1.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">23M</span></td>\n<td id=\"S5.T1.st2.5.7.1.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.7.1.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">91M</span></td>\n<td id=\"S5.T1.st2.5.7.1.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.7.1.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">203M</span></td>\n<td id=\"S5.T1.st2.5.7.1.5\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.7.1.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">360M</span></td>\n<td id=\"S5.T1.st2.5.7.1.6\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.7.1.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">555M</span></td>\n</tr>\n<tr id=\"S5.T1.st2.5.8.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.8.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.st2.5.8.2.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Params</span></th>\n<td id=\"S5.T1.st2.5.8.2.2\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.8.2.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">456K</span></td>\n<td id=\"S5.T1.st2.5.8.2.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.8.2.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">2M</span></td>\n<td id=\"S5.T1.st2.5.8.2.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.8.2.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">4M</span></td>\n<td id=\"S5.T1.st2.5.8.2.5\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.8.2.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">7M</span></td>\n<td id=\"S5.T1.st2.5.8.2.6\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.8.2.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">11M</span></td>\n</tr>\n<tr id=\"S5.T1.st2.5.9.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.9.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" colspan=\"6\"><span id=\"S5.T1.st2.5.9.3.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">FEMNIST / CNN</span></th>\n</tr>\n<tr id=\"S5.T1.st2.5.10.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.10.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.st2.5.10.4.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">MACs</span></th>\n<td id=\"S5.T1.st2.5.10.4.2\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.10.4.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">47K</span></td>\n<td id=\"S5.T1.st2.5.10.4.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.10.4.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">120K</span></td>\n<td id=\"S5.T1.st2.5.10.4.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.10.4.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">218K</span></td>\n<td id=\"S5.T1.st2.5.10.4.5\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.10.4.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">342K</span></td>\n<td id=\"S5.T1.st2.5.10.4.6\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.10.4.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">491K</span></td>\n</tr>\n<tr id=\"S5.T1.st2.5.11.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.11.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.st2.5.11.5.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Params</span></th>\n<td id=\"S5.T1.st2.5.11.5.2\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.11.5.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">5K</span></td>\n<td id=\"S5.T1.st2.5.11.5.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.11.5.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">10K</span></td>\n<td id=\"S5.T1.st2.5.11.5.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.11.5.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">15K</span></td>\n<td id=\"S5.T1.st2.5.11.5.5\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.11.5.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">20K</span></td>\n<td id=\"S5.T1.st2.5.11.5.6\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.11.5.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">26K</span></td>\n</tr>\n<tr id=\"S5.T1.st2.5.12.6\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.12.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" colspan=\"6\"><span id=\"S5.T1.st2.5.12.6.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Shakespeare / RNN</span></th>\n</tr>\n<tr id=\"S5.T1.st2.5.13.7\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.13.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.st2.5.13.7.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">MACs</span></th>\n<td id=\"S5.T1.st2.5.13.7.2\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.13.7.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">12K</span></td>\n<td id=\"S5.T1.st2.5.13.7.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.13.7.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">40K</span></td>\n<td id=\"S5.T1.st2.5.13.7.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.13.7.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">83K</span></td>\n<td id=\"S5.T1.st2.5.13.7.5\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.13.7.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">143K</span></td>\n<td id=\"S5.T1.st2.5.13.7.6\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.13.7.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">216K</span></td>\n</tr>\n<tr id=\"S5.T1.st2.5.14.8\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.14.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Params</span></th>\n<td id=\"S5.T1.st2.5.14.8.2\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">12K</span></td>\n<td id=\"S5.T1.st2.5.14.8.3\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">40K</span></td>\n<td id=\"S5.T1.st2.5.14.8.4\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">82K</span></td>\n<td id=\"S5.T1.st2.5.14.8.5\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">142K</span></td>\n<td id=\"S5.T1.st2.5.14.8.6\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">214K</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "More specifically, our technique starts by sampling a value (denoted by p𝑝p) from a distribution of candidate values. Each of these values corresponds to a specific submodel, which in turn gets translated to a specific computational and memory footprint (see Table 1(b)). Such sampled values and associations are depicted in Fig. 2. Contrary to conventional dropout (RD), our technique drops adjacent components of the model instead of random neurons, which translates to computational benefits111OD, through its nested pruning scheme that requires neither additional data structures for bookkeeping nor complex and costly data layout transformations, can capitalise directly over the existing and highly optimised dense matrix multiplication libraries. in today’s linear algebra libraries and higher accuracy as shown later.",
            "Computational and Memory Implications.\n\nThe primary objective of OD is to alleviate the excessive computational and memory demands of the training and inference deployments.\nWhen a layer is shrunk through OD, there is no need to perform the forward and backward passes or gradient updates on the pruned units.\nAs a result, OD offers gains both in terms of FLOP count and model size.\nIn particular, for every fully-connected and convolutional layer, the number of FLOPs and weight parameters is reduced by K1⋅K2/⌈p⋅K1⌉⋅⌈p⋅K2⌉∼1/p2similar-to⋅subscript𝐾1subscript𝐾2⋅⋅𝑝subscript𝐾1⋅𝑝subscript𝐾21superscript𝑝2\\nicefrac{{K_{1}\\cdot K_{2}}}{{\\left\\lceil p\\cdot K_{1}\\right\\rceil\\cdot\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p^{2}}}, where K1subscript𝐾1K_{1} and K2subscript𝐾2K_{2} correspond to the number of input and output neurons/channels, respectively. Accordingly, the bias terms are reduced by a factor of K2/⌈p⋅K2⌉∼1/psimilar-tosubscript𝐾2⋅𝑝subscript𝐾21𝑝\\nicefrac{{K_{2}}}{{\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p}}. The normalisation, activation and pooling layers are compressed in terms of FLOPs and parameters similarly to the biases in fully-connected and convolutional layers. This is also evident in Table 1(b).\nFinally, smaller model size also leads to reduced memory footprint for gradients and the optimiser’s state vectors such as momentum. However, how are these submodels related to devices in the wild and how is this getting modelled?",
            "Devices in the wild, however, can have dramatically different capabilities; a fact further exacerbated by the co-existence of previous-generation devices. Modelling discretely each device becomes quickly intractable at scale.\nTherefore, we cluster devices of similar capabilities together and subsequently associate a single pmaxisuperscriptsubscript𝑝max𝑖p_{\\text{max}}^{i} value with each cluster.\nThis clustering can be done heuristically (i.e. based on the specifications of the device) or via benchmarking of the model on the actual device and is considered a system-design decision for our paper.\nAs smartphones nowadays run a multitude of simultaneous tasks [46],\nour framework can further support modelling of transient device load by reducing its associated pmaxisuperscriptsubscript𝑝max𝑖p_{\\text{max}}^{i}, which essentially brings the capabilities of the device to a lower tier at run time, thus bringing real-time adaptability to FjORD.",
            "Datasets and Models.\nWe evaluate FjORD on\ntwo vision and one text prediction task, shown in Table 1(a). For CIFAR10 [36], we use the “CIFAR” version of ResNet18 [23]. We federate the dataset by randomly dividing it into equally-sized partitions, each allocated to a specific client, and thus remaining IID in nature.\nFor FEMNIST, we use a CNN with two convolutional layers followed by a\nsoftmax layer. For Shakespeare, we employ a RNN with an embedding layer (without dropout) followed by two LSTM [25] layers and a\nsoftmax layer.\nWe report the model’s performance of the last epoch on the test set which is constructed by combining the test data for each client.\nWe report top-111 accuracy vision tasks and negative perplexity for text prediction.\nFurther details, such as hyperparameters, description of datasets and models are available in the Appendix.",
            "Communication Optimisation.\nThe majority of existing work has focused on tackling the communication overhead in FL.\n[35] proposed using structured and sketched updates to reduce the transmitted data.\nATOMO [64] introduced a generalised gradient decomposition and sparsification technique, aiming to reduce the gradient sizes communicated upstream. [20] adaptively select the gradients’ sparsification degree based on the available bandwidth and computational power.\nBuilding upon gradient quantisation methods [47, 26, 56, 28],\n[2] proposed using quantisation in the model sharing and aggregation steps. However, their scheme requires the same clients to participate across all rounds, and is, thus, unsuitable for realistic settings where clients’ availability cannot be guaranteed.\nDespite the bandwidth savings, these communication-optimising approaches do not offer computational gains\nnor do they address device heterogeneity.\nNonetheless, they remain orthogonal to our work and can be complementarily combined to further alleviate the communication cost.",
            "While we do target heterogeneous devices found in the wild, such as mobile phones, we have not measured the performance of our technique on such devices, mainly due to the lack of maturity in tools for on-device training.\nHowever, we have demonstrated the performance gains in terms of FLOPs and parameters in Table 1(b), which are directly correlated with on-device performance, memory footprint and communication size. We defer on-device benchmarking and in-the-wild deployment at scale for future work."
        ]
    }
}