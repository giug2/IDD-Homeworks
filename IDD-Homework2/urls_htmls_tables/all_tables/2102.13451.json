{
    "PAPER'S NUMBER OF TABLES": 3,
    "S5.T1": {
        "caption": "Table 1: Datasets and models",
        "table": "<table id=\"S5.T1.st1.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.st1.6.7.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.st1.6.7.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Dataset</span></th>\n<th id=\"S5.T1.st1.6.7.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">Model</span></th>\n<th id=\"S5.T1.st1.6.7.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.3.1\" class=\"ltx_text\" style=\"font-size:50%;\"># Clients</span></th>\n<th id=\"S5.T1.st1.6.7.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.4.1\" class=\"ltx_text\" style=\"font-size:50%;\"># Samples</span></th>\n<th id=\"S5.T1.st1.6.7.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Task</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.st1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">CIFAR10</span></td>\n<td id=\"S5.T1.st1.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">ResNet18</span></td>\n<td id=\"S5.T1.st1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"100\" display=\"inline\"><semantics id=\"S5.T1.st1.1.1.1.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st1.1.1.1.m1.1.1\" xref=\"S5.T1.st1.1.1.1.m1.1.1.cmml\">100</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.1.1.1.m1.1b\"><cn type=\"integer\" id=\"S5.T1.st1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.st1.1.1.1.m1.1.1\">100</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.1.1.1.m1.1c\">100</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.2.2.2.m1.2\" class=\"ltx_Math\" alttext=\"50,000\" display=\"inline\"><semantics id=\"S5.T1.st1.2.2.2.m1.2a\"><mrow id=\"S5.T1.st1.2.2.2.m1.2.3.2\" xref=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.1.1\" xref=\"S5.T1.st1.2.2.2.m1.1.1.cmml\">50</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.2.3.2.1\" xref=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.2.2\" xref=\"S5.T1.st1.2.2.2.m1.2.2.cmml\">000</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.2.2.2.m1.2b\"><list id=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.2.2.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.2.2.2.m1.1.1.cmml\" xref=\"S5.T1.st1.2.2.2.m1.1.1\">50</cn><cn type=\"integer\" id=\"S5.T1.st1.2.2.2.m1.2.2.cmml\" xref=\"S5.T1.st1.2.2.2.m1.2.2\">000</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.2.2.2.m1.2c\">50,000</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Image classification</span></td>\n</tr>\n<tr id=\"S5.T1.st1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.4.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">FEMNIST</span></td>\n<td id=\"S5.T1.st1.4.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">CNN</span></td>\n<td id=\"S5.T1.st1.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.3.3.1.m1.2\" class=\"ltx_Math\" alttext=\"3,400\" display=\"inline\"><semantics id=\"S5.T1.st1.3.3.1.m1.2a\"><mrow id=\"S5.T1.st1.3.3.1.m1.2.3.2\" xref=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.1.1\" xref=\"S5.T1.st1.3.3.1.m1.1.1.cmml\">3</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.2.3.2.1\" xref=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.2.2\" xref=\"S5.T1.st1.3.3.1.m1.2.2.cmml\">400</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.3.3.1.m1.2b\"><list id=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\" xref=\"S5.T1.st1.3.3.1.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.3.3.1.m1.1.1.cmml\" xref=\"S5.T1.st1.3.3.1.m1.1.1\">3</cn><cn type=\"integer\" id=\"S5.T1.st1.3.3.1.m1.2.2.cmml\" xref=\"S5.T1.st1.3.3.1.m1.2.2\">400</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.3.3.1.m1.2c\">3,400</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.4.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.4.4.2.m1.2\" class=\"ltx_Math\" alttext=\"671,585\" display=\"inline\"><semantics id=\"S5.T1.st1.4.4.2.m1.2a\"><mrow id=\"S5.T1.st1.4.4.2.m1.2.3.2\" xref=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.1.1\" xref=\"S5.T1.st1.4.4.2.m1.1.1.cmml\">671</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.2.3.2.1\" xref=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.2.2\" xref=\"S5.T1.st1.4.4.2.m1.2.2.cmml\">585</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.4.4.2.m1.2b\"><list id=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.4.4.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.4.4.2.m1.1.1.cmml\" xref=\"S5.T1.st1.4.4.2.m1.1.1\">671</cn><cn type=\"integer\" id=\"S5.T1.st1.4.4.2.m1.2.2.cmml\" xref=\"S5.T1.st1.4.4.2.m1.2.2\">585</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.4.4.2.m1.2c\">671,585</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.4.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Image classification</span></td>\n</tr>\n<tr id=\"S5.T1.st1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.6.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">Shakespeare</span></td>\n<td id=\"S5.T1.st1.6.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">RNN</span></td>\n<td id=\"S5.T1.st1.5.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"715\" display=\"inline\"><semantics id=\"S5.T1.st1.5.5.1.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st1.5.5.1.m1.1.1\" xref=\"S5.T1.st1.5.5.1.m1.1.1.cmml\">715</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.5.5.1.m1.1b\"><cn type=\"integer\" id=\"S5.T1.st1.5.5.1.m1.1.1.cmml\" xref=\"S5.T1.st1.5.5.1.m1.1.1\">715</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.5.5.1.m1.1c\">715</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.6.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.6.6.2.m1.2\" class=\"ltx_Math\" alttext=\"38,001\" display=\"inline\"><semantics id=\"S5.T1.st1.6.6.2.m1.2a\"><mrow id=\"S5.T1.st1.6.6.2.m1.2.3.2\" xref=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.1.1\" xref=\"S5.T1.st1.6.6.2.m1.1.1.cmml\">38</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.2.3.2.1\" xref=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.2.2\" xref=\"S5.T1.st1.6.6.2.m1.2.2.cmml\">001</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.6.6.2.m1.2b\"><list id=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.6.6.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.6.6.2.m1.1.1.cmml\" xref=\"S5.T1.st1.6.6.2.m1.1.1\">38</cn><cn type=\"integer\" id=\"S5.T1.st1.6.6.2.m1.2.2.cmml\" xref=\"S5.T1.st1.6.6.2.m1.2.2\">001</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.6.6.2.m1.2c\">38,001</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.6.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Next character prediction</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "More specifically, our technique starts by sampling a value (denoted byÂ pğ‘p) from a distribution of candidate values. Each of these values corresponds to a specific submodel, which in turn gets translated to a specific computational and memory footprint (see TableÂ 1(b)). Such sampled values and associations are depicted in Fig.Â 2. Contrary to conventional dropout (RD), our technique drops adjacent components of the model instead of random neurons, which translates to computational benefits111OD, through its nested pruning scheme that requires neither additional data structures for bookkeeping nor complex and costly data layout transformations, can capitalise directly over the existing and highly optimised dense matrix multiplication libraries. in todayâ€™s linear algebra libraries and higher accuracy as shown later.",
            "Computational and Memory Implications.\n\nThe primary objective of OD is to alleviate the excessive computational and memory demands of the training and inference deployments.\nWhen a layer is shrunk through OD, there is no need to perform the forward and backward passes or gradient updates on the pruned units.\nAs a result, OD offers gains both in terms of FLOP count and model size.\nIn particular, for every fully-connected and convolutional layer, the number of FLOPs and weight parameters is reduced by K1â‹…K2/âŒˆpâ‹…K1âŒ‰â‹…âŒˆpâ‹…K2âŒ‰âˆ¼1/p2similar-toâ‹…subscriptğ¾1subscriptğ¾2â‹…â‹…ğ‘subscriptğ¾1â‹…ğ‘subscriptğ¾21superscriptğ‘2\\nicefrac{{K_{1}\\cdot K_{2}}}{{\\left\\lceil p\\cdot K_{1}\\right\\rceil\\cdot\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p^{2}}}, where K1subscriptğ¾1K_{1} and K2subscriptğ¾2K_{2} correspond to the number of input and output neurons/channels, respectively. Accordingly, the bias terms are reduced by a factor of K2/âŒˆpâ‹…K2âŒ‰âˆ¼1/psimilar-tosubscriptğ¾2â‹…ğ‘subscriptğ¾21ğ‘\\nicefrac{{K_{2}}}{{\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p}}. The normalisation, activation and pooling layers are compressed in terms of FLOPs and parameters similarly to the biases in fully-connected and convolutional layers. This is also evident in TableÂ 1(b).\nFinally, smaller model size also leads to reduced memory footprint for gradients and the optimiserâ€™s state vectors such as momentum. However, how are these submodels related to devices in the wild and how is this getting modelled?",
            "Datasets and Models.\nWe evaluate FjORD on\ntwo vision and one text prediction task, shown in TableÂ 1(a). For CIFAR10Â [36], we use the â€œCIFARâ€ version of ResNet18Â [23]. We federate the dataset by randomly dividing it into equally-sized partitions, each allocated to a specific client, and thus remaining IID in nature.\nFor FEMNIST, we use a CNN with two convolutional layers followed by a\nsoftmax layer. For Shakespeare, we employ a RNN with an embedding layer (without dropout) followed by two LSTMÂ [25] layers and a\nsoftmax layer.\nWe report the modelâ€™s performance of the last epoch on the test set which is constructed by combining the test data for each client.\nWe report top-111 accuracy vision tasks and negative perplexity for text prediction.\nFurther details, such as hyperparameters, description of datasets and models are available in the Appendix.",
            "While we do target heterogeneous devices found in the wild, such as mobile phones, we have not measured the performance of our technique on such devices, mainly due to the lack of maturity in tools for on-device training.\nHowever, we have demonstrated the performance gains in terms of FLOPs and parameters in TableÂ 1(b), which are directly correlated with on-device performance, memory footprint and communication size. We defer on-device benchmarking and in-the-wild deployment at scale for future work."
        ]
    },
    "S5.T1.st1": {
        "caption": "(a) Datasets description",
        "table": "<table id=\"S5.T1.st1.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.st1.6.7.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.st1.6.7.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Dataset</span></th>\n<th id=\"S5.T1.st1.6.7.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">Model</span></th>\n<th id=\"S5.T1.st1.6.7.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.3.1\" class=\"ltx_text\" style=\"font-size:50%;\"># Clients</span></th>\n<th id=\"S5.T1.st1.6.7.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.4.1\" class=\"ltx_text\" style=\"font-size:50%;\"># Samples</span></th>\n<th id=\"S5.T1.st1.6.7.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.7.1.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Task</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.st1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">CIFAR10</span></td>\n<td id=\"S5.T1.st1.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">ResNet18</span></td>\n<td id=\"S5.T1.st1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"100\" display=\"inline\"><semantics id=\"S5.T1.st1.1.1.1.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st1.1.1.1.m1.1.1\" xref=\"S5.T1.st1.1.1.1.m1.1.1.cmml\">100</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.1.1.1.m1.1b\"><cn type=\"integer\" id=\"S5.T1.st1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.st1.1.1.1.m1.1.1\">100</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.1.1.1.m1.1c\">100</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.2.2.2.m1.2\" class=\"ltx_Math\" alttext=\"50,000\" display=\"inline\"><semantics id=\"S5.T1.st1.2.2.2.m1.2a\"><mrow id=\"S5.T1.st1.2.2.2.m1.2.3.2\" xref=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.1.1\" xref=\"S5.T1.st1.2.2.2.m1.1.1.cmml\">50</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.2.3.2.1\" xref=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.2.2.2.m1.2.2\" xref=\"S5.T1.st1.2.2.2.m1.2.2.cmml\">000</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.2.2.2.m1.2b\"><list id=\"S5.T1.st1.2.2.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.2.2.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.2.2.2.m1.1.1.cmml\" xref=\"S5.T1.st1.2.2.2.m1.1.1\">50</cn><cn type=\"integer\" id=\"S5.T1.st1.2.2.2.m1.2.2.cmml\" xref=\"S5.T1.st1.2.2.2.m1.2.2\">000</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.2.2.2.m1.2c\">50,000</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Image classification</span></td>\n</tr>\n<tr id=\"S5.T1.st1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.4.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">FEMNIST</span></td>\n<td id=\"S5.T1.st1.4.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">CNN</span></td>\n<td id=\"S5.T1.st1.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.3.3.1.m1.2\" class=\"ltx_Math\" alttext=\"3,400\" display=\"inline\"><semantics id=\"S5.T1.st1.3.3.1.m1.2a\"><mrow id=\"S5.T1.st1.3.3.1.m1.2.3.2\" xref=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.1.1\" xref=\"S5.T1.st1.3.3.1.m1.1.1.cmml\">3</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.2.3.2.1\" xref=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.3.3.1.m1.2.2\" xref=\"S5.T1.st1.3.3.1.m1.2.2.cmml\">400</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.3.3.1.m1.2b\"><list id=\"S5.T1.st1.3.3.1.m1.2.3.1.cmml\" xref=\"S5.T1.st1.3.3.1.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.3.3.1.m1.1.1.cmml\" xref=\"S5.T1.st1.3.3.1.m1.1.1\">3</cn><cn type=\"integer\" id=\"S5.T1.st1.3.3.1.m1.2.2.cmml\" xref=\"S5.T1.st1.3.3.1.m1.2.2\">400</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.3.3.1.m1.2c\">3,400</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.4.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.4.4.2.m1.2\" class=\"ltx_Math\" alttext=\"671,585\" display=\"inline\"><semantics id=\"S5.T1.st1.4.4.2.m1.2a\"><mrow id=\"S5.T1.st1.4.4.2.m1.2.3.2\" xref=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.1.1\" xref=\"S5.T1.st1.4.4.2.m1.1.1.cmml\">671</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.2.3.2.1\" xref=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.4.4.2.m1.2.2\" xref=\"S5.T1.st1.4.4.2.m1.2.2.cmml\">585</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.4.4.2.m1.2b\"><list id=\"S5.T1.st1.4.4.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.4.4.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.4.4.2.m1.1.1.cmml\" xref=\"S5.T1.st1.4.4.2.m1.1.1\">671</cn><cn type=\"integer\" id=\"S5.T1.st1.4.4.2.m1.2.2.cmml\" xref=\"S5.T1.st1.4.4.2.m1.2.2\">585</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.4.4.2.m1.2c\">671,585</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.4.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Image classification</span></td>\n</tr>\n<tr id=\"S5.T1.st1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.st1.6.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">Shakespeare</span></td>\n<td id=\"S5.T1.st1.6.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">RNN</span></td>\n<td id=\"S5.T1.st1.5.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"715\" display=\"inline\"><semantics id=\"S5.T1.st1.5.5.1.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st1.5.5.1.m1.1.1\" xref=\"S5.T1.st1.5.5.1.m1.1.1.cmml\">715</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.5.5.1.m1.1b\"><cn type=\"integer\" id=\"S5.T1.st1.5.5.1.m1.1.1.cmml\" xref=\"S5.T1.st1.5.5.1.m1.1.1\">715</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.5.5.1.m1.1c\">715</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.6.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><math id=\"S5.T1.st1.6.6.2.m1.2\" class=\"ltx_Math\" alttext=\"38,001\" display=\"inline\"><semantics id=\"S5.T1.st1.6.6.2.m1.2a\"><mrow id=\"S5.T1.st1.6.6.2.m1.2.3.2\" xref=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\"><mn mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.1.1\" xref=\"S5.T1.st1.6.6.2.m1.1.1.cmml\">38</mn><mo mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.2.3.2.1\" xref=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\">,</mo><mn mathsize=\"50%\" id=\"S5.T1.st1.6.6.2.m1.2.2\" xref=\"S5.T1.st1.6.6.2.m1.2.2.cmml\">001</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st1.6.6.2.m1.2b\"><list id=\"S5.T1.st1.6.6.2.m1.2.3.1.cmml\" xref=\"S5.T1.st1.6.6.2.m1.2.3.2\"><cn type=\"integer\" id=\"S5.T1.st1.6.6.2.m1.1.1.cmml\" xref=\"S5.T1.st1.6.6.2.m1.1.1\">38</cn><cn type=\"integer\" id=\"S5.T1.st1.6.6.2.m1.2.2.cmml\" xref=\"S5.T1.st1.6.6.2.m1.2.2\">001</cn></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st1.6.6.2.m1.2c\">38,001</annotation></semantics></math></td>\n<td id=\"S5.T1.st1.6.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S5.T1.st1.6.6.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">Next character prediction</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "More specifically, our technique starts by sampling a value (denoted byÂ pğ‘p) from a distribution of candidate values. Each of these values corresponds to a specific submodel, which in turn gets translated to a specific computational and memory footprint (see TableÂ 1(b)). Such sampled values and associations are depicted in Fig.Â 2. Contrary to conventional dropout (RD), our technique drops adjacent components of the model instead of random neurons, which translates to computational benefits111OD, through its nested pruning scheme that requires neither additional data structures for bookkeeping nor complex and costly data layout transformations, can capitalise directly over the existing and highly optimised dense matrix multiplication libraries. in todayâ€™s linear algebra libraries and higher accuracy as shown later.",
            "Computational and Memory Implications.\n\nThe primary objective of OD is to alleviate the excessive computational and memory demands of the training and inference deployments.\nWhen a layer is shrunk through OD, there is no need to perform the forward and backward passes or gradient updates on the pruned units.\nAs a result, OD offers gains both in terms of FLOP count and model size.\nIn particular, for every fully-connected and convolutional layer, the number of FLOPs and weight parameters is reduced by K1â‹…K2/âŒˆpâ‹…K1âŒ‰â‹…âŒˆpâ‹…K2âŒ‰âˆ¼1/p2similar-toâ‹…subscriptğ¾1subscriptğ¾2â‹…â‹…ğ‘subscriptğ¾1â‹…ğ‘subscriptğ¾21superscriptğ‘2\\nicefrac{{K_{1}\\cdot K_{2}}}{{\\left\\lceil p\\cdot K_{1}\\right\\rceil\\cdot\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p^{2}}}, where K1subscriptğ¾1K_{1} and K2subscriptğ¾2K_{2} correspond to the number of input and output neurons/channels, respectively. Accordingly, the bias terms are reduced by a factor of K2/âŒˆpâ‹…K2âŒ‰âˆ¼1/psimilar-tosubscriptğ¾2â‹…ğ‘subscriptğ¾21ğ‘\\nicefrac{{K_{2}}}{{\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p}}. The normalisation, activation and pooling layers are compressed in terms of FLOPs and parameters similarly to the biases in fully-connected and convolutional layers. This is also evident in TableÂ 1(b).\nFinally, smaller model size also leads to reduced memory footprint for gradients and the optimiserâ€™s state vectors such as momentum. However, how are these submodels related to devices in the wild and how is this getting modelled?",
            "Devices in the wild, however, can have dramatically different capabilities; a fact further exacerbated by the co-existence of previous-generation devices. Modelling discretely each device becomes quickly intractable at scale.\nTherefore, we cluster devices of similar capabilities together and subsequently associate a single pmaxisuperscriptsubscriptğ‘maxğ‘–p_{\\text{max}}^{i} value with each cluster.\nThis clustering can be done heuristically (i.e.Â based on the specifications of the device) or via benchmarking of the model on the actual device and is considered a system-design decision for our paper.\nAs smartphones nowadays run a multitude of simultaneous tasksÂ [46],\nour framework can further support modelling of transient device load by reducing its associated pmaxisuperscriptsubscriptğ‘maxğ‘–p_{\\text{max}}^{i}, which essentially brings the capabilities of the device to a lower tier at run time, thus bringing real-time adaptability to FjORD.",
            "Datasets and Models.\nWe evaluate FjORD on\ntwo vision and one text prediction task, shown in TableÂ 1(a). For CIFAR10Â [36], we use the â€œCIFARâ€ version of ResNet18Â [23]. We federate the dataset by randomly dividing it into equally-sized partitions, each allocated to a specific client, and thus remaining IID in nature.\nFor FEMNIST, we use a CNN with two convolutional layers followed by a\nsoftmax layer. For Shakespeare, we employ a RNN with an embedding layer (without dropout) followed by two LSTMÂ [25] layers and a\nsoftmax layer.\nWe report the modelâ€™s performance of the last epoch on the test set which is constructed by combining the test data for each client.\nWe report top-111 accuracy vision tasks and negative perplexity for text prediction.\nFurther details, such as hyperparameters, description of datasets and models are available in the Appendix.",
            "Communication Optimisation.\nThe majority of existing work has focused on tackling the communication overhead in FL.\n[35] proposed using structured and sketched updates to reduce the transmitted data.\nATOMOÂ [64] introduced a generalised gradient decomposition and sparsification technique, aiming to reduce the gradient sizes communicated upstream. [20] adaptively select the gradientsâ€™ sparsification degree based on the available bandwidth and computational power.\nBuilding upon gradient quantisation methodsÂ [47, 26, 56, 28],\n[2] proposed using quantisation in the model sharing and aggregation steps. However, their scheme requires the same clients to participate across all rounds, and is, thus, unsuitable for realistic settings where clientsâ€™ availability cannot be guaranteed.\nDespite the bandwidth savings, these communication-optimising approaches do not offer computational gains\nnor do they address device heterogeneity.\nNonetheless, they remain orthogonal to our work and can be complementarily combined to further alleviate the communication cost.",
            "While we do target heterogeneous devices found in the wild, such as mobile phones, we have not measured the performance of our technique on such devices, mainly due to the lack of maturity in tools for on-device training.\nHowever, we have demonstrated the performance gains in terms of FLOPs and parameters in TableÂ 1(b), which are directly correlated with on-device performance, memory footprint and communication size. We defer on-device benchmarking and in-the-wild deployment at scale for future work."
        ]
    },
    "S5.T1.st2": {
        "caption": "(b) MACs and parameters per pğ‘p-reduced network",
        "table": "<table id=\"S5.T1.st2.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.st2.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.5.6\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S5.T1.st2.1.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><math id=\"S5.T1.st2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"p=0.2\" display=\"inline\"><semantics id=\"S5.T1.st2.1.1.1.m1.1a\"><mrow id=\"S5.T1.st2.1.1.1.m1.1.1\" xref=\"S5.T1.st2.1.1.1.m1.1.1.cmml\"><mi mathsize=\"50%\" id=\"S5.T1.st2.1.1.1.m1.1.1.2\" xref=\"S5.T1.st2.1.1.1.m1.1.1.2.cmml\">p</mi><mo mathsize=\"50%\" id=\"S5.T1.st2.1.1.1.m1.1.1.1\" xref=\"S5.T1.st2.1.1.1.m1.1.1.1.cmml\">=</mo><mn mathsize=\"50%\" id=\"S5.T1.st2.1.1.1.m1.1.1.3\" xref=\"S5.T1.st2.1.1.1.m1.1.1.3.cmml\">0.2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st2.1.1.1.m1.1b\"><apply id=\"S5.T1.st2.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.st2.1.1.1.m1.1.1\"><eq id=\"S5.T1.st2.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T1.st2.1.1.1.m1.1.1.1\"></eq><ci id=\"S5.T1.st2.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T1.st2.1.1.1.m1.1.1.2\">ğ‘</ci><cn type=\"float\" id=\"S5.T1.st2.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T1.st2.1.1.1.m1.1.1.3\">0.2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st2.1.1.1.m1.1c\">p=0.2</annotation></semantics></math></th>\n<th id=\"S5.T1.st2.2.2.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><math id=\"S5.T1.st2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"0.4\" display=\"inline\"><semantics id=\"S5.T1.st2.2.2.2.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st2.2.2.2.m1.1.1\" xref=\"S5.T1.st2.2.2.2.m1.1.1.cmml\">0.4</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st2.2.2.2.m1.1b\"><cn type=\"float\" id=\"S5.T1.st2.2.2.2.m1.1.1.cmml\" xref=\"S5.T1.st2.2.2.2.m1.1.1\">0.4</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st2.2.2.2.m1.1c\">0.4</annotation></semantics></math></th>\n<th id=\"S5.T1.st2.3.3.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><math id=\"S5.T1.st2.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"0.6\" display=\"inline\"><semantics id=\"S5.T1.st2.3.3.3.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st2.3.3.3.m1.1.1\" xref=\"S5.T1.st2.3.3.3.m1.1.1.cmml\">0.6</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st2.3.3.3.m1.1b\"><cn type=\"float\" id=\"S5.T1.st2.3.3.3.m1.1.1.cmml\" xref=\"S5.T1.st2.3.3.3.m1.1.1\">0.6</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st2.3.3.3.m1.1c\">0.6</annotation></semantics></math></th>\n<th id=\"S5.T1.st2.4.4.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><math id=\"S5.T1.st2.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"0.8\" display=\"inline\"><semantics id=\"S5.T1.st2.4.4.4.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st2.4.4.4.m1.1.1\" xref=\"S5.T1.st2.4.4.4.m1.1.1.cmml\">0.8</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st2.4.4.4.m1.1b\"><cn type=\"float\" id=\"S5.T1.st2.4.4.4.m1.1.1.cmml\" xref=\"S5.T1.st2.4.4.4.m1.1.1\">0.8</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st2.4.4.4.m1.1c\">0.8</annotation></semantics></math></th>\n<th id=\"S5.T1.st2.5.5.5\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><math id=\"S5.T1.st2.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"1.0\" display=\"inline\"><semantics id=\"S5.T1.st2.5.5.5.m1.1a\"><mn mathsize=\"50%\" id=\"S5.T1.st2.5.5.5.m1.1.1\" xref=\"S5.T1.st2.5.5.5.m1.1.1.cmml\">1.0</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.st2.5.5.5.m1.1b\"><cn type=\"float\" id=\"S5.T1.st2.5.5.5.m1.1.1.cmml\" xref=\"S5.T1.st2.5.5.5.m1.1.1\">1.0</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.st2.5.5.5.m1.1c\">1.0</annotation></semantics></math></th>\n</tr>\n<tr id=\"S5.T1.st2.5.6.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.6.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" colspan=\"6\"><span id=\"S5.T1.st2.5.6.1.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">CIFAR10 / ResNet18</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.st2.5.7.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.7.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.st2.5.7.1.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">MACs</span></th>\n<td id=\"S5.T1.st2.5.7.1.2\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.7.1.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">23M</span></td>\n<td id=\"S5.T1.st2.5.7.1.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.7.1.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">91M</span></td>\n<td id=\"S5.T1.st2.5.7.1.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.7.1.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">203M</span></td>\n<td id=\"S5.T1.st2.5.7.1.5\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.7.1.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">360M</span></td>\n<td id=\"S5.T1.st2.5.7.1.6\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.7.1.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">555M</span></td>\n</tr>\n<tr id=\"S5.T1.st2.5.8.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.8.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.st2.5.8.2.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Params</span></th>\n<td id=\"S5.T1.st2.5.8.2.2\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.8.2.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">456K</span></td>\n<td id=\"S5.T1.st2.5.8.2.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.8.2.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">2M</span></td>\n<td id=\"S5.T1.st2.5.8.2.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.8.2.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">4M</span></td>\n<td id=\"S5.T1.st2.5.8.2.5\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.8.2.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">7M</span></td>\n<td id=\"S5.T1.st2.5.8.2.6\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.8.2.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">11M</span></td>\n</tr>\n<tr id=\"S5.T1.st2.5.9.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.9.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" colspan=\"6\"><span id=\"S5.T1.st2.5.9.3.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">FEMNIST / CNN</span></th>\n</tr>\n<tr id=\"S5.T1.st2.5.10.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.10.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.st2.5.10.4.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">MACs</span></th>\n<td id=\"S5.T1.st2.5.10.4.2\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.10.4.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">47K</span></td>\n<td id=\"S5.T1.st2.5.10.4.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.10.4.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">120K</span></td>\n<td id=\"S5.T1.st2.5.10.4.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.10.4.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">218K</span></td>\n<td id=\"S5.T1.st2.5.10.4.5\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.10.4.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">342K</span></td>\n<td id=\"S5.T1.st2.5.10.4.6\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.10.4.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">491K</span></td>\n</tr>\n<tr id=\"S5.T1.st2.5.11.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.11.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.st2.5.11.5.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Params</span></th>\n<td id=\"S5.T1.st2.5.11.5.2\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.11.5.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">5K</span></td>\n<td id=\"S5.T1.st2.5.11.5.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.11.5.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">10K</span></td>\n<td id=\"S5.T1.st2.5.11.5.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.11.5.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">15K</span></td>\n<td id=\"S5.T1.st2.5.11.5.5\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.11.5.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">20K</span></td>\n<td id=\"S5.T1.st2.5.11.5.6\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.11.5.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">26K</span></td>\n</tr>\n<tr id=\"S5.T1.st2.5.12.6\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.12.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" colspan=\"6\"><span id=\"S5.T1.st2.5.12.6.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Shakespeare / RNN</span></th>\n</tr>\n<tr id=\"S5.T1.st2.5.13.7\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.13.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T1.st2.5.13.7.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">MACs</span></th>\n<td id=\"S5.T1.st2.5.13.7.2\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.13.7.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">12K</span></td>\n<td id=\"S5.T1.st2.5.13.7.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.13.7.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">40K</span></td>\n<td id=\"S5.T1.st2.5.13.7.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.13.7.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">83K</span></td>\n<td id=\"S5.T1.st2.5.13.7.5\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.13.7.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">143K</span></td>\n<td id=\"S5.T1.st2.5.13.7.6\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.st2.5.13.7.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">216K</span></td>\n</tr>\n<tr id=\"S5.T1.st2.5.14.8\" class=\"ltx_tr\">\n<th id=\"S5.T1.st2.5.14.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.1.1\" class=\"ltx_text\" style=\"font-size:50%;\">Params</span></th>\n<td id=\"S5.T1.st2.5.14.8.2\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.2.1\" class=\"ltx_text\" style=\"font-size:50%;\">12K</span></td>\n<td id=\"S5.T1.st2.5.14.8.3\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.3.1\" class=\"ltx_text\" style=\"font-size:50%;\">40K</span></td>\n<td id=\"S5.T1.st2.5.14.8.4\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.4.1\" class=\"ltx_text\" style=\"font-size:50%;\">82K</span></td>\n<td id=\"S5.T1.st2.5.14.8.5\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.5.1\" class=\"ltx_text\" style=\"font-size:50%;\">142K</span></td>\n<td id=\"S5.T1.st2.5.14.8.6\" class=\"ltx_td ltx_align_right ltx_border_bb\"><span id=\"S5.T1.st2.5.14.8.6.1\" class=\"ltx_text\" style=\"font-size:50%;\">214K</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "More specifically, our technique starts by sampling a value (denoted byÂ pğ‘p) from a distribution of candidate values. Each of these values corresponds to a specific submodel, which in turn gets translated to a specific computational and memory footprint (see TableÂ 1(b)). Such sampled values and associations are depicted in Fig.Â 2. Contrary to conventional dropout (RD), our technique drops adjacent components of the model instead of random neurons, which translates to computational benefits111OD, through its nested pruning scheme that requires neither additional data structures for bookkeeping nor complex and costly data layout transformations, can capitalise directly over the existing and highly optimised dense matrix multiplication libraries. in todayâ€™s linear algebra libraries and higher accuracy as shown later.",
            "Computational and Memory Implications.\n\nThe primary objective of OD is to alleviate the excessive computational and memory demands of the training and inference deployments.\nWhen a layer is shrunk through OD, there is no need to perform the forward and backward passes or gradient updates on the pruned units.\nAs a result, OD offers gains both in terms of FLOP count and model size.\nIn particular, for every fully-connected and convolutional layer, the number of FLOPs and weight parameters is reduced by K1â‹…K2/âŒˆpâ‹…K1âŒ‰â‹…âŒˆpâ‹…K2âŒ‰âˆ¼1/p2similar-toâ‹…subscriptğ¾1subscriptğ¾2â‹…â‹…ğ‘subscriptğ¾1â‹…ğ‘subscriptğ¾21superscriptğ‘2\\nicefrac{{K_{1}\\cdot K_{2}}}{{\\left\\lceil p\\cdot K_{1}\\right\\rceil\\cdot\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p^{2}}}, where K1subscriptğ¾1K_{1} and K2subscriptğ¾2K_{2} correspond to the number of input and output neurons/channels, respectively. Accordingly, the bias terms are reduced by a factor of K2/âŒˆpâ‹…K2âŒ‰âˆ¼1/psimilar-tosubscriptğ¾2â‹…ğ‘subscriptğ¾21ğ‘\\nicefrac{{K_{2}}}{{\\left\\lceil p\\cdot K_{2}\\right\\rceil}}\\sim\\nicefrac{{1}}{{p}}. The normalisation, activation and pooling layers are compressed in terms of FLOPs and parameters similarly to the biases in fully-connected and convolutional layers. This is also evident in TableÂ 1(b).\nFinally, smaller model size also leads to reduced memory footprint for gradients and the optimiserâ€™s state vectors such as momentum. However, how are these submodels related to devices in the wild and how is this getting modelled?",
            "Devices in the wild, however, can have dramatically different capabilities; a fact further exacerbated by the co-existence of previous-generation devices. Modelling discretely each device becomes quickly intractable at scale.\nTherefore, we cluster devices of similar capabilities together and subsequently associate a single pmaxisuperscriptsubscriptğ‘maxğ‘–p_{\\text{max}}^{i} value with each cluster.\nThis clustering can be done heuristically (i.e.Â based on the specifications of the device) or via benchmarking of the model on the actual device and is considered a system-design decision for our paper.\nAs smartphones nowadays run a multitude of simultaneous tasksÂ [46],\nour framework can further support modelling of transient device load by reducing its associated pmaxisuperscriptsubscriptğ‘maxğ‘–p_{\\text{max}}^{i}, which essentially brings the capabilities of the device to a lower tier at run time, thus bringing real-time adaptability to FjORD.",
            "Datasets and Models.\nWe evaluate FjORD on\ntwo vision and one text prediction task, shown in TableÂ 1(a). For CIFAR10Â [36], we use the â€œCIFARâ€ version of ResNet18Â [23]. We federate the dataset by randomly dividing it into equally-sized partitions, each allocated to a specific client, and thus remaining IID in nature.\nFor FEMNIST, we use a CNN with two convolutional layers followed by a\nsoftmax layer. For Shakespeare, we employ a RNN with an embedding layer (without dropout) followed by two LSTMÂ [25] layers and a\nsoftmax layer.\nWe report the modelâ€™s performance of the last epoch on the test set which is constructed by combining the test data for each client.\nWe report top-111 accuracy vision tasks and negative perplexity for text prediction.\nFurther details, such as hyperparameters, description of datasets and models are available in the Appendix.",
            "Communication Optimisation.\nThe majority of existing work has focused on tackling the communication overhead in FL.\n[35] proposed using structured and sketched updates to reduce the transmitted data.\nATOMOÂ [64] introduced a generalised gradient decomposition and sparsification technique, aiming to reduce the gradient sizes communicated upstream. [20] adaptively select the gradientsâ€™ sparsification degree based on the available bandwidth and computational power.\nBuilding upon gradient quantisation methodsÂ [47, 26, 56, 28],\n[2] proposed using quantisation in the model sharing and aggregation steps. However, their scheme requires the same clients to participate across all rounds, and is, thus, unsuitable for realistic settings where clientsâ€™ availability cannot be guaranteed.\nDespite the bandwidth savings, these communication-optimising approaches do not offer computational gains\nnor do they address device heterogeneity.\nNonetheless, they remain orthogonal to our work and can be complementarily combined to further alleviate the communication cost.",
            "While we do target heterogeneous devices found in the wild, such as mobile phones, we have not measured the performance of our technique on such devices, mainly due to the lack of maturity in tools for on-device training.\nHowever, we have demonstrated the performance gains in terms of FLOPs and parameters in TableÂ 1(b), which are directly correlated with on-device performance, memory footprint and communication size. We defer on-device benchmarking and in-the-wild deployment at scale for future work."
        ]
    }
}