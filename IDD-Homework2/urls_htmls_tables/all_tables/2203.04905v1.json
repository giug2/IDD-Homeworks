{
    "S4.T1": {
        "caption": "Table 1: Prediction error (pixel) on euclidean distance in the 2D image plane for Distractor. Different aggregation methods and augmentations are employed. The first row shows results for intra-category (IC) evaluations, the second row for cross-category (CC).",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Methods</th>\n<th id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Mean</th>\n<th id=\"S4.T1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Max</th>\n<th id=\"S4.T1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">BA</th>\n<th id=\"S4.T1.1.1.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">CA</th>\n<th id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Max<sub id=\"S4.T1.1.1.1.1\" class=\"ltx_sub\">FCL</sub>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">No Aug</td>\n<td id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T1.1.2.1.2.1\" class=\"ltx_text ltx_number\">6.02</span></td>\n<td id=\"S4.T1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T1.1.2.1.3.1\" class=\"ltx_text ltx_number\">5.11</span></td>\n<td id=\"S4.T1.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T1.1.2.1.4.1\" class=\"ltx_text ltx_number\">4.63</span></td>\n<td id=\"S4.T1.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T1.1.2.1.5.1\" class=\"ltx_text ltx_number\">5.13</span></td>\n<td id=\"S4.T1.1.2.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T1.1.2.1.6.1\" class=\"ltx_text ltx_number ltx_font_bold\">3.70</span></td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.3.2.1\" class=\"ltx_td\"/>\n<td id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.3.2.2.1\" class=\"ltx_text ltx_number\">6.89</span></td>\n<td id=\"S4.T1.1.3.2.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.3.2.3.1\" class=\"ltx_text ltx_number\">6.17</span></td>\n<td id=\"S4.T1.1.3.2.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.3.2.4.1\" class=\"ltx_text ltx_number\">5.91</span></td>\n<td id=\"S4.T1.1.3.2.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.3.2.5.1\" class=\"ltx_text ltx_number\">6.39</span></td>\n<td id=\"S4.T1.1.3.2.6\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.3.2.6.1\" class=\"ltx_text ltx_number ltx_font_bold\">4.61</span></td>\n</tr>\n<tr id=\"S4.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.4.3.1\" class=\"ltx_td ltx_align_left\">DA</td>\n<td id=\"S4.T1.1.4.3.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.4.3.2.1\" class=\"ltx_text ltx_number\">2.67</span></td>\n<td id=\"S4.T1.1.4.3.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.4.3.3.1\" class=\"ltx_text ltx_number\">2.45</span></td>\n<td id=\"S4.T1.1.4.3.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.4.3.4.1\" class=\"ltx_text ltx_number\">2.44</span></td>\n<td id=\"S4.T1.1.4.3.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.4.3.5.1\" class=\"ltx_text ltx_number\">2.65</span></td>\n<td id=\"S4.T1.1.4.3.6\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.4.3.6.1\" class=\"ltx_text ltx_number ltx_font_bold\">2.00</span></td>\n</tr>\n<tr id=\"S4.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.5.4.1\" class=\"ltx_td\"/>\n<td id=\"S4.T1.1.5.4.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.5.4.2.1\" class=\"ltx_text ltx_number\">4.10</span></td>\n<td id=\"S4.T1.1.5.4.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.5.4.3.1\" class=\"ltx_text ltx_number\">3.75</span></td>\n<td id=\"S4.T1.1.5.4.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.5.4.4.1\" class=\"ltx_text ltx_number\">3.97</span></td>\n<td id=\"S4.T1.1.5.4.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.5.4.5.1\" class=\"ltx_text ltx_number\">4.08</span></td>\n<td id=\"S4.T1.1.5.4.6\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.5.4.6.1\" class=\"ltx_text ltx_number ltx_font_bold\">3.05</span></td>\n</tr>\n<tr id=\"S4.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.6.5.1\" class=\"ltx_td ltx_align_left\">TA</td>\n<td id=\"S4.T1.1.6.5.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.6.5.2.1\" class=\"ltx_text ltx_number\">6.29</span></td>\n<td id=\"S4.T1.1.6.5.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.6.5.3.1\" class=\"ltx_text ltx_number\">6.18</span></td>\n<td id=\"S4.T1.1.6.5.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.6.5.4.1\" class=\"ltx_text ltx_number\">6.33</span></td>\n<td id=\"S4.T1.1.6.5.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.6.5.5.1\" class=\"ltx_text ltx_number\">6.32</span></td>\n<td id=\"S4.T1.1.6.5.6\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.6.5.6.1\" class=\"ltx_text ltx_number ltx_font_bold\">5.45</span></td>\n</tr>\n<tr id=\"S4.T1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.7.6.1\" class=\"ltx_td\"/>\n<td id=\"S4.T1.1.7.6.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.7.6.2.1\" class=\"ltx_text ltx_number\">7.19</span></td>\n<td id=\"S4.T1.1.7.6.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.7.6.3.1\" class=\"ltx_text ltx_number\">7.04</span></td>\n<td id=\"S4.T1.1.7.6.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.7.6.4.1\" class=\"ltx_text ltx_number\">7.02</span></td>\n<td id=\"S4.T1.1.7.6.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.7.6.5.1\" class=\"ltx_text ltx_number\">7.02</span></td>\n<td id=\"S4.T1.1.7.6.6\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.7.6.6.1\" class=\"ltx_text ltx_number ltx_font_bold\">6.66</span></td>\n</tr>\n<tr id=\"S4.T1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.8.7.1\" class=\"ltx_td ltx_align_left\">TA+DA</td>\n<td id=\"S4.T1.1.8.7.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.8.7.2.1\" class=\"ltx_text ltx_number\">3.20</span></td>\n<td id=\"S4.T1.1.8.7.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.8.7.3.1\" class=\"ltx_text ltx_number\">3.09</span></td>\n<td id=\"S4.T1.1.8.7.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.8.7.4.1\" class=\"ltx_text ltx_number\">2.65</span></td>\n<td id=\"S4.T1.1.8.7.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.8.7.5.1\" class=\"ltx_text ltx_number\">3.05</span></td>\n<td id=\"S4.T1.1.8.7.6\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.8.7.6.1\" class=\"ltx_text ltx_number ltx_font_bold\">2.60</span></td>\n</tr>\n<tr id=\"S4.T1.1.9.8\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.9.8.1\" class=\"ltx_td ltx_border_bb\"/>\n<td id=\"S4.T1.1.9.8.2\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T1.1.9.8.2.1\" class=\"ltx_text ltx_number\">6.07</span></td>\n<td id=\"S4.T1.1.9.8.3\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T1.1.9.8.3.1\" class=\"ltx_text ltx_number\">5.14</span></td>\n<td id=\"S4.T1.1.9.8.4\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T1.1.9.8.4.1\" class=\"ltx_text ltx_number\">4.67</span></td>\n<td id=\"S4.T1.1.9.8.5\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T1.1.9.8.5.1\" class=\"ltx_text ltx_number\">4.98</span></td>\n<td id=\"S4.T1.1.9.8.6\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T1.1.9.8.6.1\" class=\"ltx_text ltx_number ltx_font_bold\">3.90</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "DA, DR, TA or MR?\nFrom the results of different experiments presented in Tab. 1, Tab. 2, Tab. 3 and Tab. 4, it is obvious that DA improves the performance across all tasks and methods. Tab. 4 also shows the importance of DR on ShapeNet2D which cannot be simply compensated by DA. TA hinders the performance on Distractor but benefits all pose regression tasks. The reason for this is that, for Distractor, TA increases task complexity by shifting the origin of the image plain by the sampled noise, thus creating N2superscriptN2\\rm{N}^{2} copies of the original task, where N=16N16\\mathrm{N}=16 is the number of non-zero elements in the noise set. However, since these task copies live in independent coordinate frames, the increased task diversity is irrelevant to the original task.\nFor pose regression tasks, by contrast, TA augments the canonical poses of the existing data, which coherently benefits the original task as the augmented canonical poses remain in the coordinate frame of the original task.\nTherefore, even though TA increases the cross-entropy ℋ​(Y|X)ℋconditional𝑌𝑋\\mathcal{H}(Y|X) for both cases as demanded in [31],\nonly the pose regression tasks gain additional benefits. MR results in underfitting as combining MR with augmentations leads to worse performance than using the same augmentations alone for both ShapeNet1D and ShapeNet2D (see Tab. 3 and Tab. 4).\nFurthermore, MR requires extensive fine-tuning on the regularization parameter β𝛽\\beta (see Sec. 3.3) to modulate between underfitting and overfitting.",
            "Effect of the context set size in CNPs.\nWe compare the prediction error w.r.t. the size of the context set for Distractor (see Fig. 2(a)) and ShapeNet2D (see Fig. 2(b)). Both figures show that increasing the context set size benefits the performance, indicating that both Max and CA aggregations can merge useful information from different context pairs and thereby reduce the task ambiguity. In addition, we find that the model can further improve the performance given the size of context set surpasses the maximum number used for training (15 for both tasks). In particular, there is a small performance gap between intra- and cross-category evaluation for Distractor which is however absent for ShapeNet2D. We believe this indicates that Distractor has more task ambiguity than pose estimation and thus explains why Distractor gains more benefits from FCL than ShapeNet2D (see Tab. 1 and Tab. 4).",
            "Furthermore, we find that CA achieves competitive results on all pose estimation tasks but performs slightly worse than BA and Max on Distractor (see Tab. 1) though still better than mean aggregation. This indicates that CA helps in learning representations for object-centric images. Distractor, however, contains objects with random locations, requiring the model to disregard positional information. Methods like CA, which compare similarity between contexts and target over feature space, face inherent difficulties on Distractor. This is due to the fact that CNNs, owing to their translational equivariant nature, are prone to encode some positional information into the extracted image features.\nConsequently, CA, which compares the similarity directly on this feature space, inevitably forces the model to focus on positional similarity, which leads to a suboptimal allocation of importance.",
            "Does FCL improve CNPs?\nTab. 1 shows the evaluation on Distractor using different aggregation methods where MaxFCL denotes Max aggregation with FCL. Modulating task representation by functional contrastive learning (FCL) alleviates meta overfitting across all augmentation levels and thus achieves a significant improvement in performance. Fig. 2(a) further compares the performance of Max and MaxFCL for different context set sizes, showing that our methods can differentiate the queried object and distractors well, even for very small context sets. Furthermore, we investigate the influence of FCL on the predicted task representations over all 12 categories using different clustering metrics, where the results show that FCL leads to a more dispersed latent distribution compared to the original CNPs, which can improve generalization capability to unseen tasks. T-SNE visualizations of the task representations along with the results of cluster metrics are provided in Sec. A.1.",
            "FCL on different sets.\nWe compare FCL on three choices of positive pairs: i) We use the same context set but with different data augmentations. ii) We use different context sets sampled from the same task. iii) We use context and target sets from the same task. We test the performance on Distractor using Max aggregation and DA. For each choice, we run three experiments with different seeds and present the average performance in Tab. 8. Compared to Tab. 1, all three choices consistently outperform CNP (Max) while using FCL on context and target sets achieves the best performance."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Pascal1D pose estimation error. MSE and standard deviations are calculated with 5 random seeds.",
        "table": "<table id=\"S4.T2.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">Methods</th>\n<td id=\"S4.T2.2.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\">MAML</td>\n<td id=\"S4.T2.2.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_tt\">CNP (Mean)</td>\n<td id=\"S4.T2.2.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_tt\">CNP (CA)</td>\n</tr>\n<tr id=\"S4.T2.2.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">No Aug</th>\n<td id=\"S4.T2.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T2.2.2.2.2.1\" class=\"ltx_text ltx_number\">1.69</span> (<span id=\"S4.T2.2.2.2.2.2\" class=\"ltx_text ltx_number\">0.22</span>)</td>\n<td id=\"S4.T2.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T2.2.2.2.3.1\" class=\"ltx_text ltx_number\">5.28</span> (<span id=\"S4.T2.2.2.2.3.2\" class=\"ltx_text ltx_number\">0.51</span>)</td>\n<td id=\"S4.T2.2.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T2.2.2.2.4.1\" class=\"ltx_text ltx_number\">4.66</span> (<span id=\"S4.T2.2.2.2.4.2\" class=\"ltx_text ltx_number\">0.74</span>)</td>\n</tr>\n<tr id=\"S4.T2.2.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MR</th>\n<td id=\"S4.T2.2.3.3.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T2.2.3.3.2.1\" class=\"ltx_text ltx_number\">1.90</span> (<span id=\"S4.T2.2.3.3.2.2\" class=\"ltx_text ltx_number\">0.27</span>)</td>\n<td id=\"S4.T2.2.3.3.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T2.2.3.3.3.1\" class=\"ltx_text ltx_number\">2.96</span> (<span id=\"S4.T2.2.3.3.3.2\" class=\"ltx_text ltx_number\">0.21</span>)</td>\n<td id=\"S4.T2.2.3.3.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T2.2.3.3.4.1\" class=\"ltx_text ltx_number\">3.33</span> (<span id=\"S4.T2.2.3.3.4.2\" class=\"ltx_text ltx_number\">0.27</span>)</td>\n</tr>\n<tr id=\"S4.T2.2.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">TA</th>\n<td id=\"S4.T2.2.4.4.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T2.2.4.4.2.1\" class=\"ltx_text ltx_number ltx_font_bold\">1.02</span><span id=\"S4.T2.2.4.4.2.2\" class=\"ltx_text ltx_font_bold\"> (<span id=\"S4.T2.2.4.4.2.2.1\" class=\"ltx_text ltx_number\">0.06</span>)</span>\n</td>\n<td id=\"S4.T2.2.4.4.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T2.2.4.4.3.1\" class=\"ltx_text ltx_number ltx_font_bold\">1.98</span><span id=\"S4.T2.2.4.4.3.2\" class=\"ltx_text ltx_font_bold\"> (<span id=\"S4.T2.2.4.4.3.2.1\" class=\"ltx_text ltx_number\">0.22</span>)</span>\n</td>\n<td id=\"S4.T2.2.4.4.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T2.2.4.4.4.1\" class=\"ltx_text ltx_number ltx_font_bold\">1.36</span><span id=\"S4.T2.2.4.4.4.2\" class=\"ltx_text ltx_font_bold\"> (<span id=\"S4.T2.2.4.4.4.2.1\" class=\"ltx_text ltx_number\">0.25</span>)</span>\n</td>\n</tr>\n<tr id=\"S4.T2.2.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DA</th>\n<td id=\"S4.T2.2.5.5.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T2.2.5.5.2.1\" class=\"ltx_text ltx_number\">2.10</span> (<span id=\"S4.T2.2.5.5.2.2\" class=\"ltx_text ltx_number\">0.09</span>)</td>\n<td id=\"S4.T2.2.5.5.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T2.2.5.5.3.1\" class=\"ltx_text ltx_number\">3.69</span> (<span id=\"S4.T2.2.5.5.3.2\" class=\"ltx_text ltx_number\">0.13</span>)</td>\n<td id=\"S4.T2.2.5.5.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T2.2.5.5.4.1\" class=\"ltx_text ltx_number\">2.90</span> (<span id=\"S4.T2.2.5.5.4.2\" class=\"ltx_text ltx_number\">0.03</span>)</td>\n</tr>\n<tr id=\"S4.T2.2.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">TA+DA</th>\n<td id=\"S4.T2.2.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T2.2.6.6.2.1\" class=\"ltx_text ltx_number\">1.31</span> (<span id=\"S4.T2.2.6.6.2.2\" class=\"ltx_text ltx_number\">0.14</span>)</td>\n<td id=\"S4.T2.2.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T2.2.6.6.3.1\" class=\"ltx_text ltx_number\">2.29</span> (<span id=\"S4.T2.2.6.6.3.2\" class=\"ltx_text ltx_number\">0.19</span>)</td>\n<td id=\"S4.T2.2.6.6.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T2.2.6.6.4.1\" class=\"ltx_text ltx_number\">1.77</span> (<span id=\"S4.T2.2.6.6.4.2\" class=\"ltx_text ltx_number\">0.33</span>)</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "MAML or CNPs?\nWe compare MAML and CNPs on two pose estimation datasets, Pascal1D and ShapeNet1D. We obtain similar results as  [46, 31] on Pascal1D, where MAML performs better than CNPs and the latter shows more severe overfitting (see Tab. 2).\nHowever, Tab. 3 illustrates that both CNP variants outperform MAML with a large margin on ShapeNet1D.\nIt is good to note that, the prediction errors of all methods in Tab. 2 after denormalizing are larger than 30∘, indicating the experiments of prior work on Pascal1D simply used too little meta-data to make informative conclusions about the quality of different algorithms.\nOur interpretation is that MAML tries to learn a good initial prior (global optimum) which needs to be optimized on each specific task (fine-tuned optimum) within few samples and updates. On small datasets, MAML can easily find a global optimum that satisfies all the training tasks. At the same time MAML also overfits less, since the fine-tuning from global to fine-tuned optimum happens during inference time.\nHowever, finding a global optimum is getting difficult for large-scale datasets due to the increasing task diversity. Consequently, more samples and updates are necessary to fine-tune the task-specific parameters ϕitalic-ϕ\\phi (see Sec. 3), which also explains why MAML is sensitive to hyperparameter tuning [1]. Furthermore, MAML shows much longer training times than CNPs, which limits us to conduct exhaustive comparisons on more complicated tasks such as Distractor or ShapeNet2D. In contrast, CNPs use the local parameterization ϕitalic-ϕ\\phi as a fixed dimensional output of the encoder, which forces the model to learn an informative low-rank representation from the contexts. Meanwhile, increasing data and task diversity will encourage the model to extract more expressive and mutual-exclusive task representations.",
            "DA, DR, TA or MR?\nFrom the results of different experiments presented in Tab. 1, Tab. 2, Tab. 3 and Tab. 4, it is obvious that DA improves the performance across all tasks and methods. Tab. 4 also shows the importance of DR on ShapeNet2D which cannot be simply compensated by DA. TA hinders the performance on Distractor but benefits all pose regression tasks. The reason for this is that, for Distractor, TA increases task complexity by shifting the origin of the image plain by the sampled noise, thus creating N2superscriptN2\\rm{N}^{2} copies of the original task, where N=16N16\\mathrm{N}=16 is the number of non-zero elements in the noise set. However, since these task copies live in independent coordinate frames, the increased task diversity is irrelevant to the original task.\nFor pose regression tasks, by contrast, TA augments the canonical poses of the existing data, which coherently benefits the original task as the augmented canonical poses remain in the coordinate frame of the original task.\nTherefore, even though TA increases the cross-entropy ℋ​(Y|X)ℋconditional𝑌𝑋\\mathcal{H}(Y|X) for both cases as demanded in [31],\nonly the pose regression tasks gain additional benefits. MR results in underfitting as combining MR with augmentations leads to worse performance than using the same augmentations alone for both ShapeNet1D and ShapeNet2D (see Tab. 3 and Tab. 4).\nFurthermore, MR requires extensive fine-tuning on the regularization parameter β𝛽\\beta (see Sec. 3.3) to modulate between underfitting and overfitting.",
            "Which aggregation methods should I use?\nCross-attention (CA) performs better than mean aggregation on Pascal1D (see Tab. 2) and Max on ShapeNet1D (see Tab. 3), while it achieves a similar performance to Max aggregation and BA on ShapeNet2D (see Tab. 6). In contrast, mean aggregation used in the original CNP performs the worst on both Pascal1D and ShapeNet2D. Our interpretation is that Mean assigns the same importance to each context while the other aggregation operators can allocate different weights. Max assigns a weight of one to a context and zero to all others for each dimension of the representation while BA assigns the weights predicted by another neural network. Meanwhile, CA assigns importance by comparing the similarity between context inputs {xCi}i=1Ksuperscriptsubscriptsuperscriptsubscript𝑥𝐶𝑖𝑖1𝐾\\{x_{C}^{i}\\}_{i=1}^{K} and target input xTsubscript𝑥𝑇x_{T} at the feature space."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: ShapeNet1D pose estimation error(∘). Results are calculated with 5 random seeds except for MAML. The first row presents results for IC and the second row for CC.",
        "table": "<table id=\"S4.T3.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.2.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Methods</th>\n<th id=\"S4.T3.2.3.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">MAML</th>\n<th id=\"S4.T3.2.3.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">CNP (Max)</th>\n<th id=\"S4.T3.2.3.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">CNP (CA)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.2.4.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">No Aug</th>\n<th id=\"S4.T3.2.4.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S4.T3.2.4.1.2.1\" class=\"ltx_text ltx_number\">25.27</span></th>\n<td id=\"S4.T3.2.4.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T3.2.4.1.3.1\" class=\"ltx_text ltx_number\">14.97</span> (<span id=\"S4.T3.2.4.1.3.2\" class=\"ltx_text ltx_number\">0.37</span>)</td>\n<td id=\"S4.T3.2.4.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T3.2.4.1.4.1\" class=\"ltx_text ltx_number\">8.19</span> (<span id=\"S4.T3.2.4.1.4.2\" class=\"ltx_text ltx_number\">0.30</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.5.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.5.2.1\" class=\"ltx_td ltx_th ltx_th_row\"/>\n<th id=\"S4.T3.2.5.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.2.5.2.2.1\" class=\"ltx_text ltx_number\">21.63</span></th>\n<td id=\"S4.T3.2.5.2.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.5.2.3.1\" class=\"ltx_text ltx_number\">18.09</span> (<span id=\"S4.T3.2.5.2.3.2\" class=\"ltx_text ltx_number\">0.21</span>)</td>\n<td id=\"S4.T3.2.5.2.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.5.2.4.1\" class=\"ltx_text ltx_number\">9.13</span> (<span id=\"S4.T3.2.5.2.4.2\" class=\"ltx_text ltx_number\">0.18</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.6.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.6.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MR</th>\n<th id=\"S4.T3.2.6.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.2.6.3.2.1\" class=\"ltx_text ltx_number\">13.23</span></th>\n<td id=\"S4.T3.2.6.3.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.6.3.3.1\" class=\"ltx_text ltx_number\">12.71</span> (<span id=\"S4.T3.2.6.3.3.2\" class=\"ltx_text ltx_number\">0.26</span>)</td>\n<td id=\"S4.T3.2.6.3.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.6.3.4.1\" class=\"ltx_text ltx_number\">8.87</span> (<span id=\"S4.T3.2.6.3.4.2\" class=\"ltx_text ltx_number\">0.36</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.7.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.7.4.1\" class=\"ltx_td ltx_th ltx_th_row\"/>\n<th id=\"S4.T3.2.7.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.2.7.4.2.1\" class=\"ltx_text ltx_number\">16.55</span></th>\n<td id=\"S4.T3.2.7.4.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.7.4.3.1\" class=\"ltx_text ltx_number\">14.77</span> (<span id=\"S4.T3.2.7.4.3.2\" class=\"ltx_text ltx_number\">0.35</span>)</td>\n<td id=\"S4.T3.2.7.4.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.7.4.4.1\" class=\"ltx_text ltx_number\">8.43</span> (<span id=\"S4.T3.2.7.4.4.2\" class=\"ltx_text ltx_number\">0.39</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.8.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.8.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">TA</th>\n<th id=\"S4.T3.2.8.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.2.8.5.2.1\" class=\"ltx_text ltx_number\">23.01</span></th>\n<td id=\"S4.T3.2.8.5.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.8.5.3.1\" class=\"ltx_text ltx_number\">10.89</span> (<span id=\"S4.T3.2.8.5.3.2\" class=\"ltx_text ltx_number\">0.27</span>)</td>\n<td id=\"S4.T3.2.8.5.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.8.5.4.1\" class=\"ltx_text ltx_number\">7.92</span> (<span id=\"S4.T3.2.8.5.4.2\" class=\"ltx_text ltx_number\">0.25</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.9.6\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.9.6.1\" class=\"ltx_td ltx_th ltx_th_row\"/>\n<th id=\"S4.T3.2.9.6.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.2.9.6.2.1\" class=\"ltx_text ltx_number\">20.59</span></th>\n<td id=\"S4.T3.2.9.6.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.9.6.3.1\" class=\"ltx_text ltx_number\">14.43</span> (<span id=\"S4.T3.2.9.6.3.2\" class=\"ltx_text ltx_number\">0.55</span>)</td>\n<td id=\"S4.T3.2.9.6.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.9.6.4.1\" class=\"ltx_text ltx_number\">9.18</span> (<span id=\"S4.T3.2.9.6.4.2\" class=\"ltx_text ltx_number\">0.50</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.10.7\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.10.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DA</th>\n<th id=\"S4.T3.2.10.7.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.2.10.7.2.1\" class=\"ltx_text ltx_number\">14.69</span></th>\n<td id=\"S4.T3.2.10.7.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.10.7.3.1\" class=\"ltx_text ltx_number\">8.64</span> (<span id=\"S4.T3.2.10.7.3.2\" class=\"ltx_text ltx_number\">0.21</span>)</td>\n<td id=\"S4.T3.2.10.7.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.10.7.4.1\" class=\"ltx_text ltx_number\">6.24</span> (<span id=\"S4.T3.2.10.7.4.2\" class=\"ltx_text ltx_number\">0.15</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.11.8\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.11.8.1\" class=\"ltx_td ltx_th ltx_th_row\"/>\n<th id=\"S4.T3.2.11.8.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.2.11.8.2.1\" class=\"ltx_text ltx_number\">16.02</span></th>\n<td id=\"S4.T3.2.11.8.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.11.8.3.1\" class=\"ltx_text ltx_number\">9.87</span> (<span id=\"S4.T3.2.11.8.3.2\" class=\"ltx_text ltx_number\">0.35</span>)</td>\n<td id=\"S4.T3.2.11.8.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.11.8.4.1\" class=\"ltx_text ltx_number\">6.54</span> (<span id=\"S4.T3.2.11.8.4.2\" class=\"ltx_text ltx_number\">0.19</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.12.9\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.12.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">TA+DA</th>\n<th id=\"S4.T3.2.12.9.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.2.12.9.2.1\" class=\"ltx_text ltx_number\">17.96</span></th>\n<td id=\"S4.T3.2.12.9.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.12.9.3.1\" class=\"ltx_text ltx_number\">7.66</span> (<span id=\"S4.T3.2.12.9.3.2\" class=\"ltx_text ltx_number\">0.18</span>)</td>\n<td id=\"S4.T3.2.12.9.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.12.9.4.1\" class=\"ltx_text ltx_number ltx_font_bold\">5.81</span><span id=\"S4.T3.2.12.9.4.2\" class=\"ltx_text ltx_font_bold\"> (<span id=\"S4.T3.2.12.9.4.2.1\" class=\"ltx_text ltx_number\">0.23</span>)</span>\n</td>\n</tr>\n<tr id=\"S4.T3.2.13.10\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.13.10.1\" class=\"ltx_td ltx_th ltx_th_row\"/>\n<th id=\"S4.T3.2.13.10.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.2.13.10.2.1\" class=\"ltx_text ltx_number\">18.79</span></th>\n<td id=\"S4.T3.2.13.10.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.13.10.3.1\" class=\"ltx_text ltx_number\">8.66</span> (<span id=\"S4.T3.2.13.10.3.2\" class=\"ltx_text ltx_number\">0.19</span>)</td>\n<td id=\"S4.T3.2.13.10.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.13.10.4.1\" class=\"ltx_text ltx_number ltx_font_bold\">6.23</span><span id=\"S4.T3.2.13.10.4.2\" class=\"ltx_text ltx_font_bold\"> (<span id=\"S4.T3.2.13.10.4.2.1\" class=\"ltx_text ltx_number\">0.12</span>)</span>\n</td>\n</tr>\n<tr id=\"S4.T3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">TA+DA+FCL</th>\n<th id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><math id=\"S4.T3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\hskip 7.0pt-\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.m1.1a\"><mo id=\"S4.T3.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.m1.1.1.cmml\">−</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.m1.1b\"><minus id=\"S4.T3.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.m1.1c\">\\hskip 7.0pt-</annotation></semantics></math></th>\n<td id=\"S4.T3.1.1.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.1.1.3.1\" class=\"ltx_text ltx_number\">7.82</span> (<span id=\"S4.T3.1.1.3.2\" class=\"ltx_text ltx_number\">0.08</span>)</td>\n<td id=\"S4.T3.1.1.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.1.1.4.1\" class=\"ltx_text ltx_number\">6.44</span> (<span id=\"S4.T3.1.1.4.2\" class=\"ltx_text ltx_number\">0.36</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.2.2\" class=\"ltx_td ltx_th ltx_th_row\"/>\n<th id=\"S4.T3.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><math id=\"S4.T3.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\hskip 7.0pt-\" display=\"inline\"><semantics id=\"S4.T3.2.2.1.m1.1a\"><mo id=\"S4.T3.2.2.1.m1.1.1\" xref=\"S4.T3.2.2.1.m1.1.1.cmml\">−</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.1.m1.1b\"><minus id=\"S4.T3.2.2.1.m1.1.1.cmml\" xref=\"S4.T3.2.2.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.1.m1.1c\">\\hskip 7.0pt-</annotation></semantics></math></th>\n<td id=\"S4.T3.2.2.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.2.3.1\" class=\"ltx_text ltx_number\">8.84</span> (<span id=\"S4.T3.2.2.3.2\" class=\"ltx_text ltx_number\">0.04</span>)</td>\n<td id=\"S4.T3.2.2.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.2.4.1\" class=\"ltx_text ltx_number\">6.74</span> (<span id=\"S4.T3.2.2.4.2\" class=\"ltx_text ltx_number\">0.20</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.14.11\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.14.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">TA+DA+MR</th>\n<th id=\"S4.T3.2.14.11.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.2.14.11.2.1\" class=\"ltx_text ltx_number\">13.45</span></th>\n<td id=\"S4.T3.2.14.11.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.14.11.3.1\" class=\"ltx_text ltx_number\">10.54</span> (<span id=\"S4.T3.2.14.11.3.2\" class=\"ltx_text ltx_number\">0.37</span>)</td>\n<td id=\"S4.T3.2.14.11.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T3.2.14.11.4.1\" class=\"ltx_text ltx_number\">8.28</span> (<span id=\"S4.T3.2.14.11.4.2\" class=\"ltx_text ltx_number\">0.17</span>)</td>\n</tr>\n<tr id=\"S4.T3.2.15.12\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.15.12.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_bb\"/>\n<th id=\"S4.T3.2.15.12.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S4.T3.2.15.12.2.1\" class=\"ltx_text ltx_number\">14.44</span></th>\n<td id=\"S4.T3.2.15.12.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T3.2.15.12.3.1\" class=\"ltx_text ltx_number\">10.76</span> (<span id=\"S4.T3.2.15.12.3.2\" class=\"ltx_text ltx_number\">0.30</span>)</td>\n<td id=\"S4.T3.2.15.12.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T3.2.15.12.4.1\" class=\"ltx_text ltx_number\">8.04</span> (<span id=\"S4.T3.2.15.12.4.2\" class=\"ltx_text ltx_number\">0.10</span>)</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "MAML or CNPs?\nWe compare MAML and CNPs on two pose estimation datasets, Pascal1D and ShapeNet1D. We obtain similar results as  [46, 31] on Pascal1D, where MAML performs better than CNPs and the latter shows more severe overfitting (see Tab. 2).\nHowever, Tab. 3 illustrates that both CNP variants outperform MAML with a large margin on ShapeNet1D.\nIt is good to note that, the prediction errors of all methods in Tab. 2 after denormalizing are larger than 30∘, indicating the experiments of prior work on Pascal1D simply used too little meta-data to make informative conclusions about the quality of different algorithms.\nOur interpretation is that MAML tries to learn a good initial prior (global optimum) which needs to be optimized on each specific task (fine-tuned optimum) within few samples and updates. On small datasets, MAML can easily find a global optimum that satisfies all the training tasks. At the same time MAML also overfits less, since the fine-tuning from global to fine-tuned optimum happens during inference time.\nHowever, finding a global optimum is getting difficult for large-scale datasets due to the increasing task diversity. Consequently, more samples and updates are necessary to fine-tune the task-specific parameters ϕitalic-ϕ\\phi (see Sec. 3), which also explains why MAML is sensitive to hyperparameter tuning [1]. Furthermore, MAML shows much longer training times than CNPs, which limits us to conduct exhaustive comparisons on more complicated tasks such as Distractor or ShapeNet2D. In contrast, CNPs use the local parameterization ϕitalic-ϕ\\phi as a fixed dimensional output of the encoder, which forces the model to learn an informative low-rank representation from the contexts. Meanwhile, increasing data and task diversity will encourage the model to extract more expressive and mutual-exclusive task representations.",
            "DA, DR, TA or MR?\nFrom the results of different experiments presented in Tab. 1, Tab. 2, Tab. 3 and Tab. 4, it is obvious that DA improves the performance across all tasks and methods. Tab. 4 also shows the importance of DR on ShapeNet2D which cannot be simply compensated by DA. TA hinders the performance on Distractor but benefits all pose regression tasks. The reason for this is that, for Distractor, TA increases task complexity by shifting the origin of the image plain by the sampled noise, thus creating N2superscriptN2\\rm{N}^{2} copies of the original task, where N=16N16\\mathrm{N}=16 is the number of non-zero elements in the noise set. However, since these task copies live in independent coordinate frames, the increased task diversity is irrelevant to the original task.\nFor pose regression tasks, by contrast, TA augments the canonical poses of the existing data, which coherently benefits the original task as the augmented canonical poses remain in the coordinate frame of the original task.\nTherefore, even though TA increases the cross-entropy ℋ​(Y|X)ℋconditional𝑌𝑋\\mathcal{H}(Y|X) for both cases as demanded in [31],\nonly the pose regression tasks gain additional benefits. MR results in underfitting as combining MR with augmentations leads to worse performance than using the same augmentations alone for both ShapeNet1D and ShapeNet2D (see Tab. 3 and Tab. 4).\nFurthermore, MR requires extensive fine-tuning on the regularization parameter β𝛽\\beta (see Sec. 3.3) to modulate between underfitting and overfitting.",
            "Which aggregation methods should I use?\nCross-attention (CA) performs better than mean aggregation on Pascal1D (see Tab. 2) and Max on ShapeNet1D (see Tab. 3), while it achieves a similar performance to Max aggregation and BA on ShapeNet2D (see Tab. 6). In contrast, mean aggregation used in the original CNP performs the worst on both Pascal1D and ShapeNet2D. Our interpretation is that Mean assigns the same importance to each context while the other aggregation operators can allocate different weights. Max assigns a weight of one to a context and zero to all others for each dimension of the representation while BA assigns the weights predicted by another neural network. Meanwhile, CA assigns importance by comparing the similarity between context inputs {xCi}i=1Ksuperscriptsubscriptsuperscriptsubscript𝑥𝐶𝑖𝑖1𝐾\\{x_{C}^{i}\\}_{i=1}^{K} and target input xTsubscript𝑥𝑇x_{T} at the feature space.",
            "How much meta-data is essential?\nWe split the training data of ShapeNet1D into subsets of three different sizes, with 10 objects per category for the small dataset (S), 30 objects per category for the medium dataset (M) and 50 for the large dataset (L). Afterwards, we test the performance of CNP with Max aggregation and CA on each of them. The results in Tab. 5 show that Max overfits on the small dataset by simply memorizing all training tasks while CA works much better. Moreover, CA trained on small dataset achieves a comparable performance with Max on large dataset after using TA and DA, and even outperforms Max on the cross-category level. Thus, we conclude that using CA in combination with augmentation techniques can drastically alleviate the overfitting problem and therefore requires less meta-data on object-centric vision tasks than Max. In contrast, MAML performs much worse on ShapeNet1D (L) (see Tab. 3) than CNPs and thus hardly profits from an increased dataset."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Comparison of different augmentation techniques on ShapeNet2D. Results are calculated with 3 random seeds using CNP (CA) as baseline.",
        "table": "<table id=\"S4.T4.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">Methods</th>\n<td id=\"S4.T4.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">IC (<math id=\"S4.T4.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"1e^{-2}\" display=\"inline\"><semantics id=\"S4.T4.1.1.1.m1.1a\"><mrow id=\"S4.T4.1.1.1.m1.1.1\" xref=\"S4.T4.1.1.1.m1.1.1.cmml\"><mn id=\"S4.T4.1.1.1.m1.1.1.2\" xref=\"S4.T4.1.1.1.m1.1.1.2.cmml\">1</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T4.1.1.1.m1.1.1.1\" xref=\"S4.T4.1.1.1.m1.1.1.1.cmml\">​</mo><msup id=\"S4.T4.1.1.1.m1.1.1.3\" xref=\"S4.T4.1.1.1.m1.1.1.3.cmml\"><mi id=\"S4.T4.1.1.1.m1.1.1.3.2\" xref=\"S4.T4.1.1.1.m1.1.1.3.2.cmml\">e</mi><mrow id=\"S4.T4.1.1.1.m1.1.1.3.3\" xref=\"S4.T4.1.1.1.m1.1.1.3.3.cmml\"><mo id=\"S4.T4.1.1.1.m1.1.1.3.3a\" xref=\"S4.T4.1.1.1.m1.1.1.3.3.cmml\">−</mo><mn id=\"S4.T4.1.1.1.m1.1.1.3.3.2\" xref=\"S4.T4.1.1.1.m1.1.1.3.3.2.cmml\">2</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.1.1.1.m1.1b\"><apply id=\"S4.T4.1.1.1.m1.1.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1\"><times id=\"S4.T4.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.1\"/><cn type=\"integer\" id=\"S4.T4.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.2\">1</cn><apply id=\"S4.T4.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T4.1.1.1.m1.1.1.3.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3\">superscript</csymbol><ci id=\"S4.T4.1.1.1.m1.1.1.3.2.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3.2\">𝑒</ci><apply id=\"S4.T4.1.1.1.m1.1.1.3.3.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3.3\"><minus id=\"S4.T4.1.1.1.m1.1.1.3.3.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3.3\"/><cn type=\"integer\" id=\"S4.T4.1.1.1.m1.1.1.3.3.2.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3.3.2\">2</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.1.1.1.m1.1c\">1e^{-2}</annotation></semantics></math>)</td>\n<td id=\"S4.T4.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_tt\">CC (<math id=\"S4.T4.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"1e^{-2}\" display=\"inline\"><semantics id=\"S4.T4.2.2.2.m1.1a\"><mrow id=\"S4.T4.2.2.2.m1.1.1\" xref=\"S4.T4.2.2.2.m1.1.1.cmml\"><mn id=\"S4.T4.2.2.2.m1.1.1.2\" xref=\"S4.T4.2.2.2.m1.1.1.2.cmml\">1</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T4.2.2.2.m1.1.1.1\" xref=\"S4.T4.2.2.2.m1.1.1.1.cmml\">​</mo><msup id=\"S4.T4.2.2.2.m1.1.1.3\" xref=\"S4.T4.2.2.2.m1.1.1.3.cmml\"><mi id=\"S4.T4.2.2.2.m1.1.1.3.2\" xref=\"S4.T4.2.2.2.m1.1.1.3.2.cmml\">e</mi><mrow id=\"S4.T4.2.2.2.m1.1.1.3.3\" xref=\"S4.T4.2.2.2.m1.1.1.3.3.cmml\"><mo id=\"S4.T4.2.2.2.m1.1.1.3.3a\" xref=\"S4.T4.2.2.2.m1.1.1.3.3.cmml\">−</mo><mn id=\"S4.T4.2.2.2.m1.1.1.3.3.2\" xref=\"S4.T4.2.2.2.m1.1.1.3.3.2.cmml\">2</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.2.2.2.m1.1b\"><apply id=\"S4.T4.2.2.2.m1.1.1.cmml\" xref=\"S4.T4.2.2.2.m1.1.1\"><times id=\"S4.T4.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T4.2.2.2.m1.1.1.1\"/><cn type=\"integer\" id=\"S4.T4.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T4.2.2.2.m1.1.1.2\">1</cn><apply id=\"S4.T4.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T4.2.2.2.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T4.2.2.2.m1.1.1.3.1.cmml\" xref=\"S4.T4.2.2.2.m1.1.1.3\">superscript</csymbol><ci id=\"S4.T4.2.2.2.m1.1.1.3.2.cmml\" xref=\"S4.T4.2.2.2.m1.1.1.3.2\">𝑒</ci><apply id=\"S4.T4.2.2.2.m1.1.1.3.3.cmml\" xref=\"S4.T4.2.2.2.m1.1.1.3.3\"><minus id=\"S4.T4.2.2.2.m1.1.1.3.3.1.cmml\" xref=\"S4.T4.2.2.2.m1.1.1.3.3\"/><cn type=\"integer\" id=\"S4.T4.2.2.2.m1.1.1.3.3.2.cmml\" xref=\"S4.T4.2.2.2.m1.1.1.3.3.2\">2</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.2.2.2.m1.1c\">1e^{-2}</annotation></semantics></math>)</td>\n</tr>\n<tr id=\"S4.T4.6.7.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.6.7.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">None</th>\n<td id=\"S4.T4.6.7.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T4.6.7.1.2.1\" class=\"ltx_text ltx_number\">38.33</span> (<span id=\"S4.T4.6.7.1.2.2\" class=\"ltx_text ltx_number\">0.33</span>)</td>\n<td id=\"S4.T4.6.7.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T4.6.7.1.3.1\" class=\"ltx_text ltx_number\">39.81</span> (<span id=\"S4.T4.6.7.1.3.2\" class=\"ltx_text ltx_number\">0.31</span>)</td>\n</tr>\n<tr id=\"S4.T4.6.8.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.6.8.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DR</th>\n<td id=\"S4.T4.6.8.2.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.6.8.2.2.1\" class=\"ltx_text ltx_number\">18.67</span> (<span id=\"S4.T4.6.8.2.2.2\" class=\"ltx_text ltx_number\">0.13</span>)</td>\n<td id=\"S4.T4.6.8.2.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.6.8.2.3.1\" class=\"ltx_text ltx_number\">20.05</span> (<span id=\"S4.T4.6.8.2.3.2\" class=\"ltx_text ltx_number\">0.12</span>)</td>\n</tr>\n<tr id=\"S4.T4.6.9.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.6.9.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DR+MR</th>\n<td id=\"S4.T4.6.9.3.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.6.9.3.2.1\" class=\"ltx_text ltx_number\">27.89</span> (<span id=\"S4.T4.6.9.3.2.2\" class=\"ltx_text ltx_number\">0.61</span>)</td>\n<td id=\"S4.T4.6.9.3.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.6.9.3.3.1\" class=\"ltx_text ltx_number\">28.99</span> (<span id=\"S4.T4.6.9.3.3.2\" class=\"ltx_text ltx_number\">0.46</span>)</td>\n</tr>\n<tr id=\"S4.T4.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DR+TA<sub id=\"S4.T4.3.3.1.1\" class=\"ltx_sub\">azi</sub>\n</th>\n<td id=\"S4.T4.3.3.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.3.3.2.1\" class=\"ltx_text ltx_number\">16.94</span> (<span id=\"S4.T4.3.3.2.2\" class=\"ltx_text ltx_number\">0.13</span>)</td>\n<td id=\"S4.T4.3.3.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.3.3.3.1\" class=\"ltx_text ltx_number\">18.42</span> (<span id=\"S4.T4.3.3.3.2\" class=\"ltx_text ltx_number\">0.26</span>)</td>\n</tr>\n<tr id=\"S4.T4.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DR+TA<sub id=\"S4.T4.4.4.1.1\" class=\"ltx_sub\">azi+ele</sub>\n</th>\n<td id=\"S4.T4.4.4.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.4.4.2.1\" class=\"ltx_text ltx_number\">16.62</span> (<span id=\"S4.T4.4.4.2.2\" class=\"ltx_text ltx_number\">0.12</span>)</td>\n<td id=\"S4.T4.4.4.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.4.4.3.1\" class=\"ltx_text ltx_number\">17.76</span> (<span id=\"S4.T4.4.4.3.2\" class=\"ltx_text ltx_number\">0.35</span>)</td>\n</tr>\n<tr id=\"S4.T4.6.10.4\" class=\"ltx_tr\">\n<th id=\"S4.T4.6.10.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DA</th>\n<td id=\"S4.T4.6.10.4.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.6.10.4.2.1\" class=\"ltx_text ltx_number\">19.32</span> (<span id=\"S4.T4.6.10.4.2.2\" class=\"ltx_text ltx_number\">0.09</span>)</td>\n<td id=\"S4.T4.6.10.4.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.6.10.4.3.1\" class=\"ltx_text ltx_number\">17.98</span> (<span id=\"S4.T4.6.10.4.3.2\" class=\"ltx_text ltx_number\">0.09</span>)</td>\n</tr>\n<tr id=\"S4.T4.6.11.5\" class=\"ltx_tr\">\n<th id=\"S4.T4.6.11.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DR+DA</th>\n<td id=\"S4.T4.6.11.5.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.6.11.5.2.1\" class=\"ltx_text ltx_number\">14.26</span> (<span id=\"S4.T4.6.11.5.2.2\" class=\"ltx_text ltx_number\">0.09</span>)</td>\n<td id=\"S4.T4.6.11.5.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.6.11.5.3.1\" class=\"ltx_text ltx_number\">13.91</span> (<span id=\"S4.T4.6.11.5.3.2\" class=\"ltx_text ltx_number\">0.14</span>)</td>\n</tr>\n<tr id=\"S4.T4.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T4.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DR+DA+TA<sub id=\"S4.T4.5.5.1.1\" class=\"ltx_sub\">azi+ele</sub>\n</th>\n<td id=\"S4.T4.5.5.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.5.5.2.1\" class=\"ltx_text ltx_number\">14.12</span> (<span id=\"S4.T4.5.5.2.2\" class=\"ltx_text ltx_number\">0.14</span>)</td>\n<td id=\"S4.T4.5.5.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T4.5.5.3.1\" class=\"ltx_text ltx_number\">13.59</span> (<span id=\"S4.T4.5.5.3.2\" class=\"ltx_text ltx_number\">0.10</span>)</td>\n</tr>\n<tr id=\"S4.T4.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T4.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">DR+DA+TA<sub id=\"S4.T4.6.6.1.1\" class=\"ltx_sub\">azi+ele</sub> + FCL</th>\n<td id=\"S4.T4.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T4.6.6.2.1\" class=\"ltx_text ltx_number ltx_font_bold\">14.01</span><span id=\"S4.T4.6.6.2.2\" class=\"ltx_text ltx_font_bold\"> (<span id=\"S4.T4.6.6.2.2.1\" class=\"ltx_text ltx_number\">0.09</span>)</span>\n</td>\n<td id=\"S4.T4.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T4.6.6.3.1\" class=\"ltx_text ltx_number ltx_font_bold\">13.32</span><span id=\"S4.T4.6.6.3.2\" class=\"ltx_text ltx_font_bold\"> (<span id=\"S4.T4.6.6.3.2.1\" class=\"ltx_text ltx_number\">0.18</span>)</span>\n</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "DA, DR, TA or MR?\nFrom the results of different experiments presented in Tab. 1, Tab. 2, Tab. 3 and Tab. 4, it is obvious that DA improves the performance across all tasks and methods. Tab. 4 also shows the importance of DR on ShapeNet2D which cannot be simply compensated by DA. TA hinders the performance on Distractor but benefits all pose regression tasks. The reason for this is that, for Distractor, TA increases task complexity by shifting the origin of the image plain by the sampled noise, thus creating N2superscriptN2\\rm{N}^{2} copies of the original task, where N=16N16\\mathrm{N}=16 is the number of non-zero elements in the noise set. However, since these task copies live in independent coordinate frames, the increased task diversity is irrelevant to the original task.\nFor pose regression tasks, by contrast, TA augments the canonical poses of the existing data, which coherently benefits the original task as the augmented canonical poses remain in the coordinate frame of the original task.\nTherefore, even though TA increases the cross-entropy ℋ​(Y|X)ℋconditional𝑌𝑋\\mathcal{H}(Y|X) for both cases as demanded in [31],\nonly the pose regression tasks gain additional benefits. MR results in underfitting as combining MR with augmentations leads to worse performance than using the same augmentations alone for both ShapeNet1D and ShapeNet2D (see Tab. 3 and Tab. 4).\nFurthermore, MR requires extensive fine-tuning on the regularization parameter β𝛽\\beta (see Sec. 3.3) to modulate between underfitting and overfitting.",
            "Effect of the context set size in CNPs.\nWe compare the prediction error w.r.t. the size of the context set for Distractor (see Fig. 2(a)) and ShapeNet2D (see Fig. 2(b)). Both figures show that increasing the context set size benefits the performance, indicating that both Max and CA aggregations can merge useful information from different context pairs and thereby reduce the task ambiguity. In addition, we find that the model can further improve the performance given the size of context set surpasses the maximum number used for training (15 for both tasks). In particular, there is a small performance gap between intra- and cross-category evaluation for Distractor which is however absent for ShapeNet2D. We believe this indicates that Distractor has more task ambiguity than pose estimation and thus explains why Distractor gains more benefits from FCL than ShapeNet2D (see Tab. 1 and Tab. 4)."
        ]
    },
    "S4.T5": {
        "caption": "Table 5: Performance on ShapeNet1D using small (SS\\rm S), medium (MM\\rm M) and large (LL\\rm L) training dataset sizes for CNP with cross-attention (CA) and Max aggregation. The first row presents results for intra-category (IC) and the second row for cross-category (CC) evaluation. MSE and standard deviations are calculated with 5 random seeds.",
        "table": "<table id=\"S4.T5.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T5.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T5.6.6.7\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Methods</th>\n<th id=\"S4.T5.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">CA<sub id=\"S4.T5.1.1.1.1\" class=\"ltx_sub\">S</sub>\n</th>\n<th id=\"S4.T5.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">CA<sub id=\"S4.T5.2.2.2.1\" class=\"ltx_sub\">M</sub>\n</th>\n<th id=\"S4.T5.3.3.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">CA<sub id=\"S4.T5.3.3.3.1\" class=\"ltx_sub\">L</sub>\n</th>\n<th id=\"S4.T5.4.4.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Max<sub id=\"S4.T5.4.4.4.1\" class=\"ltx_sub\">S</sub>\n</th>\n<th id=\"S4.T5.5.5.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Max<sub id=\"S4.T5.5.5.5.1\" class=\"ltx_sub\">M</sub>\n</th>\n<th id=\"S4.T5.6.6.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Max<sub id=\"S4.T5.6.6.6.1\" class=\"ltx_sub\">L</sub>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.6.7.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.6.7.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">No Aug</th>\n<td id=\"S4.T5.6.7.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T5.6.7.1.2.1\" class=\"ltx_text ltx_number\">18.60</span> (<span id=\"S4.T5.6.7.1.2.2\" class=\"ltx_text ltx_number\">0.78</span>)</td>\n<td id=\"S4.T5.6.7.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T5.6.7.1.3.1\" class=\"ltx_text ltx_number\">12.08</span> (<span id=\"S4.T5.6.7.1.3.2\" class=\"ltx_text ltx_number\">0.44</span>)</td>\n<td id=\"S4.T5.6.7.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T5.6.7.1.4.1\" class=\"ltx_text ltx_number\">8.19</span> (<span id=\"S4.T5.6.7.1.4.2\" class=\"ltx_text ltx_number\">0.30</span>)</td>\n<td id=\"S4.T5.6.7.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T5.6.7.1.5.1\" class=\"ltx_text ltx_number\">30.44</span> (<span id=\"S4.T5.6.7.1.5.2\" class=\"ltx_text ltx_number\">0.82</span>)</td>\n<td id=\"S4.T5.6.7.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T5.6.7.1.6.1\" class=\"ltx_text ltx_number\">18.86</span> (<span id=\"S4.T5.6.7.1.6.2\" class=\"ltx_text ltx_number\">0.34</span>)</td>\n<td id=\"S4.T5.6.7.1.7\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T5.6.7.1.7.1\" class=\"ltx_text ltx_number\">14.97</span> (<span id=\"S4.T5.6.7.1.7.2\" class=\"ltx_text ltx_number\">0.37</span>)</td>\n</tr>\n<tr id=\"S4.T5.6.8.2\" class=\"ltx_tr\">\n<th id=\"S4.T5.6.8.2.1\" class=\"ltx_td ltx_th ltx_th_row\"/>\n<td id=\"S4.T5.6.8.2.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.8.2.2.1\" class=\"ltx_text ltx_number\">19.95</span> (<span id=\"S4.T5.6.8.2.2.2\" class=\"ltx_text ltx_number\">1.08</span>)</td>\n<td id=\"S4.T5.6.8.2.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.8.2.3.1\" class=\"ltx_text ltx_number\">12.62</span> (<span id=\"S4.T5.6.8.2.3.2\" class=\"ltx_text ltx_number\">0.87</span>)</td>\n<td id=\"S4.T5.6.8.2.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.8.2.4.1\" class=\"ltx_text ltx_number\">9.13</span> (<span id=\"S4.T5.6.8.2.4.2\" class=\"ltx_text ltx_number\">0.18</span>)</td>\n<td id=\"S4.T5.6.8.2.5\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.8.2.5.1\" class=\"ltx_text ltx_number\">30.59</span> (<span id=\"S4.T5.6.8.2.5.2\" class=\"ltx_text ltx_number\">1.14</span>)</td>\n<td id=\"S4.T5.6.8.2.6\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.8.2.6.1\" class=\"ltx_text ltx_number\">21.78</span> (<span id=\"S4.T5.6.8.2.6.2\" class=\"ltx_text ltx_number\">0.47</span>)</td>\n<td id=\"S4.T5.6.8.2.7\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.8.2.7.1\" class=\"ltx_text ltx_number\">18.09</span> (<span id=\"S4.T5.6.8.2.7.2\" class=\"ltx_text ltx_number\">0.21</span>)</td>\n</tr>\n<tr id=\"S4.T5.6.9.3\" class=\"ltx_tr\">\n<th id=\"S4.T5.6.9.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">TA</th>\n<td id=\"S4.T5.6.9.3.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.9.3.2.1\" class=\"ltx_text ltx_number\">18.69</span> (<span id=\"S4.T5.6.9.3.2.2\" class=\"ltx_text ltx_number\">0.87</span>)</td>\n<td id=\"S4.T5.6.9.3.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.9.3.3.1\" class=\"ltx_text ltx_number\">10.70</span> (<span id=\"S4.T5.6.9.3.3.2\" class=\"ltx_text ltx_number\">0.98</span>)</td>\n<td id=\"S4.T5.6.9.3.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.9.3.4.1\" class=\"ltx_text ltx_number\">7.92</span> (<span id=\"S4.T5.6.9.3.4.2\" class=\"ltx_text ltx_number\">0.25</span>)</td>\n<td id=\"S4.T5.6.9.3.5\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.9.3.5.1\" class=\"ltx_text ltx_number\">21.67</span> (<span id=\"S4.T5.6.9.3.5.2\" class=\"ltx_text ltx_number\">0.66</span>)</td>\n<td id=\"S4.T5.6.9.3.6\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.9.3.6.1\" class=\"ltx_text ltx_number\">13.69</span> (<span id=\"S4.T5.6.9.3.6.2\" class=\"ltx_text ltx_number\">0.27</span>)</td>\n<td id=\"S4.T5.6.9.3.7\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.9.3.7.1\" class=\"ltx_text ltx_number\">10.89</span> (<span id=\"S4.T5.6.9.3.7.2\" class=\"ltx_text ltx_number\">0.27</span>)</td>\n</tr>\n<tr id=\"S4.T5.6.10.4\" class=\"ltx_tr\">\n<th id=\"S4.T5.6.10.4.1\" class=\"ltx_td ltx_th ltx_th_row\"/>\n<td id=\"S4.T5.6.10.4.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.10.4.2.1\" class=\"ltx_text ltx_number\">19.24</span> (<span id=\"S4.T5.6.10.4.2.2\" class=\"ltx_text ltx_number\">0.79</span>)</td>\n<td id=\"S4.T5.6.10.4.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.10.4.3.1\" class=\"ltx_text ltx_number\">12.05</span> (<span id=\"S4.T5.6.10.4.3.2\" class=\"ltx_text ltx_number\">0.73</span>)</td>\n<td id=\"S4.T5.6.10.4.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.10.4.4.1\" class=\"ltx_text ltx_number\">9.18</span> (<span id=\"S4.T5.6.10.4.4.2\" class=\"ltx_text ltx_number\">0.50</span>)</td>\n<td id=\"S4.T5.6.10.4.5\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.10.4.5.1\" class=\"ltx_text ltx_number\">23.60</span> (<span id=\"S4.T5.6.10.4.5.2\" class=\"ltx_text ltx_number\">0.88</span>)</td>\n<td id=\"S4.T5.6.10.4.6\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.10.4.6.1\" class=\"ltx_text ltx_number\">16.76</span> (<span id=\"S4.T5.6.10.4.6.2\" class=\"ltx_text ltx_number\">0.62</span>)</td>\n<td id=\"S4.T5.6.10.4.7\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.10.4.7.1\" class=\"ltx_text ltx_number\">14.43</span> (<span id=\"S4.T5.6.10.4.7.2\" class=\"ltx_text ltx_number\">0.55</span>)</td>\n</tr>\n<tr id=\"S4.T5.6.11.5\" class=\"ltx_tr\">\n<th id=\"S4.T5.6.11.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">TA+DA</th>\n<td id=\"S4.T5.6.11.5.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.11.5.2.1\" class=\"ltx_text ltx_number\">7.86</span> (<span id=\"S4.T5.6.11.5.2.2\" class=\"ltx_text ltx_number\">0.21</span>)</td>\n<td id=\"S4.T5.6.11.5.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.11.5.3.1\" class=\"ltx_text ltx_number\">6.32</span> (<span id=\"S4.T5.6.11.5.3.2\" class=\"ltx_text ltx_number\">0.11</span>)</td>\n<td id=\"S4.T5.6.11.5.4\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.11.5.4.1\" class=\"ltx_text ltx_number ltx_font_bold\">5.81</span> (<span id=\"S4.T5.6.11.5.4.2\" class=\"ltx_text ltx_number ltx_font_bold\">0.23</span>)</td>\n<td id=\"S4.T5.6.11.5.5\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.11.5.5.1\" class=\"ltx_text ltx_number\">11.00</span> (<span id=\"S4.T5.6.11.5.5.2\" class=\"ltx_text ltx_number\">0.16</span>)</td>\n<td id=\"S4.T5.6.11.5.6\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.11.5.6.1\" class=\"ltx_text ltx_number\">8.23</span> (<span id=\"S4.T5.6.11.5.6.2\" class=\"ltx_text ltx_number\">0.34</span>)</td>\n<td id=\"S4.T5.6.11.5.7\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T5.6.11.5.7.1\" class=\"ltx_text ltx_number\">7.66</span> (<span id=\"S4.T5.6.11.5.7.2\" class=\"ltx_text ltx_number\">0.18</span>)</td>\n</tr>\n<tr id=\"S4.T5.6.12.6\" class=\"ltx_tr\">\n<th id=\"S4.T5.6.12.6.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_bb\"/>\n<td id=\"S4.T5.6.12.6.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T5.6.12.6.2.1\" class=\"ltx_text ltx_number\">7.49</span> (<span id=\"S4.T5.6.12.6.2.2\" class=\"ltx_text ltx_number\">0.35</span>)</td>\n<td id=\"S4.T5.6.12.6.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T5.6.12.6.3.1\" class=\"ltx_text ltx_number\">6.48</span> (<span id=\"S4.T5.6.12.6.3.2\" class=\"ltx_text ltx_number\">0.41</span>)</td>\n<td id=\"S4.T5.6.12.6.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T5.6.12.6.4.1\" class=\"ltx_text ltx_number ltx_font_bold\">6.23</span> (<span id=\"S4.T5.6.12.6.4.2\" class=\"ltx_text ltx_number ltx_font_bold\">0.12</span>)</td>\n<td id=\"S4.T5.6.12.6.5\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T5.6.12.6.5.1\" class=\"ltx_text ltx_number\">12.98</span> (<span id=\"S4.T5.6.12.6.5.2\" class=\"ltx_text ltx_number\">0.48</span>)</td>\n<td id=\"S4.T5.6.12.6.6\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T5.6.12.6.6.1\" class=\"ltx_text ltx_number\">9.65</span> (<span id=\"S4.T5.6.12.6.6.2\" class=\"ltx_text ltx_number\">0.40</span>)</td>\n<td id=\"S4.T5.6.12.6.7\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T5.6.12.6.7.1\" class=\"ltx_text ltx_number\">8.66</span> (<span id=\"S4.T5.6.12.6.7.2\" class=\"ltx_text ltx_number\">0.19</span>)</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "How much meta-data is essential?\nWe split the training data of ShapeNet1D into subsets of three different sizes, with 10 objects per category for the small dataset (S), 30 objects per category for the medium dataset (M) and 50 for the large dataset (L). Afterwards, we test the performance of CNP with Max aggregation and CA on each of them. The results in Tab. 5 show that Max overfits on the small dataset by simply memorizing all training tasks while CA works much better. Moreover, CA trained on small dataset achieves a comparable performance with Max on large dataset after using TA and DA, and even outperforms Max on the cross-category level. Thus, we conclude that using CA in combination with augmentation techniques can drastically alleviate the overfitting problem and therefore requires less meta-data on object-centric vision tasks than Max. In contrast, MAML performs much worse on ShapeNet1D (L) (see Tab. 3) than CNPs and thus hardly profits from an increased dataset."
        ]
    },
    "S4.T6": {
        "caption": "Table 6: Comparison of aggregation methods on ShapeNet2D using DR+DA+TA. Results are calculated with 3 random seeds.",
        "table": "<table id=\"S4.T6.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T6.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T6.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Methods</th>\n<th id=\"S4.T6.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">IC (<math id=\"S4.T6.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"1e^{-2}\" display=\"inline\"><semantics id=\"S4.T6.1.1.1.m1.1a\"><mrow id=\"S4.T6.1.1.1.m1.1.1\" xref=\"S4.T6.1.1.1.m1.1.1.cmml\"><mn id=\"S4.T6.1.1.1.m1.1.1.2\" xref=\"S4.T6.1.1.1.m1.1.1.2.cmml\">1</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T6.1.1.1.m1.1.1.1\" xref=\"S4.T6.1.1.1.m1.1.1.1.cmml\">​</mo><msup id=\"S4.T6.1.1.1.m1.1.1.3\" xref=\"S4.T6.1.1.1.m1.1.1.3.cmml\"><mi id=\"S4.T6.1.1.1.m1.1.1.3.2\" xref=\"S4.T6.1.1.1.m1.1.1.3.2.cmml\">e</mi><mrow id=\"S4.T6.1.1.1.m1.1.1.3.3\" xref=\"S4.T6.1.1.1.m1.1.1.3.3.cmml\"><mo id=\"S4.T6.1.1.1.m1.1.1.3.3a\" xref=\"S4.T6.1.1.1.m1.1.1.3.3.cmml\">−</mo><mn id=\"S4.T6.1.1.1.m1.1.1.3.3.2\" xref=\"S4.T6.1.1.1.m1.1.1.3.3.2.cmml\">2</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T6.1.1.1.m1.1b\"><apply id=\"S4.T6.1.1.1.m1.1.1.cmml\" xref=\"S4.T6.1.1.1.m1.1.1\"><times id=\"S4.T6.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T6.1.1.1.m1.1.1.1\"/><cn type=\"integer\" id=\"S4.T6.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T6.1.1.1.m1.1.1.2\">1</cn><apply id=\"S4.T6.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T6.1.1.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T6.1.1.1.m1.1.1.3.1.cmml\" xref=\"S4.T6.1.1.1.m1.1.1.3\">superscript</csymbol><ci id=\"S4.T6.1.1.1.m1.1.1.3.2.cmml\" xref=\"S4.T6.1.1.1.m1.1.1.3.2\">𝑒</ci><apply id=\"S4.T6.1.1.1.m1.1.1.3.3.cmml\" xref=\"S4.T6.1.1.1.m1.1.1.3.3\"><minus id=\"S4.T6.1.1.1.m1.1.1.3.3.1.cmml\" xref=\"S4.T6.1.1.1.m1.1.1.3.3\"/><cn type=\"integer\" id=\"S4.T6.1.1.1.m1.1.1.3.3.2.cmml\" xref=\"S4.T6.1.1.1.m1.1.1.3.3.2\">2</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T6.1.1.1.m1.1c\">1e^{-2}</annotation></semantics></math>)</th>\n<th id=\"S4.T6.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">CC (<math id=\"S4.T6.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"1e^{-2}\" display=\"inline\"><semantics id=\"S4.T6.2.2.2.m1.1a\"><mrow id=\"S4.T6.2.2.2.m1.1.1\" xref=\"S4.T6.2.2.2.m1.1.1.cmml\"><mn id=\"S4.T6.2.2.2.m1.1.1.2\" xref=\"S4.T6.2.2.2.m1.1.1.2.cmml\">1</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T6.2.2.2.m1.1.1.1\" xref=\"S4.T6.2.2.2.m1.1.1.1.cmml\">​</mo><msup id=\"S4.T6.2.2.2.m1.1.1.3\" xref=\"S4.T6.2.2.2.m1.1.1.3.cmml\"><mi id=\"S4.T6.2.2.2.m1.1.1.3.2\" xref=\"S4.T6.2.2.2.m1.1.1.3.2.cmml\">e</mi><mrow id=\"S4.T6.2.2.2.m1.1.1.3.3\" xref=\"S4.T6.2.2.2.m1.1.1.3.3.cmml\"><mo id=\"S4.T6.2.2.2.m1.1.1.3.3a\" xref=\"S4.T6.2.2.2.m1.1.1.3.3.cmml\">−</mo><mn id=\"S4.T6.2.2.2.m1.1.1.3.3.2\" xref=\"S4.T6.2.2.2.m1.1.1.3.3.2.cmml\">2</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T6.2.2.2.m1.1b\"><apply id=\"S4.T6.2.2.2.m1.1.1.cmml\" xref=\"S4.T6.2.2.2.m1.1.1\"><times id=\"S4.T6.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T6.2.2.2.m1.1.1.1\"/><cn type=\"integer\" id=\"S4.T6.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T6.2.2.2.m1.1.1.2\">1</cn><apply id=\"S4.T6.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T6.2.2.2.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T6.2.2.2.m1.1.1.3.1.cmml\" xref=\"S4.T6.2.2.2.m1.1.1.3\">superscript</csymbol><ci id=\"S4.T6.2.2.2.m1.1.1.3.2.cmml\" xref=\"S4.T6.2.2.2.m1.1.1.3.2\">𝑒</ci><apply id=\"S4.T6.2.2.2.m1.1.1.3.3.cmml\" xref=\"S4.T6.2.2.2.m1.1.1.3.3\"><minus id=\"S4.T6.2.2.2.m1.1.1.3.3.1.cmml\" xref=\"S4.T6.2.2.2.m1.1.1.3.3\"/><cn type=\"integer\" id=\"S4.T6.2.2.2.m1.1.1.3.3.2.cmml\" xref=\"S4.T6.2.2.2.m1.1.1.3.3.2\">2</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T6.2.2.2.m1.1c\">1e^{-2}</annotation></semantics></math>)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T6.2.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T6.2.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">CNP+Mean</th>\n<td id=\"S4.T6.2.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T6.2.3.1.2.1\" class=\"ltx_text ltx_number\">15.04</span> (<span id=\"S4.T6.2.3.1.2.2\" class=\"ltx_text ltx_number\">0.08</span>)</td>\n<td id=\"S4.T6.2.3.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T6.2.3.1.3.1\" class=\"ltx_text ltx_number\">15.45</span> (<span id=\"S4.T6.2.3.1.3.2\" class=\"ltx_text ltx_number\">0.13</span>)</td>\n</tr>\n<tr id=\"S4.T6.2.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T6.2.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CNP+Max</th>\n<td id=\"S4.T6.2.4.2.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T6.2.4.2.2.1\" class=\"ltx_text ltx_number\">14.20</span> (<span id=\"S4.T6.2.4.2.2.2\" class=\"ltx_text ltx_number\">0.06</span>)</td>\n<td id=\"S4.T6.2.4.2.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T6.2.4.2.3.1\" class=\"ltx_text ltx_number ltx_font_bold\">13.56</span> (<span id=\"S4.T6.2.4.2.3.2\" class=\"ltx_text ltx_number\">0.28</span>)</td>\n</tr>\n<tr id=\"S4.T6.2.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T6.2.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CNP+BA</th>\n<td id=\"S4.T6.2.5.3.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T6.2.5.3.2.1\" class=\"ltx_text ltx_number\">14.16</span> (<span id=\"S4.T6.2.5.3.2.2\" class=\"ltx_text ltx_number\">0.08</span>)</td>\n<td id=\"S4.T6.2.5.3.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T6.2.5.3.3.1\" class=\"ltx_text ltx_number ltx_font_bold\">13.56</span> (<span id=\"S4.T6.2.5.3.3.2\" class=\"ltx_text ltx_number\">0.18</span>)</td>\n</tr>\n<tr id=\"S4.T6.2.6.4\" class=\"ltx_tr\">\n<th id=\"S4.T6.2.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">CNP+CA</th>\n<td id=\"S4.T6.2.6.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T6.2.6.4.2.1\" class=\"ltx_text ltx_number ltx_font_bold\">14.12</span> (<span id=\"S4.T6.2.6.4.2.2\" class=\"ltx_text ltx_number\">0.14</span>)</td>\n<td id=\"S4.T6.2.6.4.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T6.2.6.4.3.1\" class=\"ltx_text ltx_number\">13.59</span> (<span id=\"S4.T6.2.6.4.3.2\" class=\"ltx_text ltx_number\">0.10</span>)</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Which aggregation methods should I use?\nCross-attention (CA) performs better than mean aggregation on Pascal1D (see Tab. 2) and Max on ShapeNet1D (see Tab. 3), while it achieves a similar performance to Max aggregation and BA on ShapeNet2D (see Tab. 6). In contrast, mean aggregation used in the original CNP performs the worst on both Pascal1D and ShapeNet2D. Our interpretation is that Mean assigns the same importance to each context while the other aggregation operators can allocate different weights. Max assigns a weight of one to a context and zero to all others for each dimension of the representation while BA assigns the weights predicted by another neural network. Meanwhile, CA assigns importance by comparing the similarity between context inputs {xCi}i=1Ksuperscriptsubscriptsuperscriptsubscript𝑥𝐶𝑖𝑖1𝐾\\{x_{C}^{i}\\}_{i=1}^{K} and target input xTsubscript𝑥𝑇x_{T} at the feature space."
        ]
    },
    "S4.T7": {
        "caption": "Table 7: Comparison of different data augmentation techniques on ShapeNet2D using CNP (CA) + DR as baseline.",
        "table": "<table id=\"S4.T7.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T7.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T7.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Methods</th>\n<th id=\"S4.T7.2.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Val</th>\n<th id=\"S4.T7.2.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Test</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T7.2.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T7.2.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">All</td>\n<td id=\"S4.T7.2.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.1417</td>\n<td id=\"S4.T7.2.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.1410</td>\n</tr>\n<tr id=\"S4.T7.2.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T7.2.3.2.1\" class=\"ltx_td ltx_align_left\">w/o CropAndPad</td>\n<td id=\"S4.T7.2.3.2.2\" class=\"ltx_td ltx_align_left\">0.1412</td>\n<td id=\"S4.T7.2.3.2.3\" class=\"ltx_td ltx_align_left\">0.1368</td>\n</tr>\n<tr id=\"S4.T7.2.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T7.2.4.3.1\" class=\"ltx_td ltx_align_left\">w/o Affine</td>\n<td id=\"S4.T7.2.4.3.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T7.2.4.3.2.1\" class=\"ltx_text ltx_font_bold\">0.1623</span></td>\n<td id=\"S4.T7.2.4.3.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T7.2.4.3.3.1\" class=\"ltx_text ltx_font_bold\">0.1743</span></td>\n</tr>\n<tr id=\"S4.T7.2.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T7.2.5.4.1\" class=\"ltx_td ltx_align_left\">w/o Dropout</td>\n<td id=\"S4.T7.2.5.4.2\" class=\"ltx_td ltx_align_left\">0.1452</td>\n<td id=\"S4.T7.2.5.4.3\" class=\"ltx_td ltx_align_left\">0.1445</td>\n</tr>\n<tr id=\"S4.T7.2.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T7.2.6.5.1\" class=\"ltx_td ltx_align_left\">w/o Contrast</td>\n<td id=\"S4.T7.2.6.5.2\" class=\"ltx_td ltx_align_left\">0.1482</td>\n<td id=\"S4.T7.2.6.5.3\" class=\"ltx_td ltx_align_left\">0.1406</td>\n</tr>\n<tr id=\"S4.T7.2.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T7.2.7.6.1\" class=\"ltx_td ltx_align_left\">w/o Brightness</td>\n<td id=\"S4.T7.2.7.6.2\" class=\"ltx_td ltx_align_left\">0.1454</td>\n<td id=\"S4.T7.2.7.6.3\" class=\"ltx_td ltx_align_left\">0.1380</td>\n</tr>\n<tr id=\"S4.T7.2.8.7\" class=\"ltx_tr\">\n<td id=\"S4.T7.2.8.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">w/o Blur</td>\n<td id=\"S4.T7.2.8.7.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">0.1426</td>\n<td id=\"S4.T7.2.8.7.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">0.1422</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Data augmentation.\nTab. 7 shows the effect of each individual data augmentation technique (see Sec. 3.3) on ShapeNet2D. The first row contains results obtained with all techniques applied jointly. In the other rows, one of the techniques is removed respectively. We find that removing Affine leads to the worst performance which indicates that object-centric pose regression tasks are more sensitive to scale. On the other hand, omitting CropAndPad even leads to an performance increase."
        ]
    },
    "S4.T8": {
        "caption": "Table 8: Analysis of FCL + CNP on different choices of positive pairs using: i) the same context set with different augmentations (Same Ctx), ii) different context sets from the same task (Diff Ctx), iii) context and target sets (Ctx & Target). Prediction error (pixel) is calculated with 3 random seeds.",
        "table": "<table id=\"S4.T8.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T8.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T8.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Methods</th>\n<th id=\"S4.T8.2.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">IC</th>\n<th id=\"S4.T8.2.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">CC</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T8.2.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T8.2.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Same Ctx</th>\n<td id=\"S4.T8.2.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T8.2.2.1.2.1\" class=\"ltx_text ltx_number\">2.30</span> (<span id=\"S4.T8.2.2.1.2.2\" class=\"ltx_text ltx_number\">0.04</span>)</td>\n<td id=\"S4.T8.2.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"S4.T8.2.2.1.3.1\" class=\"ltx_text ltx_number\">3.46</span> (<span id=\"S4.T8.2.2.1.3.2\" class=\"ltx_text ltx_number\">0.06</span>)</td>\n</tr>\n<tr id=\"S4.T8.2.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T8.2.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Diff Ctx</th>\n<td id=\"S4.T8.2.3.2.2\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T8.2.3.2.2.1\" class=\"ltx_text ltx_number\">2.16</span> (<span id=\"S4.T8.2.3.2.2.2\" class=\"ltx_text ltx_number\">0.05</span>)</td>\n<td id=\"S4.T8.2.3.2.3\" class=\"ltx_td ltx_align_left\">\n<span id=\"S4.T8.2.3.2.3.1\" class=\"ltx_text ltx_number\">3.25</span> (<span id=\"S4.T8.2.3.2.3.2\" class=\"ltx_text ltx_number\">0.05</span>)</td>\n</tr>\n<tr id=\"S4.T8.2.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T8.2.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Ctx &amp; Target</th>\n<td id=\"S4.T8.2.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T8.2.4.3.2.1\" class=\"ltx_text ltx_number ltx_font_bold\">2.00</span> (<span id=\"S4.T8.2.4.3.2.2\" class=\"ltx_text ltx_number ltx_font_bold\">0.02</span>)</td>\n<td id=\"S4.T8.2.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S4.T8.2.4.3.3.1\" class=\"ltx_text ltx_number ltx_font_bold\">3.05</span> (<span id=\"S4.T8.2.4.3.3.2\" class=\"ltx_text ltx_number ltx_font_bold\">0.08</span>)</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "FCL on different sets.\nWe compare FCL on three choices of positive pairs: i) We use the same context set but with different data augmentations. ii) We use different context sets sampled from the same task. iii) We use context and target sets from the same task. We test the performance on Distractor using Max aggregation and DA. For each choice, we run three experiments with different seeds and present the average performance in Tab. 8. Compared to Tab. 1, all three choices consistently outperform CNP (Max) while using FCL on context and target sets achieves the best performance."
        ]
    },
    "A1.T1": {
        "caption": "Table 1: Results of the evaluation on ShapeNet1D using different temperature values in FCL.",
        "table": "<table id=\"A1.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T1.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><math id=\"A1.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\tau\" display=\"inline\"><semantics id=\"A1.T1.1.1.1.m1.1a\"><mi id=\"A1.T1.1.1.1.m1.1.1\" xref=\"A1.T1.1.1.1.m1.1.1.cmml\">τ</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.1.1.1.m1.1b\"><ci id=\"A1.T1.1.1.1.m1.1.1.cmml\" xref=\"A1.T1.1.1.1.m1.1.1\">𝜏</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.1.1.1.m1.1c\">\\tau</annotation></semantics></math></th>\n<th id=\"A1.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">1.0</th>\n<th id=\"A1.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.5</th>\n<th id=\"A1.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.2</th>\n<th id=\"A1.T1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.07</th>\n<th id=\"A1.T1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.007</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"A1.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">IC</th>\n<td id=\"A1.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">8.5550</td>\n<td id=\"A1.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">8.9810</td>\n<td id=\"A1.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">8.8551</td>\n<td id=\"A1.T1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T1.1.2.1.5.1\" class=\"ltx_text ltx_font_bold\">7.8196</span></td>\n<td id=\"A1.T1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">8.1409</td>\n</tr>\n<tr id=\"A1.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"A1.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">CC</th>\n<td id=\"A1.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">10.4660</td>\n<td id=\"A1.T1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">10.5135</td>\n<td id=\"A1.T1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">10.5604</td>\n<td id=\"A1.T1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A1.T1.1.3.2.5.1\" class=\"ltx_text ltx_font_bold\">8.8420</span></td>\n<td id=\"A1.T1.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">9.3846</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "A grid search on hyperparameter τ𝜏\\tau is very expensive especially on vision tasks. Therefore, we search only on a discrete set {0.007,0.7,0.2,0.5,1.0}0.0070.70.20.51.0\\{0.007,0.7,0.2,0.5,1.0\\} and find that τ=0.07𝜏0.07\\tau=0.07 shows the best performance on ShapeNet1D and τ=0.007𝜏0.007\\tau=0.007 on ShapeNet2D. The results are shown in Tab. 1 and Tab. 2."
        ]
    },
    "A1.T2": {
        "caption": "Table 2: Results of the evaluation on ShapeNet2D using different temperature values in FCL.",
        "table": "<table id=\"A1.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T2.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><math id=\"A1.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\tau\" display=\"inline\"><semantics id=\"A1.T2.1.1.1.m1.1a\"><mi id=\"A1.T2.1.1.1.m1.1.1\" xref=\"A1.T2.1.1.1.m1.1.1.cmml\">τ</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T2.1.1.1.m1.1b\"><ci id=\"A1.T2.1.1.1.m1.1.1.cmml\" xref=\"A1.T2.1.1.1.m1.1.1\">𝜏</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T2.1.1.1.m1.1c\">\\tau</annotation></semantics></math></th>\n<th id=\"A1.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">1.0</th>\n<th id=\"A1.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.5</th>\n<th id=\"A1.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.2</th>\n<th id=\"A1.T2.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.07</th>\n<th id=\"A1.T2.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.007</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"A1.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">IC</th>\n<td id=\"A1.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1564</td>\n<td id=\"A1.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.174</td>\n<td id=\"A1.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1962,</td>\n<td id=\"A1.T2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1441</td>\n<td id=\"A1.T2.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A1.T2.1.2.1.6.1\" class=\"ltx_text ltx_font_bold\">0.1401</span></td>\n</tr>\n<tr id=\"A1.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"A1.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">CC</th>\n<td id=\"A1.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.1594</td>\n<td id=\"A1.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.1758</td>\n<td id=\"A1.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.2089</td>\n<td id=\"A1.T2.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.1390</td>\n<td id=\"A1.T2.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A1.T2.1.3.2.6.1\" class=\"ltx_text ltx_font_bold\">0.1332</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "A grid search on hyperparameter τ𝜏\\tau is very expensive especially on vision tasks. Therefore, we search only on a discrete set {0.007,0.7,0.2,0.5,1.0}0.0070.70.20.51.0\\{0.007,0.7,0.2,0.5,1.0\\} and find that τ=0.07𝜏0.07\\tau=0.07 shows the best performance on ShapeNet1D and τ=0.007𝜏0.007\\tau=0.007 on ShapeNet2D. The results are shown in Tab. 1 and Tab. 2."
        ]
    },
    "A1.T3": {
        "caption": "Table 3: Analysis of latent task representation on Distractor between Max and MaxFCL using various clustering metrics.",
        "table": "<table id=\"A1.T3.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T3.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T3.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Methods</th>\n<th id=\"A1.T3.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Max</th>\n<th id=\"A1.T3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Max<sub id=\"A1.T3.1.1.1.1\" class=\"ltx_sub\">FCL</sub>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T3.2.2\" class=\"ltx_tr\">\n<th id=\"A1.T3.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">ARI <math id=\"A1.T3.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"A1.T3.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"A1.T3.2.2.1.m1.1.1\" xref=\"A1.T3.2.2.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"A1.T3.2.2.1.m1.1b\"><ci id=\"A1.T3.2.2.1.m1.1.1.cmml\" xref=\"A1.T3.2.2.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T3.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<td id=\"A1.T3.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T3.2.2.2.1\" class=\"ltx_text ltx_number\">0.21</span></td>\n<td id=\"A1.T3.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A1.T3.2.2.3.1\" class=\"ltx_text ltx_number\">0.20</span></td>\n</tr>\n<tr id=\"A1.T3.3.3\" class=\"ltx_tr\">\n<th id=\"A1.T3.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MI <math id=\"A1.T3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"A1.T3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"A1.T3.3.3.1.m1.1.1\" xref=\"A1.T3.3.3.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"A1.T3.3.3.1.m1.1b\"><ci id=\"A1.T3.3.3.1.m1.1.1.cmml\" xref=\"A1.T3.3.3.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<td id=\"A1.T3.3.3.2\" class=\"ltx_td ltx_align_left\"><span id=\"A1.T3.3.3.2.1\" class=\"ltx_text ltx_number\">1.13</span></td>\n<td id=\"A1.T3.3.3.3\" class=\"ltx_td ltx_align_left\"><span id=\"A1.T3.3.3.3.1\" class=\"ltx_text ltx_number\">1.03</span></td>\n</tr>\n<tr id=\"A1.T3.4.4\" class=\"ltx_tr\">\n<th id=\"A1.T3.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">SS <math id=\"A1.T3.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"A1.T3.4.4.1.m1.1a\"><mo stretchy=\"false\" id=\"A1.T3.4.4.1.m1.1.1\" xref=\"A1.T3.4.4.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"A1.T3.4.4.1.m1.1b\"><ci id=\"A1.T3.4.4.1.m1.1.1.cmml\" xref=\"A1.T3.4.4.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T3.4.4.1.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<td id=\"A1.T3.4.4.2\" class=\"ltx_td ltx_align_left\"><span id=\"A1.T3.4.4.2.1\" class=\"ltx_text ltx_number\">0.31</span></td>\n<td id=\"A1.T3.4.4.3\" class=\"ltx_td ltx_align_left\"><span id=\"A1.T3.4.4.3.1\" class=\"ltx_text ltx_number\">0.15</span></td>\n</tr>\n<tr id=\"A1.T3.5.5\" class=\"ltx_tr\">\n<th id=\"A1.T3.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CHI <math id=\"A1.T3.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"A1.T3.5.5.1.m1.1a\"><mo stretchy=\"false\" id=\"A1.T3.5.5.1.m1.1.1\" xref=\"A1.T3.5.5.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"A1.T3.5.5.1.m1.1b\"><ci id=\"A1.T3.5.5.1.m1.1.1.cmml\" xref=\"A1.T3.5.5.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T3.5.5.1.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<td id=\"A1.T3.5.5.2\" class=\"ltx_td ltx_align_left\"><span id=\"A1.T3.5.5.2.1\" class=\"ltx_text ltx_number\">118.73</span></td>\n<td id=\"A1.T3.5.5.3\" class=\"ltx_td ltx_align_left\"><span id=\"A1.T3.5.5.3.1\" class=\"ltx_text ltx_number\">18.90</span></td>\n</tr>\n<tr id=\"A1.T3.6.6\" class=\"ltx_tr\">\n<th id=\"A1.T3.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">DBI <math id=\"A1.T3.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A1.T3.6.6.1.m1.1a\"><mo stretchy=\"false\" id=\"A1.T3.6.6.1.m1.1.1\" xref=\"A1.T3.6.6.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"A1.T3.6.6.1.m1.1b\"><ci id=\"A1.T3.6.6.1.m1.1.1.cmml\" xref=\"A1.T3.6.6.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T3.6.6.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<td id=\"A1.T3.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"A1.T3.6.6.2.1\" class=\"ltx_text ltx_number\">1.00</span></td>\n<td id=\"A1.T3.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"A1.T3.6.6.3.1\" class=\"ltx_text ltx_number\">1.65</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Furthermore, we investigate the influence of FCL on the predicted task representations over all 12 categories using five clustering metrics, namely Adjusted Rand Index (ARI), Mutual Information (MI), Silhouette Score (SS), Calinski-Harabasz Index (CHI) and Davies-Bouldin Index (DBI). Results are shown in Tab. 3. FCL leads to a more dispersed latent distribution compared to the original CNP, which reduces the vacancy in the latent space and thus improve the generalization ability to unseen tasks."
        ]
    },
    "A1.T4": {
        "caption": "Table 4: Performance of MMAML [41] on ShapeNet1D.",
        "table": "<table id=\"A1.T4.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T4.2.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T4.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">MMAML</th>\n<th id=\"A1.T4.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">No Aug</th>\n<th id=\"A1.T4.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">DA</th>\n<th id=\"A1.T4.2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">TA</th>\n<th id=\"A1.T4.2.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">DA+TA</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T4.2.2.1\" class=\"ltx_tr\">\n<td id=\"A1.T4.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">IC</td>\n<td id=\"A1.T4.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">19.6900</td>\n<td id=\"A1.T4.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">26.3624</td>\n<td id=\"A1.T4.2.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">19.0705</td>\n<td id=\"A1.T4.2.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">27.4973</td>\n</tr>\n<tr id=\"A1.T4.2.3.2\" class=\"ltx_tr\">\n<td id=\"A1.T4.2.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">CC</td>\n<td id=\"A1.T4.2.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">20.6123</td>\n<td id=\"A1.T4.2.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">26.4090</td>\n<td id=\"A1.T4.2.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">19.4285</td>\n<td id=\"A1.T4.2.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">27.3120</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Additional Results. We have evaluated MMAML [41], a conditional variant of MAML, on ShapeNet1D based on reviewer’s recommendation in Tab. 4. The results is worse than MAML, indicating that the designed task-aware modulation in MMAML doesn’t benefit our tasks."
        ]
    }
}