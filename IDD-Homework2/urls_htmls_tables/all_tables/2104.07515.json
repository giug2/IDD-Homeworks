{
    "PAPER'S NUMBER OF TABLES": 3,
    "S4.T1": {
        "caption": "TABLE I: Statistics of FEMNIST, MNIST, Synthetic(1,1) and Sent140.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:1pt 14.2pt;\">Dataset</th>\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:1pt 14.2pt;\">Model</th>\n<th id=\"S4.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\">Devices</th>\n<th id=\"S4.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\">Samples</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding:1pt 14.2pt;\">MNIST</th>\n<th id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding:1pt 14.2pt;\" rowspan=\"3\"><span id=\"S4.T1.1.2.1.2.1\" class=\"ltx_text\">MCLR</span></th>\n<td id=\"S4.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 14.2pt;\">1,000</td>\n<td id=\"S4.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 14.2pt;\">69,035</td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding:1pt 14.2pt;\">FEMNIST</th>\n<td id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">200</td>\n<td id=\"S4.T1.1.3.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">18,345</td>\n</tr>\n<tr id=\"S4.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding:1pt 14.2pt;\">Synthetic(1,1)</th>\n<td id=\"S4.T1.1.4.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">100</td>\n<td id=\"S4.T1.1.4.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">75,349</td>\n</tr>\n<tr id=\"S4.T1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" style=\"padding:1pt 14.2pt;\">Sent140</th>\n<th id=\"S4.T1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:1pt 14.2pt;\">LSTM</th>\n<td id=\"S4.T1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 14.2pt;\">772</td>\n<td id=\"S4.T1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 14.2pt;\">40,783</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Datasets ",
                "&",
                "\\&",
                " Models.",
                " Our evaluation includes two model families on four datasets which are consisted of both image classification tasks and text sentiment analysis tasks.\n",
                "Federated Extended MNIST (FEMNIST)",
                "[",
                "32",
                "]",
                " is a 26-class image classification dataset composed of handwritten digits and characters which partition the 62-class data in EMNIST",
                "[",
                "31",
                "]",
                " according to writers.\nThe data of FEMNIST is distributed into 200 devices where each device holds only 5 classes as heterogeneous settings.\nWe use multinomial logistic regression (MCLR) with 7850 parameters to train a convex model on FEMNIST.\n",
                "MNIST",
                "[",
                "30",
                "]",
                " is a 10-class image classification dataset composed of handwriting digits 0-9.\nOn MNIST, 18,345 samples are divided into 1,000 devices.\nTo simulate obvious heterogeneity, each device holds only 2-class digits and the samples of devices follow a power law.\nWe optimize the model on MNIST with the same training model MCLR as FEMNIST.\n",
                "Sentiment140 (Sent140)",
                "[",
                "39",
                "]",
                " is a text sentiment analysis dataset composed of many tweets where each tweet can be extracted as a positive or negative sentiment.\nThe number of clients on Sent140 is 772.\nWe use LSTM to train the model on Sent140.\n",
                "Synthetic",
                "[",
                "40",
                "]",
                " is a synthetic federated dataset that consists of 100 devices.\nWe generated Synthetic dataset with the hyperparameter ",
                "α",
                "=",
                "1",
                "𝛼",
                "1",
                "\\alpha=1",
                ", ",
                "β",
                "=",
                "1",
                "𝛽",
                "1",
                "\\beta=1",
                " (e.g. Synthetic(1,1)) and the data size on clients follows a power law.\nWe use the MCLR classifier to train the model on Synthetic(1,1).\nThe statistics of the above four datasets are shown in TABLE ",
                "I",
                ".",
                "Federated Parameters.",
                "\nAll of the above models support training with at least one iteration. We split an epoch into multiple iterations. For example, if a client is required to train 3.5 epochs, then this client will train 3 epochs and ",
                "0.5",
                "​",
                "τ",
                "0.5",
                "𝜏",
                "0.5\\tau",
                " iterations where ",
                "τ",
                "=",
                "S",
                "k",
                "B",
                "𝜏",
                "subscript",
                "𝑆",
                "𝑘",
                "𝐵",
                "\\tau=\\frac{S_{k}}{B}",
                " varies with the practical iterations of an epoch, ",
                "S",
                "k",
                "subscript",
                "𝑆",
                "𝑘",
                "S_{k}",
                " is the number of samples for client ",
                "k",
                "𝑘",
                "k",
                ", ",
                "B",
                "𝐵",
                "B",
                " is the local mini-batch.\nIn our experiments, we simulate systems heterogeneity by generating the affordable local workloads ",
                "E",
                "𝐸",
                "E",
                " of clients at each round with Gaussian Distributions ",
                "E",
                "∼",
                "𝒩",
                "​",
                "(",
                "μ",
                ",",
                "σ",
                "2",
                ")",
                "similar-to",
                "𝐸",
                "𝒩",
                "𝜇",
                "superscript",
                "𝜎",
                "2",
                "E\\sim\\mathcal{N}(\\mu,\\sigma^{2})",
                " where ",
                "μ",
                "𝜇",
                "\\mu",
                " ",
                "∈",
                "\\in",
                " ",
                "[",
                "5",
                ",",
                "10",
                ")",
                "5",
                "10",
                "[5,10)",
                ", ",
                "σ",
                "∈",
                "[",
                "μ",
                "4",
                ",",
                "μ",
                "2",
                ")",
                "𝜎",
                "𝜇",
                "4",
                "𝜇",
                "2",
                "\\sigma\\in[\\frac{\\mu}{4},\\frac{\\mu}{2})",
                ", ",
                "μ",
                "𝜇",
                "\\mu",
                ", ",
                "σ",
                "𝜎",
                "\\sigma",
                " are valued from their regions uniformly.\nWe use the same federated learning settings as introduced in ",
                "III-A",
                ": the number of selected clients per round ",
                "K",
                "=",
                "30",
                "𝐾",
                "30",
                "K=30",
                " for MNIST, ",
                "K",
                "=",
                "10",
                "𝐾",
                "10",
                "K=10",
                " for FEMNIST, Sent140 and Synthetic(1,1), the mini-batch for local SGD is ",
                "B",
                "=",
                "10",
                "𝐵",
                "10",
                "B=10",
                ", the learning rate ",
                "η",
                "𝜂",
                "\\eta",
                " for FEMNIST, MNIST, Sent140, Synthetic(1,1) respectively are 0.03, 0.03, 0.3, 0.01.\nSpecific to ",
                "FedSAE",
                ", we initialize ",
                "(",
                "L",
                "k",
                "0",
                ",",
                "H",
                "k",
                "0",
                ")",
                "superscript",
                "subscript",
                "𝐿",
                "𝑘",
                "0",
                "superscript",
                "subscript",
                "𝐻",
                "𝑘",
                "0",
                "(L_{k}^{0},H_{k}^{0})",
                " to (1,2) and we set the inverse ratio parameter ",
                "𝒰",
                "=",
                "10",
                "𝒰",
                "10",
                "\\mathcal{U}=10",
                ", smooth index ",
                "α",
                "=",
                "0.95",
                "𝛼",
                "0.95",
                "\\alpha=0.95",
                ", the increment ",
                "γ",
                "1",
                "=",
                "3",
                "subscript",
                "𝛾",
                "1",
                "3",
                "\\gamma_{1}=3",
                ", ",
                "γ",
                "2",
                "=",
                "1",
                "subscript",
                "𝛾",
                "2",
                "1",
                "\\gamma_{2}=1",
                ", scale parameter of AL ",
                "β",
                "=",
                "0.01",
                "𝛽",
                "0.01",
                "\\beta=0.01",
                ". For the convenience of understanding, we will reiterate the meaning and value of above ",
                "FedSAE",
                " parameters again when we use it.",
                "Baseline ",
                "&",
                "\\&",
                " Metrics.",
                " The baseline of this paper is the vanilla FL framework ",
                "FedAvg",
                "[",
                "2",
                "]",
                ".\nIn our experiments, the affordable workload of each client changes over time. We fix the random seed to ensure that the same client has the same affordable workload set on different datasets. If the assignment of clients is less than its affordable workload, then the client can complete the training task, otherwise, it will drop out. For ",
                "FedAvg",
                ", the server fixes the assigned workload ",
                "E",
                "𝐸",
                "E",
                " of clients to 15. For ",
                "FedSAE",
                ", the workload of clients is predicted by the server. In order to eliminate the influence of client selection, we fixed the random seed of each round to ensure that when the training framework is different, the server will select the same clients in the same round of the same dataset.\nEach round we evaluate the global model. To compare each framework intuitively, we draw the top-1 testing accuracy, training loss of global model and drop out rate of clients in the following sections."
            ]
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Results of FedSAE-Ira, FedSAE-Fassa on FEMNIST, MNIST, Sent140 and Synthetic(1,1). We show the top-1 testing accuracy and the average drop out rate( see the row of % stragglers in the TABLE) as below. Besides, the percentages of accuracy improvement and stragglers mitigation are calculated.",
        "table": "<table id=\"S4.T2.16\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.16.17.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.16.17.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding:1pt 14.2pt;\" rowspan=\"2\">\n<span id=\"S4.T2.16.17.1.1.1\" class=\"ltx_text\">Dasaset</span>\n</th>\n<th id=\"S4.T2.16.17.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\" colspan=\"2\">FedAvg (Baseline)</th>\n<th id=\"S4.T2.16.17.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\" colspan=\"2\">FedSAE-Ira (Ours)</th>\n<th id=\"S4.T2.16.17.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\" colspan=\"2\">FedSAE-Fassa (Ours)</th>\n</tr>\n<tr id=\"S4.T2.16.18.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.16.18.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\">accuracy</th>\n<th id=\"S4.T2.16.18.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\">% stragglers</th>\n<th id=\"S4.T2.16.18.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\">accuracy</th>\n<th id=\"S4.T2.16.18.2.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\">% stragglers</th>\n<th id=\"S4.T2.16.18.2.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\">accuracy</th>\n<th id=\"S4.T2.16.18.2.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding:1pt 14.2pt;\">% stragglers</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.4.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding:1pt 14.2pt;\">FEMNIST</th>\n<td id=\"S4.T2.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 14.2pt;\">41.7</td>\n<td id=\"S4.T2.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 14.2pt;\">97.5</td>\n<td id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 14.2pt;\"><span id=\"S4.T2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">77.8 (<math id=\"S4.T2.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.1.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.1.m1.1b\"><ci id=\"S4.T2.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.1.m1.1c\">\\uparrow</annotation></semantics></math> 36.1)</span></td>\n<td id=\"S4.T2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 14.2pt;\">10.2 (<math id=\"S4.T2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.2.2.2.m1.1.1\" xref=\"S4.T2.2.2.2.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.m1.1b\"><ci id=\"S4.T2.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.m1.1c\">\\downarrow</annotation></semantics></math> 87.3)</td>\n<td id=\"S4.T2.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 14.2pt;\">75.1 (<math id=\"S4.T2.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.3.3.3.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.3.3.3.m1.1.1\" xref=\"S4.T2.3.3.3.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.3.3.m1.1b\"><ci id=\"S4.T2.3.3.3.m1.1.1.cmml\" xref=\"S4.T2.3.3.3.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.3.3.m1.1c\">\\uparrow</annotation></semantics></math> 33.4)</td>\n<td id=\"S4.T2.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 14.2pt;\"><span id=\"S4.T2.4.4.4.1\" class=\"ltx_text ltx_font_bold\">8.0 (<math id=\"S4.T2.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.4.4.4.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.4.4.4.1.m1.1.1\" xref=\"S4.T2.4.4.4.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.4.4.4.1.m1.1b\"><ci id=\"S4.T2.4.4.4.1.m1.1.1.cmml\" xref=\"S4.T2.4.4.4.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.4.4.4.1.m1.1c\">\\downarrow</annotation></semantics></math> 89.5)</span></td>\n</tr>\n<tr id=\"S4.T2.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T2.8.8.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding:1pt 14.2pt;\">MNIST</th>\n<td id=\"S4.T2.8.8.6\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">81.9</td>\n<td id=\"S4.T2.8.8.7\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">96.6</td>\n<td id=\"S4.T2.5.5.1\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\"><span id=\"S4.T2.5.5.1.1\" class=\"ltx_text ltx_font_bold\">89.4 (<math id=\"S4.T2.5.5.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.5.5.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.5.5.1.1.m1.1.1\" xref=\"S4.T2.5.5.1.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.5.5.1.1.m1.1b\"><ci id=\"S4.T2.5.5.1.1.m1.1.1.cmml\" xref=\"S4.T2.5.5.1.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.5.5.1.1.m1.1c\">\\uparrow</annotation></semantics></math> 7.5)</span></td>\n<td id=\"S4.T2.6.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">8.3 (<math id=\"S4.T2.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.6.6.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.6.6.2.m1.1.1\" xref=\"S4.T2.6.6.2.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.6.6.2.m1.1b\"><ci id=\"S4.T2.6.6.2.m1.1.1.cmml\" xref=\"S4.T2.6.6.2.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.6.6.2.m1.1c\">\\downarrow</annotation></semantics></math> 88.3)</td>\n<td id=\"S4.T2.7.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\"><span id=\"S4.T2.7.7.3.1\" class=\"ltx_text ltx_font_bold\">89.4 (<math id=\"S4.T2.7.7.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.7.7.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.7.7.3.1.m1.1.1\" xref=\"S4.T2.7.7.3.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.7.7.3.1.m1.1b\"><ci id=\"S4.T2.7.7.3.1.m1.1.1.cmml\" xref=\"S4.T2.7.7.3.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.7.7.3.1.m1.1c\">\\uparrow</annotation></semantics></math> 7.5)</span></td>\n<td id=\"S4.T2.8.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\"><span id=\"S4.T2.8.8.4.1\" class=\"ltx_text ltx_font_bold\">0.3 (<math id=\"S4.T2.8.8.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.8.8.4.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.8.8.4.1.m1.1.1\" xref=\"S4.T2.8.8.4.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.8.8.4.1.m1.1b\"><ci id=\"S4.T2.8.8.4.1.m1.1.1.cmml\" xref=\"S4.T2.8.8.4.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.8.8.4.1.m1.1c\">\\downarrow</annotation></semantics></math> 96.3)</span></td>\n</tr>\n<tr id=\"S4.T2.12.12\" class=\"ltx_tr\">\n<th id=\"S4.T2.12.12.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding:1pt 14.2pt;\">Sent140</th>\n<td id=\"S4.T2.12.12.6\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">63.9</td>\n<td id=\"S4.T2.12.12.7\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">96.5</td>\n<td id=\"S4.T2.9.9.1\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">72.1 (<math id=\"S4.T2.9.9.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.9.9.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.9.9.1.m1.1.1\" xref=\"S4.T2.9.9.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.9.9.1.m1.1b\"><ci id=\"S4.T2.9.9.1.m1.1.1.cmml\" xref=\"S4.T2.9.9.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.9.9.1.m1.1c\">\\uparrow</annotation></semantics></math> 8.2)</td>\n<td id=\"S4.T2.10.10.2\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\">10.3 (<math id=\"S4.T2.10.10.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.10.10.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.10.10.2.m1.1.1\" xref=\"S4.T2.10.10.2.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.10.10.2.m1.1b\"><ci id=\"S4.T2.10.10.2.m1.1.1.cmml\" xref=\"S4.T2.10.10.2.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.10.10.2.m1.1c\">\\downarrow</annotation></semantics></math> 86.2)</td>\n<td id=\"S4.T2.11.11.3\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\"><span id=\"S4.T2.11.11.3.1\" class=\"ltx_text ltx_font_bold\">72.4 (<math id=\"S4.T2.11.11.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.11.11.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.11.11.3.1.m1.1.1\" xref=\"S4.T2.11.11.3.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.11.11.3.1.m1.1b\"><ci id=\"S4.T2.11.11.3.1.m1.1.1.cmml\" xref=\"S4.T2.11.11.3.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.11.11.3.1.m1.1c\">\\uparrow</annotation></semantics></math> 8.5)</span></td>\n<td id=\"S4.T2.12.12.4\" class=\"ltx_td ltx_align_center\" style=\"padding:1pt 14.2pt;\"><span id=\"S4.T2.12.12.4.1\" class=\"ltx_text ltx_font_bold\">1.4 (<math id=\"S4.T2.12.12.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.12.12.4.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.12.12.4.1.m1.1.1\" xref=\"S4.T2.12.12.4.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.12.12.4.1.m1.1b\"><ci id=\"S4.T2.12.12.4.1.m1.1.1.cmml\" xref=\"S4.T2.12.12.4.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.12.12.4.1.m1.1c\">\\downarrow</annotation></semantics></math> 95.1)</span></td>\n</tr>\n<tr id=\"S4.T2.16.16\" class=\"ltx_tr\">\n<th id=\"S4.T2.16.16.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" style=\"padding:1pt 14.2pt;\">Synthetic(1,1)</th>\n<td id=\"S4.T2.16.16.6\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 14.2pt;\">20.9</td>\n<td id=\"S4.T2.16.16.7\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 14.2pt;\">97.1</td>\n<td id=\"S4.T2.13.13.1\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 14.2pt;\"><span id=\"S4.T2.13.13.1.1\" class=\"ltx_text ltx_font_bold\">78.9 (<math id=\"S4.T2.13.13.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.13.13.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.13.13.1.1.m1.1.1\" xref=\"S4.T2.13.13.1.1.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.13.13.1.1.m1.1b\"><ci id=\"S4.T2.13.13.1.1.m1.1.1.cmml\" xref=\"S4.T2.13.13.1.1.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.13.13.1.1.m1.1c\">\\uparrow</annotation></semantics></math> 58)</span></td>\n<td id=\"S4.T2.14.14.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 14.2pt;\">11.2 (<math id=\"S4.T2.14.14.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.14.14.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.14.14.2.m1.1.1\" xref=\"S4.T2.14.14.2.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.14.14.2.m1.1b\"><ci id=\"S4.T2.14.14.2.m1.1.1.cmml\" xref=\"S4.T2.14.14.2.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.14.14.2.m1.1c\">\\downarrow</annotation></semantics></math> 85.9)</td>\n<td id=\"S4.T2.15.15.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 14.2pt;\">78.4 (<math id=\"S4.T2.15.15.3.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.15.15.3.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.15.15.3.m1.1.1\" xref=\"S4.T2.15.15.3.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.15.15.3.m1.1b\"><ci id=\"S4.T2.15.15.3.m1.1.1.cmml\" xref=\"S4.T2.15.15.3.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.15.15.3.m1.1c\">\\uparrow</annotation></semantics></math> 57.5)</td>\n<td id=\"S4.T2.16.16.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 14.2pt;\"><span id=\"S4.T2.16.16.4.1\" class=\"ltx_text ltx_font_bold\">2.6 (<math id=\"S4.T2.16.16.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.16.16.4.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.16.16.4.1.m1.1.1\" xref=\"S4.T2.16.16.4.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.16.16.4.1.m1.1b\"><ci id=\"S4.T2.16.16.4.1.m1.1.1.cmml\" xref=\"S4.T2.16.16.4.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.16.16.4.1.m1.1c\">\\downarrow</annotation></semantics></math> 94.5)</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "FedAvg vs. FedSAE-Ira. FedSAE-Ira predicts clients’ local epoch according to the history of completing tasks of the latest round.\nIn FedSAE-Ira, we predict the affordable workload with the increment which is inversely proportional to the amount of the client’s current work.\nWe conduct several experiments on FEMNIST and MNIST to get a suitable value of the inverse ratio parameter 𝒰𝒰\\mathcal{U}, and some details are shown in Fig. 5.\nEmpirically, we set 𝒰𝒰\\mathcal{U} to 10 so the increment is 10Ekt10superscriptsubscript𝐸𝑘𝑡\\frac{10}{E_{k}^{t}} if the client performs its assigned workloads successfully.\nTo eliminate the influence of client selection, the server selects clients randomly on both FedSAE-Ira and FedAvg.\nWe implement FedSAE-Ira (Algorithm 2) in Tensorflow[41] and report the performance of FedSAE-Ira and FedAvg in Fig. 6 and TABLE II.\nWe can see that on the four datasets, systems heterogeneity leads to more than 90%percent9090\\% of stragglers (see the pink solid lint in the bottom row of Fig. 6). Moreover, from the training loss in the second row of Fig. 6, we can see that FedAvg has a divergent trend on FEMNIST, Sent140 and Synthetic(1,1). The evidence is that the training loss does not decrease but increases. In such a situation, FedSAE-Ira effectively improves the testing accuracy by up to 58%percent5858\\% (see the line of Synthetic(1,1) in TABLE II), and reduces the stragglers by up to 88.3%percent88.388.3\\%. Besides, the convergence rate of the global model is restored. Because FedSAE-Ira predicts an appropriate workload for each client, thus a large number of clients avoid dropping out."
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: The number of training rounds for FEMNIST to achieve the goal testing accuracy 60% and MNIST to achieve the goal testing accuracy 84%.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:1pt 5.4pt;\" rowspan=\"2\"><span id=\"S4.T3.1.1.1.1.1\" class=\"ltx_text\">Dataset</span></td>\n<td id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:1pt 5.4pt;\" colspan=\"6\"># Rounds of using AL in FedSAE-Ira</td>\n<td id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:1pt 5.4pt;\" rowspan=\"2\"><span id=\"S4.T3.1.1.1.3.1\" class=\"ltx_text\">\n<span id=\"S4.T3.1.1.1.3.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.T3.1.1.1.3.1.1.1\" class=\"ltx_tr\">\n<span id=\"S4.T3.1.1.1.3.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\" style=\"padding:1pt 5.4pt;\">FedAvg,</span></span>\n<span id=\"S4.T3.1.1.1.3.1.1.2\" class=\"ltx_tr\">\n<span id=\"S4.T3.1.1.1.3.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\" style=\"padding:1pt 5.4pt;\">E=15</span></span>\n</span></span></td>\n</tr>\n<tr id=\"S4.T3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">0</td>\n<td id=\"S4.T3.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">20</td>\n<td id=\"S4.T3.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">50</td>\n<td id=\"S4.T3.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">100</td>\n<td id=\"S4.T3.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">150</td>\n<td id=\"S4.T3.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">200</td>\n</tr>\n<tr id=\"S4.T3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:1pt 5.4pt;\">FEMNIST</td>\n<td id=\"S4.T3.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">48</td>\n<td id=\"S4.T3.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">30</td>\n<td id=\"S4.T3.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">31</td>\n<td id=\"S4.T3.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">37</td>\n<td id=\"S4.T3.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">32</td>\n<td id=\"S4.T3.1.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">32</td>\n<td id=\"S4.T3.1.3.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:1pt 5.4pt;\">-</td>\n</tr>\n<tr id=\"S4.T3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding:1pt 5.4pt;\">MNIST</td>\n<td id=\"S4.T3.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 5.4pt;\">25</td>\n<td id=\"S4.T3.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 5.4pt;\">19</td>\n<td id=\"S4.T3.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 5.4pt;\">21</td>\n<td id=\"S4.T3.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 5.4pt;\">19</td>\n<td id=\"S4.T3.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 5.4pt;\">19</td>\n<td id=\"S4.T3.1.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 5.4pt;\">19</td>\n<td id=\"S4.T3.1.4.4.8\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:1pt 5.4pt;\">-</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We divide the experiment of ",
                "FedSAE",
                " into three groups: ",
                "FedAvg vs. FedSAE-Ira",
                ", ",
                "FedAvg vs. FedSAE-Fassa",
                ", ",
                "FedSAE-Ira vs. FedSAE-Fassa",
                ". The former two groups are to illustrate the effects of ",
                "FedSAE",
                ", and the latter group is to illustrate the performance difference between the two prediction algorithms. The details are following:",
                "FedAvg vs. FedSAE-Ira.",
                " ",
                "FedSAE-Ira",
                " predicts clients’ local epoch according to the history of completing tasks of the latest round.\nIn ",
                "FedSAE-Ira",
                ", we predict the affordable workload with the increment which is inversely proportional to the amount of the client’s current work.\nWe conduct several experiments on FEMNIST and MNIST to get a suitable value of the inverse ratio parameter ",
                "𝒰",
                "𝒰",
                "\\mathcal{U}",
                ", and some details are shown in Fig. ",
                "5",
                ".\nEmpirically, we set ",
                "𝒰",
                "𝒰",
                "\\mathcal{U}",
                " to 10 so the increment is ",
                "10",
                "E",
                "k",
                "t",
                "10",
                "superscript",
                "subscript",
                "𝐸",
                "𝑘",
                "𝑡",
                "\\frac{10}{E_{k}^{t}}",
                " if the client performs its assigned workloads successfully.\nTo eliminate the influence of client selection, the server selects clients randomly on both ",
                "FedSAE-Ira",
                " and ",
                "FedAvg",
                ".\nWe implement ",
                "FedSAE-Ira",
                " (Algorithm ",
                "2",
                ") in Tensorflow",
                "[",
                "41",
                "]",
                " and report the performance of ",
                "FedSAE-Ira",
                " and ",
                "FedAvg",
                " in Fig. ",
                "6",
                " and TABLE ",
                "II",
                ".\nWe can see that on the four datasets, systems heterogeneity leads to more than ",
                "90",
                "%",
                "percent",
                "90",
                "90\\%",
                " of stragglers (see the pink solid lint in the bottom row of Fig. ",
                "6",
                "). Moreover, from the training loss in the second row of Fig. ",
                "6",
                ", we can see that ",
                "FedAvg",
                " has a divergent trend on FEMNIST, Sent140 and Synthetic(1,1). The evidence is that the training loss does not decrease but increases. In such a situation, ",
                "FedSAE-Ira",
                " effectively improves the testing accuracy by up to ",
                "58",
                "%",
                "percent",
                "58",
                "58\\%",
                " (see the line of Synthetic(1,1) in TABLE ",
                "II",
                "), and reduces the stragglers by up to ",
                "88.3",
                "%",
                "percent",
                "88.3",
                "88.3\\%",
                ". Besides, the convergence rate of the global model is restored. Because ",
                "FedSAE-Ira",
                " predicts an appropriate workload for each client, thus a large number of clients avoid dropping out.",
                "FedAvg vs. FedSAE-Fassa.",
                " ",
                "FedSAE-Fassa",
                " predicts clients’ local epoch according to the training history of all of the past communication rounds.\nWe show the experimental results of choosing the suitable parameters (i.e. ",
                "α",
                "𝛼",
                "\\alpha",
                ", ",
                "γ",
                "1",
                "subscript",
                "𝛾",
                "1",
                "\\gamma_{1}",
                ", ",
                "γ",
                "2",
                "subscript",
                "𝛾",
                "2",
                "\\gamma_{2}",
                ") for ",
                "FedSAE-Fassa",
                " in Fig. ",
                "7",
                ".\nEmpirically, we set smooth index ",
                "α",
                "𝛼",
                "\\alpha",
                " to 0.95.\nAnd we set the increment parameters ",
                "γ",
                "1",
                "subscript",
                "𝛾",
                "1",
                "\\gamma_{1}",
                ", ",
                "γ",
                "2",
                "subscript",
                "𝛾",
                "2",
                "\\gamma_{2}",
                " to ",
                "3",
                "3",
                "3",
                ", ",
                "1",
                "1",
                "1",
                ".\nThe participants of each round also are selected randomly.\nThe experimental results are shown in Fig. ",
                "6",
                ".\nSimilar to ",
                "FedSAE-Ira",
                ", ",
                "FedSAE-Fassa",
                " brings the accuracy improvement and mitigates straggling.\nSpecifically, ",
                "FedSAE-Fassa",
                " improves the testing accuracy by up to ",
                "57.5",
                "%",
                "percent",
                "57.5",
                "57.5\\%",
                ", which is similar to ",
                "FedSAE-Ira",
                ". Besides, ",
                "FedSAE-Fassa",
                " also reduces stragglers up to ",
                "96.3",
                "%",
                "percent",
                "96.3",
                "96.3\\%",
                ", which is ",
                "8",
                "%",
                "percent",
                "8",
                "8\\%",
                " higher than ",
                "FedSAE-Ira",
                ". The reason may be that ",
                "FedSAE-Fassa",
                " makes full use of clients’ past training history of completing tasks, which can more accurately predict the changing characteristics of the affordable workload.",
                "FedSAE-Ira vs. FedSAE-Fassa.",
                " In Fig. ",
                "6",
                ", ",
                "FedSAE-Ira",
                " and ",
                "FedSAE-Fassa",
                " are efficient in accuracy improving and straggler decreasing.\nTo be exact, ",
                "FedSAE-Ira",
                " brings accuracy improvement +0.4% higher than ",
                "FedSAE-Fassa",
                " on average. While ",
                "FedSAE-Fassa",
                " mitigates straggling +6.875% more significantly than ",
                "FedSAE-Ira",
                " on average. From the data in TABLE ",
                "II",
                ", we see that our framework ",
                "FedSAE",
                " improves absolute testing accuracy by 26.7% and reduces the straggle rate by 90.3% on average.",
                "Although accuracy is improved, the convergence rate is still changeless.\nSo we import Active Learning to accelerate the model convergence rate as described in the following section."
            ]
        ]
    }
}