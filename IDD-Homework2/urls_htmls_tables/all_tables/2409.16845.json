{
    "id_table_1": {
        "caption": "TABLE I:  Performance of DANN and ResNet trained on synthetic data and tested across different domains   with different data preprocessing techniques (for example, pixel-level clutter reduction).",
        "table": "S1.T1.1.1",
        "footnotes": [],
        "references": [
            "To address existing challenges, a novel DG framework for SAR-ATR named integrating clutter reduction module (CRM) and adversarial learning (IRASNet) is proposed in this study. As shown in Fig.  1 , extracting domain-invariant features solely through adversarial learning can lead to overfitting in clutter regions owing to the inherent challenge of learning clutter. Additionally, separating the target and shadow regions during preprocessing can cause underfitting, stemming from the high domain variation associated with segmentation techniques. Unlike existing algorithms, IRASNet addresses both of the challenges simultaneously by combining clutter reduction at the feature level through a CRM and extracting domain-invariant features through adversarial learning to achieve DG. Additionally, incorporating shadow features into clutter-reduced features can improve ATR performance  [ choi2022fusion ] . Moreover, higher performance can be anticipated by increasing SCR at the feature level to focus on the target region.",
            "General DL frameworks are prone to learning clutter regions. Belloni et al.  [ belloni2020explainability ] , Li et al.  [ li2023discovering ] , and Heiligers et al.  [ heiligers2018importance ]  demonstrated that data and model biases caused models to exhibit non-causality to background clutter, leading to overfitting and undesirable ATR behavior. To analyze their finding in the context of DG, explainable artificial intelligence (XAI), specifically Shapley additive explanations (SHAP)  [ lundberg2017unified ] , is employed to directly visualize the rationale behind decisions of the network, as illustrated in Fig.  1 . SHAP allows for the visual inspection of how each pixel in an input image impacts the prediction of a DL model. The DL model involves a network for DG based on adversarial learning  [ dann ] , trained on synthetic and noisy data from the SAMPLE dataset  [ smpl ] , and tested on five classes of measured data. Despite overcoming domain shifts and extracting domain-invariant features through DIRL, the results show that the network makes decisions by referencing clutter regions. Therefore, clutter is a significant obstacle to DG-ATR problems in general DL frameworks. Thus, models require training to better learn true causal features, specifically the intrinsic characteristics of their targets, while relying less on background clutter.",
            "where  I T  ( p  , q  )  R P T  Q T subscript I T superscript p  superscript q  superscript R subscript P T subscript Q T I_{T}(p^{\\prime},q^{\\prime})\\in\\mathbb{R}^{P_{T}\\times Q_{T}} italic_I start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_p start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , italic_q start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT )  blackboard_R start_POSTSUPERSCRIPT italic_P start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  italic_Q start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  represents the target region.  P T subscript P T P_{T} italic_P start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  Q T subscript Q T Q_{T} italic_Q start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  denote the width and height of the target region, respectively. Similarly,  I C  ( p  , q  )  R P C  Q C subscript I C superscript p  superscript q  superscript R subscript P C subscript Q C I_{C}(p^{\\prime\\prime},q^{\\prime\\prime})\\in\\mathbb{R}^{P_{C}\\times Q_{C}} italic_I start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_p start_POSTSUPERSCRIPT   end_POSTSUPERSCRIPT , italic_q start_POSTSUPERSCRIPT   end_POSTSUPERSCRIPT )  blackboard_R start_POSTSUPERSCRIPT italic_P start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT  italic_Q start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  represents the clutter region.  P C subscript P C P_{C} italic_P start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT  and  Q C subscript Q C Q_{C} italic_Q start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT  represent the width and height of the clutter region, respectively. Additionally,  N C subscript N C N_{C} italic_N start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT  denotes the total number of pixels in the clutter region. The maximization of Eq. ( 1 ) is implemented in  [ choi2022fusion ]  using expressions:",
            "Further, we calculated SCR using Eq.  1  and adjusted the intensity of the clutter region according to the variation value to generate a new  x s  c  r superscript x s c r x^{scr} italic_x start_POSTSUPERSCRIPT italic_s italic_c italic_r end_POSTSUPERSCRIPT . The dataset comprised 13 test sets, with SCR increasing from   - - 3 dB to 3 dB in increments of 0.5 dB. The newly generated SAR images with varying SCR are presented in  Supplementary Material . Notably, SCR variations were only applied to the measured data to evaluate models trained on synthetic data.",
            "DG-ATR problems focus on domain-invariant feature extraction by aligning the distributions of multiple source domains. Therefore, the proposed framework utilizes data augmentation from synthetic datasets based on existing studies  [ mj ] ,  [ inkawhich2021bridging ]  for robust clutter reduction and constructing multiple source domains. As shown in Fig.  S1 , the key points of the target region differ across domains. Thus, to realize robust feature-level clutter reduction, additionally reflecting changes in the target signature of the clutter variants is necessary.",
            "In Section  S1 , the augmented dataset involved a ten-fold augmentation of the synthetic dataset for use in the experiments. The augmented dataset was consistently applied to all comparison models across the experiments to evaluate how well the DL models structurally reduced the domain gap at the feature level.",
            "In this section, we describe an ablation study conducted based on scenario 2 to analyze the impact of various components of our method on performance. IRASNet comprised five main components:  F T  M  F I  N  tensor-product subscript F T M superscript subscript F I N  F_{TM}\\otimes F_{IN}^{\\prime} italic_F start_POSTSUBSCRIPT italic_T italic_M end_POSTSUBSCRIPT  italic_F start_POSTSUBSCRIPT italic_I italic_N end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  F S  M  F I  N  tensor-product subscript F S M superscript subscript F I N  F_{SM}\\otimes F_{IN}^{\\prime} italic_F start_POSTSUBSCRIPT italic_S italic_M end_POSTSUBSCRIPT  italic_F start_POSTSUBSCRIPT italic_I italic_N end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , target mask loss, shadow mask loss, which together formed the CRM, and adversarial loss. Herein,  F T  M  F I  N  tensor-product subscript F T M superscript subscript F I N  F_{TM}\\otimes F_{IN}^{\\prime} italic_F start_POSTSUBSCRIPT italic_T italic_M end_POSTSUBSCRIPT  italic_F start_POSTSUBSCRIPT italic_I italic_N end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  and  F S  M  F I  N  tensor-product subscript F S M superscript subscript F I N  F_{SM}\\otimes F_{IN}^{\\prime} italic_F start_POSTSUBSCRIPT italic_S italic_M end_POSTSUBSCRIPT  italic_F start_POSTSUBSCRIPT italic_I italic_N end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  represent  F T subscript F T F_{T} italic_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  F S subscript F S F_{S} italic_F start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , respectively. Not using meant concatenating  F T  M subscript F T M F_{TM} italic_F start_POSTSUBSCRIPT italic_T italic_M end_POSTSUBSCRIPT  and  F S  M subscript F S M F_{SM} italic_F start_POSTSUBSCRIPT italic_S italic_M end_POSTSUBSCRIPT  during the AT phase to refine the features. We evaluated the contribution of each component to performance using two approaches. First, we analyzed the impact of adversarial loss by examining the presence or absence of adversarial loss in the base model and IRASNet. Second, we analyzed the effect of the proposed CRM by evaluating the presence or absence of each component in the CRM. Table  S1  shows the overall experimental results obtained through the ablation study.",
            "2) To analyze the impact of CRM components, we used a CNN with adversarial loss as the baseline model. According to Table  S1 , introducing  L t subscript L t L_{t} italic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and  L s subscript L s L_{s} italic_L start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT  increased performance by approximately 3 % percent \\% %  compared to the baseline model, indicating that utilizing the positional information of the target and shadow areas contributed to performance improvement. However, when  F T subscript F T F_{T} italic_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  F S subscript F S F_{S} italic_F start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT  were additionally introduced, accuracy increased by approximately 1.4 % percent \\% % . When using only  L t subscript L t L_{t} italic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and  L s subscript L s L_{s} italic_L start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , the mask feature was passed to the next layer. The mask feature learned from Mask GT, composed of only 0 and 1, did not secure inter-class discrimination in the feature space even after passing through AT. Herein, Fig.  S4  shows the visualization of  F t  m subscript F t m F_{tm} italic_F start_POSTSUBSCRIPT italic_t italic_m end_POSTSUBSCRIPT  and  F s  m subscript F s m F_{sm} italic_F start_POSTSUBSCRIPT italic_s italic_m end_POSTSUBSCRIPT . Evidently,  F t  m subscript F t m F_{tm} italic_F start_POSTSUBSCRIPT italic_t italic_m end_POSTSUBSCRIPT  and  F s  m subscript F s m F_{sm} italic_F start_POSTSUBSCRIPT italic_s italic_m end_POSTSUBSCRIPT  omitted the topology that contained scattering points in the target. Therefore, IRASNet, which utilized both  F T subscript F T F_{T} italic_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  F S subscript F S F_{S} italic_F start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , showed improved inter-class discrimination, resulting in higher performance. Meanwhile, the algorithm that introduced only  F T subscript F T F_{T} italic_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  F S subscript F S F_{S} italic_F start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT  also improved performance by about 3 % percent \\% %  compared to the baseline model. The configuration achieved a certain level of discrimination, but no limitation in clutter reduction was posed as the positional information of the target and shadow was not accurately reflected. Moreover, among the algorithms where positional information was reflected in only one of  F T subscript F T F_{T} italic_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  F S subscript F S F_{S} italic_F start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , using shadow information resulted in higher performance, but no significant difference compared to cases without positional information were observed."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Training and test SAR samples under four scenarios of experimental setup",
        "table": "S1.T1.1.1.2.2.1.1",
        "footnotes": [],
        "references": [
            "As illustrated in Fig.  2  (a), when the SCR is low in the measured image, the information in the target and shadow region can be entirely lost, despite applying the same segmentation method. The loss cannot be compensated within the DL network  [ strang2012linear ] , leading to degraded performance. As indicated in Table  I , performance significantly declines when training and testing with only target and shadow regions compared to using images that include clutter regions. Even in the DIRL performed by DANN  [ dann ] , the domain gap was not bridged, likely due to information loss during segmentation. Therefore, performing feature-level clutter reduction to avoid information loss is imperative, even if it results in less effective reduction of clutter regions.",
            "Furthermore, Li et al.  [ li_HDANet ]  proposed a hierarchical disentanglement-alignment network (HDANet) that reduced clutter and extracted target features through multi-task-assisted mask disentanglement and domain alignment. However, the approach did not utilize shadow information at the feature level, resulting in a decrease in ATR performance compared to when both target and shadow information were used together  [ choi2022fusion ] . Herein, Fig.  2  (b) and (c) present the features of synthetic and measured data for CFA [ cfa ]  and HDANet [ li_HDANet ]  trained on synthetic and augmented datasets, respectively. On examining the yellow bounding boxes, high values remained in the clutter region of the measured data, indicating that clutter reduction was not perfectly achieved. Currently, researchers have not extensively studied clutter reduction in the context of DG. To enhance DG performance, ensuring both domain invariance and clutter reduction simultaneously is essential.",
            "One method to obtain mask features involves inputting target and shadow masks into the DL model. However, as shown in Fig.  2 , a loss can occur at the pixel level. Therefore, we adopt an approach where convolutional layers learn the masks by using target and shadow masks as GT. The masks are obtained using the method proposed in an existing study  [ choi2022fusion ] , where  m t  { 0 , 1 } P  Q subscript m t superscript 0 1 P Q m_{t}\\in{\\{0,1\\}}^{P\\times Q} italic_m start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  { 0 , 1 } start_POSTSUPERSCRIPT italic_P  italic_Q end_POSTSUPERSCRIPT  and  m s  { 0 , 1 } P  Q subscript m s superscript 0 1 P Q m_{s}\\in{\\{0,1\\}}^{P\\times Q} italic_m start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT  { 0 , 1 } start_POSTSUPERSCRIPT italic_P  italic_Q end_POSTSUPERSCRIPT  are the target and shadow masks, respectively.",
            "Additionally, using scenarios 1 and 2, we conducted comparative experiments from the perspective of clutter reduction. We compared IRASNet with algorithms such as those presented by previous studies  [ choi2022fusion ,  wang2019sar ] , [ zhou2018sar ] , which processed by segmenting target and shadow areas in the preprocessing stage. Further, algorithm comparison was performed with that of previous studies  [ li_HDANet ]  and  [ cfa ] , which employed feature-level clutter reduction methods and clutter-robust learning methods, respectively. As shown in Table  IV , feature-level clutter reduction methods generally achieved higher performance compared to pixel-level clutter reduction methods. Despite the mitigated distribution differences at the pixel level through data augmentation, the result demonstrated, through various algorithms, that the performance was significantly affected by the information lost at the input stage, as shown in Fig.  2 .",
            "The statistical histograms of the synthetic and measured data included in the SAMPLE Dataset are shown in Fig.  S2 , illustrating the distribution differences between the two datasets. Additionally, the SAR images corresponding to Scenario 3 with varying SCR are presented in Fig.  S3  (a). At   - - 3dB, the average brightness of the clutter region was similar to that of the target, while at  + + + 3dB, the average brightness of the clutter region resembled that of the shadow area. Lastly, the data referred to as unknown clutter, corresponding to Scenario 4, is shown in Fig.  S3  (b)."
        ]
    },
    "id_table_3": {
        "caption": "TABLE III:  Experimental results under scenario 1 and 2  according to generalization methods",
        "table": "S1.T1.1.1.2.2.2.1",
        "footnotes": [],
        "references": [
            "IRASNet is a framework designed to address the DG problem, achieving high performance on measured data when trained solely on a  100 % percent 100 100\\% 100 %  synthetic dataset. The overall concept of the proposed IRASNet is presented in Fig.  3 . This section details the stepwise procedures of the proposed framework.",
            "The core of the proposed IRASNet lies in the novel feature-level clutter reduction mechanism (Fig.  3 , CRM), which simultaneously reflects the features of the target and shadow regions. Conventional clutter reduction methods reduce the intensity of clutter while preserving that of the target using the positional information of both the target and clutter regions  [ li_HDANet ,  zhou2018sar ,  wang2019sar ,  choi2022fusion ] . The methods aim to maximize SCR defined by:",
            "PST is inspired by the key mechanism proposed in the pixel-level clutter reduction method introduced in Eq. ( 3 ). The technique obtains target and shadow features by multiplying the mask features of the target and shadow with the input features.",
            "The statistical histograms of the synthetic and measured data included in the SAMPLE Dataset are shown in Fig.  S2 , illustrating the distribution differences between the two datasets. Additionally, the SAR images corresponding to Scenario 3 with varying SCR are presented in Fig.  S3  (a). At   - - 3dB, the average brightness of the clutter region was similar to that of the target, while at  + + + 3dB, the average brightness of the clutter region resembled that of the shadow area. Lastly, the data referred to as unknown clutter, corresponding to Scenario 4, is shown in Fig.  S3  (b)."
        ]
    },
    "id_table_4": {
        "caption": "TABLE IV:  Experimental results under scenario 1 and 2  according to clutter mitigation methods",
        "table": "S1.T1.1.1.2.2.4.1",
        "footnotes": [],
        "references": [
            "where  f  (  ;  F ) f  subscript  F f(\\cdot;\\theta_{F}) italic_f (  ; italic_ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT )  denotes a CNN-based extractor with internal parameters   F subscript  F \\theta_{F} italic_ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT  and  N F C subscript N subscript F C N_{F_{C}} italic_N start_POSTSUBSCRIPT italic_F start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT end_POSTSUBSCRIPT  represents total number of pixels in the clutter feature. Additionally,  F T  R C  W  H subscript F T superscript R C W H F_{T}\\in\\mathbb{R}^{C\\times W\\times H} italic_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  blackboard_R start_POSTSUPERSCRIPT italic_C  italic_W  italic_H end_POSTSUPERSCRIPT ,  F C  R C  W  H subscript F C superscript R C W H F_{C}\\in\\mathbb{R}^{C\\times W\\times H} italic_F start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT  blackboard_R start_POSTSUPERSCRIPT italic_C  italic_W  italic_H end_POSTSUPERSCRIPT , and  F S  R C  W  H subscript F S superscript R C W H F_{S}\\in\\mathbb{R}^{C\\times W\\times H} italic_F start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT  blackboard_R start_POSTSUPERSCRIPT italic_C  italic_W  italic_H end_POSTSUPERSCRIPT  represent the feature maps of the target, clutter, and shadow regions, respectively. Herein, Eq. ( 4 ) represents the objectives that CRM aims to achieve. While maximizing SCR on the feature map, the shadow feature map must also minimize its difference from the encoded segmentation mask  H S  R C  W  H subscript H S superscript R C W H H_{S}\\in\\mathbb{R}^{C\\times W\\times H} italic_H start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT  blackboard_R start_POSTSUPERSCRIPT italic_C  italic_W  italic_H end_POSTSUPERSCRIPT , which includes the positional information of the shadows. The method for obtaining  H S subscript H S H_{S} italic_H start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT  is introduced in the positional supervision task (PST). The CRM for solving Eq. ( 4 ) comprises two sub-parts:  1) positional supervision task (PST) and 2) attention task (AT) .",
            "1) SAMPLE dataset:  To verify the DG performance of the proposed IRASNet, we adopted the SAMPLE dataset  [ smpl ]  that included both synthetic and measured data. In the dataset, synthetic data were generated using sophisticated CAD models and asymmetric ray tracing techniques  [ smpl ] , while the measured data were directly obtained from the MSTAR dataset  [ zhang2023vsfa ] . The SAMPLE dataset comprised 10 ground targets captured under various SOC conditions, which were categorized into 10 different ground vehicle target classes: 2S1, BMP2, BTR70, M1, M2, M35, M548, M60, T72, and ZSU23. The paired images of synthetic and measured data for each class are shown in Fig.  4 . The SAR target images were obtained using an X-band HH-polarized SAR with a resolution of 0.30.3 m, and image size of 128128 pixels. The depression angle ranged from 14 to 17, and the azimuth angle ranged from 10 to 80. The entire SAMPLE dataset contained 1,345 paired SAR synthetic and measured image pairs with the same imaging parameters, including depression and azimuth angles.",
            "The proposed IRASNet was designed to maximize SCR in the feature map, as expressed in Eq.  4 . For numerical validation, we examined the SCR of the feature maps under SCR fluctuation. HDANet  [ li_HDANet ]  extracted features with omitted details due to the deep encoder layers, making it impossible to identify the exact locations of targets, shadows, and clutter. Thus, the SCR of the feature map could not be calculated and was excluded from the analysis. As shown in Fig.  6 , the proposed IRASNet improved the feature map SCR by approximately 10 dB in layer 1 and over 19 dB in layer 2 compared to the conventional DANN  [ dann ] . Thus, the optimization problem in Eq.  4  has been successfully achieved.",
            "2) To analyze the impact of CRM components, we used a CNN with adversarial loss as the baseline model. According to Table  S1 , introducing  L t subscript L t L_{t} italic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and  L s subscript L s L_{s} italic_L start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT  increased performance by approximately 3 % percent \\% %  compared to the baseline model, indicating that utilizing the positional information of the target and shadow areas contributed to performance improvement. However, when  F T subscript F T F_{T} italic_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  F S subscript F S F_{S} italic_F start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT  were additionally introduced, accuracy increased by approximately 1.4 % percent \\% % . When using only  L t subscript L t L_{t} italic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and  L s subscript L s L_{s} italic_L start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , the mask feature was passed to the next layer. The mask feature learned from Mask GT, composed of only 0 and 1, did not secure inter-class discrimination in the feature space even after passing through AT. Herein, Fig.  S4  shows the visualization of  F t  m subscript F t m F_{tm} italic_F start_POSTSUBSCRIPT italic_t italic_m end_POSTSUBSCRIPT  and  F s  m subscript F s m F_{sm} italic_F start_POSTSUBSCRIPT italic_s italic_m end_POSTSUBSCRIPT . Evidently,  F t  m subscript F t m F_{tm} italic_F start_POSTSUBSCRIPT italic_t italic_m end_POSTSUBSCRIPT  and  F s  m subscript F s m F_{sm} italic_F start_POSTSUBSCRIPT italic_s italic_m end_POSTSUBSCRIPT  omitted the topology that contained scattering points in the target. Therefore, IRASNet, which utilized both  F T subscript F T F_{T} italic_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  F S subscript F S F_{S} italic_F start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , showed improved inter-class discrimination, resulting in higher performance. Meanwhile, the algorithm that introduced only  F T subscript F T F_{T} italic_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  F S subscript F S F_{S} italic_F start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT  also improved performance by about 3 % percent \\% %  compared to the baseline model. The configuration achieved a certain level of discrimination, but no limitation in clutter reduction was posed as the positional information of the target and shadow was not accurately reflected. Moreover, among the algorithms where positional information was reflected in only one of  F T subscript F T F_{T} italic_F start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  F S subscript F S F_{S} italic_F start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , using shadow information resulted in higher performance, but no significant difference compared to cases without positional information were observed."
        ]
    },
    "id_table_5": {
        "caption": "TABLE V:  Average accuracy and accuracy difference between 0 and   - - 3 dB and between 0 and 3 dB datasets obtained on the SCR fluctuation test set under scenario 3.",
        "table": "S1.T1.1.1.2.2.5.1",
        "footnotes": [],
        "references": [
            "As shown in Fig.  5 , we visualized the feature space using t-SNE  [ van2008visualizing ]  for ResNet  [ resnet ] , which recorded the highest performance, and DANN  [ dann ] , the baseline for IRASNet. We observed that in the latent spaces of ResNet  [ resnet ]  and DANN  [ dann ] , the alignment of four classes was not well-matched, and the distinction between classes was visually lacking. Thus, the domain gap had not been fully overcome in the feature space. Contrarily, the proposed IRASNet successfully reduced the domain gap through feature-level clutter reduction, allowing for both domain alignment and discrimination in the t-SNE visualization. Moreover, IRASNet achieved state-of-the-art performance, being 2.34 % percent \\% %  higher than the existing technique  [ inkawhich2021bridging ]  under scenario 1 and 2.97 % percent \\% %  higher than the existing models under scenario 2. The results support our motivation to reduce clutter at the feature level for DG-ATR."
        ]
    },
    "id_table_6": {
        "caption": "TABLE VI:  Experimental results under scenario 2 and 4",
        "table": "S1.T1.1.1.2.2.7.1",
        "footnotes": [],
        "references": [
            "1) SCR fluctuation dataset:  As shown in Fig.  6 , performance decreased when the SCR was low and improved as the SCR increased. The proposed IRASNet minimized performance degradation even in low SCR conditions and enhanced performance in high SCR conditions, achieving the best performance in most test sets with SCR fluctuations. Notably, even with the same training dataset, IRASNet improved performance by 7.88 % percent \\% %  compared to an existing method  [ li_HDANet ]  in a   - - 3 dB dataset, where the brightness difference between the target and clutter was minimal. Thus, a further improvement in feature-level clutter reduction performance over existing methods is required. Additionally, compared to an existing study  [ cfa ] , which used clutter-robust learning methods, IRASNet showed a 25.28 % percent \\% %  improvement in performance. Thus, the approach of removing clutter was more effective in reducing the influence of clutter and achieving high performance than learning clutter. Additionally, the proposed IRASNet achieved over 5 % percent \\% %  better performance than all other methods, even in scenarios where SCR was higher than in the training dataset.",
            "The proposed IRASNet was designed to maximize SCR in the feature map, as expressed in Eq.  4 . For numerical validation, we examined the SCR of the feature maps under SCR fluctuation. HDANet  [ li_HDANet ]  extracted features with omitted details due to the deep encoder layers, making it impossible to identify the exact locations of targets, shadows, and clutter. Thus, the SCR of the feature map could not be calculated and was excluded from the analysis. As shown in Fig.  6 , the proposed IRASNet improved the feature map SCR by approximately 10 dB in layer 1 and over 19 dB in layer 2 compared to the conventional DANN  [ dann ] . Thus, the optimization problem in Eq.  4  has been successfully achieved.",
            "CFA  [ cfa ]  employed robust learning rather than reducing clutter at the feature level through contrastive learning. Therefore, even with a low feature map SCR, the influence of clutter was reduced and consistent results were obtained even when the SCR fluctuation was +3dB, as shown in Fig.  6 . However, in cases not present in the training data (such as   - - 3dB), the performance dropped significantly, failing to guarantee consistent results. Therefore, a strong dependency on the training data was observed."
        ]
    },
    "id_table_7": {
        "caption": "TABLE VII:  Proportion of the sum of SHAP values   for each area in the SAMPLE measured dataset.",
        "table": "S1.T1.1.1.2.2.8.1",
        "footnotes": [],
        "references": [
            "To visually confirm the results, Fig.  7  shows the SHAP value visualizations for each pixel in images corresponding to the m60 and m1 classes, under the same target conditions for SAMPLE measured, SCR fluctuation   - - 3 dB, +3 dB, and different background clutter. According to Table  VII  and Fig.  7 , DANN  [ dann ]  did not perform clutter reduction, resulting in contributions across all areas of the image, not just the target region. Additionally, CFA  [ cfa ] , through clutter-robust learning, focused more on target and shadow areas compared to DANN  [ dann ] . However, since the values of the clutter area remained in the feature space, it still relied on the clutter area for decision-making. While HDANet  [ li_HDANet ]  significantly reduced the influence through feature-level clutter reduction, it still made decisions using clutter areas.",
            "Moreover, as seen in Fig.  7 , the models primarily focused on the left part of the shadow when making decisions because, in the SAMPLE dataset, the difference in brightness between the shadow and clutter made the shadow more prominent. The characteristic acted as an important feature in CNNs, leading most networks to make decisions based on the left part of the shadow. The proposed CRM was trained considering the shadow mask through  F S  M subscript F S M F_{SM} italic_F start_POSTSUBSCRIPT italic_S italic_M end_POSTSUBSCRIPT , enhancing discriminability and positively affecting performance. While changes in the brightness of clutter and shadow affected the decisions of all networks, the emphasis on shadows positively influenced the results even when some clutter was considered. SHAP analysis revealed a tendency to closely examine the ends of shadow areas, visually demonstrating that shadows contained important information, as mentioned in  [ choi2022fusion ] . The information played a crucial role in enhancing class-specific discriminability."
        ]
    },
    "id_table_8": {
        "caption": "TABLE S1:  Ablation experiments of different components in IRASNet.",
        "table": "S4.EGx1",
        "footnotes": [],
        "references": []
    },
    "id_table_9": {
        "caption": "",
        "table": "S4.EGx2",
        "footnotes": [],
        "references": []
    },
    "id_table_10": {
        "caption": "",
        "table": "S4.EGx3",
        "footnotes": [],
        "references": []
    },
    "id_table_11": {
        "caption": "",
        "table": "S3.E4",
        "footnotes": [],
        "references": []
    },
    "id_table_12": {
        "caption": "",
        "table": "S4.EGx4",
        "footnotes": [],
        "references": []
    },
    "id_table_13": {
        "caption": "",
        "table": "S3.E6",
        "footnotes": [],
        "references": []
    },
    "id_table_14": {
        "caption": "",
        "table": "S3.E7",
        "footnotes": [],
        "references": []
    },
    "id_table_15": {
        "caption": "",
        "table": "S3.E8",
        "footnotes": [],
        "references": []
    },
    "id_table_16": {
        "caption": "",
        "table": "S3.E9",
        "footnotes": [],
        "references": []
    },
    "id_table_17": {
        "caption": "",
        "table": "S4.EGx5",
        "footnotes": [],
        "references": []
    },
    "id_table_18": {
        "caption": "",
        "table": "S4.EGx6",
        "footnotes": [],
        "references": []
    },
    "id_table_19": {
        "caption": "",
        "table": "S4.EGx7",
        "footnotes": [],
        "references": []
    },
    "id_table_20": {
        "caption": "",
        "table": "S3.E13",
        "footnotes": [],
        "references": []
    },
    "id_table_21": {
        "caption": "",
        "table": "S3.T2.8.8",
        "footnotes": [],
        "references": []
    },
    "id_table_22": {
        "caption": "",
        "table": "S3.T2.1.1.1.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_23": {
        "caption": "",
        "table": "S3.T2.1.1.1.8.1",
        "footnotes": [],
        "references": []
    },
    "id_table_24": {
        "caption": "",
        "table": "S4.T3.2.2",
        "footnotes": [],
        "references": []
    },
    "id_table_25": {
        "caption": "",
        "table": "S4.T3.2.2.4.2.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_26": {
        "caption": "",
        "table": "S4.T3.2.2.4.2.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_27": {
        "caption": "",
        "table": "S4.T4.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_28": {
        "caption": "",
        "table": "S4.T4.1.1.2.2.3.1",
        "footnotes": [],
        "references": []
    },
    "id_table_29": {
        "caption": "",
        "table": "S4.T4.1.1.2.2.4.1",
        "footnotes": [],
        "references": []
    },
    "id_table_30": {
        "caption": "",
        "table": "S4.T5.6.4",
        "footnotes": [],
        "references": []
    },
    "id_table_31": {
        "caption": "",
        "table": "S4.T6.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_32": {
        "caption": "",
        "table": "S4.T7.3.3",
        "footnotes": [],
        "references": []
    },
    "id_table_33": {
        "caption": "",
        "table": "S2.E1",
        "footnotes": [],
        "references": []
    },
    "id_table_34": {
        "caption": "",
        "table": "S4.T1.5.5",
        "footnotes": [],
        "references": []
    }
}