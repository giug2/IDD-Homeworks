{
    "id_table_1": {
        "caption": "Table 1.  Overall Preformance of our solutions on all 3 Tasks.",
        "table": "S3.T1.1",
        "footnotes": [],
        "references": [
            "Web search results  Each retrieved web search result comprises five fields:  page name ,  page url ,  page snippet ,  page last modified  and  page result . See Table  3  in Appendix  A.1  for an example.",
            "Our approach, akin to most Retrieval-Augmented Generation (RAG) systems, comprises three primary phases: retrieval, augmentation and generation. In all phases, we implement routing mechanisms to address diverse query types. Figure  1  illustrates the pipeline of our solution, while the remainder of this section details the three main phases and the routers employed in this challenge.",
            "Comparing our solutions to the RAG Baseline, we observe significant advantages in performance across all three tasks. In Table  1 , our approach showcases notable improvements in accuracy and information retention. Specifically, when contrasted with the RAG Baseline, our solutions demonstrate superior results with reduced hallucination rates and enhanced information completeness. Task 2 and Task 3, in particular, exhibit substantial enhancements in accuracy and reduced hallucination percentages, highlighting the effectiveness of our proposed methodologies in addressing these key metrics."
        ]
    },
    "id_table_2": {
        "caption": "Table 2.  Ablation Study for Major Strategies Employed in the System.",
        "table": "S3.T2.1",
        "footnotes": [],
        "references": [
            "Mock APIs  APIs for retrieving structured data from Mock KGs with predefined parameters, which are categorized by domain and output in JSON format. See Example in Appendix  A.2   .",
            "To enhance our QA system, we need to extract useful and relevant information from web search results. The primary process for retrieving web content is illustrated in Figure  2 .",
            "Table  2  presents the ablation study for major strategies employed in our solution."
        ]
    },
    "id_table_3": {
        "caption": "Table 3.  An Example of Web Search Results.",
        "table": "A1.T3.1",
        "footnotes": [],
        "references": [
            "Web search results  Each retrieved web search result comprises five fields:  page name ,  page url ,  page snippet ,  page last modified  and  page result . See Table  3  in Appendix  A.1  for an example.",
            "HTML Parsing : Structured HTML is often unnecessarily verbose and contains substantial extraneous information that can impede subsequent segmentation operations. Therefore, it is crucial to first convert this structured format into natural language text that is more amenable to processing by Large Language Models. We conducted experiments with various HTML parsing methods, including BeautifulSoup, Newspaper, Markdownify, and several others. After evaluating both parsing efficiency and quality, we ultimately selected Newspaper. See  A.3  for more details about experiment results.",
            "A total of 38 Mock APIs were provided for tasks 2&3. As mentioned above, these Mock APIs can be categorized into five distinct domains, with no overlap between the APIs of different domains. Naturally, we designed separate workflows for each domain using a Domain Router. However, the overarching process flow of the workflows across all domains remains consistent, as shown in Figure  3 :"
        ]
    },
    "id_table_4": {
        "caption": "Table 4.  Experiment Results of HTML Parsing Methods",
        "table": "A1.T4.1",
        "footnotes": [],
        "references": [
            "Named Entity Recognition (NER) : We directly utilize  Llama3-70B-Instruct   (AI,  2024 )  to identify and classify named entities in the question into predefined categories, such as movie names and artist names. Specific prompts are presented in the Appendix  A.4 ."
        ]
    },
    "global_footnotes": []
}