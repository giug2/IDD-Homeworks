{
    "S2.E1": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S2.E2": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S3.E3": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S3.E4": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S3.E5": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S4.E6": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S4.T1.5.1": {
        "caption": null,
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.5.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.5.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.5.1.1.1.1\">Model</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.5.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.1.1.1.2.1\">K=1</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.5.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.1.1.1.3.1\">K=3</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.5.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.1.1.1.4.1\">K=5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.5.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.1.1.1.5.1\">K=7</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.5.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.1.1.1.6.1\">K=9</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.5.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T1.5.1.2.2.1\">GPT2-small</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.5.1.2.2.2\">0.157</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.5.1.2.2.3\">0.179</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.5.1.2.2.4\">0.131</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.5.1.2.2.5\">0.176</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.5.1.2.2.6\">0.166</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.5.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.5.1.3.1.1\">GPT2-small-</th>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.5.1.3.1.2\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.5.1.3.1.3\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.5.1.3.1.4\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.5.1.3.1.5\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T1.5.1.3.1.6\"/>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.5.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.5.1.4.2.1\">share-encoder</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.5.1.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.1.4.2.2.1\">0.210</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.5.1.4.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.1.4.2.3.1\">0.225</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.5.1.4.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.1.4.2.4.1\">0.248</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.5.1.4.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.1.4.2.5.1\">0.211</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.5.1.4.2.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.5.1.4.2.6.1\">0.198</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [
            [
                "[3]",
                "\nMingbo Ma, Liang Huang, Hao Xiong, Renjie Zheng, Kaibo Liu, Baigong Zheng,\nChuanqiang Zhang, Zhongjun He, Hairong Liu, Xing Li, Hua Wu, and Haifeng\nWang,\n\n",
                "“STACL: Simultaneous Translation with Implicit\nAnticipation and Controllable Latency using Prefix-to-Prefix\nFramework,”\n\n",
                "in ",
                ", 2019.\n\n"
            ]
        ],
        "references": [
            "Then, we experimentally verify whether using a shared encoder as a branch predictor can achieve the same effect as using an independent language model with the same parameters.\nThe experimental results are shown in Table 1 and Table 2, which shows that compared with using an independent language model, using a shared encoder as a branch predictor can even achieve better results.\nOne possible reason why the branch prediction effect is better is that the addition of the LM loss is equivalent to fine-tuning the language model using the training data.\nThe subsequent fine-tuning analysis experiment results support this idea.\n"
        ]
    },
    "S4.T2.5.1": {
        "caption": null,
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.5.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.5.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T2.5.1.1.1.1\">Model</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.5.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.5.1.1.1.2.1\">L=0.5</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.5.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.5.1.1.1.3.1\">L=0.2</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.5.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.5.1.1.1.4.1\">L=0.1</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.5.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.5.1.1.1.5.1\">L=0.05</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.5.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.5.1.1.1.6.1\">L=0.02</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.5.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T2.5.1.2.2.1\">GPT2-small</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.5.1.2.2.2\">0.131</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.5.1.2.2.3\">0.135</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.5.1.2.2.4\">0.131</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.5.1.2.2.5\">0.135</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.5.1.2.2.6\">0.132</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.5.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.5.1.3.1.1\">GPT2-small-</th>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.5.1.3.1.2\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.5.1.3.1.3\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.5.1.3.1.4\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.5.1.3.1.5\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T2.5.1.3.1.6\"/>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.5.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.5.1.4.2.1\">share-encoder</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.5.1.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.5.1.4.2.2.1\">0.248</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.5.1.4.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.5.1.4.2.3.1\">0.265</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.5.1.4.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.5.1.4.2.4.1\">0.264</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.5.1.4.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.5.1.4.2.5.1\">0.255</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.5.1.4.2.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.5.1.4.2.6.1\">0.251</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [
            [
                "[5]",
                "\nXutai Ma, Juan Miguel Pino, James Cross, Liezl Puzon, and Jiatao Gu,\n\n",
                "“Monotonic multihead attention,”\n\n",
                "in ",
                ", 2020.\n\n"
            ]
        ],
        "references": [
            "Then, we experimentally verify whether using a shared encoder as a branch predictor can achieve the same effect as using an independent language model with the same parameters.\nThe experimental results are shown in Table 1 and Table 2, which shows that compared with using an independent language model, using a shared encoder as a branch predictor can even achieve better results.\nOne possible reason why the branch prediction effect is better is that the addition of the LM loss is equivalent to fine-tuning the language model using the training data.\nThe subsequent fine-tuning analysis experiment results support this idea.\n"
        ]
    },
    "S4.T3.5.1": {
        "caption": null,
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.5.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.5.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T3.5.1.1.1.1\">Model</th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.5.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.1.1.2.1\">K=1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.5.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.1.1.3.1\">K=3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.5.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.1.1.4.1\">K=5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.5.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.1.1.5.1\">K=7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T3.5.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.1.1.6.1\">K=9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.5.1.2.2.1\">GPT2-small</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.2.2.2\">0.162</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.2.2.3\">0.171</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.2.2.4\">0.169</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.2.2.5\">0.162</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.2.2.6\">0.154</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.5.1.3.3.1\">GPT2-medium</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.3.3.2\">0.174</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.3.3.3\">0.184</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.3.3.4\">0.185</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.3.3.5\">0.175</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.3.3.6\">0.166</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.5.1.4.4.1\">GPT2-large</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.4.4.2\">0.174</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.4.4.3\">0.190</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.4.4.4\">0.187</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.4.4.5\">0.178</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.4.4.6\">0.168</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.5.1.5.5.1\">GPT2-xl</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.5.5.2\">0.184</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.5.5.3\">0.195</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.5.5.4\">0.192</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.5.5.5\">0.183</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.1.5.5.6\">0.179</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.5.1.6.6.1\">GPT2-small-</th>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T3.5.1.6.6.2\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T3.5.1.6.6.3\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T3.5.1.6.6.4\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T3.5.1.6.6.5\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T3.5.1.6.6.6\"/>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T3.5.1.7.7.1\">fine-tuning</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.1.7.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.7.7.2.1\">0.212</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.1.7.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.7.7.3.1\">0.224</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.1.7.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.7.7.4.1\">0.227</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.1.7.7.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.7.7.5.1\">0.223</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.1.7.7.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.7.7.6.1\">0.218</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Language Models of Different Sizes\nWe also investigated the performance of the model using pre-trained GPTs of different sizes as branch predictors, and the results are shown in Table 3. It can be seen that using a larger pre-trained GPT can bring improvements, but the cost performance is not as good as fine-tuning a small GPT model.\n"
        ]
    },
    "S4.T4.2": {
        "caption": "Ablation experiments on the model with a delay loss weight of 0.1 for the MMA method.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.2\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T4.2.2.3\"><span class=\"ltx_text\" id=\"S4.T4.2.2.3.1\" style=\"font-size:90%;\">Model</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.1.1.1\">\n<span class=\"ltx_text\" id=\"S4.T4.1.1.1.1\" style=\"font-size:90%;\">BLEU</span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.1.1.1.m1.1\"><semantics id=\"S4.T4.1.1.1.m1.1a\"><mo id=\"S4.T4.1.1.1.m1.1.1\" mathsize=\"90%\" stretchy=\"false\" xref=\"S4.T4.1.1.1.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.1.1.1.m1.1b\"><ci id=\"S4.T4.1.1.1.m1.1.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.1.1.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T4.1.1.1.m1.1d\">&#8593;</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T4.2.2.2\">\n<span class=\"ltx_text\" id=\"S4.T4.2.2.2.1\" style=\"font-size:90%;\">AL</span><math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.2.2.2.m1.1\"><semantics id=\"S4.T4.2.2.2.m1.1a\"><mo id=\"S4.T4.2.2.2.m1.1.1\" mathsize=\"90%\" stretchy=\"false\" xref=\"S4.T4.2.2.2.m1.1.1.cmml\">&#8595;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.2.2.2.m1.1b\"><ci id=\"S4.T4.2.2.2.m1.1.1.cmml\" xref=\"S4.T4.2.2.2.m1.1.1\">&#8595;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.2.2.2.m1.1c\">\\downarrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T4.2.2.2.m1.1d\">&#8595;</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.2.3.1.1\"><span class=\"ltx_text\" id=\"S4.T4.2.3.1.1.1\" style=\"font-size:90%;\">MMA</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.3.1.2\"><span class=\"ltx_text\" id=\"S4.T4.2.3.1.2.1\" style=\"font-size:90%;\">26.97</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.3.1.3\"><span class=\"ltx_text\" id=\"S4.T4.2.3.1.3.1\" style=\"font-size:90%;\">4.55</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.2.4.2.1\"><span class=\"ltx_text\" id=\"S4.T4.2.4.2.1.1\" style=\"font-size:90%;\">+Pre-trained LM</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.4.2.2\"><span class=\"ltx_text\" id=\"S4.T4.2.4.2.2.1\" style=\"font-size:90%;\">29.36</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.4.2.3\"><span class=\"ltx_text\" id=\"S4.T4.2.4.2.3.1\" style=\"font-size:90%;\">4.19</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.2.5.3.1\"><span class=\"ltx_text\" id=\"S4.T4.2.5.3.1.1\" style=\"font-size:90%;\">+LM loss</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.5.3.2\"><span class=\"ltx_text\" id=\"S4.T4.2.5.3.2.1\" style=\"font-size:90%;\">27.07</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.2.5.3.3\"><span class=\"ltx_text\" id=\"S4.T4.2.5.3.3.1\" style=\"font-size:90%;\">4.86</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.2.6.4.1\"><span class=\"ltx_text\" id=\"S4.T4.2.6.4.1.1\" style=\"font-size:90%;\">+Pre-trained LM</span></th>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T4.2.6.4.2\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"S4.T4.2.6.4.3\"/>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.2.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T4.2.7.5.1\"><span class=\"ltx_text\" id=\"S4.T4.2.7.5.1.1\" style=\"font-size:90%;\">+LM loss</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.2.7.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.2.7.5.2.1\" style=\"font-size:90%;\">29.44</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T4.2.7.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.2.7.5.3.1\" style=\"font-size:90%;\">3.76</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Pre-trained Language Model and LM Loss\nWe conducted a ablation study on the proposed pre-trained language model and LM loss in Section 3.2.\nThe experimental results are shown in Table 4, which shows that the pre-trained language model and LM loss can both improve the translation quality and delay of the model, and the combination of the two achieves the best results.\n"
        ]
    }
}