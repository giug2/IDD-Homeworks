{
    "S4.T1": {
        "caption": "Table 1: Comparing MuRel to Attention. Comparison of the MuRel strategy against a strong Attention-based model on the VQA 2.0 val, VQA-CP v2 and TDIUC datasets. Both models have an equivalent number of parameters (∼similar-to\\sim60 million) and are trained on the same features following the same experimental setup.",
        "table": "<table id=\"S4.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Model</th>\n<th id=\"S4.T1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VQA 2.0</th>\n<th id=\"S4.T1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VQA CP v2</th>\n<th id=\"S4.T1.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">TDIUC</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.3.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Attention baseline</td>\n<td id=\"S4.T1.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">63.44</td>\n<td id=\"S4.T1.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">38.04</td>\n<td id=\"S4.T1.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">86.96</td>\n</tr>\n<tr id=\"S4.T1.3.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">MuRel</td>\n<td id=\"S4.T1.3.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.3.3.2.2.1\" class=\"ltx_text ltx_font_bold\">65.14</span></td>\n<td id=\"S4.T1.3.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.3.3.2.3.1\" class=\"ltx_text ltx_font_bold\">39.54</span></td>\n<td id=\"S4.T1.3.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.3.3.2.4.1\" class=\"ltx_text ltx_font_bold\">88.20</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In Table 1, we compare MuRel against a strong attentional model based on bilinear fusions [8], which encompasses a multi-glimpses attentional process [11]. The goal of this experiments is to compare our approach with strong baselines for real VQA in controlled conditions. In addition to using the same bottom-up features, which are crucial for fair comparisons, we also dimension the attention-based baseline to have an equivalent amount of learned parameters than MuRel (∼similar-to\\sim60 millions including those from the GRU encoder). Also, we train it following the same experimental setup to insure competitiveness.\nMuRel reaches a higher accuracy on the three datasets. We report a significant gain of +1.70 on VQA 2.0 and +1.50 on VQA CP v2.\nNot only these results validate the ability of MuRel to better model interactions between the question and the image, but also to generalize when the distribution of the answers per question are completely different between the training and validation set as in VQA CP v2.\nA gain of +1.24 on TDIUC demonstrates the richer modeling capacity of MuRel in a fine-grained context of 12 well delimited question types."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Ablation study of MuRel. Experimental validation of the pairwise module and the iterative processing on the VQA 2.0 val, VQA-CP v2 and TDIUC datasets.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Pairwise</th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Iter.</th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VQA 2.0</th>\n<th id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VQA CP v2</th>\n<th id=\"S4.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">TDIUC</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">✗</th>\n<th id=\"S4.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">✗</th>\n<td id=\"S4.T2.1.2.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\">64.13</td>\n<td id=\"S4.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">38.88</td>\n<td id=\"S4.T2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">87.50</td>\n</tr>\n<tr id=\"S4.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">✓</th>\n<th id=\"S4.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">✗</th>\n<td id=\"S4.T2.1.3.2.3\" class=\"ltx_td ltx_nopad_l ltx_align_center\">64.57</td>\n<td id=\"S4.T2.1.3.2.4\" class=\"ltx_td ltx_align_center\">39.12</td>\n<td id=\"S4.T2.1.3.2.5\" class=\"ltx_td ltx_align_center\">87.86</td>\n</tr>\n<tr id=\"S4.T2.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">✗</th>\n<th id=\"S4.T2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">✓</th>\n<td id=\"S4.T2.1.4.3.3\" class=\"ltx_td ltx_nopad_l ltx_align_center\">64.72</td>\n<td id=\"S4.T2.1.4.3.4\" class=\"ltx_td ltx_align_center\">39.37</td>\n<td id=\"S4.T2.1.4.3.5\" class=\"ltx_td ltx_align_center\">87.92</td>\n</tr>\n<tr id=\"S4.T2.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">✓</th>\n<th id=\"S4.T2.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\">✓</th>\n<td id=\"S4.T2.1.5.4.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.5.4.3.1\" class=\"ltx_text ltx_font_bold\">65.14</span></td>\n<td id=\"S4.T2.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.5.4.4.1\" class=\"ltx_text ltx_font_bold\">39.54</span></td>\n<td id=\"S4.T2.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\">88.20</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In Table 2, we compare three ablated instances of MuRel to its complete form.\nFirst, we validate the benefits of the pairwise module. Adding it to a vanilla MuRel without iterative process leads to higher accuracy on every datasets. In fact, between line 1 and 2, we report a gain of +0.44 on VQA 2.0, +0.24 on VQA CP v2 and +0.36 on TDIUC.\nSecondly, we validate the interest of the iterative process. Between line 1 et 3, we report a gain of +0.59 on VQA 2.0, +0.49 on VQA CP v2 and +0.42 on TDIUC.\nNotably, this modification does not add any parameters, because we iterate over a single MuRel cell.\nUnsharing the weights by using a different MuRel cell for each step gives similar results.\nFinally, the pairwise module and the iterative process are added to create the complete MuRel network. This instance (in line 4) reaches the highest accuracy on the three datasets. Interestingly, the gains provided by the combination of the two methods are sometimes larger than those of each one separately. For instance, we report a gain of +1.01 on VQA 2.0 between line 1 and 4. This attests to the complementary of the two modules."
        ]
    },
    "S4.T3": {
        "caption": "Table 3:  State-of-the-art comparison on the VQA 2.0 dataset. Results on test-dev and test-std splits. All these models were trained on the same training set (VQA 2.0 train+val), using the Bottom-up features provided by [3]. No ensembling methods have been used. ††\\dagger have been trained by [6].",
        "table": "<table id=\"S4.T3.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.2.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.3.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<th id=\"S4.T3.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\"><span id=\"S4.T3.2.3.1.2.1\" class=\"ltx_text ltx_font_italic\">test-dev</span></th>\n<th id=\"S4.T3.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.2.3.1.3.1\" class=\"ltx_text ltx_font_italic\">test-std</span></th>\n</tr>\n<tr id=\"S4.T3.2.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row\">Model</th>\n<th id=\"S4.T3.2.4.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Yes/No</th>\n<th id=\"S4.T3.2.4.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Num.</th>\n<th id=\"S4.T3.2.4.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Other</th>\n<th id=\"S4.T3.2.4.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">All</th>\n<th id=\"S4.T3.2.4.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">All</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.2.5.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">Bottom-up</th>\n<td id=\"S4.T3.2.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T3.2.5.1.2.1\" class=\"ltx_text\">81.82</span></td>\n<td id=\"S4.T3.2.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T3.2.5.1.3.1\" class=\"ltx_text\">44.21</span></td>\n<td id=\"S4.T3.2.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T3.2.5.1.4.1\" class=\"ltx_text\">56.05</span></td>\n<td id=\"S4.T3.2.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T3.2.5.1.5.1\" class=\"ltx_text\">65.32</span></td>\n<td id=\"S4.T3.2.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T3.2.5.1.6.1\" class=\"ltx_text\">65.67</span></td>\n</tr>\n<tr id=\"S4.T3.2.6.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.6.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib3\" title=\"\" class=\"ltx_ref\">3</a>]</cite></th>\n</tr>\n<tr id=\"S4.T3.2.7.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.7.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">Graph Att.</th>\n<td id=\"S4.T3.2.7.3.2\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.7.3.2.1\" class=\"ltx_text\">-</span></td>\n<td id=\"S4.T3.2.7.3.3\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.7.3.3.1\" class=\"ltx_text\">-</span></td>\n<td id=\"S4.T3.2.7.3.4\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.7.3.4.1\" class=\"ltx_text\">-</span></td>\n<td id=\"S4.T3.2.7.3.5\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.7.3.5.1\" class=\"ltx_text\">-</span></td>\n<td id=\"S4.T3.2.7.3.6\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.7.3.6.1\" class=\"ltx_text\">66.18</span></td>\n</tr>\n<tr id=\"S4.T3.2.8.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.8.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib31\" title=\"\" class=\"ltx_ref\">31</a>]</cite></th>\n</tr>\n<tr id=\"S4.T3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">MUTAN<math id=\"S4.T3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\dagger\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.m1.1a\"><mo id=\"S4.T3.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.m1.1.1.cmml\">†</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.m1.1b\"><ci id=\"S4.T3.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.m1.1.1\">†</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.m1.1c\">\\dagger</annotation></semantics></math>\n</th>\n<td id=\"S4.T3.1.1.2\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.1.1.2.1\" class=\"ltx_text\">82.88</span></td>\n<td id=\"S4.T3.1.1.3\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.1.1.3.1\" class=\"ltx_text\">44.54</span></td>\n<td id=\"S4.T3.1.1.4\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.1.1.4.1\" class=\"ltx_text\">56.50</span></td>\n<td id=\"S4.T3.1.1.5\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.1.1.5.1\" class=\"ltx_text\">66.01</span></td>\n<td id=\"S4.T3.1.1.6\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.1.1.6.1\" class=\"ltx_text\">66.38</span></td>\n</tr>\n<tr id=\"S4.T3.2.9.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.9.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib8\" title=\"\" class=\"ltx_ref\">8</a>]</cite></th>\n</tr>\n<tr id=\"S4.T3.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">MLB<math id=\"S4.T3.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\dagger\" display=\"inline\"><semantics id=\"S4.T3.2.2.1.m1.1a\"><mo id=\"S4.T3.2.2.1.m1.1.1\" xref=\"S4.T3.2.2.1.m1.1.1.cmml\">†</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.1.m1.1b\"><ci id=\"S4.T3.2.2.1.m1.1.1.cmml\" xref=\"S4.T3.2.2.1.m1.1.1\">†</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.1.m1.1c\">\\dagger</annotation></semantics></math>\n</th>\n<td id=\"S4.T3.2.2.2\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.2.2.1\" class=\"ltx_text\">83.58</span></td>\n<td id=\"S4.T3.2.2.3\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.2.3.1\" class=\"ltx_text\">44.92</span></td>\n<td id=\"S4.T3.2.2.4\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.2.4.1\" class=\"ltx_text\">56.34</span></td>\n<td id=\"S4.T3.2.2.5\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.2.5.1\" class=\"ltx_text\">66.27</span></td>\n<td id=\"S4.T3.2.2.6\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.2.6.1\" class=\"ltx_text\">66.62</span></td>\n</tr>\n<tr id=\"S4.T3.2.10.6\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.10.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib20\" title=\"\" class=\"ltx_ref\">20</a>]</cite></th>\n</tr>\n<tr id=\"S4.T3.2.11.7\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.11.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">DA-NTN</th>\n<td id=\"S4.T3.2.11.7.2\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.11.7.2.1\" class=\"ltx_text\">84.29</span></td>\n<td id=\"S4.T3.2.11.7.3\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.11.7.3.1\" class=\"ltx_text\">47.14</span></td>\n<td id=\"S4.T3.2.11.7.4\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.11.7.4.1\" class=\"ltx_text\">57.92</span></td>\n<td id=\"S4.T3.2.11.7.5\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.11.7.5.1\" class=\"ltx_text\">67.56</span></td>\n<td id=\"S4.T3.2.11.7.6\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.11.7.6.1\" class=\"ltx_text\">67.94</span></td>\n</tr>\n<tr id=\"S4.T3.2.12.8\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.12.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">6</a>]</cite></th>\n</tr>\n<tr id=\"S4.T3.2.13.9\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.13.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">Pythia</th>\n<td id=\"S4.T3.2.13.9.2\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.13.9.2.1\" class=\"ltx_text\">-</span></td>\n<td id=\"S4.T3.2.13.9.3\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.13.9.3.1\" class=\"ltx_text\">-</span></td>\n<td id=\"S4.T3.2.13.9.4\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.13.9.4.1\" class=\"ltx_text\">-</span></td>\n<td id=\"S4.T3.2.13.9.5\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.13.9.5.1\" class=\"ltx_text\">68.05</span></td>\n<td id=\"S4.T3.2.13.9.6\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.13.9.6.1\" class=\"ltx_text\">-</span></td>\n</tr>\n<tr id=\"S4.T3.2.14.10\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.14.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib40\" title=\"\" class=\"ltx_ref\">40</a>]</cite></th>\n</tr>\n<tr id=\"S4.T3.2.15.11\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.15.11.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">Counter</th>\n<td id=\"S4.T3.2.15.11.2\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.15.11.2.1\" class=\"ltx_text\">83.14</span></td>\n<td id=\"S4.T3.2.15.11.3\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.15.11.3.1\" class=\"ltx_text ltx_font_bold\">51.62</span></td>\n<td id=\"S4.T3.2.15.11.4\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.15.11.4.1\" class=\"ltx_text ltx_font_bold\">58.97</span></td>\n<td id=\"S4.T3.2.15.11.5\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.15.11.5.1\" class=\"ltx_text ltx_font_bold\">68.09</span></td>\n<td id=\"S4.T3.2.15.11.6\" class=\"ltx_td ltx_align_center\" rowspan=\"2\"><span id=\"S4.T3.2.15.11.6.1\" class=\"ltx_text ltx_font_bold\">68.41</span></td>\n</tr>\n<tr id=\"S4.T3.2.16.12\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.16.12.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib41\" title=\"\" class=\"ltx_ref\">41</a>]</cite></th>\n</tr>\n<tr id=\"S4.T3.2.17.13\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.17.13.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\">MuRel</th>\n<td id=\"S4.T3.2.17.13.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.2.17.13.2.1\" class=\"ltx_text ltx_font_bold\">84.77</span></td>\n<td id=\"S4.T3.2.17.13.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">49.84</td>\n<td id=\"S4.T3.2.17.13.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">57.85</td>\n<td id=\"S4.T3.2.17.13.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">68.03</td>\n<td id=\"S4.T3.2.17.13.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.2.17.13.6.1\" class=\"ltx_text ltx_font_bold\">68.41</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In Table 3, we compare MuRel to the most recent contributions on the VQA 2.0 dataset. For fairness considerations, all the scores correspond to models trained on the VQA 2.0 train+val split, using the Bottom-up visual features [3].\nInterestingly, our model surpasses both MUTAN [8] and MLB [20], which correspond to some of the latest development in visual attention and bilinear models. This tends to indicate that VQA models can benefit from retaining local information in mulitmodal vectors instead of scalar coefficients.\nMoreover, our model greatly improves over the recent method proposed in [31] where the regions are structured using pairwise attention scores, which are leveraged through spatial graph convolutions. This shows the interest of our spatial-semantic pairwise modeling between all possible pairs of regions.\nFinally, even though we did not extensively tune the hyperparameters of our model, our overall score on the test-dev split is highly competitive with state-of-the-art methods. In particular, we are comparable to Pythia [40] who won the VQA Challenge 2018. Please note that they improve their overall scores up to 70.01% when they include multiple types of visual features and more training data. Also, we did not report the score of 69.52% obtained by BAN [19] as they train their model on extra data from the Visual Genome dataset [23]."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: State-of-the-art comparison on the TDIUC dataset. * trained by [18].",
        "table": "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S4.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">RAU*</td>\n<td id=\"S4.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">MCB*</td>\n<td id=\"S4.T4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">QTA</td>\n<td id=\"S4.T4.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T4.1.1.1.5.1\" class=\"ltx_text\">MuRel</span></td>\n</tr>\n<tr id=\"S4.T4.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.2.2.1\" class=\"ltx_td\"></td>\n<td id=\"S4.T4.1.2.2.2\" class=\"ltx_td ltx_align_center\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib30\" title=\"\" class=\"ltx_ref\">30</a>]</cite></td>\n<td id=\"S4.T4.1.2.2.3\" class=\"ltx_td ltx_align_center\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">11</a>]</cite></td>\n<td id=\"S4.T4.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib35\" title=\"\" class=\"ltx_ref\">35</a>]</cite></td>\n</tr>\n<tr id=\"S4.T4.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Bottom-up</td>\n<td id=\"S4.T4.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">✗</td>\n<td id=\"S4.T4.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">✗</td>\n<td id=\"S4.T4.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S4.T4.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">✓</td>\n</tr>\n<tr id=\"S4.T4.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Scene Reco.</td>\n<td id=\"S4.T4.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">93.96</td>\n<td id=\"S4.T4.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">93.06</td>\n<td id=\"S4.T4.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.80</td>\n<td id=\"S4.T4.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.4.4.5.1\" class=\"ltx_text ltx_font_bold\">96.11</span></td>\n</tr>\n<tr id=\"S4.T4.1.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.5.5.1\" class=\"ltx_td ltx_align_center\">Sport Reco.</td>\n<td id=\"S4.T4.1.5.5.2\" class=\"ltx_td ltx_align_center\">93.47</td>\n<td id=\"S4.T4.1.5.5.3\" class=\"ltx_td ltx_align_center\">92.77</td>\n<td id=\"S4.T4.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">95.55</td>\n<td id=\"S4.T4.1.5.5.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.5.5.5.1\" class=\"ltx_text ltx_font_bold\">96.20</span></td>\n</tr>\n<tr id=\"S4.T4.1.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.6.6.1\" class=\"ltx_td ltx_align_center\">Color Attr.</td>\n<td id=\"S4.T4.1.6.6.2\" class=\"ltx_td ltx_align_center\">66.86</td>\n<td id=\"S4.T4.1.6.6.3\" class=\"ltx_td ltx_align_center\">68.54</td>\n<td id=\"S4.T4.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">60.16</td>\n<td id=\"S4.T4.1.6.6.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.6.6.5.1\" class=\"ltx_text ltx_font_bold\">74.43</span></td>\n</tr>\n<tr id=\"S4.T4.1.7.7\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.7.7.1\" class=\"ltx_td ltx_align_center\">Other Attr.</td>\n<td id=\"S4.T4.1.7.7.2\" class=\"ltx_td ltx_align_center\">56.49</td>\n<td id=\"S4.T4.1.7.7.3\" class=\"ltx_td ltx_align_center\">56.72</td>\n<td id=\"S4.T4.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r\">54.36</td>\n<td id=\"S4.T4.1.7.7.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.7.7.5.1\" class=\"ltx_text ltx_font_bold\">58.19</span></td>\n</tr>\n<tr id=\"S4.T4.1.8.8\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.8.8.1\" class=\"ltx_td ltx_align_center\">Activity Reco.</td>\n<td id=\"S4.T4.1.8.8.2\" class=\"ltx_td ltx_align_center\">51.60</td>\n<td id=\"S4.T4.1.8.8.3\" class=\"ltx_td ltx_align_center\">52.35</td>\n<td id=\"S4.T4.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_r\">60.10</td>\n<td id=\"S4.T4.1.8.8.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.8.8.5.1\" class=\"ltx_text ltx_font_bold\">63.83</span></td>\n</tr>\n<tr id=\"S4.T4.1.9.9\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.9.9.1\" class=\"ltx_td ltx_align_center\">Pos. Reasoning</td>\n<td id=\"S4.T4.1.9.9.2\" class=\"ltx_td ltx_align_center\">35.26</td>\n<td id=\"S4.T4.1.9.9.3\" class=\"ltx_td ltx_align_center\">35.40</td>\n<td id=\"S4.T4.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_r\">34.71</td>\n<td id=\"S4.T4.1.9.9.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.9.9.5.1\" class=\"ltx_text ltx_font_bold\">41.19</span></td>\n</tr>\n<tr id=\"S4.T4.1.10.10\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.10.10.1\" class=\"ltx_td ltx_align_center\">Object Reco.</td>\n<td id=\"S4.T4.1.10.10.2\" class=\"ltx_td ltx_align_center\">86.11</td>\n<td id=\"S4.T4.1.10.10.3\" class=\"ltx_td ltx_align_center\">85.54</td>\n<td id=\"S4.T4.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\">86.98</td>\n<td id=\"S4.T4.1.10.10.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.10.10.5.1\" class=\"ltx_text ltx_font_bold\">89.41</span></td>\n</tr>\n<tr id=\"S4.T4.1.11.11\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.11.11.1\" class=\"ltx_td ltx_align_center\">Absurd</td>\n<td id=\"S4.T4.1.11.11.2\" class=\"ltx_td ltx_align_center\">96.08</td>\n<td id=\"S4.T4.1.11.11.3\" class=\"ltx_td ltx_align_center\">84.82</td>\n<td id=\"S4.T4.1.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T4.1.11.11.4.1\" class=\"ltx_text ltx_font_bold\">100.00</span></td>\n<td id=\"S4.T4.1.11.11.5\" class=\"ltx_td ltx_align_center\">99.8</td>\n</tr>\n<tr id=\"S4.T4.1.12.12\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.12.12.1\" class=\"ltx_td ltx_align_center\">Util. and Afford.</td>\n<td id=\"S4.T4.1.12.12.2\" class=\"ltx_td ltx_align_center\">31.58</td>\n<td id=\"S4.T4.1.12.12.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.12.12.3.1\" class=\"ltx_text ltx_font_bold\">35.09</span></td>\n<td id=\"S4.T4.1.12.12.4\" class=\"ltx_td ltx_align_center ltx_border_r\">31.48</td>\n<td id=\"S4.T4.1.12.12.5\" class=\"ltx_td ltx_align_center\">21.43</td>\n</tr>\n<tr id=\"S4.T4.1.13.13\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.13.13.1\" class=\"ltx_td ltx_align_center\">Object Presence</td>\n<td id=\"S4.T4.1.13.13.2\" class=\"ltx_td ltx_align_center\">94.38</td>\n<td id=\"S4.T4.1.13.13.3\" class=\"ltx_td ltx_align_center\">93.64</td>\n<td id=\"S4.T4.1.13.13.4\" class=\"ltx_td ltx_align_center ltx_border_r\">94.55</td>\n<td id=\"S4.T4.1.13.13.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.13.13.5.1\" class=\"ltx_text ltx_font_bold\">95.75</span></td>\n</tr>\n<tr id=\"S4.T4.1.14.14\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.14.14.1\" class=\"ltx_td ltx_align_center\">Counting</td>\n<td id=\"S4.T4.1.14.14.2\" class=\"ltx_td ltx_align_center\">48.43</td>\n<td id=\"S4.T4.1.14.14.3\" class=\"ltx_td ltx_align_center\">51.01</td>\n<td id=\"S4.T4.1.14.14.4\" class=\"ltx_td ltx_align_center ltx_border_r\">53.25</td>\n<td id=\"S4.T4.1.14.14.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.14.14.5.1\" class=\"ltx_text ltx_font_bold\">61.78</span></td>\n</tr>\n<tr id=\"S4.T4.1.15.15\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.15.15.1\" class=\"ltx_td ltx_align_center\">Sentiment</td>\n<td id=\"S4.T4.1.15.15.2\" class=\"ltx_td ltx_align_center\">60.09</td>\n<td id=\"S4.T4.1.15.15.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.15.15.3.1\" class=\"ltx_text ltx_font_bold\">66.25</span></td>\n<td id=\"S4.T4.1.15.15.4\" class=\"ltx_td ltx_align_center ltx_border_r\">64.38</td>\n<td id=\"S4.T4.1.15.15.5\" class=\"ltx_td ltx_align_center\">60.65</td>\n</tr>\n<tr id=\"S4.T4.1.16.16\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.16.16.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Overall (A-MPT)</td>\n<td id=\"S4.T4.1.16.16.2\" class=\"ltx_td ltx_align_center ltx_border_t\">67.81</td>\n<td id=\"S4.T4.1.16.16.3\" class=\"ltx_td ltx_align_center ltx_border_t\">67.90</td>\n<td id=\"S4.T4.1.16.16.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">69.11</td>\n<td id=\"S4.T4.1.16.16.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.16.16.5.1\" class=\"ltx_text ltx_font_bold\">71.56</span></td>\n</tr>\n<tr id=\"S4.T4.1.17.17\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.17.17.1\" class=\"ltx_td ltx_align_center\">Overall (H-MPT)</td>\n<td id=\"S4.T4.1.17.17.2\" class=\"ltx_td ltx_align_center\">59.00</td>\n<td id=\"S4.T4.1.17.17.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.17.17.3.1\" class=\"ltx_text ltx_font_bold\">60.47</span></td>\n<td id=\"S4.T4.1.17.17.4\" class=\"ltx_td ltx_align_center ltx_border_r\">60.08</td>\n<td id=\"S4.T4.1.17.17.5\" class=\"ltx_td ltx_align_center\">59.30</td>\n</tr>\n<tr id=\"S4.T4.1.18.18\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.18.18.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">Overall Accuracy</td>\n<td id=\"S4.T4.1.18.18.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">84.26</td>\n<td id=\"S4.T4.1.18.18.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">81.86</td>\n<td id=\"S4.T4.1.18.18.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">85.03</td>\n<td id=\"S4.T4.1.18.18.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T4.1.18.18.5.1\" class=\"ltx_text ltx_font_bold\">88.20</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "One of the core aspect of VQA models lies in their ability to address different tasks. The TDIUC dataset enables a detailed analysis of the strengths and limitations of a model by evaluating its performance on different types of question. We show in Table 4 a detailed comparison of recent models to our MuRel. We obtain state-of-the-art results on the Overall Accuracy and the arithmetic mean of per-type accuracies (A-MPT), and surpass by a significant margin the second best model proposed by [35]. Interestingly, we improve over this model even though it uses a combination of Bottom-up and fixed-grid features, as well as a supervision on the question types (hence its 100% result on the Absurd task).\nMuRel notably surpasses all previous methods on the Positional reasoning (+5.9 over MCB), Counting (+8.53 over QTA) questions. These improvements are likely due to the pairwise structure induced within the MuRel cell, which makes the answer prediction depend on the spatial and semantic relations between regions. The effectiveness of our per-region context modelling is also demonstrated by our the improvement on Scene recognition questions. For these questions, representing the image as a collection of independent objects shows lower performance than replacing each of them in its spatial and semantic context.\nInterestingly, our results on the harmonic mean of per-type accuracies (H-MPT) are lower than state-of-the-art. For MuRel, this harmonic metric is significantly harmed by our low score of 21.43% on the Utility and Affordances task. As these questions concern the possible usages of objects present in the scene (such as Can you eat the yellow object?), and are not directly related to the visual understanding of the scene."
        ]
    },
    "S4.T5": {
        "caption": "Table 5: State-of-the-art comparison on the VQA-CP v2 dataset. The Attention model was trained by us using the Bottom-up features.",
        "table": "<table id=\"S4.T5.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T5.1.1.1.1.1\" class=\"ltx_text\">Model</span></th>\n<th id=\"S4.T5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Bottom</th>\n<th id=\"S4.T5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T5.1.1.1.3.1\" class=\"ltx_text\">Yes/No</span></th>\n<th id=\"S4.T5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T5.1.1.1.4.1\" class=\"ltx_text\">Num.</span></th>\n<th id=\"S4.T5.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T5.1.1.1.5.1\" class=\"ltx_text\">Other</span></th>\n<th id=\"S4.T5.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T5.1.1.1.6.1\" class=\"ltx_text\">All</span></th>\n</tr>\n<tr id=\"S4.T5.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">up</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.1.3.1\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">HAN <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a>]</cite>\n</td>\n<td id=\"S4.T5.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">✗</td>\n<td id=\"S4.T5.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">52.25</td>\n<td id=\"S4.T5.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T5.1.3.1.4.1\" class=\"ltx_text ltx_font_bold\">13.79</span></td>\n<td id=\"S4.T5.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">20.33</td>\n<td id=\"S4.T5.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">28.65</td>\n</tr>\n<tr id=\"S4.T5.1.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.4.2.1\" class=\"ltx_td ltx_align_center\">GVQA <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib1\" title=\"\" class=\"ltx_ref\">1</a>]</cite>\n</td>\n<td id=\"S4.T5.1.4.2.2\" class=\"ltx_td ltx_align_center\">✗</td>\n<td id=\"S4.T5.1.4.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.1.4.2.3.1\" class=\"ltx_text ltx_font_bold\">57.99</span></td>\n<td id=\"S4.T5.1.4.2.4\" class=\"ltx_td ltx_align_center\">13.68</td>\n<td id=\"S4.T5.1.4.2.5\" class=\"ltx_td ltx_align_center\">22.14</td>\n<td id=\"S4.T5.1.4.2.6\" class=\"ltx_td ltx_align_center\">31.30</td>\n</tr>\n<tr id=\"S4.T5.1.5.3\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.5.3.1\" class=\"ltx_td ltx_align_center\">Attention</td>\n<td id=\"S4.T5.1.5.3.2\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S4.T5.1.5.3.3\" class=\"ltx_td ltx_align_center\">41.56</td>\n<td id=\"S4.T5.1.5.3.4\" class=\"ltx_td ltx_align_center\">12.19</td>\n<td id=\"S4.T5.1.5.3.5\" class=\"ltx_td ltx_align_center\">43.29</td>\n<td id=\"S4.T5.1.5.3.6\" class=\"ltx_td ltx_align_center\">38.04</td>\n</tr>\n<tr id=\"S4.T5.1.6.4\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">MuRel</td>\n<td id=\"S4.T5.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">✓</td>\n<td id=\"S4.T5.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">42.85</td>\n<td id=\"S4.T5.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">13.17</td>\n<td id=\"S4.T5.1.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T5.1.6.4.5.1\" class=\"ltx_text ltx_font_bold\">45.04</span></td>\n<td id=\"S4.T5.1.6.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T5.1.6.4.6.1\" class=\"ltx_text ltx_font_bold\">39.54</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "This dataset has been proposed to evaluate and reduce the question-oriented bias in VQA models. In particular, the distributions of answers with respect to question types differ from train to val splits.\nIn Table 5, we report the scores of two recent baselines [1, 27], on which we improve significantly. In particular, we demonstrate an important gain over GVQA [1], whose architecture is designed to focus on Yes/No questions. However, since both methods do not use the Bottom-up features, the fairness of the comparison can be questioned. So we also train an attention model similar to [8] using these Bottom-up region representation.\nWe observe that MuRel provides a substantial gain over this strong attention baseline. Given the distribution mismatch between train and val splits, models that only focus on linguistic biases to answer the question are systematically penalized on their val scores. This property of VQA-CP v2 implies that the pairwise iterative structure of MuRel is less prone to question-based overfitting than classical attention architectures."
        ]
    }
}