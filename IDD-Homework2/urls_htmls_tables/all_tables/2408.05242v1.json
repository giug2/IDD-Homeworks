{
    "S3.T1": {
        "caption": "Table 1: The comprehensive statistics, which encompass various clients within the LoRA system implementation, are validated using a range of metrics such as rouge1, rouge2, rouge3, and BLEU. Furthermore, these statistics illustrate the accuracies of the global federated server.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S3.T1.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.1.1\">Metrics</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.2.1\">LoRA Federated</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.3.1\">LoRA Client 1</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.4.1\">LoRA Client 2</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.5.1\">LoRA Client 3</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.6.1\">LoRA Client 4</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.1.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T1.1.1.2.1.1.1\">Rouge - 1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.1.2\">32.383</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.1.3\">33.124</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.1.4\">31.824</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.1.5\">32.864</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.2.1.6\">32.372</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.3.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.2.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T1.1.1.3.2.1.1\">Rouge - 2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.2.2\">8.245</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.2.3\">8.653</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.2.4\">8.119</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.2.5\">7.969</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.3.2.6\">7.932</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.3.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T1.1.1.4.3.1.1\">Rouge - l</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.3.2\">26.804</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.3.3\">25.939</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.3.4\">25.408</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.3.5\">25.404</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.4.3.6\">26.819</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.4.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T1.1.1.5.4.1.1\">BLEU - 4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.4.2\">8.334</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.4.3\">8.932</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.4.4\">8.335</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.4.5\">8.467</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.5.4.6\">8.352</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Context GPT Evaluation: For the evaluation of the models generated by the client machines, we employed metric scales such as Rouge-1, Rouge-2, Rouge-L, and BLEU-4. These metrics assess the quality of the generated output by evaluating the uni-grams, bi-grams, and N-grams of word sequences in comparison to the original sentences. Table\u00a01 provides a detailed breakdown of these evaluation metrics for both the global server and the four client machines, highlighting the overall performance across different measurement scales. Additionally, Table\u00a02 showcases the performance levels achieved by implementing the P-Tuning PEFT strategy, incorporating the latest version for enhanced accuracy. Furthermore, Table\u00a03 offers insights into the training parameters and sizes of the GPT-generated models across the client machines, illustrating the various trainable model sizes and parameters."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Extensive statistics covering various clients within the P-Tuning-v2 system implementation, validated using diverse metrics including Rouge-1, Rouge-2, Rouge-L, and BLEU. Additionally, the table depicts the accuracies of the global federated server.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T2.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.1.1\">Metrics</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.2.1\">P-Tuning-v2 Federated</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.3.1\">P-Tuning-v2 Client 1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.4.1\">P-Tuning-v2 Client 2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.5.1\">P-Tuning-v2 Client 3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.6.1\">P-Tuning-v2 Client 4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2.2.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T2.1.1.2.2.1.1\">Rouge - 1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2.2.2\">33.132</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2.2.3\">32.283</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2.2.4\">34.734</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2.2.5\">31.881</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.2.2.6\">32.674</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.3.3.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T2.1.1.3.3.1.1\">Rouge - 2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.3.3.2\">7.899</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.3.3.3\">8.879</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.3.3.4\">7.126</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.3.3.5\">7.268</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.3.3.6\">7.121</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.4.4.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T2.1.1.4.4.1.1\">Rouge - l</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.4.4.2\">25.532</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.4.4.3\">25.814</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.4.4.4\">25.153</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.4.4.5\">25.734</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.4.4.6\">25.237</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.5.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.5.5.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T2.1.1.5.5.1.1\">BLEU - 4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.5.5.2\">8.245</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.5.5.3\">8.392</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.5.5.4\">8.736</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.5.5.5\">8.829</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.5.5.6\">8.981</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Context GPT Evaluation: For the evaluation of the models generated by the client machines, we employed metric scales such as Rouge-1, Rouge-2, Rouge-L, and BLEU-4. These metrics assess the quality of the generated output by evaluating the uni-grams, bi-grams, and N-grams of word sequences in comparison to the original sentences. Table\u00a01 provides a detailed breakdown of these evaluation metrics for both the global server and the four client machines, highlighting the overall performance across different measurement scales. Additionally, Table\u00a02 showcases the performance levels achieved by implementing the P-Tuning PEFT strategy, incorporating the latest version for enhanced accuracy. Furthermore, Table\u00a03 offers insights into the training parameters and sizes of the GPT-generated models across the client machines, illustrating the various trainable model sizes and parameters."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: The detailed statistics encompassing various trainable model parameters and sizes are essential components of our federated learning implementation aimed at constructing a context-based GPT.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T3.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.1\">Methods</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.2.1\">Model Size (MB)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.3.1\">Param Percent (%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T3.1.2.2.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S4.T3.1.2.2.1.1\">Global Sever</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.2.2.2\">6173</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.2.2.3\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T3.1.3.3.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S4.T3.1.3.3.1.1\">LoRA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.3.3.2\">3.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.3.3.3\">0.058</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T3.1.4.4.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S4.T3.1.4.4.1.1\">P-Tuning-V2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.4.4.2\">29.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.4.4.3\">0.475</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.5.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T3.1.5.5.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S4.T3.1.5.5.1.1\">Checkpoint</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.5.5.2\">6.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T3.1.5.5.3\">0.116</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T3.1.6.6.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S4.T3.1.6.6.1.1\">Full Tuning</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T3.1.6.6.2\">6173</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T3.1.6.6.3\">100</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Context GPT Evaluation: For the evaluation of the models generated by the client machines, we employed metric scales such as Rouge-1, Rouge-2, Rouge-L, and BLEU-4. These metrics assess the quality of the generated output by evaluating the uni-grams, bi-grams, and N-grams of word sequences in comparison to the original sentences. Table\u00a01 provides a detailed breakdown of these evaluation metrics for both the global server and the four client machines, highlighting the overall performance across different measurement scales. Additionally, Table\u00a02 showcases the performance levels achieved by implementing the P-Tuning PEFT strategy, incorporating the latest version for enhanced accuracy. Furthermore, Table\u00a03 offers insights into the training parameters and sizes of the GPT-generated models across the client machines, illustrating the various trainable model sizes and parameters."
        ]
    }
}