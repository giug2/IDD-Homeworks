{
    "id_table_1": {
        "caption": "Table 1:  A description of all the real-world datasets used in the evaluation. All trial data was obtained from Project Data Sphere  (Green et al.,  2015 ) .  Num Rows  refers to the raw number of data points in the trial.  Num Subj  refers to the total number of patients.  Num Events  denotes the total number of  unique  events.  Events / Subj  denotes the average number of events that a patient experiences.  Positive Label Proportion  denotes the percentage of patients that did not experience the death event.",
        "table": "S3.T1.13.1",
        "footnotes": [
            ""
        ],
        "references": [
            "TrialSynth  is created to solve the highly specific task of synthetic sequential clinical trial patient generation. As shown in Fig.  1  and Fig.  3 , a patient contains many sequences of event types and their timestamps. This essentially creates a high-vocabulary, sequential token (event types) generation problem with a regression component (event times). First, we formulate the components that compose  TrialSynth . Then, we explain key details of  TrialSynth , including the ability to input type information in the form of known types to generate (which is common in the trial generation space when up-sampling patient data). Finally, we conclude with experiments on ML utility (usefulness of synthetic data) and inference privacy (important for patient privacy) and a discussion of the results.",
            "We evaluated our models on 7 real-world clinical trial outcome datasets obtained from Project Data Sphere 3 3 3 https://data.projectdatasphere.org/projectdatasphere/html/access   (Green et al.,  2015 ; Fu et al.,  2023 ; Chang et al.,  2019 ; Chen et al.,  2024b ,  c ) . Specifically, we chose the trials as outlined in Table  1 . These datasets have shown to be effective evaluation datasets for tabular prediction  (Wang & Sun,  2022b ; Wang et al.,  2023a )  and digital twin generation  (Das et al.,  2023 ; Wang et al.,  2024 ) . Specifically, we use LC1  (Niell et al.,  2005 ) , BC1  (Baldwin et al.,  2012 ) , CC  (Alberts et al.,  2012 ) , BC2  (Fernandez-Cuesta et al.,  2012 ) , BC3  (WU et al.,  2024 ) , VTE  (Agnelli et al.,  2012 ) , LC2  (Daniel et al.,  2021 ; Fu et al.,  2024 ; Zhang et al.,  2021 ) . A full description of the data is shown in Table  1 . Each dataset contains events and the times at which they occur, e.g., medications and procedures, as well as some adverse events like vomiting etc. We use these datasets to predict if the subject experiences the death event, which is an external label. Note that  TrialSynth  does not require a fixed patient event sequence length.",
            "Autoregressive Greedy Sampling vs Probabilistic Sampling  In this section, we compare the results of greedily choosing the best type as opposed to probabilistic sampling from the re-scaled logits  l  R N e  v  e  n  t  s l superscript R subscript N e v e n t s l\\in\\mathbb{R}^{N_{events}} italic_l  blackboard_R start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_e italic_v italic_e italic_n italic_t italic_s end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  when generating events from  TrialSynth  (Events Unknown). We re-scale the logits to be positive and sum to 1:  l = l  m  i  n  ( l )  l  m  i  n  ( l ) l l m i n l l m i n l l=\\frac{l-min(l)}{\\sum l-min(l)} italic_l = divide start_ARG italic_l - italic_m italic_i italic_n ( italic_l ) end_ARG start_ARG  italic_l - italic_m italic_i italic_n ( italic_l ) end_ARG , and sample from  k  M  u  l  t  i  n  o  m  i  a  l  ( l ) similar-to k M u l t i n o m i a l l k\\sim Multinomial(l) italic_k  italic_M italic_u italic_l italic_t italic_i italic_n italic_o italic_m italic_i italic_a italic_l ( italic_l )  (For the Greedy version, we take  arg  max k  ( l ) subscript arg max k l \\operatorname*{arg\\,max}_{k}(l) start_OPERATOR roman_arg roman_max end_OPERATOR start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_l ) ). Let  Probabilistic  represent the probabilistic sampling and  Greedy  represent greedy sampling. Table  10  shows the results, and we see that the Greedy version often fails to generate useful synthetic sequences."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Utility Evaluation: Binary Classification ROCAUCs (   \\uparrow   higher the better,   plus-or-minus \\pm   standard deviation) of a downstream LSTM trained on data generated from the  TrialSynth  models as well as the original data and baselines. Note that the LSTM and the  TrialSynth  models estimate their own sequence length.  TrialSynth  (Events Known) is put in a separate category due to its requirement of event type information, with results  underlined .  Bolded  indicates original data ROC is within 1 standard deviation of synthetic data ROC",
        "table": "S3.T1.13.1.1.1.7.1",
        "footnotes": [],
        "references": [
            "The rest of this paper is organized as follows: In Section  2 , we review the related work. In Section  3 , we dive into the proposed  TrialSynth  in detail. In section  4 , we compare datasets and baselines, demonstrating the superiority of  TrialSynth . Finally, in Section  5 , we provide a discussion and conclude our findings.",
            "To accommodate this framework, we train  n  u  m  _  e  v  e  n  t n u m _ e v e n t num\\_event italic_n italic_u italic_m _ italic_e italic_v italic_e italic_n italic_t  Transformer Hawkes Process expert encoders and decoders that only model a single event. Since the event type is known, we can index in the specific encoder/decoder pair as given by the event index (shown in Figure  2 ). Finally, all independent event time predictions over all known types are combined via their predicted event times to create a final multi-event sequence prediction. Since the VAE model requires a single embedding to sample a latent vector, we sum the patient embedding output of all expert event encoders and pass this joint embedding to the expert decoders. The decoder is trained to generate the predicted time and type sequence of its respective expert event.",
            "The standard deviation of each ROCAUC score is calculated via bootstrapping (100x bootstrapped test data points). Training is performed completely on synthetic data by matching each generated patient to its ground truth death event label. Testing is performed on the original held-out ground truth split. For the Original Data baseline, we performed 5 cross-validations on 80/20 train test splits of the real data. The main results are shown in Table  2 .",
            "Distance to Closest Record (DCR) Score : Second, we follow the evaluation metrics per TabDDPM  (Kotelnikov et al.,  2023 ) . That is, we compare the feature vectors of the real vs synthetic data and measure how far the synthetic data is from the original. The higher this distance is, the more different the generated data is from the original data, and thus the more private it is. A completely different version of the data would obtain the highest distance but could result in bad performance in the downstream LSTM classification performance or a high ML Inference score (close to 1). We calculate this by featurizing the event time predictions in terms of (count, means, and standard deviations). Then, we normalize and obtain the L2 distance between a generated subject and the closest real subject. Table  5  shows this result. Notice that  TrialSynth  variants generally obtain quite low scores on this metric. TabDDPM and PAR also generate data closer to the original data compared to LSTM VAE. We note the privacy-fidelity trade-off, as LSTM VAE generates data that is further away from the original, but yields worse utility (Table  2 ).",
            "Figure  2  shows an example of the proposed model with all optional structural constraints (allowing the model to access the true event knowledge, such as type and event length information). To combine the VAE and the Hawkes process, we realize that the log-likelihood can be modeled as the log-likelihood of a Hawkes process if we assume that the event times  t t t italic_t  and event types  k k k italic_k  are generated from a Multinomial Gaussian, i.e., the combined loss may be written as the following.",
            "Assuming Knowledge of Event Lengths  In this section, we examine the ability of our framework to take in additional subject-level information regarding sequence generation. For example,  TrialSynth  assumes that we have access to the original event lengths (e.g., event 1 occurs 5 times in the original sequence, generate the times at which event 1 occurs), as well as the event indices (e.g., we know that subject 1 has events 2,5,6). For more details, see Section  3.3 . Table  9  shows the result of allowing the model to know how many times events occur (for  TrialSynth  (Events Known)) or how the total length of the sequence to be generated (for  TrialSynth  (Events Unknown) and LSTM VAE). We see that providing the model with the event lengths boosts performance, as  TrialSynth  variants as well as the VAE LSTM in Table  9  performs better than in Table  2 ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Results of ML Inference Score: LSTM binary classification of real vs synthetic ( the closer to 0.5 the score is, the better ). The standard deviation calculated via bootstrapping is shown via   plus-or-minus \\pm  . AUCROC scores are shown. Bolded indicates the best result or within 1 standard deviation of the best result.",
        "table": "S3.T1.13.1.2.1.2.1",
        "footnotes": [],
        "references": [
            "The rest of this paper is organized as follows: In Section  2 , we review the related work. In Section  3 , we dive into the proposed  TrialSynth  in detail. In section  4 , we compare datasets and baselines, demonstrating the superiority of  TrialSynth . Finally, in Section  5 , we provide a discussion and conclude our findings.",
            "TrialSynth  is created to solve the highly specific task of synthetic sequential clinical trial patient generation. As shown in Fig.  1  and Fig.  3 , a patient contains many sequences of event types and their timestamps. This essentially creates a high-vocabulary, sequential token (event types) generation problem with a regression component (event times). First, we formulate the components that compose  TrialSynth . Then, we explain key details of  TrialSynth , including the ability to input type information in the form of known types to generate (which is common in the trial generation space when up-sampling patient data). Finally, we conclude with experiments on ML utility (usefulness of synthetic data) and inference privacy (important for patient privacy) and a discussion of the results.",
            "Numerical Values  Note that we do not discretize the time in terms of the time gap. Rather, we pad out each event sequence to the number of the most occurrences, which is usually around 100-200. Each event is considered to be categorical, and numerical events such as wbc (white blood cell count in Figure  3 ) is discretized based on their unique values in real-world data.",
            "ML Inference Score : This can also be thought of as an adversarial Model Attack  Theodorou et al. ( 2023 ) . Another main concern is the privacy of the synthetic data, to prevent any data or information leakage. To address this, we calculate the performance of predicting whether a generated sequence is real vs synthetic via an LSTM binary classification  (Patki et al.,  2016 )  (similar to an adversarial model). The real subjects are labeled with 0 and the synthetic subjects are labelled with 1. Results are shown in Table  3 , and we see that  TrialSynth  variants perform closest to the optimal 0.5 ROCAUC ideal score. One thing to note is that a perfect copy of the original data would result in a 0.5 score, so we have the following metric to measure the opposite scenario. Furthermore, we see a continued trend of  TrialSynth  (Events Known) generally outperforming other baseline methods, illustrating the importance of giving the model more information in this data-scarce setting.",
            "Assuming Knowledge of Event Lengths  In this section, we examine the ability of our framework to take in additional subject-level information regarding sequence generation. For example,  TrialSynth  assumes that we have access to the original event lengths (e.g., event 1 occurs 5 times in the original sequence, generate the times at which event 1 occurs), as well as the event indices (e.g., we know that subject 1 has events 2,5,6). For more details, see Section  3.3 . Table  9  shows the result of allowing the model to know how many times events occur (for  TrialSynth  (Events Known)) or how the total length of the sequence to be generated (for  TrialSynth  (Events Unknown) and LSTM VAE). We see that providing the model with the event lengths boosts performance, as  TrialSynth  variants as well as the VAE LSTM in Table  9  performs better than in Table  2 ."
        ]
    },
    "id_table_4": {
        "caption": "Table 6:  Hyperparameters Considered for  TrialSynth",
        "table": "S3.T1.13.1.7.6.2.1",
        "footnotes": [],
        "references": [
            "The rest of this paper is organized as follows: In Section  2 , we review the related work. In Section  3 , we dive into the proposed  TrialSynth  in detail. In section  4 , we compare datasets and baselines, demonstrating the superiority of  TrialSynth . Finally, in Section  5 , we provide a discussion and conclude our findings.",
            "Figure  4  and Figure  5  show some examples of reconstructed subjects as generated by the best-performing model ( TrialSynth  (Events Known)). Intuitively, it visually reveals that the generated data generally matches the original data."
        ]
    },
    "id_table_5": {
        "caption": "Table 7:  Hyperparameters Considered for LSTM VAE",
        "table": "S3.T1.13.1.8.7.2.1",
        "footnotes": [],
        "references": [
            "The rest of this paper is organized as follows: In Section  2 , we review the related work. In Section  3 , we dive into the proposed  TrialSynth  in detail. In section  4 , we compare datasets and baselines, demonstrating the superiority of  TrialSynth . Finally, in Section  5 , we provide a discussion and conclude our findings.",
            "Distance to Closest Record (DCR) Score : Second, we follow the evaluation metrics per TabDDPM  (Kotelnikov et al.,  2023 ) . That is, we compare the feature vectors of the real vs synthetic data and measure how far the synthetic data is from the original. The higher this distance is, the more different the generated data is from the original data, and thus the more private it is. A completely different version of the data would obtain the highest distance but could result in bad performance in the downstream LSTM classification performance or a high ML Inference score (close to 1). We calculate this by featurizing the event time predictions in terms of (count, means, and standard deviations). Then, we normalize and obtain the L2 distance between a generated subject and the closest real subject. Table  5  shows this result. Notice that  TrialSynth  variants generally obtain quite low scores on this metric. TabDDPM and PAR also generate data closer to the original data compared to LSTM VAE. We note the privacy-fidelity trade-off, as LSTM VAE generates data that is further away from the original, but yields worse utility (Table  2 ).",
            "From Table  5 , we see that  TrialSynth  generally performs the best, even beating out HALO and TabDDPM.",
            "Figure  4  and Figure  5  show some examples of reconstructed subjects as generated by the best-performing model ( TrialSynth  (Events Known)). Intuitively, it visually reveals that the generated data generally matches the original data."
        ]
    },
    "id_table_6": {
        "caption": "Table 8:  Hyperparameters Considered for LSTM Predictor Models",
        "table": "S4.T2.60.56",
        "footnotes": [],
        "references": [
            "The results are shown in Figure  6 . We see a clear trade-off, as the best-performing Distance to Closest Record model, usually VAE LSTM or PAR, performs worse on the downstream ROCAC metric. This is because the generated sequences are of poorer quality, being too different from the original. The best-performing Downstream ROCAUC models also generally have good ML Inference Privacy, which is to be expected as those models generate data that is similar to the original, which would allow for (1) better performance on the held-out test set for ROCAUC and (2) being harder to distinguish from original data."
        ]
    },
    "id_table_7": {
        "caption": "Table 9:  AUCROC results (   \\uparrow   higher the better,   plus-or-minus \\pm   standard deviation) from fitting a downstream LSTM to predict death event from the ablation of informing of the exact length of the sequence to generate.",
        "table": "S4.T2.60.56.57.1.2.1",
        "footnotes": [],
        "references": [
            "Here, we visualize 3 utility/privacy trade-off plots that is inherent to any synthetic data generation task. Each metric is normalized for ease of visualization so that the maximum achieved metric is set as the tip of the triangle by dividing by the max. For ML Inference Privacy (where 0.5 is the ideal value), we first take the absolute value of the difference (i.e.  x = | x  0.5 | x x 0.5 x=|x-0.5| italic_x = | italic_x - 0.5 | ), and then divide by the max as before. The results are shown in Figure  7 . It is important to note that while a max score of 1 would be ideal for all models, in practice, we see a clear trade-off as the best-performing Distance to Closest Record model. VAE LSTM and PAR perform worse on the downstream ROCAC metric compared to more faithful (and higher utility in terms of downstream ROCAUC) models such as TabDDPM and  TrialSynth . This is because the generated sequences are of worse fidelity, being too different from the original.  TrialSynth  variants also generally have good ML Inference Privacy, which is to be expected as those models generate data that is similar to the original, which would allow for (1) better performance on the held-out test set for ROCAUC and (2) being harder to distinguish from original data."
        ]
    },
    "id_table_8": {
        "caption": "Table 10:  Binary death event classification ROCAUCs (   \\uparrow   higher the better,   plus-or-minus \\pm   standard deviation) of a downstream LSTM trained on data generated from the  TrialSynth  models comparing probabilistic decoding vs greedy decoding. Note that the sequence stopping length is the same for both approaches.",
        "table": "S4.T2.60.56.57.1.3.1",
        "footnotes": [],
        "references": []
    },
    "id_table_9": {
        "caption": "",
        "table": "S4.T2.60.56.57.1.8.1",
        "footnotes": [],
        "references": [
            "Assuming Knowledge of Event Lengths  In this section, we examine the ability of our framework to take in additional subject-level information regarding sequence generation. For example,  TrialSynth  assumes that we have access to the original event lengths (e.g., event 1 occurs 5 times in the original sequence, generate the times at which event 1 occurs), as well as the event indices (e.g., we know that subject 1 has events 2,5,6). For more details, see Section  3.3 . Table  9  shows the result of allowing the model to know how many times events occur (for  TrialSynth  (Events Known)) or how the total length of the sequence to be generated (for  TrialSynth  (Events Unknown) and LSTM VAE). We see that providing the model with the event lengths boosts performance, as  TrialSynth  variants as well as the VAE LSTM in Table  9  performs better than in Table  2 ."
        ]
    },
    "id_table_10": {
        "caption": "",
        "table": "S4.T2.60.56.57.1.9.1",
        "footnotes": [],
        "references": [
            "Autoregressive Greedy Sampling vs Probabilistic Sampling  In this section, we compare the results of greedily choosing the best type as opposed to probabilistic sampling from the re-scaled logits  l  R N e  v  e  n  t  s l superscript R subscript N e v e n t s l\\in\\mathbb{R}^{N_{events}} italic_l  blackboard_R start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_e italic_v italic_e italic_n italic_t italic_s end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  when generating events from  TrialSynth  (Events Unknown). We re-scale the logits to be positive and sum to 1:  l = l  m  i  n  ( l )  l  m  i  n  ( l ) l l m i n l l m i n l l=\\frac{l-min(l)}{\\sum l-min(l)} italic_l = divide start_ARG italic_l - italic_m italic_i italic_n ( italic_l ) end_ARG start_ARG  italic_l - italic_m italic_i italic_n ( italic_l ) end_ARG , and sample from  k  M  u  l  t  i  n  o  m  i  a  l  ( l ) similar-to k M u l t i n o m i a l l k\\sim Multinomial(l) italic_k  italic_M italic_u italic_l italic_t italic_i italic_n italic_o italic_m italic_i italic_a italic_l ( italic_l )  (For the Greedy version, we take  arg  max k  ( l ) subscript arg max k l \\operatorname*{arg\\,max}_{k}(l) start_OPERATOR roman_arg roman_max end_OPERATOR start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_l ) ). Let  Probabilistic  represent the probabilistic sampling and  Greedy  represent greedy sampling. Table  10  shows the results, and we see that the Greedy version often fails to generate useful synthetic sequences."
        ]
    },
    "id_table_11": {
        "caption": "",
        "table": "S4.T3.51.49",
        "footnotes": [],
        "references": []
    },
    "id_table_12": {
        "caption": "",
        "table": "S4.T3.51.49.50.1.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_13": {
        "caption": "",
        "table": "S4.T3.51.49.50.1.7.1",
        "footnotes": [],
        "references": []
    },
    "id_table_14": {
        "caption": "",
        "table": "S4.T3.51.49.50.1.8.1",
        "footnotes": [],
        "references": []
    },
    "id_table_15": {
        "caption": "",
        "table": "S4.T5.1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_16": {
        "caption": "",
        "table": "S4.T5.1.1.1.1.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_17": {
        "caption": "",
        "table": "S4.T5.1.1.1.1.5.1",
        "footnotes": [],
        "references": []
    },
    "id_table_18": {
        "caption": "",
        "table": "S4.T5.1.1.1.1.6.1",
        "footnotes": [],
        "references": []
    },
    "id_table_19": {
        "caption": "",
        "table": "S4.T5.4.1",
        "footnotes": [],
        "references": []
    },
    "id_table_20": {
        "caption": "",
        "table": "S4.T5.4.1.1.1.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_21": {
        "caption": "",
        "table": "S4.T5.4.1.1.1.7.1",
        "footnotes": [],
        "references": []
    },
    "id_table_22": {
        "caption": "",
        "table": "S4.T5.4.1.1.1.8.1",
        "footnotes": [],
        "references": []
    },
    "id_table_23": {
        "caption": "",
        "table": "Ax1.EGx1",
        "footnotes": [],
        "references": []
    },
    "id_table_24": {
        "caption": "",
        "table": "A1.T6.3",
        "footnotes": [],
        "references": []
    },
    "id_table_25": {
        "caption": "",
        "table": "A1.T7.1",
        "footnotes": [],
        "references": []
    },
    "id_table_26": {
        "caption": "",
        "table": "A1.T8.1",
        "footnotes": [],
        "references": []
    },
    "id_table_27": {
        "caption": "",
        "table": "A1.T9.32.28",
        "footnotes": [],
        "references": []
    },
    "id_table_28": {
        "caption": "",
        "table": "A1.T9.32.28.29.1.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_29": {
        "caption": "",
        "table": "A1.T9.32.28.29.1.3.1",
        "footnotes": [],
        "references": []
    },
    "id_table_30": {
        "caption": "",
        "table": "A1.T9.32.28.29.1.4.1",
        "footnotes": [],
        "references": []
    },
    "id_table_31": {
        "caption": "",
        "table": "A1.T9.32.28.29.1.5.1",
        "footnotes": [],
        "references": []
    },
    "id_table_32": {
        "caption": "",
        "table": "A1.T10.25.21",
        "footnotes": [],
        "references": []
    }
}