{
    "id_table_1": {
        "caption": "Table 1:  Performance comparison to baselines (ROC scores).  Grouped by off-the-shelf base models trained on standard data, domain-adapted versions of the best base models using DAPT, SIFT, and DeepCORAL, complex state-of-the-art models trained using custom datasets (Vectara, MiniCheck) or using postprocessing (AlignScore), proprietary LLMs, and versions of the base models fine-tuned with Auto-GDA. We highlight the teacher model that was used to assign initial label certainties  r ( 0 ) superscript r 0 r^{(0)} italic_r start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT  in a  box  and make three observations: (1) the Auto-GDA version of the base models always improves over the vanilla versions  and the versions trained with SIFT, Deep CORAL, and DAPT , (2) our best-performing model DeBERTaV2 (Auto-GDA) outperforms its teacher model in three out of four cases, and (3) BART and DeBERTa with Auto-GDA reach LLM-level performance.",
        "table": "S4.T1.31.31",
        "footnotes": [],
        "references": [
            "to check the outputs at inference time, we require lightweight NLI models with very low latency.  The current landscape of available NLI models for verifying grounding in RAG is illustrated in  Figure   1  based on results obtained in our  evaluation of correctness and inference time (see  Table   3  for full numeric results): Some recent works such as Mini-Check  (Tang et al.,  2024 )  have developed lightweight models for NLI, e.g., based on RoBERTa  (Liu,  2019 ) . These models have shown good performance on academic benchmarks. However, our results indicate that their performance  in verifying grounding for realistic RAG inputs lags behind LLMs by about 20% (in ROC-AUC scores). Other recent methods use pre- and post-processesing techniques such as sentence tokenization or LLM prompting to decompose long prompts  (Zha et al.,  2023 ; Es et al.,  2024 )  into several chunks or facts. Each of these chunks needs to be processed in a separate forward pass, resulting in high latency as well. While some studies (e.g.,  Manakul et al.,  2023 ; Tang et al.,  2024 ) have also explored directly using LLMs like GPT-4 for text entailment detection, their latency is about an order of magnitude above the lightweight models. Taken together, these characteristics make it hard to deploy the existing approaches in real-time industry use-cases.",
            "LLMs have been repeatedly used to generate synthetic data for various domains, including NLI  (Saad-Falcon et al.,  2024 ; Hosseini et al.,  2024 ) . In this work, we generate initial data using few-shot prompting with the prompts provided in  Section   E.1 . The prompt instructs the LLM to generate synthetic claims  c ^ = G  ( e , claim  ( D t , e ) , y ^ ) ^ c G e claim subscript D t e ^ y \\hat{{\\bm{c}}}=G({\\bm{e}},\\text{claim}(\\mathcal{D}_{t,{\\bm{e}}}),\\hat{y}) over^ start_ARG bold_italic_c end_ARG = italic_G ( bold_italic_e , claim ( caligraphic_D start_POSTSUBSCRIPT italic_t , bold_italic_e end_POSTSUBSCRIPT ) , over^ start_ARG italic_y end_ARG )  for the evidence  e e {\\bm{e}} bold_italic_e , reflecting the style of example claims from  D t subscript D t \\mathcal{D}_{t} caligraphic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  ( claim  ( D t , e ) claim subscript D t e \\text{claim}(\\mathcal{D}_{t,{\\bm{e}}}) claim ( caligraphic_D start_POSTSUBSCRIPT italic_t , bold_italic_e end_POSTSUBSCRIPT )  denoting claims from target data for the evidence  e e {\\bm{e}} bold_italic_e ) and target label  y ^  0 , 1 ^ y 0 1 \\hat{y}\\in 0,1 over^ start_ARG italic_y end_ARG  0 , 1 . For label  y ^ = 1 ^ y 1 \\hat{y}=1 over^ start_ARG italic_y end_ARG = 1 , the LLM is instructed to include only grounded facts, for  y ^ = 0 ^ y 0 \\hat{y}=0 over^ start_ARG italic_y end_ARG = 0 , some ungrounded information should be introduced. We assign labels  y ^ ^ y \\hat{y} over^ start_ARG italic_y end_ARG  according to the prompt used, resulting in complete initial generated tuples  ( c ^ , y ^ ) ^ c ^ y (\\hat{{\\bm{c}}},\\hat{y}) ( over^ start_ARG bold_italic_c end_ARG , over^ start_ARG italic_y end_ARG ) . We follow some related works  (Puri et al.,  2020 ; Vu et al.,  2021 ) , which have suggested generating many samples and only keeping the most confident. To do so, the samples can be equipped with a weak estimate of the label probability using the teacher model, e.g., another LLM or an NLI model with sophisticated pre- and postprocessing. In the binary classification setup, we can compute initial entailment certainties as  r ( 0 ) = T  ( e , c ^ ) superscript r 0 T e ^ c r^{(0)}=T({\\bm{e}},\\hat{{\\bm{c}}}) italic_r start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT = italic_T ( bold_italic_e , over^ start_ARG bold_italic_c end_ARG ) , which can be interpreded as an uncalibrated and potentially noisy estimate of  p  ( y = 1 | e , c ^ ) p y conditional 1 e ^ c p(y=1|{\\bm{e}},\\hat{{\\bm{c}}}) italic_p ( italic_y = 1 | bold_italic_e , over^ start_ARG bold_italic_c end_ARG ) . We explore LLMs for data generation and use state-of-the-art NLI models and also LLMs as teacher models  T T T italic_T  for providing initial entailment certainties. Adding the entailment certainty scores  r ( 0 ) superscript r 0 r^{(0)} italic_r start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT  to the respective tuples we obtain a set of triples  D e ( 0 ) = { ( c ^ k , y ^ k , r k ( 0 ) ) } k = 1 K subscript superscript D 0 e superscript subscript subscript ^ c k subscript ^ y k superscript subscript r k 0 k 1 K \\mathcal{D}^{(0)}_{\\bm{e}}=\\{(\\hat{{\\bm{c}}}_{k},\\hat{y}_{k},r_{k}^{(0)})\\}_{k%  =1}^{K} caligraphic_D start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_italic_e end_POSTSUBSCRIPT = { ( over^ start_ARG bold_italic_c end_ARG start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT ) } start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT  after this step.",
            "Label Invariant Augmentation Strategies:   In this work, we consider three augmentation strategies that will likely preserve entailment labels (see Appendix  Section   C.1  for additional details):",
            "Optimizing the objective.  Optimizing the objective for a subset  Q Q \\mathcal{Q} caligraphic_Q  of size  K K K italic_K  with minimal loss can be done highly efficiently in three steps: (1) Computing each samples contribution to the sum in  L t  o  t subscript L t o t \\mathcal{L}_{tot} caligraphic_L start_POSTSUBSCRIPT italic_t italic_o italic_t end_POSTSUBSCRIPT , (2) ranking the samples by this contribution, and (3) greedily  selecting the top- K K K italic_K  subset of samples with the lowest contributions. Pseudocode of our complete framework is provided in  Algorithm   1  (Appendix).",
            "Baselines.  We use state-of-the-art baselines: AlignScore  (Zha et al.,  2023 )  (RoBERTa-based with pre- and postprocessing), MiniCheck  (Tang et al.,  2024 ) , and Vectara-2.1 1 1 1 https://docs.vectara.com/docs  (both T5-based). As a teacher model to assign initial score, we use the best-performing model from the complex category, which allow easy access to uncertainty scores and have good performance. We employ  optuna 2 2 2 https://optuna.org/  to tune the remaining hyperparameters   u  superscript subscript  u  \\lambda_{u}^{\\prime} italic_ start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,   d subscript  d \\lambda_{d} italic_ start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT , and the other teacher model used to estimate entailment probabilities for augmentations in Eqn.  1  performing 50 trials per dataset. Auto-GDA is run for two iterations on RAGTruth and one iteration on the other datasets, generating synthetic datasets between  1.3  1.3\\times 1.3   and  2  2\\times 2   the original dataset size. We found no improvements through further increasing dataset size.  We also compare against several common UDA methods, including robustness-based approaches. Specifically, we implement DAPT  (Gururangan et al.,  2020 ) , SiFT  (He et al.,  2020 ) , and Deep-CORAL  (Sun & Saenko,  2016 )  for further pretraining of the DeBERTa-V2 model. Additional implementation details for all methods can be found in  Appendix   C .",
            "We present the main results obtained with Auto-GDA in  Table   1 . Our results show that Auto-GDA is highly effective and improves performance in ROC-AUC scores of all tested models on all our datasets. Additional metrics confirm our findings (balanced accuracy, f1-scores in  Section   D.1 ).",
            "Linking to our motivational  Figure   1 , we study the efficiency of our models in  Table   3 . We compute NLI scores for 50 random samples from the respective datasets. We observe models in three categories: The most efficient models (Vectara to BART-large) have medium performance on the RAG datasets used in this work indicated by their ROC. On the other hand, models using sophisticated post-processing (AlignScore) perform better, but require about 2.5 times more inference time than our most successful DeBERTa model. Finally, LLMs via APIs require about 10-fold inference time, but result in highest performance. When we compare models trained with our approach, we observe LLM-level performance at about 10% of the inference time.",
            "In this work, we show that synthetic data can successfully tackle the domain generalization gap for NLI models. We present Auto-GDA, an automatic approach for synthetic sample generation and selection overcoming the need for tedious heuristic or manual filtering and augmentation selection. Our results show that we can obtain models that perform on par with most powerful LLMs while having around 90% less inference time using our method.  Our findings further demonstrate the superiority of synthetic data generation over unsupervised domain adaptation (UDA) methods. Even with synthetic data obtained only through few-shot prompting, we can obtain better results than the UDA baselines ( Table   1  vs.  Table   2 ). We attribute this to the inherent limitations of UDA methods that usually operate in vectorial embedding spaces and fail to capture semantics of the target domain. By generating synthetic data, we can provide a more comprehensive and tailored representation, allowing for greater control over the desired features. Our results also confirm the common intuition that generalization is increasingly hard with smaller models  (Bhargava et al.,  2021 ) . This highlights that domain adaptation is particularly important when low latency at inference time is required, whereas general purpose models can be preferable when quick inference is no hard requirement.",
            "In this section we provide a strategy to estimate the label correctness term in  Equation   5  which is given by  D K  L ( p Q ( y | c ) | | p cov ( y | c ) ) D_{KL}\\left(p_{\\mathcal{Q}}(y|{\\bm{c}})\\middle|\\middle|p_{\\text{cov}}(y|{\\bm{c%  }})\\right) italic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( italic_p start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT ( italic_y | bold_italic_c ) | | italic_p start_POSTSUBSCRIPT cov end_POSTSUBSCRIPT ( italic_y | bold_italic_c ) )  (see  Section   B.1  for why we need to model this term).  We need to model both  p Q  ( y | c ) subscript p Q conditional y c p_{\\mathcal{Q}}(y|{\\bm{c}}) italic_p start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT ( italic_y | bold_italic_c )  and  p cov  ( y | c ) subscript p cov conditional y c p_{\\text{cov}}(y|{\\bm{c}}) italic_p start_POSTSUBSCRIPT cov end_POSTSUBSCRIPT ( italic_y | bold_italic_c )  to estimate this term. As they are binary, we choose Bernoulli distributions. Our estimated conditional  p Q  ( y = 1 | c ) =  0 subscript p Q y conditional 1 c subscript italic- 0 p_{\\mathcal{Q}}(y=1|{\\bm{c}})=\\phi_{0} italic_p start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT ( italic_y = 1 | bold_italic_c ) = italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  is modeled through a Bernoulli distribution with parameter   0 subscript italic- 0 \\phi_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT . This conditional distribution is assumed not to change through the augmentation once initialized (because we also do not change the hard labels during augmentations). Reasonable choices for   0 subscript italic- 0 \\phi_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  involve setting hard probabilities, i.e.,   0 = y ^ subscript italic- 0 ^ y \\phi_{0}=\\hat{y} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = over^ start_ARG italic_y end_ARG  or using the initial label certainty score   0 = r ( 0 ) subscript italic- 0 superscript r 0 \\phi_{0}=r^{(0)} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_r start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT  as a softer version.",
            "Label Correctness Term.  We model the uncertainty propagation as in  Equation   10 . Approaching   r  0  subscript  r 0 \\sigma_{r}\\rightarrow 0 italic_ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT  0 , we have",
            "We implement the algorithm outlined in  Algorithm   1 . We emphasize that we fix the teacher model to assign the initial scores. Here we can compute estimates of the model performance using the validation set of evidence-claim pairs to which we have access, allowing us to chose the best performing one as teacher. However, we do not know the performance of the models on claim-claim pairs, so we treat the teacher model used in the augmentation step as a hyperparameter, that will be optimized.",
            "We provide pseudocode for our algorithm in  Algorithm   1 .",
            "We compare our results to model trained on pseudo-labels in for the original datasets in  Table   10 . The results inicate that this is a surprisingly strong baseline, which is however surpassed by Auto-GDA in 3 out of 4 cases.",
            "Results when the models are fine-tuned on the validations set directly are shown in  Table   12 .",
            "Table  13  compares the performance (ROC-AUC scores) of various Unsupervised Domain Adaptation (UDA) methods and synthetic data approaches across different source datasets. All results are evaluated on the RAGTRUTH target dataset, using a DeBERTaV3 model trained on the PAWS, VitaminC, and Fever data.  The table illustrates the effectiveness of different UDA methods and synthetic data approaches when applied to various source datasets (MNLI, Summedits, and Ragtruth-synth). More specifically, we see that except for the synthetically generated version of RAGTruth, the choice of the source domain data does not seem to alter results significantly. We also see that vanilla finetuning on the synthetic RAGTruth data outperforms all other variations, indicating that synthetic data is more appropraite for NLI than traditional UDA methods. This is perhaps due to the fact that very small changes in the generated claim can flip the label from entailed to non-entailed and vice-versa."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Ablation:  Fine-tuning with synthetic data obtained by few-shot prompting and random selection of augmentations as opposed to using our framework Auto-GDA. We also report performance relative to the hypothetical upper baseline of fine-tuning on labeled target data and observe that we can almost close this domain-adaptation gap (ROC, DeBERTa model, avg. over 5 runs).",
        "table": "S5.T2.1.1",
        "footnotes": [],
        "references": [
            "We illustrate these steps in  Figure   2  and will detail out implementation choices for each step below.",
            "where  d  ( x , x  ) =    ( x )    ( x )   d x superscript x  delimited-  x  superscript x  d({\\bm{x}},{\\bm{x}}^{\\prime})=\\lVert\\psi({\\bm{x}})-\\psi({\\bm{x}})^{\\prime}\\rVert italic_d ( bold_italic_x , bold_italic_x start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ) =  italic_ ( bold_italic_x ) - italic_ ( bold_italic_x ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT   is a distance function over inputs in  X X \\mathcal{X} caligraphic_X  defined via textual embeddings    \\psi italic_ ,  c min , i  arg  min c   claim  ( D t , e )  d  ( c  , c ^ i )  subscript c i subscript arg min superscript c  claim subscript D t e d superscript c  subscript ^ c i {\\bm{c}}_{\\min,i}\\coloneqq\\operatorname*{arg\\,min}_{{\\bm{c}}^{\\prime}\\in\\text{%  claim}(\\mathcal{D}_{t,{\\bm{e}}})}d({\\bm{c}}^{\\prime},\\hat{{\\bm{c}}}_{i}) bold_italic_c start_POSTSUBSCRIPT roman_min , italic_i end_POSTSUBSCRIPT  start_OPERATOR roman_arg roman_min end_OPERATOR start_POSTSUBSCRIPT bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  claim ( caligraphic_D start_POSTSUBSCRIPT italic_t , bold_italic_e end_POSTSUBSCRIPT ) end_POSTSUBSCRIPT italic_d ( bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , over^ start_ARG bold_italic_c end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  is the closest claim for evidence  e e {\\bm{e}} bold_italic_e  from the target dataset, and   d ,  u subscript  d subscript  u \\lambda_{d},\\lambda_{u} italic_ start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT  are hyperparameters.  LDiv : [ 0 , 1 ]  { 0 , 1 }  R + : LDiv  0 1 0 1 subscript R \\text{LDiv}:[0,1]\\times\\{0,1\\}\\rightarrow\\mathbb{R}_{+} LDiv : [ 0 , 1 ]  { 0 , 1 }  blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  is a function that penalizes uncertain labels taking the certainty scores  r r r italic_r  and the hard labels  y ^ ^ y \\hat{y} over^ start_ARG italic_y end_ARG  as inputs as plotted in  Figure   4 . We derive the exact form of the LDiv function as a divergence estimate of the conditional distributions in  Section   B.2 . The  distance  term encourages samples to be close to claims",
            "Theoretical Properties.    Notably,  Equation   2  can be derived from first principles as an  enhanced distribution matching objective .  By defining parametric distributions  p Q , e  ( c , y ) subscript p Q e c y p_{\\mathcal{Q},{\\bm{e}}}({\\bm{c}},y) italic_p start_POSTSUBSCRIPT caligraphic_Q , bold_italic_e end_POSTSUBSCRIPT ( bold_italic_c , italic_y )  (representing the selected synthetic data for evidence  e e {\\bm{e}} bold_italic_e ) and  p cov , e  ( c , y ) subscript p cov e c y p_{\\text{cov},{\\bm{e}}}({\\bm{c}},y) italic_p start_POSTSUBSCRIPT cov , bold_italic_e end_POSTSUBSCRIPT ( bold_italic_c , italic_y )  (representing the target distribution for  e e {\\bm{e}} bold_italic_e  we aim to imitate) the objective corresponds to the divergence between these distributions plus the expected utility of the synthetic data. Formally,",
            "Components of the algorithm.  We add the components of our algorithm individually and show how they successively increase performance in  Table   2 . In all ablations  we keep dataset size and other parameters constant. The biggest gain is achieved by fine-tuning on data created by few-shot prompting. We subsequently add data augmentations without applying our selection criterion, but instead selecting few-shot and augmented samples randomly. We observe that this decreases data quality, highlighting that data augmentation is only beneficial together with our filtering criterion. When we do so and apply data augmentation with our filtering step (corresponding to full Auto-GDA), this increases performance overall with one exception on the LFQA-Verification dataset (note however that performance here is already above the labeled data, so selection based on target data may draw the results toward the labeled data scores as well).  As an upper baseline we are interested in the hypothetical performance reachable by fine-tuning on human-labeled samples and include it in  Table   2 . Considering the difference between the no fine-tuning models and the models fine-tuned on human-labeled data as the  domain adaptation gap , expressing our results relative to these baselines indicates that we manage to close an impressive 96% of this gap.",
            "Selection from Several Augmentation Routines.  We report the effect of single versus several augmentations in  Figure   6(a)  and  Figure   6(b)  in  Section   D.2 , quantitatively and qualitatively demonstrating that Auto-GDA succeeds to the most promising samples from different augmentations.",
            "In this work, we show that synthetic data can successfully tackle the domain generalization gap for NLI models. We present Auto-GDA, an automatic approach for synthetic sample generation and selection overcoming the need for tedious heuristic or manual filtering and augmentation selection. Our results show that we can obtain models that perform on par with most powerful LLMs while having around 90% less inference time using our method.  Our findings further demonstrate the superiority of synthetic data generation over unsupervised domain adaptation (UDA) methods. Even with synthetic data obtained only through few-shot prompting, we can obtain better results than the UDA baselines ( Table   1  vs.  Table   2 ). We attribute this to the inherent limitations of UDA methods that usually operate in vectorial embedding spaces and fail to capture semantics of the target domain. By generating synthetic data, we can provide a more comprehensive and tailored representation, allowing for greater control over the desired features. Our results also confirm the common intuition that generalization is increasingly hard with smaller models  (Bhargava et al.,  2021 ) . This highlights that domain adaptation is particularly important when low latency at inference time is required, whereas general purpose models can be preferable when quick inference is no hard requirement.",
            "Modeling label correctness.   We propose to model to label correctness term using the entailment certainty scores, which provides us with an estimate of how well the true and the assigned labels are aligned at a certain point.  If a positively labeled sample has very high entailment certainty or a negatively labeled sample has very low entailment certainty, the assigned labels likely match the ground truth and divergence between true conditional label distribution and assumed distribution is expected to be minimal at the sample  x x {\\bm{x}} bold_italic_x . We derive a relation between the label correctness term and our entailment certainty score in form of a function  D K  L ( p  ( y | c ) | | p cov ( y | c ) )  LDiv ( r ( i ) , y ^ ) D_{KL}\\left(p_{\\theta}(y|{\\bm{c}})\\middle|\\middle|p_{\\text{cov}}(y|{\\bm{c}})%  \\right)\\coloneqq\\text{LDiv}(r^{(i)},\\hat{y}) italic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( italic_p start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_y | bold_italic_c ) | | italic_p start_POSTSUBSCRIPT cov end_POSTSUBSCRIPT ( italic_y | bold_italic_c ) )  LDiv ( italic_r start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , over^ start_ARG italic_y end_ARG ) , relying on the current entailment certainty  r ( i ) superscript r i r^{(i)} italic_r start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT  and the assigned hard label  y ^ ^ y \\hat{y} over^ start_ARG italic_y end_ARG  in  Section   B.2  that is depicted in  Figure   4 . The resulting relation fulfills certain natural axioms including that the label correctness term is 0, when we have perfect certainty, i.e.,  LDiv  ( 0 , 0 ) = 0 LDiv 0 0 0 \\text{LDiv}(0,0)=0 LDiv ( 0 , 0 ) = 0 ,  LDiv  ( 1 , 1 ) = 0 LDiv 1 1 0 \\text{LDiv}(1,1)=0 LDiv ( 1 , 1 ) = 0 .",
            "Estimating the mislabeling probability.   An integral part of our algorithm in the estimation of the agreement probability in  Equation   44 . To investigate the effect of implementing this choice, we run an ablation study to better understand how the quality of the agreement probabilities affects the score. We provide results average over 3 runs in  Figure   7(a) . The results indicate that the choice of the model used to estimate  r r r italic_r  the label certainty score has substantial effect on the quality of the results. While the utility (in terms of ROC scores) drops when noise is added, it increases again when high levels of noise are applied. We attribute this behavior to the algorithm neglecting the mutated samples almost entirely when the noise level is too high and mainly selecting the few shot generate samples. As shown in  Table   2   these have fair utility already.",
            "Results when the models are fine-tuned on the validations set directly are shown in  Table   12 ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Inference times of the models  on the datasets as  well es average performance taken from  Table   1 . Our DeBERTa model combines LLM-level performance with substantially lower latency.",
        "table": "S5.T3.28.28",
        "footnotes": [],
        "references": [
            "to check the outputs at inference time, we require lightweight NLI models with very low latency.  The current landscape of available NLI models for verifying grounding in RAG is illustrated in  Figure   1  based on results obtained in our  evaluation of correctness and inference time (see  Table   3  for full numeric results): Some recent works such as Mini-Check  (Tang et al.,  2024 )  have developed lightweight models for NLI, e.g., based on RoBERTa  (Liu,  2019 ) . These models have shown good performance on academic benchmarks. However, our results indicate that their performance  in verifying grounding for realistic RAG inputs lags behind LLMs by about 20% (in ROC-AUC scores). Other recent methods use pre- and post-processesing techniques such as sentence tokenization or LLM prompting to decompose long prompts  (Zha et al.,  2023 ; Es et al.,  2024 )  into several chunks or facts. Each of these chunks needs to be processed in a separate forward pass, resulting in high latency as well. While some studies (e.g.,  Manakul et al.,  2023 ; Tang et al.,  2024 ) have also explored directly using LLMs like GPT-4 for text entailment detection, their latency is about an order of magnitude above the lightweight models. Taken together, these characteristics make it hard to deploy the existing approaches in real-time industry use-cases.",
            "Obtaining High-Quality Entailment Certainties.  We can combine the generative models with discriminative teacher models again to obtain weak estimates  r ( i ) superscript r i r^{(i)} italic_r start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT  of the entailment certainty of the augmented samples. Instead of directly computing the entailment probability using  T T T italic_T , we exploit logical invariances, which allow for better estimates depicted in  Figure   3 : If the original claim is entailed by the evidence, and if the modified claim is entailed by the original claim, the modified claim will also be entailed by the evidence. Suppose we have obtained  c ^  = M  ( c ^ ) superscript ^ c  M ^ c \\hat{{\\bm{c}}}^{\\prime}=M(\\hat{{\\bm{c}}}) over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT = italic_M ( over^ start_ARG bold_italic_c end_ARG )  as a modification of the synthetic claim  c ^ ^ c \\hat{{\\bm{c}}} over^ start_ARG bold_italic_c end_ARG . As we already have an estimate of the entailment probability for  ( e , c ^ ) e ^ c ({\\bm{e}},\\hat{{\\bm{c}}}) ( bold_italic_e , over^ start_ARG bold_italic_c end_ARG ) , we can reuse it and only need to compute another entailment probability for  ( c ^ , c ^  ) ^ c superscript ^ c  (\\hat{{\\bm{c}}},\\hat{{\\bm{c}}}^{\\prime}) ( over^ start_ARG bold_italic_c end_ARG , over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ) . We argue that computing this entailment probability is easier for the teacher model than directly computing  T  ( e , c ^  ) T e superscript ^ c  T({\\bm{e}},\\hat{{\\bm{c}}}^{\\prime}) italic_T ( bold_italic_e , over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ) , as the claim and the modified claim should be semantically and syntactically more similar. Paraphrasing datasets like PAWS  (Zhang et al.,  2019 )  are common pretraining datasets, and standard NLI datasets like MNLI  (Williams et al.,  2018 )  contain many similar samples due to their construction through edits, so NLI predictions are expected to be more reliable on these pairs. Querying the teacher model on  T  ( c ^ , c ^  ) T ^ c superscript ^ c  T(\\hat{{\\bm{c}}},\\hat{{\\bm{c}}}^{\\prime}) italic_T ( over^ start_ARG bold_italic_c end_ARG , over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT )  allows us to use the following update rule for the augmented sample ( e , c ^  ) {\\bm{e}},\\hat{{\\bm{c}}}^{\\prime}) bold_italic_e , over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ) :",
            "Linking to our motivational  Figure   1 , we study the efficiency of our models in  Table   3 . We compute NLI scores for 50 random samples from the respective datasets. We observe models in three categories: The most efficient models (Vectara to BART-large) have medium performance on the RAG datasets used in this work indicated by their ROC. On the other hand, models using sophisticated post-processing (AlignScore) perform better, but require about 2.5 times more inference time than our most successful DeBERTa model. Finally, LLMs via APIs require about 10-fold inference time, but result in highest performance. When we compare models trained with our approach, we observe LLM-level performance at about 10% of the inference time.",
            "Partial Rephrasing with LLM.  We use the prompt given in  Section   E.3  to instruct the LLM (Claude3-Haiku) to create different versions of a document where some parts are masked. We decide to mask a random 20% of consecutive words in the document. We let the LLM generate 3 outputs each for 2 different masks, resulting in a total of 6 rephrased versions for each claim. Sampling temperature is set to 1.0.",
            "Table  13  compares the performance (ROC-AUC scores) of various Unsupervised Domain Adaptation (UDA) methods and synthetic data approaches across different source datasets. All results are evaluated on the RAGTRUTH target dataset, using a DeBERTaV3 model trained on the PAWS, VitaminC, and Fever data.  The table illustrates the effectiveness of different UDA methods and synthetic data approaches when applied to various source datasets (MNLI, Summedits, and Ragtruth-synth). More specifically, we see that except for the synthetically generated version of RAGTruth, the choice of the source domain data does not seem to alter results significantly. We also see that vanilla finetuning on the synthetic RAGTruth data outperforms all other variations, indicating that synthetic data is more appropraite for NLI than traditional UDA methods. This is perhaps due to the fact that very small changes in the generated claim can flip the label from entailed to non-entailed and vice-versa."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Dataset sizes.",
        "table": "A3.T4.1.1",
        "footnotes": [],
        "references": [
            "Sample Selection.  Select the subset of samples of size  K K K italic_K  from  D   e ( i + 1 ) subscript superscript   D i 1 e \\bar{\\mathcal{D}}^{(i+1)}_{\\bm{e}} over  start_ARG caligraphic_D end_ARG start_POSTSUPERSCRIPT ( italic_i + 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_italic_e end_POSTSUBSCRIPT  that minimize our proposed  enhanced distribution matching objective   L tot subscript L tot \\mathcal{L}_{\\text{tot}} caligraphic_L start_POSTSUBSCRIPT tot end_POSTSUBSCRIPT  formally introduced in Eqn. ( 4 ). The objective includes the unlabeled target samples  D t subscript D t \\mathcal{D}_{t} caligraphic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and the certainty scores. The selected subset becomes the next generation dataset  D e ( i + 1 ) subscript superscript D i 1 e \\mathcal{D}^{(i+1)}_{\\bm{e}} caligraphic_D start_POSTSUPERSCRIPT ( italic_i + 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_italic_e end_POSTSUBSCRIPT .",
            "where  d  ( x , x  ) =    ( x )    ( x )   d x superscript x  delimited-  x  superscript x  d({\\bm{x}},{\\bm{x}}^{\\prime})=\\lVert\\psi({\\bm{x}})-\\psi({\\bm{x}})^{\\prime}\\rVert italic_d ( bold_italic_x , bold_italic_x start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ) =  italic_ ( bold_italic_x ) - italic_ ( bold_italic_x ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT   is a distance function over inputs in  X X \\mathcal{X} caligraphic_X  defined via textual embeddings    \\psi italic_ ,  c min , i  arg  min c   claim  ( D t , e )  d  ( c  , c ^ i )  subscript c i subscript arg min superscript c  claim subscript D t e d superscript c  subscript ^ c i {\\bm{c}}_{\\min,i}\\coloneqq\\operatorname*{arg\\,min}_{{\\bm{c}}^{\\prime}\\in\\text{%  claim}(\\mathcal{D}_{t,{\\bm{e}}})}d({\\bm{c}}^{\\prime},\\hat{{\\bm{c}}}_{i}) bold_italic_c start_POSTSUBSCRIPT roman_min , italic_i end_POSTSUBSCRIPT  start_OPERATOR roman_arg roman_min end_OPERATOR start_POSTSUBSCRIPT bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  claim ( caligraphic_D start_POSTSUBSCRIPT italic_t , bold_italic_e end_POSTSUBSCRIPT ) end_POSTSUBSCRIPT italic_d ( bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , over^ start_ARG bold_italic_c end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  is the closest claim for evidence  e e {\\bm{e}} bold_italic_e  from the target dataset, and   d ,  u subscript  d subscript  u \\lambda_{d},\\lambda_{u} italic_ start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT  are hyperparameters.  LDiv : [ 0 , 1 ]  { 0 , 1 }  R + : LDiv  0 1 0 1 subscript R \\text{LDiv}:[0,1]\\times\\{0,1\\}\\rightarrow\\mathbb{R}_{+} LDiv : [ 0 , 1 ]  { 0 , 1 }  blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT  is a function that penalizes uncertain labels taking the certainty scores  r r r italic_r  and the hard labels  y ^ ^ y \\hat{y} over^ start_ARG italic_y end_ARG  as inputs as plotted in  Figure   4 . We derive the exact form of the LDiv function as a divergence estimate of the conditional distributions in  Section   B.2 . The  distance  term encourages samples to be close to claims",
            "Datasets.  We evaluate our approach on three datasets for document-grounded summarization and question answering (QA). We select datasets which include documents, realistic LLM-generated long-form answers, and human labels that can be used for testing. The SummEdits  (Laban et al.,  2023 )  dataset contains GPT-3.5-generated and manual summaries of documents from different domains, e.g., judicial, sales emails, podcasts. We further use both the summary and the QA portion of the RAGTruth  (Wu et al.,  2023 )  dataset. The RAGTruth dataset contains summaries and answers to questions created by LLMs (GPT-3.5/4, Mistral, Llama2). Finally, we use the LFQA-Verification dataset  (Chen et al.,  2023a ) , which retrieved documents for questions from the Explain me Like I am five-dataset and generated corresponding long-form answers with GPT-3.5 and Alpaca. We selected the datasets to feature characteristics of realistic RAG systems including specific prompt templates (present in RAGTruth, LFQA-Verification) and various domains (present in all datasets, specifically in SummEdits). Details and links to the datasets can be found in  Table   4 .",
            "Modeling label correctness.   We propose to model to label correctness term using the entailment certainty scores, which provides us with an estimate of how well the true and the assigned labels are aligned at a certain point.  If a positively labeled sample has very high entailment certainty or a negatively labeled sample has very low entailment certainty, the assigned labels likely match the ground truth and divergence between true conditional label distribution and assumed distribution is expected to be minimal at the sample  x x {\\bm{x}} bold_italic_x . We derive a relation between the label correctness term and our entailment certainty score in form of a function  D K  L ( p  ( y | c ) | | p cov ( y | c ) )  LDiv ( r ( i ) , y ^ ) D_{KL}\\left(p_{\\theta}(y|{\\bm{c}})\\middle|\\middle|p_{\\text{cov}}(y|{\\bm{c}})%  \\right)\\coloneqq\\text{LDiv}(r^{(i)},\\hat{y}) italic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( italic_p start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_y | bold_italic_c ) | | italic_p start_POSTSUBSCRIPT cov end_POSTSUBSCRIPT ( italic_y | bold_italic_c ) )  LDiv ( italic_r start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , over^ start_ARG italic_y end_ARG ) , relying on the current entailment certainty  r ( i ) superscript r i r^{(i)} italic_r start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT  and the assigned hard label  y ^ ^ y \\hat{y} over^ start_ARG italic_y end_ARG  in  Section   B.2  that is depicted in  Figure   4 . The resulting relation fulfills certain natural axioms including that the label correctness term is 0, when we have perfect certainty, i.e.,  LDiv  ( 0 , 0 ) = 0 LDiv 0 0 0 \\text{LDiv}(0,0)=0 LDiv ( 0 , 0 ) = 0 ,  LDiv  ( 1 , 1 ) = 0 LDiv 1 1 0 \\text{LDiv}(1,1)=0 LDiv ( 1 , 1 ) = 0 .",
            "where     ( r ) superscript   r \\alpha^{\\prime}(r) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_r )  and     ( r ) superscript   r \\beta^{\\prime}(r) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_r )  are the numerical solutions of Proposition 2. To arrive at the formulation in the main paper, we can plug in   0 = y ^ subscript italic- 0 ^ y \\phi_{0}=\\hat{y} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = over^ start_ARG italic_y end_ARG , which is the term visualized in  Figure   4 .",
            "We derive this proposition in  Section   B.4 .  In summary, we show that for small   r subscript  r \\sigma_{r} italic_ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT  the contribution of a sample to the objective approaches a sum of three parts: The distance to the closest sample from the target claim set for evidence  e , claim  ( D t , e ) e claim subscript D t e {\\bm{e}},\\text{claim}(\\mathcal{D}_{t,{\\bm{e}}}) bold_italic_e , claim ( caligraphic_D start_POSTSUBSCRIPT italic_t , bold_italic_e end_POSTSUBSCRIPT )  to the claim  c ^ ^ c \\hat{{\\bm{c}}} over^ start_ARG bold_italic_c end_ARG , the label correctness term, and the negative utility.  We use the above decomposition in our algorithm, ensuring the objective can be solved highly efficiently in three steps: (1) Computing each samples contribution to  L t  o  t subscript L t o t \\mathcal{L}_{tot} caligraphic_L start_POSTSUBSCRIPT italic_t italic_o italic_t end_POSTSUBSCRIPT , (2) ranking the samples by this contribution, and (3) finally selecting the top- K K K italic_K  subset of samples with the lowest contributions.",
            "We apply the following preprocessing to the datasets: We filter out all samples, that have more than 1022 BART tokens (filling out the 1024 context length with an additional SEP and CLS token). The sizes and source links of the resulting datasets are provided in  Table   4 . We note that this reduces the number of usable SummEdits domains from 10 to 5 (due to some domains only containing overlength evidence documents).",
            "Estimating the mislabeling probability.   An integral part of our algorithm in the estimation of the agreement probability in  Equation   44 . To investigate the effect of implementing this choice, we run an ablation study to better understand how the quality of the agreement probabilities affects the score. We provide results average over 3 runs in  Figure   7(a) . The results indicate that the choice of the model used to estimate  r r r italic_r  the label certainty score has substantial effect on the quality of the results. While the utility (in terms of ROC scores) drops when noise is added, it increases again when high levels of noise are applied. We attribute this behavior to the algorithm neglecting the mutated samples almost entirely when the noise level is too high and mainly selecting the few shot generate samples. As shown in  Table   2   these have fair utility already."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Fixed hyperparameters dependent on dataset. Note that we set only Samples per evidence which determines synthetic dataset size together with the number of evidences.",
        "table": "A3.T5.1",
        "footnotes": [],
        "references": [
            "In this section we provide a strategy to estimate the label correctness term in  Equation   5  which is given by  D K  L ( p Q ( y | c ) | | p cov ( y | c ) ) D_{KL}\\left(p_{\\mathcal{Q}}(y|{\\bm{c}})\\middle|\\middle|p_{\\text{cov}}(y|{\\bm{c%  }})\\right) italic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( italic_p start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT ( italic_y | bold_italic_c ) | | italic_p start_POSTSUBSCRIPT cov end_POSTSUBSCRIPT ( italic_y | bold_italic_c ) )  (see  Section   B.1  for why we need to model this term).  We need to model both  p Q  ( y | c ) subscript p Q conditional y c p_{\\mathcal{Q}}(y|{\\bm{c}}) italic_p start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT ( italic_y | bold_italic_c )  and  p cov  ( y | c ) subscript p cov conditional y c p_{\\text{cov}}(y|{\\bm{c}}) italic_p start_POSTSUBSCRIPT cov end_POSTSUBSCRIPT ( italic_y | bold_italic_c )  to estimate this term. As they are binary, we choose Bernoulli distributions. Our estimated conditional  p Q  ( y = 1 | c ) =  0 subscript p Q y conditional 1 c subscript italic- 0 p_{\\mathcal{Q}}(y=1|{\\bm{c}})=\\phi_{0} italic_p start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT ( italic_y = 1 | bold_italic_c ) = italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  is modeled through a Bernoulli distribution with parameter   0 subscript italic- 0 \\phi_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT . This conditional distribution is assumed not to change through the augmentation once initialized (because we also do not change the hard labels during augmentations). Reasonable choices for   0 subscript italic- 0 \\phi_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  involve setting hard probabilities, i.e.,   0 = y ^ subscript italic- 0 ^ y \\phi_{0}=\\hat{y} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = over^ start_ARG italic_y end_ARG  or using the initial label certainty score   0 = r ( 0 ) subscript italic- 0 superscript r 0 \\phi_{0}=r^{(0)} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_r start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT  as a softer version.",
            "See  Section   B.5  for a derivation. The convergence behavior of this scheme to a unit distribution is visualized in  Figure   5 . Using the above update rule and the uncertainty estimation, we can compute the label correctness term for  r = E  [ p Q  ( y = 1 | c ) ] r E delimited-[] subscript p Q y conditional 1 c r=\\mathbb{E}\\left[p_{\\mathcal{Q}}(y=1|{\\bm{c}})\\right] italic_r = blackboard_E [ italic_p start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT ( italic_y = 1 | bold_italic_c ) ]",
            "We set the number of evidences used per claim which determines size of the synthetic dataset according to the different datasets as given in  Table   5 . Setting our chosen values results in the synthetic dataset being between 1.3-times and 2 times as large as the original dataset based on the oberservations in  Section   D.5 , suggesting that this is the optimal range."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Tuned hyperparameters.  Bold  parameters were fixed for the runs, while the remainder was tuned using the hyperparameter optimizer.",
        "table": "A3.T6.2",
        "footnotes": [],
        "references": [
            "Selection from Several Augmentation Routines.  We report the effect of single versus several augmentations in  Figure   6(a)  and  Figure   6(b)  in  Section   D.2 , quantitatively and qualitatively demonstrating that Auto-GDA succeeds to the most promising samples from different augmentations.",
            "where  Z > 0 Z 0 Z>0 italic_Z > 0  is a normalization constant. We show that a finite  Z Z Z italic_Z  always exists in the  Section   B.6 . The constant   q > 0 subscript  q 0 \\sigma_{q}>0 italic_ start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT > 0  will be treated as a hyperparameter in our framework. Let  Q  X Q X \\mathcal{Q}\\subset\\mathcal{X} caligraphic_Q  caligraphic_X  denote a finite set of selected samples. For  p  subscript p  p_{\\theta} italic_p start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT , we chose a standard kernel density estimator with kernel width   r  0 subscript  r 0 \\sigma_{r}\\geq 0 italic_ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT  0 :",
            "Optimized Hyperparameters.  As outlined in the main text, we apply  optuna  for 50 configuration trial as an hyperparameter optimizer to find the remaining hyperparameters. We set the ranges   u  [ 0.1 , 100 ] ,  u  [ 0.01 , 5000 ] formulae-sequence subscript  u 0.1 100 subscript  u 0.01 5000 \\lambda_{u}\\in[0.1,100],\\lambda_{u}\\in[0.01,5000] italic_ start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT  [ 0.1 , 100 ] , italic_ start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT  [ 0.01 , 5000 ]  and let the augmentation teacher model be selected from {vectara, alignscore, deberta}. We dont allow LLMs as teacher models for augmentations because it would be too expensive as a lot of augmented samples are created in the course of the algorithm. The final hyperparameters found through optimization are given in  Table   6 .",
            "Using one vs. several augmentation routines.  A key design goal of our algorithm was the ability to automatically select the most promising augmented samples. We investigate the effect of using only single or several augmentations in  Figure   6(a) . The results highlight that the Partial Rephrasing augmentation with LLMs as well as the sentence deletion augmentation seems to be most successful. The Complete Paraphrasing augmentation leads to substantially lower data quality on its own. However, the best utility is achieved when all three augmentations are combined. We study the origin of the samples eventually selected by our algorithm and find that the usefulness of the augmentations on their own is reflected by the share samples selected from each of the augmentations as depicted in  Figure   6(b) . Together, this highlights that Auto-GDA succeeds in selecting the most promising samples generated from the augmentations automatically."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Performance comparison to baselines (uncalibrated balanced accuracy). In this metrics, our models even outperform LLM baselines.",
        "table": "A4.T7.30.30",
        "footnotes": [],
        "references": [
            "We chose the Area under Curve for Receiver-Operator-Characteristic (AUC-ROC) as our main metric, as it is less dependent on threshold calibration and also works for imbalanced datasets. We report our results in other metrics such as balanced accuracy without threshold calibration (using 0.5. as a threshold as suggested in  Tang et al. ( 2024 ) ) in  Table   7  and F1-Scores in  Table   8 . The results highlight not only that our main results are valid across different metrics  in uncalibrated balanced accuracy, our models trained with Auto-GDA data even outperform LLMs by an average 3.4 accuracy percent points.",
            "Estimating the mislabeling probability.   An integral part of our algorithm in the estimation of the agreement probability in  Equation   44 . To investigate the effect of implementing this choice, we run an ablation study to better understand how the quality of the agreement probabilities affects the score. We provide results average over 3 runs in  Figure   7(a) . The results indicate that the choice of the model used to estimate  r r r italic_r  the label certainty score has substantial effect on the quality of the results. While the utility (in terms of ROC scores) drops when noise is added, it increases again when high levels of noise are applied. We attribute this behavior to the algorithm neglecting the mutated samples almost entirely when the noise level is too high and mainly selecting the few shot generate samples. As shown in  Table   2   these have fair utility already."
        ]
    },
    "id_table_8": {
        "caption": "Table 8:  Performance comparison to baselines (Binary F1-Scores).",
        "table": "A4.T8.30.30",
        "footnotes": [],
        "references": [
            "We chose the Area under Curve for Receiver-Operator-Characteristic (AUC-ROC) as our main metric, as it is less dependent on threshold calibration and also works for imbalanced datasets. We report our results in other metrics such as balanced accuracy without threshold calibration (using 0.5. as a threshold as suggested in  Tang et al. ( 2024 ) ) in  Table   7  and F1-Scores in  Table   8 . The results highlight not only that our main results are valid across different metrics  in uncalibrated balanced accuracy, our models trained with Auto-GDA data even outperform LLMs by an average 3.4 accuracy percent points.",
            "When choosing the dataset size we used the data size slightly larger that that of the original dataset as an orientation. We experiment with different dataset sizes and learning rates as shown in  Figure   8  When keeping training fixed to one epoch, we find that with higher learning rates, smaller dataset sizes lead to higher performance, and with lower learning rate, more data is required which seems natural. Globally, we observe that a learning rate of  10  5 superscript 10 5 10^{-5} 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT  is near optimal, but the performance is rather insensitive This is based on a prior observation that significant oversampling of the dataset size had seemingly little effect."
        ]
    },
    "id_table_9": {
        "caption": "Table 9:  Using different teacher models in Auto-GDA to fine-tune DeBERTaV2. In the upper part we add best results from  Table   1  for comparison. In the center part, we highlight that using GPT-4o as a teacher model to assign intial probabilities does not yield substantial improvement. However the lower part shows that it is possible to do self-improvement using only DeBERTa as teacher model for both initial scores and augmentation scoring.",
        "table": "A4.F6.sf1.1.1",
        "footnotes": [],
        "references": [
            "Other Teacher Models.  We investigate using LLMs and other teacher models in  Table   9  (Appendix) but observe that LLMs do not generally outperform other teacher models, possibly due to unreliable uncertainty scores. However, the table also shows that the DeBERTa model can improve its own performance through self-supervision by an average of 0.15 AUC when applied as the teacher model.",
            "We investigate the application of different teacher models in  Table   9 . Our results indicate the learning from GPT models works in general, but does not results in better performance that using the best non-LLM teacher. We additionall study self-improvement, using DeBERTa as both a teacher model for initial scoring and augmentation scoring. This shows that improvements thought self-supervision are possible.",
            "This appendix presents a comparative analysis of THE UDA methods and their impact on the fine-tuning performance of our model. Figure  9  shows the ROC-AUC scores for different UDA methods as we increase the percentage of target domain data used for fine-tuning.  We see two things: i) No configuration of the UDA methods improves the models performance significantly, and ii) the robustly trained models also do not benefit from faster finetuning with fewer samples, as their performance when further finetuned with target-data samples is similar to the original model after finetuned on the same splits. In short, we believe that traditional UDA methods do not show promise for the NLI task."
        ]
    },
    "id_table_10": {
        "caption": "Table 10:  Comparing our approach to the naive baseline of pseudo-labeling the training data and fine-tuning the DeBERTa V2 model on the pseudo-labeled data.",
        "table": "A4.T9.12.12",
        "footnotes": [],
        "references": [
            "Label Correctness Term.  We model the uncertainty propagation as in  Equation   10 . Approaching   r  0  subscript  r 0 \\sigma_{r}\\rightarrow 0 italic_ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT  0 , we have",
            "We compare our results to model trained on pseudo-labels in for the original datasets in  Table   10 . The results inicate that this is a surprisingly strong baseline, which is however surpassed by Auto-GDA in 3 out of 4 cases."
        ]
    },
    "id_table_11": {
        "caption": "Table 11:  Direct comparision of improvements",
        "table": "A4.T10.4.4",
        "footnotes": [],
        "references": []
    },
    "id_table_12": {
        "caption": "Table 12:  fine-tuning on validation set.",
        "table": "A4.T11.12.12",
        "footnotes": [],
        "references": [
            "Results when the models are fine-tuned on the validations set directly are shown in  Table   12 ."
        ]
    },
    "id_table_13": {
        "caption": "Table 13:  ROC-AUC scores for different UDA methods and synthetic data approaches.",
        "table": "A4.T12.1.1",
        "footnotes": [],
        "references": [
            "Table  13  compares the performance (ROC-AUC scores) of various Unsupervised Domain Adaptation (UDA) methods and synthetic data approaches across different source datasets. All results are evaluated on the RAGTRUTH target dataset, using a DeBERTaV3 model trained on the PAWS, VitaminC, and Fever data.  The table illustrates the effectiveness of different UDA methods and synthetic data approaches when applied to various source datasets (MNLI, Summedits, and Ragtruth-synth). More specifically, we see that except for the synthetically generated version of RAGTruth, the choice of the source domain data does not seem to alter results significantly. We also see that vanilla finetuning on the synthetic RAGTruth data outperforms all other variations, indicating that synthetic data is more appropraite for NLI than traditional UDA methods. This is perhaps due to the fact that very small changes in the generated claim can flip the label from entailed to non-entailed and vice-versa."
        ]
    },
    "id_table_14": {
        "caption": "",
        "table": "A4.T13.1",
        "footnotes": [],
        "references": []
    },
    "global_footnotes": [
        "Work done while interning at AWS AI Labs.",
        "we now assume",
        "to be in a metric space. This can be achieved using an encoder mapping the textual input to real vectors."
    ]
}