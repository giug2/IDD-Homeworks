{
    "PAPER'S NUMBER OF TABLES": 8,
    "S4.T1": {
        "caption": "Table 1: Different combinations for the original and hijacking datasets used in FL training phase.",
        "table": "<table id=\"S4.T1.5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T1.5.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.5.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"S4.T1.5.1.1.1.1\" class=\"ltx_text\">TaskSet</span></td>\n<td id=\"S4.T1.5.1.1.2\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_tt\"><span id=\"S4.T1.5.1.1.2.1\" class=\"ltx_text\">Original Dataset</span></td>\n<td id=\"S4.T1.5.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"S4.T1.5.1.1.3.1\" class=\"ltx_text\">Hijacking Dataset</span></td>\n<td id=\"S4.T1.5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S4.T1.5.1.1.4.1\" class=\"ltx_text\">Dataset Size</span></td>\n</tr>\n<tr id=\"S4.T1.5.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.5.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">I</td>\n<td id=\"S4.T1.5.1.2.2\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">CIFAR-10 (10)</td>\n<td id=\"S4.T1.5.1.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">MNIST (9)</td>\n<td id=\"S4.T1.5.1.2.4\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">60000</td>\n<td id=\"S4.T1.5.1.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">54000</td>\n</tr>\n<tr id=\"S4.T1.5.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.5.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">II</td>\n<td id=\"S4.T1.5.1.3.2\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">CIFAR-10 (10)</td>\n<td id=\"S4.T1.5.1.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">GTSRB (9)</td>\n<td id=\"S4.T1.5.1.3.4\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">60000</td>\n<td id=\"S4.T1.5.1.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\">15120</td>\n</tr>\n<tr id=\"S4.T1.5.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.5.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">III</td>\n<td id=\"S4.T1.5.1.4.2\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">TinyImageNet-100 (100)</td>\n<td id=\"S4.T1.5.1.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">MNIST (10)</td>\n<td id=\"S4.T1.5.1.4.4\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">50000</td>\n<td id=\"S4.T1.5.1.4.5\" class=\"ltx_td ltx_align_left ltx_border_t\">60000</td>\n</tr>\n<tr id=\"S4.T1.5.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.5.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">IV</td>\n<td id=\"S4.T1.5.1.5.2\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_rr ltx_border_t\">TinyImageNet-100 (100)</td>\n<td id=\"S4.T1.5.1.5.3\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">GTSRB (10)</td>\n<td id=\"S4.T1.5.1.5.4\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_rr ltx_border_t\">50000</td>\n<td id=\"S4.T1.5.1.5.5\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">16110</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We detail the concrete settings from two aspects: global settings and local settings.",
                "Global Settings.",
                " Following prior work¬†",
                "[",
                "7",
                "]",
                ", we set the number of training rounds to 200, and the total number of clients contributing to the global model is ",
                "n",
                "=",
                "50",
                "ùëõ",
                "50",
                "n=50",
                ".\nIn each round, the central server selects ",
                "m",
                "=",
                "5",
                "ùëö",
                "5",
                "m=5",
                " clients, and each client is chosen with equal probability, ensuring that all 50 clients have been involved in one round after 10 training rounds.\nFurthermore, the central server averages the received updates from the selected 5 clients in each training round.\nThe global learning rate is set to ",
                "Œ∑",
                "=",
                "10",
                "ùúÇ",
                "10",
                "\\eta=10",
                ".",
                "Local Settings.",
                " Each client controls a same-sized subset of the full original dataset, e.g., one client controls 2000 samples of the TinyImageNet-100 dataset locally.\nIn each round, all the selected clients train the local model using the same training settings, i.e., an optimizer of SGD¬†",
                "[",
                "9",
                "]",
                ", a learning rate of 0.1, and a local training epoch of 2."
            ]
        ]
    },
    "S4.T2": {
        "caption": "Table 2: The size of original and hijacking datasets used in FL prediction/testing phase.",
        "table": "<table id=\"S4.T2.5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T2.5.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"S4.T2.5.1.1.1.1\" class=\"ltx_text\">TaskSet</span></td>\n<td id=\"S4.T2.5.1.1.2\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_tt\"><span id=\"S4.T2.5.1.1.2.1\" class=\"ltx_text\">Original Dataset</span></td>\n<td id=\"S4.T2.5.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"S4.T2.5.1.1.3.1\" class=\"ltx_text\">Hijacking Dataset</span></td>\n<td id=\"S4.T2.5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S4.T2.5.1.1.4.1\" class=\"ltx_text\">Dataset Size</span></td>\n</tr>\n<tr id=\"S4.T2.5.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">I</td>\n<td id=\"S4.T2.5.1.2.2\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">CIFAR-10 (10)</td>\n<td id=\"S4.T2.5.1.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">MNIST (9)</td>\n<td id=\"S4.T2.5.1.2.4\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">10000</td>\n<td id=\"S4.T2.5.1.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">9000</td>\n</tr>\n<tr id=\"S4.T2.5.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">II</td>\n<td id=\"S4.T2.5.1.3.2\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">CIFAR-10 (10)</td>\n<td id=\"S4.T2.5.1.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">GTSRB (9)</td>\n<td id=\"S4.T2.5.1.3.4\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">10000</td>\n<td id=\"S4.T2.5.1.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\">4320</td>\n</tr>\n<tr id=\"S4.T2.5.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">III</td>\n<td id=\"S4.T2.5.1.4.2\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">TinyImageNet-100 (100)</td>\n<td id=\"S4.T2.5.1.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">MNIST (10)</td>\n<td id=\"S4.T2.5.1.4.4\" class=\"ltx_td ltx_align_right ltx_border_rr ltx_border_t\">10000</td>\n<td id=\"S4.T2.5.1.4.5\" class=\"ltx_td ltx_align_left ltx_border_t\">10000</td>\n</tr>\n<tr id=\"S4.T2.5.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">IV</td>\n<td id=\"S4.T2.5.1.5.2\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_rr ltx_border_t\">TinyImageNet-100 (100)</td>\n<td id=\"S4.T2.5.1.5.3\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">GTSRB (10)</td>\n<td id=\"S4.T2.5.1.5.4\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_rr ltx_border_t\">10000</td>\n<td id=\"S4.T2.5.1.5.5\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">4800</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We detail the concrete settings from two aspects: global settings and local settings.",
                "Global Settings.",
                " Following prior work¬†",
                "[",
                "7",
                "]",
                ", we set the number of training rounds to 200, and the total number of clients contributing to the global model is ",
                "n",
                "=",
                "50",
                "ùëõ",
                "50",
                "n=50",
                ".\nIn each round, the central server selects ",
                "m",
                "=",
                "5",
                "ùëö",
                "5",
                "m=5",
                " clients, and each client is chosen with equal probability, ensuring that all 50 clients have been involved in one round after 10 training rounds.\nFurthermore, the central server averages the received updates from the selected 5 clients in each training round.\nThe global learning rate is set to ",
                "Œ∑",
                "=",
                "10",
                "ùúÇ",
                "10",
                "\\eta=10",
                ".",
                "Local Settings.",
                " Each client controls a same-sized subset of the full original dataset, e.g., one client controls 2000 samples of the TinyImageNet-100 dataset locally.\nIn each round, all the selected clients train the local model using the same training settings, i.e., an optimizer of SGD¬†",
                "[",
                "9",
                "]",
                ", a learning rate of 0.1, and a local training epoch of 2."
            ]
        ]
    },
    "S4.T3": {
        "caption": "Table 3: The utility of the clean global models and the hijacked global models on the clean test set.",
        "table": "<table id=\"S4.T3.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T3.4.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">Model</td>\n<td id=\"S4.T3.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T3.4.1.1.2.1\" class=\"ltx_text\">TaskSet</span></td>\n<td id=\"S4.T3.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Clean</td>\n<td id=\"S4.T3.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"background-color:#E6E6E6;\" colspan=\"5\"><span id=\"S4.T3.4.1.1.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Hijacked Global Model</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Architecture</td>\n<td id=\"S4.T3.4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Model</td>\n<td id=\"S4.T3.4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.2.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Data Poison (naive)</span></td>\n<td id=\"S4.T3.4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.2.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Data Poison (transform)</span></td>\n<td id=\"S4.T3.4.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.2.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Model Poison (naive)</span></td>\n<td id=\"S4.T3.4.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.2.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Model Poison (transform)</span></td>\n<td id=\"S4.T3.4.1.2.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.2.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Ours</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.T3.4.1.3.1.1\" class=\"ltx_text\">ResNet-18</span></td>\n<td id=\"S4.T3.4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">I</td>\n<td id=\"S4.T3.4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8803</td>\n<td id=\"S4.T3.4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.3.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8822</span></td>\n<td id=\"S4.T3.4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.3.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8639</span></td>\n<td id=\"S4.T3.4.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.3.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8639</span></td>\n<td id=\"S4.T3.4.1.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.3.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8774</span></td>\n<td id=\"S4.T3.4.1.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.3.8.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8803</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">II</td>\n<td id=\"S4.T3.4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.8803</td>\n<td id=\"S4.T3.4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.4.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8803</span></td>\n<td id=\"S4.T3.4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.4.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8713</span></td>\n<td id=\"S4.T3.4.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.4.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8809</span></td>\n<td id=\"S4.T3.4.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.4.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8483</span></td>\n<td id=\"S4.T3.4.1.4.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.4.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8803</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">III</td>\n<td id=\"S4.T3.4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.5460</td>\n<td id=\"S4.T3.4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.5.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5362</span></td>\n<td id=\"S4.T3.4.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.5.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5390</span></td>\n<td id=\"S4.T3.4.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.5.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5456</span></td>\n<td id=\"S4.T3.4.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.5.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.3806</span></td>\n<td id=\"S4.T3.4.1.5.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.5.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5460</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">IV</td>\n<td id=\"S4.T3.4.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.5460</td>\n<td id=\"S4.T3.4.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.6.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5344</span></td>\n<td id=\"S4.T3.4.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.6.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5328</span></td>\n<td id=\"S4.T3.4.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.6.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5436</span></td>\n<td id=\"S4.T3.4.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.6.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.3102</span></td>\n<td id=\"S4.T3.4.1.6.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.6.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5460</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.T3.4.1.7.1.1\" class=\"ltx_text\">MobileNet-V2</span></td>\n<td id=\"S4.T3.4.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">I</td>\n<td id=\"S4.T3.4.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8592</td>\n<td id=\"S4.T3.4.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.7.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8459</span></td>\n<td id=\"S4.T3.4.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.7.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8041</span></td>\n<td id=\"S4.T3.4.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.7.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8554</span></td>\n<td id=\"S4.T3.4.1.7.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.7.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.7466</span></td>\n<td id=\"S4.T3.4.1.7.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.7.8.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8592</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\">II</td>\n<td id=\"S4.T3.4.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.8592</td>\n<td id=\"S4.T3.4.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.8.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8597</span></td>\n<td id=\"S4.T3.4.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.8.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8247</span></td>\n<td id=\"S4.T3.4.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.8.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8529</span></td>\n<td id=\"S4.T3.4.1.8.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.8.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8121</span></td>\n<td id=\"S4.T3.4.1.8.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.8.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8592</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.9\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">III</td>\n<td id=\"S4.T3.4.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.4472</td>\n<td id=\"S4.T3.4.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.9.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.4592</span></td>\n<td id=\"S4.T3.4.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.9.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.3884</span></td>\n<td id=\"S4.T3.4.1.9.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.9.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.4350</span></td>\n<td id=\"S4.T3.4.1.9.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.9.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.2994</span></td>\n<td id=\"S4.T3.4.1.9.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.9.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.4472</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.10\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_r\">IV</td>\n<td id=\"S4.T3.4.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.4472</td>\n<td id=\"S4.T3.4.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.10.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.4598</span></td>\n<td id=\"S4.T3.4.1.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.10.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.4218</span></td>\n<td id=\"S4.T3.4.1.10.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.10.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.4564</span></td>\n<td id=\"S4.T3.4.1.10.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.10.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.2564</span></td>\n<td id=\"S4.T3.4.1.10.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.10.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.4472</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.11\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.11.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S4.T3.4.1.11.1.1\" class=\"ltx_text\">ShuffleNet-V2</span></td>\n<td id=\"S4.T3.4.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">I</td>\n<td id=\"S4.T3.4.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8705</td>\n<td id=\"S4.T3.4.1.11.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.11.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8716</span></td>\n<td id=\"S4.T3.4.1.11.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.11.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8489</span></td>\n<td id=\"S4.T3.4.1.11.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.11.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8674</span></td>\n<td id=\"S4.T3.4.1.11.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.11.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8174</span></td>\n<td id=\"S4.T3.4.1.11.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.11.8.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8746</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.12\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.12.1\" class=\"ltx_td ltx_align_center ltx_border_r\">II</td>\n<td id=\"S4.T3.4.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.8746</td>\n<td id=\"S4.T3.4.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.12.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8726</span></td>\n<td id=\"S4.T3.4.1.12.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.12.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8765</span></td>\n<td id=\"S4.T3.4.1.12.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.12.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8730</span></td>\n<td id=\"S4.T3.4.1.12.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.12.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8438</span></td>\n<td id=\"S4.T3.4.1.12.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.12.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.8746</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.13\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.13.1\" class=\"ltx_td ltx_align_center ltx_border_r\">III</td>\n<td id=\"S4.T3.4.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.5178</td>\n<td id=\"S4.T3.4.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.13.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5188</span></td>\n<td id=\"S4.T3.4.1.13.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.13.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.4822</span></td>\n<td id=\"S4.T3.4.1.13.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.13.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5150</span></td>\n<td id=\"S4.T3.4.1.13.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.13.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.3334</span></td>\n<td id=\"S4.T3.4.1.13.7\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.13.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5178</span></td>\n</tr>\n<tr id=\"S4.T3.4.1.14\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.14.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">IV</td>\n<td id=\"S4.T3.4.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">0.5178</td>\n<td id=\"S4.T3.4.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.14.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5132</span></td>\n<td id=\"S4.T3.4.1.14.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.14.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5028</span></td>\n<td id=\"S4.T3.4.1.14.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.14.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5252</span></td>\n<td id=\"S4.T3.4.1.14.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.14.6.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.3752</span></td>\n<td id=\"S4.T3.4.1.14.7\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T3.4.1.14.7.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">0.5178</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Existing model hijacking attacks¬†",
                "[",
                "28",
                ", ",
                "32",
                "]",
                " aim to hijack centralized ML models to perform different tasks.\nThe core idea of existing work is to utilize data poisoning to achieve the goal of hijacking.\nWe generalize this data poisoning approach to the federated learning setting as a baseline attack.\nIn addition, we consider adapting the data poisoning approach to model poisoning based on the idea of backdooring the FL model proposed by Bagdasaryan et al.¬†",
                "[",
                "7",
                "]",
                ".",
                "Data Poisoning.",
                "\nThe adversary can poison the training dataset, achieving the goal of hijacking when the model is trained on this poisoned data.\nSalem et al.¬†",
                "[",
                "28",
                "]",
                " and Si et al.¬†",
                "[",
                "32",
                "]",
                " employ this method.\nSpecifically, Salem et al.¬†",
                "[",
                "28",
                "]",
                " introduce two attack methods.\nThe first involves mixing the original dataset with the hijacking dataset and then using this poisoned dataset to train the target model.\nThis achieves the upper bound on attack performance yet causes a drawback: it can be easily detected by the model owner since samples in the original and the hijacking datasets can be significantly different.\nThus, Salem et al.¬†",
                "[",
                "28",
                "]",
                " introduce an additional model to transform the hijacking dataset into one that is visually similar to the original dataset, which is then mixed with the original dataset to train the target model.\nSi et al.¬†",
                "[",
                "32",
                "]",
                " adopt a similar approach by using an additional model to transform the hijacking dataset.\nIn this study, we apply both of these methods to the FL scenario, called ",
                "Data Poison (naive)",
                " and ",
                "Data Poison (transform)",
                ".\nWe emphasize that both methods are essentially data poisoning attacks aimed at altering the target model‚Äôs parameters, while our attack avoids such modifications.",
                "Model Poisoning.",
                " Model poisoning (also called model replacement) is first proposed in backdooring FL models by Bagdasaryan et al.¬†",
                "[",
                "7",
                "]",
                ".\nThis approach exploits the fact that federated learning gives malicious clients direct influence over the global model, enabling significantly more powerful attacks than data poisoning.\nSpecially, the adversary can substitute the new global model ",
                "G",
                "t",
                "+",
                "1",
                "subscript",
                "ùê∫",
                "ùë°",
                "1",
                "G_{t+1}",
                " with a malicious model ",
                "X",
                "ùëã",
                "X",
                " in ",
                "Equation¬†1",
                ":",
                "As the global model converges, these deviations start to cancel out, i.e., ",
                "‚àë",
                "i",
                "=",
                "1",
                "m",
                "‚àí",
                "1",
                "(",
                "F",
                "i",
                "t",
                "+",
                "1",
                "‚àí",
                "G",
                "t",
                ")",
                "‚âà",
                "0",
                "superscript",
                "subscript",
                "ùëñ",
                "1",
                "ùëö",
                "1",
                "superscript",
                "subscript",
                "ùêπ",
                "ùëñ",
                "ùë°",
                "1",
                "superscript",
                "ùê∫",
                "ùë°",
                "0",
                "\\sum_{i=1}^{m-1}\\left(F_{i}^{t+1}-G^{t}\\right)\\approx 0",
                ".\nThus, the adversary can submit the model update as follows:",
                "This adversary scales up the weights of the malicious model ",
                "X",
                "ùëã",
                "X",
                " by ",
                "Œ≥",
                "=",
                "n",
                "Œ∑",
                "ùõæ",
                "ùëõ",
                "ùúÇ",
                "\\gamma=\\frac{n}{\\eta}",
                " to ensure that the backdoor survives the averaging and the global model is replaced by ",
                "X",
                "ùëã",
                "X",
                ".\nIn this work, we adapt the two aforementioned data poisoning methods to model poisoning, called ",
                "Model Poison (naive)",
                " and ",
                "Model Poison (transform)",
                ".\nSpecifically, we scale up the adversary‚Äôs submitted model parameters to survive the averaging.\nWe make a strong assumption for the adversary that they know the exact FL settings, i.e., ",
                "n",
                "=",
                "50",
                "ùëõ",
                "50",
                "n=50",
                " and ",
                "Œ∑",
                "=",
                "10",
                "ùúÇ",
                "10",
                "\\eta=10",
                ".\nThus, we set the scale-up parameter ",
                "Œ≥",
                "=",
                "n",
                "Œ∑",
                "=",
                "5",
                "ùõæ",
                "ùëõ",
                "ùúÇ",
                "5",
                "\\gamma=\\frac{n}{\\eta}=5",
                "."
            ]
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Comparison between HijackFL that uses only one cloak for the entire hijacking dataset and HijackFL that employs one cloak for each hijacking class (i.e., multi cloaks).",
        "table": "<table id=\"S5.T4.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T4.4.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T4.4.1.1.1.1\" class=\"ltx_text\">TaskSet</span></td>\n<td id=\"S5.T4.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">ResNet-18</td>\n<td id=\"S5.T4.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\">MobileNet-V2</td>\n</tr>\n<tr id=\"S5.T4.4.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">One Cloak</td>\n<td id=\"S5.T4.4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Multi Cloak</td>\n<td id=\"S5.T4.4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">One Cloak</td>\n<td id=\"S5.T4.4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Multi Cloak</td>\n</tr>\n<tr id=\"S5.T4.4.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.4.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">I</td>\n<td id=\"S5.T4.4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1246</td>\n<td id=\"S5.T4.4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9275</td>\n<td id=\"S5.T4.4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1246</td>\n<td id=\"S5.T4.4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.5903</td>\n</tr>\n<tr id=\"S5.T4.4.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.4.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">II</td>\n<td id=\"S5.T4.4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1200</td>\n<td id=\"S5.T4.4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.7545</td>\n<td id=\"S5.T4.4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1200</td>\n<td id=\"S5.T4.4.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.5060</td>\n</tr>\n<tr id=\"S5.T4.4.1.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.4.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">III</td>\n<td id=\"S5.T4.4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1135</td>\n<td id=\"S5.T4.4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.7984</td>\n<td id=\"S5.T4.4.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1135</td>\n<td id=\"S5.T4.4.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.6156</td>\n</tr>\n<tr id=\"S5.T4.4.1.6\" class=\"ltx_tr\">\n<td id=\"S5.T4.4.1.6.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">IV</td>\n<td id=\"S5.T4.4.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.1111</td>\n<td id=\"S5.T4.4.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.6733</td>\n<td id=\"S5.T4.4.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.1111</td>\n<td id=\"S5.T4.4.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.5808</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Hijacking Round.",
                " We now explore the impact of the hijacking round, denoting the FL training round where the adversary starts cloak computation.\nIn the above evaluations, we default the adversary to start cloak computation at the ",
                "150",
                "150",
                "150",
                "th training round.\nHowever, in real-world scenarios, the adversary may not have control over their participation round, as the central server might follow specific protocols, such as randomly selecting clients.\nHence, it is essential to investigate how the hijacking round impacts our HijackFL.",
                "Specifically, within the span of 200 FL training rounds, we configure the adversary to start cloak computation at the ",
                "10",
                "10",
                "10",
                "th, ",
                "50",
                "50",
                "50",
                "th, ",
                "80",
                "80",
                "80",
                "th, ",
                "100",
                "100",
                "100",
                "th, and ",
                "150",
                "150",
                "150",
                "th training rounds, respectively.\nTo clarify, for instance, the adversary starts cloak computation only once at the ",
                "80",
                "80",
                "80",
                "th round and evaluates the attack on the ultimate global model trained over the entire 200 rounds.\nSubsequently, we evaluate the efficacy of the obtained cloaks by launching attacks on the final global model.\nAs depicted in ",
                "Figure¬†11",
                ", a clear trend emerges, indicating a positive correlation between the attack performance of HijackFL and the hijacking round.\nIn other words, initiating cloak computation later in the adversarial process results in higher attack performance.",
                "The underlying reason is that after the hijacking round, the global model undergoes further aggregation based on the submitted model updates in subsequent training rounds. This implies that the final global model differs from the one on which the adversary starts cloak computation. Such disparities impact the transferability of the cloaks. Starting cloak computation closer to the final training rounds, where the global model experiences minimal updates, allows the cloaked samples to be extracted to features similar to the original samples, resulting in a higher level of attack success rate.\nIn practical applications, the adversary can leverage its own original dataset to estimate the global model‚Äôs convergence status.\nThe adversary should initiate cloak computation when the global model has either converged or is close to convergence.",
                "Complexity of Hijacking Task.",
                "\nWe here study the impact of hijacking task complexity.\nSpecifically, we consider the hijacking task complexity from two perspectives: the number of classes and the number of samples per class. More concretely, for the original dataset TinyImageNet-100 and the hijacking dataset GTSRB, we reconstruct the GTSRB dataset by adjusting the number of classes from 2 to 10. Additionally, we vary the number of GTSRB samples per class within the range of 200 to 1000.\nWe conduct extensive experiments to simultaneously tune these two hyper-parameters and report the results in ",
                "Figure¬†12",
                ".\nThrough investigation, we make the following observations.",
                "The attack performance tends to increase with the number of samples per class.",
                "The attack performance initially increases with the number of classes and then decreases, peaking around 6 or 8 classes.",
                "The first observation is rooted in the fact that having more hijacking samples per class results in the learning of a more effective, general, and stable cloak, consequently leading to a higher attack performance.\nConcerning the second observation, we speculate that it is linked to intricate interactions between the global model architectures and the complexity of the original task.\nWe leave the in-depth exploration of such intricate interactions as a future work.",
                "Number of Hijacking Task.",
                "\nWe now discuss the impact of the number of hijacking tasks, which involves hijacking the global model with multiple datasets. Importantly, owing to our innovative design, HijackFL distinguishes itself by not interacting with the global model‚Äôs parameters, in contrast to the baseline attacks of data poison and model poison. Consequently, the adversary can initiate cloak computation based on the same global model, irrespective of the number of hijacking datasets. This approach enables the adversary to possess distinct sets of cloaks for different hijacking datasets, offering flexibility when launching attacks on the final global model as they can select the suitable set of cloaks.",
                "In contrast, it is expected that the baseline attacks of data poison and model poison will be influenced by the number of hijacking tasks. More hijacking datasets are likely to result in submitted model updates deviating further from a clean one, thereby causing a larger utility drop in the global model.",
                "Balance Parameter ",
                "Œ±",
                "ùõº",
                "\\alpha",
                ".",
                "\nRecall that we employ a convex combination of the hijacking samples and the cloak: ",
                "x",
                "h",
                "‚äï",
                "Œ¥",
                "h",
                "=",
                "Œ±",
                "‚Äã",
                "x",
                "h",
                "+",
                "(",
                "1",
                "‚àí",
                "Œ±",
                ")",
                "‚Äã",
                "Œ¥",
                "h",
                "direct-sum",
                "subscript",
                "ùë•",
                "‚Ñé",
                "subscript",
                "ùõø",
                "‚Ñé",
                "ùõº",
                "subscript",
                "ùë•",
                "‚Ñé",
                "1",
                "ùõº",
                "subscript",
                "ùõø",
                "‚Ñé",
                "{x_{h}}\\oplus\\delta_{h}=\\alpha{x_{h}}+(1-\\alpha)\\delta_{h}",
                ". In this expression, the parameter ",
                "Œ±",
                "‚àà",
                "[",
                "0",
                ",",
                "1",
                "]",
                "ùõº",
                "0",
                "1",
                "\\alpha\\in[0,1]",
                " governs the balance between the weight or influence of ",
                "x",
                "h",
                "subscript",
                "ùë•",
                "‚Ñé",
                "x_{h}",
                " and ",
                "Œ¥",
                "h",
                "subscript",
                "ùõø",
                "‚Ñé",
                "\\delta_{h}",
                " on the cloaked samples. In this section, we investigate the impact of ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " on the attack performance. Note that we use a default value of 0.5 for ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " in the evaluations presented above.",
                "Specifically, we vary the parameter ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " from 0 to 1 and present the results in ",
                "Figure¬†13",
                ". We clearly observe a trend where the attack performance initially increases and then decreases in most cases. The peak attack performance is attained when ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " falls within the range of 0.5 to 0.7.\nThis observation motivates the adversary to either carefully select the optimal ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " or simply use a value within the range of 0.5 to 0.7.",
                "Number of Cloak.",
                " In our previous evaluations, we employ a single generalized cloak for all hijacking samples within the same class.\nIn this section, we explore the impact of the number of cloaks on attack performance.\nIn particular, we generate only one cloak for all hijacking samples, irrespective of their respective hijacking classes.\n",
                "Table¬†4",
                " shows evaluation results on ResNet-18 and MobileNet-V2 with all TaskSets.\nWe can clearly observe that employing just one cloak for the entire hijacking classes fails to effectively achieve the hijacking goal.\nThis outcome is understandable, as it becomes considerably more challenging for a single cloak to establish class mappings from various hijacking classes to various original classes compared to the simpler task of mapping one hijacking class to one original class.",
                "We further consider the feasibility of generating a specific cloak for each hijacking sample.\nWe assert that this approach is impractical for several reasons.\nFirstly, optimizing a cloak for each individual sample limits its effectiveness to that sample alone, rendering it ineffective for new, unseen hijacking instances.\nMoreover, in hijacking datasets with numerous samples, generating a unique cloak for each becomes unwieldy for the adversary, making selection for new samples challenging.\nThus, adversaries should optimize cloaks based on a data domain (e.g., hijacking samples within the same class) with the aim of achieving generalizability."
            ]
        ]
    },
    "S6.T5": {
        "caption": "Table 5: The attack success rate of HijackFL against the feature-based anomaly defense.",
        "table": "<table id=\"S6.T5.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T5.4.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T5.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S6.T5.4.1.1.1.1\" class=\"ltx_text\">TaskSet</span></td>\n<td id=\"S6.T5.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">ResNet-18</td>\n<td id=\"S6.T5.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\">MobileNet-V2</td>\n</tr>\n<tr id=\"S6.T5.4.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No Defense</td>\n<td id=\"S6.T5.4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Defense</td>\n<td id=\"S6.T5.4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No Defense</td>\n<td id=\"S6.T5.4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Defense</td>\n</tr>\n<tr id=\"S6.T5.4.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T5.4.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">I</td>\n<td id=\"S6.T5.4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9275</td>\n<td id=\"S6.T5.4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1164</td>\n<td id=\"S6.T5.4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.5903</td>\n<td id=\"S6.T5.4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1150</td>\n</tr>\n<tr id=\"S6.T5.4.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T5.4.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">II</td>\n<td id=\"S6.T5.4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.7545</td>\n<td id=\"S6.T5.4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1158</td>\n<td id=\"S6.T5.4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.5060</td>\n<td id=\"S6.T5.4.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1108</td>\n</tr>\n<tr id=\"S6.T5.4.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T5.4.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">III</td>\n<td id=\"S6.T5.4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.7984</td>\n<td id=\"S6.T5.4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1073</td>\n<td id=\"S6.T5.4.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.6156</td>\n<td id=\"S6.T5.4.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1009</td>\n</tr>\n<tr id=\"S6.T5.4.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T5.4.1.6.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">IV</td>\n<td id=\"S6.T5.4.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.6733</td>\n<td id=\"S6.T5.4.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.1041</td>\n<td id=\"S6.T5.4.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.5808</td>\n<td id=\"S6.T5.4.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.1088</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Since detecting attacks during the FL training phase is impossible, we explore two defenses in the FL prediction phase: feature-based anomaly detection and adversarial example detection.",
                "Feature-based Anomaly Detection.",
                "\nThe intuition is motivated by HijackFL‚Äôs execution stage: given a hijacking sample for query, the adversary will add all cloaks for it and submit these cloaked samples to the targeted deployed global model.\nAmong these queries, only one cloak will map the given sample to the original class ",
                "y",
                "ùë¶",
                "y",
                ", while all other cloaks will consistently map the given sample to the negative original class ",
                "y",
                "‚àó",
                "superscript",
                "ùë¶",
                "‚àó",
                "y^{\\ast}",
                ".\nAs a result, there will be one cloaked sample with feature significantly further away from the negative anchor feature, compared to the other cloaked samples, as depicted in ",
                "Figure¬†14",
                ".",
                "Building upon the above insight, we propose a feature-based anomaly detection.\nPrecisely, the defense pipeline consists of the following steps:",
                "The model owner first generates a set of anchor features regarding each original class (",
                "Equation¬†5",
                ").",
                "When an adversary queries a set of cloaked samples (i.e., a hijacking sample with different cloaks), the model owner extracts their features.",
                "For each anchor feature, the model owner measures the L2 distance between it and each cloaked sample‚Äôs feature.",
                "If only one cloaked sample‚Äôs feature is much far away from the anchor feature (i.e., L2 distance larger than a threshold, see Appendix ",
                "Table¬†7",
                "), the queried set of samples is considered to serve a hijacking sample.",
                "Table¬†5",
                " reports the attack performance under the feature-based anomaly detection.\nNote that this defense is specifically designed for a set of cloaked samples serving hijacking samples and has no side effects on the utility, so we do not report it.\nWe can see that this defense can substantially mitigate the attack.\nHowever, it‚Äôs important to note that the adversary may not query a set of cloaked samples all at once; instead, they can intelligently query them at different times.\nFurthermore, in the real world, the model is typically queried with mostly original samples, and interspersed among them are some cloaked samples.\nBoth of the above situations present significant challenges for this defense.\nWe leave the in-depth exploration of more effective defense mechanisms against our attack as a future work.",
                "Adversarial Example Defenses.",
                "\nHijackFL adds cloaks to the hijacking samples, similar to adversarial examples that add slight pixel-level perturbations to input samples.\nTherefore, a straightforward defense strategy is utilizing adversarial example defense.\nHere, we employ a widely used adversarial example defense called Feature Squeezing¬†",
                "[",
                "38",
                "]",
                ", which detects adversarial examples at the model prediction phase.\nThis defense is driven by the observation that the input spaces are often unnecessarily large, and this vast input space provides extensive opportunities for an adversary to construct adversarial examples.\nThus, the defender can ‚Äúsqueeze‚Äù out unnecessary input space to reduce the degrees of freedom available to an adversary.\nThe key idea is to compare the model‚Äôs prediction on the input sample with its prediction on the sample after squeezing.\nIf the input sample and squeezed samples produce substantially different outputs from the model, the input sample is likely to be adversarial.\nBy comparing the difference between predictions with a selected threshold, the defender can reject adversarial inputs.",
                "Since this defense also squeezes the original sample, we report the utility of the global model in addition to the attack performance, as shown in ",
                "Table¬†6",
                ".\nIn particular, we examine two thresholds (see Appendix ",
                "Table¬†8",
                "), set significantly lower/higher, to increase sensitivity/insensitivity to input examples with added perturbations, respectively.\nWe find that a smaller threshold (Threshold 1) successfully detects hijacking samples but also yields a high rate of false positives when detecting original samples, resulting in a significant degradation of utility.\nConversely, with a higher threshold (Threshold 2), this defense fails to detect hijacking, leading to HijackFL still outperforming baseline attacks."
            ]
        ]
    },
    "S6.T6": {
        "caption": "Table 6: The defensive performance of adversarial example defense, i.e., Feature Squeezing.",
        "table": "<table id=\"S6.T6.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T6.4.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T6.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" rowspan=\"3\"><span id=\"S6.T6.4.1.1.1.1\" class=\"ltx_text\">TaskSet</span></td>\n<td id=\"S6.T6.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"4\">ResNet-18</td>\n<td id=\"S6.T6.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\">MobileNet-V2</td>\n</tr>\n<tr id=\"S6.T6.4.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T6.4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">Threshold 1</td>\n<td id=\"S6.T6.4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">Threshold 2</td>\n<td id=\"S6.T6.4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">Threshold 1</td>\n<td id=\"S6.T6.4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\">Threshold 2</td>\n</tr>\n<tr id=\"S6.T6.4.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T6.4.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Utility</td>\n<td id=\"S6.T6.4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ASR</td>\n<td id=\"S6.T6.4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Utility</td>\n<td id=\"S6.T6.4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ASR</td>\n<td id=\"S6.T6.4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Utility</td>\n<td id=\"S6.T6.4.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ASR</td>\n<td id=\"S6.T6.4.1.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Utility</td>\n<td id=\"S6.T6.4.1.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">ASR</td>\n</tr>\n<tr id=\"S6.T6.4.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T6.4.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">I</td>\n<td id=\"S6.T6.4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.5736</td>\n<td id=\"S6.T6.4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1223</td>\n<td id=\"S6.T6.4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8641</td>\n<td id=\"S6.T6.4.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8934</td>\n<td id=\"S6.T6.4.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.6126</td>\n<td id=\"S6.T6.4.1.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1397</td>\n<td id=\"S6.T6.4.1.4.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8423</td>\n<td id=\"S6.T6.4.1.4.9\" class=\"ltx_td ltx_align_center ltx_border_t\">0.5304</td>\n</tr>\n<tr id=\"S6.T6.4.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T6.4.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">II</td>\n<td id=\"S6.T6.4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.5776</td>\n<td id=\"S6.T6.4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1267</td>\n<td id=\"S6.T6.4.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8633</td>\n<td id=\"S6.T6.4.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.7128</td>\n<td id=\"S6.T6.4.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.6090</td>\n<td id=\"S6.T6.4.1.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1125</td>\n<td id=\"S6.T6.4.1.5.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8428</td>\n<td id=\"S6.T6.4.1.5.9\" class=\"ltx_td ltx_align_center ltx_border_t\">0.4260</td>\n</tr>\n<tr id=\"S6.T6.4.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T6.4.1.6.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">III</td>\n<td id=\"S6.T6.4.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.2390</td>\n<td id=\"S6.T6.4.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1179</td>\n<td id=\"S6.T6.4.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.4966</td>\n<td id=\"S6.T6.4.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.5771</td>\n<td id=\"S6.T6.4.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.3140</td>\n<td id=\"S6.T6.4.1.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1081</td>\n<td id=\"S6.T6.4.1.6.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.4482</td>\n<td id=\"S6.T6.4.1.6.9\" class=\"ltx_td ltx_align_center ltx_border_t\">0.5417</td>\n</tr>\n<tr id=\"S6.T6.4.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T6.4.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">IV</td>\n<td id=\"S6.T6.4.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.2402</td>\n<td id=\"S6.T6.4.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.1206</td>\n<td id=\"S6.T6.4.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.4966</td>\n<td id=\"S6.T6.4.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.5543</td>\n<td id=\"S6.T6.4.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.3108</td>\n<td id=\"S6.T6.4.1.7.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.0894</td>\n<td id=\"S6.T6.4.1.7.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.4484</td>\n<td id=\"S6.T6.4.1.7.9\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.4452</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Since detecting attacks during the FL training phase is impossible, we explore two defenses in the FL prediction phase: feature-based anomaly detection and adversarial example detection.",
                "Feature-based Anomaly Detection.",
                "\nThe intuition is motivated by HijackFL‚Äôs execution stage: given a hijacking sample for query, the adversary will add all cloaks for it and submit these cloaked samples to the targeted deployed global model.\nAmong these queries, only one cloak will map the given sample to the original class ",
                "y",
                "ùë¶",
                "y",
                ", while all other cloaks will consistently map the given sample to the negative original class ",
                "y",
                "‚àó",
                "superscript",
                "ùë¶",
                "‚àó",
                "y^{\\ast}",
                ".\nAs a result, there will be one cloaked sample with feature significantly further away from the negative anchor feature, compared to the other cloaked samples, as depicted in ",
                "Figure¬†14",
                ".",
                "Building upon the above insight, we propose a feature-based anomaly detection.\nPrecisely, the defense pipeline consists of the following steps:",
                "The model owner first generates a set of anchor features regarding each original class (",
                "Equation¬†5",
                ").",
                "When an adversary queries a set of cloaked samples (i.e., a hijacking sample with different cloaks), the model owner extracts their features.",
                "For each anchor feature, the model owner measures the L2 distance between it and each cloaked sample‚Äôs feature.",
                "If only one cloaked sample‚Äôs feature is much far away from the anchor feature (i.e., L2 distance larger than a threshold, see Appendix ",
                "Table¬†7",
                "), the queried set of samples is considered to serve a hijacking sample.",
                "Table¬†5",
                " reports the attack performance under the feature-based anomaly detection.\nNote that this defense is specifically designed for a set of cloaked samples serving hijacking samples and has no side effects on the utility, so we do not report it.\nWe can see that this defense can substantially mitigate the attack.\nHowever, it‚Äôs important to note that the adversary may not query a set of cloaked samples all at once; instead, they can intelligently query them at different times.\nFurthermore, in the real world, the model is typically queried with mostly original samples, and interspersed among them are some cloaked samples.\nBoth of the above situations present significant challenges for this defense.\nWe leave the in-depth exploration of more effective defense mechanisms against our attack as a future work.",
                "Adversarial Example Defenses.",
                "\nHijackFL adds cloaks to the hijacking samples, similar to adversarial examples that add slight pixel-level perturbations to input samples.\nTherefore, a straightforward defense strategy is utilizing adversarial example defense.\nHere, we employ a widely used adversarial example defense called Feature Squeezing¬†",
                "[",
                "38",
                "]",
                ", which detects adversarial examples at the model prediction phase.\nThis defense is driven by the observation that the input spaces are often unnecessarily large, and this vast input space provides extensive opportunities for an adversary to construct adversarial examples.\nThus, the defender can ‚Äúsqueeze‚Äù out unnecessary input space to reduce the degrees of freedom available to an adversary.\nThe key idea is to compare the model‚Äôs prediction on the input sample with its prediction on the sample after squeezing.\nIf the input sample and squeezed samples produce substantially different outputs from the model, the input sample is likely to be adversarial.\nBy comparing the difference between predictions with a selected threshold, the defender can reject adversarial inputs.",
                "Since this defense also squeezes the original sample, we report the utility of the global model in addition to the attack performance, as shown in ",
                "Table¬†6",
                ".\nIn particular, we examine two thresholds (see Appendix ",
                "Table¬†8",
                "), set significantly lower/higher, to increase sensitivity/insensitivity to input examples with added perturbations, respectively.\nWe find that a smaller threshold (Threshold 1) successfully detects hijacking samples but also yields a high rate of false positives when detecting original samples, resulting in a significant degradation of utility.\nConversely, with a higher threshold (Threshold 2), this defense fails to detect hijacking, leading to HijackFL still outperforming baseline attacks."
            ]
        ]
    },
    "A0.T7": {
        "caption": "Table 7: The threshold of the feature-based anomaly defense..",
        "table": "<table id=\"A0.T7.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A0.T7.4.1.1\" class=\"ltx_tr\">\n<td id=\"A0.T7.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">TaskSet</td>\n<td id=\"A0.T7.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">ResNet-18</td>\n<td id=\"A0.T7.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">MobileNet-V2</td>\n</tr>\n<tr id=\"A0.T7.4.1.2\" class=\"ltx_tr\">\n<td id=\"A0.T7.4.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">I</td>\n<td id=\"A0.T7.4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.6</td>\n<td id=\"A0.T7.4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.6</td>\n</tr>\n<tr id=\"A0.T7.4.1.3\" class=\"ltx_tr\">\n<td id=\"A0.T7.4.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">II</td>\n<td id=\"A0.T7.4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.6</td>\n<td id=\"A0.T7.4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.6</td>\n</tr>\n<tr id=\"A0.T7.4.1.4\" class=\"ltx_tr\">\n<td id=\"A0.T7.4.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">III</td>\n<td id=\"A0.T7.4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.6</td>\n<td id=\"A0.T7.4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.6</td>\n</tr>\n<tr id=\"A0.T7.4.1.5\" class=\"ltx_tr\">\n<td id=\"A0.T7.4.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">IV</td>\n<td id=\"A0.T7.4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.6</td>\n<td id=\"A0.T7.4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.6</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Machine learning (ML), driven by prominent paradigms such as centralized and federated learning, has made significant progress in various critical applications ranging from autonomous driving to face recognition.\nHowever, its remarkable success has been accompanied by various attacks.\nRecently, the model hijacking attack has shown that ML models can be hijacked to execute tasks different from their original tasks, which increases both accountability and parasitic computational risks.",
                "Nevertheless, thus far, this attack has only focused on centralized learning.\nIn this work, we broaden the scope of this attack to the federated learning domain, where multiple clients collaboratively train a global model without sharing their data.\nSpecifically, we present ",
                "HijackFL",
                ", the first-of-its-kind hijacking attack against the global model in federated learning.\nThe adversary aims to force the global model to perform a different task (called hijacking task) from its original task without the server or benign client noticing.\nTo accomplish this, unlike existing methods that use data poisoning to modify the target model‚Äôs parameters, HijackFL¬†searches for pixel-level perturbations based on their local model (without modifications) to align hijacking samples with the original ones in the feature space.\nWhen performing the hijacking task, the adversary applies these cloaks to the hijacking samples, compelling the global model to identify them as original samples and predict them accordingly.\nWe conduct extensive experiments on four benchmark datasets and three popular models.\nEmpirical results demonstrate that its attack performance outperforms baselines.\nWe further investigate the factors that affect its performance and discuss possible defenses to mitigate its impact."
            ]
        ]
    },
    "A0.T8": {
        "caption": "Table 8: The threshold of Feature Squeezing.",
        "table": "<table id=\"A0.T8.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A0.T8.4.1.1\" class=\"ltx_tr\">\n<td id=\"A0.T8.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"A0.T8.4.1.1.1.1\" class=\"ltx_text\">TaskSet</span></td>\n<td id=\"A0.T8.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">ResNet-18</td>\n<td id=\"A0.T8.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\">MobileNet-V2</td>\n</tr>\n<tr id=\"A0.T8.4.1.2\" class=\"ltx_tr\">\n<td id=\"A0.T8.4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Threshold 1</td>\n<td id=\"A0.T8.4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Threshold 2</td>\n<td id=\"A0.T8.4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Threshold 1</td>\n<td id=\"A0.T8.4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Threshold 2</td>\n</tr>\n<tr id=\"A0.T8.4.1.3\" class=\"ltx_tr\">\n<td id=\"A0.T8.4.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">I</td>\n<td id=\"A0.T8.4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3</td>\n<td id=\"A0.T8.4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">15</td>\n<td id=\"A0.T8.4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3</td>\n<td id=\"A0.T8.4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">15</td>\n</tr>\n<tr id=\"A0.T8.4.1.4\" class=\"ltx_tr\">\n<td id=\"A0.T8.4.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">II</td>\n<td id=\"A0.T8.4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3</td>\n<td id=\"A0.T8.4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">15</td>\n<td id=\"A0.T8.4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3</td>\n<td id=\"A0.T8.4.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">15</td>\n</tr>\n<tr id=\"A0.T8.4.1.5\" class=\"ltx_tr\">\n<td id=\"A0.T8.4.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">III</td>\n<td id=\"A0.T8.4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">20</td>\n<td id=\"A0.T8.4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">60</td>\n<td id=\"A0.T8.4.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">20</td>\n<td id=\"A0.T8.4.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">60</td>\n</tr>\n<tr id=\"A0.T8.4.1.6\" class=\"ltx_tr\">\n<td id=\"A0.T8.4.1.6.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">IV</td>\n<td id=\"A0.T8.4.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">20</td>\n<td id=\"A0.T8.4.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">60</td>\n<td id=\"A0.T8.4.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">20</td>\n<td id=\"A0.T8.4.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">60</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Machine learning (ML), driven by prominent paradigms such as centralized and federated learning, has made significant progress in various critical applications ranging from autonomous driving to face recognition.\nHowever, its remarkable success has been accompanied by various attacks.\nRecently, the model hijacking attack has shown that ML models can be hijacked to execute tasks different from their original tasks, which increases both accountability and parasitic computational risks.",
                "Nevertheless, thus far, this attack has only focused on centralized learning.\nIn this work, we broaden the scope of this attack to the federated learning domain, where multiple clients collaboratively train a global model without sharing their data.\nSpecifically, we present ",
                "HijackFL",
                ", the first-of-its-kind hijacking attack against the global model in federated learning.\nThe adversary aims to force the global model to perform a different task (called hijacking task) from its original task without the server or benign client noticing.\nTo accomplish this, unlike existing methods that use data poisoning to modify the target model‚Äôs parameters, HijackFL¬†searches for pixel-level perturbations based on their local model (without modifications) to align hijacking samples with the original ones in the feature space.\nWhen performing the hijacking task, the adversary applies these cloaks to the hijacking samples, compelling the global model to identify them as original samples and predict them accordingly.\nWe conduct extensive experiments on four benchmark datasets and three popular models.\nEmpirical results demonstrate that its attack performance outperforms baselines.\nWe further investigate the factors that affect its performance and discuss possible defenses to mitigate its impact."
            ]
        ]
    }
}