{
    "PAPER'S NUMBER OF TABLES": 7,
    "S4.T1": {
        "caption": "Table 1: Benchmark results.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Dataset</th>\n<th id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Acc</th>\n<th id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">\n<math id=\"S4.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\Delta\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\">Δ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><ci id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">Δ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">\\Delta</annotation></semantics></math>Acc</th>\n<th id=\"S4.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WSR</th>\n<th id=\"S4.T1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WSR_Gap</th>\n<th id=\"S4.T1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">TAcc</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">Digits</th>\n<th id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">0.8855</th>\n<th id=\"S4.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">0.0234</th>\n<td id=\"S4.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9909</td>\n<td id=\"S4.T1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9895</td>\n<td id=\"S4.T1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">1.0000</td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">CIFAR-10</th>\n<th id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">0.5583</th>\n<th id=\"S4.T1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">0.0003</th>\n<td id=\"S4.T1.1.3.2.4\" class=\"ltx_td ltx_align_center\">1.0000</td>\n<td id=\"S4.T1.1.3.2.5\" class=\"ltx_td ltx_align_center\">0.9998</td>\n<td id=\"S4.T1.1.3.2.6\" class=\"ltx_td ltx_align_center\">1.0000</td>\n</tr>\n<tr id=\"S4.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">CIFAR-100</th>\n<th id=\"S4.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">0.5745</th>\n<th id=\"S4.T1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">0.0063</th>\n<td id=\"S4.T1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">1.0000</td>\n<td id=\"S4.T1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.9998</td>\n<td id=\"S4.T1.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">1.0000</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We evaluate our method using the IP tracking benchmark with various metrics as shown in ",
                "Table",
                " ",
                "1",
                ". Our ownership verification is confident with\nall WSRs over ",
                "99",
                "%",
                "percent",
                "99",
                "99\\%",
                " (",
                "R2",
                "). The model utility is also preserved with accuracy degradation ",
                "2.34",
                "%",
                "percent",
                "2.34",
                "2.34\\%",
                ", ",
                "0.03",
                "%",
                "percent",
                "0.03",
                "0.03\\%",
                ", and ",
                "0.63",
                "%",
                "percent",
                "0.63",
                "0.63\\%",
                ", respectively for Digits, CIFAR-10 and CIFAR-100 (",
                "R3",
                "). TAcc for all benchmark datasets is ",
                "100",
                "%",
                "percent",
                "100",
                "100\\%",
                " which indicates accurate IP tracking (",
                "R1",
                ").\nAll WSR_Gap is over ",
                "98",
                "%",
                "percent",
                "98",
                "98\\%",
                ", which means the WSRs for all other benign client’s verification datasets are close to ",
                "0",
                "%",
                "percent",
                "0",
                "0\\%",
                ". In this way, the malicious client can be tracked accurately with high confidence, no collisions will occur within our tracking mechanism (",
                "R1",
                ")."
            ]
        ]
    },
    "S4.T3": {
        "caption": "",
        "table": "<table id=\"S4.T3.2.2.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.2.2.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">Dataset</th>\n<th id=\"S4.T3.2.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">Acc</th>\n<th id=\"S4.T3.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">\n<math id=\"S4.T3.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\Delta\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S4.T3.1.1.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.cmml\">Δ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.1.1.m1.1b\"><ci id=\"S4.T3.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1\">Δ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.1.1.m1.1c\">\\Delta</annotation></semantics></math>Acc</th>\n<th id=\"S4.T3.2.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">WSR</th>\n<th id=\"S4.T3.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">\n<math id=\"S4.T3.2.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\Delta\" display=\"inline\"><semantics id=\"S4.T3.2.2.2.2.2.m1.1a\"><mi mathvariant=\"normal\" id=\"S4.T3.2.2.2.2.2.m1.1.1\" xref=\"S4.T3.2.2.2.2.2.m1.1.1.cmml\">Δ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.2.2.2.m1.1b\"><ci id=\"S4.T3.2.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T3.2.2.2.2.2.m1.1.1\">Δ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.2.2.2.m1.1c\">\\Delta</annotation></semantics></math>WSR</th>\n<th id=\"S4.T3.2.2.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">TAcc</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.2.2.2.3.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">Digits</td>\n<td id=\"S4.T3.2.2.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">0.9712</td>\n<td id=\"S4.T3.2.2.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">-0.0258</td>\n<td id=\"S4.T3.2.2.2.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">0.9924</td>\n<td id=\"S4.T3.2.2.2.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">0.0030</td>\n<td id=\"S4.T3.2.2.2.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">1.0000</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.4.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">CIFAR-10</td>\n<td id=\"S4.T3.2.2.2.4.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">0.7933</td>\n<td id=\"S4.T3.2.2.2.4.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">0.1521</td>\n<td id=\"S4.T3.2.2.2.4.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">1.0000</td>\n<td id=\"S4.T3.2.2.2.4.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">0.0000</td>\n<td id=\"S4.T3.2.2.2.4.2.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">1.0000</td>\n</tr>\n<tr id=\"S4.T3.2.2.2.5.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">CIFAR-100</td>\n<td id=\"S4.T3.2.2.2.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">0.4580</td>\n<td id=\"S4.T3.2.2.2.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">0.0290</td>\n<td id=\"S4.T3.2.2.2.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">0.9930</td>\n<td id=\"S4.T3.2.2.2.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">0.0070</td>\n<td id=\"S4.T3.2.2.2.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:2.8pt;padding-right:2.8pt;\">1.0000</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Federated learning (FL) emerges as an effective collaborative learning framework to coordinate data and computation resources from massive and distributed clients in training.\nSuch collaboration results in non-trivial intellectual property (IP) represented by the model parameters that should be protected and shared by the whole party rather than an individual user.\nMeanwhile, the distributed nature of FL endorses a malicious client the convenience to compromise IP through illegal model leakage to unauthorized third parties.\nTo block such IP leakage, it is essential to make the IP identifiable in the shared model and locate the anonymous infringer who first leaks it.\nThe collective challenges call for accountable federated learning, which requires verifiable ownership of the model and is capable of revealing the infringer’s identity upon leakage.\nIn this paper, we propose\nDecodable Unique Watermarking (DUW) for complying with the requirements of accountable FL.\nSpecifically, before a global model is sent to a client in an FL round, DUW encodes a client-unique key into the model by leveraging a backdoor-based watermark injection.\nTo identify the infringer of a leaked model, DUW examines the model and checks if the triggers can be decoded as the corresponding keys.\nExtensive empirical results show that DUW is highly effective and robust, achieving over 99%percent9999\\% watermark success rate for Digits, CIFAR-10, and CIFAR-100 datasets under heterogeneous FL settings, and identifying the IP infringer with 100%percent100100\\% accuracy even after common watermark removal attempts.",
            "Federated learning (FL) (Konečnỳ et al., 2015) has been widely explored as a distributed learning paradigm to enable remote clients to collaboratively learn a central model without sharing their raw data, effectively leveraging the massive and diverse data available in clients for learning and protecting the data confidentiality.\nThe learning process of FL models typically requires the coordination of significant computing resources from a multitude of clients to curate the valuable information in the client’s data, and the FL models usually have improved performance than isolated learning and thus high commercial value.\nRecently, the risk of leaking such high-value models has drawn the attention of the public. One notable example is the leakage of the foundation model from Meta (Vincent, 2023) by users who gained the restricted distribution of models.\nThe leakage through restricted distribution could be even more severe in FL which allows all participating clients to gain access to the valued model.\nFor each iterative communication round, a central server consolidates models from various client devices, forming a global or central model. This model is then disseminated back to the clients for the next update, and therefore the malicious clients have full access to the global models.\nAs such, effectively protecting the global models in FL is a grand challenge.",
            "Watermarking has shown to be a feasible solution for IP verification, and the major goal of this work is to seek a powerful extension for traceable IP verification for accountable FL that can accurately identify the infringers among a scalable number of clients.\nA straightforward solution is injecting different watermarks for different clients.\nHowever, increasing the number of watermarks could lower the model’s utility as measured by the standard accuracy due to increased forged knowledge  (Tang et al., 2020) (R3).\nMeanwhile, maintaining multiple watermarks could be less robust to watermark removal because of the inconsistency between injections (R4).\nAccurate IP tracking (R1) is one unique requirement we seek to identify the infringer’s identity as compared with traditional watermarking in central training.\nThe greatest challenge in satisfying R1 is addressing the watermark collisions between different clients.\nA watermark collision is when the suspect model produces similar watermark responses on different individual verification datasets in FL systems. Formally:",
            "In this section, we propose the Decodable Unique Watermark (DUW) that can simultaneously address the four requirements of accountable FL summarized in Section 1: R1 (accurate IP tracking), R2 (confident verification), R3 (model utility), R4 (robustness).\nIn DUW, all the watermarking is conducted on the server side, so no computational overhead is introduced to clients.\nBefore broadcasting the global model to each local client, the server will inject a unique watermark for each client. The watermark is unknown to clients but known to the server (see Fig. 1 server watermark injection).\nOur DUW consists of the following two steps for encoding and decoding the client-unique keys.",
            "Robustness against fine-tuning attack.\nWe report the robustness of our proposed DUW against fine-tuning in Table 3. ΔΔ\\DeltaAcc and ΔΔ\\DeltaWSR in this table indicate the accuracy and WSR drop compared with accuracy and WSR before the attack. According to the results, after 505050 epochs of fine-tuning, the attacker can only decrease the WSR by less than 1%percent11\\%, and the TAcc is even not affected. Fine-tuning with their limited local training samples can also cause a standard accuracy degradation.\nFine-tuning can neither remove our watermark nor affect our IP tracking, even if sacrifices their standard accuracy.",
            "Hybrid watermark.\nIf DUW meets a black-box suspect model,\nour DUW can also be combined with existing black-box unified watermarks. We can identify IP leakage using black-box detection with a unified watermark first, then identify infringers using DUW with client-unique watermark.\nWe design a simple hybrid watermark in this section as an example. We pick one of the trigger sets we generated for the clients as the trigger set for the unified watermark injection, and the target label is assigned as 00 which belongs to the original label set of the training data. We use this trigger set to fine-tune the entire global model for 101010 steps before injecting our proposed DUW. Note that no decoder is used for the unified watermark, and the unified watermarks can also be replaced with other existing works. The results on Digits are shown in Table 7. For this table, we can observe that the unified watermark is injected successfully in the presence of our DUW, with a 98.82%percent98.8298.82\\% WSR. Besides, the effectiveness of our DUW is also not affected,\nsince the WSR of DUW only decreases by 0.72%percent0.720.72\\%, and TAcc remains 100%percent100100\\%. The model utility is also not affected, since the standard accuracy remains high.",
            "In this paper,\nwe target at accountable FL, and propose\nDecodable Unique Watermarking (DUW), that can verify the FL model’s ownership and track the IP infringers in the FL system at the same time. Specifically, the server will embed a client-unique key into each client’s local model before broadcasting. The IP infringer can be tracked according to the decoded keys from the suspect model. Extensive experimental results show the effectiveness of our method in accurate IP tracking, confident verification, model utility preserving, and robustness against various watermark removal attacks.",
            "Complexity.\nClients will not experience additional computations as our DUW is carried out on the server side. The additional computation for the server is decided by the number of watermark injection steps Twsubscript𝑇𝑤T_{w}. We found that WSR could reach 99%percent9999\\% just within Tw=10subscript𝑇𝑤10T_{w}=10 steps. Injection of one client-unique watermark takes around 111 second. The server can embed the watermark parallelly for all the clients. Since the watermarked model for each client is independent and has no sequence relationship with each other, there is no need to serialize it.\nThus, the delay caused by the server is neglectable.",
            "Future works.\nThis paper makes the FL model leakage from anonymity to accountability by injecting client-unique watermarks.\nWe recognize the most significant challenge for accountable FL is addressing watermark collision for accurate IP tracking (R1).\nWe believe it is important to scale our method with more clients in the future. One plausible solution is increasing the dimension of the input of the encoder to allow more one-hot encoding target labels. Another solution is to use a hash function as the target label for different clients. In this way, the lower-dimensional encoder and decoder can accommodate more clients. For instance, an encoder with input dimension 101010 can allow at most 102410241024 different clients. However, adopting hash functions as the target labels can increase the chance of watermark collision between clients, and more elegant strategies have to be developed to address this problem.\nAs we focus on the collision, we leave the scalability for future work."
        ]
    },
    "S4.T5": {
        "caption": "",
        "table": "<table id=\"S4.T5.1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T5.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">Method</th>\n<th id=\"S4.T5.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">Acc</th>\n<th id=\"S4.T5.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">\n<math id=\"S4.T5.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\Delta\" display=\"inline\"><semantics id=\"S4.T5.1.1.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S4.T5.1.1.1.1.1.m1.1.1\" xref=\"S4.T5.1.1.1.1.1.m1.1.1.cmml\">Δ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.1.1.1.1.1.m1.1b\"><ci id=\"S4.T5.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T5.1.1.1.1.1.m1.1.1\">Δ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.1.1.1.1.1.m1.1c\">\\Delta</annotation></semantics></math>Acc</th>\n<th id=\"S4.T5.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">WSR</th>\n<th id=\"S4.T5.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">TAcc</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">w/ decoder</td>\n<td id=\"S4.T5.1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">0.3287</td>\n<td id=\"S4.T5.1.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">0.0736</td>\n<td id=\"S4.T5.1.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.4pt;padding-right:3.4pt;\"><span id=\"S4.T5.1.1.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">0.8778</span></td>\n<td id=\"S4.T5.1.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.4pt;padding-right:3.4pt;\"><span id=\"S4.T5.1.1.1.2.1.5.1\" class=\"ltx_text ltx_font_bold\">1.0000</span></td>\n</tr>\n<tr id=\"S4.T5.1.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">w/o decoder</td>\n<td id=\"S4.T5.1.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">0.3235</td>\n<td id=\"S4.T5.1.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">0.0788</td>\n<td id=\"S4.T5.1.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">0.8099</td>\n<td id=\"S4.T5.1.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.4pt;padding-right:3.4pt;\">0.0600</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Federated learning (FL) emerges as an effective collaborative learning framework to coordinate data and computation resources from massive and distributed clients in training.\nSuch collaboration results in non-trivial intellectual property (IP) represented by the model parameters that should be protected and shared by the whole party rather than an individual user.\nMeanwhile, the distributed nature of FL endorses a malicious client the convenience to compromise IP through illegal model leakage to unauthorized third parties.\nTo block such IP leakage, it is essential to make the IP identifiable in the shared model and locate the anonymous infringer who first leaks it.\nThe collective challenges call for accountable federated learning, which requires verifiable ownership of the model and is capable of revealing the infringer’s identity upon leakage.\nIn this paper, we propose\nDecodable Unique Watermarking (DUW) for complying with the requirements of accountable FL.\nSpecifically, before a global model is sent to a client in an FL round, DUW encodes a client-unique key into the model by leveraging a backdoor-based watermark injection.\nTo identify the infringer of a leaked model, DUW examines the model and checks if the triggers can be decoded as the corresponding keys.\nExtensive empirical results show that DUW is highly effective and robust, achieving over 99%percent9999\\% watermark success rate for Digits, CIFAR-10, and CIFAR-100 datasets under heterogeneous FL settings, and identifying the IP infringer with 100%percent100100\\% accuracy even after common watermark removal attempts.",
            "Federated learning (FL) (Konečnỳ et al., 2015) has been widely explored as a distributed learning paradigm to enable remote clients to collaboratively learn a central model without sharing their raw data, effectively leveraging the massive and diverse data available in clients for learning and protecting the data confidentiality.\nThe learning process of FL models typically requires the coordination of significant computing resources from a multitude of clients to curate the valuable information in the client’s data, and the FL models usually have improved performance than isolated learning and thus high commercial value.\nRecently, the risk of leaking such high-value models has drawn the attention of the public. One notable example is the leakage of the foundation model from Meta (Vincent, 2023) by users who gained the restricted distribution of models.\nThe leakage through restricted distribution could be even more severe in FL which allows all participating clients to gain access to the valued model.\nFor each iterative communication round, a central server consolidates models from various client devices, forming a global or central model. This model is then disseminated back to the clients for the next update, and therefore the malicious clients have full access to the global models.\nAs such, effectively protecting the global models in FL is a grand challenge.",
            "Watermarking has shown to be a feasible solution for IP verification, and the major goal of this work is to seek a powerful extension for traceable IP verification for accountable FL that can accurately identify the infringers among a scalable number of clients.\nA straightforward solution is injecting different watermarks for different clients.\nHowever, increasing the number of watermarks could lower the model’s utility as measured by the standard accuracy due to increased forged knowledge  (Tang et al., 2020) (R3).\nMeanwhile, maintaining multiple watermarks could be less robust to watermark removal because of the inconsistency between injections (R4).\nAccurate IP tracking (R1) is one unique requirement we seek to identify the infringer’s identity as compared with traditional watermarking in central training.\nThe greatest challenge in satisfying R1 is addressing the watermark collisions between different clients.\nA watermark collision is when the suspect model produces similar watermark responses on different individual verification datasets in FL systems. Formally:",
            "In this section, we propose the Decodable Unique Watermark (DUW) that can simultaneously address the four requirements of accountable FL summarized in Section 1: R1 (accurate IP tracking), R2 (confident verification), R3 (model utility), R4 (robustness).\nIn DUW, all the watermarking is conducted on the server side, so no computational overhead is introduced to clients.\nBefore broadcasting the global model to each local client, the server will inject a unique watermark for each client. The watermark is unknown to clients but known to the server (see Fig. 1 server watermark injection).\nOur DUW consists of the following two steps for encoding and decoding the client-unique keys.",
            "Robustness against fine-tuning attack.\nWe report the robustness of our proposed DUW against fine-tuning in Table 3. ΔΔ\\DeltaAcc and ΔΔ\\DeltaWSR in this table indicate the accuracy and WSR drop compared with accuracy and WSR before the attack. According to the results, after 505050 epochs of fine-tuning, the attacker can only decrease the WSR by less than 1%percent11\\%, and the TAcc is even not affected. Fine-tuning with their limited local training samples can also cause a standard accuracy degradation.\nFine-tuning can neither remove our watermark nor affect our IP tracking, even if sacrifices their standard accuracy.",
            "Hybrid watermark.\nIf DUW meets a black-box suspect model,\nour DUW can also be combined with existing black-box unified watermarks. We can identify IP leakage using black-box detection with a unified watermark first, then identify infringers using DUW with client-unique watermark.\nWe design a simple hybrid watermark in this section as an example. We pick one of the trigger sets we generated for the clients as the trigger set for the unified watermark injection, and the target label is assigned as 00 which belongs to the original label set of the training data. We use this trigger set to fine-tune the entire global model for 101010 steps before injecting our proposed DUW. Note that no decoder is used for the unified watermark, and the unified watermarks can also be replaced with other existing works. The results on Digits are shown in Table 7. For this table, we can observe that the unified watermark is injected successfully in the presence of our DUW, with a 98.82%percent98.8298.82\\% WSR. Besides, the effectiveness of our DUW is also not affected,\nsince the WSR of DUW only decreases by 0.72%percent0.720.72\\%, and TAcc remains 100%percent100100\\%. The model utility is also not affected, since the standard accuracy remains high.",
            "In this paper,\nwe target at accountable FL, and propose\nDecodable Unique Watermarking (DUW), that can verify the FL model’s ownership and track the IP infringers in the FL system at the same time. Specifically, the server will embed a client-unique key into each client’s local model before broadcasting. The IP infringer can be tracked according to the decoded keys from the suspect model. Extensive experimental results show the effectiveness of our method in accurate IP tracking, confident verification, model utility preserving, and robustness against various watermark removal attacks.",
            "Complexity.\nClients will not experience additional computations as our DUW is carried out on the server side. The additional computation for the server is decided by the number of watermark injection steps Twsubscript𝑇𝑤T_{w}. We found that WSR could reach 99%percent9999\\% just within Tw=10subscript𝑇𝑤10T_{w}=10 steps. Injection of one client-unique watermark takes around 111 second. The server can embed the watermark parallelly for all the clients. Since the watermarked model for each client is independent and has no sequence relationship with each other, there is no need to serialize it.\nThus, the delay caused by the server is neglectable.",
            "Future works.\nThis paper makes the FL model leakage from anonymity to accountability by injecting client-unique watermarks.\nWe recognize the most significant challenge for accountable FL is addressing watermark collision for accurate IP tracking (R1).\nWe believe it is important to scale our method with more clients in the future. One plausible solution is increasing the dimension of the input of the encoder to allow more one-hot encoding target labels. Another solution is to use a hash function as the target label for different clients. In this way, the lower-dimensional encoder and decoder can accommodate more clients. For instance, an encoder with input dimension 101010 can allow at most 102410241024 different clients. However, adopting hash functions as the target labels can increase the chance of watermark collision between clients, and more elegant strategies have to be developed to address this problem.\nAs we focus on the collision, we leave the scalability for future work."
        ]
    },
    "S4.T6": {
        "caption": "Table 6: Ablation study: results for different numbers of clients on digits. ",
        "table": "<table id=\"S4.T6.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T6.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T6.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Number of clients</th>\n<th id=\"S4.T6.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Acc</th>\n<th id=\"S4.T6.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">\n<math id=\"S4.T6.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\Delta\" display=\"inline\"><semantics id=\"S4.T6.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S4.T6.1.1.1.m1.1.1\" xref=\"S4.T6.1.1.1.m1.1.1.cmml\">Δ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T6.1.1.1.m1.1b\"><ci id=\"S4.T6.1.1.1.m1.1.1.cmml\" xref=\"S4.T6.1.1.1.m1.1.1\">Δ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T6.1.1.1.m1.1c\">\\Delta</annotation></semantics></math>Acc</th>\n<th id=\"S4.T6.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WSR</th>\n<th id=\"S4.T6.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WSR_Gap</th>\n<th id=\"S4.T6.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">TAcc</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T6.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T6.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">40</th>\n<td id=\"S4.T6.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8855</td>\n<td id=\"S4.T6.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0234</td>\n<td id=\"S4.T6.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9909</td>\n<td id=\"S4.T6.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9895</td>\n<td id=\"S4.T6.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">1.0000</td>\n</tr>\n<tr id=\"S4.T6.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T6.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">400</th>\n<td id=\"S4.T6.1.3.2.2\" class=\"ltx_td ltx_align_center\">0.8597</td>\n<td id=\"S4.T6.1.3.2.3\" class=\"ltx_td ltx_align_center\">-0.0332</td>\n<td id=\"S4.T6.1.3.2.4\" class=\"ltx_td ltx_align_center\">0.9521</td>\n<td id=\"S4.T6.1.3.2.5\" class=\"ltx_td ltx_align_center\">0.9267</td>\n<td id=\"S4.T6.1.3.2.6\" class=\"ltx_td ltx_align_center\">1.0000</td>\n</tr>\n<tr id=\"S4.T6.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T6.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">600</th>\n<td id=\"S4.T6.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.8276</td>\n<td id=\"S4.T6.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">-0.0035</td>\n<td id=\"S4.T6.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.7337</td>\n<td id=\"S4.T6.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.6383</td>\n<td id=\"S4.T6.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">1.0000</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Effects of decoder.",
                "\nTo investigate the effects of the decoder on avoiding watermark collision, we compare the results of w/ and w/o decoder. When the decoder is removed, the task dimension of the watermark injection will be the same as the FL classification, thus, we also have to change the original target label (the same as the input key) to the FL classification task dimension. To achieve this goal, we set the target label of w/o decoder case as (client_ID ",
                "%",
                "percent",
                "\\%",
                " class_number).\nWe report the results of w/ and w/o decoder on CIFAR-10 after ",
                "1",
                "1",
                "1",
                " round of watermark injection at round ",
                "20",
                "20",
                "20",
                " in ",
                "Table",
                " ",
                "5",
                ".\nAccording to the results, when we have 100 clients in total, w/o decoder can only achieve a TAcc of ",
                "6",
                "%",
                "percent",
                "6",
                "6\\%",
                ", while w/ decoder can increase TAcc to ",
                "100",
                "%",
                "percent",
                "100",
                "100\\%",
                ". We also find that clients with the same target label are more likely to conflict with each other, which makes those clients difficult to be identified, even if their trigger sets are different. Utilizing a decoder to increase the target label space to a dimension larger than the client number allows all the clients to have their own target label. In this way, watermark collision can be avoided. Besides, WSR of w/ decoder is also higher than w/o decoder after ",
                "1",
                "1",
                "1",
                " round of injection. One possible reason is that we differ the watermark injection task from the original classification task using the decoder, thus, in this case, the watermark will be more easily injected compared with directly injected to the original FL classification task.",
                "Effects of ",
                "l",
                "2",
                "subscript",
                "𝑙",
                "2",
                "l_{2}",
                " regularization.",
                "\nTo show the effects of ",
                "l",
                "2",
                "subscript",
                "𝑙",
                "2",
                "l_{2}",
                " regularization in ",
                "Eq.",
                " ",
                "5",
                ", we report the validation accuracy and WSR for ",
                "4",
                "4",
                "4",
                " rounds of watermark injection on Digits with different values of the hyperparameter ",
                "β",
                "𝛽",
                "\\beta",
                "\nin ",
                "Fig.",
                " ",
                "4(a)",
                ".\nValidation accuracy is the standard FL accuracy evaluated on a validation dataset for every round.\nWe see that with the increase of ",
                "β",
                "𝛽",
                "\\beta",
                ", higher validation accuracy can be achieved, but correspondingly, WSR drops from over ",
                "90",
                "%",
                "percent",
                "90",
                "90\\%",
                " to only ",
                "35.65",
                "%",
                "percent",
                "35.65",
                "35.65\\%",
                ".\nLarger ",
                "β",
                "𝛽",
                "\\beta",
                " increases the impact of ",
                "l",
                "2",
                "subscript",
                "𝑙",
                "2",
                "l_{2}",
                " norm, which decreases the model difference between the watermarked model and the non-watermarked one, so the validation accuracy will increase.\nAt the same time, the updates during watermark injection also have much more restriction due to ",
                "l",
                "2",
                "subscript",
                "𝑙",
                "2",
                "l_{2}",
                " regularization, so the WSR drops to a low value.\nAccordingly, we select ",
                "β",
                "=",
                "0.1",
                "𝛽",
                "0.1",
                "\\beta=0.1",
                " for all our experiments, since ",
                "β",
                "=",
                "0.1",
                "𝛽",
                "0.1",
                "\\beta=0.1",
                " can increase validation accuracy by ",
                "6.88",
                "%",
                "percent",
                "6.88",
                "6.88\\%",
                " compared with ",
                "β",
                "=",
                "0",
                "𝛽",
                "0",
                "\\beta=0",
                ", while maintaining WSR over ",
                "90",
                "%",
                "percent",
                "90",
                "90\\%",
                ".",
                "Effects of different OoD datasets for watermark injection.",
                "\nWe investigate the effects of different OoD datasets including USPS ",
                "(Hull, ",
                "1994",
                ")",
                ", GTSRB ",
                "(Stallkamp et al., ",
                "2012",
                ")",
                ", random noise, and Jigsaw for watermark injection when the standard training data is Digits.\nAll OoD images are cropped to the same size as the training images.\nA jigsaw image is generated from a small ",
                "4",
                "×",
                "4",
                "4",
                "4",
                "4\\times 4",
                " random image, and then uses reflect padding mode from PyTorch to padding to the same size as the training images.\nThe effect of these different OoD datasets is shown in ",
                "Table",
                " ",
                "5",
                " and ",
                "Fig.",
                " ",
                "4(b)",
                ".\nWe see that all OoD datasets can achieve ",
                "100",
                "%",
                "percent",
                "100",
                "100\\%",
                " TAcc, suggesting the selection of OoD dataset will not affect the tracking of the malicious client.\nThere is a trade-off between the Acc and WSR: higher WSR always leads to lower Acc.\nRandom noise and jigsaw achieve high Acc, with accuracy degradation within ",
                "1",
                "%",
                "percent",
                "1",
                "1\\%",
                ".\nThese two noise OoD also have a faster recovery of the standard accuracy after the accuracy drop at the watermark injection round as shown in ",
                "Fig.",
                " ",
                "4(b)",
                ", but the WSR of random noise and Jigsaw are lower than ",
                "90",
                "%",
                "percent",
                "90",
                "90\\%",
                ". For two real OoD datasets USPS and GTSRB, the WSR quickly reaches over ",
                "99",
                "%",
                "percent",
                "99",
                "99\\%",
                " after ",
                "1",
                "1",
                "1",
                " communication round, but their accuracy degradation is larger than ",
                "2",
                "%",
                "percent",
                "2",
                "2\\%",
                ".",
                "Scalability of DUW to more clients.",
                "\nWe conduct an ablation study to show the effect of the number of clients in ",
                "Table",
                " ",
                "6",
                ". According to the results, even with ",
                "600",
                "600",
                "600",
                " clients, the WSR is still over ",
                "73",
                "%",
                "percent",
                "73",
                "73\\%",
                " and the TAcc remains ",
                "100",
                "%",
                "percent",
                "100",
                "100\\%",
                ". With more clients participating in FL, we can still track the malicious client correctly with high confidence.",
                "Hybrid watermark.",
                "\nIf DUW meets a black-box suspect model,\nour DUW can also be combined with existing black-box unified watermarks. We can identify IP leakage using black-box detection with a unified watermark first, then identify infringers using DUW with client-unique watermark.\nWe design a simple hybrid watermark in this section as an example. We pick one of the trigger sets we generated for the clients as the trigger set for the unified watermark injection, and the target label is assigned as ",
                "0",
                "0",
                " which belongs to the original label set of the training data. We use this trigger set to fine-tune the entire global model for ",
                "10",
                "10",
                "10",
                " steps before injecting our proposed DUW. Note that no decoder is used for the unified watermark, and the unified watermarks can also be replaced with other existing works. The results on Digits are shown in ",
                "Table",
                " ",
                "7",
                ". For this table, we can observe that the unified watermark is injected successfully in the presence of our DUW, with a ",
                "98.82",
                "%",
                "percent",
                "98.82",
                "98.82\\%",
                " WSR. Besides, the effectiveness of our DUW is also not affected,\nsince the WSR of DUW only decreases by ",
                "0.72",
                "%",
                "percent",
                "0.72",
                "0.72\\%",
                ", and TAcc remains ",
                "100",
                "%",
                "percent",
                "100",
                "100\\%",
                ". The model utility is also not affected, since the standard accuracy remains high."
            ]
        ]
    },
    "S4.T7": {
        "caption": "Table 7: Results for hybrid watermark.",
        "table": "<table id=\"S4.T7.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T7.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T7.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Method</th>\n<th id=\"S4.T7.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Acc</th>\n<th id=\"S4.T7.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">\n<math id=\"S4.T7.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\Delta\" display=\"inline\"><semantics id=\"S4.T7.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S4.T7.1.1.1.m1.1.1\" xref=\"S4.T7.1.1.1.m1.1.1.cmml\">Δ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.1.1.1.m1.1b\"><ci id=\"S4.T7.1.1.1.m1.1.1.cmml\" xref=\"S4.T7.1.1.1.m1.1.1\">Δ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T7.1.1.1.m1.1c\">\\Delta</annotation></semantics></math>Acc</th>\n<th id=\"S4.T7.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WSR</th>\n<th id=\"S4.T7.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WSR_Gap</th>\n<th id=\"S4.T7.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">TAcc</th>\n<th id=\"S4.T7.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Unified WSR</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T7.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T7.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">w/o unified watermark</th>\n<th id=\"S4.T7.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">0.8855</th>\n<th id=\"S4.T7.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">0.0234</th>\n<td id=\"S4.T7.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9909</td>\n<td id=\"S4.T7.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9895</td>\n<td id=\"S4.T7.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">1.0000</td>\n<td id=\"S4.T7.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">/</td>\n</tr>\n<tr id=\"S4.T7.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T7.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">w/ unified watermark</th>\n<th id=\"S4.T7.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">0.8886</th>\n<th id=\"S4.T7.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">0.0203</th>\n<td id=\"S4.T7.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.9837</td>\n<td id=\"S4.T7.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.9701</td>\n<td id=\"S4.T7.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">1.0000</td>\n<td id=\"S4.T7.1.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.9882</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Hybrid watermark.\nIf DUW meets a black-box suspect model,\nour DUW can also be combined with existing black-box unified watermarks. We can identify IP leakage using black-box detection with a unified watermark first, then identify infringers using DUW with client-unique watermark.\nWe design a simple hybrid watermark in this section as an example. We pick one of the trigger sets we generated for the clients as the trigger set for the unified watermark injection, and the target label is assigned as 00 which belongs to the original label set of the training data. We use this trigger set to fine-tune the entire global model for 101010 steps before injecting our proposed DUW. Note that no decoder is used for the unified watermark, and the unified watermarks can also be replaced with other existing works. The results on Digits are shown in Table 7. For this table, we can observe that the unified watermark is injected successfully in the presence of our DUW, with a 98.82%percent98.8298.82\\% WSR. Besides, the effectiveness of our DUW is also not affected,\nsince the WSR of DUW only decreases by 0.72%percent0.720.72\\%, and TAcc remains 100%percent100100\\%. The model utility is also not affected, since the standard accuracy remains high."
        ]
    },
    "A2.T8": {
        "caption": "Table 8: Prediction results for random noise trigger for client 90-99.",
        "table": "<table id=\"A2.T8.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T8.1.1.1\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">ground truth client_ID</td>\n<td id=\"A2.T8.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">predicted client_ID</td>\n</tr>\n<tr id=\"A2.T8.1.2.2\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90</td>\n<td id=\"A2.T8.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0</td>\n</tr>\n<tr id=\"A2.T8.1.3.3\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">91</td>\n<td id=\"A2.T8.1.3.3.2\" class=\"ltx_td ltx_align_center\">1</td>\n</tr>\n<tr id=\"A2.T8.1.4.4\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">92</td>\n<td id=\"A2.T8.1.4.4.2\" class=\"ltx_td ltx_align_center\">92</td>\n</tr>\n<tr id=\"A2.T8.1.5.5\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">93</td>\n<td id=\"A2.T8.1.5.5.2\" class=\"ltx_td ltx_align_center\">3</td>\n</tr>\n<tr id=\"A2.T8.1.6.6\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">94</td>\n<td id=\"A2.T8.1.6.6.2\" class=\"ltx_td ltx_align_center\">4</td>\n</tr>\n<tr id=\"A2.T8.1.7.7\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">95</td>\n<td id=\"A2.T8.1.7.7.2\" class=\"ltx_td ltx_align_center\">5</td>\n</tr>\n<tr id=\"A2.T8.1.8.8\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.8.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\">96</td>\n<td id=\"A2.T8.1.8.8.2\" class=\"ltx_td ltx_align_center\">6</td>\n</tr>\n<tr id=\"A2.T8.1.9.9\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.9.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">97</td>\n<td id=\"A2.T8.1.9.9.2\" class=\"ltx_td ltx_align_center\">49</td>\n</tr>\n<tr id=\"A2.T8.1.10.10\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_r\">98</td>\n<td id=\"A2.T8.1.10.10.2\" class=\"ltx_td ltx_align_center\">8</td>\n</tr>\n<tr id=\"A2.T8.1.11.11\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.11.11.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">99</td>\n<td id=\"A2.T8.1.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">99</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We compare our proposed DUW with two traditional backdoor-based watermarks in ",
                "Fig.",
                " ",
                "5",
                ". Due to the reason that if all the clients share the same trigger, watermark collision will definitely happen, we design different triggers for different clients. Specifically, we use traditional backdoor-based watermarking by adding arbitrary badnet triggers using random noise or 0-1 coding trigger for each client. To distinguish between different clients, for 0-1 trigger, following  ",
                "Tang et al. (",
                "2020",
                ")",
                ", we set ",
                "5",
                "5",
                "5",
                " pixel values of the pattern into ",
                "0",
                "0",
                " and other ",
                "11",
                "11",
                "11",
                " pixels into 1, different combinations of the pattern are randomly chosen for different clients. For random noise triggers, we generate different random noise triggers for different clients.\nThe trigger size ",
                "4",
                "×",
                "4",
                "4",
                "4",
                "4\\times 4",
                " and the injection is conducted for ",
                "4",
                "4",
                "4",
                " rounds. The target label for each client is set as (client_ID % class_number). According to the results, traditional backdoor-based watermarks can only achieve a tracking accuracy lower than ",
                "13",
                "%",
                "percent",
                "13",
                "13\\%",
                " (it will even be lower with the increase of the communication rounds), which is much lower than the ",
                "100",
                "%",
                "percent",
                "100",
                "100\\%",
                " tracking accuracy we have achieved. Note that, the rate of clients with watermark collisions can be calculated as 1-TAcc.",
                "To analyze the failure of the traditional backdoor-based watermarking,\nwe give detailed prediction results for one trial on CIFAR10 for random noise trigger as an example. The client number is ",
                "100",
                "100",
                "100",
                ", so the client_ID is from 0-99, and the class number is ",
                "10",
                "10",
                "10",
                ". Here we provide a fine-grained analysis of the concerned ",
                "13",
                "%",
                "percent",
                "13",
                "13\\%",
                " TAcc by looking into the last ",
                "10",
                "10",
                "10",
                " clients. We list the client_ID and their corresponding predicted client_ID for clients 90-99 in ",
                "Table",
                " ",
                "8",
                ". From the prediction results, ",
                "8",
                "8",
                "8",
                " of ",
                "10",
                "10",
                "10",
                " clients are tracked wrong. Among these ",
                "8",
                "8",
                "8",
                " failure cases, ",
                "7",
                "7",
                "7",
                " of the predicted client_ID (client ",
                "90",
                "90",
                "90",
                ", ",
                "91",
                "91",
                "91",
                ", ",
                "93",
                "93",
                "93",
                ", ",
                "94",
                "94",
                "94",
                " ",
                "95",
                "95",
                "95",
                ", ",
                "96",
                "96",
                "96",
                ", ",
                "98",
                "98",
                "98",
                ") share the same targets, and 1 of them (client 97) have both different triggers and different target labels. The two kinds of failures correspond to two different reasons respectively as we illustrated in ",
                "Section",
                " ",
                "3.1",
                "."
            ]
        ]
    },
    "A2.T9": {
        "caption": "Table 9: Ablation study: results for watermark injection in different rounds on digits.",
        "table": "<table id=\"A2.T9.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T9.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T9.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Inject round</th>\n<th id=\"A2.T9.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Acc</th>\n<th id=\"A2.T9.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">\n<math id=\"A2.T9.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\Delta\" display=\"inline\"><semantics id=\"A2.T9.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"A2.T9.1.1.1.m1.1.1\" xref=\"A2.T9.1.1.1.m1.1.1.cmml\">Δ</mi><annotation-xml encoding=\"MathML-Content\" id=\"A2.T9.1.1.1.m1.1b\"><ci id=\"A2.T9.1.1.1.m1.1.1.cmml\" xref=\"A2.T9.1.1.1.m1.1.1\">Δ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T9.1.1.1.m1.1c\">\\Delta</annotation></semantics></math>Acc</th>\n<th id=\"A2.T9.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WSR</th>\n<th id=\"A2.T9.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WSR_Gap</th>\n<th id=\"A2.T9.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">TAcc</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T9.1.2.1\" class=\"ltx_tr\">\n<th id=\"A2.T9.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">5</th>\n<td id=\"A2.T9.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8838</td>\n<td id=\"A2.T9.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0251</td>\n<td id=\"A2.T9.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9951</td>\n<td id=\"A2.T9.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9948</td>\n<td id=\"A2.T9.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">1.0000</td>\n</tr>\n<tr id=\"A2.T9.1.3.2\" class=\"ltx_tr\">\n<th id=\"A2.T9.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">10</th>\n<td id=\"A2.T9.1.3.2.2\" class=\"ltx_td ltx_align_center\">0.8811</td>\n<td id=\"A2.T9.1.3.2.3\" class=\"ltx_td ltx_align_center\">0.0278</td>\n<td id=\"A2.T9.1.3.2.4\" class=\"ltx_td ltx_align_center\">0.9946</td>\n<td id=\"A2.T9.1.3.2.5\" class=\"ltx_td ltx_align_center\">0.9938</td>\n<td id=\"A2.T9.1.3.2.6\" class=\"ltx_td ltx_align_center\">1.0000</td>\n</tr>\n<tr id=\"A2.T9.1.4.3\" class=\"ltx_tr\">\n<th id=\"A2.T9.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">20</th>\n<td id=\"A2.T9.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.8855</td>\n<td id=\"A2.T9.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.0234</td>\n<td id=\"A2.T9.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.9909</td>\n<td id=\"A2.T9.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.9895</td>\n<td id=\"A2.T9.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">1.0000</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Visualization of unique trigger sets.",
                "\nWe show the visualization example for the original image, encoded image (image in trigger set), and residual image based on different OoD datasets in ",
                "Fig.",
                " ",
                "6",
                ". We observe that for all four different OoD datasets, the original image and encoded image with our client keys are indistinguishable from the human eye. The difference between these two images can be observed in the residual image. Note that although the OoD datasets are different, the encoder that we used to generate the trigger sets is the same. According to ",
                "Fig.",
                " ",
                "6",
                ", the encoder will generate sample-wise triggers for different images.",
                "To investigate the difference between different clients’ trigger sets based on the same OoD dataset, we show one example in the trigger set generated by the jigsaw image for two randomly picked clients in ",
                "Fig.",
                " ",
                "7",
                ". The trigger sets are generated based on the same jigsaw dataset and differ by their embedded keys. According to ",
                "Fig.",
                " ",
                "7",
                ",\nalthough the samples from different trigger sets do not look distinguishable according\nto the human inspection, the difference between keys decoded from the trigger sets can be distinguished by our model.",
                "Effects of the different numbers of samples in trigger sets.",
                "\nWe investigate how the size of the trigger set will affect our watermark injection and standard FL training in ",
                "Fig.",
                " ",
                "8",
                " by varying the number of samples in the trigger set from ",
                "50",
                "50",
                "50",
                " to ",
                "500",
                "500",
                "500",
                " for Digits training (USPS is used to generate the trigger set). Note that for all cases, TAcc always remains to be ",
                "100",
                "%",
                "percent",
                "100",
                "100\\%",
                ". We observe that with only ",
                "50",
                "50",
                "50",
                " samples in one trigger set, we can achieve an accuracy degradation around ",
                "2",
                "%",
                "percent",
                "2",
                "2\\%",
                ", and with a WSR over ",
                "98",
                "%",
                "percent",
                "98",
                "98\\%",
                ". When the number of samples increases to ",
                "300",
                "300",
                "300",
                ", WSR is over ",
                "99",
                "%",
                "percent",
                "99",
                "99\\%",
                ". In general, the change in the number of samples in the trigger set has almost no effect on both standard accuracy and WSR. A small trigger set (such as ",
                "50",
                "50",
                "50",
                ") can achieve comparable results with a large trigger set.\nThe advantages of a smaller trigger set include quicker trigger set generation, quicker watermark injection, quicker ownership verification, and quicker IP tracking. Besides, less effort can be made for OoD data synthesizing or collecting.",
                "Effects of different watermark injection rounds.",
                " We conduct an ablation study to show the effect of the injection round of the watermark in ",
                "Table",
                " ",
                "9",
                ". The results verify that injecting in earlier rounds will not affect standard accuracy, WSR, and TAcc. In our paper, we do not start our watermark injection at the very beginning of training since early-stage protection usually means more computational resources, so it is more valuable to focus on high-quality models rather than low-quality models.",
                "Effects of different FL algorithms",
                "\nIn ",
                "Fig.",
                " ",
                "9",
                ", we show the standard accuracy, WSR and TAcc for our proposed DUW in two different FL settings: fedavg and fedprox ",
                "(Li et al., ",
                "2020",
                ")",
                ". According to the results, fedprox can achieve comparable WSR as fedavg and higher standard accuracy. TAcc for both FL algorithms remains to be ",
                "100",
                "%",
                "percent",
                "100",
                "100\\%",
                ". Our proposed method is not sensitive to the FL framework, in which it is implanted."
            ]
        ]
    }
}