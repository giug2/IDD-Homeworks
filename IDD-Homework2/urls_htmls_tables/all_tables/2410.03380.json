{
    "id_table_1": {
        "caption": "Table 2:  Results on 5 Perturb-seq datasets. Top: trivial perturbations. Bottom: non-trivial perturbations. Primary setting: train all cell lines jointly, test on unseen perturbations. Suffix  -cl : leave out the one cell line from training, test on the same set of unseen perturbations in the unseen cell line. Metrics, from left to right: normalized rank of ground truth, top 20 recall, and top 1 Pearson correlation. For ablations, runtimes, and uncertainties, see Appendix  D .",
        "table": "S4.2.2.2.2",
        "footnotes": [
            ""
        ],
        "references": [
            "Our model is composed of two modules: a frozen  causal featurizer , and a learned  differential network , which we refer to jointly as  Cdn  (Figure  2 ). The causal featurizer is a pretrained, amortized causal discovery model  (Wu et al.,  2024 )  that runs efficiently on up to a thousand nodes (Section  3.1 ), while the differential network is an axial-attention based classifier  (Ho et al.,  2020 )  that predicts the nodes whose data-generating mechanisms have changed (Section  3.2 ).",
            "We evaluated  Cdn  on seven transcriptomics datasets, with comparisons to state-of-the-art models for these applications (Section  4.1 ). Note that these baselines all use various domain knowledge to inform their predictions. For completeness, we also benchmarked  Cdn  against multiple causal discovery algorithms for unknown interventions in variety of controlled settings (Section  4.2 ).",
            "To ensure high quality labels, we filtered perturbations to those that induced over 10 differentially-expressed genes (statistically significant change, compared to control), of which the true target should be present. This is to exclude perturbations with insufficient cells (low statistical power), with minimal to no effect (uninteresting), and those that did not achieve the desired effect (CRISPR efficacy is not guaranteed). For evaluation, we limited the set of candidate targets to the top 1000 differentially expressed genes, ranked by log-fold change per perturbation. If fewer genes were differentially expressed, we randomly sampled additional candidates until we reached a minimum of 100 genes. Finally, we also stratify genetic perturbations based on whether the target is trivially identifiable as the gene with the largest log-fold change (trivial vs. non-trivial). This is because genetic perturbations are highly specific by design, but also constitute the largest single-cell perturbation datasets. The final data statistics are shown in Table  1 , with additional details in Appendix  B.1 .",
            "All baselines were run with their official implementations and/or latest releases. For more details, please see Appendix  C.1 .",
            "We compare against discrete and continuous causal discovery algorithms for unknown interventions.  Ut-Igsp   (Squires et al.,  2020 )  infers causal graphs and unknown targets by greedily selecting the permutation of variables that minimizes their proposed score function.  Dcdi   (Brouillard et al.,  2020 )  and  Bacadi   (Hagele et al.,  2023 )  are continuous causal discovery algorithms that fit generative models to the data, where the causal graph and intervention targets are model parameters. The  -G  and  -Dsf  suffixes on  Dcdi  correspond to Gaussian and deep sigmoidal flow parametrizations of the likelihood.  Bacadi  is evaluated here using the fully-connected implementation (better performance), with the linear version in Table  11 . Its  -E  and  -M  suffixes indicate empirical (standard) and mixture (bootstrap) variants.",
            "All source code will be made publicly available. Hyperparameter and implementation choices are described in Section  3.3 . Details regarding biological data pre-processing can be found in Section  4.1  and Appendix  B.1 . The raw data are freely available via the accession codes listed in Table  5 . Synthetic data generation is discussed in Appendix  B.2 . Details required to reproduce baselines are described in Sections  4.1  and  4.2 , as well as Appendix  C.1 .",
            "Due to space limitations, we report uncertainty estimates in Table  10 . Multiple baselines produce deterministic results ( Linear ,  GenePt ), so instead of model randomness, we report uncertainties over the sampling of single cells. Specifically, for each perturbation with  M M M italic_M  cells, we sample",
            "Table  11  reports results on all synthetic test datasets, averaging over all interventions for each dataset."
        ]
    },
    "id_table_2": {
        "caption": "Table 4:  Intervention target prediction results on synthetic datasets with  N = 10 , E = 10 formulae-sequence N 10 E 10 N=10,E=10 italic_N = 10 , italic_E = 10 . Uncertainty is standard deviation over 5 distinct datasets. Top: hard interventions; bottom: soft interventions (scale). Number in parentheses indicates number of intervention targets. Runtimes are documented in Table  9 , and full results are available in Table  11 .",
        "table": "S4.T2.282.280",
        "footnotes": [
            "",
            ""
        ],
        "references": [
            "Our model is composed of two modules: a frozen  causal featurizer , and a learned  differential network , which we refer to jointly as  Cdn  (Figure  2 ). The causal featurizer is a pretrained, amortized causal discovery model  (Wu et al.,  2024 )  that runs efficiently on up to a thousand nodes (Section  3.1 ), while the differential network is an axial-attention based classifier  (Ho et al.,  2020 )  that predicts the nodes whose data-generating mechanisms have changed (Section  3.2 ).",
            "Given the graph representation, the differential network predicts which nodes were intervened upon (Figure  2 , right). Its architecture is composed of an axial-attention layer, followed by a linear projection. Following  Sea , the axial attention layer attends separately along the rows and columns of the graphs adjacency matrix. This operation is equivalent to self-attention along all nodes in the outgoing edge direction, with the incoming edges as a batch dimension, followed by the opposite. We use pre-layer normalization on each self-attention, followed by dropout and residual connections:",
            "We evaluated  Cdn  on seven transcriptomics datasets, with comparisons to state-of-the-art models for these applications (Section  4.1 ). Note that these baselines all use various domain knowledge to inform their predictions. For completeness, we also benchmarked  Cdn  against multiple causal discovery algorithms for unknown interventions in variety of controlled settings (Section  4.2 ).",
            "Table  2  reports our results on five Perturb-seq datasets. In the majority of cases,  Cdn  outperforms baselines, both in the seen and unseen cell line settings. This is more evident in Figure  4 , in which  Cdn  achieves higher recall at  k k k italic_k  at nearly all points on the curves. While no baseline is as consistent as  Cdn ,  GenePt  is surprisingly competitive against more complex baselines. This may indicate that natural language induces embedding spaces with favorable geometries with respect to biological function. On the two chemical perturbation datasets,  Cdn  ranks the ground truth targets higher than  PdGrapher  on all six drugs (Table  3 ). However, the mutually low performance on doxorubicin (doxo.) in T98G cells may indicate a failure mode of both models.",
            "We generated 120 synthetic test datasets with hard and soft interventions. To generate observational data, we sampled Erdos-Renyi graphs with  N = 10 , 20 N 10 20 N=10,20 italic_N = 10 , 20  nodes and  E = N , 2  N E N 2 N E=N,2N italic_E = italic_N , 2 italic_N  expected edges; causal mechanism parameters; and observations of each variable, in topological order. We sampled  3  N 3 N 3N 3 italic_N  distinct subsets of 1-3 nodes ( N N N italic_N  each) as intervention targets. For hard interventions, we set  x  z  x z x\\leftarrow z italic_x  italic_z , where  z z z italic_z  is uniform. To emulate transcriptomics data, in which perturbation effects are measured in fold change, we introduce soft interventions:  x  c  f  (  x )  x c f subscript  x x\\leftarrow cf(\\pi_{x}) italic_x  italic_c italic_f ( italic_ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ) , where  c c c italic_c  is a positive scaling factor, with equal probability  c  1 less-than-or-greater-than c 1 c\\lessgtr 1 italic_c  1 . For our synthetic training set, we generated approximately 4000 datasets following the training set of  Sea , with hard interventions only. Full details are available in Appendix  B.2 .",
            "All source code will be made publicly available. Hyperparameter and implementation choices are described in Section  3.3 . Details regarding biological data pre-processing can be found in Section  4.1  and Appendix  B.1 . The raw data are freely available via the accession codes listed in Table  5 . Synthetic data generation is discussed in Appendix  B.2 . Details required to reproduce baselines are described in Sections  4.1  and  4.2 , as well as Appendix  C.1 ."
        ]
    },
    "id_table_3": {
        "caption": "Table 7:  Ablation studies. We re-train  Cdn  without pretrained aggregator weights, marginal estimates, or global statistics.",
        "table": "S4.SS1.SSS0.Px3.13.13.12.12",
        "footnotes": [],
        "references": [
            "Our model is composed of two modules: a frozen  causal featurizer , and a learned  differential network , which we refer to jointly as  Cdn  (Figure  2 ). The causal featurizer is a pretrained, amortized causal discovery model  (Wu et al.,  2024 )  that runs efficiently on up to a thousand nodes (Section  3.1 ), while the differential network is an axial-attention based classifier  (Ho et al.,  2020 )  that predicts the nodes whose data-generating mechanisms have changed (Section  3.2 ).",
            "We evaluate  Cdn  on five Perturb-seq  (Dixit et al.,  2016 )  datasets (genetic perturbations) from  Replogle et al. ( 2022 )  and  Nadig et al. ( 2024 ) ; as well as two Sci-Plex  (Srivatsan et al.,  2020 )  datasets (chemical perturbations) from  McFaline-Figueroa et al. ( 2024 ) . Each dataset is a real-valued matrix of gene expression levels: the number of examples  M M M italic_M  is the number of cells, the number of variables  N N N italic_N  is the number of genes, and each entry is a log-normalized count of how many copies of gene  j j j italic_j  was measured from cell  i i i italic_i  (Figure  3 A). In Perturb-seq datasets, we aim to recover the gene whose promoter was targeted by the CRISPR guide, and in Sci-Plex datasets, we aim to identify the gene that corresponds to the drugs intended target.",
            "We consider two splits: seen and unseen cell lines (Figure  3 B). In the former, models may be trained on approximately half of the perturbations from each cell line, and are evaluated on the unseen perturbations. In the latter, we hold out one cell line at a time, and models may be trained on data from the remaining cell lines. Note that not all baselines can be evaluated on unseen cell lines. To ensure that our train and test splits are sufficiently distinct, we cluster perturbations based on their log-fold change and assign each cluster to the same split.",
            "Table  2  reports our results on five Perturb-seq datasets. In the majority of cases,  Cdn  outperforms baselines, both in the seen and unseen cell line settings. This is more evident in Figure  4 , in which  Cdn  achieves higher recall at  k k k italic_k  at nearly all points on the curves. While no baseline is as consistent as  Cdn ,  GenePt  is surprisingly competitive against more complex baselines. This may indicate that natural language induces embedding spaces with favorable geometries with respect to biological function. On the two chemical perturbation datasets,  Cdn  ranks the ground truth targets higher than  PdGrapher  on all six drugs (Table  3 ). However, the mutually low performance on doxorubicin (doxo.) in T98G cells may indicate a failure mode of both models.",
            "All source code will be made publicly available. Hyperparameter and implementation choices are described in Section  3.3 . Details regarding biological data pre-processing can be found in Section  4.1  and Appendix  B.1 . The raw data are freely available via the accession codes listed in Table  5 . Synthetic data generation is discussed in Appendix  B.2 . Details required to reproduce baselines are described in Sections  4.1  and  4.2 , as well as Appendix  C.1 ."
        ]
    },
    "id_table_4": {
        "caption": "Table 8:   Ablation study on global statistics over synthetic datasets.  Mlp  and  Axial  use inverse covariance (same as pretraining).  Corr  was finetuned for correlation, and  Corr+Cov  was finetuned for correlation  and  covariance (concatenated).",
        "table": "S4.T4.138.136",
        "footnotes": [],
        "references": [
            "For the causal featurizer, we used a frozen, pretrained aggregator from  (Wu et al.,  2024 ) , which corresponded to the FCI-based marginal estimates  (Spirtes et al.,  1995 ) . The differential network was implemented with one axial attention layer, following the same architecture as the pretrained aggregator, with twice the model dimension (paired graphs). We swept over the number of layers (1-4) on synthetic data and found that a single layer performed the best. In terms of model design, we ablated replacing the attention architecture with a multi-layer perceptron (no communication between nodes, Table  4 ), as well as other components (Table  7 ) and summary statistics (Table  8 ). Due to the large graph sizes (adjacency matrices up to  1000 2 superscript 1000 2 1000^{2} 1000 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), standard 1D attention was intractable. Following  Sea , we used inverse covariance as the global statistic on synthetic data, and correlation on transcriptomics data.",
            "We evaluated  Cdn  on seven transcriptomics datasets, with comparisons to state-of-the-art models for these applications (Section  4.1 ). Note that these baselines all use various domain knowledge to inform their predictions. For completeness, we also benchmarked  Cdn  against multiple causal discovery algorithms for unknown interventions in variety of controlled settings (Section  4.2 ).",
            "Table  2  reports our results on five Perturb-seq datasets. In the majority of cases,  Cdn  outperforms baselines, both in the seen and unseen cell line settings. This is more evident in Figure  4 , in which  Cdn  achieves higher recall at  k k k italic_k  at nearly all points on the curves. While no baseline is as consistent as  Cdn ,  GenePt  is surprisingly competitive against more complex baselines. This may indicate that natural language induces embedding spaces with favorable geometries with respect to biological function. On the two chemical perturbation datasets,  Cdn  ranks the ground truth targets higher than  PdGrapher  on all six drugs (Table  3 ). However, the mutually low performance on doxorubicin (doxo.) in T98G cells may indicate a failure mode of both models.",
            "On synthetic data,  Cdn  achieves high performance across intervention types and data-generating mechanisms (Table  4 ), while running in seconds (Table  9 ). As an ablation study, we investigated replacing the differential network with a multi-layer perceptron, which does not model interactions between edges. On the hard interventions, the  Mlp  is sufficient for predicting intervention targets, perhaps by abusing marginal variances  (Reisach et al.,  2021 )  or other node-level artifacts of synthetic data. Once we consider soft interventions, however, the original  Cdn  formulation significantly outperforms the  Mlp  variant  indicating that graph-level information is essential.",
            "All source code will be made publicly available. Hyperparameter and implementation choices are described in Section  3.3 . Details regarding biological data pre-processing can be found in Section  4.1  and Appendix  B.1 . The raw data are freely available via the accession codes listed in Table  5 . Synthetic data generation is discussed in Appendix  B.2 . Details required to reproduce baselines are described in Sections  4.1  and  4.2 , as well as Appendix  C.1 ."
        ]
    },
    "id_table_5": {
        "caption": "Table 10:  Uncertainty quantification on Perturb-seq datasets by sub-sampling to  80 % percent 80 80\\% 80 %  of cells per perturbation (or 50, whichever is higher). Standard deviation reported over 5 rounds of sub-sampling.  Cdn  is also the most robust to sub-sampling, compared to baselines.  GenePt  performance is highly variable.",
        "table": "A4.EGx1",
        "footnotes": [],
        "references": [
            "All source code will be made publicly available. Hyperparameter and implementation choices are described in Section  3.3 . Details regarding biological data pre-processing can be found in Section  4.1  and Appendix  B.1 . The raw data are freely available via the accession codes listed in Table  5 . Synthetic data generation is discussed in Appendix  B.2 . Details required to reproduce baselines are described in Sections  4.1  and  4.2 , as well as Appendix  C.1 .",
            "We converted all single cell datasets to LogTP10K + 1 expression values (log-normalized, transcripts per 10,000 UMIs). Perturb-seq dataset variables represented genes that were mapped and filtered by the authors. Sci-Plex dataset variables represented genes that appeared in at least 5,000 cells (threshold chosen to achieve a similar number of genes). We performed differential expression analysis via the  scanpy  package  (Wolf et al.,  2018 ) , using the Wilcoxon signed-rank test  (Wilcoxon,  1945 )  with Benjamini-Hochberg p-value correction and a threshold of adjusted p-value  < 0.05 absent 0.05 <0.05 < 0.05 . Table  5  reports statistics of the raw, unprocessed datasets.",
            "For Perturb-seq datasets, we kept perturbations with  > 10 absent 10 >10 > 10  differentially-expressed genes (DEGs), and clustered them using k-means with  k = 200 k 200 k=200 italic_k = 200 , chosen heuristically based on log-fold change heatmaps (Figure  5 ). These clusters were used to inform data splits for seen cell lines, where the largest cluster was allocated to the training set, and all remaining clusters were split equally among train and test. The largest cluster(s) appear to contain perturbations with smaller effects. For Sci-Plex datasets, only 6 drug perturbations across 2 cell lines resulted in differential expression of their known protein targets (Supplementary Table 8 from  McFaline-Figueroa et al. ( 2024 ) ). Therefore, we used these exclusively as test sets. Table  6  reports statistics of the final, processed datasets. Figures  6  and  7  plot the full distribution of number of cells and DEGs per perturbation."
        ]
    },
    "id_table_6": {
        "caption": "Table 11:   Intervention target prediction results on synthetic datasets, extended results. Uncertainty is standard deviation over 5 distinct datasets. Metrics are averaged over all  3  N 3 N 3N 3 italic_N  perturbations for a given dataset (1-3 targets).",
        "table": "A4.EGx2",
        "footnotes": [],
        "references": [
            "There are two considerations that motivate further experiments in controlled settings. First, while it would be ideal to evaluate all algorithms on real data, current causal discovery algorithms that support unknown interventions are not tractable on datasets with more than tens of variables. In fact, many baselines require hours on even  N = 10 N 10 N=10 italic_N = 10  datasets, and they do not scale favorably (Table  9 ). Our transcriptomics datasets contain hundreds of genes, even after filtering to those that are differentially expressed (Figures  6  and  7 ). On the other hand, existing models for biological perturbations all rely on some form of domain knowledge, and their performance is inseparable from the choice and quality of these external data. Here, synthetic settings allow us to assess the models capacity to predict intervention targets in isolation.",
            "For Perturb-seq datasets, we kept perturbations with  > 10 absent 10 >10 > 10  differentially-expressed genes (DEGs), and clustered them using k-means with  k = 200 k 200 k=200 italic_k = 200 , chosen heuristically based on log-fold change heatmaps (Figure  5 ). These clusters were used to inform data splits for seen cell lines, where the largest cluster was allocated to the training set, and all remaining clusters were split equally among train and test. The largest cluster(s) appear to contain perturbations with smaller effects. For Sci-Plex datasets, only 6 drug perturbations across 2 cell lines resulted in differential expression of their known protein targets (Supplementary Table 8 from  McFaline-Figueroa et al. ( 2024 ) ). Therefore, we used these exclusively as test sets. Table  6  reports statistics of the final, processed datasets. Figures  6  and  7  plot the full distribution of number of cells and DEGs per perturbation."
        ]
    },
    "id_table_7": {
        "caption": "",
        "table": "A2.SS1.4.4.4",
        "footnotes": [
            "",
            "",
            ""
        ],
        "references": [
            "For the causal featurizer, we used a frozen, pretrained aggregator from  (Wu et al.,  2024 ) , which corresponded to the FCI-based marginal estimates  (Spirtes et al.,  1995 ) . The differential network was implemented with one axial attention layer, following the same architecture as the pretrained aggregator, with twice the model dimension (paired graphs). We swept over the number of layers (1-4) on synthetic data and found that a single layer performed the best. In terms of model design, we ablated replacing the attention architecture with a multi-layer perceptron (no communication between nodes, Table  4 ), as well as other components (Table  7 ) and summary statistics (Table  8 ). Due to the large graph sizes (adjacency matrices up to  1000 2 superscript 1000 2 1000^{2} 1000 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), standard 1D attention was intractable. Following  Sea , we used inverse covariance as the global statistic on synthetic data, and correlation on transcriptomics data.",
            "There are two considerations that motivate further experiments in controlled settings. First, while it would be ideal to evaluate all algorithms on real data, current causal discovery algorithms that support unknown interventions are not tractable on datasets with more than tens of variables. In fact, many baselines require hours on even  N = 10 N 10 N=10 italic_N = 10  datasets, and they do not scale favorably (Table  9 ). Our transcriptomics datasets contain hundreds of genes, even after filtering to those that are differentially expressed (Figures  6  and  7 ). On the other hand, existing models for biological perturbations all rely on some form of domain knowledge, and their performance is inseparable from the choice and quality of these external data. Here, synthetic settings allow us to assess the models capacity to predict intervention targets in isolation.",
            "For Perturb-seq datasets, we kept perturbations with  > 10 absent 10 >10 > 10  differentially-expressed genes (DEGs), and clustered them using k-means with  k = 200 k 200 k=200 italic_k = 200 , chosen heuristically based on log-fold change heatmaps (Figure  5 ). These clusters were used to inform data splits for seen cell lines, where the largest cluster was allocated to the training set, and all remaining clusters were split equally among train and test. The largest cluster(s) appear to contain perturbations with smaller effects. For Sci-Plex datasets, only 6 drug perturbations across 2 cell lines resulted in differential expression of their known protein targets (Supplementary Table 8 from  McFaline-Figueroa et al. ( 2024 ) ). Therefore, we used these exclusively as test sets. Table  6  reports statistics of the final, processed datasets. Figures  6  and  7  plot the full distribution of number of cells and DEGs per perturbation.",
            "We run ablation studies on the model architecture (Table  7 ) by re-training  Cdn  without pretrained aggregator weights, global statistics, or marginal estimates. We find that pretrained weights and global correlation are essential to model performance. The marginal estimates are of mixed importance: they are beneficial on the genome-wide (gw) dataset and Jurkat, but less on the others."
        ]
    },
    "id_table_8": {
        "caption": "",
        "table": "A2.SS1.6.2.2",
        "footnotes": [],
        "references": [
            "For the causal featurizer, we used a frozen, pretrained aggregator from  (Wu et al.,  2024 ) , which corresponded to the FCI-based marginal estimates  (Spirtes et al.,  1995 ) . The differential network was implemented with one axial attention layer, following the same architecture as the pretrained aggregator, with twice the model dimension (paired graphs). We swept over the number of layers (1-4) on synthetic data and found that a single layer performed the best. In terms of model design, we ablated replacing the attention architecture with a multi-layer perceptron (no communication between nodes, Table  4 ), as well as other components (Table  7 ) and summary statistics (Table  8 ). Due to the large graph sizes (adjacency matrices up to  1000 2 superscript 1000 2 1000^{2} 1000 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), standard 1D attention was intractable. Following  Sea , we used inverse covariance as the global statistic on synthetic data, and correlation on transcriptomics data.",
            "where  c i subscript c i c_{i} italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  are sampled at random per synthetic dataset. This choice is inspired by the fact that biological perturbation effects are measured in fold-change. Here, the adjacency matrices are the same, but global statistics differ. In particular, we focus on two statistics: the correlation matrix  R R R italic_R  and the covariance matrix    \\Sigma roman_ . Note that while these inputs differ slightly from our main experiments (reasons discussed in Appendix  D ), we show that they still achieve reasonable performance in Table  8 .",
            "Figure  8  depicts the low, but non-trivial proportion of differentially expressed genes for which  Gears  was unable to make a prediction, due to lack of node coverage in their processed gene ontology graph  (Ashburner et al.,  2000 ) . These genes were not considered in the rankings or evaluations for  Gears .",
            "Table  8  ablates variants of  Cdn  trained with different global statistics (but initialized with the inverse covariance pretrained weights) on synthetic data. The default summary statistic ( Mlp ,  Axial ) is inverse covariance.  Corr  denotes the correlation version, later finetuned on Perturb-seq data (since correlation is much easier to compute on large graphs, compared to inverse covariance). The  Corr+Cov  version aligns exactly with our theoretical intuition, and performs well in most settings (polynomial soft is the exception). This model modified the global layer to take an input of size  N  N  2 N N 2 N\\times N\\times 2 italic_N  italic_N  2 , where each embedding was initialized to a distinct copy of the original. However, the inverse covariance version still performed the best, perhaps since there is no mismatch between the pretraining and finetuning statistics."
        ]
    },
    "id_table_9": {
        "caption": "",
        "table": "A4.EGx3",
        "footnotes": [],
        "references": [
            "There are two considerations that motivate further experiments in controlled settings. First, while it would be ideal to evaluate all algorithms on real data, current causal discovery algorithms that support unknown interventions are not tractable on datasets with more than tens of variables. In fact, many baselines require hours on even  N = 10 N 10 N=10 italic_N = 10  datasets, and they do not scale favorably (Table  9 ). Our transcriptomics datasets contain hundreds of genes, even after filtering to those that are differentially expressed (Figures  6  and  7 ). On the other hand, existing models for biological perturbations all rely on some form of domain knowledge, and their performance is inseparable from the choice and quality of these external data. Here, synthetic settings allow us to assess the models capacity to predict intervention targets in isolation.",
            "On synthetic data,  Cdn  achieves high performance across intervention types and data-generating mechanisms (Table  4 ), while running in seconds (Table  9 ). As an ablation study, we investigated replacing the differential network with a multi-layer perceptron, which does not model interactions between edges. On the hard interventions, the  Mlp  is sufficient for predicting intervention targets, perhaps by abusing marginal variances  (Reisach et al.,  2021 )  or other node-level artifacts of synthetic data. Once we consider soft interventions, however, the original  Cdn  formulation significantly outperforms the  Mlp  variant  indicating that graph-level information is essential.",
            "We also compared the runtimes of various algorithms on the Perturb-seq and synthetic datasets. On the Perturb-seq data, all models finished running within minutes with the exception of  Gears  (Figure  9 ). Runtimes of the various causal algorithms varied significantly (Table  9 ). The slowest method was  Dcdi , with an average runtime of around 10 hours on  N = 20 N 20 N=20 italic_N = 20  datasets, while the fastest were  Ut-Igsp  and the  Mlp  variant of  Cdn . All models were benchmarked on equivalent hardware (A6000 GPU, 1 CPU core)."
        ]
    },
    "id_table_10": {
        "caption": "",
        "table": "A4.T7.73.73",
        "footnotes": [],
        "references": [
            "Due to space limitations, we report uncertainty estimates in Table  10 . Multiple baselines produce deterministic results ( Linear ,  GenePt ), so instead of model randomness, we report uncertainties over the sampling of single cells. Specifically, for each perturbation with  M M M italic_M  cells, we sample"
        ]
    },
    "id_table_11": {
        "caption": "",
        "table": "A4.T8.138.138",
        "footnotes": [],
        "references": [
            "We compare against discrete and continuous causal discovery algorithms for unknown interventions.  Ut-Igsp   (Squires et al.,  2020 )  infers causal graphs and unknown targets by greedily selecting the permutation of variables that minimizes their proposed score function.  Dcdi   (Brouillard et al.,  2020 )  and  Bacadi   (Hagele et al.,  2023 )  are continuous causal discovery algorithms that fit generative models to the data, where the causal graph and intervention targets are model parameters. The  -G  and  -Dsf  suffixes on  Dcdi  correspond to Gaussian and deep sigmoidal flow parametrizations of the likelihood.  Bacadi  is evaluated here using the fully-connected implementation (better performance), with the linear version in Table  11 . Its  -E  and  -M  suffixes indicate empirical (standard) and mixture (bootstrap) variants.",
            "Table  11  reports results on all synthetic test datasets, averaging over all interventions for each dataset."
        ]
    },
    "id_table_12": {
        "caption": "",
        "table": "A4.SS0.SSS0.Px4.2.fig1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_13": {
        "caption": "",
        "table": "A4.T10.102.100",
        "footnotes": [],
        "references": []
    },
    "id_table_14": {
        "caption": "",
        "table": "A4.T11.268.266",
        "footnotes": [],
        "references": []
    }
}