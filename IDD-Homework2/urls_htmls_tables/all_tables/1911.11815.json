{
    "PAPER'S NUMBER OF TABLES": 15,
    "S4.T1": {
        "caption": "Table 1: Default setting for key parameters.",
        "table": "<table id=\"S4.T1.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.6.7.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.6.7.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.6.7.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Parameter</span></th>\n<th id=\"S4.T1.6.7.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.6.7.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Description</span></th>\n<th id=\"S4.T1.6.7.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.6.7.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Value</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><math id=\"S4.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"m\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mi mathsize=\"90%\" id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\">m</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><ci id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">ğ‘š</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">m</annotation></semantics></math></td>\n<td id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Number of worker devices.</span></td>\n<td id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">100</span></td>\n</tr>\n<tr id=\"S4.T1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><math id=\"S4.T1.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"c\" display=\"inline\"><semantics id=\"S4.T1.2.2.1.m1.1a\"><mi mathsize=\"90%\" id=\"S4.T1.2.2.1.m1.1.1\" xref=\"S4.T1.2.2.1.m1.1.1.cmml\">c</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.2.2.1.m1.1b\"><ci id=\"S4.T1.2.2.1.m1.1.1.cmml\" xref=\"S4.T1.2.2.1.m1.1.1\">ğ‘</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.2.2.1.m1.1c\">c</annotation></semantics></math></td>\n<td id=\"S4.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Number of compromised worker devices.</span></td>\n<td id=\"S4.T1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">20</span></td>\n</tr>\n<tr id=\"S4.T1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><math id=\"S4.T1.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"p\" display=\"inline\"><semantics id=\"S4.T1.3.3.1.m1.1a\"><mi mathsize=\"90%\" id=\"S4.T1.3.3.1.m1.1.1\" xref=\"S4.T1.3.3.1.m1.1.1.cmml\">p</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.3.3.1.m1.1b\"><ci id=\"S4.T1.3.3.1.m1.1.1.cmml\" xref=\"S4.T1.3.3.1.m1.1.1\">ğ‘</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.3.3.1.m1.1c\">p</annotation></semantics></math></td>\n<td id=\"S4.T1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Degree of Non-IID.</span></td>\n<td id=\"S4.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.5</span></td>\n</tr>\n<tr id=\"S4.T1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><math id=\"S4.T1.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\epsilon\" display=\"inline\"><semantics id=\"S4.T1.4.4.1.m1.1a\"><mi mathsize=\"90%\" id=\"S4.T1.4.4.1.m1.1.1\" xref=\"S4.T1.4.4.1.m1.1.1.cmml\">Ïµ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.4.4.1.m1.1b\"><ci id=\"S4.T1.4.4.1.m1.1.1.cmml\" xref=\"S4.T1.4.4.1.m1.1.1\">italic-Ïµ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.4.4.1.m1.1c\">\\epsilon</annotation></semantics></math></td>\n<td id=\"S4.T1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Distance parameter for Krum attacks.</span></td>\n<td id=\"S4.T1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.01</span></td>\n</tr>\n<tr id=\"S4.T1.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><math id=\"S4.T1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\beta\" display=\"inline\"><semantics id=\"S4.T1.5.5.1.m1.1a\"><mi mathsize=\"90%\" id=\"S4.T1.5.5.1.m1.1.1\" xref=\"S4.T1.5.5.1.m1.1.1.cmml\">Î²</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.5.5.1.m1.1b\"><ci id=\"S4.T1.5.5.1.m1.1.1.cmml\" xref=\"S4.T1.5.5.1.m1.1.1\">ğ›½</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.5.5.1.m1.1c\">\\beta</annotation></semantics></math></td>\n<td id=\"S4.T1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><span id=\"S4.T1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Parameter of trimmed mean.</span></td>\n<td id=\"S4.T1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 4.0pt;\"><math id=\"S4.T1.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"c\" display=\"inline\"><semantics id=\"S4.T1.6.6.2.m1.1a\"><mi mathsize=\"90%\" id=\"S4.T1.6.6.2.m1.1.1\" xref=\"S4.T1.6.6.2.m1.1.1.cmml\">c</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.6.6.2.m1.1b\"><ci id=\"S4.T1.6.6.2.m1.1.1.cmml\" xref=\"S4.T1.6.6.2.m1.1.1\">ğ‘</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.6.6.2.m1.1c\">c</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Parameter setting:Â  We describe parameter setting for the federated learning algorithms and our attacks. TableÂ 1 summarizes the default setting for key parameters. We use MXNetÂ [12] to implement federated learning and attacks. We repeat each experiment for 50 trials and report the average results. We observed that the variances are very small, so we omit them for simplicity."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Testing error rates of various attacks.",
        "table": "<table id=\"S4.T2.sf1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.sf1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf1.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S4.T2.sf1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">NoAttack</span></td>\n<td id=\"S4.T2.sf1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Gaussian</span></td>\n<td id=\"S4.T2.sf1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">LabelFlip</span></td>\n<td id=\"S4.T2.sf1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Partial</span></td>\n<td id=\"S4.T2.sf1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Full</span></td>\n</tr>\n<tr id=\"S4.T2.sf1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></td>\n<td id=\"S4.T2.sf1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S4.T2.sf1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T2.sf1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T2.sf1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.72</span></td>\n<td id=\"S4.T2.sf1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.80</span></td>\n</tr>\n<tr id=\"S4.T2.sf1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></td>\n<td id=\"S4.T2.sf1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S4.T2.sf1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.11</span></td>\n<td id=\"S4.T2.sf1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T2.sf1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.23</span></td>\n<td id=\"S4.T2.sf1.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.52</span></td>\n</tr>\n<tr id=\"S4.T2.sf1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></td>\n<td id=\"S4.T2.sf1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T2.sf1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T2.sf1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.15</span></td>\n<td id=\"S4.T2.sf1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.19</span></td>\n<td id=\"S4.T2.sf1.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.29</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Our attacks are effective: TableÂ 2e shows the testing error rates of the compared attacks on the four datasets.\nFirst, these results show that our attacks are effective and substantially outperform existing attacks, i.e., our attacks result in higher error rates. For instance, when dataset is MNIST, classifier is LR, and aggregation rule is Krum, our partial knowledge attack increases the error rate from 0.14 to 0.72 (around 400% relative increase).\nGaussian attacks only increase the error rates in several cases, e.g., median aggregation rule for Fashion-MNIST, and trimmed mean and median for CH-MNIST. Label flipping attacks can increase the error rates for DNN classifiers in some cases but have limited success for LR classifiers.",
            "Alternative training strategy:Â  Each iteration results in a global model. Instead of selecting the last global model as the final model, an alternative training strategy is to select the global model that has the lowest testing error rate.333We give advantages to the alternative training strategy since we use testing error rate to select the global model. TableÂ 3 shows the testing error rates of various attacks on the DNN classifier for MNIST, when such alternative training strategy is adopted. In these experiments, our attacks attack each iteration of federated learning, and the column â€œNoAttackâ€ corresponds to the scenarios where no iterations are attacked. Compared to TableÂ 2b, this alternative training strategy is slightly more secure against our attacks. However, our attacks are still effective. For instance, for the Krum, trimmed mean, and median aggregation rules, our partial knowledge attacks still increase the testing error rates by 590%, 100%, and 83%, respectively.  Another training strategy is to roll back to a few iterations ago if the master device detects an unusual increase of training error rate. However, such training strategy is not applicable because the training error rates of the global models still decrease until convergence when we perform our attacks in each iteration. In other words, there are no unusual increases of training error rates."
        ]
    },
    "S4.T2.sf1": {
        "caption": "(a) LR classifier, MNIST",
        "table": "<table id=\"S4.T2.sf1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.sf1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf1.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S4.T2.sf1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">NoAttack</span></td>\n<td id=\"S4.T2.sf1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Gaussian</span></td>\n<td id=\"S4.T2.sf1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">LabelFlip</span></td>\n<td id=\"S4.T2.sf1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Partial</span></td>\n<td id=\"S4.T2.sf1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Full</span></td>\n</tr>\n<tr id=\"S4.T2.sf1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></td>\n<td id=\"S4.T2.sf1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S4.T2.sf1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T2.sf1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T2.sf1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.72</span></td>\n<td id=\"S4.T2.sf1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.80</span></td>\n</tr>\n<tr id=\"S4.T2.sf1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></td>\n<td id=\"S4.T2.sf1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S4.T2.sf1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.11</span></td>\n<td id=\"S4.T2.sf1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T2.sf1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.23</span></td>\n<td id=\"S4.T2.sf1.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.52</span></td>\n</tr>\n<tr id=\"S4.T2.sf1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></td>\n<td id=\"S4.T2.sf1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T2.sf1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T2.sf1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.15</span></td>\n<td id=\"S4.T2.sf1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.19</span></td>\n<td id=\"S4.T2.sf1.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf1.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.29</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Deep neural networks (DNN). For MNIST, Fashion-MNIST, and Breast Cancer Wisconsin (Diagnostic), we use a DNN with the architecture described in TableÂ 7a in Appendix. We use ResNet20Â [28] for CH-MNIST. Our DNN architecture does not necessarily achieve the smallest error rates for the considered datasets, as our goal is not to search for the best DNN architecture. Our goal is to show that our attacks can increase the testing error rates of the learnt DNN classifiers.",
            "Parameter setting:Â  We describe parameter setting for the federated learning algorithms and our attacks. TableÂ 1 summarizes the default setting for key parameters. We use MXNetÂ [12] to implement federated learning and attacks. We repeat each experiment for 50 trials and report the average results. We observed that the variances are very small, so we omit them for simplicity.",
            "Our attacks are effective: TableÂ 2e shows the testing error rates of the compared attacks on the four datasets.\nFirst, these results show that our attacks are effective and substantially outperform existing attacks, i.e., our attacks result in higher error rates. For instance, when dataset is MNIST, classifier is LR, and aggregation rule is Krum, our partial knowledge attack increases the error rate from 0.14 to 0.72 (around 400% relative increase).\nGaussian attacks only increase the error rates in several cases, e.g., median aggregation rule for Fashion-MNIST, and trimmed mean and median for CH-MNIST. Label flipping attacks can increase the error rates for DNN classifiers in some cases but have limited success for LR classifiers.",
            "Impact of the percentage of compromised worker devices:Â  FigureÂ 2 shows the error rates of different attacks as the percentage of compromised worker devices increases on MNIST.\nOur attacks increase the error rates significantly as we compromise more worker devices; label flipping only slightly increases the error rates; and Gaussian attacks have no notable impact on the error rates. Two exceptions are that Krumâ€™s error rates decrease when the percentage of compromised worker devices increases from 5% to 10% in FigureÂ 2a and from 10% to 15% in FigureÂ 2d. We suspect the reason is that Krum selects one local model as a global model in each iteration. We have similar observations on the other datasets. Therefore, we omit the corresponding results for simplicity.",
            "Worker devices can perform multiple rounds of stochastic gradient descent to update their local models. FigureÂ 4a shows the impact of the number of rounds on the testing error rates of our attack. The testing error rates decrease as we use more rounds of stochastic gradient descent for both no attack and our partial knowledge attack. This is because more rounds of stochastic gradient descent lead to more accurate local models, and the local models on different worker devices are less diverse, leaving a smaller attack space. However, our attack still increases the error rates substantially even if we use more rounds. For instance, our attack still increases the error rate by more than 30% when using 10 rounds of stochastic gradient descent. We note that a large number of rounds result in large computational cost for worker devices, which may be unacceptable for resource-constrained devices such as mobile phones and IoT devices.",
            "Alternative training strategy:Â  Each iteration results in a global model. Instead of selecting the last global model as the final model, an alternative training strategy is to select the global model that has the lowest testing error rate.333We give advantages to the alternative training strategy since we use testing error rate to select the global model. TableÂ 3 shows the testing error rates of various attacks on the DNN classifier for MNIST, when such alternative training strategy is adopted. In these experiments, our attacks attack each iteration of federated learning, and the column â€œNoAttackâ€ corresponds to the scenarios where no iterations are attacked. Compared to TableÂ 2b, this alternative training strategy is slightly more secure against our attacks. However, our attacks are still effective. For instance, for the Krum, trimmed mean, and median aggregation rules, our partial knowledge attacks still increase the testing error rates by 590%, 100%, and 83%, respectively.  Another training strategy is to roll back to a few iterations ago if the master device detects an unusual increase of training error rate. However, such training strategy is not applicable because the training error rates of the global models still decrease until convergence when we perform our attacks in each iteration. In other words, there are no unusual increases of training error rates.",
            "We craft local models based on one aggregation rule and show the attack effectiveness for other aggregation rules.\nTableÂ 4 shows the transferability between aggregation rules, where MNIST and LR classifier are considered.\nWe observe different levels of transferability between aggregation rules. Specifically, Krum based attack can well transfer to trimmed mean and median, e.g., Krum based attack increases the error rate from 0.12 to 0.15 (25% relative increase) for trimmed mean, and from 0.13 to 0.18 (38% relative increase) for median. Trimmed mean based attack does not transfer to Krum but transfers to median well. For instance, trimmed mean based attack increases the error rates from 0.13 to 0.20 (54% relative increase) for median.",
            "We consider the two scenarios because they represent two extremes for distributing data (concentrated or evenly distributed) and we expect one extreme to maximize attack effectiveness.\nTableÂ 5 compares BGA with our attacks. We observe that BGA has limited success at attacking Byzantine-robust aggregation rules, while our attacks can substantially increase the testing error rates. We note that if the federated learning uses the mean aggregation rule BGA is still successful. For instance, when the mean aggregation rule is used, BGA can increase the testing error rate by 50% when distributing the poisoned data to the compromised worker devices uniformly at random. However, when applying our attacks for trimmed mean to attack the mean aggregation rule, we can increase the testing error rates substantially more (see the last two cells in the second row of TableÂ 5).",
            "Defense results:Â  TableÂ 6 shows the defense results of ERR, FLR, and Union, where partial knowledge attacks are considered. We use the default parameter setting discussed in SectionÂ 1, e.g., 100 worker devices, 20% of compromised worker devices, MNIST dataset, and LR classifier. Moreover, we sample 100 testing examples uniformly at random as the validation dataset. Each row of the table corresponds to a defense, e.g., Krum + ERR means that the master device uses ERR to remove the potentially malicious local models and uses Krum as the aggregation rule. Each column indicates the attackerâ€™s assumed aggregation rule when performing attacks, e.g., the column â€œKrumâ€ corresponds to attacks that are based on Krum. We have several observations.",
            "Bulyan is based on Krum. We apply our attacks for Krum to attack Bulyan. TableÂ 7b shows results of attacking Bulyan. The dataset is MNIST, the classifier is logistic regression, m=100ğ‘š100m=100, c=20ğ‘20c=20, Î¸=mâˆ’2â€‹cğœƒğ‘š2ğ‘\\theta=m-2c (Bulyan selects Î¸ğœƒ\\theta local models using Krum), and Î³=Î¸âˆ’2â€‹cğ›¾ğœƒ2ğ‘\\gamma=\\theta-2c (Bulyan takes the mean of Î³ğ›¾\\gamma parameters).\nOur results show that our attacks to Krum can transfer to Bulyan. Specifically, our partial knowledge attack increases the error rate by around 150%, while our full knowledge attack increases the error rate by 165%.",
            "Experimental results: TableÂ 8 empirically compares the deviation goal and directed deviation goal, where MNIST and LR classifier are used.\nFor Krum, both goals achieve high testing error rates. However, for trimmed mean and median, the directed deviation goal achieves significantly higher testing error rates than the deviation goal."
        ]
    },
    "S4.T2.sf2": {
        "caption": "(b) DNN classifier, MNIST",
        "table": "<table id=\"S4.T2.sf2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.sf2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf2.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S4.T2.sf2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">NoAttack</span></td>\n<td id=\"S4.T2.sf2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Gaussian</span></td>\n<td id=\"S4.T2.sf2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">LabelFlip</span></td>\n<td id=\"S4.T2.sf2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Partial</span></td>\n<td id=\"S4.T2.sf2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Full</span></td>\n</tr>\n<tr id=\"S4.T2.sf2.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></td>\n<td id=\"S4.T2.sf2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.11</span></td>\n<td id=\"S4.T2.sf2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.10</span></td>\n<td id=\"S4.T2.sf2.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.10</span></td>\n<td id=\"S4.T2.sf2.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.75</span></td>\n<td id=\"S4.T2.sf2.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.77</span></td>\n</tr>\n<tr id=\"S4.T2.sf2.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf2.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></td>\n<td id=\"S4.T2.sf2.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.06</span></td>\n<td id=\"S4.T2.sf2.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.07</span></td>\n<td id=\"S4.T2.sf2.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.07</span></td>\n<td id=\"S4.T2.sf2.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S4.T2.sf2.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.23</span></td>\n</tr>\n<tr id=\"S4.T2.sf2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf2.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></td>\n<td id=\"S4.T2.sf2.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.06</span></td>\n<td id=\"S4.T2.sf2.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.06</span></td>\n<td id=\"S4.T2.sf2.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.16</span></td>\n<td id=\"S4.T2.sf2.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.28</span></td>\n<td id=\"S4.T2.sf2.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf2.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.32</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Deep neural networks (DNN). For MNIST, Fashion-MNIST, and Breast Cancer Wisconsin (Diagnostic), we use a DNN with the architecture described in TableÂ 7a in Appendix. We use ResNet20Â [28] for CH-MNIST. Our DNN architecture does not necessarily achieve the smallest error rates for the considered datasets, as our goal is not to search for the best DNN architecture. Our goal is to show that our attacks can increase the testing error rates of the learnt DNN classifiers.",
            "Parameter setting:Â  We describe parameter setting for the federated learning algorithms and our attacks. TableÂ 1 summarizes the default setting for key parameters. We use MXNetÂ [12] to implement federated learning and attacks. We repeat each experiment for 50 trials and report the average results. We observed that the variances are very small, so we omit them for simplicity.",
            "Our attacks are effective: TableÂ 2e shows the testing error rates of the compared attacks on the four datasets.\nFirst, these results show that our attacks are effective and substantially outperform existing attacks, i.e., our attacks result in higher error rates. For instance, when dataset is MNIST, classifier is LR, and aggregation rule is Krum, our partial knowledge attack increases the error rate from 0.14 to 0.72 (around 400% relative increase).\nGaussian attacks only increase the error rates in several cases, e.g., median aggregation rule for Fashion-MNIST, and trimmed mean and median for CH-MNIST. Label flipping attacks can increase the error rates for DNN classifiers in some cases but have limited success for LR classifiers.",
            "Impact of the percentage of compromised worker devices:Â  FigureÂ 2 shows the error rates of different attacks as the percentage of compromised worker devices increases on MNIST.\nOur attacks increase the error rates significantly as we compromise more worker devices; label flipping only slightly increases the error rates; and Gaussian attacks have no notable impact on the error rates. Two exceptions are that Krumâ€™s error rates decrease when the percentage of compromised worker devices increases from 5% to 10% in FigureÂ 2a and from 10% to 15% in FigureÂ 2d. We suspect the reason is that Krum selects one local model as a global model in each iteration. We have similar observations on the other datasets. Therefore, we omit the corresponding results for simplicity.",
            "Worker devices can perform multiple rounds of stochastic gradient descent to update their local models. FigureÂ 4a shows the impact of the number of rounds on the testing error rates of our attack. The testing error rates decrease as we use more rounds of stochastic gradient descent for both no attack and our partial knowledge attack. This is because more rounds of stochastic gradient descent lead to more accurate local models, and the local models on different worker devices are less diverse, leaving a smaller attack space. However, our attack still increases the error rates substantially even if we use more rounds. For instance, our attack still increases the error rate by more than 30% when using 10 rounds of stochastic gradient descent. We note that a large number of rounds result in large computational cost for worker devices, which may be unacceptable for resource-constrained devices such as mobile phones and IoT devices.",
            "Alternative training strategy:Â  Each iteration results in a global model. Instead of selecting the last global model as the final model, an alternative training strategy is to select the global model that has the lowest testing error rate.333We give advantages to the alternative training strategy since we use testing error rate to select the global model. TableÂ 3 shows the testing error rates of various attacks on the DNN classifier for MNIST, when such alternative training strategy is adopted. In these experiments, our attacks attack each iteration of federated learning, and the column â€œNoAttackâ€ corresponds to the scenarios where no iterations are attacked. Compared to TableÂ 2b, this alternative training strategy is slightly more secure against our attacks. However, our attacks are still effective. For instance, for the Krum, trimmed mean, and median aggregation rules, our partial knowledge attacks still increase the testing error rates by 590%, 100%, and 83%, respectively.  Another training strategy is to roll back to a few iterations ago if the master device detects an unusual increase of training error rate. However, such training strategy is not applicable because the training error rates of the global models still decrease until convergence when we perform our attacks in each iteration. In other words, there are no unusual increases of training error rates.",
            "We craft local models based on one aggregation rule and show the attack effectiveness for other aggregation rules.\nTableÂ 4 shows the transferability between aggregation rules, where MNIST and LR classifier are considered.\nWe observe different levels of transferability between aggregation rules. Specifically, Krum based attack can well transfer to trimmed mean and median, e.g., Krum based attack increases the error rate from 0.12 to 0.15 (25% relative increase) for trimmed mean, and from 0.13 to 0.18 (38% relative increase) for median. Trimmed mean based attack does not transfer to Krum but transfers to median well. For instance, trimmed mean based attack increases the error rates from 0.13 to 0.20 (54% relative increase) for median.",
            "We consider the two scenarios because they represent two extremes for distributing data (concentrated or evenly distributed) and we expect one extreme to maximize attack effectiveness.\nTableÂ 5 compares BGA with our attacks. We observe that BGA has limited success at attacking Byzantine-robust aggregation rules, while our attacks can substantially increase the testing error rates. We note that if the federated learning uses the mean aggregation rule BGA is still successful. For instance, when the mean aggregation rule is used, BGA can increase the testing error rate by 50% when distributing the poisoned data to the compromised worker devices uniformly at random. However, when applying our attacks for trimmed mean to attack the mean aggregation rule, we can increase the testing error rates substantially more (see the last two cells in the second row of TableÂ 5).",
            "Defense results:Â  TableÂ 6 shows the defense results of ERR, FLR, and Union, where partial knowledge attacks are considered. We use the default parameter setting discussed in SectionÂ 1, e.g., 100 worker devices, 20% of compromised worker devices, MNIST dataset, and LR classifier. Moreover, we sample 100 testing examples uniformly at random as the validation dataset. Each row of the table corresponds to a defense, e.g., Krum + ERR means that the master device uses ERR to remove the potentially malicious local models and uses Krum as the aggregation rule. Each column indicates the attackerâ€™s assumed aggregation rule when performing attacks, e.g., the column â€œKrumâ€ corresponds to attacks that are based on Krum. We have several observations.",
            "Bulyan is based on Krum. We apply our attacks for Krum to attack Bulyan. TableÂ 7b shows results of attacking Bulyan. The dataset is MNIST, the classifier is logistic regression, m=100ğ‘š100m=100, c=20ğ‘20c=20, Î¸=mâˆ’2â€‹cğœƒğ‘š2ğ‘\\theta=m-2c (Bulyan selects Î¸ğœƒ\\theta local models using Krum), and Î³=Î¸âˆ’2â€‹cğ›¾ğœƒ2ğ‘\\gamma=\\theta-2c (Bulyan takes the mean of Î³ğ›¾\\gamma parameters).\nOur results show that our attacks to Krum can transfer to Bulyan. Specifically, our partial knowledge attack increases the error rate by around 150%, while our full knowledge attack increases the error rate by 165%.",
            "Experimental results: TableÂ 8 empirically compares the deviation goal and directed deviation goal, where MNIST and LR classifier are used.\nFor Krum, both goals achieve high testing error rates. However, for trimmed mean and median, the directed deviation goal achieves significantly higher testing error rates than the deviation goal."
        ]
    },
    "S4.T2.sf3": {
        "caption": "(c) DNN classifier, Fashion-MNIST",
        "table": "<table id=\"S4.T2.sf3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.sf3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf3.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S4.T2.sf3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">NoAttack</span></td>\n<td id=\"S4.T2.sf3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Gaussian</span></td>\n<td id=\"S4.T2.sf3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">LabelFlip</span></td>\n<td id=\"S4.T2.sf3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Partial</span></td>\n<td id=\"S4.T2.sf3.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Full</span></td>\n</tr>\n<tr id=\"S4.T2.sf3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf3.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></td>\n<td id=\"S4.T2.sf3.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.16</span></td>\n<td id=\"S4.T2.sf3.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.16</span></td>\n<td id=\"S4.T2.sf3.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.16</span></td>\n<td id=\"S4.T2.sf3.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.90</span></td>\n<td id=\"S4.T2.sf3.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.91</span></td>\n</tr>\n<tr id=\"S4.T2.sf3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf3.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></td>\n<td id=\"S4.T2.sf3.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.10</span></td>\n<td id=\"S4.T2.sf3.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.10</span></td>\n<td id=\"S4.T2.sf3.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S4.T2.sf3.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.26</span></td>\n<td id=\"S4.T2.sf3.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.28</span></td>\n</tr>\n<tr id=\"S4.T2.sf3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf3.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></td>\n<td id=\"S4.T2.sf3.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.09</span></td>\n<td id=\"S4.T2.sf3.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S4.T2.sf3.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S4.T2.sf3.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.21</span></td>\n<td id=\"S4.T2.sf3.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf3.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.29</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Deep neural networks (DNN). For MNIST, Fashion-MNIST, and Breast Cancer Wisconsin (Diagnostic), we use a DNN with the architecture described in TableÂ 7a in Appendix. We use ResNet20Â [28] for CH-MNIST. Our DNN architecture does not necessarily achieve the smallest error rates for the considered datasets, as our goal is not to search for the best DNN architecture. Our goal is to show that our attacks can increase the testing error rates of the learnt DNN classifiers.",
            "Parameter setting:Â  We describe parameter setting for the federated learning algorithms and our attacks. TableÂ 1 summarizes the default setting for key parameters. We use MXNetÂ [12] to implement federated learning and attacks. We repeat each experiment for 50 trials and report the average results. We observed that the variances are very small, so we omit them for simplicity.",
            "Our attacks are effective: TableÂ 2e shows the testing error rates of the compared attacks on the four datasets.\nFirst, these results show that our attacks are effective and substantially outperform existing attacks, i.e., our attacks result in higher error rates. For instance, when dataset is MNIST, classifier is LR, and aggregation rule is Krum, our partial knowledge attack increases the error rate from 0.14 to 0.72 (around 400% relative increase).\nGaussian attacks only increase the error rates in several cases, e.g., median aggregation rule for Fashion-MNIST, and trimmed mean and median for CH-MNIST. Label flipping attacks can increase the error rates for DNN classifiers in some cases but have limited success for LR classifiers.",
            "Impact of the percentage of compromised worker devices:Â  FigureÂ 2 shows the error rates of different attacks as the percentage of compromised worker devices increases on MNIST.\nOur attacks increase the error rates significantly as we compromise more worker devices; label flipping only slightly increases the error rates; and Gaussian attacks have no notable impact on the error rates. Two exceptions are that Krumâ€™s error rates decrease when the percentage of compromised worker devices increases from 5% to 10% in FigureÂ 2a and from 10% to 15% in FigureÂ 2d. We suspect the reason is that Krum selects one local model as a global model in each iteration. We have similar observations on the other datasets. Therefore, we omit the corresponding results for simplicity.",
            "Worker devices can perform multiple rounds of stochastic gradient descent to update their local models. FigureÂ 4a shows the impact of the number of rounds on the testing error rates of our attack. The testing error rates decrease as we use more rounds of stochastic gradient descent for both no attack and our partial knowledge attack. This is because more rounds of stochastic gradient descent lead to more accurate local models, and the local models on different worker devices are less diverse, leaving a smaller attack space. However, our attack still increases the error rates substantially even if we use more rounds. For instance, our attack still increases the error rate by more than 30% when using 10 rounds of stochastic gradient descent. We note that a large number of rounds result in large computational cost for worker devices, which may be unacceptable for resource-constrained devices such as mobile phones and IoT devices.",
            "Alternative training strategy:Â  Each iteration results in a global model. Instead of selecting the last global model as the final model, an alternative training strategy is to select the global model that has the lowest testing error rate.333We give advantages to the alternative training strategy since we use testing error rate to select the global model. TableÂ 3 shows the testing error rates of various attacks on the DNN classifier for MNIST, when such alternative training strategy is adopted. In these experiments, our attacks attack each iteration of federated learning, and the column â€œNoAttackâ€ corresponds to the scenarios where no iterations are attacked. Compared to TableÂ 2b, this alternative training strategy is slightly more secure against our attacks. However, our attacks are still effective. For instance, for the Krum, trimmed mean, and median aggregation rules, our partial knowledge attacks still increase the testing error rates by 590%, 100%, and 83%, respectively.  Another training strategy is to roll back to a few iterations ago if the master device detects an unusual increase of training error rate. However, such training strategy is not applicable because the training error rates of the global models still decrease until convergence when we perform our attacks in each iteration. In other words, there are no unusual increases of training error rates.",
            "We craft local models based on one aggregation rule and show the attack effectiveness for other aggregation rules.\nTableÂ 4 shows the transferability between aggregation rules, where MNIST and LR classifier are considered.\nWe observe different levels of transferability between aggregation rules. Specifically, Krum based attack can well transfer to trimmed mean and median, e.g., Krum based attack increases the error rate from 0.12 to 0.15 (25% relative increase) for trimmed mean, and from 0.13 to 0.18 (38% relative increase) for median. Trimmed mean based attack does not transfer to Krum but transfers to median well. For instance, trimmed mean based attack increases the error rates from 0.13 to 0.20 (54% relative increase) for median.",
            "We consider the two scenarios because they represent two extremes for distributing data (concentrated or evenly distributed) and we expect one extreme to maximize attack effectiveness.\nTableÂ 5 compares BGA with our attacks. We observe that BGA has limited success at attacking Byzantine-robust aggregation rules, while our attacks can substantially increase the testing error rates. We note that if the federated learning uses the mean aggregation rule BGA is still successful. For instance, when the mean aggregation rule is used, BGA can increase the testing error rate by 50% when distributing the poisoned data to the compromised worker devices uniformly at random. However, when applying our attacks for trimmed mean to attack the mean aggregation rule, we can increase the testing error rates substantially more (see the last two cells in the second row of TableÂ 5).",
            "Defense results:Â  TableÂ 6 shows the defense results of ERR, FLR, and Union, where partial knowledge attacks are considered. We use the default parameter setting discussed in SectionÂ 1, e.g., 100 worker devices, 20% of compromised worker devices, MNIST dataset, and LR classifier. Moreover, we sample 100 testing examples uniformly at random as the validation dataset. Each row of the table corresponds to a defense, e.g., Krum + ERR means that the master device uses ERR to remove the potentially malicious local models and uses Krum as the aggregation rule. Each column indicates the attackerâ€™s assumed aggregation rule when performing attacks, e.g., the column â€œKrumâ€ corresponds to attacks that are based on Krum. We have several observations.",
            "Bulyan is based on Krum. We apply our attacks for Krum to attack Bulyan. TableÂ 7b shows results of attacking Bulyan. The dataset is MNIST, the classifier is logistic regression, m=100ğ‘š100m=100, c=20ğ‘20c=20, Î¸=mâˆ’2â€‹cğœƒğ‘š2ğ‘\\theta=m-2c (Bulyan selects Î¸ğœƒ\\theta local models using Krum), and Î³=Î¸âˆ’2â€‹cğ›¾ğœƒ2ğ‘\\gamma=\\theta-2c (Bulyan takes the mean of Î³ğ›¾\\gamma parameters).\nOur results show that our attacks to Krum can transfer to Bulyan. Specifically, our partial knowledge attack increases the error rate by around 150%, while our full knowledge attack increases the error rate by 165%.",
            "Experimental results: TableÂ 8 empirically compares the deviation goal and directed deviation goal, where MNIST and LR classifier are used.\nFor Krum, both goals achieve high testing error rates. However, for trimmed mean and median, the directed deviation goal achieves significantly higher testing error rates than the deviation goal."
        ]
    },
    "S4.T2.sf4": {
        "caption": "(d) DNN classifier, CH-MNIST",
        "table": "<table id=\"S4.T2.sf4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.sf4.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf4.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S4.T2.sf4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">NoAttack</span></td>\n<td id=\"S4.T2.sf4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Gaussian</span></td>\n<td id=\"S4.T2.sf4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">LabelFlip</span></td>\n<td id=\"S4.T2.sf4.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Partial</span></td>\n<td id=\"S4.T2.sf4.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Full</span></td>\n</tr>\n<tr id=\"S4.T2.sf4.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf4.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></td>\n<td id=\"S4.T2.sf4.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.29</span></td>\n<td id=\"S4.T2.sf4.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.30</span></td>\n<td id=\"S4.T2.sf4.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.43</span></td>\n<td id=\"S4.T2.sf4.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.73</span></td>\n<td id=\"S4.T2.sf4.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.81</span></td>\n</tr>\n<tr id=\"S4.T2.sf4.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf4.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></td>\n<td id=\"S4.T2.sf4.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.17</span></td>\n<td id=\"S4.T2.sf4.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.25</span></td>\n<td id=\"S4.T2.sf4.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.37</span></td>\n<td id=\"S4.T2.sf4.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.69</span></td>\n<td id=\"S4.T2.sf4.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.69</span></td>\n</tr>\n<tr id=\"S4.T2.sf4.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf4.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></td>\n<td id=\"S4.T2.sf4.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.17</span></td>\n<td id=\"S4.T2.sf4.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.20</span></td>\n<td id=\"S4.T2.sf4.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.17</span></td>\n<td id=\"S4.T2.sf4.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.57</span></td>\n<td id=\"S4.T2.sf4.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf4.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.63</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Deep neural networks (DNN). For MNIST, Fashion-MNIST, and Breast Cancer Wisconsin (Diagnostic), we use a DNN with the architecture described in TableÂ 7a in Appendix. We use ResNet20Â [28] for CH-MNIST. Our DNN architecture does not necessarily achieve the smallest error rates for the considered datasets, as our goal is not to search for the best DNN architecture. Our goal is to show that our attacks can increase the testing error rates of the learnt DNN classifiers.",
            "Parameter setting:Â  We describe parameter setting for the federated learning algorithms and our attacks. TableÂ 1 summarizes the default setting for key parameters. We use MXNetÂ [12] to implement federated learning and attacks. We repeat each experiment for 50 trials and report the average results. We observed that the variances are very small, so we omit them for simplicity.",
            "Our attacks are effective: TableÂ 2e shows the testing error rates of the compared attacks on the four datasets.\nFirst, these results show that our attacks are effective and substantially outperform existing attacks, i.e., our attacks result in higher error rates. For instance, when dataset is MNIST, classifier is LR, and aggregation rule is Krum, our partial knowledge attack increases the error rate from 0.14 to 0.72 (around 400% relative increase).\nGaussian attacks only increase the error rates in several cases, e.g., median aggregation rule for Fashion-MNIST, and trimmed mean and median for CH-MNIST. Label flipping attacks can increase the error rates for DNN classifiers in some cases but have limited success for LR classifiers.",
            "Impact of the percentage of compromised worker devices:Â  FigureÂ 2 shows the error rates of different attacks as the percentage of compromised worker devices increases on MNIST.\nOur attacks increase the error rates significantly as we compromise more worker devices; label flipping only slightly increases the error rates; and Gaussian attacks have no notable impact on the error rates. Two exceptions are that Krumâ€™s error rates decrease when the percentage of compromised worker devices increases from 5% to 10% in FigureÂ 2a and from 10% to 15% in FigureÂ 2d. We suspect the reason is that Krum selects one local model as a global model in each iteration. We have similar observations on the other datasets. Therefore, we omit the corresponding results for simplicity.",
            "Worker devices can perform multiple rounds of stochastic gradient descent to update their local models. FigureÂ 4a shows the impact of the number of rounds on the testing error rates of our attack. The testing error rates decrease as we use more rounds of stochastic gradient descent for both no attack and our partial knowledge attack. This is because more rounds of stochastic gradient descent lead to more accurate local models, and the local models on different worker devices are less diverse, leaving a smaller attack space. However, our attack still increases the error rates substantially even if we use more rounds. For instance, our attack still increases the error rate by more than 30% when using 10 rounds of stochastic gradient descent. We note that a large number of rounds result in large computational cost for worker devices, which may be unacceptable for resource-constrained devices such as mobile phones and IoT devices.",
            "Alternative training strategy:Â  Each iteration results in a global model. Instead of selecting the last global model as the final model, an alternative training strategy is to select the global model that has the lowest testing error rate.333We give advantages to the alternative training strategy since we use testing error rate to select the global model. TableÂ 3 shows the testing error rates of various attacks on the DNN classifier for MNIST, when such alternative training strategy is adopted. In these experiments, our attacks attack each iteration of federated learning, and the column â€œNoAttackâ€ corresponds to the scenarios where no iterations are attacked. Compared to TableÂ 2b, this alternative training strategy is slightly more secure against our attacks. However, our attacks are still effective. For instance, for the Krum, trimmed mean, and median aggregation rules, our partial knowledge attacks still increase the testing error rates by 590%, 100%, and 83%, respectively.  Another training strategy is to roll back to a few iterations ago if the master device detects an unusual increase of training error rate. However, such training strategy is not applicable because the training error rates of the global models still decrease until convergence when we perform our attacks in each iteration. In other words, there are no unusual increases of training error rates.",
            "We craft local models based on one aggregation rule and show the attack effectiveness for other aggregation rules.\nTableÂ 4 shows the transferability between aggregation rules, where MNIST and LR classifier are considered.\nWe observe different levels of transferability between aggregation rules. Specifically, Krum based attack can well transfer to trimmed mean and median, e.g., Krum based attack increases the error rate from 0.12 to 0.15 (25% relative increase) for trimmed mean, and from 0.13 to 0.18 (38% relative increase) for median. Trimmed mean based attack does not transfer to Krum but transfers to median well. For instance, trimmed mean based attack increases the error rates from 0.13 to 0.20 (54% relative increase) for median.",
            "We consider the two scenarios because they represent two extremes for distributing data (concentrated or evenly distributed) and we expect one extreme to maximize attack effectiveness.\nTableÂ 5 compares BGA with our attacks. We observe that BGA has limited success at attacking Byzantine-robust aggregation rules, while our attacks can substantially increase the testing error rates. We note that if the federated learning uses the mean aggregation rule BGA is still successful. For instance, when the mean aggregation rule is used, BGA can increase the testing error rate by 50% when distributing the poisoned data to the compromised worker devices uniformly at random. However, when applying our attacks for trimmed mean to attack the mean aggregation rule, we can increase the testing error rates substantially more (see the last two cells in the second row of TableÂ 5).",
            "Defense results:Â  TableÂ 6 shows the defense results of ERR, FLR, and Union, where partial knowledge attacks are considered. We use the default parameter setting discussed in SectionÂ 1, e.g., 100 worker devices, 20% of compromised worker devices, MNIST dataset, and LR classifier. Moreover, we sample 100 testing examples uniformly at random as the validation dataset. Each row of the table corresponds to a defense, e.g., Krum + ERR means that the master device uses ERR to remove the potentially malicious local models and uses Krum as the aggregation rule. Each column indicates the attackerâ€™s assumed aggregation rule when performing attacks, e.g., the column â€œKrumâ€ corresponds to attacks that are based on Krum. We have several observations.",
            "Bulyan is based on Krum. We apply our attacks for Krum to attack Bulyan. TableÂ 7b shows results of attacking Bulyan. The dataset is MNIST, the classifier is logistic regression, m=100ğ‘š100m=100, c=20ğ‘20c=20, Î¸=mâˆ’2â€‹cğœƒğ‘š2ğ‘\\theta=m-2c (Bulyan selects Î¸ğœƒ\\theta local models using Krum), and Î³=Î¸âˆ’2â€‹cğ›¾ğœƒ2ğ‘\\gamma=\\theta-2c (Bulyan takes the mean of Î³ğ›¾\\gamma parameters).\nOur results show that our attacks to Krum can transfer to Bulyan. Specifically, our partial knowledge attack increases the error rate by around 150%, while our full knowledge attack increases the error rate by 165%.",
            "Experimental results: TableÂ 8 empirically compares the deviation goal and directed deviation goal, where MNIST and LR classifier are used.\nFor Krum, both goals achieve high testing error rates. However, for trimmed mean and median, the directed deviation goal achieves significantly higher testing error rates than the deviation goal."
        ]
    },
    "S4.T2.sf5": {
        "caption": "(e) DNN classifier, Breast Cancer Wisconsin (Diagnostic)",
        "table": "<table id=\"S4.T2.sf5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.sf5.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf5.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S4.T2.sf5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">NoAttack</span></td>\n<td id=\"S4.T2.sf5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Gaussian</span></td>\n<td id=\"S4.T2.sf5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">LabelFlip</span></td>\n<td id=\"S4.T2.sf5.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Partial</span></td>\n<td id=\"S4.T2.sf5.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Full</span></td>\n</tr>\n<tr id=\"S4.T2.sf5.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf5.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></td>\n<td id=\"S4.T2.sf5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.03</span></td>\n<td id=\"S4.T2.sf5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.04</span></td>\n<td id=\"S4.T2.sf5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S4.T2.sf5.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.17</span></td>\n<td id=\"S4.T2.sf5.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.17</span></td>\n</tr>\n<tr id=\"S4.T2.sf5.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf5.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></td>\n<td id=\"S4.T2.sf5.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.02</span></td>\n<td id=\"S4.T2.sf5.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.03</span></td>\n<td id=\"S4.T2.sf5.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.05</span></td>\n<td id=\"S4.T2.sf5.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S4.T2.sf5.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.15</span></td>\n</tr>\n<tr id=\"S4.T2.sf5.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.sf5.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></td>\n<td id=\"S4.T2.sf5.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.03</span></td>\n<td id=\"S4.T2.sf5.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.03</span></td>\n<td id=\"S4.T2.sf5.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.04</span></td>\n<td id=\"S4.T2.sf5.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.17</span></td>\n<td id=\"S4.T2.sf5.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T2.sf5.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.18</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Deep neural networks (DNN). For MNIST, Fashion-MNIST, and Breast Cancer Wisconsin (Diagnostic), we use a DNN with the architecture described in TableÂ 7a in Appendix. We use ResNet20Â [28] for CH-MNIST. Our DNN architecture does not necessarily achieve the smallest error rates for the considered datasets, as our goal is not to search for the best DNN architecture. Our goal is to show that our attacks can increase the testing error rates of the learnt DNN classifiers.",
            "Parameter setting:Â  We describe parameter setting for the federated learning algorithms and our attacks. TableÂ 1 summarizes the default setting for key parameters. We use MXNetÂ [12] to implement federated learning and attacks. We repeat each experiment for 50 trials and report the average results. We observed that the variances are very small, so we omit them for simplicity.",
            "Our attacks are effective: TableÂ 2e shows the testing error rates of the compared attacks on the four datasets.\nFirst, these results show that our attacks are effective and substantially outperform existing attacks, i.e., our attacks result in higher error rates. For instance, when dataset is MNIST, classifier is LR, and aggregation rule is Krum, our partial knowledge attack increases the error rate from 0.14 to 0.72 (around 400% relative increase).\nGaussian attacks only increase the error rates in several cases, e.g., median aggregation rule for Fashion-MNIST, and trimmed mean and median for CH-MNIST. Label flipping attacks can increase the error rates for DNN classifiers in some cases but have limited success for LR classifiers.",
            "Impact of the percentage of compromised worker devices:Â  FigureÂ 2 shows the error rates of different attacks as the percentage of compromised worker devices increases on MNIST.\nOur attacks increase the error rates significantly as we compromise more worker devices; label flipping only slightly increases the error rates; and Gaussian attacks have no notable impact on the error rates. Two exceptions are that Krumâ€™s error rates decrease when the percentage of compromised worker devices increases from 5% to 10% in FigureÂ 2a and from 10% to 15% in FigureÂ 2d. We suspect the reason is that Krum selects one local model as a global model in each iteration. We have similar observations on the other datasets. Therefore, we omit the corresponding results for simplicity.",
            "Worker devices can perform multiple rounds of stochastic gradient descent to update their local models. FigureÂ 4a shows the impact of the number of rounds on the testing error rates of our attack. The testing error rates decrease as we use more rounds of stochastic gradient descent for both no attack and our partial knowledge attack. This is because more rounds of stochastic gradient descent lead to more accurate local models, and the local models on different worker devices are less diverse, leaving a smaller attack space. However, our attack still increases the error rates substantially even if we use more rounds. For instance, our attack still increases the error rate by more than 30% when using 10 rounds of stochastic gradient descent. We note that a large number of rounds result in large computational cost for worker devices, which may be unacceptable for resource-constrained devices such as mobile phones and IoT devices.",
            "Alternative training strategy:Â  Each iteration results in a global model. Instead of selecting the last global model as the final model, an alternative training strategy is to select the global model that has the lowest testing error rate.333We give advantages to the alternative training strategy since we use testing error rate to select the global model. TableÂ 3 shows the testing error rates of various attacks on the DNN classifier for MNIST, when such alternative training strategy is adopted. In these experiments, our attacks attack each iteration of federated learning, and the column â€œNoAttackâ€ corresponds to the scenarios where no iterations are attacked. Compared to TableÂ 2b, this alternative training strategy is slightly more secure against our attacks. However, our attacks are still effective. For instance, for the Krum, trimmed mean, and median aggregation rules, our partial knowledge attacks still increase the testing error rates by 590%, 100%, and 83%, respectively.  Another training strategy is to roll back to a few iterations ago if the master device detects an unusual increase of training error rate. However, such training strategy is not applicable because the training error rates of the global models still decrease until convergence when we perform our attacks in each iteration. In other words, there are no unusual increases of training error rates.",
            "We craft local models based on one aggregation rule and show the attack effectiveness for other aggregation rules.\nTableÂ 4 shows the transferability between aggregation rules, where MNIST and LR classifier are considered.\nWe observe different levels of transferability between aggregation rules. Specifically, Krum based attack can well transfer to trimmed mean and median, e.g., Krum based attack increases the error rate from 0.12 to 0.15 (25% relative increase) for trimmed mean, and from 0.13 to 0.18 (38% relative increase) for median. Trimmed mean based attack does not transfer to Krum but transfers to median well. For instance, trimmed mean based attack increases the error rates from 0.13 to 0.20 (54% relative increase) for median.",
            "We consider the two scenarios because they represent two extremes for distributing data (concentrated or evenly distributed) and we expect one extreme to maximize attack effectiveness.\nTableÂ 5 compares BGA with our attacks. We observe that BGA has limited success at attacking Byzantine-robust aggregation rules, while our attacks can substantially increase the testing error rates. We note that if the federated learning uses the mean aggregation rule BGA is still successful. For instance, when the mean aggregation rule is used, BGA can increase the testing error rate by 50% when distributing the poisoned data to the compromised worker devices uniformly at random. However, when applying our attacks for trimmed mean to attack the mean aggregation rule, we can increase the testing error rates substantially more (see the last two cells in the second row of TableÂ 5).",
            "Defense results:Â  TableÂ 6 shows the defense results of ERR, FLR, and Union, where partial knowledge attacks are considered. We use the default parameter setting discussed in SectionÂ 1, e.g., 100 worker devices, 20% of compromised worker devices, MNIST dataset, and LR classifier. Moreover, we sample 100 testing examples uniformly at random as the validation dataset. Each row of the table corresponds to a defense, e.g., Krum + ERR means that the master device uses ERR to remove the potentially malicious local models and uses Krum as the aggregation rule. Each column indicates the attackerâ€™s assumed aggregation rule when performing attacks, e.g., the column â€œKrumâ€ corresponds to attacks that are based on Krum. We have several observations.",
            "Bulyan is based on Krum. We apply our attacks for Krum to attack Bulyan. TableÂ 7b shows results of attacking Bulyan. The dataset is MNIST, the classifier is logistic regression, m=100ğ‘š100m=100, c=20ğ‘20c=20, Î¸=mâˆ’2â€‹cğœƒğ‘š2ğ‘\\theta=m-2c (Bulyan selects Î¸ğœƒ\\theta local models using Krum), and Î³=Î¸âˆ’2â€‹cğ›¾ğœƒ2ğ‘\\gamma=\\theta-2c (Bulyan takes the mean of Î³ğ›¾\\gamma parameters).\nOur results show that our attacks to Krum can transfer to Bulyan. Specifically, our partial knowledge attack increases the error rate by around 150%, while our full knowledge attack increases the error rate by 165%.",
            "Experimental results: TableÂ 8 empirically compares the deviation goal and directed deviation goal, where MNIST and LR classifier are used.\nFor Krum, both goals achieve high testing error rates. However, for trimmed mean and median, the directed deviation goal achieves significantly higher testing error rates than the deviation goal."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Testing error rates of attacks on the DNN classifier for MNIST when the master device chooses the global model with the lowest testing error rate.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">NoAttack</span></td>\n<td id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Gaussian</span></td>\n<td id=\"S4.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">LabelFlip</span></td>\n<td id=\"S4.T3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Partial</span></td>\n<td id=\"S4.T3.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Full</span></td>\n</tr>\n<tr id=\"S4.T3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></td>\n<td id=\"S4.T3.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.10</span></td>\n<td id=\"S4.T3.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.10</span></td>\n<td id=\"S4.T3.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.09</span></td>\n<td id=\"S4.T3.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.69</span></td>\n<td id=\"S4.T3.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.70</span></td>\n</tr>\n<tr id=\"S4.T3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></td>\n<td id=\"S4.T3.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.06</span></td>\n<td id=\"S4.T3.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.06</span></td>\n<td id=\"S4.T3.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.07</span></td>\n<td id=\"S4.T3.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S4.T3.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.18</span></td>\n</tr>\n<tr id=\"S4.T3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></td>\n<td id=\"S4.T3.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.06</span></td>\n<td id=\"S4.T3.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.06</span></td>\n<td id=\"S4.T3.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.06</span></td>\n<td id=\"S4.T3.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.11</span></td>\n<td id=\"S4.T3.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.32</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Alternative training strategy:Â  Each iteration results in a global model. Instead of selecting the last global model as the final model, an alternative training strategy is to select the global model that has the lowest testing error rate.333We give advantages to the alternative training strategy since we use testing error rate to select the global model. TableÂ 3 shows the testing error rates of various attacks on the DNN classifier for MNIST, when such alternative training strategy is adopted. In these experiments, our attacks attack each iteration of federated learning, and the column â€œNoAttackâ€ corresponds to the scenarios where no iterations are attacked. Compared to TableÂ 2b, this alternative training strategy is slightly more secure against our attacks. However, our attacks are still effective. For instance, for the Krum, trimmed mean, and median aggregation rules, our partial knowledge attacks still increase the testing error rates by 590%, 100%, and 83%, respectively.  Another training strategy is to roll back to a few iterations ago if the master device detects an unusual increase of training error rate. However, such training strategy is not applicable because the training error rates of the global models still decrease until convergence when we perform our attacks in each iteration. In other words, there are no unusual increases of training error rates."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Transferability between aggregation rules. â€œKrum attackâ€ and â€œTrimmed mean attackâ€ mean that we craft the compromised local models based on the Krum and trimmed mean aggregation rules, respectively. Partial knowledge attacks are considered. The numbers are testing error rates.",
        "table": "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"></th>\n<th id=\"S4.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></th>\n<th id=\"S4.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></th>\n<th id=\"S4.T4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">No attack</span></td>\n<td id=\"S4.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S4.T4.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S4.T4.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.2.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n</tr>\n<tr id=\"S4.T4.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum attack</span></td>\n<td id=\"S4.T4.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.70</span></td>\n<td id=\"S4.T4.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.15</span></td>\n<td id=\"S4.T4.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.3.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.18</span></td>\n</tr>\n<tr id=\"S4.T4.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean attack</span></td>\n<td id=\"S4.T4.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S4.T4.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.25</span></td>\n<td id=\"S4.T4.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.4.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.20</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We craft local models based on one aggregation rule and show the attack effectiveness for other aggregation rules.\nTableÂ 4 shows the transferability between aggregation rules, where MNIST and LR classifier are considered.\nWe observe different levels of transferability between aggregation rules. Specifically, Krum based attack can well transfer to trimmed mean and median, e.g., Krum based attack increases the error rate from 0.12 to 0.15 (25% relative increase) for trimmed mean, and from 0.13 to 0.18 (38% relative increase) for median. Trimmed mean based attack does not transfer to Krum but transfers to median well. For instance, trimmed mean based attack increases the error rates from 0.13 to 0.20 (54% relative increase) for median."
        ]
    },
    "S4.T5": {
        "caption": "Table 5: Testing error rates of back-gradient optimization based attacks (SingleWorker and Uniform) and our attacks (Partial and Full).",
        "table": "<table id=\"S4.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S4.T5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">NoAttack</span></td>\n<td id=\"S4.T5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">SingleWorker</span></td>\n<td id=\"S4.T5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Uniform</span></td>\n<td id=\"S4.T5.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Partial</span></td>\n<td id=\"S4.T5.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Full</span></td>\n</tr>\n<tr id=\"S4.T5.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Mean</span></td>\n<td id=\"S4.T5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.10</span></td>\n<td id=\"S4.T5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.11</span></td>\n<td id=\"S4.T5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.15</span></td>\n<td id=\"S4.T5.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.54</span></td>\n<td id=\"S4.T5.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.69</span></td>\n</tr>\n<tr id=\"S4.T5.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></td>\n<td id=\"S4.T5.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.23</span></td>\n<td id=\"S4.T5.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.24</span></td>\n<td id=\"S4.T5.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.25</span></td>\n<td id=\"S4.T5.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.85</span></td>\n<td id=\"S4.T5.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.89</span></td>\n</tr>\n<tr id=\"S4.T5.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></td>\n<td id=\"S4.T5.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S4.T5.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S4.T5.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T5.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.27</span></td>\n<td id=\"S4.T5.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.32</span></td>\n</tr>\n<tr id=\"S4.T5.1.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></td>\n<td id=\"S4.T5.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T5.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S4.T5.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.5.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S4.T5.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.5.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.19</span></td>\n<td id=\"S4.T5.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T5.1.5.5.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.21</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We consider the two scenarios because they represent two extremes for distributing data (concentrated or evenly distributed) and we expect one extreme to maximize attack effectiveness.\nTableÂ 5 compares BGA with our attacks. We observe that BGA has limited success at attacking Byzantine-robust aggregation rules, while our attacks can substantially increase the testing error rates. We note that if the federated learning uses the mean aggregation rule BGA is still successful. For instance, when the mean aggregation rule is used, BGA can increase the testing error rate by 50% when distributing the poisoned data to the compromised worker devices uniformly at random. However, when applying our attacks for trimmed mean to attack the mean aggregation rule, we can increase the testing error rates substantially more (see the last two cells in the second row of TableÂ 5)."
        ]
    },
    "S5.T6": {
        "caption": "Table 6: Defense results. The numbers are testing error rates. The columns â€œKrumâ€ and â€œTrimmed meanâ€ indicate the attackerâ€™s assumed aggregation rule when performing attacks, while the rows indicate the actual aggregation rules and defenses. Partial knowledge attacks are considered.",
        "table": "<table id=\"S5.T6.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T6.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S5.T6.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">No attack</span></td>\n<td id=\"S5.T6.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></td>\n<td id=\"S5.T6.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></td>\n</tr>\n<tr id=\"S5.T6.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></td>\n<td id=\"S5.T6.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S5.T6.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.72</span></td>\n<td id=\"S5.T6.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n</tr>\n<tr id=\"S5.T6.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum + ERR</span></td>\n<td id=\"S5.T6.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S5.T6.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.62</span></td>\n<td id=\"S5.T6.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n</tr>\n<tr id=\"S5.T6.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum + LFR</span></td>\n<td id=\"S5.T6.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S5.T6.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.58</span></td>\n<td id=\"S5.T6.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n</tr>\n<tr id=\"S5.T6.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum + Union</span></td>\n<td id=\"S5.T6.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n<td id=\"S5.T6.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.48</span></td>\n<td id=\"S5.T6.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.5.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n</tr>\n<tr id=\"S5.T6.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.6.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></td>\n<td id=\"S5.T6.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.6.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S5.T6.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.15</span></td>\n<td id=\"S5.T6.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.6.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.23</span></td>\n</tr>\n<tr id=\"S5.T6.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.7.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean + ERR</span></td>\n<td id=\"S5.T6.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.7.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S5.T6.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.7.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.17</span></td>\n<td id=\"S5.T6.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.7.7.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.21</span></td>\n</tr>\n<tr id=\"S5.T6.1.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.8.8.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.8.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean + LFR</span></td>\n<td id=\"S5.T6.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.8.8.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S5.T6.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.8.8.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.18</span></td>\n<td id=\"S5.T6.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.8.8.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n</tr>\n<tr id=\"S5.T6.1.9.9\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.9.9.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.9.9.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean + Union</span></td>\n<td id=\"S5.T6.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.9.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n<td id=\"S5.T6.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.9.9.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.18</span></td>\n<td id=\"S5.T6.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.9.9.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n</tr>\n<tr id=\"S5.T6.1.10.10\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.10.10.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></td>\n<td id=\"S5.T6.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.10.10.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S5.T6.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.10.10.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.17</span></td>\n<td id=\"S5.T6.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.10.10.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.19</span></td>\n</tr>\n<tr id=\"S5.T6.1.11.11\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.11.11.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.11.11.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median + ERR</span></td>\n<td id=\"S5.T6.1.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.11.11.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S5.T6.1.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.11.11.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.21</span></td>\n<td id=\"S5.T6.1.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.11.11.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.25</span></td>\n</tr>\n<tr id=\"S5.T6.1.12.12\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.12.12.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.12.12.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median + LFR</span></td>\n<td id=\"S5.T6.1.12.12.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.12.12.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S5.T6.1.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.12.12.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.20</span></td>\n<td id=\"S5.T6.1.12.12.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.12.12.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n</tr>\n<tr id=\"S5.T6.1.13.13\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.13.13.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.13.13.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median + Union</span></td>\n<td id=\"S5.T6.1.13.13.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.13.13.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td id=\"S5.T6.1.13.13.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.13.13.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.19</span></td>\n<td id=\"S5.T6.1.13.13.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S5.T6.1.13.13.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Defense results:Â  TableÂ 6 shows the defense results of ERR, FLR, and Union, where partial knowledge attacks are considered. We use the default parameter setting discussed in SectionÂ 1, e.g., 100 worker devices, 20% of compromised worker devices, MNIST dataset, and LR classifier. Moreover, we sample 100 testing examples uniformly at random as the validation dataset. Each row of the table corresponds to a defense, e.g., Krum + ERR means that the master device uses ERR to remove the potentially malicious local models and uses Krum as the aggregation rule. Each column indicates the attackerâ€™s assumed aggregation rule when performing attacks, e.g., the column â€œKrumâ€ corresponds to attacks that are based on Krum. We have several observations."
        ]
    },
    "A0.T7": {
        "caption": "Table 7: (a) The DNN architecture (input layer is not shown) used for MNIST and Fashion MNIST. (b) Testing error rates when applying attacks for Krum to attack Bulyan.",
        "table": "<table id=\"A0.T7.sf1.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A0.T7.sf1.4.5.1\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.5.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Layer Type</span></th>\n<th id=\"A0.T7.sf1.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.5.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Size</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A0.T7.sf1.1.1\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Convolution + ReLU</span></th>\n<td id=\"A0.T7.sf1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><math id=\"A0.T7.sf1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"3\\times 3\\times 30\" display=\"inline\"><semantics id=\"A0.T7.sf1.1.1.1.m1.1a\"><mrow id=\"A0.T7.sf1.1.1.1.m1.1.1\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.cmml\"><mn mathsize=\"90%\" id=\"A0.T7.sf1.1.1.1.m1.1.1.2\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.2.cmml\">3</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.1.1.1.m1.1.1.1\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.1.1.1.m1.1.1.3\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.3.cmml\">3</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.1.1.1.m1.1.1.1a\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.1.1.1.m1.1.1.4\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.4.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A0.T7.sf1.1.1.1.m1.1b\"><apply id=\"A0.T7.sf1.1.1.1.m1.1.1.cmml\" xref=\"A0.T7.sf1.1.1.1.m1.1.1\"><times id=\"A0.T7.sf1.1.1.1.m1.1.1.1.cmml\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"A0.T7.sf1.1.1.1.m1.1.1.2.cmml\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.2\">3</cn><cn type=\"integer\" id=\"A0.T7.sf1.1.1.1.m1.1.1.3.cmml\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.3\">3</cn><cn type=\"integer\" id=\"A0.T7.sf1.1.1.1.m1.1.1.4.cmml\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.4\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A0.T7.sf1.1.1.1.m1.1c\">3\\times 3\\times 30</annotation></semantics></math></td>\n</tr>\n<tr id=\"A0.T7.sf1.2.2\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Max Pooling</span></th>\n<td id=\"A0.T7.sf1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><math id=\"A0.T7.sf1.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"2\\times 2\" display=\"inline\"><semantics id=\"A0.T7.sf1.2.2.1.m1.1a\"><mrow id=\"A0.T7.sf1.2.2.1.m1.1.1\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.cmml\"><mn mathsize=\"90%\" id=\"A0.T7.sf1.2.2.1.m1.1.1.2\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.2.cmml\">2</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.2.2.1.m1.1.1.1\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.2.2.1.m1.1.1.3\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A0.T7.sf1.2.2.1.m1.1b\"><apply id=\"A0.T7.sf1.2.2.1.m1.1.1.cmml\" xref=\"A0.T7.sf1.2.2.1.m1.1.1\"><times id=\"A0.T7.sf1.2.2.1.m1.1.1.1.cmml\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"A0.T7.sf1.2.2.1.m1.1.1.2.cmml\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.2\">2</cn><cn type=\"integer\" id=\"A0.T7.sf1.2.2.1.m1.1.1.3.cmml\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A0.T7.sf1.2.2.1.m1.1c\">2\\times 2</annotation></semantics></math></td>\n</tr>\n<tr id=\"A0.T7.sf1.3.3\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Convolution + ReLU</span></th>\n<td id=\"A0.T7.sf1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><math id=\"A0.T7.sf1.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"3\\times 3\\times 50\" display=\"inline\"><semantics id=\"A0.T7.sf1.3.3.1.m1.1a\"><mrow id=\"A0.T7.sf1.3.3.1.m1.1.1\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.cmml\"><mn mathsize=\"90%\" id=\"A0.T7.sf1.3.3.1.m1.1.1.2\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.2.cmml\">3</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.3.3.1.m1.1.1.1\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.3.3.1.m1.1.1.3\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.3.cmml\">3</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.3.3.1.m1.1.1.1a\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.3.3.1.m1.1.1.4\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.4.cmml\">50</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A0.T7.sf1.3.3.1.m1.1b\"><apply id=\"A0.T7.sf1.3.3.1.m1.1.1.cmml\" xref=\"A0.T7.sf1.3.3.1.m1.1.1\"><times id=\"A0.T7.sf1.3.3.1.m1.1.1.1.cmml\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"A0.T7.sf1.3.3.1.m1.1.1.2.cmml\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.2\">3</cn><cn type=\"integer\" id=\"A0.T7.sf1.3.3.1.m1.1.1.3.cmml\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.3\">3</cn><cn type=\"integer\" id=\"A0.T7.sf1.3.3.1.m1.1.1.4.cmml\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.4\">50</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A0.T7.sf1.3.3.1.m1.1c\">3\\times 3\\times 50</annotation></semantics></math></td>\n</tr>\n<tr id=\"A0.T7.sf1.4.4\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.4.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Max Pooling</span></th>\n<td id=\"A0.T7.sf1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><math id=\"A0.T7.sf1.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"2\\times 2\" display=\"inline\"><semantics id=\"A0.T7.sf1.4.4.1.m1.1a\"><mrow id=\"A0.T7.sf1.4.4.1.m1.1.1\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.cmml\"><mn mathsize=\"90%\" id=\"A0.T7.sf1.4.4.1.m1.1.1.2\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.2.cmml\">2</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.4.4.1.m1.1.1.1\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.4.4.1.m1.1.1.3\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A0.T7.sf1.4.4.1.m1.1b\"><apply id=\"A0.T7.sf1.4.4.1.m1.1.1.cmml\" xref=\"A0.T7.sf1.4.4.1.m1.1.1\"><times id=\"A0.T7.sf1.4.4.1.m1.1.1.1.cmml\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"A0.T7.sf1.4.4.1.m1.1.1.2.cmml\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.2\">2</cn><cn type=\"integer\" id=\"A0.T7.sf1.4.4.1.m1.1.1.3.cmml\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A0.T7.sf1.4.4.1.m1.1c\">2\\times 2</annotation></semantics></math></td>\n</tr>\n<tr id=\"A0.T7.sf1.4.6.1\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.4.6.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.6.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fully Connected + ReLU</span></th>\n<td id=\"A0.T7.sf1.4.6.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.6.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">200</span></td>\n</tr>\n<tr id=\"A0.T7.sf1.4.7.2\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.4.7.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.7.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Softmax</span></th>\n<td id=\"A0.T7.sf1.4.7.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.7.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">10 / 8</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Deep neural networks (DNN). For MNIST, Fashion-MNIST, and Breast Cancer Wisconsin (Diagnostic), we use a DNN with the architecture described in TableÂ 7a in Appendix. We use ResNet20Â [28] for CH-MNIST. Our DNN architecture does not necessarily achieve the smallest error rates for the considered datasets, as our goal is not to search for the best DNN architecture. Our goal is to show that our attacks can increase the testing error rates of the learnt DNN classifiers.",
            "Bulyan is based on Krum. We apply our attacks for Krum to attack Bulyan. TableÂ 7b shows results of attacking Bulyan. The dataset is MNIST, the classifier is logistic regression, m=100ğ‘š100m=100, c=20ğ‘20c=20, Î¸=mâˆ’2â€‹cğœƒğ‘š2ğ‘\\theta=m-2c (Bulyan selects Î¸ğœƒ\\theta local models using Krum), and Î³=Î¸âˆ’2â€‹cğ›¾ğœƒ2ğ‘\\gamma=\\theta-2c (Bulyan takes the mean of Î³ğ›¾\\gamma parameters).\nOur results show that our attacks to Krum can transfer to Bulyan. Specifically, our partial knowledge attack increases the error rate by around 150%, while our full knowledge attack increases the error rate by 165%."
        ]
    },
    "A0.T7.sf1": {
        "caption": "(a) ",
        "table": "<table id=\"A0.T7.sf1.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A0.T7.sf1.4.5.1\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.5.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Layer Type</span></th>\n<th id=\"A0.T7.sf1.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.5.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Size</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A0.T7.sf1.1.1\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Convolution + ReLU</span></th>\n<td id=\"A0.T7.sf1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><math id=\"A0.T7.sf1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"3\\times 3\\times 30\" display=\"inline\"><semantics id=\"A0.T7.sf1.1.1.1.m1.1a\"><mrow id=\"A0.T7.sf1.1.1.1.m1.1.1\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.cmml\"><mn mathsize=\"90%\" id=\"A0.T7.sf1.1.1.1.m1.1.1.2\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.2.cmml\">3</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.1.1.1.m1.1.1.1\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.1.1.1.m1.1.1.3\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.3.cmml\">3</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.1.1.1.m1.1.1.1a\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.1.1.1.m1.1.1.4\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.4.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A0.T7.sf1.1.1.1.m1.1b\"><apply id=\"A0.T7.sf1.1.1.1.m1.1.1.cmml\" xref=\"A0.T7.sf1.1.1.1.m1.1.1\"><times id=\"A0.T7.sf1.1.1.1.m1.1.1.1.cmml\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"A0.T7.sf1.1.1.1.m1.1.1.2.cmml\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.2\">3</cn><cn type=\"integer\" id=\"A0.T7.sf1.1.1.1.m1.1.1.3.cmml\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.3\">3</cn><cn type=\"integer\" id=\"A0.T7.sf1.1.1.1.m1.1.1.4.cmml\" xref=\"A0.T7.sf1.1.1.1.m1.1.1.4\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A0.T7.sf1.1.1.1.m1.1c\">3\\times 3\\times 30</annotation></semantics></math></td>\n</tr>\n<tr id=\"A0.T7.sf1.2.2\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Max Pooling</span></th>\n<td id=\"A0.T7.sf1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><math id=\"A0.T7.sf1.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"2\\times 2\" display=\"inline\"><semantics id=\"A0.T7.sf1.2.2.1.m1.1a\"><mrow id=\"A0.T7.sf1.2.2.1.m1.1.1\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.cmml\"><mn mathsize=\"90%\" id=\"A0.T7.sf1.2.2.1.m1.1.1.2\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.2.cmml\">2</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.2.2.1.m1.1.1.1\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.2.2.1.m1.1.1.3\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A0.T7.sf1.2.2.1.m1.1b\"><apply id=\"A0.T7.sf1.2.2.1.m1.1.1.cmml\" xref=\"A0.T7.sf1.2.2.1.m1.1.1\"><times id=\"A0.T7.sf1.2.2.1.m1.1.1.1.cmml\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"A0.T7.sf1.2.2.1.m1.1.1.2.cmml\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.2\">2</cn><cn type=\"integer\" id=\"A0.T7.sf1.2.2.1.m1.1.1.3.cmml\" xref=\"A0.T7.sf1.2.2.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A0.T7.sf1.2.2.1.m1.1c\">2\\times 2</annotation></semantics></math></td>\n</tr>\n<tr id=\"A0.T7.sf1.3.3\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Convolution + ReLU</span></th>\n<td id=\"A0.T7.sf1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><math id=\"A0.T7.sf1.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"3\\times 3\\times 50\" display=\"inline\"><semantics id=\"A0.T7.sf1.3.3.1.m1.1a\"><mrow id=\"A0.T7.sf1.3.3.1.m1.1.1\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.cmml\"><mn mathsize=\"90%\" id=\"A0.T7.sf1.3.3.1.m1.1.1.2\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.2.cmml\">3</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.3.3.1.m1.1.1.1\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.3.3.1.m1.1.1.3\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.3.cmml\">3</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.3.3.1.m1.1.1.1a\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.3.3.1.m1.1.1.4\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.4.cmml\">50</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A0.T7.sf1.3.3.1.m1.1b\"><apply id=\"A0.T7.sf1.3.3.1.m1.1.1.cmml\" xref=\"A0.T7.sf1.3.3.1.m1.1.1\"><times id=\"A0.T7.sf1.3.3.1.m1.1.1.1.cmml\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"A0.T7.sf1.3.3.1.m1.1.1.2.cmml\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.2\">3</cn><cn type=\"integer\" id=\"A0.T7.sf1.3.3.1.m1.1.1.3.cmml\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.3\">3</cn><cn type=\"integer\" id=\"A0.T7.sf1.3.3.1.m1.1.1.4.cmml\" xref=\"A0.T7.sf1.3.3.1.m1.1.1.4\">50</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A0.T7.sf1.3.3.1.m1.1c\">3\\times 3\\times 50</annotation></semantics></math></td>\n</tr>\n<tr id=\"A0.T7.sf1.4.4\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.4.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Max Pooling</span></th>\n<td id=\"A0.T7.sf1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><math id=\"A0.T7.sf1.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"2\\times 2\" display=\"inline\"><semantics id=\"A0.T7.sf1.4.4.1.m1.1a\"><mrow id=\"A0.T7.sf1.4.4.1.m1.1.1\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.cmml\"><mn mathsize=\"90%\" id=\"A0.T7.sf1.4.4.1.m1.1.1.2\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.2.cmml\">2</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"A0.T7.sf1.4.4.1.m1.1.1.1\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.1.cmml\">Ã—</mo><mn mathsize=\"90%\" id=\"A0.T7.sf1.4.4.1.m1.1.1.3\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A0.T7.sf1.4.4.1.m1.1b\"><apply id=\"A0.T7.sf1.4.4.1.m1.1.1.cmml\" xref=\"A0.T7.sf1.4.4.1.m1.1.1\"><times id=\"A0.T7.sf1.4.4.1.m1.1.1.1.cmml\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"A0.T7.sf1.4.4.1.m1.1.1.2.cmml\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.2\">2</cn><cn type=\"integer\" id=\"A0.T7.sf1.4.4.1.m1.1.1.3.cmml\" xref=\"A0.T7.sf1.4.4.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A0.T7.sf1.4.4.1.m1.1c\">2\\times 2</annotation></semantics></math></td>\n</tr>\n<tr id=\"A0.T7.sf1.4.6.1\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.4.6.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.6.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fully Connected + ReLU</span></th>\n<td id=\"A0.T7.sf1.4.6.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.6.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">200</span></td>\n</tr>\n<tr id=\"A0.T7.sf1.4.7.2\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf1.4.7.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.7.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Softmax</span></th>\n<td id=\"A0.T7.sf1.4.7.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf1.4.7.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">10 / 8</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Deep neural networks (DNN). For MNIST, Fashion-MNIST, and Breast Cancer Wisconsin (Diagnostic), we use a DNN with the architecture described in TableÂ 7a in Appendix. We use ResNet20Â [28] for CH-MNIST. Our DNN architecture does not necessarily achieve the smallest error rates for the considered datasets, as our goal is not to search for the best DNN architecture. Our goal is to show that our attacks can increase the testing error rates of the learnt DNN classifiers.",
            "Parameter setting:Â  We describe parameter setting for the federated learning algorithms and our attacks. TableÂ 1 summarizes the default setting for key parameters. We use MXNetÂ [12] to implement federated learning and attacks. We repeat each experiment for 50 trials and report the average results. We observed that the variances are very small, so we omit them for simplicity.",
            "Our attacks are effective: TableÂ 2e shows the testing error rates of the compared attacks on the four datasets.\nFirst, these results show that our attacks are effective and substantially outperform existing attacks, i.e., our attacks result in higher error rates. For instance, when dataset is MNIST, classifier is LR, and aggregation rule is Krum, our partial knowledge attack increases the error rate from 0.14 to 0.72 (around 400% relative increase).\nGaussian attacks only increase the error rates in several cases, e.g., median aggregation rule for Fashion-MNIST, and trimmed mean and median for CH-MNIST. Label flipping attacks can increase the error rates for DNN classifiers in some cases but have limited success for LR classifiers.",
            "Impact of the percentage of compromised worker devices:Â  FigureÂ 2 shows the error rates of different attacks as the percentage of compromised worker devices increases on MNIST.\nOur attacks increase the error rates significantly as we compromise more worker devices; label flipping only slightly increases the error rates; and Gaussian attacks have no notable impact on the error rates. Two exceptions are that Krumâ€™s error rates decrease when the percentage of compromised worker devices increases from 5% to 10% in FigureÂ 2a and from 10% to 15% in FigureÂ 2d. We suspect the reason is that Krum selects one local model as a global model in each iteration. We have similar observations on the other datasets. Therefore, we omit the corresponding results for simplicity.",
            "Worker devices can perform multiple rounds of stochastic gradient descent to update their local models. FigureÂ 4a shows the impact of the number of rounds on the testing error rates of our attack. The testing error rates decrease as we use more rounds of stochastic gradient descent for both no attack and our partial knowledge attack. This is because more rounds of stochastic gradient descent lead to more accurate local models, and the local models on different worker devices are less diverse, leaving a smaller attack space. However, our attack still increases the error rates substantially even if we use more rounds. For instance, our attack still increases the error rate by more than 30% when using 10 rounds of stochastic gradient descent. We note that a large number of rounds result in large computational cost for worker devices, which may be unacceptable for resource-constrained devices such as mobile phones and IoT devices.",
            "Alternative training strategy:Â  Each iteration results in a global model. Instead of selecting the last global model as the final model, an alternative training strategy is to select the global model that has the lowest testing error rate.333We give advantages to the alternative training strategy since we use testing error rate to select the global model. TableÂ 3 shows the testing error rates of various attacks on the DNN classifier for MNIST, when such alternative training strategy is adopted. In these experiments, our attacks attack each iteration of federated learning, and the column â€œNoAttackâ€ corresponds to the scenarios where no iterations are attacked. Compared to TableÂ 2b, this alternative training strategy is slightly more secure against our attacks. However, our attacks are still effective. For instance, for the Krum, trimmed mean, and median aggregation rules, our partial knowledge attacks still increase the testing error rates by 590%, 100%, and 83%, respectively.  Another training strategy is to roll back to a few iterations ago if the master device detects an unusual increase of training error rate. However, such training strategy is not applicable because the training error rates of the global models still decrease until convergence when we perform our attacks in each iteration. In other words, there are no unusual increases of training error rates.",
            "We craft local models based on one aggregation rule and show the attack effectiveness for other aggregation rules.\nTableÂ 4 shows the transferability between aggregation rules, where MNIST and LR classifier are considered.\nWe observe different levels of transferability between aggregation rules. Specifically, Krum based attack can well transfer to trimmed mean and median, e.g., Krum based attack increases the error rate from 0.12 to 0.15 (25% relative increase) for trimmed mean, and from 0.13 to 0.18 (38% relative increase) for median. Trimmed mean based attack does not transfer to Krum but transfers to median well. For instance, trimmed mean based attack increases the error rates from 0.13 to 0.20 (54% relative increase) for median.",
            "We consider the two scenarios because they represent two extremes for distributing data (concentrated or evenly distributed) and we expect one extreme to maximize attack effectiveness.\nTableÂ 5 compares BGA with our attacks. We observe that BGA has limited success at attacking Byzantine-robust aggregation rules, while our attacks can substantially increase the testing error rates. We note that if the federated learning uses the mean aggregation rule BGA is still successful. For instance, when the mean aggregation rule is used, BGA can increase the testing error rate by 50% when distributing the poisoned data to the compromised worker devices uniformly at random. However, when applying our attacks for trimmed mean to attack the mean aggregation rule, we can increase the testing error rates substantially more (see the last two cells in the second row of TableÂ 5).",
            "Defense results:Â  TableÂ 6 shows the defense results of ERR, FLR, and Union, where partial knowledge attacks are considered. We use the default parameter setting discussed in SectionÂ 1, e.g., 100 worker devices, 20% of compromised worker devices, MNIST dataset, and LR classifier. Moreover, we sample 100 testing examples uniformly at random as the validation dataset. Each row of the table corresponds to a defense, e.g., Krum + ERR means that the master device uses ERR to remove the potentially malicious local models and uses Krum as the aggregation rule. Each column indicates the attackerâ€™s assumed aggregation rule when performing attacks, e.g., the column â€œKrumâ€ corresponds to attacks that are based on Krum. We have several observations.",
            "Bulyan is based on Krum. We apply our attacks for Krum to attack Bulyan. TableÂ 7b shows results of attacking Bulyan. The dataset is MNIST, the classifier is logistic regression, m=100ğ‘š100m=100, c=20ğ‘20c=20, Î¸=mâˆ’2â€‹cğœƒğ‘š2ğ‘\\theta=m-2c (Bulyan selects Î¸ğœƒ\\theta local models using Krum), and Î³=Î¸âˆ’2â€‹cğ›¾ğœƒ2ğ‘\\gamma=\\theta-2c (Bulyan takes the mean of Î³ğ›¾\\gamma parameters).\nOur results show that our attacks to Krum can transfer to Bulyan. Specifically, our partial knowledge attack increases the error rate by around 150%, while our full knowledge attack increases the error rate by 165%.",
            "Experimental results: TableÂ 8 empirically compares the deviation goal and directed deviation goal, where MNIST and LR classifier are used.\nFor Krum, both goals achieve high testing error rates. However, for trimmed mean and median, the directed deviation goal achieves significantly higher testing error rates than the deviation goal."
        ]
    },
    "A0.T7.sf2": {
        "caption": "(b) ",
        "table": "<table id=\"A0.T7.sf2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A0.T7.sf2.1.1.1\" class=\"ltx_tr\">\n<th id=\"A0.T7.sf2.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"></th>\n<th id=\"A0.T7.sf2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf2.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Bulyan</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A0.T7.sf2.1.2.1\" class=\"ltx_tr\">\n<td id=\"A0.T7.sf2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf2.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">No attack</span></td>\n<td id=\"A0.T7.sf2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf2.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.14</span></td>\n</tr>\n<tr id=\"A0.T7.sf2.1.3.2\" class=\"ltx_tr\">\n<td id=\"A0.T7.sf2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf2.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Partial Knowledge</span></td>\n<td id=\"A0.T7.sf2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf2.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.36</span></td>\n</tr>\n<tr id=\"A0.T7.sf2.1.4.3\" class=\"ltx_tr\">\n<td id=\"A0.T7.sf2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf2.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Full Knowledge</span></td>\n<td id=\"A0.T7.sf2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 2.0pt;\"><span id=\"A0.T7.sf2.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.38</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Deep neural networks (DNN). For MNIST, Fashion-MNIST, and Breast Cancer Wisconsin (Diagnostic), we use a DNN with the architecture described in TableÂ 7a in Appendix. We use ResNet20Â [28] for CH-MNIST. Our DNN architecture does not necessarily achieve the smallest error rates for the considered datasets, as our goal is not to search for the best DNN architecture. Our goal is to show that our attacks can increase the testing error rates of the learnt DNN classifiers.",
            "Parameter setting:Â  We describe parameter setting for the federated learning algorithms and our attacks. TableÂ 1 summarizes the default setting for key parameters. We use MXNetÂ [12] to implement federated learning and attacks. We repeat each experiment for 50 trials and report the average results. We observed that the variances are very small, so we omit them for simplicity.",
            "Our attacks are effective: TableÂ 2e shows the testing error rates of the compared attacks on the four datasets.\nFirst, these results show that our attacks are effective and substantially outperform existing attacks, i.e., our attacks result in higher error rates. For instance, when dataset is MNIST, classifier is LR, and aggregation rule is Krum, our partial knowledge attack increases the error rate from 0.14 to 0.72 (around 400% relative increase).\nGaussian attacks only increase the error rates in several cases, e.g., median aggregation rule for Fashion-MNIST, and trimmed mean and median for CH-MNIST. Label flipping attacks can increase the error rates for DNN classifiers in some cases but have limited success for LR classifiers.",
            "Impact of the percentage of compromised worker devices:Â  FigureÂ 2 shows the error rates of different attacks as the percentage of compromised worker devices increases on MNIST.\nOur attacks increase the error rates significantly as we compromise more worker devices; label flipping only slightly increases the error rates; and Gaussian attacks have no notable impact on the error rates. Two exceptions are that Krumâ€™s error rates decrease when the percentage of compromised worker devices increases from 5% to 10% in FigureÂ 2a and from 10% to 15% in FigureÂ 2d. We suspect the reason is that Krum selects one local model as a global model in each iteration. We have similar observations on the other datasets. Therefore, we omit the corresponding results for simplicity.",
            "Worker devices can perform multiple rounds of stochastic gradient descent to update their local models. FigureÂ 4a shows the impact of the number of rounds on the testing error rates of our attack. The testing error rates decrease as we use more rounds of stochastic gradient descent for both no attack and our partial knowledge attack. This is because more rounds of stochastic gradient descent lead to more accurate local models, and the local models on different worker devices are less diverse, leaving a smaller attack space. However, our attack still increases the error rates substantially even if we use more rounds. For instance, our attack still increases the error rate by more than 30% when using 10 rounds of stochastic gradient descent. We note that a large number of rounds result in large computational cost for worker devices, which may be unacceptable for resource-constrained devices such as mobile phones and IoT devices.",
            "Alternative training strategy:Â  Each iteration results in a global model. Instead of selecting the last global model as the final model, an alternative training strategy is to select the global model that has the lowest testing error rate.333We give advantages to the alternative training strategy since we use testing error rate to select the global model. TableÂ 3 shows the testing error rates of various attacks on the DNN classifier for MNIST, when such alternative training strategy is adopted. In these experiments, our attacks attack each iteration of federated learning, and the column â€œNoAttackâ€ corresponds to the scenarios where no iterations are attacked. Compared to TableÂ 2b, this alternative training strategy is slightly more secure against our attacks. However, our attacks are still effective. For instance, for the Krum, trimmed mean, and median aggregation rules, our partial knowledge attacks still increase the testing error rates by 590%, 100%, and 83%, respectively.  Another training strategy is to roll back to a few iterations ago if the master device detects an unusual increase of training error rate. However, such training strategy is not applicable because the training error rates of the global models still decrease until convergence when we perform our attacks in each iteration. In other words, there are no unusual increases of training error rates.",
            "We craft local models based on one aggregation rule and show the attack effectiveness for other aggregation rules.\nTableÂ 4 shows the transferability between aggregation rules, where MNIST and LR classifier are considered.\nWe observe different levels of transferability between aggregation rules. Specifically, Krum based attack can well transfer to trimmed mean and median, e.g., Krum based attack increases the error rate from 0.12 to 0.15 (25% relative increase) for trimmed mean, and from 0.13 to 0.18 (38% relative increase) for median. Trimmed mean based attack does not transfer to Krum but transfers to median well. For instance, trimmed mean based attack increases the error rates from 0.13 to 0.20 (54% relative increase) for median.",
            "We consider the two scenarios because they represent two extremes for distributing data (concentrated or evenly distributed) and we expect one extreme to maximize attack effectiveness.\nTableÂ 5 compares BGA with our attacks. We observe that BGA has limited success at attacking Byzantine-robust aggregation rules, while our attacks can substantially increase the testing error rates. We note that if the federated learning uses the mean aggregation rule BGA is still successful. For instance, when the mean aggregation rule is used, BGA can increase the testing error rate by 50% when distributing the poisoned data to the compromised worker devices uniformly at random. However, when applying our attacks for trimmed mean to attack the mean aggregation rule, we can increase the testing error rates substantially more (see the last two cells in the second row of TableÂ 5).",
            "Defense results:Â  TableÂ 6 shows the defense results of ERR, FLR, and Union, where partial knowledge attacks are considered. We use the default parameter setting discussed in SectionÂ 1, e.g., 100 worker devices, 20% of compromised worker devices, MNIST dataset, and LR classifier. Moreover, we sample 100 testing examples uniformly at random as the validation dataset. Each row of the table corresponds to a defense, e.g., Krum + ERR means that the master device uses ERR to remove the potentially malicious local models and uses Krum as the aggregation rule. Each column indicates the attackerâ€™s assumed aggregation rule when performing attacks, e.g., the column â€œKrumâ€ corresponds to attacks that are based on Krum. We have several observations.",
            "Bulyan is based on Krum. We apply our attacks for Krum to attack Bulyan. TableÂ 7b shows results of attacking Bulyan. The dataset is MNIST, the classifier is logistic regression, m=100ğ‘š100m=100, c=20ğ‘20c=20, Î¸=mâˆ’2â€‹cğœƒğ‘š2ğ‘\\theta=m-2c (Bulyan selects Î¸ğœƒ\\theta local models using Krum), and Î³=Î¸âˆ’2â€‹cğ›¾ğœƒ2ğ‘\\gamma=\\theta-2c (Bulyan takes the mean of Î³ğ›¾\\gamma parameters).\nOur results show that our attacks to Krum can transfer to Bulyan. Specifically, our partial knowledge attack increases the error rate by around 150%, while our full knowledge attack increases the error rate by 165%.",
            "Experimental results: TableÂ 8 empirically compares the deviation goal and directed deviation goal, where MNIST and LR classifier are used.\nFor Krum, both goals achieve high testing error rates. However, for trimmed mean and median, the directed deviation goal achieves significantly higher testing error rates than the deviation goal."
        ]
    },
    "A0.T8": {
        "caption": "Table 8: Testing error rates of our attacks based on the deviation goal and directed deviation goal.",
        "table": "<table id=\"A0.T8.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A0.T8.1.1.1\" class=\"ltx_tr\">\n<th id=\"A0.T8.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"></th>\n<th id=\"A0.T8.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></th>\n<th id=\"A0.T8.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed mean</span></th>\n<th id=\"A0.T8.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A0.T8.1.2.1\" class=\"ltx_tr\">\n<td id=\"A0.T8.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Deviation goal</span></td>\n<td id=\"A0.T8.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.87</span></td>\n<td id=\"A0.T8.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.10</span></td>\n<td id=\"A0.T8.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.2.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.12</span></td>\n</tr>\n<tr id=\"A0.T8.1.3.2\" class=\"ltx_tr\">\n<td id=\"A0.T8.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Directed deviation goal</span></td>\n<td id=\"A0.T8.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.80</span></td>\n<td id=\"A0.T8.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.52</span></td>\n<td id=\"A0.T8.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:-0.5pt;padding-bottom:-0.5pt;\"><span id=\"A0.T8.1.3.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.29</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Experimental results: TableÂ 8 empirically compares the deviation goal and directed deviation goal, where MNIST and LR classifier are used.\nFor Krum, both goals achieve high testing error rates. However, for trimmed mean and median, the directed deviation goal achieves significantly higher testing error rates than the deviation goal."
        ]
    }
}