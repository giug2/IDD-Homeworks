{
    "PAPER'S NUMBER OF TABLES": 3,
    "S6.T1": {
        "caption": "Table 1: Model accuracy while applying the defense mechanisms.\nPN: pure noise, DP: differential privacy, GC: gradient compression.",
        "table": "<table id=\"S6.T1.6\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T1.6.7.1\" class=\"ltx_tr\">\n<th id=\"S6.T1.6.7.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"></th>\n<th id=\"S6.T1.6.7.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"3\">FedSGD (Acc. = 93.3%)</th>\n<th id=\"S6.T1.6.7.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" colspan=\"3\">FedAvg (Acc. = 94.5%)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">\n<span id=\"S6.T1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">PN</span> (<math id=\"S6.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sigma\" display=\"inline\"><semantics id=\"S6.T1.1.1.1.m1.1a\"><mi id=\"S6.T1.1.1.1.m1.1.1\" xref=\"S6.T1.1.1.1.m1.1.1.cmml\">σ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.1.1.1.m1.1b\"><ci id=\"S6.T1.1.1.1.m1.1.1.cmml\" xref=\"S6.T1.1.1.1.m1.1.1\">𝜎</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.1.1.1.m1.1c\">\\sigma</annotation></semantics></math>)</th>\n<td id=\"S6.T1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.01</td>\n<td id=\"S6.T1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.1</td>\n<td id=\"S6.T1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1</td>\n<td id=\"S6.T1.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.01</td>\n<td id=\"S6.T1.1.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\">0.1</td>\n<td id=\"S6.T1.1.1.7\" class=\"ltx_td ltx_align_left ltx_border_t\">1</td>\n</tr>\n<tr id=\"S6.T1.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T1.3.3.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Acc. (%)</th>\n<td id=\"S6.T1.3.3.4\" class=\"ltx_td ltx_align_left\">93.4</td>\n<td id=\"S6.T1.3.3.5\" class=\"ltx_td ltx_align_left\">89.9</td>\n<td id=\"S6.T1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_r\">\n<math id=\"S6.T1.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\leq\" display=\"inline\"><semantics id=\"S6.T1.2.2.1.m1.1a\"><mo id=\"S6.T1.2.2.1.m1.1.1\" xref=\"S6.T1.2.2.1.m1.1.1.cmml\">≤</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.2.2.1.m1.1b\"><leq id=\"S6.T1.2.2.1.m1.1.1.cmml\" xref=\"S6.T1.2.2.1.m1.1.1\"></leq></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.2.2.1.m1.1c\">\\leq</annotation></semantics></math> 10.1</td>\n<td id=\"S6.T1.3.3.6\" class=\"ltx_td ltx_align_left\">94.6</td>\n<td id=\"S6.T1.3.3.7\" class=\"ltx_td ltx_align_left\">91.4</td>\n<td id=\"S6.T1.3.3.2\" class=\"ltx_td ltx_align_left\">\n<math id=\"S6.T1.3.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\leq\" display=\"inline\"><semantics id=\"S6.T1.3.3.2.m1.1a\"><mo id=\"S6.T1.3.3.2.m1.1.1\" xref=\"S6.T1.3.3.2.m1.1.1.cmml\">≤</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.3.3.2.m1.1b\"><leq id=\"S6.T1.3.3.2.m1.1.1.cmml\" xref=\"S6.T1.3.3.2.m1.1.1\"></leq></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.3.3.2.m1.1c\">\\leq</annotation></semantics></math> 13.5</td>\n</tr>\n<tr id=\"S6.T1.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">\n<span id=\"S6.T1.4.4.1.1\" class=\"ltx_text ltx_font_bold\">DP</span> (<math id=\"S6.T1.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\beta\" display=\"inline\"><semantics id=\"S6.T1.4.4.1.m1.1a\"><mi id=\"S6.T1.4.4.1.m1.1.1\" xref=\"S6.T1.4.4.1.m1.1.1.cmml\">β</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.4.4.1.m1.1b\"><ci id=\"S6.T1.4.4.1.m1.1.1.cmml\" xref=\"S6.T1.4.4.1.m1.1.1\">𝛽</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.4.4.1.m1.1c\">\\beta</annotation></semantics></math>)</th>\n<td id=\"S6.T1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_t\">10</td>\n<td id=\"S6.T1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_t\">5</td>\n<td id=\"S6.T1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1</td>\n<td id=\"S6.T1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_t\">10</td>\n<td id=\"S6.T1.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_t\">5</td>\n<td id=\"S6.T1.4.4.7\" class=\"ltx_td ltx_align_left ltx_border_t\">1</td>\n</tr>\n<tr id=\"S6.T1.5.5\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Acc. (%)</th>\n<td id=\"S6.T1.5.5.3\" class=\"ltx_td ltx_align_left\">89</td>\n<td id=\"S6.T1.5.5.4\" class=\"ltx_td ltx_align_left\">86.1</td>\n<td id=\"S6.T1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_r\">\n<math id=\"S6.T1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\leq\" display=\"inline\"><semantics id=\"S6.T1.5.5.1.m1.1a\"><mo id=\"S6.T1.5.5.1.m1.1.1\" xref=\"S6.T1.5.5.1.m1.1.1.cmml\">≤</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.5.5.1.m1.1b\"><leq id=\"S6.T1.5.5.1.m1.1.1.cmml\" xref=\"S6.T1.5.5.1.m1.1.1\"></leq></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.5.5.1.m1.1c\">\\leq</annotation></semantics></math> 52.4</td>\n<td id=\"S6.T1.5.5.5\" class=\"ltx_td ltx_align_left\">91.2</td>\n<td id=\"S6.T1.5.5.6\" class=\"ltx_td ltx_align_left\">90.5</td>\n<td id=\"S6.T1.5.5.7\" class=\"ltx_td ltx_align_left\">52.5</td>\n</tr>\n<tr id=\"S6.T1.6.6\" class=\"ltx_tr\">\n<th id=\"S6.T1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">\n<span id=\"S6.T1.6.6.1.1\" class=\"ltx_text ltx_font_bold\">GC</span> (<math id=\"S6.T1.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"\\theta\\%\" display=\"inline\"><semantics id=\"S6.T1.6.6.1.m1.1a\"><mrow id=\"S6.T1.6.6.1.m1.1.1\" xref=\"S6.T1.6.6.1.m1.1.1.cmml\"><mi id=\"S6.T1.6.6.1.m1.1.1.2\" xref=\"S6.T1.6.6.1.m1.1.1.2.cmml\">θ</mi><mo id=\"S6.T1.6.6.1.m1.1.1.1\" xref=\"S6.T1.6.6.1.m1.1.1.1.cmml\">%</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.6.6.1.m1.1b\"><apply id=\"S6.T1.6.6.1.m1.1.1.cmml\" xref=\"S6.T1.6.6.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T1.6.6.1.m1.1.1.1.cmml\" xref=\"S6.T1.6.6.1.m1.1.1.1\">percent</csymbol><ci id=\"S6.T1.6.6.1.m1.1.1.2.cmml\" xref=\"S6.T1.6.6.1.m1.1.1.2\">𝜃</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.6.6.1.m1.1c\">\\theta\\%</annotation></semantics></math>)</th>\n<td id=\"S6.T1.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_t\">20</td>\n<td id=\"S6.T1.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_t\">40</td>\n<td id=\"S6.T1.6.6.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">80</td>\n<td id=\"S6.T1.6.6.5\" class=\"ltx_td ltx_align_left ltx_border_t\">20</td>\n<td id=\"S6.T1.6.6.6\" class=\"ltx_td ltx_align_left ltx_border_t\">40</td>\n<td id=\"S6.T1.6.6.7\" class=\"ltx_td ltx_align_left ltx_border_t\">80</td>\n</tr>\n<tr id=\"S6.T1.6.8.1\" class=\"ltx_tr\">\n<th id=\"S6.T1.6.8.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\">Acc. (%)</th>\n<td id=\"S6.T1.6.8.1.2\" class=\"ltx_td ltx_align_left ltx_border_b\">93.4</td>\n<td id=\"S6.T1.6.8.1.3\" class=\"ltx_td ltx_align_left ltx_border_b\">93.7</td>\n<td id=\"S6.T1.6.8.1.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">91.9</td>\n<td id=\"S6.T1.6.8.1.5\" class=\"ltx_td ltx_align_left ltx_border_b\">92.8</td>\n<td id=\"S6.T1.6.8.1.6\" class=\"ltx_td ltx_align_left ltx_border_b\">91.6</td>\n<td id=\"S6.T1.6.8.1.7\" class=\"ltx_td ltx_align_left ltx_border_b\">89.3</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In Figure 7 (a), we can see that the higher the magnitude of the noise the less accurate the attack.\nThis is expected as the attack partially uses the magnitude of the gradients to infer the labels following Property 2. Interestingly, we observe that the noise has less effect on the attack when the batch size is increasing.\nWe investigated this observation further by inspecting the values of the gradients before and after noise addition.\nOur empirical analysis showed earlier in Figure 3 (a, b) that the majority of gradients gisubscript𝑔𝑖g_{i} have values close to zero when they correspond to labels not present in the batch. Adding noise to such small gradient values might lead to flipping their sign, and consequently, disrupting Property 1, which is one of the basis of the attack.\nFor batch sizes B<n𝐵𝑛B<n with n𝑛n as the number of classes, not all the labels will be present in the batch, so the flipping effect can be prominent on the attack success rate.\nWhereas, in bigger batches, it is more likely to have more differing labels, thus, their gradients values are not close to zero.\nAs a result, adding a small amount of noise does not lead to sign flipping.\nThis also explains the stability of ASR values when B≥n𝐵𝑛B\\geq n. \nOverall, adding noise does not eliminate the risk completely while reducing the model accuracy (see Table 1). \nAs we can see, LLG + maintains higher ASRs than the random guess for all the test noise scales.",
            "Figure 7 (b) shows that adding noise of σ=0.1𝜎0.1\\sigma=0.1 with clipping bound β=1𝛽1\\beta=1, is an effective defense against LLG + for batch sizes B>16𝐵16B>16, where the ASR drops beyond the random guess.\nHowever, this leads to a significant drop in the model accuracy as shown in Table 1."
        ]
    },
    "Sx2.T2": {
        "caption": "Table 2: Architecture of CNN, the default model in the experimental setting.",
        "table": "<table id=\"Sx2.T2.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"Sx2.T2.4.1.1\" class=\"ltx_tr\">\n<th id=\"Sx2.T2.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Layer</th>\n<th id=\"Sx2.T2.4.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Size</th>\n<th id=\"Sx2.T2.4.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Activation function</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx2.T2.4.2.1\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.4.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">(input)</td>\n<td id=\"Sx2.T2.4.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">-</td>\n<td id=\"Sx2.T2.4.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">-</td>\n</tr>\n<tr id=\"Sx2.T2.4.3.2\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.4.3.2.1\" class=\"ltx_td ltx_align_left\">Conv 2D</td>\n<td id=\"Sx2.T2.4.3.2.2\" class=\"ltx_td ltx_align_left\">channels x 12</td>\n<td id=\"Sx2.T2.4.3.2.3\" class=\"ltx_td ltx_align_left\">Sigmoid</td>\n</tr>\n<tr id=\"Sx2.T2.4.4.3\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.4.4.3.1\" class=\"ltx_td ltx_align_left\">Conv 2D</td>\n<td id=\"Sx2.T2.4.4.3.2\" class=\"ltx_td ltx_align_left\">12 x 12</td>\n<td id=\"Sx2.T2.4.4.3.3\" class=\"ltx_td ltx_align_left\">Sigmoid</td>\n</tr>\n<tr id=\"Sx2.T2.4.5.4\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.4.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_b\">Conv 2D</td>\n<td id=\"Sx2.T2.4.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_b\">12 x 12</td>\n<td id=\"Sx2.T2.4.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_b\">Sigmoid</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We use a CNN model with three convolutional layers (see Appendix, Table 2) as our default model for a classification task. The activation function is Sigmoid, and we use SGD as an optimizer with learning rate 0.10.10.1 and cross-entropy as loss function.\nWe use batches of varying sizes B=2k:k∈[0,7]:𝐵superscript2𝑘𝑘07B=2^{k}:k\\in[0,7].\nWhen applying the attack for FedSGD, we feed the model with one batch,\nand we use γ=10𝛾10\\gamma=10 batches for FedAvg. \nThe label distribution in a batch can be balanced or unbalanced.\nFor balanced data, the samples of the batch are selected randomly from the dataset.\nFor unbalanced data, we select 50% of the batch samples from one random label i𝑖i and 25% from another label j𝑗j.\nThe remaining 25% of the batch is chosen randomly.\nWe initialize the model with random weights and repeat each experiment 100 times, then report the mean values for analysis and discussion."
        ]
    },
    "Sx2.T3": {
        "caption": "Table 3: Architecture of LeNet network, a very common architecture adopted in computer vision.",
        "table": "<table id=\"Sx2.T3.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"Sx2.T3.4.1.1\" class=\"ltx_tr\">\n<th id=\"Sx2.T3.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Layer</th>\n<th id=\"Sx2.T3.4.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Size</th>\n<th id=\"Sx2.T3.4.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Activation function</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx2.T3.4.2.1\" class=\"ltx_tr\">\n<td id=\"Sx2.T3.4.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">(input)</td>\n<td id=\"Sx2.T3.4.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">-</td>\n<td id=\"Sx2.T3.4.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">-</td>\n</tr>\n<tr id=\"Sx2.T3.4.3.2\" class=\"ltx_tr\">\n<td id=\"Sx2.T3.4.3.2.1\" class=\"ltx_td ltx_align_left\">Conv 2D</td>\n<td id=\"Sx2.T3.4.3.2.2\" class=\"ltx_td ltx_align_left\">1 x 6</td>\n<td id=\"Sx2.T3.4.3.2.3\" class=\"ltx_td ltx_align_left\">ReLU</td>\n</tr>\n<tr id=\"Sx2.T3.4.4.3\" class=\"ltx_tr\">\n<td id=\"Sx2.T3.4.4.3.1\" class=\"ltx_td ltx_align_left\">Maxpool</td>\n<td id=\"Sx2.T3.4.4.3.2\" class=\"ltx_td ltx_align_left\">2 x 2</td>\n<td id=\"Sx2.T3.4.4.3.3\" class=\"ltx_td ltx_align_left\">-</td>\n</tr>\n<tr id=\"Sx2.T3.4.5.4\" class=\"ltx_tr\">\n<td id=\"Sx2.T3.4.5.4.1\" class=\"ltx_td ltx_align_left\">Conv 2D</td>\n<td id=\"Sx2.T3.4.5.4.2\" class=\"ltx_td ltx_align_left\">6 x 16</td>\n<td id=\"Sx2.T3.4.5.4.3\" class=\"ltx_td ltx_align_left\">ReLU</td>\n</tr>\n<tr id=\"Sx2.T3.4.6.5\" class=\"ltx_tr\">\n<td id=\"Sx2.T3.4.6.5.1\" class=\"ltx_td ltx_align_left\">Maxpool</td>\n<td id=\"Sx2.T3.4.6.5.2\" class=\"ltx_td ltx_align_left\">2</td>\n<td id=\"Sx2.T3.4.6.5.3\" class=\"ltx_td ltx_align_left\">-</td>\n</tr>\n<tr id=\"Sx2.T3.4.7.6\" class=\"ltx_tr\">\n<td id=\"Sx2.T3.4.7.6.1\" class=\"ltx_td ltx_align_left\">Linear</td>\n<td id=\"Sx2.T3.4.7.6.2\" class=\"ltx_td ltx_align_left\">16 x 6</td>\n<td id=\"Sx2.T3.4.7.6.3\" class=\"ltx_td ltx_align_left\">ReLU</td>\n</tr>\n<tr id=\"Sx2.T3.4.8.7\" class=\"ltx_tr\">\n<td id=\"Sx2.T3.4.8.7.1\" class=\"ltx_td ltx_align_left\">Linear</td>\n<td id=\"Sx2.T3.4.8.7.2\" class=\"ltx_td ltx_align_left\">120 x 84</td>\n<td id=\"Sx2.T3.4.8.7.3\" class=\"ltx_td ltx_align_left\">ReLU</td>\n</tr>\n<tr id=\"Sx2.T3.4.9.8\" class=\"ltx_tr\">\n<td id=\"Sx2.T3.4.9.8.1\" class=\"ltx_td ltx_align_left ltx_border_b\">Linear</td>\n<td id=\"Sx2.T3.4.9.8.2\" class=\"ltx_td ltx_align_left ltx_border_b\">84 x 10</td>\n<td id=\"Sx2.T3.4.9.8.3\" class=\"ltx_td ltx_align_left ltx_border_b\">ReLU</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            []
        ]
    }
}