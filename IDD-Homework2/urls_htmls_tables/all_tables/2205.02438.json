{
    "PAPER'S NUMBER OF TABLES": 7,
    "S6.T1": {
        "caption": "TABLE I: THE COMPARISION OF BEST TEST ACCURACY ON Fashion-MNIST WITH DIFFERENT Œ±ùõº\\alpha.",
        "table": "<table id=\"S6.T1.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T1.6.4\" class=\"ltx_tr\">\n<th id=\"S6.T1.6.4.5\" class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"></th>\n<td id=\"S6.T1.6.4.6\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.6.4.6.1\" class=\"ltx_text ltx_font_bold\">Algorithms</span></td>\n<td id=\"S6.T1.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">\n<math id=\"S6.T1.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T1.3.1.1.m1.1a\"><mi id=\"S6.T1.3.1.1.m1.1.1\" xref=\"S6.T1.3.1.1.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.3.1.1.m1.1b\"><ci id=\"S6.T1.3.1.1.m1.1.1.cmml\" xref=\"S6.T1.3.1.1.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.3.1.1.m1.1c\">\\alpha</annotation></semantics></math>=0.5</td>\n<td id=\"S6.T1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">\n<math id=\"S6.T1.4.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T1.4.2.2.m1.1a\"><mi id=\"S6.T1.4.2.2.m1.1.1\" xref=\"S6.T1.4.2.2.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.4.2.2.m1.1b\"><ci id=\"S6.T1.4.2.2.m1.1.1.cmml\" xref=\"S6.T1.4.2.2.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.4.2.2.m1.1c\">\\alpha</annotation></semantics></math>=1</td>\n<td id=\"S6.T1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">\n<math id=\"S6.T1.5.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T1.5.3.3.m1.1a\"><mi id=\"S6.T1.5.3.3.m1.1.1\" xref=\"S6.T1.5.3.3.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.5.3.3.m1.1b\"><ci id=\"S6.T1.5.3.3.m1.1.1.cmml\" xref=\"S6.T1.5.3.3.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.5.3.3.m1.1c\">\\alpha</annotation></semantics></math>=5</td>\n<td id=\"S6.T1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">\n<math id=\"S6.T1.6.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T1.6.4.4.m1.1a\"><mi id=\"S6.T1.6.4.4.m1.1.1\" xref=\"S6.T1.6.4.4.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.6.4.4.m1.1b\"><ci id=\"S6.T1.6.4.4.m1.1.1.cmml\" xref=\"S6.T1.6.4.4.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.6.4.4.m1.1c\">\\alpha</annotation></semantics></math>=10</td>\n</tr>\n<tr id=\"S6.T1.6.5.1\" class=\"ltx_tr\">\n<th id=\"S6.T1.6.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"3\"><span id=\"S6.T1.6.5.1.1.1\" class=\"ltx_text\">\n<span id=\"S6.T1.6.5.1.1.1.1\" class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:8.8pt;height:19.4pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:19.4pt;transform:translate(-5.33pt,-4.36pt) rotate(-90deg) ;\">\n<span id=\"S6.T1.6.5.1.1.1.1.1\" class=\"ltx_p\"><span id=\"S6.T1.6.5.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Sup.</span></span>\n</span></span></span></th>\n<td id=\"S6.T1.6.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FedAvg-SL</td>\n<td id=\"S6.T1.6.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">81.71</td>\n<td id=\"S6.T1.6.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">82.09</td>\n<td id=\"S6.T1.6.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">81.98</td>\n<td id=\"S6.T1.6.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">82.32</td>\n</tr>\n<tr id=\"S6.T1.6.6.2\" class=\"ltx_tr\">\n<td id=\"S6.T1.6.6.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FedProx-SL</td>\n<td id=\"S6.T1.6.6.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">81.83</td>\n<td id=\"S6.T1.6.6.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">83.01</td>\n<td id=\"S6.T1.6.6.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">82.65</td>\n<td id=\"S6.T1.6.6.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">83.63</td>\n</tr>\n<tr id=\"S6.T1.6.7.3\" class=\"ltx_tr\">\n<td id=\"S6.T1.6.7.3.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FedBN-SL</td>\n<td id=\"S6.T1.6.7.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">75.79</td>\n<td id=\"S6.T1.6.7.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">79.91</td>\n<td id=\"S6.T1.6.7.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">82.85</td>\n<td id=\"S6.T1.6.7.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">82.18</td>\n</tr>\n<tr id=\"S6.T1.6.8.4\" class=\"ltx_tr\">\n<th id=\"S6.T1.6.8.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"7\"><span id=\"S6.T1.6.8.4.1.1\" class=\"ltx_text\">\n<span id=\"S6.T1.6.8.4.1.1.1\" class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:8.8pt;height:43.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:43.9pt;transform:translate(-17.56pt,-16.58pt) rotate(-90deg) ;\">\n<span id=\"S6.T1.6.8.4.1.1.1.1\" class=\"ltx_p\"><span id=\"S6.T1.6.8.4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Semi-Sup.</span></span>\n</span></span></span></th>\n<td id=\"S6.T1.6.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FixAvg</td>\n<td id=\"S6.T1.6.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">75.94</td>\n<td id=\"S6.T1.6.8.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">76.78</td>\n<td id=\"S6.T1.6.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">78.68</td>\n<td id=\"S6.T1.6.8.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">79.59</td>\n</tr>\n<tr id=\"S6.T1.6.9.5\" class=\"ltx_tr\">\n<td id=\"S6.T1.6.9.5.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FixProx</td>\n<td id=\"S6.T1.6.9.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">76.77</td>\n<td id=\"S6.T1.6.9.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">77.46</td>\n<td id=\"S6.T1.6.9.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">77.64</td>\n<td id=\"S6.T1.6.9.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">78.00</td>\n</tr>\n<tr id=\"S6.T1.6.10.6\" class=\"ltx_tr\">\n<td id=\"S6.T1.6.10.6.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FixBN</td>\n<td id=\"S6.T1.6.10.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">76.40</td>\n<td id=\"S6.T1.6.10.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">79.22</td>\n<td id=\"S6.T1.6.10.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">80.48</td>\n<td id=\"S6.T1.6.10.6.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.6.10.6.5.1\" class=\"ltx_text ltx_font_bold\">81.88</span></td>\n</tr>\n<tr id=\"S6.T1.6.11.7\" class=\"ltx_tr\">\n<td id=\"S6.T1.6.11.7.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FedPer</td>\n<td id=\"S6.T1.6.11.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">60.65</td>\n<td id=\"S6.T1.6.11.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">50.90</td>\n<td id=\"S6.T1.6.11.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">37.89</td>\n<td id=\"S6.T1.6.11.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">38.05</td>\n</tr>\n<tr id=\"S6.T1.6.12.8\" class=\"ltx_tr\">\n<td id=\"S6.T1.6.12.8.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">LG-FedAvg</td>\n<td id=\"S6.T1.6.12.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">74.64</td>\n<td id=\"S6.T1.6.12.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">78.49</td>\n<td id=\"S6.T1.6.12.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">75.39</td>\n<td id=\"S6.T1.6.12.8.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">66.54</td>\n</tr>\n<tr id=\"S6.T1.6.13.9\" class=\"ltx_tr\">\n<td id=\"S6.T1.6.13.9.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">pFedMe</td>\n<td id=\"S6.T1.6.13.9.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">44.53</td>\n<td id=\"S6.T1.6.13.9.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">49.01</td>\n<td id=\"S6.T1.6.13.9.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">47.38</td>\n<td id=\"S6.T1.6.13.9.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">45.39</td>\n</tr>\n<tr id=\"S6.T1.6.14.10\" class=\"ltx_tr\">\n<td id=\"S6.T1.6.14.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">UM-pFSSL</td>\n<td id=\"S6.T1.6.14.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.6.14.10.2.1\" class=\"ltx_text ltx_font_bold\">79.00</span></td>\n<td id=\"S6.T1.6.14.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.6.14.10.3.1\" class=\"ltx_text ltx_font_bold\">80.93</span></td>\n<td id=\"S6.T1.6.14.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.6.14.10.4.1\" class=\"ltx_text ltx_font_bold\">81.16</span></td>\n<td id=\"S6.T1.6.14.10.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">81.49</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this subsection, we compare the results of UM-pFSSL with Non-IID schemes and personalized federated learning methods. We run each experiment 20 times and take the average as final result.",
                "Impact of heterogeneity:",
                " TABLE ",
                "I",
                " and TABLE ",
                "II",
                " illustrate the best achievable test accuracy of our proposed method and compared group on different datasets (Sup. represents the supervised methods). From TABLE ",
                "I",
                " we can observe that, on Fashion-MNIST, UM-pFSSL outperforms most of the Non-IID FL methods and personalized methods with highly heterogeneous data. With the heterogeneity decreasing (",
                "Œ±",
                "ùõº",
                "\\alpha",
                " increasing), the baseline methods and Non-IID FL methods obtain noticeable performance improvement (about 2% ",
                "‚àº",
                "similar-to",
                "\\sim",
                " 7%) while the personalized methods suffer the accuracy decline. Compared with other peer schemes, UM-pFSSL is able to retain a well-accepted accuracy ",
                ">",
                ">",
                " 79% with data dissimilarity across clients varying. TABLE ",
                "II",
                " depicts the result on CIFAR-10 dataset. In this task, personalized methods also show that performance degrades as the heterogeneity increases. The UM-pFSSL obtains comparable performance and even higher accuracy than baseline method FedAvg-SL, although the performance improvement is slightly weaker than the Non-IID methods FixAvg, FixProx and FixBN. The reason behind is that, under the highly heterogeneous setting, the helper selection mechanism can pick out the most related clients that can give most confident prediction about local unlabeled data. On the contrary, in nearly homogeneous context, almost all clients contain the similar distribution, the client with the largest labeled dataset will predominate the helper list of all clients. The potential knowledge aggregation is weakened in this scenario; thus, the performance does not show significant growth.",
                "Learning efficiency:",
                " Figs. ",
                "4",
                " and ",
                "5",
                " visualize the curve of the average validation accuracy during the training procedure on Fashion-MNIST and CIFAR-10, respectively. As shown in Fig. ",
                "4",
                ", the personalized methods can acquire better accuracy improvement in the first few rounds, especially the LG-FedAvg and UM-pFSSL. As the training rounds increase, Non-IID methods show precipitous accuracy upgrading and quickly turn to flat convergence, while the LG-FedAvg and UM-pFSSL have a more smooth training curve. Additionally, compared to other personalized methods, UM-pFSSL keeps the performance superiority as the heterogeneity decreases. As shown in Fig. ",
                "5",
                ", for more complicate learning task CIFAR-10, the Non-IID methods tend to overfit after 100 rounds and end up to inferior validation accuracy. The UM-pFSSL shows more smooth learning curve and better performance than personalized methods and Non-IID methods with highly heterogeneous data distribution (",
                "Œ±",
                "=",
                "0.5",
                "ùõº",
                "0.5",
                "\\alpha=0.5",
                "). The comparisons indicate that our proposed methods can achieve more stable training and benefit from the heterogeneity of data. The main reason is the pseudo-label selection approach can collect the most useful information from related helpers. With higher the heterogeneity in distributed datasets, each selected helper can only provide confident predictions to a fraction of unlabeled data, thus the potential knowledge aggregation integrates more helpers and obtain more preferable and robust performance.",
                "Performance fairness:",
                " In personalized FL system, the divergence of local performance between clients can be utilized to qualify the fairness of the FL methods. Specifically, we adopt the variance of the test accuracy of different clients to compare the fairness of our proposed UM-pFSSL with other methods. As shown in Fig. ",
                "6",
                "(a), the most biased method is the LG-FedAvg, which achieves the secondary performance among the personalized methods. In comparison, other methods obviously achieve more unbiased results with the ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " increases. From Fig. ",
                "6",
                "(b), most of the compared schemes obtain evident decrease in variance with ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " increases, and the UM-pFSSL reaches the lowest accuracy variance with ",
                "Œ±",
                "=",
                "5",
                "ùõº",
                "5",
                "\\alpha=5",
                ". Based on these phenomena, we can easily obtain that, on both datasets, the UM-pFSSL achieves the least biased results with different degree of heterogeneity. Combined with the results in Figs. ",
                "4",
                " and ",
                "5",
                ", the UM-pFSSL shows both superior accuracy and comparable fairness in comparison with Non-IID and personalized methods, especially with massive data heterogeneity.",
                "Communication cost:",
                " With a greedily searching strategy in helper-selection stage, the messages transmitted through network have the size:",
                "which includes the model upload of ",
                "œÑ",
                "‚Äã",
                "K",
                "ùúè",
                "ùêæ",
                "\\tau K",
                " selected clients and peer model download (",
                "œÑ",
                "ùúè",
                "\\tau",
                " is the sample rate for training nodes, ",
                "K",
                "ùêæ",
                "K",
                " is the total number of clients); ",
                "|",
                "w",
                "|",
                "ùë§",
                "|w|",
                " denotes parameter size of the uniform neural architecture, and ",
                "n",
                "ùëõ",
                "n",
                " is the number of rounds.",
                "With the helper selection protocol, in first ",
                "F",
                "ùêπ",
                "F",
                " rounds, we replace ",
                "R",
                "ùëÖ",
                "R",
                " helpers in the helper list and update the models of total ",
                "M",
                "ùëÄ",
                "M",
                " helpers every ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                " rounds through cloud server (these operations are executed on all ",
                "K",
                "ùêæ",
                "K",
                " clients). In some cases, the update or replacement should be skipped if there is no modification of existing ",
                "M",
                "ùëÄ",
                "M",
                " helpers or suitable substitutes for ",
                "R",
                "ùëÖ",
                "R",
                " helpers are not found. Therefore, the upper bound of the communication cost is",
                "The difference of ",
                "Cost",
                "2",
                "subscript",
                "Cost",
                "2",
                "\\operatorname{Cost}_{2}",
                " and ",
                "Cost",
                "1",
                "subscript",
                "Cost",
                "1",
                "\\operatorname{Cost}_{1}",
                " can be derived as",
                "Physically, ",
                "F",
                "‚Äã",
                "R",
                "ùêπ",
                "ùëÖ",
                "FR",
                " in Eq. (29) represents the number of helpers that each user can search for during the entire training period. In the experiments, we set ",
                "F",
                "ùêπ",
                "F",
                " to 30 and ",
                "R",
                "ùëÖ",
                "R",
                " to 2 by default. In such a case, we have ",
                "œÑ",
                "‚Äã",
                "K",
                "‚Äã",
                "n",
                "=",
                "2000",
                "ùúè",
                "ùêæ",
                "ùëõ",
                "2000",
                "\\tau Kn=2000",
                ", ",
                "F",
                "‚Äã",
                "R",
                "=",
                "60",
                "ùêπ",
                "ùëÖ",
                "60",
                "FR=60",
                " and ",
                "n",
                "‚Äã",
                "(",
                "M",
                "+",
                "œÑ",
                "‚Äã",
                "ŒΩ",
                ")",
                "/",
                "ŒΩ",
                "=",
                "120",
                "ùëõ",
                "ùëÄ",
                "ùúè",
                "ùúà",
                "ùúà",
                "120",
                "n(M+\\tau\\nu)/\\nu=120",
                ". There is a significant gap between ",
                "Cost",
                "1",
                "subscript",
                "Cost",
                "1",
                "\\operatorname{Cost}_{1}",
                " and ",
                "Cost",
                "2",
                "subscript",
                "Cost",
                "2",
                "\\operatorname{Cost}_{2}",
                ", more than 90% of the communication cost is saved. To intuitively reveal the effect of ",
                "F",
                "‚Äã",
                "R",
                "ùêπ",
                "ùëÖ",
                "FR",
                ", we evaluate the communication cost of UM-pFSSL on two datasets by setting ",
                "F",
                "ùêπ",
                "F",
                " to different number with ",
                "Œ±",
                "=",
                "0.5",
                "ùõº",
                "0.5",
                "\\alpha=0.5",
                ". As shown in Fig. ",
                "7",
                ", higher ",
                "F",
                "ùêπ",
                "F",
                " introduces more communication burden of the system and but always improves the test accuracy accordingly; while ",
                "F",
                "ùêπ",
                "F",
                " exceeds 30, the performance improvement effect gradually weakens. The results show that, our scheme can save considerable communication overhead with acceptable performance sacrifice."
            ]
        ]
    },
    "S6.T2": {
        "caption": "TABLE II: THE COMPARISION OF BEST TEST ACCURACY ON CIFAR-10 WITH DIFFERENT Œ±ùõº\\alpha.",
        "table": "<table id=\"S6.T2.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T2.6.4\" class=\"ltx_tr\">\n<th id=\"S6.T2.6.4.5\" class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"></th>\n<td id=\"S6.T2.6.4.6\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T2.6.4.6.1\" class=\"ltx_text ltx_font_bold\">Algorithms</span></td>\n<td id=\"S6.T2.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">\n<math id=\"S6.T2.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T2.3.1.1.m1.1a\"><mi id=\"S6.T2.3.1.1.m1.1.1\" xref=\"S6.T2.3.1.1.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.3.1.1.m1.1b\"><ci id=\"S6.T2.3.1.1.m1.1.1.cmml\" xref=\"S6.T2.3.1.1.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.3.1.1.m1.1c\">\\alpha</annotation></semantics></math>=0.5</td>\n<td id=\"S6.T2.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">\n<math id=\"S6.T2.4.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T2.4.2.2.m1.1a\"><mi id=\"S6.T2.4.2.2.m1.1.1\" xref=\"S6.T2.4.2.2.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.4.2.2.m1.1b\"><ci id=\"S6.T2.4.2.2.m1.1.1.cmml\" xref=\"S6.T2.4.2.2.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.4.2.2.m1.1c\">\\alpha</annotation></semantics></math>=1</td>\n<td id=\"S6.T2.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">\n<math id=\"S6.T2.5.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T2.5.3.3.m1.1a\"><mi id=\"S6.T2.5.3.3.m1.1.1\" xref=\"S6.T2.5.3.3.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.5.3.3.m1.1b\"><ci id=\"S6.T2.5.3.3.m1.1.1.cmml\" xref=\"S6.T2.5.3.3.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.5.3.3.m1.1c\">\\alpha</annotation></semantics></math>=5</td>\n<td id=\"S6.T2.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">\n<math id=\"S6.T2.6.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T2.6.4.4.m1.1a\"><mi id=\"S6.T2.6.4.4.m1.1.1\" xref=\"S6.T2.6.4.4.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.6.4.4.m1.1b\"><ci id=\"S6.T2.6.4.4.m1.1.1.cmml\" xref=\"S6.T2.6.4.4.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.6.4.4.m1.1c\">\\alpha</annotation></semantics></math>=10</td>\n</tr>\n<tr id=\"S6.T2.6.5.1\" class=\"ltx_tr\">\n<th id=\"S6.T2.6.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"3\"><span id=\"S6.T2.6.5.1.1.1\" class=\"ltx_text\">\n<span id=\"S6.T2.6.5.1.1.1.1\" class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:8.8pt;height:19.4pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:19.4pt;transform:translate(-5.33pt,-4.36pt) rotate(-90deg) ;\">\n<span id=\"S6.T2.6.5.1.1.1.1.1\" class=\"ltx_p\"><span id=\"S6.T2.6.5.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Sup.</span></span>\n</span></span></span></th>\n<td id=\"S6.T2.6.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FedAvg-SL</td>\n<td id=\"S6.T2.6.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">48.56</td>\n<td id=\"S6.T2.6.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">48.25</td>\n<td id=\"S6.T2.6.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">54.53</td>\n<td id=\"S6.T2.6.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">55.33</td>\n</tr>\n<tr id=\"S6.T2.6.6.2\" class=\"ltx_tr\">\n<td id=\"S6.T2.6.6.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FedProx-SL</td>\n<td id=\"S6.T2.6.6.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">51.62</td>\n<td id=\"S6.T2.6.6.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">53.47</td>\n<td id=\"S6.T2.6.6.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">55.06</td>\n<td id=\"S6.T2.6.6.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">55.32</td>\n</tr>\n<tr id=\"S6.T2.6.7.3\" class=\"ltx_tr\">\n<td id=\"S6.T2.6.7.3.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FedBN-SL</td>\n<td id=\"S6.T2.6.7.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">51.54</td>\n<td id=\"S6.T2.6.7.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">52.47</td>\n<td id=\"S6.T2.6.7.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">54.32</td>\n<td id=\"S6.T2.6.7.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">55.61</td>\n</tr>\n<tr id=\"S6.T2.6.8.4\" class=\"ltx_tr\">\n<th id=\"S6.T2.6.8.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"7\"><span id=\"S6.T2.6.8.4.1.1\" class=\"ltx_text\">\n<span id=\"S6.T2.6.8.4.1.1.1\" class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:8.8pt;height:43.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:43.9pt;transform:translate(-17.56pt,-16.58pt) rotate(-90deg) ;\">\n<span id=\"S6.T2.6.8.4.1.1.1.1\" class=\"ltx_p\"><span id=\"S6.T2.6.8.4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Semi-Sup.</span></span>\n</span></span></span></th>\n<td id=\"S6.T2.6.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FixAvg</td>\n<td id=\"S6.T2.6.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">46.41</td>\n<td id=\"S6.T2.6.8.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">46.79</td>\n<td id=\"S6.T2.6.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">52.46</td>\n<td id=\"S6.T2.6.8.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">53.04</td>\n</tr>\n<tr id=\"S6.T2.6.9.5\" class=\"ltx_tr\">\n<td id=\"S6.T2.6.9.5.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FixProx</td>\n<td id=\"S6.T2.6.9.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">49.37</td>\n<td id=\"S6.T2.6.9.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">49.81</td>\n<td id=\"S6.T2.6.9.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">48.61</td>\n<td id=\"S6.T2.6.9.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T2.6.9.5.5.1\" class=\"ltx_text ltx_font_bold\">54.65</span></td>\n</tr>\n<tr id=\"S6.T2.6.10.6\" class=\"ltx_tr\">\n<td id=\"S6.T2.6.10.6.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FixBN</td>\n<td id=\"S6.T2.6.10.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">47.54</td>\n<td id=\"S6.T2.6.10.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">50.28</td>\n<td id=\"S6.T2.6.10.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">51.52</td>\n<td id=\"S6.T2.6.10.6.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">51.93</td>\n</tr>\n<tr id=\"S6.T2.6.11.7\" class=\"ltx_tr\">\n<td id=\"S6.T2.6.11.7.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FedPer</td>\n<td id=\"S6.T2.6.11.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">42.16</td>\n<td id=\"S6.T2.6.11.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">30.02</td>\n<td id=\"S6.T2.6.11.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">18.94</td>\n<td id=\"S6.T2.6.11.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">18.68</td>\n</tr>\n<tr id=\"S6.T2.6.12.8\" class=\"ltx_tr\">\n<td id=\"S6.T2.6.12.8.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">LG-FedAvg</td>\n<td id=\"S6.T2.6.12.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">43.41</td>\n<td id=\"S6.T2.6.12.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">41.93</td>\n<td id=\"S6.T2.6.12.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">38.23</td>\n<td id=\"S6.T2.6.12.8.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">38.37</td>\n</tr>\n<tr id=\"S6.T2.6.13.9\" class=\"ltx_tr\">\n<td id=\"S6.T2.6.13.9.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">pFedMe</td>\n<td id=\"S6.T2.6.13.9.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">25.70</td>\n<td id=\"S6.T2.6.13.9.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">27.38</td>\n<td id=\"S6.T2.6.13.9.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">22.56</td>\n<td id=\"S6.T2.6.13.9.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">18.00</td>\n</tr>\n<tr id=\"S6.T2.6.14.10\" class=\"ltx_tr\">\n<td id=\"S6.T2.6.14.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">UM-pFSSL</td>\n<td id=\"S6.T2.6.14.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T2.6.14.10.2.1\" class=\"ltx_text ltx_font_bold\">51.14</span></td>\n<td id=\"S6.T2.6.14.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T2.6.14.10.3.1\" class=\"ltx_text ltx_font_bold\">52.24</span></td>\n<td id=\"S6.T2.6.14.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T2.6.14.10.4.1\" class=\"ltx_text ltx_font_bold\">52.83</span></td>\n<td id=\"S6.T2.6.14.10.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">54.03</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this subsection, we compare the results of UM-pFSSL with Non-IID schemes and personalized federated learning methods. We run each experiment 20 times and take the average as final result.",
                "Impact of heterogeneity:",
                " TABLE ",
                "I",
                " and TABLE ",
                "II",
                " illustrate the best achievable test accuracy of our proposed method and compared group on different datasets (Sup. represents the supervised methods). From TABLE ",
                "I",
                " we can observe that, on Fashion-MNIST, UM-pFSSL outperforms most of the Non-IID FL methods and personalized methods with highly heterogeneous data. With the heterogeneity decreasing (",
                "Œ±",
                "ùõº",
                "\\alpha",
                " increasing), the baseline methods and Non-IID FL methods obtain noticeable performance improvement (about 2% ",
                "‚àº",
                "similar-to",
                "\\sim",
                " 7%) while the personalized methods suffer the accuracy decline. Compared with other peer schemes, UM-pFSSL is able to retain a well-accepted accuracy ",
                ">",
                ">",
                " 79% with data dissimilarity across clients varying. TABLE ",
                "II",
                " depicts the result on CIFAR-10 dataset. In this task, personalized methods also show that performance degrades as the heterogeneity increases. The UM-pFSSL obtains comparable performance and even higher accuracy than baseline method FedAvg-SL, although the performance improvement is slightly weaker than the Non-IID methods FixAvg, FixProx and FixBN. The reason behind is that, under the highly heterogeneous setting, the helper selection mechanism can pick out the most related clients that can give most confident prediction about local unlabeled data. On the contrary, in nearly homogeneous context, almost all clients contain the similar distribution, the client with the largest labeled dataset will predominate the helper list of all clients. The potential knowledge aggregation is weakened in this scenario; thus, the performance does not show significant growth.",
                "Learning efficiency:",
                " Figs. ",
                "4",
                " and ",
                "5",
                " visualize the curve of the average validation accuracy during the training procedure on Fashion-MNIST and CIFAR-10, respectively. As shown in Fig. ",
                "4",
                ", the personalized methods can acquire better accuracy improvement in the first few rounds, especially the LG-FedAvg and UM-pFSSL. As the training rounds increase, Non-IID methods show precipitous accuracy upgrading and quickly turn to flat convergence, while the LG-FedAvg and UM-pFSSL have a more smooth training curve. Additionally, compared to other personalized methods, UM-pFSSL keeps the performance superiority as the heterogeneity decreases. As shown in Fig. ",
                "5",
                ", for more complicate learning task CIFAR-10, the Non-IID methods tend to overfit after 100 rounds and end up to inferior validation accuracy. The UM-pFSSL shows more smooth learning curve and better performance than personalized methods and Non-IID methods with highly heterogeneous data distribution (",
                "Œ±",
                "=",
                "0.5",
                "ùõº",
                "0.5",
                "\\alpha=0.5",
                "). The comparisons indicate that our proposed methods can achieve more stable training and benefit from the heterogeneity of data. The main reason is the pseudo-label selection approach can collect the most useful information from related helpers. With higher the heterogeneity in distributed datasets, each selected helper can only provide confident predictions to a fraction of unlabeled data, thus the potential knowledge aggregation integrates more helpers and obtain more preferable and robust performance.",
                "Performance fairness:",
                " In personalized FL system, the divergence of local performance between clients can be utilized to qualify the fairness of the FL methods. Specifically, we adopt the variance of the test accuracy of different clients to compare the fairness of our proposed UM-pFSSL with other methods. As shown in Fig. ",
                "6",
                "(a), the most biased method is the LG-FedAvg, which achieves the secondary performance among the personalized methods. In comparison, other methods obviously achieve more unbiased results with the ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " increases. From Fig. ",
                "6",
                "(b), most of the compared schemes obtain evident decrease in variance with ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " increases, and the UM-pFSSL reaches the lowest accuracy variance with ",
                "Œ±",
                "=",
                "5",
                "ùõº",
                "5",
                "\\alpha=5",
                ". Based on these phenomena, we can easily obtain that, on both datasets, the UM-pFSSL achieves the least biased results with different degree of heterogeneity. Combined with the results in Figs. ",
                "4",
                " and ",
                "5",
                ", the UM-pFSSL shows both superior accuracy and comparable fairness in comparison with Non-IID and personalized methods, especially with massive data heterogeneity.",
                "Communication cost:",
                " With a greedily searching strategy in helper-selection stage, the messages transmitted through network have the size:",
                "which includes the model upload of ",
                "œÑ",
                "‚Äã",
                "K",
                "ùúè",
                "ùêæ",
                "\\tau K",
                " selected clients and peer model download (",
                "œÑ",
                "ùúè",
                "\\tau",
                " is the sample rate for training nodes, ",
                "K",
                "ùêæ",
                "K",
                " is the total number of clients); ",
                "|",
                "w",
                "|",
                "ùë§",
                "|w|",
                " denotes parameter size of the uniform neural architecture, and ",
                "n",
                "ùëõ",
                "n",
                " is the number of rounds.",
                "With the helper selection protocol, in first ",
                "F",
                "ùêπ",
                "F",
                " rounds, we replace ",
                "R",
                "ùëÖ",
                "R",
                " helpers in the helper list and update the models of total ",
                "M",
                "ùëÄ",
                "M",
                " helpers every ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                " rounds through cloud server (these operations are executed on all ",
                "K",
                "ùêæ",
                "K",
                " clients). In some cases, the update or replacement should be skipped if there is no modification of existing ",
                "M",
                "ùëÄ",
                "M",
                " helpers or suitable substitutes for ",
                "R",
                "ùëÖ",
                "R",
                " helpers are not found. Therefore, the upper bound of the communication cost is",
                "The difference of ",
                "Cost",
                "2",
                "subscript",
                "Cost",
                "2",
                "\\operatorname{Cost}_{2}",
                " and ",
                "Cost",
                "1",
                "subscript",
                "Cost",
                "1",
                "\\operatorname{Cost}_{1}",
                " can be derived as",
                "Physically, ",
                "F",
                "‚Äã",
                "R",
                "ùêπ",
                "ùëÖ",
                "FR",
                " in Eq. (29) represents the number of helpers that each user can search for during the entire training period. In the experiments, we set ",
                "F",
                "ùêπ",
                "F",
                " to 30 and ",
                "R",
                "ùëÖ",
                "R",
                " to 2 by default. In such a case, we have ",
                "œÑ",
                "‚Äã",
                "K",
                "‚Äã",
                "n",
                "=",
                "2000",
                "ùúè",
                "ùêæ",
                "ùëõ",
                "2000",
                "\\tau Kn=2000",
                ", ",
                "F",
                "‚Äã",
                "R",
                "=",
                "60",
                "ùêπ",
                "ùëÖ",
                "60",
                "FR=60",
                " and ",
                "n",
                "‚Äã",
                "(",
                "M",
                "+",
                "œÑ",
                "‚Äã",
                "ŒΩ",
                ")",
                "/",
                "ŒΩ",
                "=",
                "120",
                "ùëõ",
                "ùëÄ",
                "ùúè",
                "ùúà",
                "ùúà",
                "120",
                "n(M+\\tau\\nu)/\\nu=120",
                ". There is a significant gap between ",
                "Cost",
                "1",
                "subscript",
                "Cost",
                "1",
                "\\operatorname{Cost}_{1}",
                " and ",
                "Cost",
                "2",
                "subscript",
                "Cost",
                "2",
                "\\operatorname{Cost}_{2}",
                ", more than 90% of the communication cost is saved. To intuitively reveal the effect of ",
                "F",
                "‚Äã",
                "R",
                "ùêπ",
                "ùëÖ",
                "FR",
                ", we evaluate the communication cost of UM-pFSSL on two datasets by setting ",
                "F",
                "ùêπ",
                "F",
                " to different number with ",
                "Œ±",
                "=",
                "0.5",
                "ùõº",
                "0.5",
                "\\alpha=0.5",
                ". As shown in Fig. ",
                "7",
                ", higher ",
                "F",
                "ùêπ",
                "F",
                " introduces more communication burden of the system and but always improves the test accuracy accordingly; while ",
                "F",
                "ùêπ",
                "F",
                " exceeds 30, the performance improvement effect gradually weakens. The results show that, our scheme can save considerable communication overhead with acceptable performance sacrifice."
            ]
        ]
    },
    "S6.T3": {
        "caption": "TABLE III: The results of key components in UM-pFSSL.",
        "table": "<table id=\"S6.T3.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T3.4.5.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.5.1.1\" class=\"ltx_td ltx_border_tt\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"></td>\n<th id=\"S6.T3.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S6.T3.4.5.1.2.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"S6.T3.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">TA</th>\n<th id=\"S6.T3.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">EN</th>\n<th id=\"S6.T3.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">EN + TA</th>\n</tr>\n<tr id=\"S6.T3.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" rowspan=\"2\"><span id=\"S6.T3.1.1.1.1\" class=\"ltx_text\"><math id=\"S6.T3.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=0.5\" display=\"inline\"><semantics id=\"S6.T3.1.1.1.1.m1.1a\"><mrow id=\"S6.T3.1.1.1.1.m1.1.1\" xref=\"S6.T3.1.1.1.1.m1.1.1.cmml\"><mi id=\"S6.T3.1.1.1.1.m1.1.1.2\" xref=\"S6.T3.1.1.1.1.m1.1.1.2.cmml\">Œ±</mi><mo id=\"S6.T3.1.1.1.1.m1.1.1.1\" xref=\"S6.T3.1.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T3.1.1.1.1.m1.1.1.3\" xref=\"S6.T3.1.1.1.1.m1.1.1.3.cmml\">0.5</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.1.1.1.1.m1.1b\"><apply id=\"S6.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S6.T3.1.1.1.1.m1.1.1\"><eq id=\"S6.T3.1.1.1.1.m1.1.1.1.cmml\" xref=\"S6.T3.1.1.1.1.m1.1.1.1\"></eq><ci id=\"S6.T3.1.1.1.1.m1.1.1.2.cmml\" xref=\"S6.T3.1.1.1.1.m1.1.1.2\">ùõº</ci><cn type=\"float\" id=\"S6.T3.1.1.1.1.m1.1.1.3.cmml\" xref=\"S6.T3.1.1.1.1.m1.1.1.3\">0.5</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.1.1.1.1.m1.1c\">\\alpha=0.5</annotation></semantics></math></span></td>\n<td id=\"S6.T3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">Fashion-MNIST</td>\n<td id=\"S6.T3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">71.39</td>\n<td id=\"S6.T3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">73.25</td>\n<td id=\"S6.T3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">79.00</td>\n</tr>\n<tr id=\"S6.T3.4.6.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.6.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">CIFAR-10</td>\n<td id=\"S6.T3.4.6.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">41.97</td>\n<td id=\"S6.T3.4.6.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">45.82</td>\n<td id=\"S6.T3.4.6.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">51.14</td>\n</tr>\n<tr id=\"S6.T3.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" rowspan=\"2\"><span id=\"S6.T3.2.2.1.1\" class=\"ltx_text\"><math id=\"S6.T3.2.2.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=1\" display=\"inline\"><semantics id=\"S6.T3.2.2.1.1.m1.1a\"><mrow id=\"S6.T3.2.2.1.1.m1.1.1\" xref=\"S6.T3.2.2.1.1.m1.1.1.cmml\"><mi id=\"S6.T3.2.2.1.1.m1.1.1.2\" xref=\"S6.T3.2.2.1.1.m1.1.1.2.cmml\">Œ±</mi><mo id=\"S6.T3.2.2.1.1.m1.1.1.1\" xref=\"S6.T3.2.2.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T3.2.2.1.1.m1.1.1.3\" xref=\"S6.T3.2.2.1.1.m1.1.1.3.cmml\">1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.2.2.1.1.m1.1b\"><apply id=\"S6.T3.2.2.1.1.m1.1.1.cmml\" xref=\"S6.T3.2.2.1.1.m1.1.1\"><eq id=\"S6.T3.2.2.1.1.m1.1.1.1.cmml\" xref=\"S6.T3.2.2.1.1.m1.1.1.1\"></eq><ci id=\"S6.T3.2.2.1.1.m1.1.1.2.cmml\" xref=\"S6.T3.2.2.1.1.m1.1.1.2\">ùõº</ci><cn type=\"integer\" id=\"S6.T3.2.2.1.1.m1.1.1.3.cmml\" xref=\"S6.T3.2.2.1.1.m1.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.2.2.1.1.m1.1c\">\\alpha=1</annotation></semantics></math></span></td>\n<td id=\"S6.T3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">Fashion-MNIST</td>\n<td id=\"S6.T3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">75.11</td>\n<td id=\"S6.T3.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">77.74</td>\n<td id=\"S6.T3.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">80.93</td>\n</tr>\n<tr id=\"S6.T3.4.7.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.7.3.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">CIFAR-10</td>\n<td id=\"S6.T3.4.7.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">46.16</td>\n<td id=\"S6.T3.4.7.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">48.93</td>\n<td id=\"S6.T3.4.7.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">52.24</td>\n</tr>\n<tr id=\"S6.T3.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" rowspan=\"2\"><span id=\"S6.T3.3.3.1.1\" class=\"ltx_text\"><math id=\"S6.T3.3.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=5\" display=\"inline\"><semantics id=\"S6.T3.3.3.1.1.m1.1a\"><mrow id=\"S6.T3.3.3.1.1.m1.1.1\" xref=\"S6.T3.3.3.1.1.m1.1.1.cmml\"><mi id=\"S6.T3.3.3.1.1.m1.1.1.2\" xref=\"S6.T3.3.3.1.1.m1.1.1.2.cmml\">Œ±</mi><mo id=\"S6.T3.3.3.1.1.m1.1.1.1\" xref=\"S6.T3.3.3.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T3.3.3.1.1.m1.1.1.3\" xref=\"S6.T3.3.3.1.1.m1.1.1.3.cmml\">5</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.3.3.1.1.m1.1b\"><apply id=\"S6.T3.3.3.1.1.m1.1.1.cmml\" xref=\"S6.T3.3.3.1.1.m1.1.1\"><eq id=\"S6.T3.3.3.1.1.m1.1.1.1.cmml\" xref=\"S6.T3.3.3.1.1.m1.1.1.1\"></eq><ci id=\"S6.T3.3.3.1.1.m1.1.1.2.cmml\" xref=\"S6.T3.3.3.1.1.m1.1.1.2\">ùõº</ci><cn type=\"integer\" id=\"S6.T3.3.3.1.1.m1.1.1.3.cmml\" xref=\"S6.T3.3.3.1.1.m1.1.1.3\">5</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.3.3.1.1.m1.1c\">\\alpha=5</annotation></semantics></math></span></td>\n<td id=\"S6.T3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">Fashion-MNIST</td>\n<td id=\"S6.T3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">76.39</td>\n<td id=\"S6.T3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">78.25</td>\n<td id=\"S6.T3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">81.16</td>\n</tr>\n<tr id=\"S6.T3.4.8.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.8.4.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">CIFAR-10</td>\n<td id=\"S6.T3.4.8.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">47.63</td>\n<td id=\"S6.T3.4.8.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">49.32</td>\n<td id=\"S6.T3.4.8.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">52.83</td>\n</tr>\n<tr id=\"S6.T3.4.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" rowspan=\"2\"><span id=\"S6.T3.4.4.1.1\" class=\"ltx_text\"><math id=\"S6.T3.4.4.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=10\" display=\"inline\"><semantics id=\"S6.T3.4.4.1.1.m1.1a\"><mrow id=\"S6.T3.4.4.1.1.m1.1.1\" xref=\"S6.T3.4.4.1.1.m1.1.1.cmml\"><mi id=\"S6.T3.4.4.1.1.m1.1.1.2\" xref=\"S6.T3.4.4.1.1.m1.1.1.2.cmml\">Œ±</mi><mo id=\"S6.T3.4.4.1.1.m1.1.1.1\" xref=\"S6.T3.4.4.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T3.4.4.1.1.m1.1.1.3\" xref=\"S6.T3.4.4.1.1.m1.1.1.3.cmml\">10</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.4.4.1.1.m1.1b\"><apply id=\"S6.T3.4.4.1.1.m1.1.1.cmml\" xref=\"S6.T3.4.4.1.1.m1.1.1\"><eq id=\"S6.T3.4.4.1.1.m1.1.1.1.cmml\" xref=\"S6.T3.4.4.1.1.m1.1.1.1\"></eq><ci id=\"S6.T3.4.4.1.1.m1.1.1.2.cmml\" xref=\"S6.T3.4.4.1.1.m1.1.1.2\">ùõº</ci><cn type=\"integer\" id=\"S6.T3.4.4.1.1.m1.1.1.3.cmml\" xref=\"S6.T3.4.4.1.1.m1.1.1.3\">10</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.4.4.1.1.m1.1c\">\\alpha=10</annotation></semantics></math></span></td>\n<td id=\"S6.T3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">Fashion-MNIST</td>\n<td id=\"S6.T3.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">76.83</td>\n<td id=\"S6.T3.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">79.19</td>\n<td id=\"S6.T3.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">81.49</td>\n</tr>\n<tr id=\"S6.T3.4.9.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.4.9.5.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">CIFAR-10</td>\n<td id=\"S6.T3.4.9.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">47.95</td>\n<td id=\"S6.T3.4.9.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">50.47</td>\n<td id=\"S6.T3.4.9.5.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">54.03</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To show the detailed contributions of the components in UM-pFSSL, we conduct ablation experiments with two datasets. In detail, we separately test the effect on the final model performance using the two components in Eq. (13), i.e., the entropy term (EN) and the test accuracy term (TA). As shown in TABLE ",
                "III",
                ", the entropy term outperforms the accuracy term in all sorts of situations, and the fusion of them can even further improve the performance.",
                "The pseudo-label error rate of the key compoments with ",
                "Œ±",
                "=",
                "0.5",
                "ùõº",
                "0.5",
                "\\alpha=0.5",
                " is visualized in Fig. ",
                "8",
                ". As the training rounds increase, UM-pFSSL with EN shows more smooth error decreasing than the one with TA. While the UM-pFSSL with TA presents a rapid dropping in 50-100 rounds and then oscillates around a stable value. The combination of the two shows the same downward trend as EN and has a lower error rate than both. This result clearly tells us that with our designed corresponding metric, the selected helpers are able to annotate unlabeled data effectively.",
                "We also give the distribution of data features with less heterogeneity (",
                "Œ±",
                "=",
                "5",
                "ùõº",
                "5",
                "\\alpha=5",
                "). In this situation, we take the output of the final hidden unit as the latent feature of input data. Since the models are fully personalized, we pick the optimal model in each case for visualization. As depicted in Fig. ",
                "9",
                ", with the combination of EN and AT, the model manifestly improves the discrimination on hard samples (the green and red classes in the figure)."
            ]
        ]
    },
    "S6.T4": {
        "caption": "TABLE IV: INFLUENCE OF ŒΩùúà\\nu ON UM-pFSSL.",
        "table": "<table id=\"S6.T4.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T4.3.1\" class=\"ltx_tr\">\n<th id=\"S6.T4.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><math id=\"S6.T4.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\nu\" display=\"inline\"><semantics id=\"S6.T4.3.1.1.m1.1a\"><mi id=\"S6.T4.3.1.1.m1.1.1\" xref=\"S6.T4.3.1.1.m1.1.1.cmml\">ŒΩ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T4.3.1.1.m1.1b\"><ci id=\"S6.T4.3.1.1.m1.1.1.cmml\" xref=\"S6.T4.3.1.1.m1.1.1\">ùúà</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T4.3.1.1.m1.1c\">\\nu</annotation></semantics></math></th>\n<th id=\"S6.T4.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">1 (baseline)</th>\n<th id=\"S6.T4.3.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">5</th>\n<th id=\"S6.T4.3.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">10 (default)</th>\n<th id=\"S6.T4.3.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">15</th>\n<th id=\"S6.T4.3.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">20</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T4.3.2.1\" class=\"ltx_tr\">\n<th id=\"S6.T4.3.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">Accuracy</th>\n<td id=\"S6.T4.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">80.32</td>\n<td id=\"S6.T4.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">79.85</td>\n<td id=\"S6.T4.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">79.00</td>\n<td id=\"S6.T4.3.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">76.68</td>\n<td id=\"S6.T4.3.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">73.21</td>\n</tr>\n<tr id=\"S6.T4.3.3.2\" class=\"ltx_tr\">\n<th id=\"S6.T4.3.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">Cost</th>\n<td id=\"S6.T4.3.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">100%</td>\n<td id=\"S6.T4.3.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">26%</td>\n<td id=\"S6.T4.3.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">16.7%</td>\n<td id=\"S6.T4.3.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">13.5%</td>\n<td id=\"S6.T4.3.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">12%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Firstly, we discuss the influence of the ",
                "M",
                "ùëÄ",
                "M",
                " on the final experimental results in helper selection. We adjust this parameter from 3 to 15, and visualize the results in Fig. ",
                "10",
                ". The results show that increasing the number of helpers has obvious benefits for systems with less heterogeneity. For those with higher degree of heterogeneity, increasing helpers may lead to a decrease in model performance. This stems from the model aggregation procedure described in Section ",
                "III",
                ". With this operation, aggregating models from heterogeneous clients reduces the convergence speed and training stability of the model.",
                "The frequency of updating helpers‚Äô model ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                " also affects performance and communication efficiency. We adjust ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                " from 1 to 20, and evaluate communication cost and model performance on Fashion-MNIST with ",
                "Œ±",
                "=",
                "0.5",
                "ùõº",
                "0.5",
                "\\alpha=0.5",
                ". The results are shown in TABLE ",
                "IV",
                ". A larger ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                " can save certain communication costs, but as the value of ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                " gets larger, the degree of performance degradation also increases.",
                "According to Eq. (29), the client sampling rate ",
                "œÑ",
                "ùúè",
                "\\tau",
                " linearly affects the communication load of the system. Same as TABLE ",
                "IV",
                ", we adjust it from 0.05 to 1, and show the results in TABLE ",
                "V",
                ". Different from ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                ", a larger ",
                "œÑ",
                "ùúè",
                "\\tau",
                " means more local training performed by each client. The performance improvement brought by increasing ",
                "œÑ",
                "ùúè",
                "\\tau",
                " is more significant than that of ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                "."
            ]
        ]
    },
    "S6.T5": {
        "caption": "TABLE V: INFLUENCE OF œÑùúè\\tau ON UM-pFSSL.",
        "table": "<table id=\"S6.T5.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T5.3.1\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><math id=\"S6.T5.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\tau\" display=\"inline\"><semantics id=\"S6.T5.3.1.1.m1.1a\"><mi id=\"S6.T5.3.1.1.m1.1.1\" xref=\"S6.T5.3.1.1.m1.1.1.cmml\">œÑ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T5.3.1.1.m1.1b\"><ci id=\"S6.T5.3.1.1.m1.1.1.cmml\" xref=\"S6.T5.3.1.1.m1.1.1\">ùúè</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T5.3.1.1.m1.1c\">\\tau</annotation></semantics></math></th>\n<th id=\"S6.T5.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">0.05</th>\n<th id=\"S6.T5.3.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">0.1 (default)</th>\n<th id=\"S6.T5.3.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">0.2</th>\n<th id=\"S6.T5.3.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">0.5</th>\n<th id=\"S6.T5.3.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">1.0 (baseline)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T5.3.2.1\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">Accuracy</th>\n<td id=\"S6.T5.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">77.46</td>\n<td id=\"S6.T5.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">79.00</td>\n<td id=\"S6.T5.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">81.75</td>\n<td id=\"S6.T5.3.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">82.03</td>\n<td id=\"S6.T5.3.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">83.21</td>\n</tr>\n<tr id=\"S6.T5.3.3.2\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">Cost</th>\n<td id=\"S6.T5.3.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">5.7%</td>\n<td id=\"S6.T5.3.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">10.7%</td>\n<td id=\"S6.T5.3.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">20.6%</td>\n<td id=\"S6.T5.3.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">50.4%</td>\n<td id=\"S6.T5.3.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">100%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Firstly, we discuss the influence of the ",
                "M",
                "ùëÄ",
                "M",
                " on the final experimental results in helper selection. We adjust this parameter from 3 to 15, and visualize the results in Fig. ",
                "10",
                ". The results show that increasing the number of helpers has obvious benefits for systems with less heterogeneity. For those with higher degree of heterogeneity, increasing helpers may lead to a decrease in model performance. This stems from the model aggregation procedure described in Section ",
                "III",
                ". With this operation, aggregating models from heterogeneous clients reduces the convergence speed and training stability of the model.",
                "The frequency of updating helpers‚Äô model ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                " also affects performance and communication efficiency. We adjust ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                " from 1 to 20, and evaluate communication cost and model performance on Fashion-MNIST with ",
                "Œ±",
                "=",
                "0.5",
                "ùõº",
                "0.5",
                "\\alpha=0.5",
                ". The results are shown in TABLE ",
                "IV",
                ". A larger ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                " can save certain communication costs, but as the value of ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                " gets larger, the degree of performance degradation also increases.",
                "According to Eq. (29), the client sampling rate ",
                "œÑ",
                "ùúè",
                "\\tau",
                " linearly affects the communication load of the system. Same as TABLE ",
                "IV",
                ", we adjust it from 0.05 to 1, and show the results in TABLE ",
                "V",
                ". Different from ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                ", a larger ",
                "œÑ",
                "ùúè",
                "\\tau",
                " means more local training performed by each client. The performance improvement brought by increasing ",
                "œÑ",
                "ùúè",
                "\\tau",
                " is more significant than that of ",
                "ŒΩ",
                "ùúà",
                "\\nu",
                "."
            ]
        ]
    },
    "S6.T6": {
        "caption": "TABLE VI: THE COMPARISION OF BEST TEST ACCURACY ON PathMNIST WITH DIFFERENT Œ±ùõº\\alpha.",
        "table": "<table id=\"S6.T6.6\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T6.6.4\" class=\"ltx_tr\">\n<td id=\"S6.T6.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"><span id=\"S6.T6.6.4.5.1\" class=\"ltx_text ltx_font_bold\">Algorithms</span></td>\n<td id=\"S6.T6.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">\n<math id=\"S6.T6.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T6.3.1.1.m1.1a\"><mi id=\"S6.T6.3.1.1.m1.1.1\" xref=\"S6.T6.3.1.1.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.3.1.1.m1.1b\"><ci id=\"S6.T6.3.1.1.m1.1.1.cmml\" xref=\"S6.T6.3.1.1.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.3.1.1.m1.1c\">\\alpha</annotation></semantics></math>=0.5</td>\n<td id=\"S6.T6.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">\n<math id=\"S6.T6.4.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T6.4.2.2.m1.1a\"><mi id=\"S6.T6.4.2.2.m1.1.1\" xref=\"S6.T6.4.2.2.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.4.2.2.m1.1b\"><ci id=\"S6.T6.4.2.2.m1.1.1.cmml\" xref=\"S6.T6.4.2.2.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.4.2.2.m1.1c\">\\alpha</annotation></semantics></math>=1</td>\n<td id=\"S6.T6.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">\n<math id=\"S6.T6.5.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T6.5.3.3.m1.1a\"><mi id=\"S6.T6.5.3.3.m1.1.1\" xref=\"S6.T6.5.3.3.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.5.3.3.m1.1b\"><ci id=\"S6.T6.5.3.3.m1.1.1.cmml\" xref=\"S6.T6.5.3.3.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.5.3.3.m1.1c\">\\alpha</annotation></semantics></math>=5</td>\n<td id=\"S6.T6.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">\n<math id=\"S6.T6.6.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T6.6.4.4.m1.1a\"><mi id=\"S6.T6.6.4.4.m1.1.1\" xref=\"S6.T6.6.4.4.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.6.4.4.m1.1b\"><ci id=\"S6.T6.6.4.4.m1.1.1.cmml\" xref=\"S6.T6.6.4.4.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.6.4.4.m1.1c\">\\alpha</annotation></semantics></math>=10</td>\n</tr>\n<tr id=\"S6.T6.6.5.1\" class=\"ltx_tr\">\n<td id=\"S6.T6.6.5.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">FixAvg</td>\n<td id=\"S6.T6.6.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">70.48</td>\n<td id=\"S6.T6.6.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">72.16</td>\n<td id=\"S6.T6.6.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">75.63</td>\n<td id=\"S6.T6.6.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">77.28</td>\n</tr>\n<tr id=\"S6.T6.6.6.2\" class=\"ltx_tr\">\n<td id=\"S6.T6.6.6.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">FixProx</td>\n<td id=\"S6.T6.6.6.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">71.36</td>\n<td id=\"S6.T6.6.6.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">73.57</td>\n<td id=\"S6.T6.6.6.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">76.07</td>\n<td id=\"S6.T6.6.6.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">77.85</td>\n</tr>\n<tr id=\"S6.T6.6.7.3\" class=\"ltx_tr\">\n<td id=\"S6.T6.6.7.3.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">FixBN</td>\n<td id=\"S6.T6.6.7.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">72.46</td>\n<td id=\"S6.T6.6.7.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">75.19</td>\n<td id=\"S6.T6.6.7.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">78.38</td>\n<td id=\"S6.T6.6.7.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">79.33</td>\n</tr>\n<tr id=\"S6.T6.6.8.4\" class=\"ltx_tr\">\n<td id=\"S6.T6.6.8.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">FedPer</td>\n<td id=\"S6.T6.6.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">68.09</td>\n<td id=\"S6.T6.6.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">64.71</td>\n<td id=\"S6.T6.6.8.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">62.36</td>\n<td id=\"S6.T6.6.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">60.13</td>\n</tr>\n<tr id=\"S6.T6.6.9.5\" class=\"ltx_tr\">\n<td id=\"S6.T6.6.9.5.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">LG-FedAvg</td>\n<td id=\"S6.T6.6.9.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">74.25</td>\n<td id=\"S6.T6.6.9.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">73.49</td>\n<td id=\"S6.T6.6.9.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">73.41</td>\n<td id=\"S6.T6.6.9.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">72.71</td>\n</tr>\n<tr id=\"S6.T6.6.10.6\" class=\"ltx_tr\">\n<td id=\"S6.T6.6.10.6.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">pFedMe</td>\n<td id=\"S6.T6.6.10.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">64.19</td>\n<td id=\"S6.T6.6.10.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">63.73</td>\n<td id=\"S6.T6.6.10.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">62.32</td>\n<td id=\"S6.T6.6.10.6.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">60.17</td>\n</tr>\n<tr id=\"S6.T6.6.11.7\" class=\"ltx_tr\">\n<td id=\"S6.T6.6.11.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">UM-pFSSL</td>\n<td id=\"S6.T6.6.11.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"><span id=\"S6.T6.6.11.7.2.1\" class=\"ltx_text ltx_font_bold\">78.64</span></td>\n<td id=\"S6.T6.6.11.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"><span id=\"S6.T6.6.11.7.3.1\" class=\"ltx_text ltx_font_bold\">79.83</span></td>\n<td id=\"S6.T6.6.11.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"><span id=\"S6.T6.6.11.7.4.1\" class=\"ltx_text ltx_font_bold\">80.94</span></td>\n<td id=\"S6.T6.6.11.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"><span id=\"S6.T6.6.11.7.5.1\" class=\"ltx_text ltx_font_bold\">81.47</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In order to examine the performance of our method in real-world applications, we additionally adopt two medical imaging datasets from MedMNIST collection [42]: OrganMNIST(Axial) and PathMNIST datasets. OrganMNIST consists of 11 types of body organs for classification task. PathMNIST is comprised of 9 types of tissues for classification task. We set the number of engaged clients ",
                "K",
                "ùêæ",
                "K",
                " to 20 and client sample rate ",
                "œÑ",
                "ùúè",
                "\\tau",
                " to 1. The other settings are the same as Subsection A. TABLE ",
                "VI",
                " and TABLE ",
                "VII",
                " give the results of the test accuracy on the two medical datasets. Clearly, our method exhibits superior performance than compared methods, with margins ",
                ">",
                ">",
                " 2% at varying degrees of heterogeneity. In addition, we aggregate the test results on all clients and compare with the mixture of all Non-FL methods, which is the ensemble of FixAvg, FixProx and FixBN by averaging their output. The detailed classification results through the confusion matrices are shown in Fig. ",
                "11",
                " (with ",
                "Œ±",
                "=",
                "0.5",
                "ùõº",
                "0.5",
                "\\alpha=0.5",
                "). From this figure, we can learn that, UM-pFSSL achieves higher worst-case accuracy and superior accuracy on more than half of the classes than mixed method. These additional experiments demonstrate that our scheme can achieve superior performance on real-world datasets compared to related methods."
            ]
        ]
    },
    "S6.T7": {
        "caption": "TABLE VII: THE COMPARISION OF BEST TEST ACCURACY ON OrganMNIST WITH DIFFERENT Œ±ùõº\\alpha.",
        "table": "<table id=\"S6.T7.6\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T7.6.4\" class=\"ltx_tr\">\n<td id=\"S6.T7.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"><span id=\"S6.T7.6.4.5.1\" class=\"ltx_text ltx_font_bold\">Algorithms</span></td>\n<td id=\"S6.T7.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">\n<math id=\"S6.T7.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T7.3.1.1.m1.1a\"><mi id=\"S6.T7.3.1.1.m1.1.1\" xref=\"S6.T7.3.1.1.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T7.3.1.1.m1.1b\"><ci id=\"S6.T7.3.1.1.m1.1.1.cmml\" xref=\"S6.T7.3.1.1.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T7.3.1.1.m1.1c\">\\alpha</annotation></semantics></math>=0.5</td>\n<td id=\"S6.T7.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">\n<math id=\"S6.T7.4.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T7.4.2.2.m1.1a\"><mi id=\"S6.T7.4.2.2.m1.1.1\" xref=\"S6.T7.4.2.2.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T7.4.2.2.m1.1b\"><ci id=\"S6.T7.4.2.2.m1.1.1.cmml\" xref=\"S6.T7.4.2.2.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T7.4.2.2.m1.1c\">\\alpha</annotation></semantics></math>=1</td>\n<td id=\"S6.T7.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">\n<math id=\"S6.T7.5.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T7.5.3.3.m1.1a\"><mi id=\"S6.T7.5.3.3.m1.1.1\" xref=\"S6.T7.5.3.3.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T7.5.3.3.m1.1b\"><ci id=\"S6.T7.5.3.3.m1.1.1.cmml\" xref=\"S6.T7.5.3.3.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T7.5.3.3.m1.1c\">\\alpha</annotation></semantics></math>=5</td>\n<td id=\"S6.T7.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">\n<math id=\"S6.T7.6.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"S6.T7.6.4.4.m1.1a\"><mi id=\"S6.T7.6.4.4.m1.1.1\" xref=\"S6.T7.6.4.4.m1.1.1.cmml\">Œ±</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T7.6.4.4.m1.1b\"><ci id=\"S6.T7.6.4.4.m1.1.1.cmml\" xref=\"S6.T7.6.4.4.m1.1.1\">ùõº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T7.6.4.4.m1.1c\">\\alpha</annotation></semantics></math>=10</td>\n</tr>\n<tr id=\"S6.T7.6.5.1\" class=\"ltx_tr\">\n<td id=\"S6.T7.6.5.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">FixAvg</td>\n<td id=\"S6.T7.6.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">78.79</td>\n<td id=\"S6.T7.6.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">80.82</td>\n<td id=\"S6.T7.6.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">82.38</td>\n<td id=\"S6.T7.6.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">82.74</td>\n</tr>\n<tr id=\"S6.T7.6.6.2\" class=\"ltx_tr\">\n<td id=\"S6.T7.6.6.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">FixProx</td>\n<td id=\"S6.T7.6.6.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">79.37</td>\n<td id=\"S6.T7.6.6.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">82.81</td>\n<td id=\"S6.T7.6.6.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">84.61</td>\n<td id=\"S6.T7.6.6.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">84.65</td>\n</tr>\n<tr id=\"S6.T7.6.7.3\" class=\"ltx_tr\">\n<td id=\"S6.T7.6.7.3.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">FixBN</td>\n<td id=\"S6.T7.6.7.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">81.54</td>\n<td id=\"S6.T7.6.7.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">83.28</td>\n<td id=\"S6.T7.6.7.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">85.52</td>\n<td id=\"S6.T7.6.7.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">85.93</td>\n</tr>\n<tr id=\"S6.T7.6.8.4\" class=\"ltx_tr\">\n<td id=\"S6.T7.6.8.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">FedPer</td>\n<td id=\"S6.T7.6.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">72.86</td>\n<td id=\"S6.T7.6.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">69.93</td>\n<td id=\"S6.T7.6.8.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">68.76</td>\n<td id=\"S6.T7.6.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">68.53</td>\n</tr>\n<tr id=\"S6.T7.6.9.5\" class=\"ltx_tr\">\n<td id=\"S6.T7.6.9.5.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">LG-FedAvg</td>\n<td id=\"S6.T7.6.9.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">75.29</td>\n<td id=\"S6.T7.6.9.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">74.78</td>\n<td id=\"S6.T7.6.9.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">73.62</td>\n<td id=\"S6.T7.6.9.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">72.97</td>\n</tr>\n<tr id=\"S6.T7.6.10.6\" class=\"ltx_tr\">\n<td id=\"S6.T7.6.10.6.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">pFedMe</td>\n<td id=\"S6.T7.6.10.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">66.59</td>\n<td id=\"S6.T7.6.10.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">64.27</td>\n<td id=\"S6.T7.6.10.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">63.79</td>\n<td id=\"S6.T7.6.10.6.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">62.36</td>\n</tr>\n<tr id=\"S6.T7.6.11.7\" class=\"ltx_tr\">\n<td id=\"S6.T7.6.11.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\">UM-pFSSL</td>\n<td id=\"S6.T7.6.11.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"><span id=\"S6.T7.6.11.7.2.1\" class=\"ltx_text ltx_font_bold\">86.62</span></td>\n<td id=\"S6.T7.6.11.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"><span id=\"S6.T7.6.11.7.3.1\" class=\"ltx_text ltx_font_bold\">87.23</span></td>\n<td id=\"S6.T7.6.11.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"><span id=\"S6.T7.6.11.7.4.1\" class=\"ltx_text ltx_font_bold\">87.68</span></td>\n<td id=\"S6.T7.6.11.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.8pt;padding-right:12.8pt;\"><span id=\"S6.T7.6.11.7.5.1\" class=\"ltx_text ltx_font_bold\">88.53</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In order to examine the performance of our method in real-world applications, we additionally adopt two medical imaging datasets from MedMNIST collection [42]: OrganMNIST(Axial) and PathMNIST datasets. OrganMNIST consists of 11 types of body organs for classification task. PathMNIST is comprised of 9 types of tissues for classification task. We set the number of engaged clients ",
                "K",
                "ùêæ",
                "K",
                " to 20 and client sample rate ",
                "œÑ",
                "ùúè",
                "\\tau",
                " to 1. The other settings are the same as Subsection A. TABLE ",
                "VI",
                " and TABLE ",
                "VII",
                " give the results of the test accuracy on the two medical datasets. Clearly, our method exhibits superior performance than compared methods, with margins ",
                ">",
                ">",
                " 2% at varying degrees of heterogeneity. In addition, we aggregate the test results on all clients and compare with the mixture of all Non-FL methods, which is the ensemble of FixAvg, FixProx and FixBN by averaging their output. The detailed classification results through the confusion matrices are shown in Fig. ",
                "11",
                " (with ",
                "Œ±",
                "=",
                "0.5",
                "ùõº",
                "0.5",
                "\\alpha=0.5",
                "). From this figure, we can learn that, UM-pFSSL achieves higher worst-case accuracy and superior accuracy on more than half of the classes than mixed method. These additional experiments demonstrate that our scheme can achieve superior performance on real-world datasets compared to related methods."
            ]
        ]
    }
}