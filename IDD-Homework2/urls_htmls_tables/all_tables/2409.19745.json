{
    "id_table_1": {
        "caption": "Table 1:  An example input for the proxy task, where unique letters representing distinct tokens, with  n = 4 n 4 n=4 italic_n = 4 .  For example, at position  n + i = 5 n i 5 n+i=5 italic_n + italic_i = 5  (with  i = 1 i 1 i=1 italic_i = 1 ), when an LLM receives ABCDA as input, it is likely to output B.  This happens because the last occurrence of A in the preceding context is followed by B.  If a head suppresses copying B from position  i + 1 = 2 i 1 2 i+1=2 italic_i + 1 = 2  to position  n + i = 5 n i 5 n+i=5 italic_n + italic_i = 5 , it could negatively impact RAG performance.",
        "table": "S1.T1.11",
        "footnotes": [],
        "references": [
            "In the first stage, we discover attention heads negatively affect performance on a proxy task.  The proxy task involves feeding the model a random token sequence of length  2  n 2 n 2n 2 italic_n , which consists of a duplicated sub-sequence of length  n n n italic_n . Table  1  illustrates an example input.  At position  n + i n i n+i italic_n + italic_i , the model typically predicts the token from position  i + 1 i 1 i+1 italic_i + 1 , as the natural continuation for a semantically meaningless context is to copy the existing in-context token pattern  (Lv et al.,  2024b ) .  The negatively impactful attention heads are discovered using the path patching technique  (Wang et al.,  2023 ) .  Since this proxy task is free from semantic bias and requires both in-context retrieval and generation based on the contextfundamental capacities for RAG, we refer to discovered heads as RAG-suppression heads 2 2 2 We do not imply that these heads hinder RAG through the same mechanisms (discussed in Section  4.1 ). .",
            "In this paper, we primarily focus on analyzing the working mechanism of attention heads in language models.  We briefly introduce a paradigm from a series of works  (Wang et al.,  2023 ; Zhang & Nanda,  2024 ; Wang et al.,  2024 )  that discovers which attention heads are crucial for processing an input sequence  X X X italic_X  of length  n n n italic_n .  Suppose the language model consists of  L L L italic_L  layers, with  H H H italic_H  attention heads per layer.  Let  A ( l , h ) superscript A l h A^{(l,h)} italic_A start_POSTSUPERSCRIPT ( italic_l , italic_h ) end_POSTSUPERSCRIPT  denote the  h h h italic_h -th attention head in the  l l l italic_l -th layer, and let its outputs be denoted by  a ( l , h )  R n  d superscript a l h superscript R n d \\textbf{a}^{(l,h)}\\in\\mathbb{R}^{n\\times d} a start_POSTSUPERSCRIPT ( italic_l , italic_h ) end_POSTSUPERSCRIPT  blackboard_R start_POSTSUPERSCRIPT italic_n  italic_d end_POSTSUPERSCRIPT .  We use  a i ( l , h )  R d subscript superscript a l h i superscript R d \\textbf{a}^{(l,h)}_{i}\\in\\mathbb{R}^{d} a start_POSTSUPERSCRIPT ( italic_l , italic_h ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT , where  1  i  n 1 i n 1\\leq i\\leq n 1  italic_i  italic_n , to represent the output at position  i i i italic_i .  The discovery paradigm typically includes three steps, as illustrated in Figure  1 :",
            "For each input sample, we create a sequence of length  n n n italic_n , denoted as  { x 1 , ... , x n } subscript x 1 ... subscript x n \\{x_{1},\\ldots,x_{n}\\} { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ... , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } , where each  x i subscript x i x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is a randomly sampled token from the vocabulary. This sequence is repeated to form an input sample  X = { x 1 , ... , x 2  n } X subscript x 1 ... subscript x 2 n X=\\{x_{1},\\ldots,x_{2n}\\} italic_X = { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ... , italic_x start_POSTSUBSCRIPT 2 italic_n end_POSTSUBSCRIPT } , with  x i = x i + n subscript x i subscript x i n x_{i}=x_{i+n} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_x start_POSTSUBSCRIPT italic_i + italic_n end_POSTSUBSCRIPT  for  i  [ 1 , n ] i 1 n i\\in[1,n] italic_i  [ 1 , italic_n ] .  Research has shown that, in semantically meaningless contexts, models tend to check if the last few tokens in the sequence appeared previously and copy the suffix of their last appearance as the output  (Olsson et al.,  2022 ; Lv et al.,  2024b ) .  We consider an arbitrary LLM to successfully perform the proxy task when, at position  n + i n i n+i italic_n + italic_i , the token with the highest output logits is  x i + 1 subscript x i 1 x_{i+1} italic_x start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT .  Table  1  shows an example input.",
            "For an arbitrary LLM, we repeat the proxy task multiple times with varying values of  n n n italic_n  to mitigate bias in context length.  The final metric score for each head is the average of the results from these repeated experiments.  The detailed setup is provided in Section  5.1 .",
            "We also compared several competitive baseline methods for enhancing LLMs context awareness, including Attention Buckets (AB,  (Chen et al.,  2024 ) ), Ms-PoE  (Zhang et al.,  2024 ) , and MoICE  (Lin et al.,  2024 ) .  Details on these methods can be found in Section  2.1 .",
            "Intuitively, most heads are optimized to values less than one, which reduces their relative weight compared to other heads within the same layer when multi-head outputs are aggregated.  Due to BF16 training precision, many    \\tau italic_ s are optimized to the same value.  However, using FP32 precision for training did not significantly impact the results.  Notably,    \\tau italic_ s for 9 heads, which have relatively low       \\Delta\\pi roman_ italic_ , are greater than one.  We do not attribute this to the precision of the discovery process, as constraining the re-weighting coefficients to be less than one led to suboptimal performance. Thus, a plausible explanation is that RAG suppression is a complex, cooperative effect involving multiple heads, each with distinct working mechanisms, as discussed in Section  4.1 ."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Discovered RAG-suppression heads in Llama2-Chat-7B-4k, OPT-6.7B-2k and Baichuan-13B-chat-4k, respectively.",
        "table": "S5.T2.2.2",
        "footnotes": [],
        "references": [
            "In this section, we provide a detailed introduction to our proposed method,  PEAR , which is executed in two stages: (1) discovering RAG-suppression heads and (2) re-weighting coefficient learning.  The first stage discovers attention heads that have a negative impact on general RAG tasks based on circuit discovery for a proxy task.  In the second stage, we optimize learnable coefficients to re-weight the outputs of the discovered heads, aiming to mitigate their RAG-suppression effect.  These coefficients remain fixed during inference, irrespective of the specific input.  Figure  2  demonstrates the overview of  PEAR .",
            "Figure  2  illustrates a re-weighting process during optimization.  Notably, the re-weighting process shown in this figure adds extra multiplication operations in a forward pass.  In practice, when coefficient learning ends, we re-scale  W O ( l , h ) subscript superscript W l h O W^{(l,h)}_{O} italic_W start_POSTSUPERSCRIPT ( italic_l , italic_h ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_O end_POSTSUBSCRIPT  (the output projection matrix in head  A ( l , h ) superscript A l h A^{(l,h)} italic_A start_POSTSUPERSCRIPT ( italic_l , italic_h ) end_POSTSUPERSCRIPT ) by   ( l , h ) superscript  l h \\tau^{(l,h)} italic_ start_POSTSUPERSCRIPT ( italic_l , italic_h ) end_POSTSUPERSCRIPT , which is equivalent to Eq.  2  and does not add any extra computation during inference.",
            "We also compared several competitive baseline methods for enhancing LLMs context awareness, including Attention Buckets (AB,  (Chen et al.,  2024 ) ), Ms-PoE  (Zhang et al.,  2024 ) , and MoICE  (Lin et al.,  2024 ) .  Details on these methods can be found in Section  2.1 .",
            "For head discovery, we constructed 200 task samples.  In the case of the Llama and OPT models, we repeat the discovery process four times with varying values of  n n n italic_n :  10 , 15 , 25 , 50 10 15 25 50 10,15,25,50 10 , 15 , 25 , 50 .  For the Baichuan model, the  n n n italic_n  values are  10 , 20 , 50 , 80 10 20 50 80 10,20,50,80 10 , 20 , 50 , 80 .  We found that each model has a group of heads with significantly large       \\Delta\\pi roman_ italic_  values, leading us to select the  K K K italic_K  values based on the observed group sizes: 30, 22, and 21, respectively.  Table  2  presents the discovered RAG-suppression heads for the LLMs under study.  Figure  3  illustrates       \\Delta\\pi roman_ italic_  values when  n = 10 n 10 n=10 italic_n = 10  for each model.  Further detailed results can be found in Appendix  A ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Performance comparison of Llama2-7B-chat-4k and its enhancements across three RAG tasks.",
        "table": "S5.T3.4",
        "footnotes": [],
        "references": [
            "We previously outlined the head discovery algorithm in Section  3 . Here, we provide additional practical details for the first stage of  PEAR .",
            "For head discovery, we constructed 200 task samples.  In the case of the Llama and OPT models, we repeat the discovery process four times with varying values of  n n n italic_n :  10 , 15 , 25 , 50 10 15 25 50 10,15,25,50 10 , 15 , 25 , 50 .  For the Baichuan model, the  n n n italic_n  values are  10 , 20 , 50 , 80 10 20 50 80 10,20,50,80 10 , 20 , 50 , 80 .  We found that each model has a group of heads with significantly large       \\Delta\\pi roman_ italic_  values, leading us to select the  K K K italic_K  values based on the observed group sizes: 30, 22, and 21, respectively.  Table  2  presents the discovered RAG-suppression heads for the LLMs under study.  Figure  3  illustrates       \\Delta\\pi roman_ italic_  values when  n = 10 n 10 n=10 italic_n = 10  for each model.  Further detailed results can be found in Appendix  A .",
            "Our experiments are conducted with Llama2-7B-chat-4k, as the baselines are tailored specifically for RoPE.  We evaluate the models performance using exact match scores, with results reported in Table  3 .  Notably, our method achieves the highest average improvement across all three tasks.  Although  PEAR  does not achieve the top performance on the MuSiQue task, it outperforms the original model by a large margin."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Practical inference time (in seconds) and GPU memory cost (in GB) per test sample for different methods.  For a fair comparison, Flash-Attention  (Dao,  2024 )  was not applied.  The experiments were conducted on a single H800-80G GPU.",
        "table": "S5.T4.4.4",
        "footnotes": [],
        "references": [
            "As a result, we contend that such suppression mechanism in LLMs can be safely 1 1 1 Safely means that the parametric knowledge and fundamental capabilities remain unaffected.  Detailed experimental results are presented in Section  5.4 .  weakened in RAG scenarios, thereby improving the RAG performance of LLMs.  Our proposed  PEAR  includes two stages:",
            "In the first stage, we discover attention heads negatively affect performance on a proxy task.  The proxy task involves feeding the model a random token sequence of length  2  n 2 n 2n 2 italic_n , which consists of a duplicated sub-sequence of length  n n n italic_n . Table  1  illustrates an example input.  At position  n + i n i n+i italic_n + italic_i , the model typically predicts the token from position  i + 1 i 1 i+1 italic_i + 1 , as the natural continuation for a semantically meaningless context is to copy the existing in-context token pattern  (Lv et al.,  2024b ) .  The negatively impactful attention heads are discovered using the path patching technique  (Wang et al.,  2023 ) .  Since this proxy task is free from semantic bias and requires both in-context retrieval and generation based on the contextfundamental capacities for RAG, we refer to discovered heads as RAG-suppression heads 2 2 2 We do not imply that these heads hinder RAG through the same mechanisms (discussed in Section  4.1 ). .",
            "Additionally, we present inference time and memory costs for these datasets in Table  4 .   PEAR  does not increase GPU memory usage and inference time costs.  This makes it significantly more efficient than other enhancement methods.",
            "Using Llama2-7B-chat as an example, we present the learned coefficients of PEAR in Figure  4 , with heads ranked by their       \\Delta\\pi roman_ italic_  scores.",
            "Intuitively, most heads are optimized to values less than one, which reduces their relative weight compared to other heads within the same layer when multi-head outputs are aggregated.  Due to BF16 training precision, many    \\tau italic_ s are optimized to the same value.  However, using FP32 precision for training did not significantly impact the results.  Notably,    \\tau italic_ s for 9 heads, which have relatively low       \\Delta\\pi roman_ italic_ , are greater than one.  We do not attribute this to the precision of the discovery process, as constraining the re-weighting coefficients to be less than one led to suboptimal performance. Thus, a plausible explanation is that RAG suppression is a complex, cooperative effect involving multiple heads, each with distinct working mechanisms, as discussed in Section  4.1 ."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Experimental results on the MDQA task show that  PEAR  achieves the highest accuracy in 24 out of 25 comparisons across three LLMs, demonstrating its broad applicability to various position embeddings and its robustness in enhancing awareness to different contextual positions.",
        "table": "S5.T5.3.1",
        "footnotes": [],
        "references": [
            "As a result, we contend that such suppression mechanism in LLMs can be safely 1 1 1 Safely means that the parametric knowledge and fundamental capabilities remain unaffected.  Detailed experimental results are presented in Section  5.4 .  weakened in RAG scenarios, thereby improving the RAG performance of LLMs.  Our proposed  PEAR  includes two stages:",
            "For an arbitrary LLM, we repeat the proxy task multiple times with varying values of  n n n italic_n  to mitigate bias in context length.  The final metric score for each head is the average of the results from these repeated experiments.  The detailed setup is provided in Section  5.1 .",
            "Notably, we do not suggest that the heads we discovered suppressing RAG tasks operate through the same mechanisms.  In Section  5.6 , we demonstrate that these heads may serve various functions, such as copy suppression  (McDougall et al.,  2023 ) , incorporating high-frequency token information  (Lv et al.,  2024a ) , or influencing the behavior of other heads to indirectly affect outputs  (Wang et al.,  2023 ) .  Analyzing the specific mechanism for each head is not the focus of this paper and is left for future works.",
            "In this section, we demonstrate the applicability of  PEAR  to LLMs utilizing different position embeddings.  We conduct a multi-document question-answering (MDQA) experiment based on data from  (Liu et al.,  2023 ) , which leverage a subset of NaturalQuestions-Open   (Lee et al.,  2019 ; Kwiatkowski et al.,  2019 ) , consisting of 2,655 queries. Each query is paired with a context consisting of 10 documents with an average of 1,722 tokens.  Following  (Liu et al.,  2023 ; Chen et al.,  2024 ) , we position the gold document (i.e., the document contains the ground truth answer) at various contextual positions to evaluate the robustness of a context-awareness enhancement method.  In our experiments, we set the maximum document count to 10 and assess the question-answering accuracy when the gold document is placed as the 1st, 3rd, 5th, 7th, and 10th document, respectively.  Since baseline methods are not compatible with the OPT and Baichuan models, we compare  PEAR  only with the original models.  The results are presented in Table  5 ."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Results on the MMLU benchmark showing that  PEAR  does not enhance LLMs context capacities at the expense of knowledge ability.",
        "table": "S5.T6.3.1",
        "footnotes": [],
        "references": [
            "Notably, we do not suggest that the heads we discovered suppressing RAG tasks operate through the same mechanisms.  In Section  5.6 , we demonstrate that these heads may serve various functions, such as copy suppression  (McDougall et al.,  2023 ) , incorporating high-frequency token information  (Lv et al.,  2024a ) , or influencing the behavior of other heads to indirectly affect outputs  (Wang et al.,  2023 ) .  Analyzing the specific mechanism for each head is not the focus of this paper and is left for future works.",
            "To investigate this, we evaluated a  PEAR -enhanced Llama2-7B-chat model using the MMLU benchmark  (Hendrycks et al.,  2021 ) , and the results are presented in Table  6 .  The performance of the enhanced Llama2-7B-chat and the original Llama2-7B-chat did not show a significant difference.  Consequently, we argue that  PEAR , through its effective head discovery and re-weighting learning approaches, does not compromise the knowledge capabilities of LLMs."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  The experiment results on the question answering task with ablation settings, which show that our control over the number of suppression heads is effective.",
        "table": "S5.T7.4",
        "footnotes": [],
        "references": [
            "Using Llama2-7B-chat as a case study, we vary  K K K italic_K  and observe its impact on  PEAR s performance.  Table  7  presents results on RAG tasks, while Table  8  details analysis for MDQA tasks.  The findings indicate that  PEAR  performs optimally when  K K K italic_K  matches the inherent threshold of the model (i.e.,  K = 30 K 30 K=30 italic_K = 30  for Llama2-7B-chat), i.e., the number of heads with a significantly higher       \\Delta\\pi roman_ italic_  than others."
        ]
    },
    "id_table_8": {
        "caption": "Table 8:  The experiment results on the MDQA task with ablation settings, which show that our control over the number of suppression heads is effective.",
        "table": "S5.T8.4",
        "footnotes": [],
        "references": [
            "Using Llama2-7B-chat as a case study, we vary  K K K italic_K  and observe its impact on  PEAR s performance.  Table  7  presents results on RAG tasks, while Table  8  details analysis for MDQA tasks.  The findings indicate that  PEAR  performs optimally when  K K K italic_K  matches the inherent threshold of the model (i.e.,  K = 30 K 30 K=30 italic_K = 30  for Llama2-7B-chat), i.e., the number of heads with a significantly higher       \\Delta\\pi roman_ italic_  than others."
        ]
    },
    "global_footnotes": [
        "Safely means that the parametric knowledge and fundamental capabilities remain unaffected.  Detailed experimental results are presented in Section",
        ".",
        "We do not imply that these heads hinder RAG through the same mechanisms (discussed in Section",
        ")."
    ]
}