{
    "S4.T1": {
        "caption": "TABLE I: Few-shot detection performance (mAP@0.5) on Pascal VOC for novel classes",
        "table": null,
        "footnotes": [],
        "references": [
            "Table‚ÄÑI shows the few-shot detection performance for novel classes of Pascal VOC. It can be seen that Meta-DETR consistently outperforms existing methods across various setups. With multiple runs over randomly sampled support datasets to reduce randomness, Meta-DETR achieves the best average performance across all setups, with a large margin of +‚Äâ4.6% overall mAP compared with the second-best. The strong performance demonstrates the superiority and robustness of our proposed Meta-DETR.",
            "Region-Level Detection vs. Image-Level Detection.‚ÄÑ‚ÄÑ\nFrom Table‚ÄÑI and Table‚ÄÑIII, we can find that fine-tuning Deformable DETR (Deformable-DETR+ft-full) generally outperforms fine-tuning Faster R-CNN (FRCN+ft-full), especially in the MS COCO dataset, where it is much harder to obtain accurate region proposals for novel classes due to higher complexity (see Fig.‚ÄÑ2(a)). This observation aligns well with our insight that region-based detection frameworks tend to suffer from inaccurate regional proposals for novel classes. To further verify the superiority of image-level few-shot object detection, we adopt FsDetView¬†[4], a state-of-the-art meta-learning-based few-shot detector built on top of Faster R-CNN, as a solid baseline to compare with our method. For a fair comparison, we add deformable transformers to FsDetView (denoted as FsDetView‚Äâ+‚ÄâDeform.‚ÄâTrans.) to rule out the performance difference brought by the transformer architecture. Furthermore, we replace our proposed CAM in Meta-DETR with the feature aggregation module proposed in FsDetView (denoted as Meta-DETR‚Äâw/o‚ÄâCAM). As shown in Table‚ÄÑIV, even with aligned network architecture and aggregation scheme, Meta-DETR‚Äâw/o‚ÄâCAM still outperforms FsDetView‚Äâ+‚ÄâDeform.‚ÄâTrans. under most setups. The results validate the superiority of solving few-shot object detection at image level."
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Few-shot detection performance (mAP@0.5) \non Pascal VOC class split 1 for both base and novel classes",
        "table": null,
        "footnotes": [],
        "references": [
            "We also present results taking base classes into consideration in Table‚ÄÑII. While achieving good performance for novel classes with limited training samples, Meta-DETR can still detect objects of base classes with competitive performance. TFA¬†[31] produces outstanding performance for base classes since it only fine-tunes detector‚Äôs last layer, thus having relatively constrained capacity in generalizing on novel classes. We would highlight that our proposed Meta-DETR achieves the best base-class and novel-class performance among all compared methods using meta-learning (i.e., Meta-YOLO¬†[2] and FsDetView¬†[4])."
        ]
    },
    "S5.T3": {
        "caption": "TABLE III: Few-shot detection performance on COCO for novel classes",
        "table": null,
        "footnotes": [],
        "references": [
            "Table‚ÄÑIII shows experimental results on MS COCO. It can be seen that, although MS COCO is much more challenging than Pascal VOC with higher complexity like occlusions and large scale variations, Meta-DETR still outperforms all existing methods under all setups by even larger margins. This can be attributed to (i) the complete circumvention of even more inaccurate region proposals for novel classes (See Fig.¬†2(a)) caused by the higher complexity of MS COCO, and (ii) the effective exploitation of the correlations among more classes in MS COCO. In addition, Meta-DETR performs exceptionally well compared with other region-based methods under the stricter metric AP0.75, which implies that our proposed Meta-DETR can effectively lift the constraint of inaccurate region proposals and produce more accurate few-shot object detection.",
            "Region-Level Detection vs. Image-Level Detection.‚ÄÑ‚ÄÑ\nFrom Table‚ÄÑI and Table‚ÄÑIII, we can find that fine-tuning Deformable DETR (Deformable-DETR+ft-full) generally outperforms fine-tuning Faster R-CNN (FRCN+ft-full), especially in the MS COCO dataset, where it is much harder to obtain accurate region proposals for novel classes due to higher complexity (see Fig.‚ÄÑ2(a)). This observation aligns well with our insight that region-based detection frameworks tend to suffer from inaccurate regional proposals for novel classes. To further verify the superiority of image-level few-shot object detection, we adopt FsDetView¬†[4], a state-of-the-art meta-learning-based few-shot detector built on top of Faster R-CNN, as a solid baseline to compare with our method. For a fair comparison, we add deformable transformers to FsDetView (denoted as FsDetView‚Äâ+‚ÄâDeform.‚ÄâTrans.) to rule out the performance difference brought by the transformer architecture. Furthermore, we replace our proposed CAM in Meta-DETR with the feature aggregation module proposed in FsDetView (denoted as Meta-DETR‚Äâw/o‚ÄâCAM). As shown in Table‚ÄÑIV, even with aligned network architecture and aggregation scheme, Meta-DETR‚Äâw/o‚ÄâCAM still outperforms FsDetView‚Äâ+‚ÄâDeform.‚ÄâTrans. under most setups. The results validate the superiority of solving few-shot object detection at image level."
        ]
    },
    "S5.T4": {
        "caption": "TABLE IV: Ablation study on region-level detection vs. image-level detection",
        "table": null,
        "footnotes": [],
        "references": [
            "Region-Level Detection vs. Image-Level Detection.‚ÄÑ‚ÄÑ\nFrom Table‚ÄÑI and Table‚ÄÑIII, we can find that fine-tuning Deformable DETR (Deformable-DETR+ft-full) generally outperforms fine-tuning Faster R-CNN (FRCN+ft-full), especially in the MS COCO dataset, where it is much harder to obtain accurate region proposals for novel classes due to higher complexity (see Fig.‚ÄÑ2(a)). This observation aligns well with our insight that region-based detection frameworks tend to suffer from inaccurate regional proposals for novel classes. To further verify the superiority of image-level few-shot object detection, we adopt FsDetView¬†[4], a state-of-the-art meta-learning-based few-shot detector built on top of Faster R-CNN, as a solid baseline to compare with our method. For a fair comparison, we add deformable transformers to FsDetView (denoted as FsDetView‚Äâ+‚ÄâDeform.‚ÄâTrans.) to rule out the performance difference brought by the transformer architecture. Furthermore, we replace our proposed CAM in Meta-DETR with the feature aggregation module proposed in FsDetView (denoted as Meta-DETR‚Äâw/o‚ÄâCAM). As shown in Table‚ÄÑIV, even with aligned network architecture and aggregation scheme, Meta-DETR‚Äâw/o‚ÄâCAM still outperforms FsDetView‚Äâ+‚ÄâDeform.‚ÄâTrans. under most setups. The results validate the superiority of solving few-shot object detection at image level."
        ]
    },
    "S5.T5": {
        "caption": "TABLE V: Ablation study on the impact of Correlational Aggregation Module",
        "table": null,
        "footnotes": [],
        "references": [
            "Impact of Correlational Aggregation Module (CAM).‚ÄÑ‚ÄÑ\nAs shown in Table‚ÄÑV, when incorporating CAM into our model, even if we keep the number of support classes for simultaneous aggregation (Cùê∂C) as 1, CAM can still boost few-shot detection performance under all settings. This demonstrates CAM‚Äôs strong capacity in aggregating query and support information even without the leverage of inter-class correlation. When multiple support classes are available (C‚â•ùê∂absentC\\geq2), CAM can further exploit their inter-class correlation to boost few-shot detection performance under lower-shot (‚â§\\leq5) settings, especially under 1-shot (+‚Äâ4.8%‚ÄÑmAP) and 2-shot (+‚Äâ5.0%‚ÄÑmAP), which shows the benefit of inter-class correlational meta-learning. No clear performance gain is observed for 10-shot, which implies that, when more training samples are available, the detector can already recognize novel classes and differentiate them from similar classes without explicitly modeling the inter-class correlation. We also apply our designed CAM to the commonly used region-based meta-detector FsDetView¬†[4] and report the results in Table‚ÄÑV. Its steady performance gain demonstrates that CAM and the proposed inter-class correaltional meta-learning strategy can also benefit region-level few-shot object detection."
        ]
    },
    "S5.T6": {
        "caption": "TABLE VI: Confusion matrices of similar class pairs predicted with \nand without the proposed Correlational Aggregation Module",
        "table": null,
        "footnotes": [],
        "references": [
            "To understand how CAM functions to improve detection accuracy, we visualize the objects from different classes in the feature space learned with and without the proposed CAM with t-SNE¬†[49]. As shown in Fig.‚ÄÑ6, with CAM included to perform inter-class correlational meta-learning, object classes are better separated from each other, which affirms our motivation of leveraging inter-class correlation to reduce misclassification among similar classes. To further verify our claim that CAM effectively reduces misclassification among similar classes, we select two pairs of similar classes (motorbike‚ÄÑvs.‚ÄÑbike and cow‚ÄÑvs.‚ÄÑhorse) and plot their confusion matrices in Table‚ÄÑVI. We can observe that CAM indeed reduces the misclassification by large margins with the exploitation of inter-class correlation. We also observe fewer missed predictions, which shows that the effective leverage of inter-class correlations also facilitates generalization to detect previously missed cases."
        ]
    },
    "S5.T7": {
        "caption": "TABLE VII: Ablation study on the design choices of the attention mechanism \nin the proposed Correlational Aggregation Module",
        "table": null,
        "footnotes": [],
        "references": [
            "Design Choices for Correlational Aggregation Module (CAM).‚ÄÑ‚ÄÑ\nThe proposed CAM‚Äôs attention mechanism differs from the original DETR attention in three aspects: (a) applying a sigmoid function to attention‚Äôs Value in feature matching, (b) multiplying attention‚Äôs output with attention‚Äôs Query in feature matching, and (c) explicitly modelling a prototype for the ‚Äòbackground‚Äô class. Among them, (a) and (b) are designed as a whole with (a) for generating ‚Äòfilters‚Äô to remove query features that are irrelevant to the given support classes and (b) for applying the learned ‚Äòfilters‚Äô to the query image features. And (c) enables Meta-DETR to better handle the ‚Äòno match‚Äô scenario where the query features do not match any of the support classes. We present ablation experiments in Table‚ÄÑVII that verify the effectiveness of the above three modifications."
        ]
    },
    "S5.T8": {
        "caption": "TABLE VIII: Ablation study on early aggregation vs. late aggregation",
        "table": null,
        "footnotes": [],
        "references": [
            "Early Aggregation vs. Late Aggregation.‚ÄÑ‚ÄÑ‚ÄÑ\nThe proposed CAM replaces one encoder layer in the transformer. As shown in Fig.¬†3, we place CAM ahead of the transformer encoder (as the first layer of the encoder). Table¬†VIII studies the impact of the location of CAM in the transformer encoder. As shown, it is preferable to place CAM at the beginning stage of the transformer encoder for early aggregation, which also suggests the importance of learning a deep class-agnostic predictor."
        ]
    },
    "S5.T9": {
        "caption": "TABLE IX: Few-shot object detection and instance segmentation performance on COCO for novel classes",
        "table": null,
        "footnotes": [],
        "references": [
            "Experimental Results.‚ÄÑ‚ÄÑ We conduct experiments for few-shot instance segmentation on MS COCO under 5-shot and 10-shot setups. Similarly, the 20 classes shared with Pascal VOC are chosen as novel classes, and the remaining 60 classes are set as base classes. Note that AP for instance segmentation is evaluated with mask IoU. As shown in Table¬†IX, Meta-DETR outperforms compared methods by large margins. The results demonstrate the superiority and universality of our Meta-DETR, which can extend to other instance-level few-shot learning tasks. Note that the compared Meta R-CNN¬†[3] adopts region-level prediction together with the conventional class-by-class meta-learning via feature reweighting. The comparison between Meta R-CNN¬†[3] and our proposed Meta-DETR verifies that the combination of the image-level prediction and the exploitation of inter-class correlation via correlational meta-learning can effectively benefit other instance-level few-shot learning tasks like few-shot instance segmentation. We also provide qualitative results for instance segmentation in Fig.¬†9."
        ]
    }
}