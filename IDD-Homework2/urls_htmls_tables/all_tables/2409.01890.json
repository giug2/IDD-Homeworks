{
    "id_table_1": {
        "caption": "Table 1:  Natural Questions   (Kwiatkowski et al.,  2019 ) .  \\faNewspaper [regular]  This paper;    \\dagger    (Reddi et al.,  2019 )   + + +   (Monath et al.,  2023 ) . We measure the performance of dense retrieval models trained with different softmax approximations via hard negatives. We find that our proposed approach nearly matches the performance of exhaustively re-embedding all targets. Similarly, our approach requires significantly less re-embedding of targets than Dynnibal, which requires at least one exhaustive re-embedding to get competitive results.  Bold-face numbers  indicate best performance with zero re-embeddings performed at training time;  underlined numbers  indicate best performance using re-embedding at training time.",
        "table": "S5.T1.14",
        "footnotes": [],
        "references": [
            "where  P ~  ( y | x ) ~ P conditional y x \\tilde{P}(y|x) over~ start_ARG italic_P end_ARG ( italic_y | italic_x )  is the truncated softmax  g  ( y ) g y g(y) italic_g ( italic_y )  (Eq.  3 ). The mean-squared error loss directly tries to match the target encoder models embeddings.  The cross-entropy loss down-weights the importance of targets  y y y italic_y  which do not contribute substantial probability to  P  ( y | x ) P conditional y x P(y|x) italic_P ( italic_y | italic_x )  and allows for greater use of model capacity.  The parameters of the target corrector networks are optimized using gradient descent.  Empirically, we find the cross-entropy objective to perform slightly better (Table  1 ) and focus the presentation on cross-entropy.",
            "Jointly Training Corrector Networks & Dual-Encoders    We present a method (Algorithm  1 ) for simultaneously training dual-encoders for a given task (e.g., retrieval or equivalently large output-space classification)  and the target corrector network. The training algorithm will optimize both the  parameters of the target corrector network and additionally use the corrector network to approximate the softmax. Each step consists of: (1) using the corrector network to provide an approximately updated representation of every target, (2) picking a subset of targets for the truncated softmax using the output of the corrector network, (3) computing a task loss for the dual-encoder models and loss for the corrector networks, (4) updating, according to their respective losses, the parameters for both the dual-encoders and the corrector networks using gradient descent.",
            "The training procedure is summarized in Algorithm    1 . At prediction time, the corrector network is not used, instead the trained dual-encoder  g  ( y ,  ) g y  g(y,\\Theta) italic_g ( italic_y , roman_ )  is used.",
            "To facilitate efficient training, we use our proposed target corrector network to select the subset of retrieved targets  S x  ( Y ) subscript S x Y S_{x}(\\mathcal{Y}) italic_S start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( caligraphic_Y )  used at training time. This is done in the same way as in Algorithm  1 , i.e., we pick a subset of  k k k italic_k  targets  S x  ( Y ) subscript S x Y S_{x}(\\mathcal{Y}) italic_S start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( caligraphic_Y )  for  x x x italic_x  according to  exp  (   f  ( x ) T  h  g   ( y ) )  f superscript x T h superscript g  y \\exp(\\beta f(x)^{T}h\\circ g^{\\prime}(y)) roman_exp ( italic_ italic_f ( italic_x ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_h  italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_y ) )  via top- k k k italic_k  or Gumbel-Max sampling. We can make simple modifications to Algorithm  1 , which are presented in Algorithm  2  to train the RLM. We compute two task-specific losses (perplexity distillation, negative log-likelihood) and optimize both the reader and retriever parameters. We use cross-entropy to train the corrector, which is again only used at training time. At prediction time, the trained retriever model is used.",
            "and similarly define  D Y  P g  ( y | x )  subscript D Y subscript P g conditional y x {\\mathscr{D}}_{Y}\\triangleq{P}_{g}(y|x) script_D start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT  italic_P start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( italic_y | italic_x )  as the true distribution, using  g g g italic_g  (Eq.  1 ).",
            "No Re-embedding Needed  Training using target corrector networks matches the task performance of exhaustively re-embed all targets every 500 steps throughout training in both dense retrieval (Table  1 ) and retrieval augmented language models (Table  3 ). Target correctors achieve this without ever needing to re-embed targets during training, yielding significant computational savings (Fig.  2 ).",
            "Simpler and Less Computation  Target correctors perform as well or better than Stochastic Negative Mining (SNM)  (Reddi et al.,  2019 )  despite SNM doing more re-embedding. Similarly, target corrector networks nearly match Dynnibal  (Monath et al.,  2023 )  when Dynnibal uses much more computation (Table  1 ). Dynnibal is a much more complicated and difficult to implement method.",
            "In Table  1 , our  target corrector network approach greatly improves upon the stale approach, especially in Recall@1, 5, 10. We observe a nearly 5 point improvement at R@10 in the dev set and a 4 point improvement in R@1 on the test over the stale approach. Our approach nearly matches the performance of the computationally intensive exhaustive approach. Furthermore, we perform comparably to the more expensive SNM and Dynnibal methods. We perform better than Dynnibal for the same amount of re-embedding. While doubling the number of index refreshes may appear negligible, having to re-embed the buffer during training can be computationally burdensome, especially as the number of targets grows. Using a buffer created from the initial parameters of the dual-encoder as with our approach, allows the buffer to be constructed once ahead of time and re-used across both training and tasks. Dynnibal requires hand tuning to get the re-embedding schedule correct.",
            "Table  1  also compares dual-encoder initialization. GTR is pre-trained for retrieval and hence achieves better results. T5 is not pre-trained for retrieval and requires more adaptation for the retrieval task. We observe that SNM struggles more to match the performance of Exhaustive with T5. Furthermore, Dynnibal requires more full index refreshes to get competitive results. Our method is able to achieve nearly as good results as the Exhaustive approach and Dynnibal (with re-embedding) despite never needing to re-embed.",
            "Setting & Metrics   We evaluate the latent variable use case of training the retriever in a retrieval-augmented language model (RLM), as described in Section  3.1 . We will compare approaches for training in terms of their re-embedding costs.",
            "Setting & Metrics  We will measure the ability of proposed  corrector network to approximate categorical distributions parameterized by the softmax. We do so by training the corrector network,  h h h italic_h , in isolation, e.g., only training the parameters of the corrector network,    \\Psi roman_ , without training parameters of the dual-encoder for a particular task. We measure the quality of approximation using the KL-divergence between the true categorical distribution  P  ( y | x ) P conditional y x P(y|x) italic_P ( italic_y | italic_x )  (Equation  1 ) and the approximate distribution given by the corrector network  P h  ( y | x ) subscript P h conditional y x P_{h}(y|x) italic_P start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ( italic_y | italic_x )  (Equation  4 ). We measure the complexity of the corrector network by its parameter count,  |  |  |\\Psi| | roman_ | . We measure staleness, i.e., the difficulty of correcting a set of stale representations, by the KL-divergence between the true categorical distribution  P  ( y | x ) P conditional y x P(y|x) italic_P ( italic_y | italic_x )  and the distribution  P g   ( y | x )  exp  (    f  ( x ) , g   ( y )  ) proportional-to subscript P superscript g  conditional y x  f x superscript g  y P_{g^{\\prime}}(y|x)\\propto\\exp(\\beta\\langle f(x),g^{\\prime}(y)\\rangle) italic_P start_POSTSUBSCRIPT italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_y | italic_x )  roman_exp ( italic_  italic_f ( italic_x ) , italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_y )  ) .",
            "See  4.1    Proof . We bound the gap between true population risk and stale population risk.  Recall that  G l , F subscript G l F \\mathcal{G}_{\\ell,\\mathcal{F}} caligraphic_G start_POSTSUBSCRIPT roman_l , caligraphic_F end_POSTSUBSCRIPT  is the induced function class:  G l , F = { y  l  ( f  ( y ) , g  ( y ) ) : f  F } . subscript G l F conditional-set maps-to y l f y g y f F \\mathcal{G}_{\\ell,\\mathcal{F}}=\\{y\\mapsto\\ell(f(y),g(y)):f\\in\\mathcal{F}\\}. caligraphic_G start_POSTSUBSCRIPT roman_l , caligraphic_F end_POSTSUBSCRIPT = { italic_y  roman_l ( italic_f ( italic_y ) , italic_g ( italic_y ) ) : italic_f  caligraphic_F } .   Now note that",
            "Combining results from Eq.  16 ,  A , and  23 , we obtain that with probability at least  1   1  1-\\delta 1 - italic_ ,",
            "In our main experiments (as stated in Appendix  B.1 ) we train with hard negatives  and  uniform negatives. Initial experiments showed that adding uniform negatives lead to improved performance in some settings. We provide some additional results ablating this choice using exhaustive re-encoding. These can be found in Table  6 . We can see that this choice provides negligible improvement on the reported benchmarks (although we believe its worth trying in other settings)."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Steps-Per-Second Comparison.  We compare on NQ-dev the performance and speed of corrector networks and exhaustive re-encoding. Models are finetuned GTR-base.",
        "table": "S5.T2.1",
        "footnotes": [],
        "references": [
            "P  ( a | y , x ) P conditional a y x P(a|y,x) italic_P ( italic_a | italic_y , italic_x )  is an autoregressive language model.  P  ( y | x ) P conditional y x P(y|x) italic_P ( italic_y | italic_x )  is computed by the softmax with logits from Equation  2  using the encoder models  f  ( x ) f x f(x) italic_f ( italic_x )  and  g  ( y ) g y g(y) italic_g ( italic_y ) .",
            "To facilitate efficient training, we use our proposed target corrector network to select the subset of retrieved targets  S x  ( Y ) subscript S x Y S_{x}(\\mathcal{Y}) italic_S start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( caligraphic_Y )  used at training time. This is done in the same way as in Algorithm  1 , i.e., we pick a subset of  k k k italic_k  targets  S x  ( Y ) subscript S x Y S_{x}(\\mathcal{Y}) italic_S start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( caligraphic_Y )  for  x x x italic_x  according to  exp  (   f  ( x ) T  h  g   ( y ) )  f superscript x T h superscript g  y \\exp(\\beta f(x)^{T}h\\circ g^{\\prime}(y)) roman_exp ( italic_ italic_f ( italic_x ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_h  italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_y ) )  via top- k k k italic_k  or Gumbel-Max sampling. We can make simple modifications to Algorithm  1 , which are presented in Algorithm  2  to train the RLM. We compute two task-specific losses (perplexity distillation, negative log-likelihood) and optimize both the reader and retriever parameters. We use cross-entropy to train the corrector, which is again only used at training time. At prediction time, the trained retriever model is used.",
            "No Re-embedding Needed  Training using target corrector networks matches the task performance of exhaustively re-embed all targets every 500 steps throughout training in both dense retrieval (Table  1 ) and retrieval augmented language models (Table  3 ). Target correctors achieve this without ever needing to re-embed targets during training, yielding significant computational savings (Fig.  2 ).",
            "We also report timing comparisons in terms of steps-per-second between corrector networks (of two sizes) and exhaustive re-encoding of the targets. These can be found in table  2 . We can see that both small and large corrector networks lead large speed gains over exhaustive re-encoding with minimal performance gains. This indicates that corrector networks can have practical training time efficiency gains over exhaustive methods.",
            "See Appendix  B.2  for additional results (MSMARCO, other ablations) and further discussion.",
            "See  4.2",
            "Combining results from Eq.  16 ,  A , and  23 , we obtain that with probability at least  1   1  1-\\delta 1 - italic_ ,"
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Exact Match Accuracy, RLM Training . We find that our target corrector approach can match the performance of the fully refreshed index while never re-embedding the targets across NQ, TriviaQA (TQA), and HotPotQA (HPQA).",
        "table": "S5.T3.1",
        "footnotes": [],
        "references": [
            "Methodological  ( 3 ) - We describe a novel training procedure for large output space models. It is based on approximating softmax-parameterized categorical distributions by using a parametric target corrector network that learns to improve stale approximations of logits.",
            "where  P ~  ( y | x ) ~ P conditional y x \\tilde{P}(y|x) over~ start_ARG italic_P end_ARG ( italic_y | italic_x )  is the truncated softmax  g  ( y ) g y g(y) italic_g ( italic_y )  (Eq.  3 ). The mean-squared error loss directly tries to match the target encoder models embeddings.  The cross-entropy loss down-weights the importance of targets  y y y italic_y  which do not contribute substantial probability to  P  ( y | x ) P conditional y x P(y|x) italic_P ( italic_y | italic_x )  and allows for greater use of model capacity.  The parameters of the target corrector networks are optimized using gradient descent.  Empirically, we find the cross-entropy objective to perform slightly better (Table  1 ) and focus the presentation on cross-entropy.",
            "Given this subset, we compute the task and correction losses and update their respective model parameters. First, we compute the task loss, which is cross-entropy. The task loss will only be used to update the parameters of the dual-encoders,    \\Theta roman_ , not the parameters of the target corrector network. We compute the truncated softmax  P ~  ( y | x )  exp  (    f  ( x ) , g  ( y )  ) proportional-to ~ P conditional y x  f x g y \\tilde{P}(y|x)\\propto\\exp(\\beta\\langle f(x),g(y)\\rangle) over~ start_ARG italic_P end_ARG ( italic_y | italic_x )  roman_exp ( italic_  italic_f ( italic_x ) , italic_g ( italic_y )  )  (Equation  3 ). We define a one-hot  P  superscript P  P^{\\star} italic_P start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  according to the training data label  y i subscript y i y_{i} italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . We compute the task specific loss  L L \\mathcal{L} caligraphic_L  as a function of  P ~ ~ P \\tilde{P} over~ start_ARG italic_P end_ARG  and  P  superscript P  P^{\\star} italic_P start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , and update the dual encoder parameters via gradient descent          L     subscript   L \\Theta\\leftarrow\\Theta-\\eta\\nabla_{\\Theta}\\mathcal{L} roman_  roman_ - italic_  start_POSTSUBSCRIPT roman_ end_POSTSUBSCRIPT caligraphic_L .",
            "To train the reader and retriever model, we use perplexity distillation  (Izacard et al.,  2022 )  for retriever loss and negative log-likelihood for the reader loss. Perplexity distillation is computed as the cross-entropy between two truncated distributions, one being the retrievers  P ~  ( y | x ) ~ P conditional y x \\tilde{P}(y|x) over~ start_ARG italic_P end_ARG ( italic_y | italic_x )  (Equation  3 ) and the other using the reader model to provide a soft-relevance label for each target in  S x  ( Y ) subscript S x Y S_{x}(\\mathcal{Y}) italic_S start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( caligraphic_Y ) :",
            "We empirically explore some of these trade-offs in  5.3 .",
            "No Re-embedding Needed  Training using target corrector networks matches the task performance of exhaustively re-embed all targets every 500 steps throughout training in both dense retrieval (Table  1 ) and retrieval augmented language models (Table  3 ). Target correctors achieve this without ever needing to re-embed targets during training, yielding significant computational savings (Fig.  2 ).",
            "Setting & Metrics   We evaluate the latent variable use case of training the retriever in a retrieval-augmented language model (RLM), as described in Section  3.1 . We will compare approaches for training in terms of their re-embedding costs.",
            "In Table  3 , we report exact match accuracy on the held-out validation sets. Our proposed target corrector matches or nearly matches the performance of the exhaustive re-embedding approach without ever having to re-embed the buffer. This is a dramatic reduction in computational cost, as the exhaustive approach ends up embedding all 28M passages 40 times (1.1B re-embeddings). Target correctors greatly outperform the approaches that do not use retrieval (by more than 20 points) and the frozen retriever approach (by at least 4 points and by up to 10 points).",
            "Varying  | S  ( Y ) | S Y |S(\\mathcal{Y})| | italic_S ( caligraphic_Y ) | , number of targets used for training  In Figure  3 , we explore trade-offs between the complexity in terms of the parameter count  |  |  |\\Psi| | roman_ |  of  h h h italic_h  (x-axis); the approximation error  KL  ( P  P h ) KL conditional P subscript P h \\operatorname{KL}(P\\|P_{h}) roman_KL ( italic_P  italic_P start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT )  after applying the trained correction model (y-axis); and the fraction of samples used for training  h h h italic_h . We report the complexity of the transformation from  g  superscript g  g^{\\prime} italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  to  g g g italic_g  in terms of  KL  ( P  P g  ) KL conditional P subscript P superscript g  \\operatorname{KL}(P\\|P_{g^{\\prime}}) roman_KL ( italic_P  italic_P start_POSTSUBSCRIPT italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT )  above each pane.  Using a higher fraction of training samples is needed when there is more staleness. When the drift is more significant (right-hand pane), we observe that using increased parameters with a smaller fraction of samples does lead to overfitting. In this setting, it seems that sampling  10 % percent 10 10\\% 10 %  of the targets is generally sufficient.",
            "See  4.3",
            "Combining results from Eq.  16 ,  A , and  23 , we obtain that with probability at least  1   1  1-\\delta 1 - italic_ ,"
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  MSMARCO, T5 Initialization.  In this experiment, we measure performance of methods on MSMARCO. With fewer targets than Natural Questions, the gap between stochastic negative mining and the refreshed index is reduced.",
        "table": "A2.T4.1",
        "footnotes": [],
        "references": [
            "Theoretical  ( 4 ) - We analyze the generalization properties of the corrector networks in terms of the discrepancy between the stale approximation and the true distribution, the complexity of the network, and the amount of training data.",
            "In more detail, we are given task training data,  X = { ( x 1 , y 1 ) , ... , ( x m , y m ) } X subscript x 1 subscript y 1 ... subscript x m subscript y m X=\\{(x_{1},y_{1}),\\dots,(x_{m},y_{m})\\} italic_X = { ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , ... , ( italic_x start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) } . We are given a task loss function  L L \\mathcal{L} caligraphic_L  and a corrector network loss  l l \\ell roman_l . The dual-encoder models are  f  ( x ) , g  ( y ) f x g y f(x),g(y) italic_f ( italic_x ) , italic_g ( italic_y )  and their initial parameters are   0 subscript  0 \\Theta_{0} roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT .  Prior to the first training step, we instantiate a buffer of the targets representations,  B y = g   ( y ) = g  ( y ;  0 ) subscript B y superscript g  y g y subscript  0 B_{y}=g^{\\prime}(y)=g(y;\\Theta_{0}) italic_B start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT = italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_y ) = italic_g ( italic_y ; roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) . We will avert the need for the expensive updating of the buffer by re-embedding targets with the target encoder.  In each step, we sample a training point and label pair  x i , y i subscript x i subscript y i x_{i},y_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  from  X X X italic_X . We apply the target corrector network to all of the stale representations in the buffer to obtain  h  g   ( y )   y  Y h superscript g  y for-all y Y h\\circ g^{\\prime}(y)\\ \\forall y\\in\\mathcal{Y} italic_h  italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_y )  italic_y  caligraphic_Y . This computation does not require running a dual-encoder; we use the cached buffer representation of each target as input to the corrector network. The corrector network is typically a two-layer MLP and hence efficient enough to be used in this way. With these representations from  h  (  ) h  h(\\cdot) italic_h (  ) , we sample (or select exact top- k k k italic_k ) targets according to  P h  ( y | x ) subscript P h conditional y x P_{h}(y|x) italic_P start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ( italic_y | italic_x )  (Eq.  4 ) to form a subset of targets  S x i  ( Y ) subscript S subscript x i Y S_{x_{i}}(\\mathcal{Y}) italic_S start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( caligraphic_Y )  for the truncated softmax.",
            "Setting & Metrics  We will measure the ability of proposed  corrector network to approximate categorical distributions parameterized by the softmax. We do so by training the corrector network,  h h h italic_h , in isolation, e.g., only training the parameters of the corrector network,    \\Psi roman_ , without training parameters of the dual-encoder for a particular task. We measure the quality of approximation using the KL-divergence between the true categorical distribution  P  ( y | x ) P conditional y x P(y|x) italic_P ( italic_y | italic_x )  (Equation  1 ) and the approximate distribution given by the corrector network  P h  ( y | x ) subscript P h conditional y x P_{h}(y|x) italic_P start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ( italic_y | italic_x )  (Equation  4 ). We measure the complexity of the corrector network by its parameter count,  |  |  |\\Psi| | roman_ | . We measure staleness, i.e., the difficulty of correcting a set of stale representations, by the KL-divergence between the true categorical distribution  P  ( y | x ) P conditional y x P(y|x) italic_P ( italic_y | italic_x )  and the distribution  P g   ( y | x )  exp  (    f  ( x ) , g   ( y )  ) proportional-to subscript P superscript g  conditional y x  f x superscript g  y P_{g^{\\prime}}(y|x)\\propto\\exp(\\beta\\langle f(x),g^{\\prime}(y)\\rangle) italic_P start_POSTSUBSCRIPT italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_y | italic_x )  roman_exp ( italic_  italic_f ( italic_x ) , italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_y )  ) .",
            "Varying Complexity of the Target Corrector Network   In order to explore how the KL divergence of our approximation may change with respect to the staleness of the embeddings  g  superscript g  g^{\\prime} italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , we train our embedding model to approximate the distributions  P P P italic_P .  In Figure  4 , we explore how the KL divergence of our approximation may change with respect to the staleness of the embeddings  g  superscript g  g^{\\prime} italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ,  We can obtain a significant reduction in KL divergence via the correction model (on the y-axis) across a wide variety of drifts (as measured by  KL  ( P  P g  ) KL conditional P subscript P superscript g  \\operatorname{KL}(P\\|P_{g^{\\prime}}) roman_KL ( italic_P  italic_P start_POSTSUBSCRIPT italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) ). Increasing parameter count is always effective, but it yields greater benefit when approximating a distribution with greater divergence.",
            "See  4.1    Proof . We bound the gap between true population risk and stale population risk.  Recall that  G l , F subscript G l F \\mathcal{G}_{\\ell,\\mathcal{F}} caligraphic_G start_POSTSUBSCRIPT roman_l , caligraphic_F end_POSTSUBSCRIPT  is the induced function class:  G l , F = { y  l  ( f  ( y ) , g  ( y ) ) : f  F } . subscript G l F conditional-set maps-to y l f y g y f F \\mathcal{G}_{\\ell,\\mathcal{F}}=\\{y\\mapsto\\ell(f(y),g(y)):f\\in\\mathcal{F}\\}. caligraphic_G start_POSTSUBSCRIPT roman_l , caligraphic_F end_POSTSUBSCRIPT = { italic_y  roman_l ( italic_f ( italic_y ) , italic_g ( italic_y ) ) : italic_f  caligraphic_F } .   Now note that",
            "See  4.2",
            "See  4.3",
            "In Table  4 , we report performance on MSMarco using T5-base as the encoder. Here, with fewer targets, Stochastic Negative Mining provides a better approximation as a larger fraction of targets is re-encoded. Our method is still able to nearly match the performance of the exhaustive approach. We are able to achieve such results without having to re-embed the buffer."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Comparison with 2-round training.  We compare the performance of corrector networks, exhaustive re-encoding, and 2-round training. Results are presented on the NQ Test set.",
        "table": "A2.T5.1",
        "footnotes": [],
        "references": [
            "Empirical  ( 5 ) -  We evaluate our approach in training both dense retrieval models and latent variable retrieval augmented language models. Our approach matches the performance of much more computationally intensive approaches at a fraction of the computational expense.",
            "We consider two loss functions for training  h h h italic_h : the mean-squared error between representations given by  g  ( y ) g y g(y) italic_g ( italic_y )  and the corrected representations  h  g   ( y ) h superscript g  y h\\circ g^{\\prime}(y) italic_h  italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_y )  (Eq.  5 ) and the cross entropy loss between the truncated softmax using  g  ( y ) g y g(y) italic_g ( italic_y )  and truncated softmax using  h  g   ( y ) h superscript g  y h\\circ g^{\\prime}(y) italic_h  italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_y )  (Eq.  6 ):",
            "Let  l : R  R  R : l  R R R \\ell:\\mathbb{R}\\times\\mathbb{R}\\to\\mathbb{R} roman_l : blackboard_R  blackboard_R  blackboard_R  is a loss function for the target corrector network (Eq.  5  &  6 ).",
            "We empirically explore some of these trade-offs in  5.3 .",
            "Several recent works such as  (Qu et al.,  2021 )  which addresses difficulties of training dense retrieval models proposes to train in 2 stages. First all targets are encoded (using random or pre-trained model). Then the model is trained for one half of the desired iterations. Then the new models parameters are used to re-encode the targets a single time. Then the model is trained for the remaining steps using these re-encoded targets. We compare this approch with corrector networks in Table  5 . We see that when using GTR-base, the performance for all methods is quite similar (with corrector networks and exhaustive re-encoding slightly outperforming). When T5-base is used though, we find the performance of corrector networks and exhaustive re-encoding to notably out-perform the 2-step procedure. We attribute this to GTR being a better initialization for the model. In this case we would expect its parameters (and therefore its target embeddings) to change less from pre-training to fine-tuning, meaning that there is less embedding drift and therefore less bias when using the 2-step procedure."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Uniform Negatives Comparison.  We compare the performance of exhaustive re-encoding with and without the addition of uniform (in-batch) negatives. Results are presented on the NQ Dev set.",
        "table": "A2.T6.1",
        "footnotes": [],
        "references": [
            "We consider two loss functions for training  h h h italic_h : the mean-squared error between representations given by  g  ( y ) g y g(y) italic_g ( italic_y )  and the corrected representations  h  g   ( y ) h superscript g  y h\\circ g^{\\prime}(y) italic_h  italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_y )  (Eq.  5 ) and the cross entropy loss between the truncated softmax using  g  ( y ) g y g(y) italic_g ( italic_y )  and truncated softmax using  h  g   ( y ) h superscript g  y h\\circ g^{\\prime}(y) italic_h  italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_y )  (Eq.  6 ):",
            "Let  l : R  R  R : l  R R R \\ell:\\mathbb{R}\\times\\mathbb{R}\\to\\mathbb{R} roman_l : blackboard_R  blackboard_R  blackboard_R  is a loss function for the target corrector network (Eq.  5  &  6 ).",
            "Combining results from Eq.  16 ,  A , and  23 , we obtain that with probability at least  1   1  1-\\delta 1 - italic_ ,",
            "In our main experiments (as stated in Appendix  B.1 ) we train with hard negatives  and  uniform negatives. Initial experiments showed that adding uniform negatives lead to improved performance in some settings. We provide some additional results ablating this choice using exhaustive re-encoding. These can be found in Table  6 . We can see that this choice provides negligible improvement on the reported benchmarks (although we believe its worth trying in other settings)."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Approximating Large Models with Small Models  On the dataset Arguana  (Wachsmuth et al.,  2018 ) , we use our method to warp the embedding space of GTR Small so that it is better aligned with GTR Large. Note that here we present nearest neighbor precision, i.e., the overlap in the top-K neighbors from the large model at 10, 20, and 100. We use 32 samples for each query to train the correction model.",
        "table": "A2.T7.2",
        "footnotes": [],
        "references": [
            "In this experiment, we focus on sampling in isolation. We sample a batch of input points and we measure the ability of our method to approximate one dual encoder model with another. In particular, we study a case where we approximate a large dual encoder with a small model. We approximate the GTR large model  (Ni et al.,  2021 )  (e.g.,  g  (  ) g  g(\\cdot) italic_g (  ) ) with the GTR small model(e.g.,  g   (  ) superscript g   g^{\\prime}(\\cdot) italic_g start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT (  ) ). In Table  7 , we report nearest neighbor precision, i.e., measuring the overlap in the top-K neighbors from the large models neighbors at 10, 20, and 100 on the dataset Arguana  (Wachsmuth et al.,  2018 )  from the BEIR benchmark  (Thakur et al.,  2021 ) . We use 32 samples for each query to train the correction model. We find that overlap amongst smaller K seems to be better aligned using our method."
        ]
    },
    "global_footnotes": [
        "Our JAX",
        "implementation run on Cloud TPUv3 re-embeds ~2184 targets per second on each core."
    ]
}