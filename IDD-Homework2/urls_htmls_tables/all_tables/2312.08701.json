{
    "PAPER'S NUMBER OF TABLES": 2,
    "S2.T2": {
        "caption": "Table 2: (a) Statistic of the datasets used in the biological aging prediction from ECG signal experiment. (b) Testing mean square error (MSE) of the biological aging prediction from ECG signal models. The average column computes the average MSE across two datasets, weighted by the number of testing samples.",
        "table": "<table id=\"S2.F2.sf1.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S2.F2.sf1.2.1.1\" class=\"ltx_tr\">\n<th id=\"S2.F2.sf1.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S2.F2.sf1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Client</span></th>\n<th id=\"S2.F2.sf1.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S2.F2.sf1.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Train</span></th>\n<th id=\"S2.F2.sf1.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S2.F2.sf1.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Val</span></th>\n<th id=\"S2.F2.sf1.2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S2.F2.sf1.2.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Test</span></th>\n<th id=\"S2.F2.sf1.2.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S2.F2.sf1.2.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Total</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S2.F2.sf1.2.2.1\" class=\"ltx_tr\">\n<th id=\"S2.F2.sf1.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">ANL</th>\n<td id=\"S2.F2.sf1.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">64518</td>\n<td id=\"S2.F2.sf1.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">7905</td>\n<td id=\"S2.F2.sf1.2.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7905</td>\n<td id=\"S2.F2.sf1.2.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">80328</td>\n</tr>\n<tr id=\"S2.F2.sf1.2.3.2\" class=\"ltx_tr\">\n<th id=\"S2.F2.sf1.2.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\">Broad</th>\n<td id=\"S2.F2.sf1.2.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b\">33140</td>\n<td id=\"S2.F2.sf1.2.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_b\">4143</td>\n<td id=\"S2.F2.sf1.2.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">4143</td>\n<td id=\"S2.F2.sf1.2.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_b\">41426</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Result - FL versus local training. All models are evaluated on the clients’ test set using the cross-site validation feature of APPFLx. We separately plot the ROC curves (Figure 2-left), confusion matrices (Figure 2-right), and compute the corresponding areas under the ROC curve (AUC), confidence interval (Table 2(d)) when testing them on the two datasets.\nWe compute the AUC as the main evaluation metric for discussion.\nOver the two datasets, we observe that while models trained on a single dataset (rows 1-2) achieve satisfactory performance when evaluating on test sets with the same distribution, the performance drops significantly on the test set of other sites (e.g., 0.80→0.56→0.800.560.80\\rightarrow 0.56 for the model trained on MIDRC dataset and 0.67→0.56→0.670.560.67\\rightarrow 0.56 for the model trained on UChicago). Meanwhile, the model trained in FL settings with combined MIDRC+UChicago dataset (row 3) can overcome this circumstance on single-dataset models, and provide a more stable performance. Notably, for the MIDRC dataset, the performance of the FL model (0.690.690.69) was significantly reduced in comparison to the local model (0.800.800.80). This result indicates joint training with the UChicago dataset with a large distribution gap can possibly downgrade the performance of FL model."
        ]
    },
    "S2.T3": {
        "caption": "Table 3: (a) Statistics of the datasets used in the COVID-19 chest X-ray image recognition experiment. Numbers in the parentheses indicate the number of positive (+)(+) and negative (−)(-) samples. (b) AUC score of the COVID-19 chest X-ray image recognition models. Statistical significant comparisons within a testing population are bold.",
        "table": "<table id=\"S2.F2.sf3.2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S2.F2.sf3.2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S2.F2.sf3.2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S2.F2.sf3.2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Client</span></th>\n<th id=\"S2.F2.sf3.2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S2.F2.sf3.2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Train</span></th>\n<th id=\"S2.F2.sf3.2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S2.F2.sf3.2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Val</span></th>\n<th id=\"S2.F2.sf3.2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S2.F2.sf3.2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Test</span></th>\n<th id=\"S2.F2.sf3.2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S2.F2.sf3.2.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Total</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S2.F2.sf3.2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S2.F2.sf3.2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">MIDRC</td>\n<td id=\"S2.F2.sf3.2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">9867 (4226+/5641-)</td>\n<td id=\"S2.F2.sf3.2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">2056 (925+/1131-)</td>\n<td id=\"S2.F2.sf3.2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2081 (932+/1149-)</td>\n<td id=\"S2.F2.sf3.2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">14004</td>\n</tr>\n<tr id=\"S2.F2.sf3.2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S2.F2.sf3.2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">UChicago</td>\n<td id=\"S2.F2.sf3.2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b\">26047 (4226+/23226-)</td>\n<td id=\"S2.F2.sf3.2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_b\">5569 (587+/4982-)</td>\n<td id=\"S2.F2.sf3.2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">5619 (637+/4982-)</td>\n<td id=\"S2.F2.sf3.2.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_b\">37235</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Task Description.",
                "\nOne of the most widespread implementations of Artificial Intelligence (AI) techniques for data that may require increased security or privacy is medical imaging. However, allowing for open-source access to medical images can be cumbersome, particularly considering privacy concerns related to attack models and potentially inconsistent or ineffective data de-identification requirements across different local sites (e.g., face shearing technology). The COVID-19 pandemic served as a prime example of a clinical use case for ",
                "APPFLx",
                " implementation; many institutions were interested in contributing to aggregated datasets for use in developing medical imaging-based AI models for COVID-19 detection, differential disease diagnosis, and other radiological tasks. Despite good intentions, several complications arose through “Frankenstein” datasets, biased algorithms, and extensive time to open source ",
                "driggs2021_pitfallsCovid ",
                ". Many of these obstacles could have been alleviated if a privacy-preserving FL system were available. Thus, we consider COVID-19 detection on chest x-ray images (CXR) as a clinical use case to evaluate our proposed system. Clinically, the most common methods of COVID-19 detection are non-imaging exams (e.g., antigen or RT-PCR exams), however, imaging could play a role in differential disease detection upon image acquisition in the future when non-imaging tests are less readily available or no longer standard practice.",
                "Datasets and FL Sites. ",
                " We set up a two-site training for this case study.\nThe first site hosts the publicly available CXR dataset from the Medical Imaging and Data Resource Center ",
                "(MIDRC)",
                ".\nInitiated in 2020 to combat the pandemic, MIDRC is a multi-institutional collaborative initiative in medical imaging through data sharing. This comprehensive dataset contains digital radiograph images, COVID test results, and demographic information collected from multiple hospitals.\nThe second one holds a private dataset that was collected at the University of Chicago ",
                "(UChicago)",
                ".\nThe UChicago dataset is collected as part of the University of Chicago Center for Research Informatics (CRI) COVID-19 Datamart in conjunction with the Human Imaging ResearchOffice (HIRO).\nThe two datasets’ train-test splitting scheme, statistics, and the number of positive and negative samples used in this experiment are reported in ",
                "Table ",
                "2(c)",
                ".",
                "Classification Model and FL Setup. ",
                " This case study demonstrates a simple transfer learning approach to CXR data. We fine-tune a ResNet18 ",
                "he2016residual ",
                " model pre-trained on ImageNet ",
                "deng2009imagenet ",
                ". The last softmax layer is modified to match the binary classification task (i.e., COVID-19 positive and negative).\nFurther, other recent publications have investigated the relevance of ",
                "personalized FL",
                " ",
                "zying2022_personalized ",
                "; ",
                "viraj2020_survey ",
                ", or the development/improvement of FL models for performance at individual clients. We incorporate personalized FL in this study through additional local ",
                "fine tuning",
                " on a small subset of labeled data (here, we conveniently adopt the validation set) at both the MIDRC and UChicago clients for an additional 40 epochs. Noteworthy, for this fine-tuning step, only the trainable parameters of the batch normalization layers ",
                "sergey2015_batchnorm ",
                " are updated. This adjustment specifically targets the sensitivity of these layers to local data statistics. Similar strategies have been implemented in other domain adaptation approaches ",
                "li2017revisiting ",
                "; ",
                "wang2021tent ",
                ".",
                "Using ",
                "APPFLx",
                ", we establish the federation across multiple institutes. For simplicity, we adopt the common FedAvg ",
                "pmlr-v54-mcmahan17a ",
                " algorithm for the global aggregation. Two Globus Compute endpoints are installed at UChicago while the global server is hosted at UIUC. The clients securely store their dataset, and only reveal the data loaders to the server. Once the federation is created, the server can automatically facilitate the training and cross-site evaluation process. During training, each client performs two local updates before being integrated into the global model. We repeat this process for a total of 40 global FL aggregation rounds. For hardware requirements, the center server only requires a CPU machine, while most of the heavy-computing tasks are performed locally on two GPU clusters of the University of Chicago (HPE Superdome Flex NUMA computation server with 2 NVIDIA Tesla V100 32GB GPUs).",
                "Result - FL versus local training.",
                " All models are evaluated on the clients’ test set using the cross-site validation feature of ",
                "APPFLx",
                ". We separately plot the ROC curves (",
                "Figure",
                " ",
                "2",
                "-left), confusion matrices (",
                "Figure",
                " ",
                "2",
                "-right), and compute the corresponding areas under the ROC curve (AUC), confidence interval (",
                "Table",
                " ",
                "2(d)",
                ") when testing them on the two datasets.\nWe compute the AUC as the main evaluation metric for discussion.\nOver the two datasets, we observe that while models trained on a single dataset (rows 1-2) achieve satisfactory performance when evaluating on test sets with the same distribution, the performance",
                " drops significantly on the test set of other sites",
                " (e.g., ",
                "0.80",
                "→",
                "0.56",
                "→",
                "0.80",
                "0.56",
                "0.80\\rightarrow 0.56",
                " for the model trained on MIDRC dataset and ",
                "0.67",
                "→",
                "0.56",
                "→",
                "0.67",
                "0.56",
                "0.67\\rightarrow 0.56",
                " for the model trained on UChicago). Meanwhile, the model trained in FL settings with combined MIDRC+UChicago dataset (row 3) can overcome this circumstance on single-dataset models, and provide a more stable performance. Notably, for the MIDRC dataset, the performance of the FL model (",
                "0.69",
                "0.69",
                "0.69",
                ") was significantly reduced in comparison to the local model (",
                "0.80",
                "0.80",
                "0.80",
                "). This result indicates joint training with the UChicago dataset with a large distribution gap can possibly downgrade the performance of FL model.",
                "However, our investigation of ",
                "fine tuning ",
                "for personalized FL through ",
                "APPFLx",
                " (row 4) demonstrated ",
                "superior performance",
                ", achieving comparable performance to the locally-trained MIDRC model and significantly outperforming the local UChicago model. This suggests that the baseline model provided by the FL algorithm serves as a better foundation than the original ImageNet-trained ",
                "deng2009imagenet ",
                "; ",
                "he2016residual ",
                " model for addressing our task of COVID-19 detection. This has potential practical implications in how FL is deployed, particularly in scenarios with differing data distributions across FL clients as in our case study; specifically, in such scenarios when a single model cannot effectively achieve high performance simultaneously across clients, personalized FL as deployed in our ",
                "APPFLx",
                " scheme could play a significant role in the development of improved models."
            ]
        ]
    }
}