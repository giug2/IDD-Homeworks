{
    "S4.T1": {
        "caption": "Table 1: Performance for supervised and unsupervised adaptation methods. We report the averaged accuracy over 600 tasks (supervised adaptation)/all meta-testing users (unsupervised adaptation).",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_tt\" colspan=\"5\">Supervised Adaptation</td>\n<td id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\">Unsupervised Adaptation</td>\n</tr>\n<tr id=\"S4.T1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Data</td>\n<td id=\"S4.T1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\" colspan=\"2\">Amazon Review</td>\n<td id=\"S4.T1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_rr\" colspan=\"2\">Huffpost</td>\n<td id=\"S4.T1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Data</td>\n<td id=\"S4.T1.1.2.5\" class=\"ltx_td ltx_align_center\" colspan=\"2\">Twitter</td>\n</tr>\n<tr id=\"S4.T1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Shot</td>\n<td id=\"S4.T1.1.3.2\" class=\"ltx_td ltx_align_center\">1-shot</td>\n<td id=\"S4.T1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">5-shot</td>\n<td id=\"S4.T1.1.3.4\" class=\"ltx_td ltx_align_center\">1-shot</td>\n<td id=\"S4.T1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_rr\">5-shot</td>\n<td id=\"S4.T1.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r\">User Ratio</td>\n<td id=\"S4.T1.1.3.7\" class=\"ltx_td ltx_align_center\">0.6</td>\n<td id=\"S4.T1.1.3.8\" class=\"ltx_td ltx_align_center\">1.0</td>\n</tr>\n<tr id=\"S4.T1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">MAML</td>\n<td id=\"S4.T1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">44.35%</td>\n<td id=\"S4.T1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">56.94%</td>\n<td id=\"S4.T1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">39.95%</td>\n<td id=\"S4.T1.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\">51.74%</td>\n<td id=\"S4.T1.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ERM</td>\n<td id=\"S4.T1.1.4.7\" class=\"ltx_td ltx_align_center ltx_border_t\">62.91%</td>\n<td id=\"S4.T1.1.4.8\" class=\"ltx_td ltx_align_center ltx_border_t\">66.05%</td>\n</tr>\n<tr id=\"S4.T1.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">ProtoNet</td>\n<td id=\"S4.T1.1.5.2\" class=\"ltx_td ltx_align_center\">55.32%</td>\n<td id=\"S4.T1.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">73.30%</td>\n<td id=\"S4.T1.1.5.4\" class=\"ltx_td ltx_align_center\">41.72%</td>\n<td id=\"S4.T1.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_rr\">57.53%</td>\n<td id=\"S4.T1.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r\">UW</td>\n<td id=\"S4.T1.1.5.7\" class=\"ltx_td ltx_align_center\">63.51%</td>\n<td id=\"S4.T1.1.5.8\" class=\"ltx_td ltx_align_center\">64.13%</td>\n</tr>\n<tr id=\"S4.T1.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">InductNet</td>\n<td id=\"S4.T1.1.6.2\" class=\"ltx_td ltx_align_center\">45.35%</td>\n<td id=\"S4.T1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">56.73%</td>\n<td id=\"S4.T1.1.6.4\" class=\"ltx_td ltx_align_center\">41.35%</td>\n<td id=\"S4.T1.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_rr\">55.96%</td>\n<td id=\"S4.T1.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r\">ARM</td>\n<td id=\"S4.T1.1.6.7\" class=\"ltx_td ltx_align_center\">60.42%</td>\n<td id=\"S4.T1.1.6.8\" class=\"ltx_td ltx_align_center\">60.42%</td>\n</tr>\n<tr id=\"S4.T1.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">MatchingNet</td>\n<td id=\"S4.T1.1.7.2\" class=\"ltx_td ltx_align_center\">51.16%</td>\n<td id=\"S4.T1.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">69.89%</td>\n<td id=\"S4.T1.1.7.4\" class=\"ltx_td ltx_align_center\">41.18%</td>\n<td id=\"S4.T1.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_rr\">54.41%</td>\n<td id=\"S4.T1.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_r\">DRNN</td>\n<td id=\"S4.T1.1.7.7\" class=\"ltx_td ltx_align_center\">63.02%</td>\n<td id=\"S4.T1.1.7.8\" class=\"ltx_td ltx_align_center\">64.02%</td>\n</tr>\n<tr id=\"S4.T1.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\">REGRAB</td>\n<td id=\"S4.T1.1.8.2\" class=\"ltx_td ltx_align_center\">55.07%</td>\n<td id=\"S4.T1.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_r\">72.53%</td>\n<td id=\"S4.T1.1.8.4\" class=\"ltx_td ltx_align_center\">42.17%</td>\n<td id=\"S4.T1.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_rr\">57.66%</td>\n<td id=\"S4.T1.1.8.6\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S4.T1.1.8.7\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T1.1.8.8\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T1.1.9\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.9.1.1\" class=\"ltx_text ltx_font_bold\">KGML-MAML</span></td>\n<td id=\"S4.T1.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\">51.44%</td>\n<td id=\"S4.T1.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">58.81%</td>\n<td id=\"S4.T1.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.9.4.1\" class=\"ltx_text ltx_font_bold\">44.29%</span></td>\n<td id=\"S4.T1.1.9.5\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\">54.16%</td>\n<td id=\"S4.T1.1.9.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.9.6.1\" class=\"ltx_text ltx_font_bold\">KGML</span></td>\n<td id=\"S4.T1.1.9.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.9.7.1\" class=\"ltx_text ltx_font_bold\">64.92%</span></td>\n<td id=\"S4.T1.1.9.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.9.8.1\" class=\"ltx_text ltx_font_bold\">67.00%</span></td>\n</tr>\n<tr id=\"S4.T1.1.10\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T1.1.10.1.1\" class=\"ltx_text ltx_font_bold\">KGML-ProtoNet</span></td>\n<td id=\"S4.T1.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.10.2.1\" class=\"ltx_text ltx_font_bold\">58.62%</span></td>\n<td id=\"S4.T1.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T1.1.10.3.1\" class=\"ltx_text ltx_font_bold\">74.55%</span></td>\n<td id=\"S4.T1.1.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">42.37%</td>\n<td id=\"S4.T1.1.10.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_rr\"><span id=\"S4.T1.1.10.5.1\" class=\"ltx_text ltx_font_bold\">58.75%</span></td>\n<td id=\"S4.T1.1.10.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">-</td>\n<td id=\"S4.T1.1.10.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">-</td>\n<td id=\"S4.T1.1.10.8\" class=\"ltx_td ltx_align_center ltx_border_bb\">-</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "The overall performance of all baselines and KGML are reported in Table¬†1. The results indicate that KGML achieves the best performance in all scenarios by using knowledge bases to bridge the gap between the meta-training and meta-testing tasks. Additionally, under the supervised adaptation scenario, the improvements of Amazon Review are larger than that in Huffpost under the 1-shot setting, indicating that the former has a larger gap between meta-training and meta-testing tasks. One potential reason is that the number of entities of Amazon review is more than Huffpost headlines, resulting in more comprehensive knowledge graphs. Another interesting finding is that ARM hurts the performance under the unsupervised adaptation. However, with the help of the knowledge graph, KGML achieves the best performance, corroborating its effectiveness in learning more transferable representations and further enabling efficient unsupervised adaptation."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Ablation study (1-shot scenario). Backbone: base meta-learning algorithm",
        "table": "<table id=\"S4.T2.1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T2.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">Ablations</td>\n<td id=\"S4.T2.1.1.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">Backbone</td>\n<td id=\"S4.T2.1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">Amazon</td>\n<td id=\"S4.T2.1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">Huffpost</td>\n</tr>\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\" rowspan=\"2\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text\">I. Remove <math id=\"S4.T2.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathrm{AGG}_{kf}\" display=\"inline\"><semantics id=\"S4.T2.1.1.1.1.1.m1.1a\"><msub id=\"S4.T2.1.1.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T2.1.1.1.1.1.m1.1.1.2\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.2.cmml\">AGG</mi><mrow id=\"S4.T2.1.1.1.1.1.m1.1.1.3\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.3.cmml\"><mi id=\"S4.T2.1.1.1.1.1.m1.1.1.3.2\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.3.2.cmml\">k</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T2.1.1.1.1.1.m1.1.1.3.1\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.3.1.cmml\">‚Äã</mo><mi id=\"S4.T2.1.1.1.1.1.m1.1.1.3.3\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.3.3.cmml\">f</mi></mrow></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.1.1.m1.1b\"><apply id=\"S4.T2.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T2.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T2.1.1.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T2.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.2\">AGG</ci><apply id=\"S4.T2.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.3\"><times id=\"S4.T2.1.1.1.1.1.m1.1.1.3.1.cmml\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.3.1\"/><ci id=\"S4.T2.1.1.1.1.1.m1.1.1.3.2.cmml\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.3.2\">ùëò</ci><ci id=\"S4.T2.1.1.1.1.1.m1.1.1.3.3.cmml\" xref=\"S4.T2.1.1.1.1.1.m1.1.1.3.3\">ùëì</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.1.1.m1.1c\">\\mathrm{AGG}_{kf}</annotation></semantics></math></span></td>\n<td id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">MAML</td>\n<td id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">45.68%</td>\n<td id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">41.55%</td>\n</tr>\n<tr id=\"S4.T2.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">ProtoNet</td>\n<td id=\"S4.T2.1.1.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">57.94%</td>\n<td id=\"S4.T2.1.1.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">41.71%</td>\n</tr>\n<tr id=\"S4.T2.1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\" rowspan=\"2\"><span id=\"S4.T2.1.1.4.1.1\" class=\"ltx_text\">II. Remove KNN</span></td>\n<td id=\"S4.T2.1.1.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">MAML</td>\n<td id=\"S4.T2.1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">51.07%</td>\n<td id=\"S4.T2.1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">41.20%</td>\n</tr>\n<tr id=\"S4.T2.1.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">ProtoNet</td>\n<td id=\"S4.T2.1.1.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">57.80%</td>\n<td id=\"S4.T2.1.1.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">41.91%</td>\n</tr>\n<tr id=\"S4.T2.1.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.6.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">KGML</td>\n<td id=\"S4.T2.1.1.6.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">MAML</td>\n<td id=\"S4.T2.1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">51.44%</td>\n<td id=\"S4.T2.1.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span id=\"S4.T2.1.1.6.4.1\" class=\"ltx_text ltx_font_bold\">44.29%</span></td>\n</tr>\n<tr id=\"S4.T2.1.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">KGML</td>\n<td id=\"S4.T2.1.1.7.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">ProtoNet</td>\n<td id=\"S4.T2.1.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.8pt;padding-right:4.8pt;\"><span id=\"S4.T2.1.1.7.3.1\" class=\"ltx_text ltx_font_bold\">58.62%</span></td>\n<td id=\"S4.T2.1.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">42.37%</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "We conduct ablation studies to investigate the contribution of each component in KGML. Two ablation models are proposed: I. replacing the aggregator AGGk‚ÄãfsubscriptAGGùëòùëì\\mathrm{AGG}_{kf} with a simple feature concatenator; II. removing extra edges in KG, which are introduced by k-nearest neighbor graph. The performance of each ablation model and the KGML of Amazon and Huffpost are reported in Table¬†2. We observe that (1) KGML outperforms model I, demonstrating the effectiveness of the designed aggregator; (2) Comparing between KGML with model II, the results show that KNN boosts performance. One potential reason is that KNN densifies the whole network according to the entities‚Äô semantic embeddings learned from the original WordNet, which explicitly enriches the semantic information of the neighbor set of each entity. It further benefits the representation learning process and improves the performance."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Results of meta-training time per task.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">Model</td>\n<td id=\"S4.T3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">Supervised (MAML)</td>\n<td id=\"S4.T3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">Unsupervised</td>\n</tr>\n<tr id=\"S4.T3.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">w/o KG</td>\n<td id=\"S4.T3.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">0.297s</td>\n<td id=\"S4.T3.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">0.146s</td>\n</tr>\n<tr id=\"S4.T3.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">with KG</td>\n<td id=\"S4.T3.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">0.407s</td>\n<td id=\"S4.T3.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.8pt;padding-right:4.8pt;\">0.181s</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "We further conduct the analysis of computational complexity and reported the meta-training time per task in Table¬†3, where the results of supervised adaptation are performed under the setting of Huffpost 5-shot.\nThough KGML increases the meta-training time to some extent, the who training process can be finished within 1-2 hours. Thus, the additional computational cost seems to be a reasonable trade-off for accuracy."
        ]
    }
}