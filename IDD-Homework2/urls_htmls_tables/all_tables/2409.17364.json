{
    "id_table_1": {
        "caption": "Table 1:  Training dataset detailed overview.",
        "table": "S3.T1.1.1",
        "footnotes": [],
        "references": [
            "We explore the use of synthetic data to aid in cross-speaker style transfer in a TTS model with a style encoder. Initially, we train a voice conversion model on neutral data and convert the expressive speech of the source speaker to all target speakers. Next, we use a two-stage approach for training the TTS model (Figure  1 ). In the first stage, we pre-train the style encoder, and in the second stage, we train the TTS using the pre-trained, frozen style encoder. In all stages, the original data is used with or without the addition of synthetic data. To explore the use of synthetic data, we conduct three experiments:",
            "We performed the experiments on an internal Brazilian Portuguese dataset. The dataset consists of three speakers, coded as PTBR 1 (female), PTBR 2 (male), and PTBR 3 (female), as shown in Table  1 . Speaker PTBR 1 has three highly expressive styles of speech in addition to neutral: lively, welcoming, and harsh. Speakers PTBR 2 and 3 only have neutral recordings."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Naturalness MOS with 95% confidence intervals.",
        "table": "S4.T2.5",
        "footnotes": [],
        "references": [
            "We report the overall naturalness MOS results in Table  2 . The results indicate that synthetic data generated by voice conversion (VC) exhibit higher naturalness than those from cross-speaker style transfer experiments. Consequently, both the Synth TTS and Synth both experiments, which incorporate synthetic data during training, show increased naturalness compared to Synth None, with Synth both demonstrating the highest improvement.",
            "Although using only original expressive data appears to yield higher style intensity perception in synthetic speech, it results in lower naturalness and speaker similarity. Employing synthetic data generated by a Voice Conversion (VC) model improved both naturalness and speaker similarity. However, the effectiveness of style transfer in TTS for highly expressive styles is sensitive to the quality of the VC for each style. Also, training stage 1 with both synthetic and ground truth data generates a more meaningful representations as shown in Figure  2 ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Style Intensity (SI-MOS) and Naturalness (N-MOS) Mean Opinion Scores with 95% confidence intervals.",
        "table": "S4.T3.30",
        "footnotes": [],
        "references": [
            "However, we note that for style intensity, the Synth none configuration performed better in two out of three expressive styles in the dataset, despite having lower naturalness in each case (Table  3 )."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Speaker Similarity MOS 95% confidence intervals.",
        "table": "S4.T4.3",
        "footnotes": [],
        "references": [
            "Regarding speaker similarity (Table  4 ), we observe that Synth TTS mostly preserves the similarity of timbre in cross-speaker scenarios, with Synth both following closely. However, Synth none performs worse in this aspect."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Cross-language objective metrics.",
        "table": "S4.T5.3",
        "footnotes": [],
        "references": [
            "Analyzing the effect of using synthetic data in a more content-dependent cross-speaker transfer, we performed the same experiments to transfer accents for our three PTBR speakers to two languages: English and Spanish. We report the objective metrics in Table  5 ."
        ]
    }
}