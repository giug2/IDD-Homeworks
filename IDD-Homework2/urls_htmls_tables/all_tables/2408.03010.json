{
    "id_table_1": {
        "caption": "Table 1:  Results for the graph retrieval evaluation (metrics in %). IoU stands for intersection over union and EE for Entity Enhancement, see  Section   4.1 .",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": [
            "In this paper, we present FactFinder - a hybrid question answering (QA) system - which leverages both KG and LLM to provide answers to scientific questions. Fig.  1  depicts the systems architecture, which is structured as a pipeline with several subcomponents.  Our main contributions are:",
            "Knowledge graph.   We use PrimeKG  Chandak et al. ( 2023 )  as our source of fact-based background knowledge. PrimeKG integrates 20 high-quality resources to describe 17,080 diseases with 4,050,249 relationships, including over 100,000 nodes and 29 types of edges that densely connect disease nodes with drugs, genes, exposures, and phenotypes.  We preprocess the graph data by mapping names to their preferred terms, as described in  Section   3.1 , and converting all entries to lowercase.",
            "With the advent of LLMs, however, QA systems can now understand domain-specific questions and generate valid queries directly, allowing for more flexible approaches.  Much of the research has been centered on text-to-SQL generation, where LLMs have demonstrated considerable effectiveness  Gao et al. ( 2023 ); Chang and Fosler-Lussier ( 2023 ) , including in the medical domain  Ziletti and DAmbrosi ( 2024 ) , and have often performed better than specialized models  Pourreza and Rafiei ( 2023 ) .  Conversely, the area of text-to-Cypher query generation remains relatively under-explored, with prior research primarily focused on sequence-to-sequence models  Zhao et al. ( 2024 ); Guo et al. ( 2022 ) . Only recently has the application of LLMs to this task begun to emerge  Feng et al. ( 2023 ) .  To bridge this gap, our work evaluates the capabilities of LLMs to produce Cypher queries for scientific QA in the medical domain (see Sec.  4.1 ).",
            "We include an entity extraction model to align entity names in questions with those in the KG, based on Linnaeus  Gerner et al. ( 2010 )  and developed set of vocabularies for entity types. This step ensures consistency by replacing detected entities with their preferred KG terms (e.g.,  alcohol  to  ethanol ) and generating sentences linking each entity to its category (see Fig.  1  left), reducing the LLMs reliance on domain-specific knowledge.",
            "To quantify the graph retrieval step, we assess the returned nodes from graph queries by comparing result nodes from executing the ground truth queries with those from the generated queries. This enables a quantitative evaluation of the text-to-Cypher step. We use the ground truth text-to-Cypher dataset described in Sec.  2  for this evaluation. We compute intersection over union (IoU), precision, and recall for the expected and generated graph result sets, as shown in Table  1 .",
            "The results indicate strong performance, with the best model exceeding 75%. GPT-4o outperforms GPT-4-Turbo overall. Entity Enhancement (EE, Fig.  1  left and Sec.  3.1 ) improves GPT-4-Turbos performance but slightly decreases GPT-4os effectiveness. Manual analysis revealed that PrimeKGs merging of genes and proteins into a single node can mislead GPT-4o when EE is applied, directing it towards incorrect relations. GPT-4os internal knowledge allows it to infer relationships more accurately without EE, while GPT-4-Turbo benefits from the additional clarity provided by EE.  This suggests that LLMs internal knowledge can be beneficial for Cypher query generation.",
            "Hybrid system vs. LLM-only.   We compare the hybrid KG-based system against a standalone LLM. The hybrid system (GPT-4o without entity enhancement, Sec.  4.1 ) is evaluated to produce more correct (complete) answers in 94.12% (96.08%) of cases, demonstrating its superior performance in providing accurate and complete responses."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Handling irrelevant information in graph responses.",
        "table": "S4.T2.1",
        "footnotes": [],
        "references": [
            "Subgraph Visualization.  To enhance interpretability, we provide a subgraph as part of the evidence. This subgraph visually displays (via Pyvis 5 5 5 https://pyvis.readthedocs.io/ ) the relevant nodes and edges, illustrating the subset of the main graph that contributed to the specific answer, as shown in Fig.  2 .",
            "To quantify the graph retrieval step, we assess the returned nodes from graph queries by comparing result nodes from executing the ground truth queries with those from the generated queries. This enables a quantitative evaluation of the text-to-Cypher step. We use the ground truth text-to-Cypher dataset described in Sec.  2  for this evaluation. We compute intersection over union (IoU), precision, and recall for the expected and generated graph result sets, as shown in Table  1 .",
            "The results in Table  2  show that both GPT-4-turbo and GPT-4-o can detect irrelevant information and correctly respond with \"I dont know\" in over 90% of cases, demonstrating that the LLMs can reason and understand when the knowledge passed to them is not relevant. This highlights FactFinders ability to enhance reliability by leveraging both structured and world knowledge."
        ]
    },
    "global_footnotes": []
}