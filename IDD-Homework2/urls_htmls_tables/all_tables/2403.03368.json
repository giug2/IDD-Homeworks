{
    "PAPER'S NUMBER OF TABLES": 1,
    "S3.T1": {
        "caption": "Table I: AUCs of ML architectures in centralized training scenario.",
        "table": "<table id=\"S3.T1.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S3.T1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Architecture</td>\n<td id=\"S3.T1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">AUC</td>\n</tr>\n<tr id=\"S3.T1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">FCN</td>\n<td id=\"S3.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.793</td>\n</tr>\n<tr id=\"S3.T1.2.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">GRU</td>\n<td id=\"S3.T1.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">0.957</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We primarily used two neural network architectures; fully connected network (FCN) and gated recurrent unit (GRU). While we applied a multi-hot encoder for FCN, we flattened the codes of the visits and concatenated them across all visits so that a patient has a sentence-like sequence of codes that can be fed into GRU. Table I shows the AUC values of each ML architecture in the conventional centralized training scenario. The results shows that the recurrent architecture outperforms the fully connected architecture. This performance advantage can be attributed to the GRU’s ability to capture and model the evolving dynamics and temporal dependencies inherent in patients’ medical histories, a capability that the FCN, relying on a bag-of-words approach, does not possess."
        ]
    }
}