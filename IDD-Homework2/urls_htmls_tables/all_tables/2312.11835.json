{
    "PAPER'S NUMBER OF TABLES": 2,
    "Sx5.T1": {
        "caption": "Table 1: Experimental setting in distributed robust hyperparameter optimization and distributed\ndomain adaptation.",
        "table": "<table id=\"Sx5.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"Sx5.T1.3.3\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding:0.5pt 0.0pt;\"></th>\n<th id=\"Sx5.T1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding:0.5pt 0.0pt;\"><math id=\"Sx5.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"N\" display=\"inline\"><semantics id=\"Sx5.T1.1.1.1.m1.1a\"><mi id=\"Sx5.T1.1.1.1.m1.1.1\" xref=\"Sx5.T1.1.1.1.m1.1.1.cmml\">N</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx5.T1.1.1.1.m1.1b\"><ci id=\"Sx5.T1.1.1.1.m1.1.1.cmml\" xref=\"Sx5.T1.1.1.1.m1.1.1\">𝑁</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx5.T1.1.1.1.m1.1c\">N</annotation></semantics></math></th>\n<th id=\"Sx5.T1.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding:0.5pt 0.0pt;\"><math id=\"Sx5.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"S\" display=\"inline\"><semantics id=\"Sx5.T1.2.2.2.m1.1a\"><mi id=\"Sx5.T1.2.2.2.m1.1.1\" xref=\"Sx5.T1.2.2.2.m1.1.1.cmml\">S</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx5.T1.2.2.2.m1.1b\"><ci id=\"Sx5.T1.2.2.2.m1.1.1.cmml\" xref=\"Sx5.T1.2.2.2.m1.1.1\">𝑆</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx5.T1.2.2.2.m1.1c\">S</annotation></semantics></math></th>\n<th id=\"Sx5.T1.3.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding:0.5pt 0.0pt;\">Stragglers</th>\n<th id=\"Sx5.T1.3.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding:0.5pt 0.0pt;\"><math id=\"Sx5.T1.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\tau\" display=\"inline\"><semantics id=\"Sx5.T1.3.3.3.m1.1a\"><mi id=\"Sx5.T1.3.3.3.m1.1.1\" xref=\"Sx5.T1.3.3.3.m1.1.1.cmml\">τ</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx5.T1.3.3.3.m1.1b\"><ci id=\"Sx5.T1.3.3.3.m1.1.1.cmml\" xref=\"Sx5.T1.3.3.3.m1.1.1\">𝜏</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx5.T1.3.3.3.m1.1c\">\\tau</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx5.T1.3.4.1\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.4.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding:0.5pt 0.0pt;\">Diabetes</th>\n<td id=\"Sx5.T1.3.4.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 0.0pt;\">4</td>\n<td id=\"Sx5.T1.3.4.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 0.0pt;\">3</td>\n<td id=\"Sx5.T1.3.4.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 0.0pt;\">1</td>\n<td id=\"Sx5.T1.3.4.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding:0.5pt 0.0pt;\">10</td>\n</tr>\n<tr id=\"Sx5.T1.3.5.2\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.5.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">Boston</th>\n<td id=\"Sx5.T1.3.5.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">4</td>\n<td id=\"Sx5.T1.3.5.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">3</td>\n<td id=\"Sx5.T1.3.5.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">1</td>\n<td id=\"Sx5.T1.3.5.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 0.0pt;\">10</td>\n</tr>\n<tr id=\"Sx5.T1.3.6.3\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.6.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">Red-wine</th>\n<td id=\"Sx5.T1.3.6.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">4</td>\n<td id=\"Sx5.T1.3.6.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">3</td>\n<td id=\"Sx5.T1.3.6.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">1</td>\n<td id=\"Sx5.T1.3.6.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 0.0pt;\">10</td>\n</tr>\n<tr id=\"Sx5.T1.3.7.4\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.7.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">White-wine</th>\n<td id=\"Sx5.T1.3.7.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">6</td>\n<td id=\"Sx5.T1.3.7.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">4</td>\n<td id=\"Sx5.T1.3.7.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">1</td>\n<td id=\"Sx5.T1.3.7.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 0.0pt;\">10</td>\n</tr>\n<tr id=\"Sx5.T1.3.8.5\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.8.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">SVHN (finetune)</th>\n<td id=\"Sx5.T1.3.8.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">4</td>\n<td id=\"Sx5.T1.3.8.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">3</td>\n<td id=\"Sx5.T1.3.8.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">1</td>\n<td id=\"Sx5.T1.3.8.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 0.0pt;\">5</td>\n</tr>\n<tr id=\"Sx5.T1.3.9.6\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.9.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">SVHN (pretrain)</th>\n<td id=\"Sx5.T1.3.9.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">6</td>\n<td id=\"Sx5.T1.3.9.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">3</td>\n<td id=\"Sx5.T1.3.9.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">2</td>\n<td id=\"Sx5.T1.3.9.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding:0.5pt 0.0pt;\">15</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In the experiment, two distributed trilevel optimization tasks are employed to assess the performance of the proposed method. In the distributed robust hyperparameter optimization, experiments are carried out on the regression tasks following (Sato, Tanaka, and Takeda 2021), and in distributed domain adaptation for pretraining &\\& finetuning, the multiple domain digits recognition task in (Qian et al. 2019; Wang et al. 2021) is considered. The details of the experimental setting are summarized in Table 1 and Appendix H. More experimental results are reported in Appendix G. To further show the superior performance of the proposed method, experimental results of comparisons between the non-distributed version of the proposed method with existing state-of-the-art TLO methods (Sato, Tanaka, and Takeda 2021; Choe et al. 2022) on three TLO tasks are shown in Appendix A in the supplementary material.",
            "where 𝝋𝝋{\\boldsymbol{\\varphi}}, 𝒘𝒘{\\boldsymbol{w}} and 𝒑𝒑{\\boldsymbol{p}} respectively denote the regularization parameter, model parameter, and adversarial noise, 𝒑′=[p1′,⋯,pN′]superscript𝒑′superscriptsubscript𝑝1′⋯superscriptsubscript𝑝𝑁′{\\boldsymbol{p}}^{\\prime}=[p_{1}^{\\prime},\\cdots,p_{N}^{\\prime}], N𝑁N is the number of workers. f𝑓f denotes the output of a MLP, c𝑐c denotes the penalty for the adversarial noise, and ||⋅||1⁣∗||\\cdot||_{1*} is a smoothed l1subscript𝑙1l_{1}-norm (Saheya, Nguyen, and Chen 2019). Xjval,yjval,|Djval|subscriptsuperscript𝑋val𝑗subscriptsuperscript𝑦val𝑗subscriptsuperscript𝐷val𝑗X^{\\rm{val}}_{j},y^{\\rm{val}}_{j},{|D^{\\rm{val}}_{j}|}, Xjtr,yjtr,|Djtr|subscriptsuperscript𝑋tr𝑗subscriptsuperscript𝑦tr𝑗subscriptsuperscript𝐷tr𝑗X^{\\rm{tr}}_{j},y^{\\rm{tr}}_{j},{|D^{\\rm{tr}}_{j}|} respectively denote the data, label and the number of data of the validation and training datasets on local worker j𝑗j. Following (Sato, Tanaka, and Takeda 2021), the experiments are carried out on the regression tasks with the following\ndatasets: Diabetes (Dua, Graff et al. 2017), Boston (Harrison Jr and Rubinfeld 1978), Red-wine and White-wine quality (Cortez et al. 2009) datasets. We summarize the experimental setting on each dataset in Table 1. To show the performance of the proposed AFTO, we report the mean squared error (MSE) of clean test data and test data with Gaussian noise vs running time of the AFTO and SFTO (Synchronous Federated Trilevel Optimization) in Figure 1. It is seen that the proposed AFTO can effectively solve the TLO problem in a distributed manner and converges much faster than SFTO since the master can update its variables once it receives updates from a subset of workers instead of all workers in AFTO. Furthermore, we compare the proposed method with the state-of-the-art distributed bilevel optimization methods ADBO (Jiao et al. 2022b) and FEDNEST (Tarzanagh et al. 2022). It is shown in Table 2 that the proposed AFTO can achieve superior performance, which demonstrates the effectiveness of the proposed method.",
            "where 𝝋𝝋{\\boldsymbol{\\varphi}}, 𝒗𝒗{\\boldsymbol{v}} and 𝒘𝒘{\\boldsymbol{w}} respectively denote the parameters for pretraining, finetuning, and reweighting networks. xi,jsubscript𝑥𝑖𝑗x_{i,j} and LP​T,jisuperscriptsubscript𝐿𝑃𝑇𝑗𝑖L_{PT,j}^{i} represent the ithsuperscript𝑖thi^{\\rm{th}} pretraining sample and loss in worker j𝑗j, LF​T,jsubscript𝐿𝐹𝑇𝑗L_{FT,j} represents the finetuning loss in worker j𝑗j. ℛ​(xi,j,𝝋)ℛsubscript𝑥𝑖𝑗𝝋\\mathcal{R}(x_{i,j},{\\boldsymbol{\\varphi}}) denotes the importance of pretraining sample xi,jsubscript𝑥𝑖𝑗x_{i,j}, and λ𝜆\\lambda is the proximal regularization parameter. To evaluate the performance of the proposed method, the multiple domain digits recognition task in (Qian et al. 2019; Wang et al. 2021) is considered. There are two benchmark datasets for\nthis task: MNIST (LeCun et al. 1998) and SVHN (Netzer et al. 2011). In the experiments, we utilize the same image resize strategy as in (Qian et al. 2019) to make the format consistent, and LeNet-5 is used for all pretraining/finetuning/reweighting networks. We summarize the experimental setting in Table 1 and Appendix H. Following (Ji, Yang, and Liang 2021), we utilize the test accuracy/test loss vs running time to evaluate the proposed AFTO. It is seen from Figure 2 that the proposed AFTO can effectively solve the distributed trilevel optimization problem and exhibits superior performance, which achieves a faster convergence rate than SFTO with a maximum acceleration of approximately 80%percent\\%."
        ]
    },
    "Sx5.T2": {
        "caption": "Table 2: MSE of test data with Gaussian noise, lower scores ↓↓\\downarrow represent better performance which are shown in boldface.",
        "table": "<table id=\"Sx5.T2.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx5.T2.3.1.1\" class=\"ltx_tr\">\n<th id=\"Sx5.T2.3.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">Method</th>\n<td id=\"Sx5.T2.3.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">Diabetes</td>\n<td id=\"Sx5.T2.3.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">Boston</td>\n<td id=\"Sx5.T2.3.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">Red-wine</td>\n<td id=\"Sx5.T2.3.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">White-wine</td>\n</tr>\n<tr id=\"Sx5.T2.3.2.2\" class=\"ltx_tr\">\n<th id=\"Sx5.T2.3.2.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">FEDNEST</th>\n<td id=\"Sx5.T2.3.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.5293 ± 0.0229</td>\n<td id=\"Sx5.T2.3.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.3509 ± 0.0177</td>\n<td id=\"Sx5.T2.3.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.0339 ± 0.0014</td>\n<td id=\"Sx5.T2.3.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.0268 ± 0.0010</td>\n</tr>\n<tr id=\"Sx5.T2.3.3.3\" class=\"ltx_tr\">\n<th id=\"Sx5.T2.3.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">ADBO</th>\n<td id=\"Sx5.T2.3.3.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.5284 ± 0.0074</td>\n<td id=\"Sx5.T2.3.3.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.3243 ± 0.0046</td>\n<td id=\"Sx5.T2.3.3.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.0336 ± 0.0018</td>\n<td id=\"Sx5.T2.3.3.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.0277 ± 0.0013</td>\n</tr>\n<tr id=\"Sx5.T2.3.4.4\" class=\"ltx_tr\">\n<th id=\"Sx5.T2.3.4.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"Sx5.T2.3.4.4.1.1\" class=\"ltx_text ltx_font_bold\">AFTO</span></th>\n<td id=\"Sx5.T2.3.4.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">\n<span id=\"Sx5.T2.3.4.4.2.1\" class=\"ltx_text ltx_font_bold\">0.5124</span> ± <span id=\"Sx5.T2.3.4.4.2.2\" class=\"ltx_text ltx_font_bold\">0.0068</span>\n</td>\n<td id=\"Sx5.T2.3.4.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">\n<span id=\"Sx5.T2.3.4.4.3.1\" class=\"ltx_text ltx_font_bold\">0.3130</span> ± <span id=\"Sx5.T2.3.4.4.3.2\" class=\"ltx_text ltx_font_bold\">0.0037</span>\n</td>\n<td id=\"Sx5.T2.3.4.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">\n<span id=\"Sx5.T2.3.4.4.4.1\" class=\"ltx_text ltx_font_bold\">0.0321</span> ± <span id=\"Sx5.T2.3.4.4.4.2\" class=\"ltx_text ltx_font_bold\">0.0026</span>\n</td>\n<td id=\"Sx5.T2.3.4.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">\n<span id=\"Sx5.T2.3.4.4.5.1\" class=\"ltx_text ltx_font_bold\">0.0248</span> ± <span id=\"Sx5.T2.3.4.4.5.2\" class=\"ltx_text ltx_font_bold\">0.0021</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "where 𝝋𝝋{\\boldsymbol{\\varphi}}, 𝒘𝒘{\\boldsymbol{w}} and 𝒑𝒑{\\boldsymbol{p}} respectively denote the regularization parameter, model parameter, and adversarial noise, 𝒑′=[p1′,⋯,pN′]superscript𝒑′superscriptsubscript𝑝1′⋯superscriptsubscript𝑝𝑁′{\\boldsymbol{p}}^{\\prime}=[p_{1}^{\\prime},\\cdots,p_{N}^{\\prime}], N𝑁N is the number of workers. f𝑓f denotes the output of a MLP, c𝑐c denotes the penalty for the adversarial noise, and ||⋅||1⁣∗||\\cdot||_{1*} is a smoothed l1subscript𝑙1l_{1}-norm (Saheya, Nguyen, and Chen 2019). Xjval,yjval,|Djval|subscriptsuperscript𝑋val𝑗subscriptsuperscript𝑦val𝑗subscriptsuperscript𝐷val𝑗X^{\\rm{val}}_{j},y^{\\rm{val}}_{j},{|D^{\\rm{val}}_{j}|}, Xjtr,yjtr,|Djtr|subscriptsuperscript𝑋tr𝑗subscriptsuperscript𝑦tr𝑗subscriptsuperscript𝐷tr𝑗X^{\\rm{tr}}_{j},y^{\\rm{tr}}_{j},{|D^{\\rm{tr}}_{j}|} respectively denote the data, label and the number of data of the validation and training datasets on local worker j𝑗j. Following (Sato, Tanaka, and Takeda 2021), the experiments are carried out on the regression tasks with the following\ndatasets: Diabetes (Dua, Graff et al. 2017), Boston (Harrison Jr and Rubinfeld 1978), Red-wine and White-wine quality (Cortez et al. 2009) datasets. We summarize the experimental setting on each dataset in Table 1. To show the performance of the proposed AFTO, we report the mean squared error (MSE) of clean test data and test data with Gaussian noise vs running time of the AFTO and SFTO (Synchronous Federated Trilevel Optimization) in Figure 1. It is seen that the proposed AFTO can effectively solve the TLO problem in a distributed manner and converges much faster than SFTO since the master can update its variables once it receives updates from a subset of workers instead of all workers in AFTO. Furthermore, we compare the proposed method with the state-of-the-art distributed bilevel optimization methods ADBO (Jiao et al. 2022b) and FEDNEST (Tarzanagh et al. 2022). It is shown in Table 2 that the proposed AFTO can achieve superior performance, which demonstrates the effectiveness of the proposed method."
        ]
    }
}