{
    "PAPER'S NUMBER OF TABLES": 2,
    "Sx5.T1": {
        "caption": "Table 1: Experimental setting in distributed robust hyperparameter optimization and distributed\ndomain adaptation.",
        "table": "<table id=\"Sx5.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"Sx5.T1.3.3\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding:0.5pt 0.0pt;\"></th>\n<th id=\"Sx5.T1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding:0.5pt 0.0pt;\"><math id=\"Sx5.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"N\" display=\"inline\"><semantics id=\"Sx5.T1.1.1.1.m1.1a\"><mi id=\"Sx5.T1.1.1.1.m1.1.1\" xref=\"Sx5.T1.1.1.1.m1.1.1.cmml\">N</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx5.T1.1.1.1.m1.1b\"><ci id=\"Sx5.T1.1.1.1.m1.1.1.cmml\" xref=\"Sx5.T1.1.1.1.m1.1.1\">ğ‘</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx5.T1.1.1.1.m1.1c\">N</annotation></semantics></math></th>\n<th id=\"Sx5.T1.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding:0.5pt 0.0pt;\"><math id=\"Sx5.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"S\" display=\"inline\"><semantics id=\"Sx5.T1.2.2.2.m1.1a\"><mi id=\"Sx5.T1.2.2.2.m1.1.1\" xref=\"Sx5.T1.2.2.2.m1.1.1.cmml\">S</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx5.T1.2.2.2.m1.1b\"><ci id=\"Sx5.T1.2.2.2.m1.1.1.cmml\" xref=\"Sx5.T1.2.2.2.m1.1.1\">ğ‘†</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx5.T1.2.2.2.m1.1c\">S</annotation></semantics></math></th>\n<th id=\"Sx5.T1.3.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding:0.5pt 0.0pt;\">Stragglers</th>\n<th id=\"Sx5.T1.3.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding:0.5pt 0.0pt;\"><math id=\"Sx5.T1.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\tau\" display=\"inline\"><semantics id=\"Sx5.T1.3.3.3.m1.1a\"><mi id=\"Sx5.T1.3.3.3.m1.1.1\" xref=\"Sx5.T1.3.3.3.m1.1.1.cmml\">Ï„</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx5.T1.3.3.3.m1.1b\"><ci id=\"Sx5.T1.3.3.3.m1.1.1.cmml\" xref=\"Sx5.T1.3.3.3.m1.1.1\">ğœ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx5.T1.3.3.3.m1.1c\">\\tau</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx5.T1.3.4.1\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.4.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding:0.5pt 0.0pt;\">Diabetes</th>\n<td id=\"Sx5.T1.3.4.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 0.0pt;\">4</td>\n<td id=\"Sx5.T1.3.4.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 0.0pt;\">3</td>\n<td id=\"Sx5.T1.3.4.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 0.0pt;\">1</td>\n<td id=\"Sx5.T1.3.4.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding:0.5pt 0.0pt;\">10</td>\n</tr>\n<tr id=\"Sx5.T1.3.5.2\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.5.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">Boston</th>\n<td id=\"Sx5.T1.3.5.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">4</td>\n<td id=\"Sx5.T1.3.5.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">3</td>\n<td id=\"Sx5.T1.3.5.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">1</td>\n<td id=\"Sx5.T1.3.5.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 0.0pt;\">10</td>\n</tr>\n<tr id=\"Sx5.T1.3.6.3\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.6.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">Red-wine</th>\n<td id=\"Sx5.T1.3.6.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">4</td>\n<td id=\"Sx5.T1.3.6.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">3</td>\n<td id=\"Sx5.T1.3.6.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">1</td>\n<td id=\"Sx5.T1.3.6.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 0.0pt;\">10</td>\n</tr>\n<tr id=\"Sx5.T1.3.7.4\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.7.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">White-wine</th>\n<td id=\"Sx5.T1.3.7.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">6</td>\n<td id=\"Sx5.T1.3.7.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">4</td>\n<td id=\"Sx5.T1.3.7.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">1</td>\n<td id=\"Sx5.T1.3.7.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 0.0pt;\">10</td>\n</tr>\n<tr id=\"Sx5.T1.3.8.5\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.8.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">SVHN (finetune)</th>\n<td id=\"Sx5.T1.3.8.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">4</td>\n<td id=\"Sx5.T1.3.8.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">3</td>\n<td id=\"Sx5.T1.3.8.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">1</td>\n<td id=\"Sx5.T1.3.8.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding:0.5pt 0.0pt;\">5</td>\n</tr>\n<tr id=\"Sx5.T1.3.9.6\" class=\"ltx_tr\">\n<th id=\"Sx5.T1.3.9.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">SVHN (pretrain)</th>\n<td id=\"Sx5.T1.3.9.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">6</td>\n<td id=\"Sx5.T1.3.9.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">3</td>\n<td id=\"Sx5.T1.3.9.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding:0.5pt 0.0pt;\">2</td>\n<td id=\"Sx5.T1.3.9.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding:0.5pt 0.0pt;\">15</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In the experiment, two distributed trilevel optimization tasks are employed to assess the performance of the proposed method. In the distributed robust hyperparameter optimization, experiments are carried out on the regression tasks following (Sato, Tanaka, and Takeda 2021), and in distributed domain adaptation for pretraining &\\& finetuning, the multiple domain digits recognition task in (Qian etÂ al. 2019; Wang etÂ al. 2021) is considered. The details of the experimental setting are summarized in Table 1 and Appendix H. More experimental results are reported in Appendix G. To further show the superior performance of the proposed method, experimental results of comparisons between the non-distributed version of the proposed method with existing state-of-the-art TLO methods (Sato, Tanaka, and Takeda 2021; Choe etÂ al. 2022) on three TLO tasks are shown in Appendix A in the supplementary material.",
            "where ğ‹ğ‹{\\boldsymbol{\\varphi}}, ğ’˜ğ’˜{\\boldsymbol{w}} and ğ’‘ğ’‘{\\boldsymbol{p}} respectively denote the regularization parameter, model parameter, and adversarial noise, ğ’‘â€²=[p1â€²,â‹¯,pNâ€²]superscriptğ’‘â€²superscriptsubscriptğ‘1â€²â‹¯superscriptsubscriptğ‘ğ‘â€²{\\boldsymbol{p}}^{\\prime}=[p_{1}^{\\prime},\\cdots,p_{N}^{\\prime}], Nğ‘N is the number of workers. fğ‘“f denotes the output of a MLP, cğ‘c denotes the penalty for the adversarial noise, and ||â‹…||1â£âˆ—||\\cdot||_{1*} is a smoothed l1subscriptğ‘™1l_{1}-norm (Saheya, Nguyen, and Chen 2019). Xjval,yjval,|Djval|subscriptsuperscriptğ‘‹valğ‘—subscriptsuperscriptğ‘¦valğ‘—subscriptsuperscriptğ·valğ‘—X^{\\rm{val}}_{j},y^{\\rm{val}}_{j},{|D^{\\rm{val}}_{j}|}, Xjtr,yjtr,|Djtr|subscriptsuperscriptğ‘‹trğ‘—subscriptsuperscriptğ‘¦trğ‘—subscriptsuperscriptğ·trğ‘—X^{\\rm{tr}}_{j},y^{\\rm{tr}}_{j},{|D^{\\rm{tr}}_{j}|} respectively denote the data, label and the number of data of the validation and training datasets on local worker jğ‘—j. Following (Sato, Tanaka, and Takeda 2021), the experiments are carried out on the regression tasks with the following\ndatasets: Diabetes (Dua, Graff etÂ al. 2017), Boston (HarrisonÂ Jr and Rubinfeld 1978), Red-wine and White-wine quality (Cortez etÂ al. 2009) datasets. We summarize the experimental setting on each dataset in Table 1. To show the performance of the proposed AFTO, we report the mean squared error (MSE) of clean test data and test data with Gaussian noise vs running time of the AFTO and SFTO (Synchronous Federated Trilevel Optimization) in Figure 1. It is seen that the proposed AFTO can effectively solve the TLO problem in a distributed manner and converges much faster than SFTO since the master can update its variables once it receives updates from a subset of workers instead of all workers in AFTO. Furthermore, we compare the proposed method with the state-of-the-art distributed bilevel optimization methods ADBO (Jiao etÂ al. 2022b) and FEDNEST (Tarzanagh etÂ al. 2022). It is shown in Table 2 that the proposed AFTO can achieve superior performance, which demonstrates the effectiveness of the proposed method.",
            "where ğ‹ğ‹{\\boldsymbol{\\varphi}}, ğ’—ğ’—{\\boldsymbol{v}} and ğ’˜ğ’˜{\\boldsymbol{w}} respectively denote the parameters for pretraining, finetuning, and reweighting networks. xi,jsubscriptğ‘¥ğ‘–ğ‘—x_{i,j} and LPâ€‹T,jisuperscriptsubscriptğ¿ğ‘ƒğ‘‡ğ‘—ğ‘–L_{PT,j}^{i} represent the ithsuperscriptğ‘–thi^{\\rm{th}} pretraining sample and loss in worker jğ‘—j, LFâ€‹T,jsubscriptğ¿ğ¹ğ‘‡ğ‘—L_{FT,j} represents the finetuning loss in worker jğ‘—j. â„›â€‹(xi,j,ğ‹)â„›subscriptğ‘¥ğ‘–ğ‘—ğ‹\\mathcal{R}(x_{i,j},{\\boldsymbol{\\varphi}}) denotes the importance of pretraining sample xi,jsubscriptğ‘¥ğ‘–ğ‘—x_{i,j}, and Î»ğœ†\\lambda is the proximal regularization parameter. To evaluate the performance of the proposed method, the multiple domain digits recognition task in (Qian etÂ al. 2019; Wang etÂ al. 2021) is considered. There are two benchmark datasets for\nthis task: MNIST (LeCun etÂ al. 1998) and SVHN (Netzer etÂ al. 2011). In the experiments, we utilize the same image resize strategy as in (Qian etÂ al. 2019) to make the format consistent, and LeNet-5 is used for all pretraining/finetuning/reweighting networks. We summarize the experimental setting in Table 1 and Appendix H. Following (Ji, Yang, and Liang 2021), we utilize the test accuracy/test loss vs running time to evaluate the proposed AFTO. It is seen from Figure 2 that the proposed AFTO can effectively solve the distributed trilevel optimization problem and exhibits superior performance, which achieves a faster convergence rate than SFTO with a maximum acceleration of approximately 80%percent\\%."
        ]
    },
    "Sx5.T2": {
        "caption": "Table 2: MSE of test data with Gaussian noise, lower scores â†“â†“\\downarrow represent better performance which are shown in boldface.",
        "table": "<table id=\"Sx5.T2.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx5.T2.3.1.1\" class=\"ltx_tr\">\n<th id=\"Sx5.T2.3.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">Method</th>\n<td id=\"Sx5.T2.3.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">Diabetes</td>\n<td id=\"Sx5.T2.3.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">Boston</td>\n<td id=\"Sx5.T2.3.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">Red-wine</td>\n<td id=\"Sx5.T2.3.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">White-wine</td>\n</tr>\n<tr id=\"Sx5.T2.3.2.2\" class=\"ltx_tr\">\n<th id=\"Sx5.T2.3.2.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">FEDNEST</th>\n<td id=\"Sx5.T2.3.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.5293 Â± 0.0229</td>\n<td id=\"Sx5.T2.3.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.3509 Â± 0.0177</td>\n<td id=\"Sx5.T2.3.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.0339 Â± 0.0014</td>\n<td id=\"Sx5.T2.3.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.0268 Â± 0.0010</td>\n</tr>\n<tr id=\"Sx5.T2.3.3.3\" class=\"ltx_tr\">\n<th id=\"Sx5.T2.3.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">ADBO</th>\n<td id=\"Sx5.T2.3.3.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.5284 Â± 0.0074</td>\n<td id=\"Sx5.T2.3.3.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.3243 Â± 0.0046</td>\n<td id=\"Sx5.T2.3.3.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.0336 Â± 0.0018</td>\n<td id=\"Sx5.T2.3.3.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">0.0277 Â± 0.0013</td>\n</tr>\n<tr id=\"Sx5.T2.3.4.4\" class=\"ltx_tr\">\n<th id=\"Sx5.T2.3.4.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"Sx5.T2.3.4.4.1.1\" class=\"ltx_text ltx_font_bold\">AFTO</span></th>\n<td id=\"Sx5.T2.3.4.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">\n<span id=\"Sx5.T2.3.4.4.2.1\" class=\"ltx_text ltx_font_bold\">0.5124</span> Â± <span id=\"Sx5.T2.3.4.4.2.2\" class=\"ltx_text ltx_font_bold\">0.0068</span>\n</td>\n<td id=\"Sx5.T2.3.4.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">\n<span id=\"Sx5.T2.3.4.4.3.1\" class=\"ltx_text ltx_font_bold\">0.3130</span> Â± <span id=\"Sx5.T2.3.4.4.3.2\" class=\"ltx_text ltx_font_bold\">0.0037</span>\n</td>\n<td id=\"Sx5.T2.3.4.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">\n<span id=\"Sx5.T2.3.4.4.4.1\" class=\"ltx_text ltx_font_bold\">0.0321</span> Â± <span id=\"Sx5.T2.3.4.4.4.2\" class=\"ltx_text ltx_font_bold\">0.0026</span>\n</td>\n<td id=\"Sx5.T2.3.4.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">\n<span id=\"Sx5.T2.3.4.4.5.1\" class=\"ltx_text ltx_font_bold\">0.0248</span> Â± <span id=\"Sx5.T2.3.4.4.5.2\" class=\"ltx_text ltx_font_bold\">0.0021</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "where ğ‹ğ‹{\\boldsymbol{\\varphi}}, ğ’˜ğ’˜{\\boldsymbol{w}} and ğ’‘ğ’‘{\\boldsymbol{p}} respectively denote the regularization parameter, model parameter, and adversarial noise, ğ’‘â€²=[p1â€²,â‹¯,pNâ€²]superscriptğ’‘â€²superscriptsubscriptğ‘1â€²â‹¯superscriptsubscriptğ‘ğ‘â€²{\\boldsymbol{p}}^{\\prime}=[p_{1}^{\\prime},\\cdots,p_{N}^{\\prime}], Nğ‘N is the number of workers. fğ‘“f denotes the output of a MLP, cğ‘c denotes the penalty for the adversarial noise, and ||â‹…||1â£âˆ—||\\cdot||_{1*} is a smoothed l1subscriptğ‘™1l_{1}-norm (Saheya, Nguyen, and Chen 2019). Xjval,yjval,|Djval|subscriptsuperscriptğ‘‹valğ‘—subscriptsuperscriptğ‘¦valğ‘—subscriptsuperscriptğ·valğ‘—X^{\\rm{val}}_{j},y^{\\rm{val}}_{j},{|D^{\\rm{val}}_{j}|}, Xjtr,yjtr,|Djtr|subscriptsuperscriptğ‘‹trğ‘—subscriptsuperscriptğ‘¦trğ‘—subscriptsuperscriptğ·trğ‘—X^{\\rm{tr}}_{j},y^{\\rm{tr}}_{j},{|D^{\\rm{tr}}_{j}|} respectively denote the data, label and the number of data of the validation and training datasets on local worker jğ‘—j. Following (Sato, Tanaka, and Takeda 2021), the experiments are carried out on the regression tasks with the following\ndatasets: Diabetes (Dua, Graff etÂ al. 2017), Boston (HarrisonÂ Jr and Rubinfeld 1978), Red-wine and White-wine quality (Cortez etÂ al. 2009) datasets. We summarize the experimental setting on each dataset in Table 1. To show the performance of the proposed AFTO, we report the mean squared error (MSE) of clean test data and test data with Gaussian noise vs running time of the AFTO and SFTO (Synchronous Federated Trilevel Optimization) in Figure 1. It is seen that the proposed AFTO can effectively solve the TLO problem in a distributed manner and converges much faster than SFTO since the master can update its variables once it receives updates from a subset of workers instead of all workers in AFTO. Furthermore, we compare the proposed method with the state-of-the-art distributed bilevel optimization methods ADBO (Jiao etÂ al. 2022b) and FEDNEST (Tarzanagh etÂ al. 2022). It is shown in Table 2 that the proposed AFTO can achieve superior performance, which demonstrates the effectiveness of the proposed method."
        ]
    }
}