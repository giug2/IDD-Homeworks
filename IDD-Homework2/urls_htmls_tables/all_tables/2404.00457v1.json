{
    "S3.T1": {
        "caption": "Table 1: Example IE Labels, Counts, and Relative Frequency in our constructed symbolic distillation dataset, grouped by the number of tokens.",
        "table": null,
        "footnotes": [],
        "references": [
            "Table¬†1 shows some statistics and example results of the labels returned by the LLM, illustrating a broad spectrum of IE domains, ranging from simple entities and events to complex relationships and contexts.\nThe diversity in the nùëõn-gram categories\nshowcases the model‚Äôs ability to capture a wide array of query types.\nThis variety underscores the comprehensive coverage and nuanced understanding that LLMs bring to the task of generating queries across different facets of the IE domain."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Few-shot transferring performance (F1 score) of different meta-learning sources on IE tasks. Bold: Performance of the small LM that is not significantly different from the best one. (p<0.05)ùëù0.05(p<0.05)",
        "table": null,
        "footnotes": [],
        "references": [
            "The result from our experiments is presented in Table¬†2. The vanilla model is poorly transferred by fine-tuning to all kinds of IE tasks. The model with meta-learning on a single IE task, NER, is only well-transferred to other NER datasets but poorly-transferred to other IE tasks. Among IE-level meta-learning methods, the MultiIE model can be transferred to in-domain IE tasks with outstanding performance but still fails to be transferred to out-of-domain IE tasks, either with regular pre-training or meta-learning frameworks like MAML. In contrast to all these baselines, our MetaIE shows a strong transferability to all IE tasks, especially on out-of-domain tasks for MultiIE. Thus, the experiment results are highly consistent with our claim in IE task transferability that wider pre-training label set ‚Ñí(I‚ÄãE)superscript‚Ñíùêºùê∏\\mathcal{L}^{(IE)} will enable macro transferability of the model to all IE tasks."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Comparison between different frameworks on MetaIE distillation.",
        "table": null,
        "footnotes": [],
        "references": [
            "We compare the performance of different distillation frameworks on NER as an example and the result is demonstrated in Table¬†3. Sequence labeling models perform the best in few-shot transfer learning, which indicates their advantage in the distillation of meta-understanding of IE. This can be attributed to the consistency of sequence labeling with the extraction nature. We thus conclude distilling IE knowledge to a traditional sequence labeling model is better than those popular generative models. Between sequence labeling models, RoBERTa outperforms BERT, showing a better student model also benefits the distillation procedure."
        ]
    }
}