{
    "PAPER'S NUMBER OF TABLES": 5,
    "A1.T1": {
        "caption": "Table 1: Datasets, Tasks & Models",
        "table": "<table id=\"A1.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T1.1.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Dataset</span></td>\n<td id=\"A1.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\" colspan=\"2\"><span id=\"A1.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Num Clients</span></td>\n<td id=\"A1.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\" colspan=\"2\"><span id=\"A1.T1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Num Examples</span></td>\n<td id=\"A1.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Task</span></td>\n<td id=\"A1.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Model</span></td>\n</tr>\n<tr id=\"A1.T1.1.2.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.2.2.1\" class=\"ltx_td\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"></td>\n<td id=\"A1.T1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Train</span></td>\n<td id=\"A1.T1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Test</span></td>\n<td id=\"A1.T1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Train</span></td>\n<td id=\"A1.T1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Test</span></td>\n<td id=\"A1.T1.1.2.2.6\" class=\"ltx_td\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"></td>\n<td id=\"A1.T1.1.2.2.7\" class=\"ltx_td\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"></td>\n</tr>\n<tr id=\"A1.T1.1.3.3\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.3.3.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">EMNIST</span></td>\n<td id=\"A1.T1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.3.3.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">3.4K</span></td>\n<td id=\"A1.T1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.3.3.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">3.4K</span></td>\n<td id=\"A1.T1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.3.3.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">672K</span></td>\n<td id=\"A1.T1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.3.3.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">77K</span></td>\n<td id=\"A1.T1.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.3.3.6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.3.3.6.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.3.3.6.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.3.3.6.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Character</span></td>\n</tr>\n<tr id=\"A1.T1.1.3.3.6.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.3.3.6.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.3.3.6.1.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Recognition</span></td>\n</tr>\n</table>\n</td>\n<td id=\"A1.T1.1.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.3.3.7.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">CNN</span></td>\n</tr>\n<tr id=\"A1.T1.1.4.4\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.4.4.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">CIFAR100</span></td>\n<td id=\"A1.T1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.4.4.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">500</span></td>\n<td id=\"A1.T1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.4.4.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">100</span></td>\n<td id=\"A1.T1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.4.4.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">50K</span></td>\n<td id=\"A1.T1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.4.4.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">10K</span></td>\n<td id=\"A1.T1.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.4.4.6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.4.4.6.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.4.4.6.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.4.4.6.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Image</span></td>\n</tr>\n<tr id=\"A1.T1.1.4.4.6.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.4.4.6.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.4.4.6.1.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Recognition</span></td>\n</tr>\n</table>\n</td>\n<td id=\"A1.T1.1.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.4.4.7.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.4.4.7.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.4.4.7.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.4.4.7.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">ResNet-18</span></td>\n</tr>\n<tr id=\"A1.T1.1.4.4.7.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.4.4.7.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.4.4.7.1.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">with GroupNorm</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"A1.T1.1.5.5\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.5.5.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.5.5.1.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.5.5.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.5.5.1.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Stack</span></td>\n</tr>\n<tr id=\"A1.T1.1.5.5.1.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.5.5.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.5.5.1.1.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Overflow</span></td>\n</tr>\n</table>\n</td>\n<td id=\"A1.T1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.5.5.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">342K</span></td>\n<td id=\"A1.T1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.5.5.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">204K</span></td>\n<td id=\"A1.T1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.5.5.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">135.8M</span></td>\n<td id=\"A1.T1.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.5.5.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">16.6M</span></td>\n<td id=\"A1.T1.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.5.5.6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.5.5.6.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.5.5.6.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.5.5.6.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Next-Token</span></td>\n</tr>\n<tr id=\"A1.T1.1.5.5.6.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.5.5.6.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.5.5.6.1.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Prediction</span></td>\n</tr>\n</table>\n</td>\n<td id=\"A1.T1.1.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.5.5.7.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.5.5.7.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.5.5.7.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.5.5.7.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">350M Parameter</span></td>\n</tr>\n<tr id=\"A1.T1.1.5.5.7.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.5.5.7.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.5.5.7.1.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Decoder-only Transformer</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"A1.T1.1.6.6\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.6.6.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.6.6.1.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.6.6.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.6.6.1.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">C4</span></td>\n</tr>\n</table>\n</td>\n<td id=\"A1.T1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.6.6.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">15.6M</span></td>\n<td id=\"A1.T1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.6.6.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">8.5K</span></td>\n<td id=\"A1.T1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.6.6.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">364.9M</span></td>\n<td id=\"A1.T1.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.6.6.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">365K</span></td>\n<td id=\"A1.T1.1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.6.6.6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.6.6.6.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.6.6.6.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.6.6.6.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Next-Token</span></td>\n</tr>\n<tr id=\"A1.T1.1.6.6.6.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.6.6.6.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.6.6.6.1.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Prediction</span></td>\n</tr>\n</table>\n</td>\n<td id=\"A1.T1.1.6.6.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.6.6.7.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.6.6.7.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.6.6.7.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.6.6.7.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">1.5B Parameter</span></td>\n</tr>\n<tr id=\"A1.T1.1.6.6.7.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.6.6.7.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.6.6.7.1.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Decoder-only Transformer</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"A1.T1.1.7.7\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.7.7.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.7.7.1.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.7.7.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.7.7.1.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">CC-News</span></td>\n</tr>\n</table>\n</td>\n<td id=\"A1.T1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.7.7.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">‚Äì</span></td>\n<td id=\"A1.T1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.7.7.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">8.8K</span></td>\n<td id=\"A1.T1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.7.7.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">‚Äì</span></td>\n<td id=\"A1.T1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.7.7.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">708K</span></td>\n<td id=\"A1.T1.1.7.7.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.7.7.6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.7.7.6.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.7.7.6.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.7.7.6.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Next-Token</span></td>\n</tr>\n<tr id=\"A1.T1.1.7.7.6.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.7.7.6.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.7.7.6.1.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Prediction</span></td>\n</tr>\n</table>\n</td>\n<td id=\"A1.T1.1.7.7.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\">\n<table id=\"A1.T1.1.7.7.7.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T1.1.7.7.7.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.7.7.7.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.7.7.7.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">1.5B Parameter</span></td>\n</tr>\n<tr id=\"A1.T1.1.7.7.7.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T1.1.7.7.7.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.25pt;padding-bottom:2.25pt;\"><span id=\"A1.T1.1.7.7.7.1.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Decoder-only Transformer</span></td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We use four datasets for training models using ",
                "FedAvg",
                " and ",
                "FedFish",
                ": the federated extended MNIST dataset (EMNIST) ",
                "(Cohen et¬†al., ",
                "2017",
                ")",
                ", the CIFAR100 dataset ",
                "(",
                "Krizhevsky et¬†al., ",
                ")",
                ", the Stack Overflow dataset ",
                "(Authors, ",
                "2019",
                ")",
                " and the C4 dataset ",
                "(Raffel et¬†al., ",
                "2020",
                ")",
                ". We additionally use the CC-News ",
                "(Hamborg et¬†al., ",
                "2017",
                ")",
                " and Stack Overflow datasets for evaluating transfer and post-personalization performance of models trained on C4 using each algorithm of study.",
                "Each of these datasets is publicly available. EMNIST is licensed under Standard Reference Data by NIST. CIFAR100 is published by the authors. Stack Overflow is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License. C4 and CC-News are hosted by ",
                "commoncrawl.org",
                " and we access both through HuggingFace datasets.",
                "Table",
                "¬†",
                "1",
                " lists the scale of each dataset, the associated task and the model used for training. We include additional details on dataset preprocessing and model configuration for each experiment setting below."
            ]
        ]
    },
    "A1.T2": {
        "caption": "Table 2: Final hyperparameter configurations for all datasets.",
        "table": "<table id=\"A1.T2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></td>\n<td id=\"A1.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">EMNIST</span></td>\n<td id=\"A1.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">CIFAR100</span></td>\n<td id=\"A1.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Stack Overflow</span></td>\n<td id=\"A1.T2.1.1.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">C4</span></td>\n</tr>\n<tr id=\"A1.T2.1.2.2\" class=\"ltx_tr\">\n<td id=\"A1.T2.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Number of clients per round</span></td>\n<td id=\"A1.T2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">64</td>\n<td id=\"A1.T2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">64</td>\n<td id=\"A1.T2.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">16</td>\n<td id=\"A1.T2.1.2.2.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">8</td>\n</tr>\n<tr id=\"A1.T2.1.3.3\" class=\"ltx_tr\">\n<td id=\"A1.T2.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.3.3.1.1\" class=\"ltx_text ltx_font_bold\">Number of training rounds</span></td>\n<td id=\"A1.T2.1.3.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1500</td>\n<td id=\"A1.T2.1.3.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1500</td>\n<td id=\"A1.T2.1.3.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1500</td>\n<td id=\"A1.T2.1.3.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">10000</td>\n</tr>\n<tr id=\"A1.T2.1.4.4\" class=\"ltx_tr\">\n<td id=\"A1.T2.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.4.4.1.1\" class=\"ltx_text ltx_font_bold\">Batch size for local training</span></td>\n<td id=\"A1.T2.1.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">10</td>\n<td id=\"A1.T2.1.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">25</td>\n<td id=\"A1.T2.1.4.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">4</td>\n<td id=\"A1.T2.1.4.4.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">4</td>\n</tr>\n<tr id=\"A1.T2.1.5.5\" class=\"ltx_tr\">\n<td id=\"A1.T2.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.5.5.1.1\" class=\"ltx_text ltx_font_bold\">Max client dataset size per round</span></td>\n<td id=\"A1.T2.1.5.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">100</td>\n<td id=\"A1.T2.1.5.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">100</td>\n<td id=\"A1.T2.1.5.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">16</td>\n<td id=\"A1.T2.1.5.5.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">16</td>\n</tr>\n<tr id=\"A1.T2.1.6.6\" class=\"ltx_tr\">\n<td id=\"A1.T2.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.6.6.1.1\" class=\"ltx_text ltx_font_bold\">Sequence length (training)</span></td>\n<td id=\"A1.T2.1.6.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">-</td>\n<td id=\"A1.T2.1.6.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">-</td>\n<td id=\"A1.T2.1.6.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">128</td>\n<td id=\"A1.T2.1.6.6.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1024</td>\n</tr>\n<tr id=\"A1.T2.1.7.7\" class=\"ltx_tr\">\n<td id=\"A1.T2.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.7.7.1.1\" class=\"ltx_text ltx_font_bold\">Sequence length (personalization and evaluation)</span></td>\n<td id=\"A1.T2.1.7.7.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">-</td>\n<td id=\"A1.T2.1.7.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">-</td>\n<td id=\"A1.T2.1.7.7.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">128</td>\n<td id=\"A1.T2.1.7.7.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">128</td>\n</tr>\n<tr id=\"A1.T2.1.8.8\" class=\"ltx_tr\">\n<td id=\"A1.T2.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.8.8.1.1\" class=\"ltx_text ltx_font_bold\">Number of personalization epochs</span></td>\n<td id=\"A1.T2.1.8.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1</td>\n<td id=\"A1.T2.1.8.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">4</td>\n<td id=\"A1.T2.1.8.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">4</td>\n<td id=\"A1.T2.1.8.8.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">4</td>\n</tr>\n<tr id=\"A1.T2.1.9.9\" class=\"ltx_tr\">\n<td id=\"A1.T2.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.9.9.1.1\" class=\"ltx_text ltx_font_bold\">Global learning rate</span></td>\n<td id=\"A1.T2.1.9.9.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1e-3</td>\n<td id=\"A1.T2.1.9.9.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1e-3</td>\n<td id=\"A1.T2.1.9.9.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1e-2</td>\n<td id=\"A1.T2.1.9.9.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1e-2</td>\n</tr>\n<tr id=\"A1.T2.1.10.10\" class=\"ltx_tr\">\n<td id=\"A1.T2.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"A1.T2.1.10.10.1.1\" class=\"ltx_text ltx_font_bold\">Local learning rate</span></td>\n<td id=\"A1.T2.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1e-3</td>\n<td id=\"A1.T2.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1e-3</td>\n<td id=\"A1.T2.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1e-3</td>\n<td id=\"A1.T2.1.10.10.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">1e-3</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We fix hyperparameters like number of clients per round, number of training rounds, local batch size, maximum dataset size for any client and sequence length for language models to reasonable values based on previous literature. For local and global learning rates, we conducted a grid search over [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1], and chose the best performing hyperparameters. Final hyperparameter configurations used to obtain the results in the paper are listed in ",
                "table",
                "¬†",
                "2",
                ". These are held consistent for ",
                "FedAvg",
                " and ",
                "FedFish",
                " experiments."
            ]
        ]
    },
    "A1.T3": {
        "caption": "Table 3: Longer local training improves overall performance in terms of both global model accuracy as well as personalization. When amount of compute, i.e. total number of training epochs, is fixed, FedFish can achieve better performance than FedAvg with fewer rounds of communication between the server and clients.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nDataset\nLocal epochs\nMethod\nGlobal Accuracy\nPersonalized Accuracy\n\nFixed compute\nFixed rounds\nFixed compute\nFixed rounds\n\nEMNIST\n4\nFedAvg\n81.3881.3881.38\n81.3881.3881.38\n83.0983.0983.09\n83.0983.0983.09\n\nFedFish\n82.6482.6482.64\n82.6482.6482.64\n83.4483.4483.44\n83.4483.4483.44\n\n8\nFedAvg\n82.0582.0582.05\n82.2482.2482.24\n83.4683.4683.46\n83.8283.8283.82\n\nFedFish\n83.1983.1983.19\n84.4284.4284.42\n84.3784.3784.37\n85.685.685.6\n\n16\nFedAvg\n76.4576.4576.45\n77.5277.5277.52\n77.9677.9677.96\n79.6379.6379.63\n\nFedFish\n79.0179.0179.01\n82.8682.8682.86\n81.0581.0581.05\n84.9684.9684.96\n\nCIFAR100\n4\nFedAvg\n35.7535.7535.75\n35.7535.7535.75\n37.0637.0637.06\n37.0637.0637.06\n\nFedFish\n36.8836.8836.88\n36.8836.8836.88\n41.3141.3141.31\n41.3141.3141.31\n\n16\nFedAvg\n28.5628.5628.56\n33.2833.2833.28\n36.0036.0036.00\n32.1332.1332.13\n\nFedFish\n31.6331.6331.63\n37.7237.7237.72\n40.5340.5340.53\n44.6944.6944.69\n\n\n",
        "references": [
            "We study the effect of local training on the global model‚Äôs performance by varying the number of epochs of training clients perform in between rounds. Since increasing the number of local epochs for a fixed number of rounds increases computational costs, we present our results by separately fixing compute (or total number of training iterations) and number of aggregation rounds. We provide a complete table of results covering all settings in table¬†3 of section¬†A.4 and discuss representative experiments here. With fixed compute, fig.¬†3 (left) shows a decline in global accuracy as number of local epochs is increased for both FedAvg and FedFish, as expected by the client-drift phenomenon. However, within each setting, and across datasets, FedFish outperforms FedAvg, suffering a more graceful decline in performance with more local training and converging to higher performance faster. Figure¬†4 similarly shows FedFish outperforming FedAvg in terms of classification accuracy and next-token prediction accuracy for CIFAR100 (left) and Stack Overflow (right) datasets, respectively. In both of these settings, FedFish is much more robust to longer periods of local training that FedAvg, whose performance suffers as local training increases. In fig.¬†5 (left), we use the heterogeneous C4 dataset for federated training and evaluate its zero-shot performance on unseen clients from C4 itself. The bottom row of the plot shows that the global model, without any personalization data, benefits considerably from increased local epochs during federated pretraining for both algorithms, with FedFish outperforming FedAvg."
        ]
    },
    "A1.T4": {
        "caption": "Table 4: Full results on global and post-personalization performance of language models that are pretrained in a federated manner with varying number of local epochs and then evaluated on different datasets. These results correspond to the entire RùëÖR rounds of federated training.",
        "table": "",
        "footnotes": "\n\n\n\n\n\n\n\n\nTraining\n\nDataset\n\n\n\n\nTraining Local\n\nEpochs\n\n\n\n\nPersonalization\n\nDataset\n\nMethod\nGlobal\nPersonalized (25%)\nPersonalized (50%)\n\nToken Pred\nPerplexity\nToken Pred\nPerplexity\nToken Pred\nPerplexity\n\n\n\nStack Overflow\n8\nStack Overflow\nFedAvg\n32.00\n3.79\n-\n-\n32.34\n3.90\n\nFedFish\n32.98\n3.77\n-\n-\n34.28\n3.68\n\n16\nFedAvg\n21.77\n5.56\n-\n-\n25.46\n4.61\n\nFedFish\n31.27\n3.96\n-\n-\n32.60\n3.81\n\nC4\n1\nC4\nFedAvg\n30.16\n4.26\n30.81\n4.21\n30.95\n4.20\n\nFedFish\n31.15\n4.19\n32.10\n4.12\n32.34\n4.11\n\n16\nFedAvg\n31.04\n4.13\n32.26\n4.12\n32.73\n4.08\n\nFedFish\n32.37\n3.99\n33.54\n3.92\n33.98\n3.87\n\nC4\n1\nStack Overflow\nFedAvg\n17.91\n5.29\n19.85\n5.13\n21.58\n5.03\n\nFedFish\n19.55\n5.101\n22.07\n4.91\n23.38\n4.815\n\n16\nFedAvg\n18.83\n5.13\n19.63\n5.201\n22.98\n4.69\n\nFedFish\n19.54\n5.16\n26.89\n4.32\n27.77\n4.22\n\nC4\n1\nCC-News\nFedAvg\n29.03\n4.38\n29.45\n4.34\n29.73\n4.31\n\nFedFish\n29.53\n4.41\n30.14\n4.35\n30.61\n4.32\n\n16\nFedAvg\n29.96\n4.25\n29.69\n4.35\n31.00\n4.21\n\nFedFish\n31.00\n4.15\n31.75\n4.08\n32.58\n3.98\n\n\n",
        "references": [
            [
                "Here, we include additional results and report the performance visualized in ",
                "section",
                "¬†",
                "5",
                ". ",
                "Table",
                "¬†",
                "3",
                " shows results on image benchmarks where performance is computed by keeping either the computational requirement or the total number of rounds fixed. For the former, we limit the number of training rounds according to the number of local epochs so that total amount of client-side training remains constant. Unsurprisingly, allowing for more rounds of training helps performance. However, at fixed compute, we see that ",
                "FedFish",
                " is able to achieve better performance than ",
                "FedAvg",
                " with fewer rounds of communication. ",
                "Table",
                "¬†",
                "4",
                " and ",
                "table",
                "¬†",
                "5",
                " include full results on our language modeling experiments, including different numbers of local training epochs, different datasets used for federated pretraining or personalization, different performance metrics and different amounts of data used for personalization. Finally, similar to ",
                "fig.",
                "¬†",
                "5",
                " with shows next-token prediction performance, we present perplexity performance for the C4 transfer experiments in ",
                "fig.",
                "¬†",
                "7",
                "."
            ]
        ]
    },
    "A1.T5": {
        "caption": "Table 5: Results on global and post-personalization performance of language models in different settings, evaluated at R/2ùëÖ2R/2 rounds of federated training.",
        "table": "",
        "footnotes": "\n\n\n\n\n\n\n\n\nTraining\n\nDataset\n\n\n\n\nTraining Local\n\nEpochs\n\n\n\n\nPersonalization\n\nDataset\n\nMethod\nGlobal\nPersonalized (25%)\nPersonalized (50%)\n\nToken Pred\nPerplexity\nToken Pred\nPerplexity\nToken Pred\nPerplexity\n\n\n\nC4\n1\nC4\nFedAvg\n26.82\n4.67\n27.56\n4.61\n27.73\n4.60\n\nFedFish\n27.69\n4.63\n28.70\n4.55\n28.91\n4.54\n\n16\nFedAvg\n28.63\n4.42\n29.84\n4.37\n30.11\n4.39\n\nFedFish\n30.33\n4.28\n31.54\n4.11\n31.61\n4.10\n\n1\nStack Overflow\nFedAvg\n17.10\n5.38\n19.92\n5.20\n21.78\n5.10\n\nFedFish\n17.25\n5.41\n19.62\n5.2\n21.10\n5.08\n\n16\nFedAvg\n18.57\n5.29\n16.23\n7.03\n18.91\n6.09\n\nFedFish\n17.80\n5.42\n20.81\n4.77\n22.78\n4.58\n\n1\nCC-News\nFedAvg\n26.03\n4.79\n26.44\n4.75\n26.72\n4.72\n\nFedFish\n26.23\n4.86\n26.88\n4.80\n27.34\n4.76\n\n16\nFedAvg\n27.55\n4.58\n27.23\n4.59\n28.02\n4.55\n\nFedFish\n28.91\n4.44\n29.86\n4.29\n30.06\n4.27\n\n\n",
        "references": [
            [
                "Here, we include additional results and report the performance visualized in ",
                "section",
                "¬†",
                "5",
                ". ",
                "Table",
                "¬†",
                "3",
                " shows results on image benchmarks where performance is computed by keeping either the computational requirement or the total number of rounds fixed. For the former, we limit the number of training rounds according to the number of local epochs so that total amount of client-side training remains constant. Unsurprisingly, allowing for more rounds of training helps performance. However, at fixed compute, we see that ",
                "FedFish",
                " is able to achieve better performance than ",
                "FedAvg",
                " with fewer rounds of communication. ",
                "Table",
                "¬†",
                "4",
                " and ",
                "table",
                "¬†",
                "5",
                " include full results on our language modeling experiments, including different numbers of local training epochs, different datasets used for federated pretraining or personalization, different performance metrics and different amounts of data used for personalization. Finally, similar to ",
                "fig.",
                "¬†",
                "5",
                " with shows next-token prediction performance, we present perplexity performance for the C4 transfer experiments in ",
                "fig.",
                "¬†",
                "7",
                "."
            ]
        ]
    }
}