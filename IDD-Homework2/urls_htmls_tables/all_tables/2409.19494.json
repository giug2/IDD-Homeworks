{
    "id_table_1": {
        "caption": "TABLE I :  Overview of related work. Methods based on either RGB or depth images that output a grasp with translation  t t \\mathbf{t} bold_t  or rotation  R R \\mathbf{R} bold_R .",
        "table": "S2.T1.6",
        "footnotes": [
            "",
            "",
            "",
            "",
            ""
        ],
        "references": []
    },
    "id_table_2": {
        "caption": "TABLE II :  Definitions for different scores used in the affordance grasp score function.   N N N italic_N  is the number of depth measurements along the perimeter suction projection,  D i subscript D i D_{i} italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is the depth at point  i i i italic_i  along the perimeter of the suction projection,  D m  a  x subscript D m a x D_{max} italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT  is the maximum depth,  A max subscript A max A_{\\text{max}} italic_A start_POSTSUBSCRIPT max end_POSTSUBSCRIPT  is the maximum Anomaly score,       \\Delta\\theta roman_ italic_  is the angle resolution,   D subscript  D \\sigma_{D} italic_ start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT  is the standard deviation of the depth values,   i subscript  i \\theta_{i} italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is the angle between the normal vector at point  i i i italic_i  and the reference normal vector, and   thresh subscript  thresh \\theta_{\\text{thresh}} italic_ start_POSTSUBSCRIPT thresh end_POSTSUBSCRIPT  and   max subscript  max \\theta_{\\text{max}} italic_ start_POSTSUBSCRIPT max end_POSTSUBSCRIPT  is the threshold and maximum allowed inclination angles, respectively. These components collectively ensure robust and reliable suction grasps.",
        "table": "S4.T2.10",
        "footnotes": [],
        "references": [
            "This section describes  OptiGrasp , a learning-based pipeline developed to create a grasp point detection model. This configuration processes only a single view RGB image of the scene configuration, generating three affordance maps: grasp location, pitch    \\beta italic_ , and yaw    \\gamma italic_  on the target object or all the objects within the scene. The primary map estimates the likelihood of successful suction grasp, while the additional maps predict the best roll and yaw angles for optimal grasping points identified on the primary map. These maps collectively predict the pixel-wise success probability of object pickup, as illustrated in  Fig. 2 . Note that the model was trained exclusively on synthetic images without any real-world fine-tuning, and zero-shot transfer was demonstrated in real-world experiments.",
            "The  OptiGrasp  as shown in  Fig. 2  integrates a pre-trained DINOv2  [ 2 ]  from the Depth Anything  [ 1 ]  model using a ViT-base architecture. This pre-trained network processes input single-view RGB images to generate a dense feature map. The output from DINOv2 is subsequently passed to a DPT model. The output from the DPT  [ 3 ]  model is then combined with the segmentation mask obtained from STOW  [ 38 ] , provides the segmentation masks, and tracks unseen object instances in discrete frames. It is then passed to the Affordance Grasp Head. This module produces three affordance maps corresponding to the grasp point, pitch    \\beta italic_ , and yaw    \\gamma italic_ , facilitating the interpretation of scene affordances for determining the 6D pose.",
            "The system operates on single-view synthetic RGB images. Segmentation masks are incorporated into the Affordance Grasp Head for training. The system calculates loss across all segmented pixels for each affordance map as referred in  Eq. 2 .",
            "We use Huber loss  L   ( a ) subscript L  a L_{\\delta}(a) italic_L start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_a )  as shown in  Eq. 2  to calculate the loss for all three affordance maps, where  y y y italic_y  represents the labels which are produced as mentioned in  Section  IV-C  and  y ^ ^ y \\hat{y} over^ start_ARG italic_y end_ARG  represents the affordance maps predictions. The loss is calculated by summing all three affordance maps for grasp location, pitch, and yaw.    \\delta italic_  is a threshold parameter that is set to 1.0 throughout this paper.  A A \\mathcal{A} caligraphic_A  represents the set of all affordance maps and  Mask  represents pixels within the segmentation mask."
        ]
    },
    "id_table_3": {
        "caption": "TABLE III :  Success rates of grasping methods across object sets of different difficulty. The evaluation involved 215 grasps on 170 unique objects.",
        "table": "S5.T3.4",
        "footnotes": [],
        "references": []
    },
    "id_table_4": {
        "caption": "TABLE IV :  Accuracy comparison of grasping methods using RGB and depth data across 230 real-world objects. Our method (OptiGrasp) achieves better accuracy.",
        "table": "S5.T4.4",
        "footnotes": [
            ""
        ],
        "references": [
            "The objective of our experiment is to investigate robotic suction grasping for industrial warehouse shelves, as detailed in  [ 40 ] .  Fig. 4  depicts the robot setup and the industrial shelving unit, where a huge variety of objects can be stored. Throughout the evaluation, a Universal Robots UR16e robot was equipped with a custom industrial vacuum suction gripper. The vacuum gripper houses a Schmalz SCTSi-EIP 4 vacuum ejector, which has a maximum flow rate of  65.5   L / min times 65.5 divide liter minute 65.5\\text{\\,}\\mathrm{L}\\text{/}\\mathrm{min} start_ARG 65.5 end_ARG start_ARG times end_ARG start_ARG start_ARG roman_L end_ARG start_ARG divide end_ARG start_ARG roman_min end_ARG end_ARG . RRT Connect [ 41 ]  along with OMPL [ 42 ]  was used for motion planning of the robotic arm."
        ]
    },
    "id_table_5": {
        "caption": "TABLE V:  Comparison of accuracy across different backbone and DPT configurations, where Real success rate denotes the accuracy achieved during real robot experiments on real-world data, and Synthetic success rate represents the accuracy on synthetic data, calculated by comparing model predictions with the true labels (human expert evaluation). The backbone corresponds to the specific DinoV2 variant used in our study where the DinoV2 structure is similar to the original DinoV2 [ 2 ]  and From Depth Anything [ 1 ] , while DPT refers to the variant utilized for ablation analysis.",
        "table": "S5.T5.2",
        "footnotes": [
            "",
            ""
        ],
        "references": [
            "Fig. 5  displays the categorized object sets:"
        ]
    }
}