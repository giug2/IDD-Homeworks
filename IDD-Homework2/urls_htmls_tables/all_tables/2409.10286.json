{
    "id_table_1": {
        "caption": "Table 1:  Classification performance of EfficientNet-V2 and ResNet-50 models with various data augmentation strategies.",
        "table": "S5.T1.1.1",
        "footnotes": [],
        "references": [
            "Post-training, the VAE synthesizes new images by performing an interpolation between the latent representations of two images within the same class, with the process illustrated in Figure  1 . This interpolation is achieved by computing a weighted sum of their latent vectors  z 1 subscript z 1 z_{1} italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  and  z 2 subscript z 2 z_{2} italic_z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , yielding a new latent representation, denoted as  z i  n  t  e  r  p subscript z i n t e r p z_{interp} italic_z start_POSTSUBSCRIPT italic_i italic_n italic_t italic_e italic_r italic_p end_POSTSUBSCRIPT :",
            "Experimental results, presented in Table  1 , remark the efficacy of incorporating synthetic data augmentation via class-specific VAEs in enhancing classification performance. A comparative analysis across different models and augmentation strategies reveals that the addition of VAE-generated synthetic images leads to substantial improvements in overall accuracy, precision, recall, and F1-scores."
        ]
    }
}