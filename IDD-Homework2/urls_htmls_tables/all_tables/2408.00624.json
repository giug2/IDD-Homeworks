{
    "S4.T1": {
        "caption": "Table 1: Experimental results comparing on single-task and multi-task on different visual encoders. The relative improvement rate represents the performance influence of incorporating visual modality to the original model under the certain tasks, the visual influence in single-task or multi-task scenarios are calculated independently.",
        "table": "<table id=\"S4.T1.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.4.5.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.5.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"></th>\n<th id=\"S4.T1.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.4.5.1.2.1\" class=\"ltx_text ltx_font_bold\">ASR (How2)</span></th>\n<th id=\"S4.T1.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.4.5.1.3.1\" class=\"ltx_text ltx_font_bold\">ASR (VisSpeech)</span></th>\n<th id=\"S4.T1.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.4.5.1.4.1\" class=\"ltx_text ltx_font_bold\">ST</span></th>\n<th id=\"S4.T1.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.4.5.1.5.1\" class=\"ltx_text ltx_font_bold\">MT</span></th>\n</tr>\n<tr id=\"S4.T1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.5\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"></th>\n<th id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">WER(<math id=\"S4.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\">&#8595;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><ci id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">&#8595;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>)</th>\n<th id=\"S4.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">WER(<math id=\"S4.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T1.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.2.2.2.m1.1.1\" xref=\"S4.T1.2.2.2.m1.1.1.cmml\">&#8595;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.2.2.2.m1.1b\"><ci id=\"S4.T1.2.2.2.m1.1.1.cmml\" xref=\"S4.T1.2.2.2.m1.1.1\">&#8595;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.2.2.2.m1.1c\">\\downarrow</annotation></semantics></math>)</th>\n<th id=\"S4.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">BLEU(<math id=\"S4.T1.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T1.3.3.3.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.3.3.3.m1.1.1\" xref=\"S4.T1.3.3.3.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.3.3.3.m1.1b\"><ci id=\"S4.T1.3.3.3.m1.1.1.cmml\" xref=\"S4.T1.3.3.3.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.3.3.3.m1.1c\">\\uparrow</annotation></semantics></math>)</th>\n<th id=\"S4.T1.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">BLEU(<math id=\"S4.T1.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T1.4.4.4.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.4.4.4.m1.1.1\" xref=\"S4.T1.4.4.4.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.4.4.4.m1.1b\"><ci id=\"S4.T1.4.4.4.m1.1.1.cmml\" xref=\"S4.T1.4.4.4.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.4.4.4.m1.1c\">\\uparrow</annotation></semantics></math>)</th>\n</tr>\n<tr id=\"S4.T1.4.6.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.6.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">How2 Baseline w/ visual &#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">12</a>]</cite>\n</th>\n<th id=\"S4.T1.4.6.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">18.0</th>\n<th id=\"S4.T1.4.6.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">-</th>\n<th id=\"S4.T1.4.6.2.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">37.2</th>\n<th id=\"S4.T1.4.6.2.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">54.4</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.4.7.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.7.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Single w/o visual</th>\n<td id=\"S4.T1.4.7.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">17.6</td>\n<td id=\"S4.T1.4.7.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">41.6</td>\n<td id=\"S4.T1.4.7.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">40.5</td>\n<td id=\"S4.T1.4.7.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">55.2</td>\n</tr>\n<tr id=\"S4.T1.4.8.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.8.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Single w/ visual (CLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\">32</a>]</cite>)</th>\n<td id=\"S4.T1.4.8.2.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.4.8.2.2.1\" class=\"ltx_text ltx_font_bold\">17.0 (+3.41%)</span></td>\n<td id=\"S4.T1.4.8.2.3\" class=\"ltx_td ltx_align_left\">41.7 (-0.24%)</td>\n<td id=\"S4.T1.4.8.2.4\" class=\"ltx_td ltx_align_left\">40.7 (+0.49%)</td>\n<td id=\"S4.T1.4.8.2.5\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.4.8.2.5.1\" class=\"ltx_text ltx_font_bold\">55.6 (+0.72%)</span></td>\n</tr>\n<tr id=\"S4.T1.4.9.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.9.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Single w/ visual (EVA-CLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib34\" title=\"\" class=\"ltx_ref\">34</a>]</cite>)</th>\n<td id=\"S4.T1.4.9.3.2\" class=\"ltx_td ltx_align_left\">17.6 (+0.00%)</td>\n<td id=\"S4.T1.4.9.3.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.4.9.3.3.1\" class=\"ltx_text ltx_font_bold\">40.4 (+2.88%)</span></td>\n<td id=\"S4.T1.4.9.3.4\" class=\"ltx_td ltx_align_left\">41.3 (+1.98%)</td>\n<td id=\"S4.T1.4.9.3.5\" class=\"ltx_td ltx_align_left\">54.7 (-0.91%)</td>\n</tr>\n<tr id=\"S4.T1.4.10.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.10.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Single w/ visual (SigLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">33</a>]</cite>)</th>\n<td id=\"S4.T1.4.10.4.2\" class=\"ltx_td ltx_align_left\">17.3 (+1.70%)</td>\n<td id=\"S4.T1.4.10.4.3\" class=\"ltx_td ltx_align_left\">42.3 (-1.68%)</td>\n<td id=\"S4.T1.4.10.4.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.4.10.4.4.1\" class=\"ltx_text ltx_font_bold\">41.4 (+2.22%)</span></td>\n<td id=\"S4.T1.4.10.4.5\" class=\"ltx_td ltx_align_left\">54.7 (-0.91%)</td>\n</tr>\n<tr id=\"S4.T1.4.11.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.11.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Multi w/o visual</th>\n<td id=\"S4.T1.4.11.5.2\" class=\"ltx_td ltx_align_left ltx_border_t\">16.4</td>\n<td id=\"S4.T1.4.11.5.3\" class=\"ltx_td ltx_align_left ltx_border_t\">40.8</td>\n<td id=\"S4.T1.4.11.5.4\" class=\"ltx_td ltx_align_left ltx_border_t\">42.9</td>\n<td id=\"S4.T1.4.11.5.5\" class=\"ltx_td ltx_align_left ltx_border_t\">54.7</td>\n</tr>\n<tr id=\"S4.T1.4.12.6\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.12.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Multi w/ visual (CLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\">32</a>]</cite>)</th>\n<td id=\"S4.T1.4.12.6.2\" class=\"ltx_td ltx_align_left\">16.1 (+1.83%)</td>\n<td id=\"S4.T1.4.12.6.3\" class=\"ltx_td ltx_align_left\">40.1 (+1.72%)</td>\n<td id=\"S4.T1.4.12.6.4\" class=\"ltx_td ltx_align_left\">43.0 (+0.23%)</td>\n<td id=\"S4.T1.4.12.6.5\" class=\"ltx_td ltx_align_left\">54.0 (-1.30%)</td>\n</tr>\n<tr id=\"S4.T1.4.13.7\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.13.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Multi w/ visual (EVA-CLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib34\" title=\"\" class=\"ltx_ref\">34</a>]</cite>)</th>\n<td id=\"S4.T1.4.13.7.2\" class=\"ltx_td ltx_align_left\">15.9 (+3.05%)</td>\n<td id=\"S4.T1.4.13.7.3\" class=\"ltx_td ltx_align_left\">40.2 (+1.47%)</td>\n<td id=\"S4.T1.4.13.7.4\" class=\"ltx_td ltx_align_left\">43.4 (+1.17%)</td>\n<td id=\"S4.T1.4.13.7.5\" class=\"ltx_td ltx_align_left\">53.9 (-1.46%)</td>\n</tr>\n<tr id=\"S4.T1.4.14.8\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.14.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">Multi w/ visual (SigLIP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">33</a>]</cite>)</th>\n<td id=\"S4.T1.4.14.8.2\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T1.4.14.8.2.1\" class=\"ltx_text ltx_font_bold\">15.7 (+4.27%)</span></td>\n<td id=\"S4.T1.4.14.8.3\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T1.4.14.8.3.1\" class=\"ltx_text ltx_font_bold\">39.4 (+3.43%)</span></td>\n<td id=\"S4.T1.4.14.8.4\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T1.4.14.8.4.1\" class=\"ltx_text ltx_font_bold\">43.5 (+1.40%)</span></td>\n<td id=\"S4.T1.4.14.8.5\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T1.4.14.8.5.1\" class=\"ltx_text ltx_font_bold\">54.8 (+0.18%)</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Table 1 shows the experimental results evaluating the impact of visual features in both single-task and multi-task settings. Our methodology is evaluated across three distinct tasks: ASR, ST, and MT. Furthermore, we explore the effectiveness of three different visual encoders\u00a0[32, 34, 33] to determine which encoder best aligns with speech-text discrete representations.",
            "Compare with the SOTA methods.\nIn Table 3, we compare our model with state-of-the-art methods on the AV-ASR task. The results demonstrate that our approach surpasses most of the methods when utilizing only the How2 dataset. Note that, both AVATAR [4] and AVFormer [5] pretrain on the vast HowTo100M [38] dataset, which makes them perform well explicitly on single AV-ASR task. Contrary to the design purposes of these models, we aim to explore an unified model architecture for different audio-visual related tasks. Under the multitasking scenario, our model not only retains high performance in the AV-ASR task but also surpasses the How2 baseline in ST and MT tasks. Specifically, as shown in Table 1, we observed a significant improvement in the BLEU score for ST, increasing from 37.2 to 43.5. Similarly, for MT, there was a modest enhancement from 54.4 to 54.8 in the BLEU score."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Ablation Study. Experimental AV-ASR task results comparing the visual influence on multi-task SigLIP[33] encoder. Random visual means randomly select the visual features from other video clips.",
        "table": "<table id=\"S4.T2.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.2.3\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"></th>\n<th id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S4.T2.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T2.1.1.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.1.1.1.1.2.1.1\" class=\"ltx_text ltx_font_bold\">ASR (How2)</span></td>\n</tr>\n<tr id=\"S4.T2.1.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">WER(<math id=\"S4.T2.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.1.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.1.1.1.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.1.1.1.m1.1.1.cmml\">&#8595;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.1.1.1.m1.1b\"><ci id=\"S4.T2.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.1.1.1.m1.1.1\">&#8595;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>)</td>\n</tr>\n</table>\n</th>\n<th id=\"S4.T2.2.2.2\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S4.T2.2.2.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T2.2.2.2.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.2.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.2.2.2.1.2.1.1\" class=\"ltx_text ltx_font_bold\">ASR (Visspeech)</span></td>\n</tr>\n<tr id=\"S4.T2.2.2.2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.2.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">WER(<math id=\"S4.T2.2.2.2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.2.2.2.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.2.2.2.1.1.1.m1.1.1\" xref=\"S4.T2.2.2.2.1.1.1.m1.1.1.cmml\">&#8595;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.1.1.1.m1.1b\"><ci id=\"S4.T2.2.2.2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.1.1.1.m1.1.1\">&#8595;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>)</td>\n</tr>\n</table>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.2.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Multi w/o visual</th>\n<td id=\"S4.T2.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">16.4</td>\n<td id=\"S4.T2.2.3.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">40.8</td>\n</tr>\n<tr id=\"S4.T2.2.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Multi w random visual</th>\n<td id=\"S4.T2.2.4.2.2\" class=\"ltx_td ltx_align_center\">16.4</td>\n<td id=\"S4.T2.2.4.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">41.0</td>\n</tr>\n<tr id=\"S4.T2.2.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Multi w visual</th>\n<td id=\"S4.T2.2.5.3.2\" class=\"ltx_td ltx_align_center\">15.9</td>\n<td id=\"S4.T2.2.5.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">39.4</td>\n</tr>\n<tr id=\"S4.T2.2.6.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">Multi w visual + synthetic</th>\n<td id=\"S4.T2.2.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.2.6.4.2.1\" class=\"ltx_text ltx_font_bold\">15.7</span></td>\n<td id=\"S4.T2.2.6.4.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S4.T2.2.6.4.3.1\" class=\"ltx_text ltx_font_bold\">39.4</span></td>\n</tr>\n</tbody>\n</table>\n<table id=\"S4.T2.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T2.1.1.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.1.1.1.1.2.1.1\" class=\"ltx_text ltx_font_bold\">ASR (How2)</span></td>\n</tr>\n<tr id=\"S4.T2.1.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">WER(<math id=\"S4.T2.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.1.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.1.1.1.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.1.1.1.m1.1.1.cmml\">&#8595;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.1.1.1.m1.1b\"><ci id=\"S4.T2.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.1.1.1.m1.1.1\">&#8595;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>)</td>\n</tr>\n</table>\n<table id=\"S4.T2.2.2.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T2.2.2.2.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.2.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T2.2.2.2.1.2.1.1\" class=\"ltx_text ltx_font_bold\">ASR (Visspeech)</span></td>\n</tr>\n<tr id=\"S4.T2.2.2.2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.2.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">WER(<math id=\"S4.T2.2.2.2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.2.2.2.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.2.2.2.1.1.1.m1.1.1\" xref=\"S4.T2.2.2.2.1.1.1.m1.1.1.cmml\">&#8595;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.1.1.1.m1.1b\"><ci id=\"S4.T2.2.2.2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.1.1.1.m1.1.1\">&#8595;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>)</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "There are some notable instances where the visual modality enhances ASR task performance. As demonstrated in Figure 3, visual cues are instrumental in recognizing seldom-used vocabulary, especially when there is a strong correlation between the visual content and these specific words. This highlights the potential of language models to comprehend visual information and merge it with speech data for a multimodal understanding. The findings indicate that incorporating SynesLM's visual modality consistently enhances performance across all the tasks when compared to an audio-only baseline (e.g., improving the WER from 16.4% to 15.7% in a multitask setting using SigLIP [33]). Among the visual encoders tested, CLIP [32] achieves the highest performance in single-task experiments. On the other hand, in the multitask framework, SigLIP [33] demonstrates superior efficacy, notably achieving a 3.43% relative performance increase in the zero-shot AV-ASR on the VisSpeech [4] dataset. Furthermore, to delve deeper into the impact of visual features, we conduct an ablation study where the visual input is replaced with a random image. As shown in Table 2, the WER for the random visual input scenario increases from 15.7% to 16.4%, which is the same as the performance without visual input. In addition, our synthetic data recovery technique further improves the performance from 15.9% to 15.7%, indicating that better audio-visual correlation could further benefit model performance. This outcome underscores the robustness of our model in audio-visual tasks."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Comparison with the state-of-the-art on AV-ASR task. The train set section for last two rows indicates that those methods use additional dataset other then How2 [12] for pre-training. \u2020 denotes initialization with OPT. Results are reported as WER (%, lower is better).",
        "table": "<table id=\"S4.T3.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.5.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\"><span id=\"S4.T3.5.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<td id=\"S4.T3.5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T3.5.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Train Set</span></td>\n<th id=\"S4.T3.5.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\"><span id=\"S4.T3.5.1.1.3.1\" class=\"ltx_text ltx_font_bold\">How2</span></th>\n<td id=\"S4.T3.5.1.1.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\"><span id=\"S4.T3.5.1.1.4.1\" class=\"ltx_text ltx_font_bold\">VisSpeech</span></td>\n</tr>\n<tr id=\"S4.T3.5.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">How2 Base <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">12</a>]</cite>\n</th>\n<td id=\"S4.T3.5.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">300hrs</td>\n<th id=\"S4.T3.5.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">18.0</th>\n<td id=\"S4.T3.5.2.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S4.T3.5.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">LLD <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib42\" title=\"\" class=\"ltx_ref\">42</a>]</cite>\n</th>\n<td id=\"S4.T3.5.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">300hrs</td>\n<th id=\"S4.T3.5.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">16.7</th>\n<td id=\"S4.T3.5.3.3.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T3.5.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">VAT <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib43\" title=\"\" class=\"ltx_ref\">43</a>]</cite>\n</th>\n<td id=\"S4.T3.5.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">300hrs</td>\n<th id=\"S4.T3.5.4.4.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">18.0</th>\n<td id=\"S4.T3.5.4.4.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T3.5.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">MultiRes <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib44\" title=\"\" class=\"ltx_ref\">44</a>]</cite>\n</th>\n<td id=\"S4.T3.5.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">300hrs</td>\n<th id=\"S4.T3.5.5.5.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">20.5</th>\n<td id=\"S4.T3.5.5.5.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T3.5.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.6.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">AVATAR <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib4\" title=\"\" class=\"ltx_ref\">4</a>]</cite>\n</th>\n<td id=\"S4.T3.5.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">300hrs</td>\n<th id=\"S4.T3.5.6.6.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><span id=\"S4.T3.5.6.6.3.1\" class=\"ltx_text ltx_font_bold\">15.6</span></th>\n<td id=\"S4.T3.5.6.6.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">43.4</td>\n</tr>\n<tr id=\"S4.T3.5.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.7.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><span id=\"S4.T3.5.7.7.1.1\" class=\"ltx_text ltx_font_bold\">Ours<sup id=\"S4.T3.5.7.7.1.1.1\" class=\"ltx_sup\">&#8224;</sup></span></th>\n<td id=\"S4.T3.5.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">300hrs</td>\n<th id=\"S4.T3.5.7.7.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">15.7</th>\n<td id=\"S4.T3.5.7.7.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S4.T3.5.7.7.4.1\" class=\"ltx_text ltx_font_bold\">39.4</span></td>\n</tr>\n<tr id=\"S4.T3.5.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.8.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">AVFormer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a>]</cite>\n</th>\n<td id=\"S4.T3.5.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">960hrs + 6500hrs</td>\n<th id=\"S4.T3.5.8.8.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">13.6</th>\n<td id=\"S4.T3.5.8.8.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">16.6</td>\n</tr>\n<tr id=\"S4.T3.5.9.9\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.9.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">AVATAR <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib4\" title=\"\" class=\"ltx_ref\">4</a>]</cite>\n</th>\n<td id=\"S4.T3.5.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_r\">300hrs + 131k hrs</td>\n<th id=\"S4.T3.5.9.9.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">9.1</th>\n<td id=\"S4.T3.5.9.9.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">11.3</td>\n</tr>\n<tr id=\"S4.T3.5.10.10\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.10.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">Prompt-whisper <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib30\" title=\"\" class=\"ltx_ref\">30</a>]</cite>\n</th>\n<td id=\"S4.T3.5.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">680k hrs</td>\n<th id=\"S4.T3.5.10.10.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">-</th>\n<td id=\"S4.T3.5.10.10.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">7.16</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Performance: We achieved improved performance across all tasks, recording a 4.0% WER absolute improvement in zero-shot AV-ASR and BLEU scores of 43.5 for VST and 54.8 for VMT, showcasing our model's strong audio processing and visual comprehension capabilities (Table 3).",
            "Compare with the SOTA methods.\nIn Table 3, we compare our model with state-of-the-art methods on the AV-ASR task. The results demonstrate that our approach surpasses most of the methods when utilizing only the How2 dataset. Note that, both AVATAR [4] and AVFormer [5] pretrain on the vast HowTo100M [38] dataset, which makes them perform well explicitly on single AV-ASR task. Contrary to the design purposes of these models, we aim to explore an unified model architecture for different audio-visual related tasks. Under the multitasking scenario, our model not only retains high performance in the AV-ASR task but also surpasses the How2 baseline in ST and MT tasks. Specifically, as shown in Table 1, we observed a significant improvement in the BLEU score for ST, increasing from 37.2 to 43.5. Similarly, for MT, there was a modest enhancement from 54.4 to 54.8 in the BLEU score."
        ]
    }
}