{
    "S4.T1": {
        "caption": "Table 1: Rank-correlation of importance maps with human attention maps (higher is better). The last row represents inter-human agreement.",
        "table": "<table id=\"S4.T1.4.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.4.4.5.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.5.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"></th>\n<th id=\"S4.T1.4.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S4.T1.4.4.5.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Rank-correlation</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S4.T1.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Random</span></th>\n<td id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span id=\"S4.T1.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.000 </span><math id=\"S4.T1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.1.m1.1a\"><mo mathsize=\"90%\" id=\"S4.T1.1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.1.m1.1c\">\\pm</annotation></semantics></math><span id=\"S4.T1.1.1.1.1.2\" class=\"ltx_text\" style=\"font-size:90%;\"> 0.001</span>\n</td>\n</tr>\n<tr id=\"S4.T1.2.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S4.T1.2.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Occlusion</span></th>\n<td id=\"S4.T1.2.2.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span id=\"S4.T1.2.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.173 </span><math id=\"S4.T1.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.T1.2.2.2.1.m1.1a\"><mo mathsize=\"90%\" id=\"S4.T1.2.2.2.1.m1.1.1\" xref=\"S4.T1.2.2.2.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.2.2.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T1.2.2.2.1.m1.1.1.cmml\" xref=\"S4.T1.2.2.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.2.2.2.1.m1.1c\">\\pm</annotation></semantics></math><span id=\"S4.T1.2.2.2.1.2\" class=\"ltx_text\" style=\"font-size:90%;\"> 0.004</span>\n</td>\n</tr>\n<tr id=\"S4.T1.3.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S4.T1.3.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Guided backpropagation</span></th>\n<td id=\"S4.T1.3.3.3.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span id=\"S4.T1.3.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.292 </span><math id=\"S4.T1.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.T1.3.3.3.1.m1.1a\"><mo mathsize=\"90%\" id=\"S4.T1.3.3.3.1.m1.1.1\" xref=\"S4.T1.3.3.3.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.3.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T1.3.3.3.1.m1.1.1.cmml\" xref=\"S4.T1.3.3.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.3.3.3.1.m1.1c\">\\pm</annotation></semantics></math><span id=\"S4.T1.3.3.3.1.2\" class=\"ltx_text\" style=\"font-size:90%;\"> 0.004</span>\n</td>\n</tr>\n<tr id=\"S4.T1.4.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S4.T1.4.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Human</span></th>\n<td id=\"S4.T1.4.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span id=\"S4.T1.4.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.623 </span><math id=\"S4.T1.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.T1.4.4.4.1.m1.1a\"><mo mathsize=\"90%\" id=\"S4.T1.4.4.4.1.m1.1.1\" xref=\"S4.T1.4.4.4.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.4.4.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T1.4.4.4.1.m1.1.1.cmml\" xref=\"S4.T1.4.4.4.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.4.4.4.1.m1.1c\">\\pm</annotation></semantics></math><span id=\"S4.T1.4.4.4.1.2\" class=\"ltx_text\" style=\"font-size:90%;\"> 0.003</span>\n</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "We evaluate the quality of image importance maps obtained from the two methods (guided backpropagation and occlusion) by comparing them to the human attention maps.\nThe human attention dataset contains annotations for 1374 (question, image) pairs from VQA\n[Antol et al., 2015]\nvalidation set.\nFollowing the evaluation protocol in [Das et al., 2016],\nwe take the absolute value of the importance maps and compute their mean rank-correlation with the human attention maps.\nSpecifically, we first scale both the image importance and human attention\nmaps to 14x14, normalize them spatially and\nrank the pixels according to their spatial attention,\nand then compute correlation between these two\nranked lists.\nThe results are shown in Table 1.\nWe find that both importance maps (occlusion and guided BP) are weakly positively correlated with human attention maps, although it is far from inter-human correlation.\nThus, our techniques revealed an interesting finding – that even without attention mechanisms, VQA models may be implicitly attending to relevant regions in the image."
        ]
    }
}