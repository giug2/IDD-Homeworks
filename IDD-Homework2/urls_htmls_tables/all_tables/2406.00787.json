{
    "S4.T1.1": {
        "caption": "Datasets used for evaluating different target languages. The Dataset Size describes the number of sentences in the dataset.\nRussian and German datasets are described in  ’s paper. The Hebrew dataset is based on the Opus TED talks dataset  .",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.1\">Language</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.2\">Dataset Name</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.3\">Dataset Size</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.2.1.1\">Russian</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.2.1.2\">newstest2019</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.2.1.3\">1997</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.3.2.1\">German</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.3.2.2\">newstest2012</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.3.2.3\">3003</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.1.4.3.1\">Hebrew</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T1.1.4.3.2\">TED dev</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.1.4.3.3\">1000</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [
            [],
            []
        ],
        "references": [
            "For extrinsic debiasing measurement, we employ the automatic accuracy metric from Stanovsky et al. (2019), assessing the percentage of instances where the target entity retains its original gender from the English sentence, using morphological markers in the target language.\nWe focus on the performance on the anti-stereotypical set of 1584 sentences from WinoMT (Stanovsky et al., 2019). These consist of anti-stereotypical gender role assignments, such as the female doctor in Example 1.\nIn addition, we approximate the translation quality before and after debiasing using BLEU  (Papineni et al., 2002) on several parallel corpora described in Table 1, and manually evaluate the translations to corroborate our findings.\nFinally, all results are statistically significant with p-value <0.05absent0.05<0.05< 0.05, see Appendix C for details.\n"
        ]
    },
    "S4.T2.1.1": {
        "caption": "Accuracy on different target languages when varying the tokens debiasing strategy. Presenting results for applying (1) the baseline (no-debiasing), (2)  , debiasing tokens corresponding to professions that are tokenized into one or more tokens, and (3)  , debiasing only professions that are tokenized into a single token. For brevity, each cell presents the the best performing choice of embedding table and debiasing method.\n",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T2.1.1.1.1.1\">Target Language</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.1.2\">German</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.1.3\">Hebrew</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.1.4\">Russian</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T2.1.1.2.2.1\">no-debiasing</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.2.2.2\">57.7</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.2.2.3\">45.6</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.2.2.4\">41.0</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.1.3.1.1\">n-token-profession</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.3.1.2\">60.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.3.1.3\">48.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.3.1.4\">41.0</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.1.1.4.2.1\">1-token-profession</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.1.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.4.2.2.1\">61.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.1.4.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.4.2.3.1\">48.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.1.4.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.4.2.4.1\">41.2</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Table 2 shows the gender translation accuracy when applying debiasing methods on different tokens. 555Excluding results for debiasing all tokens, as it led to garbled translations where automatic debiasing measures are irrelevant.\nFor the three tested languages, debiasing only professions that are tokenized into single tokens improved the gender prediction the most.\nThis hints that the sub-word tokens that compose a profession word do not hold the same gender information as the whole word.\n\n",
            "Debiasing has a positive impact on the accuracy of gender translation in both German and Hebrew, with German improving by 3.7 points and Hebrew by 2.8 points. In contrast, Russian did not see as much improvement (Table 2).\nThe difference may be due to Russian’s relatively rich morphology (e.g., it has 7 cases compared to 4 in German (Dryer and Haspelmath, 2013)), resulting in much fewer single-token professions (59% in Russian compared to 65% in Hebrew, and 83% in German).\n"
        ]
    },
    "S4.T3.1.1": {
        "caption": "Opus MT’s gender prediction accuracy with intrinsic debiasing methods applied on different embedding tables. Each cell is averaged across our target languages ( ). Bold numbers represent best per debiasing method. The accuracy is measured by  ’s method on their WinoMT dataset",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T3.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.1.1\">Embedding Table</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.2.1\">Baseline</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.3.1\">Hard-Debiasing</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.4.1\">INLP</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.1.1.5.1\">LEACE</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.1.1.2.1.1\">Encoder Input</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.1.2\">48.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.2.1.3.1\">49.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.1.4\">43.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.1.1.2.1.5\">43.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.1.1.3.2.1\">Decoder Input</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.3.2.2\">48.1</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.3.2.3\">48.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.3.2.4\">50.0</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.1.1.3.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.3.2.5.1\">53.8</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T3.1.1.4.3.1\">Decoder Output</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.1.1.4.3.2\">48.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.1.1.4.3.3\">48.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.1.1.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.4.3.4.1\">50.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.1.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.4.3.5.1\">53.8</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [
            []
        ],
        "references": [
            "Table 3 shows the improvement in gender prediction averaged across languages when applied on different embedding tables.\nHard-Debiasing improves gender prediction only when debiasing the encoder’s inputs, while INLP and LEACE improves gender prediction accuracy the most when applied to the decoder output.\nThis may be explained by INLP’s and LEACE’s linearity, which therefore works best at the end of the decoder, after all nonlinear layers, while Hard-Debiasing employs a non-linear PCA component.666We tested debiasing all 8 combinations of the three embedding tables, but this did not change our findings.\n"
        ]
    }
}