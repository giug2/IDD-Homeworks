{
    "PAPER'S NUMBER OF TABLES": 3,
    "S3.T1": {
        "caption": "Table 1: The comprehensive statistics, which encompass various clients within the LoRA system implementation, are validated using a range of metrics such as rouge1, rouge2, rouge3, and BLEU. Furthermore, these statistics illustrate the accuracies of the global federated server.",
        "table": "<table id=\"S3.T1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Metrics</span></th>\n<th id=\"S3.T1.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">LoRA Federated</span></th>\n<th id=\"S3.T1.1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">LoRA Client 1</span></th>\n<th id=\"S3.T1.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">LoRA Client 2</span></th>\n<th id=\"S3.T1.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">LoRA Client 3</span></th>\n<th id=\"S3.T1.1.1.1.1.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">LoRA Client 4</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Rouge - 1</span></td>\n<td id=\"S3.T1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.383</td>\n<td id=\"S3.T1.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.124</td>\n<td id=\"S3.T1.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">31.824</td>\n<td id=\"S3.T1.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.864</td>\n<td id=\"S3.T1.1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.372</td>\n</tr>\n<tr id=\"S3.T1.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.3.2.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Rouge - 2</span></td>\n<td id=\"S3.T1.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">8.245</td>\n<td id=\"S3.T1.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">8.653</td>\n<td id=\"S3.T1.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">8.119</td>\n<td id=\"S3.T1.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7.969</td>\n<td id=\"S3.T1.1.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7.932</td>\n</tr>\n<tr id=\"S3.T1.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.4.3.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Rouge - l</span></td>\n<td id=\"S3.T1.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">26.804</td>\n<td id=\"S3.T1.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">25.939</td>\n<td id=\"S3.T1.1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">25.408</td>\n<td id=\"S3.T1.1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">25.404</td>\n<td id=\"S3.T1.1.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">26.819</td>\n</tr>\n<tr id=\"S3.T1.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.5.4.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">BLEU - 4</span></td>\n<td id=\"S3.T1.1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.334</td>\n<td id=\"S3.T1.1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.932</td>\n<td id=\"S3.T1.1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.335</td>\n<td id=\"S3.T1.1.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.467</td>\n<td id=\"S3.T1.1.1.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.352</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Context GPT Evaluation: For the evaluation of the models generated by the client machines, we employed metric scales such as Rouge-1, Rouge-2, Rouge-L, and BLEU-4. These metrics assess the quality of the generated output by evaluating the uni-grams, bi-grams, and N-grams of word sequences in comparison to the original sentences. Table 1 provides a detailed breakdown of these evaluation metrics for both the global server and the four client machines, highlighting the overall performance across different measurement scales. Additionally, Table 2 showcases the performance levels achieved by implementing the P-Tuning PEFT strategy, incorporating the latest version for enhanced accuracy. Furthermore, Table 3 offers insights into the training parameters and sizes of the GPT-generated models across the client machines, illustrating the various trainable model sizes and parameters."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Extensive statistics covering various clients within the P-Tuning-v2 system implementation, validated using diverse metrics including Rouge-1, Rouge-2, Rouge-L, and BLEU. Additionally, the table depicts the accuracies of the global federated server.",
        "table": "<table id=\"S3.T2.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Metrics</span></td>\n<td id=\"S3.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">P-Tuning-v2 Federated</span></td>\n<td id=\"S3.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">P-Tuning-v2 Client 1</span></td>\n<td id=\"S3.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">P-Tuning-v2 Client 2</span></td>\n<td id=\"S3.T2.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">P-Tuning-v2 Client 3</span></td>\n<td id=\"S3.T2.1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">P-Tuning-v2 Client 4</span></td>\n</tr>\n<tr id=\"S3.T2.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.2.2.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Rouge - 1</span></td>\n<td id=\"S3.T2.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.132</td>\n<td id=\"S3.T2.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.283</td>\n<td id=\"S3.T2.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">34.734</td>\n<td id=\"S3.T2.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">31.881</td>\n<td id=\"S3.T2.1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.674</td>\n</tr>\n<tr id=\"S3.T2.1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.3.3.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Rouge - 2</span></td>\n<td id=\"S3.T2.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7.899</td>\n<td id=\"S3.T2.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">8.879</td>\n<td id=\"S3.T2.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7.126</td>\n<td id=\"S3.T2.1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7.268</td>\n<td id=\"S3.T2.1.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7.121</td>\n</tr>\n<tr id=\"S3.T2.1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.4.4.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Rouge - l</span></td>\n<td id=\"S3.T2.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">25.532</td>\n<td id=\"S3.T2.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">25.814</td>\n<td id=\"S3.T2.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">25.153</td>\n<td id=\"S3.T2.1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">25.734</td>\n<td id=\"S3.T2.1.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">25.237</td>\n</tr>\n<tr id=\"S3.T2.1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.5.5.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">BLEU - 4</span></td>\n<td id=\"S3.T2.1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.245</td>\n<td id=\"S3.T2.1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.392</td>\n<td id=\"S3.T2.1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.736</td>\n<td id=\"S3.T2.1.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.829</td>\n<td id=\"S3.T2.1.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.981</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Context GPT Evaluation: For the evaluation of the models generated by the client machines, we employed metric scales such as Rouge-1, Rouge-2, Rouge-L, and BLEU-4. These metrics assess the quality of the generated output by evaluating the uni-grams, bi-grams, and N-grams of word sequences in comparison to the original sentences. Table 1 provides a detailed breakdown of these evaluation metrics for both the global server and the four client machines, highlighting the overall performance across different measurement scales. Additionally, Table 2 showcases the performance levels achieved by implementing the P-Tuning PEFT strategy, incorporating the latest version for enhanced accuracy. Furthermore, Table 3 offers insights into the training parameters and sizes of the GPT-generated models across the client machines, illustrating the various trainable model sizes and parameters."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: The detailed statistics encompassing various trainable model parameters and sizes are essential components of our federated learning implementation aimed at constructing a context-based GPT.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Methods</span></td>\n<td id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Model Size (MB)</span></td>\n<td id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Param Percent (%)</span></td>\n</tr>\n<tr id=\"S4.T3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.2.2.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Global Sever</span></td>\n<td id=\"S4.T3.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">6173</td>\n<td id=\"S4.T3.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n</tr>\n<tr id=\"S4.T3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.3.3.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">LoRA</span></td>\n<td id=\"S4.T3.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.6</td>\n<td id=\"S4.T3.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.058</td>\n</tr>\n<tr id=\"S4.T3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.4.4.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">P-Tuning-V2</span></td>\n<td id=\"S4.T3.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">29.3</td>\n<td id=\"S4.T3.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.475</td>\n</tr>\n<tr id=\"S4.T3.1.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.5.5.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Checkpoint</span></td>\n<td id=\"S4.T3.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">6.2</td>\n<td id=\"S4.T3.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.116</td>\n</tr>\n<tr id=\"S4.T3.1.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.6.6.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">Full Tuning</span></td>\n<td id=\"S4.T3.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">6173</td>\n<td id=\"S4.T3.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">100</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Context GPT Evaluation: For the evaluation of the models generated by the client machines, we employed metric scales such as Rouge-1, Rouge-2, Rouge-L, and BLEU-4. These metrics assess the quality of the generated output by evaluating the uni-grams, bi-grams, and N-grams of word sequences in comparison to the original sentences. Table 1 provides a detailed breakdown of these evaluation metrics for both the global server and the four client machines, highlighting the overall performance across different measurement scales. Additionally, Table 2 showcases the performance levels achieved by implementing the P-Tuning PEFT strategy, incorporating the latest version for enhanced accuracy. Furthermore, Table 3 offers insights into the training parameters and sizes of the GPT-generated models across the client machines, illustrating the various trainable model sizes and parameters."
        ]
    }
}