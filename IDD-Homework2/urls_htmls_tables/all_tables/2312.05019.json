{
    "id_table_1": {
        "caption": "",
        "table": [
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T1.4.1.1.1\">\n        <span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.1.1.1.1\">\n         Method Type\n        </span>\n       </th>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.1.1.2\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.1.1.2.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.1.1.2.1.1\" style=\"width:65.0pt;\">\n          <span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.1.1.2.1.1.1\">\n           Perception End\n          </span>\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.1.1.3\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.1.1.3.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.1.1.3.1.1\" style=\"width:65.0pt;\">\n          <span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.1.1.3.1.1.1\">\n           Control End\n          </span>\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.1.1.4\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.1.1.4.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.1.1.4.1.1\" style=\"width:43.4pt;\">\n          <span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.1.1.4.1.1.1\">\n           Key Studies\n          </span>\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.1.1.5\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.1.1.5.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.1.1.5.1.1\" style=\"width:151.8pt;\">\n          <span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.4.1.1.5.1.1.1\">\n           Description and Applicability\n          </span>\n         </span>\n        </span>\n       </td>\n      \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T1.4.2.2.1\" rowspan=\"2\">\n        <span class=\"ltx_text\" id=\"S4.T1.4.2.2.1.1\">\n         Indirect Methods\n        </span>\n       </th>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.2.2.2\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.2.2.2.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.2.2.2.1.1\" style=\"width:65.0pt;\">\n          Depth maps, 3D point cloud maps\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.2.2.3\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.2.2.3.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.2.2.3.1.1\" style=\"width:65.0pt;\">\n          Traditional optimization algorithms\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.2.2.4\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.2.2.4.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.2.2.4.1.1\" style=\"width:43.4pt;\">\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib85\" title=\"\">\n            85\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib86\" title=\"\">\n            86\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib87\" title=\"\">\n            87\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib91\" title=\"\">\n            91\n           </a>\n           ]\n          </cite>\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.2.2.5\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.2.2.5.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.2.2.5.1.1\" style=\"width:151.8pt;\">\n          Focus on generating visual odometry, depth maps, and 3D point cloud maps for path planning. Suitable for safety-critical tasks with accurate models.\n         </span>\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.3.3.1\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.3.3.1.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.3.3.1.1.1\" style=\"width:65.0pt;\">\n          Depth maps, 3D point cloud maps\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.3.3.2\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.3.3.2.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.3.3.2.1.1\" style=\"width:65.0pt;\">\n          Online path planning, APF, etc.\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.3.3.3\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.3.3.3.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.3.3.3.1.1\" style=\"width:43.4pt;\">\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib27\" title=\"\">\n            27\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib92\" title=\"\">\n            92\n           </a>\n           ]\n          </cite>\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.3.3.4\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.3.3.4.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.3.3.4.1.1\" style=\"width:151.8pt;\">\n          Utilize depth information for real-time visual perception and decision-making in dynamic environments. Suitable for rapid response tasks with certain information.\n         </span>\n        </span>\n       </td>\n      \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.1\" rowspan=\"2\">\n        <span class=\"ltx_text\" id=\"S4.T1.4.4.4.1.1\">\n         End-to-End Methods\n        </span>\n       </th>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.2\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.4.4.2.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.4.4.2.1.1\" style=\"width:65.0pt;\">\n          Visual observations encoded by DNNs\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.3\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.4.4.3.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.4.4.3.1.1\" style=\"width:65.0pt;\">\n          RL for action mapping\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.4\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.4.4.4.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.4.4.4.1.1\" style=\"width:43.4pt;\">\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib56\" title=\"\">\n            56\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib103\" title=\"\">\n            103\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib104\" title=\"\">\n            104\n           </a>\n           ]\n          </cite>\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.4.4.5\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.4.4.5.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.4.4.5.1.1\" style=\"width:151.8pt;\">\n          Combine deep learning for visual perception with RL for direct action response. Suitable for complex tasks with uncertain information.\n         </span>\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.5.5.1\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.5.5.1.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.5.5.1.1.1\" style=\"width:65.0pt;\">\n          Encoded visual observations\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.5.5.2\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.5.5.2.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.5.5.2.1.1\" style=\"width:65.0pt;\">\n          Imitation learning and online training\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.5.5.3\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.5.5.3.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.5.5.3.1.1\" style=\"width:43.4pt;\">\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib127\" title=\"\">\n            127\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib28\" title=\"\">\n            28\n           </a>\n           ]\n          </cite>\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.5.5.4\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.5.5.4.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.5.5.4.1.1\" style=\"width:151.8pt;\">\n          Use deep learning for visual encoding and train the control system with expert demonstrations and online training. Suitable for sample-efficient tasks with expert demonstrations.\n         </span>\n        </span>\n       </td>\n      \n"
            ],
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T1.4.6.6.1\" rowspan=\"2\">\n        <span class=\"ltx_text\" id=\"S4.T1.4.6.6.1.1\">\n         Semi-Direct Methods\n        </span>\n       </th>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.6.6.2\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.6.6.2.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.6.6.2.1.1\" style=\"width:65.0pt;\">\n          Intermediate features from image processing\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.6.6.3\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.6.6.3.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.6.6.3.1.1\" style=\"width:65.0pt;\">\n          DRL for action\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.6.6.4\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.6.6.4.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.6.6.4.1.1\" style=\"width:43.4pt;\">\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib83\" title=\"\">\n            83\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib125\" title=\"\">\n            125\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib15\" title=\"\">\n            15\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib128\" title=\"\">\n            128\n           </a>\n           ]\n          </cite>\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" id=\"S4.T1.4.6.6.5\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.6.6.5.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.6.6.5.1.1\" style=\"width:151.8pt;\">\n          Extract intermediate features like relative positions or velocities and use DRL for action decisions. Suitable for complex tasks with high generalization requirement.\n         </span>\n        </span>\n       </td>\n      \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T1.4.7.7.1\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.7.7.1.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.7.7.1.1.1\" style=\"width:65.0pt;\">\n          Raw image data for depth images or obstacle tracking\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T1.4.7.7.2\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.7.7.2.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.7.7.2.1.1\" style=\"width:65.0pt;\">\n          Numerical/Heuristic methods for obstacle avoidance\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T1.4.7.7.3\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.7.7.3.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.7.7.3.1.1\" style=\"width:43.4pt;\">\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib126\" title=\"\">\n            126\n           </a>\n           ]\n          </cite>\n          ,\n          <cite class=\"ltx_cite ltx_citemacro_cite\">\n           [\n           <a class=\"ltx_ref\" href=\"#bib.bib45\" title=\"\">\n            45\n           </a>\n           ]\n          </cite>\n         </span>\n        </span>\n       </td>\n       \n",
                "<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T1.4.7.7.4\">\n        <span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T1.4.7.7.4.1\">\n         <span class=\"ltx_p\" id=\"S4.T1.4.7.7.4.1.1\" style=\"width:151.8pt;\">\n          Utilize direct image data to obtain necessary states for obstacle avoidance using non-learning-based methods. Suitable for tasks where robust stereo information is not available.\n         </span>\n        </span>\n       </td>\n      \n"
            ]
        ],
        "footnotes": [],
        "references": [
            "In summary, the field of vision-based control for drones encompasses a variety of methods, each with its own unique approach to perception and control. Indirect methods rely on traditional optimization algorithms and depth or 3D point cloud maps for navigation and obstacle avoidance. End-to-end methods leverage deep neural networks for visual perception and utilize reinforcement learning for direct action mapping. Semi-direct methods balance between computational efficiency and generalization by using intermediate features from image processing and a combination of DRL and heuristic methods for action generation. A comprehensive overview of these methods, along with key studies in each category, is summarized in Table                  1                , which provides a detailed comparison of their perception and control strategies."
        ]
    }
}