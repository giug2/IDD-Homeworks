{
    "id_table_1": {
        "caption": "TABLE I:  A comparison of the grouping accuracy (GA) and parsing accuracy (PA) for the state-of-the-art parsers and OpenLogParser.",
        "table": "S5.T1.1.1",
        "footnotes": [],
        "references": [
            "Real-world software systems generate large amounts of logs, often hundreds of gigabytes or even terabytes per day  [ 19 ,  11 ,  48 ] . These logs provide developers with invaluable runtime information, essential for understanding system execution and debugging. To manage and analyze this vast amount of data, researchers and practitioners have proposed many automated approaches, such as monitoring  [ 8 ,  43 ] , anomaly detection  [ 25 ,  40 ] , and root cause analysis  [ 46 ,  33 ] .  However, as shown in Figure  1 , logs are semi-structured, containing a mixture of static text and dynamically generated variables (e.g., port number  62267 ), which makes direct analysis challenging.",
            "Log parsing is a critical first step in log analysis that transforms unstructured logs into log templates, dividing logs into static parts (static messages) and dynamic parts (variables). As illustrated in Figure  1 , log templates represent the event structure of logs, providing a standardized format that simplifies further analysis. By distinguishing between static and dynamic components, log parsing enables more efficient and accurate downstream tasks  [ 22 ,  37 ,  26 ] .  Given the sheer volume and diversity of generated logs, prior research has proposed various syntax-based parsers for efficient and effective log parsing. These parsers, such as Drain  [ 14 ]  and AEL  [ 18 ] , use manually crafted heuristics or predefined rules to identify and extract log templates. Although promising, these log parsers often experience decreased accuracy when processing logs that deviate from predefined rules  [ 48 ,  21 ,  19 ] ."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Number of logs and parsing time, in seconds, for the state-of-the-art (first four columns) and OpenLogParser.",
        "table": "S5.T2.1.1",
        "footnotes": [],
        "references": [
            "In this section, we introduce OpenLogParser, an efficient unsupervised log parser, leveraging memory capabilities and advanced prompting techniques to maximize efficiency and parsing accuracy. OpenLogParser leverages a smaller-size open-source LLM to enhance privacy and reduce operation costs. Figure  2  illustrates the overall architecture of OpenLogParser, which primarily comprises of three components:  (i)  log grouping , which groups logs that share a commonality in their text. Such log groups can then be used as input to LLM to uncover dynamic variables.  (ii) An  unsupervised LLM-based log parser  that uses retrieval-augmented generation (RAG), followed by an iterative self-reflection mechanism to accurately parse the grouped logs into log templates.  (iii) An  efficient log template memory , which memorizes the parsed log templates for future query. The core idea is to enhance efficiency by storing parsed log templates in memory, thereby avoiding the need for repeated LLM queries."
        ]
    },
    "id_table_3": {
        "caption": "TABLE III:  OpenLogParser performance under different settings. The numbers in the parenthesis indicate the percentage difference compared to the full version of OpenLogParser.",
        "table": "S5.T3.1.1",
        "footnotes": [],
        "references": [
            "Our prompts to LLMs contain representative logs (based on variability) retrieved from each log group (from Section  III-A ) to guide LLMs in separating dynamic variables and static text. Figure  3  illustrates the prompt template that OpenLogParser uses. Below, we discuss the composition of our prompt in detail.",
            "Prompt Instruction.   In the instruction part of our prompt, we define the goal of the log parsing task to the LLM (highlighted in green in Figure  3 ). We emphasize that all the provided logs should share one common template that matches all selected logs. This specification is crucial to ensure that the LLM can effectively identify the commonalities and variability within the provided logs, thereby preventing any difficulties in parsing due to inconsistent log templates.",
            "Standardizing LLM Response by Input and Output Example.   Since our LLM is not instruction fine-tuned  [ 31 ] , it is crucial to clearly describe our task instruction and include an input-output example in the prompt. This explicit guidance helps the LLM understand the desired input and output formats.  As shown in Figure  3 , we provide one example to illustrate the input/output form. The example remains unchanged for all systems.  This approach effectively guides the LLM in understanding the objective and input-output formats without the need of instruction fine-tuning or labeled data.",
            "Specifically, the logs selected from the log group are listed in the format of a Python list within the prompt for parsing. We use a prefix (i.e.,  Log list: ) to help the LLM identify the logs that require parsing (highlighted in yellow in Figure  3 ). This consistency in input format, mirroring the Input and Output Example, also guides the LLM to respond with the log template in a fixed format as demonstrated in the example, facilitating accurate template generation and extraction.",
            "Self-Reflection for Verifying Log Template.  After generating a log template, we verify whether the template can match each log within the group. If a log is correctly matched by a log template, we consider it to be parsed successfully. The log template is then added to the log template memory for future use. After all logs in the group have been checked, any unparsed logs undergo a  self-reflection  process  [ 38 ] , which aims to revise the templates and improve parsing results. Similar to the initial parsing attempt, we first select these unparsed logs and then utilize the prompt described in Figure  3  to generate a new log template using LLMs. This step is repeated until all logs in the group can be matched/parsed by the generated templates. Note that, to prevent the LLM from entering a parsing loop (i.e., repeatedly generating incorrect templates), we limit the self-reflection process to three iterations."
        ]
    },
    "id_table_4": {
        "caption": "TABLE IV:  Parsing performance of OpenLogParser using different LLMs.",
        "table": "S5.T4.1.1",
        "footnotes": [],
        "references": [
            "During retrieval augmented log parsing, varying the number of selected logs affects the performance of OpenLogParser. Retrieving three logs into the prompt yields the highest effectiveness.   Fig  4  shows the OpenLogParser performance with variations in the number of logs from a group retrieved into the prompts.  OpenLogParser maintains high accuracy across various sample sizes, with optimal performance achieved when the sample size is set to three, reaching peak values in both GA and PA. Notably, when the sample size is reduced to one, GA and PA drop to 0.80 and 0.70, respectively, representing a decline of 8.26% and 18% compared to a sample size of three. This reduction highlights the challenges LLM faces in parsing logs accurately without sufficient comparative data, such as multiple log comparisons or labeled logs. As the sample size increases from one to two, both GA and PA show significant improvements, peaking when the sample size reaches three. However, further increases in sample size from three to eight result in slight decreases in GA and PA, stabilizing around 0.865 and 0.835, respectively. This suggests that an excess of log samples may introduce noise, subsequently lowering performance  [ 47 ] . Importantly, when the sample size reaches 10, both GA and PA decrease compared to a sample size of eight. This decrease is attributed to prompt truncation caused by an overload of retrieved logs, which exceeds the context size of the LLM, resulting in incomplete input data."
        ]
    },
    "global_footnotes": []
}