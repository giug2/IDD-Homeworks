{
    "PAPER'S NUMBER OF TABLES": 13,
    "S3.T1": {
        "caption": "Table 1: Model summary for generic datasets.",
        "table": "<table id=\"S3.T1.sf1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.sf1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.sf1.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.1.1.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">Layer</span>\n</span>\n</th>\n<th id=\"S3.T1.sf1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Output Shape</th>\n<th id=\"S3.T1.sf1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Param #</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.sf1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.2.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.2.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.2.1.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">conv2d_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 26, 26, 32)</td>\n<td id=\"S3.T1.sf1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">320</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.3.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.3.2.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">max_pooling2d_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.3.2.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 13, 13, 32)</td>\n<td id=\"S3.T1.sf1.1.3.2.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.4.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.4.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.4.3.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">conv2d_1</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.4.3.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 11, 11, 64)</td>\n<td id=\"S3.T1.sf1.1.4.3.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">18496</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.5.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.5.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.5.4.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">max_pooling2d_1</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.5.4.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 5, 5, 64)</td>\n<td id=\"S3.T1.sf1.1.5.4.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.6.5.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.6.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.6.5.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">flatten_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.6.5.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 1600)</td>\n<td id=\"S3.T1.sf1.1.6.5.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.7.6.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.7.6.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.7.6.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">dropout_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.7.6.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 1600)</td>\n<td id=\"S3.T1.sf1.1.7.6.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.8.7.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.8.7.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.8.7.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">dense_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.8.7.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 10)</td>\n<td id=\"S3.T1.sf1.1.8.7.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">16010</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.9.8\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.9.8.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.9.8.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.9.8.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\"><span id=\"S3.T1.sf1.1.9.8.1.1.1.1\" class=\"ltx_text ltx_align_left ltx_inline-block\" style=\"width:0.0pt;\">Total params: 34,826</span></span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.9.8.2\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td id=\"S3.T1.sf1.1.9.8.3\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n</tr>\n<tr id=\"S3.T1.sf1.1.10.9\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.10.9.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.10.9.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.10.9.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\"><span id=\"S3.T1.sf1.1.10.9.1.1.1.1\" class=\"ltx_text ltx_align_left ltx_inline-block\" style=\"width:0.0pt;\">Trainable params: 34,826</span></span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.10.9.2\" class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td id=\"S3.T1.sf1.1.10.9.3\" class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n</tr>\n<tr id=\"S3.T1.sf1.1.11.10\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.11.10.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.11.10.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.11.10.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\"><span id=\"S3.T1.sf1.1.11.10.1.1.1.1\" class=\"ltx_text ltx_align_left ltx_inline-block\" style=\"width:0.0pt;\">Non-trainable params: 0</span></span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.11.10.2\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td id=\"S3.T1.sf1.1.11.10.3\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Models:\nOur models for generic datasets are simple convolutional neural networks with 12 and 7 layers for CIFAR-10 and Fashion MNIST, respectively, which are taken from Keras’ tutorials and examples (cif, 2021; mni, 2021). Table 1 shows a summary of the models used for Fashion MNIST and CIFAR-10 datasets.\nFor the ADNI dataset, we use a transfer learning (TL) approach using the VGG16 model (Simonyan and Zisserman, 2015) pre-trained on ImageNet (Russakovsky et al., 2015). Our classifier consists of one dense layer with 512 neurons and a rectified linear activation followed by a dense layer with two neurons and a softmax activation. The VGG16 weights were frozen during training."
        ]
    },
    "S3.T1.sf1": {
        "caption": "(a) Fashion MNIST",
        "table": "<table id=\"S3.T1.sf1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.sf1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.sf1.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.1.1.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">Layer</span>\n</span>\n</th>\n<th id=\"S3.T1.sf1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Output Shape</th>\n<th id=\"S3.T1.sf1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Param #</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.sf1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.2.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.2.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.2.1.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">conv2d_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 26, 26, 32)</td>\n<td id=\"S3.T1.sf1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">320</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.3.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.3.2.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">max_pooling2d_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.3.2.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 13, 13, 32)</td>\n<td id=\"S3.T1.sf1.1.3.2.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.4.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.4.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.4.3.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">conv2d_1</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.4.3.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 11, 11, 64)</td>\n<td id=\"S3.T1.sf1.1.4.3.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">18496</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.5.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.5.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.5.4.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">max_pooling2d_1</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.5.4.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 5, 5, 64)</td>\n<td id=\"S3.T1.sf1.1.5.4.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.6.5.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.6.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.6.5.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">flatten_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.6.5.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 1600)</td>\n<td id=\"S3.T1.sf1.1.6.5.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.7.6.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.7.6.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.7.6.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">dropout_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.7.6.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 1600)</td>\n<td id=\"S3.T1.sf1.1.7.6.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.8.7.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.8.7.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.8.7.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">dense_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.8.7.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 10)</td>\n<td id=\"S3.T1.sf1.1.8.7.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">16010</td>\n</tr>\n<tr id=\"S3.T1.sf1.1.9.8\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.9.8.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.9.8.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.9.8.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\"><span id=\"S3.T1.sf1.1.9.8.1.1.1.1\" class=\"ltx_text ltx_align_left ltx_inline-block\" style=\"width:0.0pt;\">Total params: 34,826</span></span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.9.8.2\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td id=\"S3.T1.sf1.1.9.8.3\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n</tr>\n<tr id=\"S3.T1.sf1.1.10.9\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.10.9.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.10.9.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.10.9.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\"><span id=\"S3.T1.sf1.1.10.9.1.1.1.1\" class=\"ltx_text ltx_align_left ltx_inline-block\" style=\"width:0.0pt;\">Trainable params: 34,826</span></span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.10.9.2\" class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td id=\"S3.T1.sf1.1.10.9.3\" class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n</tr>\n<tr id=\"S3.T1.sf1.1.11.10\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf1.1.11.10.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf1.1.11.10.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf1.1.11.10.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\"><span id=\"S3.T1.sf1.1.11.10.1.1.1.1\" class=\"ltx_text ltx_align_left ltx_inline-block\" style=\"width:0.0pt;\">Non-trainable params: 0</span></span>\n</span>\n</td>\n<td id=\"S3.T1.sf1.1.11.10.2\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td id=\"S3.T1.sf1.1.11.10.3\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Models:\nOur models for generic datasets are simple convolutional neural networks with 12 and 7 layers for CIFAR-10 and Fashion MNIST, respectively, which are taken from Keras’ tutorials and examples (cif, 2021; mni, 2021). Table 1 shows a summary of the models used for Fashion MNIST and CIFAR-10 datasets.\nFor the ADNI dataset, we use a transfer learning (TL) approach using the VGG16 model (Simonyan and Zisserman, 2015) pre-trained on ImageNet (Russakovsky et al., 2015). Our classifier consists of one dense layer with 512 neurons and a rectified linear activation followed by a dense layer with two neurons and a softmax activation. The VGG16 weights were frozen during training.",
            "Furthermore, the mean and std values reported in the tables are taken across different configurations (e.g., non-iid degree) described in their related sections. The mean is taken over different configurations instead of the median since we want to consider all configurations equally in the final result. These mean and std values should not be confused with the median taken across different runs (mean and std are applied to the results of different configurations reported in different figures.). Also, other metrics like the median of different configurations and also the raw results for each configuration can be found in our replication package.",
            "To address this concern, we show how the image is affected when it gets mutated by the Noise mutator with different sigma multipliers in Figure 5. As the sigma multiplier increases, the image gets noisier as expected. However, if we increase it too much, the image gets unrecognizable, like in Figure 5e. Since the Noise mutator is supposed to simulate faults, extreme values for the sigma multiplier become unacceptable, and this is the reason that we set this parameter to be one in our experiments.",
            "We report a summary of faults’ effect on Federated Averaging in Table 2. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are affected by the mutators. As the results show, the mutators do not significantly impact the accuracy. However, out of the mutators, the Noise mutator has the most impact on the final model, which is less than 6% and is insignificant. Note that the statistical test results here show that in 20% of the cases, these differences are statistically the same as well, but in 80%, they are statistically different. However, the amount of difference itself is not actually significant (less than 6%).",
            "Like the faults section, we report a summary of attacks against Federated Averaging in Table 3. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are under attack.\nAmong the untargeted attacks, Random Update and Sign Flip are the most effective attacks against Federated Averaging, with around 70% accuracy change. Furthermore, all the attacks are much more effective than mutators as they decrease the accuracy by at least 21.26% (the best mutator did not even reach 6%). Furthermore, the statistical test shows that all these changes are statistically different as well.",
            "We report a summary of aggregators for CIFAR-10 and Fashion MNIST in Table 4 based on the average accuracy of the final model on the test data and the number of times each aggregator was the most robust one. Note that only attacks are selected here since data mutators were ineffective and untargeted attacks and backdoor attacks were split to avoid confusion. As it can be seen, Krum achieves the best accuracy on average and achieves the top rank the most in the CIFAR-10 dataset, so all in all, it is the most robust aggregation method for that dataset. For Fashion MNIST, Median is the most robust aggregator. However, considering the first rank count of aggregators, Krum comes in a close second, but its mean accuracy is less than of the Median. This is because it achieves far worse results in the Label Flip attack.",
            "Following what we did in RQ2, we report the summary of aggregators for this dataset in Table 5. Unlike RQ2, the Overlap mutator is also included here since it showed to be effective for this dataset.",
            "According to the table, Trimmed Mean gets the best results for untargeted attacks and mutators, and Median comes in second with a negligible difference. All aggregators lose the competition to the attacker for the Backdoor attack except Krum, which shows decent robustness, but its main task accuracy can still be problematic.",
            "We report the results in Table 6. Out of these 12 configurations, the ensemble aggregator is the best option in Five cases, according to the median accuracies. Running statistical tests (Mann-Whitney U Test) shows that the ensemble is significantly better than the second technique in three cases out of five. However, in the remaining two cases, there is no significant difference. Furthermore, this difference is insignificant in four cases out of the seven remaining cases where the ensemble is not the best. As a result, in 75% of cases, the ensemble aggregator is the most reasonable choice. If were run the same test for other aggregators, Federated Averaging gets 25%, and the rest will achieve 33.3%, which clearly shows the ensemble method is superior.\nLastly, our ensemble technique achieves the highest mean accuracy compared to other aggregators.",
            "A summary of this paper’s contributions compared to some of the more related works is reported in Table 7.",
            "In this paper, we conducted a large-scale empirical study on the effect of faults and attacks on FL aggregators. We performed our experiments on two generic image datasets, each with three different distributions, one federated medical dataset, eight attacks and mutators, and four aggregation techniques resulting in 496 configurations.\nResults show that the Sign Flip and Backdoor attacks are the most effective attacks. Moreover, mutators do not significantly impact FL’s quality, except for the Overlap data mutator, which can affect Federated Averaging in the ADNI dataset. In addition, our study shows that there is no single best robust aggregator, and their accuracy depends on factors such as attack type, dataset, and data distribution. For instance, Krum is most robust in model poisoning attacks, but it is not acceptable in the Label Flip attacks. Inspired by the results of different aggregators, we show that an ensemble of these aggregators can be more robust than (or as good as) any single aggregator to improve the FL process quality in 75% of cases where the attacks and data distribution are unknown to the aggregator.\nIn the future, we plan to study different attack scenarios, e.g., a case where the attacker is aware of the aggregator used on the server. Also, we want to extend this study to other FL-exclusive issues, such as clients’ machines capabilities, learning frameworks, network failures, and arithmetic computation precision issues. Lastly, we want to extend the ensemble technique to make it effective against targeted attacks like the Backdoor attack and more efficient by using different heuristics while selecting the best aggregator in each round."
        ]
    },
    "S3.T1.sf2": {
        "caption": "(b) CIFAR-10",
        "table": "<table id=\"S3.T1.sf2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.sf2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.sf2.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.1.1.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">Layer</span>\n</span>\n</th>\n<th id=\"S3.T1.sf2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Output Shape</th>\n<th id=\"S3.T1.sf2.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Param #</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.sf2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.2.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.2.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.2.1.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">conv2d_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 32, 32, 32)</td>\n<td id=\"S3.T1.sf2.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">896</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.3.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.3.2.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">conv2d_1</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.3.2.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 30, 30, 32)</td>\n<td id=\"S3.T1.sf2.1.3.2.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">9248</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.4.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.4.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.4.3.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">max_pooling2d_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.4.3.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 15, 15, 32)</td>\n<td id=\"S3.T1.sf2.1.4.3.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.5.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.5.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.5.4.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">dropout_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.5.4.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 15, 15, 32)</td>\n<td id=\"S3.T1.sf2.1.5.4.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.6.5.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.6.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.6.5.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">conv2d_2</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.6.5.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 15, 15, 64)</td>\n<td id=\"S3.T1.sf2.1.6.5.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">18496</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.7.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.7.6.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.7.6.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.7.6.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">conv2d_3</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.7.6.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 13, 13, 64)</td>\n<td id=\"S3.T1.sf2.1.7.6.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">36928</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.8.7\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.8.7.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.8.7.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.8.7.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">max_pooling2d_1</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.8.7.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 6, 6, 64)</td>\n<td id=\"S3.T1.sf2.1.8.7.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.9.8\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.9.8.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.9.8.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.9.8.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">dropout_1</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.9.8.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 6, 6, 64)</td>\n<td id=\"S3.T1.sf2.1.9.8.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.10.9\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.10.9.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.10.9.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.10.9.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">flatten_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.10.9.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 2304)</td>\n<td id=\"S3.T1.sf2.1.10.9.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.11.10\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.11.10.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.11.10.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.11.10.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">dense_0</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.11.10.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 512)</td>\n<td id=\"S3.T1.sf2.1.11.10.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1180160</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.12.11\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.12.11.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.12.11.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.12.11.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">dropout_2</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.12.11.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 512)</td>\n<td id=\"S3.T1.sf2.1.12.11.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.13.12\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.13.12.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.13.12.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.13.12.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\">dense_1</span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.13.12.2\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">(None, 10)</td>\n<td id=\"S3.T1.sf2.1.13.12.3\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">5130</td>\n</tr>\n<tr id=\"S3.T1.sf2.1.14.13\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.14.13.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.14.13.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.14.13.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\"><span id=\"S3.T1.sf2.1.14.13.1.1.1.1\" class=\"ltx_text ltx_align_left ltx_inline-block\" style=\"width:0.0pt;\">Total params: 1,250,858</span></span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.14.13.2\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td id=\"S3.T1.sf2.1.14.13.3\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n</tr>\n<tr id=\"S3.T1.sf2.1.15.14\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.15.14.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.15.14.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.15.14.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\"><span id=\"S3.T1.sf2.1.15.14.1.1.1.1\" class=\"ltx_text ltx_align_left ltx_inline-block\" style=\"width:0.0pt;\">Trainable params: 1,250,858</span></span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.15.14.2\" class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td id=\"S3.T1.sf2.1.15.14.3\" class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n</tr>\n<tr id=\"S3.T1.sf2.1.16.15\" class=\"ltx_tr\">\n<td id=\"S3.T1.sf2.1.16.15.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S3.T1.sf2.1.16.15.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.sf2.1.16.15.1.1.1\" class=\"ltx_p\" style=\"width:69.4pt;\"><span id=\"S3.T1.sf2.1.16.15.1.1.1.1\" class=\"ltx_text ltx_align_left ltx_inline-block\" style=\"width:0.0pt;\">Non-trainable params: 0</span></span>\n</span>\n</td>\n<td id=\"S3.T1.sf2.1.16.15.2\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td id=\"S3.T1.sf2.1.16.15.3\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Models:\nOur models for generic datasets are simple convolutional neural networks with 12 and 7 layers for CIFAR-10 and Fashion MNIST, respectively, which are taken from Keras’ tutorials and examples (cif, 2021; mni, 2021). Table 1 shows a summary of the models used for Fashion MNIST and CIFAR-10 datasets.\nFor the ADNI dataset, we use a transfer learning (TL) approach using the VGG16 model (Simonyan and Zisserman, 2015) pre-trained on ImageNet (Russakovsky et al., 2015). Our classifier consists of one dense layer with 512 neurons and a rectified linear activation followed by a dense layer with two neurons and a softmax activation. The VGG16 weights were frozen during training.",
            "Furthermore, the mean and std values reported in the tables are taken across different configurations (e.g., non-iid degree) described in their related sections. The mean is taken over different configurations instead of the median since we want to consider all configurations equally in the final result. These mean and std values should not be confused with the median taken across different runs (mean and std are applied to the results of different configurations reported in different figures.). Also, other metrics like the median of different configurations and also the raw results for each configuration can be found in our replication package.",
            "To address this concern, we show how the image is affected when it gets mutated by the Noise mutator with different sigma multipliers in Figure 5. As the sigma multiplier increases, the image gets noisier as expected. However, if we increase it too much, the image gets unrecognizable, like in Figure 5e. Since the Noise mutator is supposed to simulate faults, extreme values for the sigma multiplier become unacceptable, and this is the reason that we set this parameter to be one in our experiments.",
            "We report a summary of faults’ effect on Federated Averaging in Table 2. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are affected by the mutators. As the results show, the mutators do not significantly impact the accuracy. However, out of the mutators, the Noise mutator has the most impact on the final model, which is less than 6% and is insignificant. Note that the statistical test results here show that in 20% of the cases, these differences are statistically the same as well, but in 80%, they are statistically different. However, the amount of difference itself is not actually significant (less than 6%).",
            "Like the faults section, we report a summary of attacks against Federated Averaging in Table 3. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are under attack.\nAmong the untargeted attacks, Random Update and Sign Flip are the most effective attacks against Federated Averaging, with around 70% accuracy change. Furthermore, all the attacks are much more effective than mutators as they decrease the accuracy by at least 21.26% (the best mutator did not even reach 6%). Furthermore, the statistical test shows that all these changes are statistically different as well.",
            "We report a summary of aggregators for CIFAR-10 and Fashion MNIST in Table 4 based on the average accuracy of the final model on the test data and the number of times each aggregator was the most robust one. Note that only attacks are selected here since data mutators were ineffective and untargeted attacks and backdoor attacks were split to avoid confusion. As it can be seen, Krum achieves the best accuracy on average and achieves the top rank the most in the CIFAR-10 dataset, so all in all, it is the most robust aggregation method for that dataset. For Fashion MNIST, Median is the most robust aggregator. However, considering the first rank count of aggregators, Krum comes in a close second, but its mean accuracy is less than of the Median. This is because it achieves far worse results in the Label Flip attack.",
            "Following what we did in RQ2, we report the summary of aggregators for this dataset in Table 5. Unlike RQ2, the Overlap mutator is also included here since it showed to be effective for this dataset.",
            "According to the table, Trimmed Mean gets the best results for untargeted attacks and mutators, and Median comes in second with a negligible difference. All aggregators lose the competition to the attacker for the Backdoor attack except Krum, which shows decent robustness, but its main task accuracy can still be problematic.",
            "We report the results in Table 6. Out of these 12 configurations, the ensemble aggregator is the best option in Five cases, according to the median accuracies. Running statistical tests (Mann-Whitney U Test) shows that the ensemble is significantly better than the second technique in three cases out of five. However, in the remaining two cases, there is no significant difference. Furthermore, this difference is insignificant in four cases out of the seven remaining cases where the ensemble is not the best. As a result, in 75% of cases, the ensemble aggregator is the most reasonable choice. If were run the same test for other aggregators, Federated Averaging gets 25%, and the rest will achieve 33.3%, which clearly shows the ensemble method is superior.\nLastly, our ensemble technique achieves the highest mean accuracy compared to other aggregators.",
            "A summary of this paper’s contributions compared to some of the more related works is reported in Table 7.",
            "In this paper, we conducted a large-scale empirical study on the effect of faults and attacks on FL aggregators. We performed our experiments on two generic image datasets, each with three different distributions, one federated medical dataset, eight attacks and mutators, and four aggregation techniques resulting in 496 configurations.\nResults show that the Sign Flip and Backdoor attacks are the most effective attacks. Moreover, mutators do not significantly impact FL’s quality, except for the Overlap data mutator, which can affect Federated Averaging in the ADNI dataset. In addition, our study shows that there is no single best robust aggregator, and their accuracy depends on factors such as attack type, dataset, and data distribution. For instance, Krum is most robust in model poisoning attacks, but it is not acceptable in the Label Flip attacks. Inspired by the results of different aggregators, we show that an ensemble of these aggregators can be more robust than (or as good as) any single aggregator to improve the FL process quality in 75% of cases where the attacks and data distribution are unknown to the aggregator.\nIn the future, we plan to study different attack scenarios, e.g., a case where the attacker is aware of the aggregator used on the server. Also, we want to extend this study to other FL-exclusive issues, such as clients’ machines capabilities, learning frameworks, network failures, and arithmetic computation precision issues. Lastly, we want to extend the ensemble technique to make it effective against targeted attacks like the Backdoor attack and more efficient by using different heuristics while selecting the best aggregator in each round."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: The accuracy change (between clean and 0.5 proportion configs) of Federated Averaging, per mutator (averaged over all non-iid configurations).",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\">Accuracy change</th>\n</tr>\n<tr id=\"S3.T2.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.2.2.1\" class=\"ltx_td\"></td>\n<th id=\"S3.T2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" colspan=\"2\">CIFAR-10</th>\n<th id=\"S3.T2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" colspan=\"2\">Fashion MNIST</th>\n</tr>\n<tr id=\"S3.T2.1.3.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Mutator</th>\n<th id=\"S3.T2.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Mean</th>\n<th id=\"S3.T2.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Std</th>\n<th id=\"S3.T2.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Mean</th>\n<th id=\"S3.T2.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Std</th>\n</tr>\n<tr id=\"S3.T2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">Delete</td>\n<td id=\"S3.T2.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">-4.3</td>\n<td id=\"S3.T2.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.7</td>\n<td id=\"S3.T2.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">-0.1</td>\n<td id=\"S3.T2.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">1.24</td>\n</tr>\n<tr id=\"S3.T2.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.5.5.1\" class=\"ltx_td ltx_align_center\">Overlap</td>\n<td id=\"S3.T2.1.5.5.2\" class=\"ltx_td ltx_align_center\">-0.71</td>\n<td id=\"S3.T2.1.5.5.3\" class=\"ltx_td ltx_align_center\">3.29</td>\n<td id=\"S3.T2.1.5.5.4\" class=\"ltx_td ltx_align_center\">-1.3</td>\n<td id=\"S3.T2.1.5.5.5\" class=\"ltx_td ltx_align_center\">4.11</td>\n</tr>\n<tr id=\"S3.T2.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.6.6.1\" class=\"ltx_td ltx_align_center\">Unbalance</td>\n<td id=\"S3.T2.1.6.6.2\" class=\"ltx_td ltx_align_center\">-0.64</td>\n<td id=\"S3.T2.1.6.6.3\" class=\"ltx_td ltx_align_center\">1.01</td>\n<td id=\"S3.T2.1.6.6.4\" class=\"ltx_td ltx_align_center\">-0.21</td>\n<td id=\"S3.T2.1.6.6.5\" class=\"ltx_td ltx_align_center\">1.75</td>\n</tr>\n<tr id=\"S3.T2.1.7.7\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">Noise</td>\n<td id=\"S3.T2.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">-5.66</td>\n<td id=\"S3.T2.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">1.05</td>\n<td id=\"S3.T2.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">-2.84</td>\n<td id=\"S3.T2.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">1.04</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We report a summary of faults’ effect on Federated Averaging in Table 2. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are affected by the mutators. As the results show, the mutators do not significantly impact the accuracy. However, out of the mutators, the Noise mutator has the most impact on the final model, which is less than 6% and is insignificant. Note that the statistical test results here show that in 20% of the cases, these differences are statistically the same as well, but in 80%, they are statistically different. However, the amount of difference itself is not actually significant (less than 6%)."
        ]
    },
    "S3.T3": {
        "caption": "Table 3: The accuracy change (between clean and 0.5 proportion configs) of Federated Averaging, per attack (averaged over all non-iid configurations).",
        "table": "<table id=\"S3.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S3.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\">Accuracy change</td>\n</tr>\n<tr id=\"S3.T3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.2.2.1\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.1.2.2.2\" class=\"ltx_td ltx_align_center\" colspan=\"2\">CIFAR-10</td>\n<td id=\"S3.T3.1.2.2.3\" class=\"ltx_td ltx_align_center\" colspan=\"2\">Fashion MNIST</td>\n</tr>\n<tr id=\"S3.T3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.3.3.1\" class=\"ltx_td ltx_align_center\">Mutator</td>\n<td id=\"S3.T3.1.3.3.2\" class=\"ltx_td ltx_align_center\">Mean</td>\n<td id=\"S3.T3.1.3.3.3\" class=\"ltx_td ltx_align_center\">Std</td>\n<td id=\"S3.T3.1.3.3.4\" class=\"ltx_td ltx_align_center\">Mean</td>\n<td id=\"S3.T3.1.3.3.5\" class=\"ltx_td ltx_align_center\">Std</td>\n</tr>\n<tr id=\"S3.T3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">Label Flip</td>\n<td id=\"S3.T3.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">-39.02</td>\n<td id=\"S3.T3.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">7.81</td>\n<td id=\"S3.T3.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">-21.26</td>\n<td id=\"S3.T3.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">9.6</td>\n</tr>\n<tr id=\"S3.T3.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.5.5.1\" class=\"ltx_td ltx_align_center\">Random Update</td>\n<td id=\"S3.T3.1.5.5.2\" class=\"ltx_td ltx_align_center\">-66.13</td>\n<td id=\"S3.T3.1.5.5.3\" class=\"ltx_td ltx_align_center\">1.67</td>\n<td id=\"S3.T3.1.5.5.4\" class=\"ltx_td ltx_align_center\">-77.81</td>\n<td id=\"S3.T3.1.5.5.5\" class=\"ltx_td ltx_align_center\">1.53</td>\n</tr>\n<tr id=\"S3.T3.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">Sign Flip</td>\n<td id=\"S3.T3.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">-66.13</td>\n<td id=\"S3.T3.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">1.67</td>\n<td id=\"S3.T3.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">-77.81</td>\n<td id=\"S3.T3.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">1.53</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Like the faults section, we report a summary of attacks against Federated Averaging in Table 3. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are under attack.\nAmong the untargeted attacks, Random Update and Sign Flip are the most effective attacks against Federated Averaging, with around 70% accuracy change. Furthermore, all the attacks are much more effective than mutators as they decrease the accuracy by at least 21.26% (the best mutator did not even reach 6%). Furthermore, the statistical test shows that all these changes are statistically different as well."
        ]
    },
    "S3.T4": {
        "caption": "Table 4: Aggregators summary in terms of their accuracy (averaged across attacks, non-iid configurations, and proportion of affected clients) and the number of times the aggregator is the best choice among all aggregators under study (Number of times achieving the Top rank) – The shaded cells mark the best techniques.",
        "table": "<table id=\"S3.T4.sf1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T4.sf1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S3.T4.sf1.1.1.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\"></th>\n<th id=\"S3.T4.sf1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">Accuracy</th>\n<th id=\"S3.T4.sf1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T4.sf1.1.1.1.4.1\" class=\"ltx_text\">\n<span id=\"S3.T4.sf1.1.1.1.4.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T4.sf1.1.1.1.4.1.1.1\" class=\"ltx_p\">Top rank</span>\n<span id=\"S3.T4.sf1.1.1.1.4.1.1.2\" class=\"ltx_p\">frequency</span>\n</span></span></th>\n</tr>\n<tr id=\"S3.T4.sf1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T4.sf1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Dataset</th>\n<th id=\"S3.T4.sf1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Aggregator</th>\n<th id=\"S3.T4.sf1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Mean</th>\n<th id=\"S3.T4.sf1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Std</th>\n</tr>\n<tr id=\"S3.T4.sf1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"4\"><span id=\"S3.T4.sf1.1.3.3.1.1\" class=\"ltx_text\">CIFAR-10</span></td>\n<td id=\"S3.T4.sf1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</td>\n<td id=\"S3.T4.sf1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">26.31</td>\n<td id=\"S3.T4.sf1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">24.88</td>\n<td id=\"S3.T4.sf1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">8</td>\n</tr>\n<tr id=\"S3.T4.sf1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.4.4.1\" class=\"ltx_td ltx_align_center\">Krum</td>\n<td id=\"S3.T4.sf1.1.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.4.4.2.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">51.09</span></td>\n<td id=\"S3.T4.sf1.1.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">16.66</span></td>\n<td id=\"S3.T4.sf1.1.4.4.4\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.4.4.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">12</span></td>\n</tr>\n<tr id=\"S3.T4.sf1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.5.5.1\" class=\"ltx_td ltx_align_center\">Median</td>\n<td id=\"S3.T4.sf1.1.5.5.2\" class=\"ltx_td ltx_align_center\">37.04</td>\n<td id=\"S3.T4.sf1.1.5.5.3\" class=\"ltx_td ltx_align_center\">27.32</td>\n<td id=\"S3.T4.sf1.1.5.5.4\" class=\"ltx_td ltx_align_center\">6</td>\n</tr>\n<tr id=\"S3.T4.sf1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.6.6.1\" class=\"ltx_td ltx_align_center\">Tri-mean</td>\n<td id=\"S3.T4.sf1.1.6.6.2\" class=\"ltx_td ltx_align_center\">24.61</td>\n<td id=\"S3.T4.sf1.1.6.6.3\" class=\"ltx_td ltx_align_center\">23.2</td>\n<td id=\"S3.T4.sf1.1.6.6.4\" class=\"ltx_td ltx_align_center\">1</td>\n</tr>\n<tr id=\"S3.T4.sf1.1.7.7\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"4\"><span id=\"S3.T4.sf1.1.7.7.1.1\" class=\"ltx_text\">\n<span id=\"S3.T4.sf1.1.7.7.1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T4.sf1.1.7.7.1.1.1.1\" class=\"ltx_p\">Fashion</span>\n<span id=\"S3.T4.sf1.1.7.7.1.1.1.2\" class=\"ltx_p\">MNIST</span>\n</span></span></td>\n<td id=\"S3.T4.sf1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">FedAvg</td>\n<td id=\"S3.T4.sf1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">33.14</td>\n<td id=\"S3.T4.sf1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">33.29</td>\n<td id=\"S3.T4.sf1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">5</td>\n</tr>\n<tr id=\"S3.T4.sf1.1.8.8\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.8.8.1\" class=\"ltx_td ltx_align_center\">Krum</td>\n<td id=\"S3.T4.sf1.1.8.8.2\" class=\"ltx_td ltx_align_center\">51.32</td>\n<td id=\"S3.T4.sf1.1.8.8.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.8.8.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">30.27</span></td>\n<td id=\"S3.T4.sf1.1.8.8.4\" class=\"ltx_td ltx_align_center\">9</td>\n</tr>\n<tr id=\"S3.T4.sf1.1.9.9\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.9.9.1\" class=\"ltx_td ltx_align_center\">Median</td>\n<td id=\"S3.T4.sf1.1.9.9.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.9.9.2.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">58.43</span></td>\n<td id=\"S3.T4.sf1.1.9.9.3\" class=\"ltx_td ltx_align_center\">31.93</td>\n<td id=\"S3.T4.sf1.1.9.9.4\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.9.9.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">10</span></td>\n</tr>\n<tr id=\"S3.T4.sf1.1.10.10\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">Tri-mean</td>\n<td id=\"S3.T4.sf1.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">53.69</td>\n<td id=\"S3.T4.sf1.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">32.25</td>\n<td id=\"S3.T4.sf1.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">3</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We report a summary of aggregators for CIFAR-10 and Fashion MNIST in Table 4 based on the average accuracy of the final model on the test data and the number of times each aggregator was the most robust one. Note that only attacks are selected here since data mutators were ineffective and untargeted attacks and backdoor attacks were split to avoid confusion. As it can be seen, Krum achieves the best accuracy on average and achieves the top rank the most in the CIFAR-10 dataset, so all in all, it is the most robust aggregation method for that dataset. For Fashion MNIST, Median is the most robust aggregator. However, considering the first rank count of aggregators, Krum comes in a close second, but its mean accuracy is less than of the Median. This is because it achieves far worse results in the Label Flip attack."
        ]
    },
    "S3.T4.sf1": {
        "caption": "(a) Results for untargeted attacks (higher accuracy is better)",
        "table": "<table id=\"S3.T4.sf1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T4.sf1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S3.T4.sf1.1.1.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\"></th>\n<th id=\"S3.T4.sf1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">Accuracy</th>\n<th id=\"S3.T4.sf1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T4.sf1.1.1.1.4.1\" class=\"ltx_text\">\n<span id=\"S3.T4.sf1.1.1.1.4.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T4.sf1.1.1.1.4.1.1.1\" class=\"ltx_p\">Top rank</span>\n<span id=\"S3.T4.sf1.1.1.1.4.1.1.2\" class=\"ltx_p\">frequency</span>\n</span></span></th>\n</tr>\n<tr id=\"S3.T4.sf1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T4.sf1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Dataset</th>\n<th id=\"S3.T4.sf1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Aggregator</th>\n<th id=\"S3.T4.sf1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Mean</th>\n<th id=\"S3.T4.sf1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Std</th>\n</tr>\n<tr id=\"S3.T4.sf1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"4\"><span id=\"S3.T4.sf1.1.3.3.1.1\" class=\"ltx_text\">CIFAR-10</span></td>\n<td id=\"S3.T4.sf1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</td>\n<td id=\"S3.T4.sf1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">26.31</td>\n<td id=\"S3.T4.sf1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">24.88</td>\n<td id=\"S3.T4.sf1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">8</td>\n</tr>\n<tr id=\"S3.T4.sf1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.4.4.1\" class=\"ltx_td ltx_align_center\">Krum</td>\n<td id=\"S3.T4.sf1.1.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.4.4.2.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">51.09</span></td>\n<td id=\"S3.T4.sf1.1.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">16.66</span></td>\n<td id=\"S3.T4.sf1.1.4.4.4\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.4.4.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">12</span></td>\n</tr>\n<tr id=\"S3.T4.sf1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.5.5.1\" class=\"ltx_td ltx_align_center\">Median</td>\n<td id=\"S3.T4.sf1.1.5.5.2\" class=\"ltx_td ltx_align_center\">37.04</td>\n<td id=\"S3.T4.sf1.1.5.5.3\" class=\"ltx_td ltx_align_center\">27.32</td>\n<td id=\"S3.T4.sf1.1.5.5.4\" class=\"ltx_td ltx_align_center\">6</td>\n</tr>\n<tr id=\"S3.T4.sf1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.6.6.1\" class=\"ltx_td ltx_align_center\">Tri-mean</td>\n<td id=\"S3.T4.sf1.1.6.6.2\" class=\"ltx_td ltx_align_center\">24.61</td>\n<td id=\"S3.T4.sf1.1.6.6.3\" class=\"ltx_td ltx_align_center\">23.2</td>\n<td id=\"S3.T4.sf1.1.6.6.4\" class=\"ltx_td ltx_align_center\">1</td>\n</tr>\n<tr id=\"S3.T4.sf1.1.7.7\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"4\"><span id=\"S3.T4.sf1.1.7.7.1.1\" class=\"ltx_text\">\n<span id=\"S3.T4.sf1.1.7.7.1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T4.sf1.1.7.7.1.1.1.1\" class=\"ltx_p\">Fashion</span>\n<span id=\"S3.T4.sf1.1.7.7.1.1.1.2\" class=\"ltx_p\">MNIST</span>\n</span></span></td>\n<td id=\"S3.T4.sf1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">FedAvg</td>\n<td id=\"S3.T4.sf1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">33.14</td>\n<td id=\"S3.T4.sf1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">33.29</td>\n<td id=\"S3.T4.sf1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">5</td>\n</tr>\n<tr id=\"S3.T4.sf1.1.8.8\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.8.8.1\" class=\"ltx_td ltx_align_center\">Krum</td>\n<td id=\"S3.T4.sf1.1.8.8.2\" class=\"ltx_td ltx_align_center\">51.32</td>\n<td id=\"S3.T4.sf1.1.8.8.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.8.8.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">30.27</span></td>\n<td id=\"S3.T4.sf1.1.8.8.4\" class=\"ltx_td ltx_align_center\">9</td>\n</tr>\n<tr id=\"S3.T4.sf1.1.9.9\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.9.9.1\" class=\"ltx_td ltx_align_center\">Median</td>\n<td id=\"S3.T4.sf1.1.9.9.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.9.9.2.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">58.43</span></td>\n<td id=\"S3.T4.sf1.1.9.9.3\" class=\"ltx_td ltx_align_center\">31.93</td>\n<td id=\"S3.T4.sf1.1.9.9.4\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf1.1.9.9.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">10</span></td>\n</tr>\n<tr id=\"S3.T4.sf1.1.10.10\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf1.1.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">Tri-mean</td>\n<td id=\"S3.T4.sf1.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">53.69</td>\n<td id=\"S3.T4.sf1.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">32.25</td>\n<td id=\"S3.T4.sf1.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">3</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Models:\nOur models for generic datasets are simple convolutional neural networks with 12 and 7 layers for CIFAR-10 and Fashion MNIST, respectively, which are taken from Keras’ tutorials and examples (cif, 2021; mni, 2021). Table 1 shows a summary of the models used for Fashion MNIST and CIFAR-10 datasets.\nFor the ADNI dataset, we use a transfer learning (TL) approach using the VGG16 model (Simonyan and Zisserman, 2015) pre-trained on ImageNet (Russakovsky et al., 2015). Our classifier consists of one dense layer with 512 neurons and a rectified linear activation followed by a dense layer with two neurons and a softmax activation. The VGG16 weights were frozen during training.",
            "Furthermore, the mean and std values reported in the tables are taken across different configurations (e.g., non-iid degree) described in their related sections. The mean is taken over different configurations instead of the median since we want to consider all configurations equally in the final result. These mean and std values should not be confused with the median taken across different runs (mean and std are applied to the results of different configurations reported in different figures.). Also, other metrics like the median of different configurations and also the raw results for each configuration can be found in our replication package.",
            "To address this concern, we show how the image is affected when it gets mutated by the Noise mutator with different sigma multipliers in Figure 5. As the sigma multiplier increases, the image gets noisier as expected. However, if we increase it too much, the image gets unrecognizable, like in Figure 5e. Since the Noise mutator is supposed to simulate faults, extreme values for the sigma multiplier become unacceptable, and this is the reason that we set this parameter to be one in our experiments.",
            "We report a summary of faults’ effect on Federated Averaging in Table 2. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are affected by the mutators. As the results show, the mutators do not significantly impact the accuracy. However, out of the mutators, the Noise mutator has the most impact on the final model, which is less than 6% and is insignificant. Note that the statistical test results here show that in 20% of the cases, these differences are statistically the same as well, but in 80%, they are statistically different. However, the amount of difference itself is not actually significant (less than 6%).",
            "Like the faults section, we report a summary of attacks against Federated Averaging in Table 3. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are under attack.\nAmong the untargeted attacks, Random Update and Sign Flip are the most effective attacks against Federated Averaging, with around 70% accuracy change. Furthermore, all the attacks are much more effective than mutators as they decrease the accuracy by at least 21.26% (the best mutator did not even reach 6%). Furthermore, the statistical test shows that all these changes are statistically different as well.",
            "We report a summary of aggregators for CIFAR-10 and Fashion MNIST in Table 4 based on the average accuracy of the final model on the test data and the number of times each aggregator was the most robust one. Note that only attacks are selected here since data mutators were ineffective and untargeted attacks and backdoor attacks were split to avoid confusion. As it can be seen, Krum achieves the best accuracy on average and achieves the top rank the most in the CIFAR-10 dataset, so all in all, it is the most robust aggregation method for that dataset. For Fashion MNIST, Median is the most robust aggregator. However, considering the first rank count of aggregators, Krum comes in a close second, but its mean accuracy is less than of the Median. This is because it achieves far worse results in the Label Flip attack.",
            "Following what we did in RQ2, we report the summary of aggregators for this dataset in Table 5. Unlike RQ2, the Overlap mutator is also included here since it showed to be effective for this dataset.",
            "According to the table, Trimmed Mean gets the best results for untargeted attacks and mutators, and Median comes in second with a negligible difference. All aggregators lose the competition to the attacker for the Backdoor attack except Krum, which shows decent robustness, but its main task accuracy can still be problematic.",
            "We report the results in Table 6. Out of these 12 configurations, the ensemble aggregator is the best option in Five cases, according to the median accuracies. Running statistical tests (Mann-Whitney U Test) shows that the ensemble is significantly better than the second technique in three cases out of five. However, in the remaining two cases, there is no significant difference. Furthermore, this difference is insignificant in four cases out of the seven remaining cases where the ensemble is not the best. As a result, in 75% of cases, the ensemble aggregator is the most reasonable choice. If were run the same test for other aggregators, Federated Averaging gets 25%, and the rest will achieve 33.3%, which clearly shows the ensemble method is superior.\nLastly, our ensemble technique achieves the highest mean accuracy compared to other aggregators.",
            "A summary of this paper’s contributions compared to some of the more related works is reported in Table 7.",
            "In this paper, we conducted a large-scale empirical study on the effect of faults and attacks on FL aggregators. We performed our experiments on two generic image datasets, each with three different distributions, one federated medical dataset, eight attacks and mutators, and four aggregation techniques resulting in 496 configurations.\nResults show that the Sign Flip and Backdoor attacks are the most effective attacks. Moreover, mutators do not significantly impact FL’s quality, except for the Overlap data mutator, which can affect Federated Averaging in the ADNI dataset. In addition, our study shows that there is no single best robust aggregator, and their accuracy depends on factors such as attack type, dataset, and data distribution. For instance, Krum is most robust in model poisoning attacks, but it is not acceptable in the Label Flip attacks. Inspired by the results of different aggregators, we show that an ensemble of these aggregators can be more robust than (or as good as) any single aggregator to improve the FL process quality in 75% of cases where the attacks and data distribution are unknown to the aggregator.\nIn the future, we plan to study different attack scenarios, e.g., a case where the attacker is aware of the aggregator used on the server. Also, we want to extend this study to other FL-exclusive issues, such as clients’ machines capabilities, learning frameworks, network failures, and arithmetic computation precision issues. Lastly, we want to extend the ensemble technique to make it effective against targeted attacks like the Backdoor attack and more efficient by using different heuristics while selecting the best aggregator in each round."
        ]
    },
    "S3.T4.sf2": {
        "caption": "(b) Results for the Backdoor attack (lower backdoor accuracy is better)",
        "table": "<table id=\"S3.T4.sf2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T4.sf2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf2.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S3.T4.sf2.1.1.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\"></th>\n<th id=\"S3.T4.sf2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">Backdoor accuracy</th>\n<th id=\"S3.T4.sf2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T4.sf2.1.1.1.4.1\" class=\"ltx_text\">\n<span id=\"S3.T4.sf2.1.1.1.4.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T4.sf2.1.1.1.4.1.1.1\" class=\"ltx_p\">Top rank</span>\n<span id=\"S3.T4.sf2.1.1.1.4.1.1.2\" class=\"ltx_p\">frequency</span>\n</span></span></th>\n</tr>\n<tr id=\"S3.T4.sf2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T4.sf2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Dataset</th>\n<th id=\"S3.T4.sf2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Aggregator</th>\n<th id=\"S3.T4.sf2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Mean</th>\n<th id=\"S3.T4.sf2.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Std</th>\n</tr>\n<tr id=\"S3.T4.sf2.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf2.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"4\"><span id=\"S3.T4.sf2.1.3.3.1.1\" class=\"ltx_text\">CIFAR-10</span></td>\n<td id=\"S3.T4.sf2.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</td>\n<td id=\"S3.T4.sf2.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">95.16</td>\n<td id=\"S3.T4.sf2.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf2.1.3.3.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">1.78</span></td>\n<td id=\"S3.T4.sf2.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">0</td>\n</tr>\n<tr id=\"S3.T4.sf2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf2.1.4.4.1\" class=\"ltx_td ltx_align_center\">Krum</td>\n<td id=\"S3.T4.sf2.1.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf2.1.4.4.2.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">4.26</span></td>\n<td id=\"S3.T4.sf2.1.4.4.3\" class=\"ltx_td ltx_align_center\">1.86</td>\n<td id=\"S3.T4.sf2.1.4.4.4\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf2.1.4.4.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">9</span></td>\n</tr>\n<tr id=\"S3.T4.sf2.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf2.1.5.5.1\" class=\"ltx_td ltx_align_center\">Median</td>\n<td id=\"S3.T4.sf2.1.5.5.2\" class=\"ltx_td ltx_align_center\">90.72</td>\n<td id=\"S3.T4.sf2.1.5.5.3\" class=\"ltx_td ltx_align_center\">6.65</td>\n<td id=\"S3.T4.sf2.1.5.5.4\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"S3.T4.sf2.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf2.1.6.6.1\" class=\"ltx_td ltx_align_center\">Tri-mean</td>\n<td id=\"S3.T4.sf2.1.6.6.2\" class=\"ltx_td ltx_align_center\">93.56</td>\n<td id=\"S3.T4.sf2.1.6.6.3\" class=\"ltx_td ltx_align_center\">3.71</td>\n<td id=\"S3.T4.sf2.1.6.6.4\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"S3.T4.sf2.1.7.7\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf2.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"4\"><span id=\"S3.T4.sf2.1.7.7.1.1\" class=\"ltx_text\">\n<span id=\"S3.T4.sf2.1.7.7.1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T4.sf2.1.7.7.1.1.1.1\" class=\"ltx_p\">Fashion</span>\n<span id=\"S3.T4.sf2.1.7.7.1.1.1.2\" class=\"ltx_p\">MNIST</span>\n</span></span></td>\n<td id=\"S3.T4.sf2.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">FedAvg</td>\n<td id=\"S3.T4.sf2.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">99.94</td>\n<td id=\"S3.T4.sf2.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf2.1.7.7.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">0.08</span></td>\n<td id=\"S3.T4.sf2.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0</td>\n</tr>\n<tr id=\"S3.T4.sf2.1.8.8\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf2.1.8.8.1\" class=\"ltx_td ltx_align_center\">Krum</td>\n<td id=\"S3.T4.sf2.1.8.8.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf2.1.8.8.2.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">1.71</span></td>\n<td id=\"S3.T4.sf2.1.8.8.3\" class=\"ltx_td ltx_align_center\">2.27</td>\n<td id=\"S3.T4.sf2.1.8.8.4\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T4.sf2.1.8.8.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">9</span></td>\n</tr>\n<tr id=\"S3.T4.sf2.1.9.9\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf2.1.9.9.1\" class=\"ltx_td ltx_align_center\">Median</td>\n<td id=\"S3.T4.sf2.1.9.9.2\" class=\"ltx_td ltx_align_center\">82.39</td>\n<td id=\"S3.T4.sf2.1.9.9.3\" class=\"ltx_td ltx_align_center\">24.79</td>\n<td id=\"S3.T4.sf2.1.9.9.4\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"S3.T4.sf2.1.10.10\" class=\"ltx_tr\">\n<td id=\"S3.T4.sf2.1.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">Tri-mean</td>\n<td id=\"S3.T4.sf2.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">99.73</td>\n<td id=\"S3.T4.sf2.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.23</td>\n<td id=\"S3.T4.sf2.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Models:\nOur models for generic datasets are simple convolutional neural networks with 12 and 7 layers for CIFAR-10 and Fashion MNIST, respectively, which are taken from Keras’ tutorials and examples (cif, 2021; mni, 2021). Table 1 shows a summary of the models used for Fashion MNIST and CIFAR-10 datasets.\nFor the ADNI dataset, we use a transfer learning (TL) approach using the VGG16 model (Simonyan and Zisserman, 2015) pre-trained on ImageNet (Russakovsky et al., 2015). Our classifier consists of one dense layer with 512 neurons and a rectified linear activation followed by a dense layer with two neurons and a softmax activation. The VGG16 weights were frozen during training.",
            "Furthermore, the mean and std values reported in the tables are taken across different configurations (e.g., non-iid degree) described in their related sections. The mean is taken over different configurations instead of the median since we want to consider all configurations equally in the final result. These mean and std values should not be confused with the median taken across different runs (mean and std are applied to the results of different configurations reported in different figures.). Also, other metrics like the median of different configurations and also the raw results for each configuration can be found in our replication package.",
            "To address this concern, we show how the image is affected when it gets mutated by the Noise mutator with different sigma multipliers in Figure 5. As the sigma multiplier increases, the image gets noisier as expected. However, if we increase it too much, the image gets unrecognizable, like in Figure 5e. Since the Noise mutator is supposed to simulate faults, extreme values for the sigma multiplier become unacceptable, and this is the reason that we set this parameter to be one in our experiments.",
            "We report a summary of faults’ effect on Federated Averaging in Table 2. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are affected by the mutators. As the results show, the mutators do not significantly impact the accuracy. However, out of the mutators, the Noise mutator has the most impact on the final model, which is less than 6% and is insignificant. Note that the statistical test results here show that in 20% of the cases, these differences are statistically the same as well, but in 80%, they are statistically different. However, the amount of difference itself is not actually significant (less than 6%).",
            "Like the faults section, we report a summary of attacks against Federated Averaging in Table 3. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are under attack.\nAmong the untargeted attacks, Random Update and Sign Flip are the most effective attacks against Federated Averaging, with around 70% accuracy change. Furthermore, all the attacks are much more effective than mutators as they decrease the accuracy by at least 21.26% (the best mutator did not even reach 6%). Furthermore, the statistical test shows that all these changes are statistically different as well.",
            "We report a summary of aggregators for CIFAR-10 and Fashion MNIST in Table 4 based on the average accuracy of the final model on the test data and the number of times each aggregator was the most robust one. Note that only attacks are selected here since data mutators were ineffective and untargeted attacks and backdoor attacks were split to avoid confusion. As it can be seen, Krum achieves the best accuracy on average and achieves the top rank the most in the CIFAR-10 dataset, so all in all, it is the most robust aggregation method for that dataset. For Fashion MNIST, Median is the most robust aggregator. However, considering the first rank count of aggregators, Krum comes in a close second, but its mean accuracy is less than of the Median. This is because it achieves far worse results in the Label Flip attack.",
            "Following what we did in RQ2, we report the summary of aggregators for this dataset in Table 5. Unlike RQ2, the Overlap mutator is also included here since it showed to be effective for this dataset.",
            "According to the table, Trimmed Mean gets the best results for untargeted attacks and mutators, and Median comes in second with a negligible difference. All aggregators lose the competition to the attacker for the Backdoor attack except Krum, which shows decent robustness, but its main task accuracy can still be problematic.",
            "We report the results in Table 6. Out of these 12 configurations, the ensemble aggregator is the best option in Five cases, according to the median accuracies. Running statistical tests (Mann-Whitney U Test) shows that the ensemble is significantly better than the second technique in three cases out of five. However, in the remaining two cases, there is no significant difference. Furthermore, this difference is insignificant in four cases out of the seven remaining cases where the ensemble is not the best. As a result, in 75% of cases, the ensemble aggregator is the most reasonable choice. If were run the same test for other aggregators, Federated Averaging gets 25%, and the rest will achieve 33.3%, which clearly shows the ensemble method is superior.\nLastly, our ensemble technique achieves the highest mean accuracy compared to other aggregators.",
            "A summary of this paper’s contributions compared to some of the more related works is reported in Table 7.",
            "In this paper, we conducted a large-scale empirical study on the effect of faults and attacks on FL aggregators. We performed our experiments on two generic image datasets, each with three different distributions, one federated medical dataset, eight attacks and mutators, and four aggregation techniques resulting in 496 configurations.\nResults show that the Sign Flip and Backdoor attacks are the most effective attacks. Moreover, mutators do not significantly impact FL’s quality, except for the Overlap data mutator, which can affect Federated Averaging in the ADNI dataset. In addition, our study shows that there is no single best robust aggregator, and their accuracy depends on factors such as attack type, dataset, and data distribution. For instance, Krum is most robust in model poisoning attacks, but it is not acceptable in the Label Flip attacks. Inspired by the results of different aggregators, we show that an ensemble of these aggregators can be more robust than (or as good as) any single aggregator to improve the FL process quality in 75% of cases where the attacks and data distribution are unknown to the aggregator.\nIn the future, we plan to study different attack scenarios, e.g., a case where the attacker is aware of the aggregator used on the server. Also, we want to extend this study to other FL-exclusive issues, such as clients’ machines capabilities, learning frameworks, network failures, and arithmetic computation precision issues. Lastly, we want to extend the ensemble technique to make it effective against targeted attacks like the Backdoor attack and more efficient by using different heuristics while selecting the best aggregator in each round."
        ]
    },
    "S3.T5": {
        "caption": "Table 5: \nADNI - Aggregators summary in terms of their accuracy (averaged across attacks and proportion of affected clients) and the number of times the aggregator is the best choice among all aggregators under study (Number of times achieving the Top rank) – The shaded cells mark the best techniques.",
        "table": "<table id=\"S3.T5.sf1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T5.sf1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf1.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S3.T5.sf1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">Accuracy</th>\n<th id=\"S3.T5.sf1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T5.sf1.1.1.1.3.1\" class=\"ltx_text\">\n<span id=\"S3.T5.sf1.1.1.1.3.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T5.sf1.1.1.1.3.1.1.1\" class=\"ltx_p\">Top rank</span>\n<span id=\"S3.T5.sf1.1.1.1.3.1.1.2\" class=\"ltx_p\">frequency</span>\n</span></span></th>\n</tr>\n<tr id=\"S3.T5.sf1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T5.sf1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Aggregator</th>\n<th id=\"S3.T5.sf1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Mean</th>\n<th id=\"S3.T5.sf1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Std</th>\n</tr>\n<tr id=\"S3.T5.sf1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</td>\n<td id=\"S3.T5.sf1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">52.89</td>\n<td id=\"S3.T5.sf1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">12.66</td>\n<td id=\"S3.T5.sf1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">1</td>\n</tr>\n<tr id=\"S3.T5.sf1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf1.1.4.4.1\" class=\"ltx_td ltx_align_center\">Krum</td>\n<td id=\"S3.T5.sf1.1.4.4.2\" class=\"ltx_td ltx_align_center\">63.23</td>\n<td id=\"S3.T5.sf1.1.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T5.sf1.1.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">6.24</span></td>\n<td id=\"S3.T5.sf1.1.4.4.4\" class=\"ltx_td ltx_align_center\">2</td>\n</tr>\n<tr id=\"S3.T5.sf1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf1.1.5.5.1\" class=\"ltx_td ltx_align_center\">Median</td>\n<td id=\"S3.T5.sf1.1.5.5.2\" class=\"ltx_td ltx_align_center\">64.97</td>\n<td id=\"S3.T5.sf1.1.5.5.3\" class=\"ltx_td ltx_align_center\">11.87</td>\n<td id=\"S3.T5.sf1.1.5.5.4\" class=\"ltx_td ltx_align_center\">4</td>\n</tr>\n<tr id=\"S3.T5.sf1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf1.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">Tri-mean</td>\n<td id=\"S3.T5.sf1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T5.sf1.1.6.6.2.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">65.16</span></td>\n<td id=\"S3.T5.sf1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">11.72</td>\n<td id=\"S3.T5.sf1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T5.sf1.1.6.6.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">5</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Following what we did in RQ2, we report the summary of aggregators for this dataset in Table 5. Unlike RQ2, the Overlap mutator is also included here since it showed to be effective for this dataset."
        ]
    },
    "S3.T5.sf1": {
        "caption": "(a) Results for untargeted attacks and Overlap mutator (higher accuracy is better)",
        "table": "<table id=\"S3.T5.sf1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T5.sf1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf1.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S3.T5.sf1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">Accuracy</th>\n<th id=\"S3.T5.sf1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T5.sf1.1.1.1.3.1\" class=\"ltx_text\">\n<span id=\"S3.T5.sf1.1.1.1.3.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T5.sf1.1.1.1.3.1.1.1\" class=\"ltx_p\">Top rank</span>\n<span id=\"S3.T5.sf1.1.1.1.3.1.1.2\" class=\"ltx_p\">frequency</span>\n</span></span></th>\n</tr>\n<tr id=\"S3.T5.sf1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T5.sf1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Aggregator</th>\n<th id=\"S3.T5.sf1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Mean</th>\n<th id=\"S3.T5.sf1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Std</th>\n</tr>\n<tr id=\"S3.T5.sf1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</td>\n<td id=\"S3.T5.sf1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">52.89</td>\n<td id=\"S3.T5.sf1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">12.66</td>\n<td id=\"S3.T5.sf1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">1</td>\n</tr>\n<tr id=\"S3.T5.sf1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf1.1.4.4.1\" class=\"ltx_td ltx_align_center\">Krum</td>\n<td id=\"S3.T5.sf1.1.4.4.2\" class=\"ltx_td ltx_align_center\">63.23</td>\n<td id=\"S3.T5.sf1.1.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T5.sf1.1.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">6.24</span></td>\n<td id=\"S3.T5.sf1.1.4.4.4\" class=\"ltx_td ltx_align_center\">2</td>\n</tr>\n<tr id=\"S3.T5.sf1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf1.1.5.5.1\" class=\"ltx_td ltx_align_center\">Median</td>\n<td id=\"S3.T5.sf1.1.5.5.2\" class=\"ltx_td ltx_align_center\">64.97</td>\n<td id=\"S3.T5.sf1.1.5.5.3\" class=\"ltx_td ltx_align_center\">11.87</td>\n<td id=\"S3.T5.sf1.1.5.5.4\" class=\"ltx_td ltx_align_center\">4</td>\n</tr>\n<tr id=\"S3.T5.sf1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf1.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">Tri-mean</td>\n<td id=\"S3.T5.sf1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T5.sf1.1.6.6.2.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">65.16</span></td>\n<td id=\"S3.T5.sf1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">11.72</td>\n<td id=\"S3.T5.sf1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T5.sf1.1.6.6.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">5</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Models:\nOur models for generic datasets are simple convolutional neural networks with 12 and 7 layers for CIFAR-10 and Fashion MNIST, respectively, which are taken from Keras’ tutorials and examples (cif, 2021; mni, 2021). Table 1 shows a summary of the models used for Fashion MNIST and CIFAR-10 datasets.\nFor the ADNI dataset, we use a transfer learning (TL) approach using the VGG16 model (Simonyan and Zisserman, 2015) pre-trained on ImageNet (Russakovsky et al., 2015). Our classifier consists of one dense layer with 512 neurons and a rectified linear activation followed by a dense layer with two neurons and a softmax activation. The VGG16 weights were frozen during training.",
            "Furthermore, the mean and std values reported in the tables are taken across different configurations (e.g., non-iid degree) described in their related sections. The mean is taken over different configurations instead of the median since we want to consider all configurations equally in the final result. These mean and std values should not be confused with the median taken across different runs (mean and std are applied to the results of different configurations reported in different figures.). Also, other metrics like the median of different configurations and also the raw results for each configuration can be found in our replication package.",
            "To address this concern, we show how the image is affected when it gets mutated by the Noise mutator with different sigma multipliers in Figure 5. As the sigma multiplier increases, the image gets noisier as expected. However, if we increase it too much, the image gets unrecognizable, like in Figure 5e. Since the Noise mutator is supposed to simulate faults, extreme values for the sigma multiplier become unacceptable, and this is the reason that we set this parameter to be one in our experiments.",
            "We report a summary of faults’ effect on Federated Averaging in Table 2. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are affected by the mutators. As the results show, the mutators do not significantly impact the accuracy. However, out of the mutators, the Noise mutator has the most impact on the final model, which is less than 6% and is insignificant. Note that the statistical test results here show that in 20% of the cases, these differences are statistically the same as well, but in 80%, they are statistically different. However, the amount of difference itself is not actually significant (less than 6%).",
            "Like the faults section, we report a summary of attacks against Federated Averaging in Table 3. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are under attack.\nAmong the untargeted attacks, Random Update and Sign Flip are the most effective attacks against Federated Averaging, with around 70% accuracy change. Furthermore, all the attacks are much more effective than mutators as they decrease the accuracy by at least 21.26% (the best mutator did not even reach 6%). Furthermore, the statistical test shows that all these changes are statistically different as well.",
            "We report a summary of aggregators for CIFAR-10 and Fashion MNIST in Table 4 based on the average accuracy of the final model on the test data and the number of times each aggregator was the most robust one. Note that only attacks are selected here since data mutators were ineffective and untargeted attacks and backdoor attacks were split to avoid confusion. As it can be seen, Krum achieves the best accuracy on average and achieves the top rank the most in the CIFAR-10 dataset, so all in all, it is the most robust aggregation method for that dataset. For Fashion MNIST, Median is the most robust aggregator. However, considering the first rank count of aggregators, Krum comes in a close second, but its mean accuracy is less than of the Median. This is because it achieves far worse results in the Label Flip attack.",
            "Following what we did in RQ2, we report the summary of aggregators for this dataset in Table 5. Unlike RQ2, the Overlap mutator is also included here since it showed to be effective for this dataset.",
            "According to the table, Trimmed Mean gets the best results for untargeted attacks and mutators, and Median comes in second with a negligible difference. All aggregators lose the competition to the attacker for the Backdoor attack except Krum, which shows decent robustness, but its main task accuracy can still be problematic.",
            "We report the results in Table 6. Out of these 12 configurations, the ensemble aggregator is the best option in Five cases, according to the median accuracies. Running statistical tests (Mann-Whitney U Test) shows that the ensemble is significantly better than the second technique in three cases out of five. However, in the remaining two cases, there is no significant difference. Furthermore, this difference is insignificant in four cases out of the seven remaining cases where the ensemble is not the best. As a result, in 75% of cases, the ensemble aggregator is the most reasonable choice. If were run the same test for other aggregators, Federated Averaging gets 25%, and the rest will achieve 33.3%, which clearly shows the ensemble method is superior.\nLastly, our ensemble technique achieves the highest mean accuracy compared to other aggregators.",
            "A summary of this paper’s contributions compared to some of the more related works is reported in Table 7.",
            "In this paper, we conducted a large-scale empirical study on the effect of faults and attacks on FL aggregators. We performed our experiments on two generic image datasets, each with three different distributions, one federated medical dataset, eight attacks and mutators, and four aggregation techniques resulting in 496 configurations.\nResults show that the Sign Flip and Backdoor attacks are the most effective attacks. Moreover, mutators do not significantly impact FL’s quality, except for the Overlap data mutator, which can affect Federated Averaging in the ADNI dataset. In addition, our study shows that there is no single best robust aggregator, and their accuracy depends on factors such as attack type, dataset, and data distribution. For instance, Krum is most robust in model poisoning attacks, but it is not acceptable in the Label Flip attacks. Inspired by the results of different aggregators, we show that an ensemble of these aggregators can be more robust than (or as good as) any single aggregator to improve the FL process quality in 75% of cases where the attacks and data distribution are unknown to the aggregator.\nIn the future, we plan to study different attack scenarios, e.g., a case where the attacker is aware of the aggregator used on the server. Also, we want to extend this study to other FL-exclusive issues, such as clients’ machines capabilities, learning frameworks, network failures, and arithmetic computation precision issues. Lastly, we want to extend the ensemble technique to make it effective against targeted attacks like the Backdoor attack and more efficient by using different heuristics while selecting the best aggregator in each round."
        ]
    },
    "S3.T5.sf2": {
        "caption": "(b) Results for Backdoor attack (lower accuracy is better)",
        "table": "<table id=\"S3.T5.sf2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T5.sf2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf2.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S3.T5.sf2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">Backdoor accuracy</th>\n<th id=\"S3.T5.sf2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T5.sf2.1.1.1.3.1\" class=\"ltx_text\">\n<span id=\"S3.T5.sf2.1.1.1.3.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T5.sf2.1.1.1.3.1.1.1\" class=\"ltx_p\">Top rank</span>\n<span id=\"S3.T5.sf2.1.1.1.3.1.1.2\" class=\"ltx_p\">frequency</span>\n</span></span></th>\n</tr>\n<tr id=\"S3.T5.sf2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T5.sf2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Aggregator</th>\n<th id=\"S3.T5.sf2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Mean</th>\n<th id=\"S3.T5.sf2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Std</th>\n</tr>\n<tr id=\"S3.T5.sf2.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf2.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</td>\n<td id=\"S3.T5.sf2.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">99.47</td>\n<td id=\"S3.T5.sf2.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T5.sf2.1.3.3.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">0.75</span></td>\n<td id=\"S3.T5.sf2.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">0</td>\n</tr>\n<tr id=\"S3.T5.sf2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf2.1.4.4.1\" class=\"ltx_td ltx_align_center\">Krum</td>\n<td id=\"S3.T5.sf2.1.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T5.sf2.1.4.4.2.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">53.34</span></td>\n<td id=\"S3.T5.sf2.1.4.4.3\" class=\"ltx_td ltx_align_center\">5.05</td>\n<td id=\"S3.T5.sf2.1.4.4.4\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T5.sf2.1.4.4.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">3</span></td>\n</tr>\n<tr id=\"S3.T5.sf2.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf2.1.5.5.1\" class=\"ltx_td ltx_align_center\">Median</td>\n<td id=\"S3.T5.sf2.1.5.5.2\" class=\"ltx_td ltx_align_center\">96.9</td>\n<td id=\"S3.T5.sf2.1.5.5.3\" class=\"ltx_td ltx_align_center\">3.41</td>\n<td id=\"S3.T5.sf2.1.5.5.4\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"S3.T5.sf2.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T5.sf2.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">Tri-mean</td>\n<td id=\"S3.T5.sf2.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">97.92</td>\n<td id=\"S3.T5.sf2.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">2.09</td>\n<td id=\"S3.T5.sf2.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Models:\nOur models for generic datasets are simple convolutional neural networks with 12 and 7 layers for CIFAR-10 and Fashion MNIST, respectively, which are taken from Keras’ tutorials and examples (cif, 2021; mni, 2021). Table 1 shows a summary of the models used for Fashion MNIST and CIFAR-10 datasets.\nFor the ADNI dataset, we use a transfer learning (TL) approach using the VGG16 model (Simonyan and Zisserman, 2015) pre-trained on ImageNet (Russakovsky et al., 2015). Our classifier consists of one dense layer with 512 neurons and a rectified linear activation followed by a dense layer with two neurons and a softmax activation. The VGG16 weights were frozen during training.",
            "Furthermore, the mean and std values reported in the tables are taken across different configurations (e.g., non-iid degree) described in their related sections. The mean is taken over different configurations instead of the median since we want to consider all configurations equally in the final result. These mean and std values should not be confused with the median taken across different runs (mean and std are applied to the results of different configurations reported in different figures.). Also, other metrics like the median of different configurations and also the raw results for each configuration can be found in our replication package.",
            "To address this concern, we show how the image is affected when it gets mutated by the Noise mutator with different sigma multipliers in Figure 5. As the sigma multiplier increases, the image gets noisier as expected. However, if we increase it too much, the image gets unrecognizable, like in Figure 5e. Since the Noise mutator is supposed to simulate faults, extreme values for the sigma multiplier become unacceptable, and this is the reason that we set this parameter to be one in our experiments.",
            "We report a summary of faults’ effect on Federated Averaging in Table 2. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are affected by the mutators. As the results show, the mutators do not significantly impact the accuracy. However, out of the mutators, the Noise mutator has the most impact on the final model, which is less than 6% and is insignificant. Note that the statistical test results here show that in 20% of the cases, these differences are statistically the same as well, but in 80%, they are statistically different. However, the amount of difference itself is not actually significant (less than 6%).",
            "Like the faults section, we report a summary of attacks against Federated Averaging in Table 3. The change values reported are the amount of accuracy change between a clean scenario and the case where half of the clients are under attack.\nAmong the untargeted attacks, Random Update and Sign Flip are the most effective attacks against Federated Averaging, with around 70% accuracy change. Furthermore, all the attacks are much more effective than mutators as they decrease the accuracy by at least 21.26% (the best mutator did not even reach 6%). Furthermore, the statistical test shows that all these changes are statistically different as well.",
            "We report a summary of aggregators for CIFAR-10 and Fashion MNIST in Table 4 based on the average accuracy of the final model on the test data and the number of times each aggregator was the most robust one. Note that only attacks are selected here since data mutators were ineffective and untargeted attacks and backdoor attacks were split to avoid confusion. As it can be seen, Krum achieves the best accuracy on average and achieves the top rank the most in the CIFAR-10 dataset, so all in all, it is the most robust aggregation method for that dataset. For Fashion MNIST, Median is the most robust aggregator. However, considering the first rank count of aggregators, Krum comes in a close second, but its mean accuracy is less than of the Median. This is because it achieves far worse results in the Label Flip attack.",
            "Following what we did in RQ2, we report the summary of aggregators for this dataset in Table 5. Unlike RQ2, the Overlap mutator is also included here since it showed to be effective for this dataset.",
            "According to the table, Trimmed Mean gets the best results for untargeted attacks and mutators, and Median comes in second with a negligible difference. All aggregators lose the competition to the attacker for the Backdoor attack except Krum, which shows decent robustness, but its main task accuracy can still be problematic.",
            "We report the results in Table 6. Out of these 12 configurations, the ensemble aggregator is the best option in Five cases, according to the median accuracies. Running statistical tests (Mann-Whitney U Test) shows that the ensemble is significantly better than the second technique in three cases out of five. However, in the remaining two cases, there is no significant difference. Furthermore, this difference is insignificant in four cases out of the seven remaining cases where the ensemble is not the best. As a result, in 75% of cases, the ensemble aggregator is the most reasonable choice. If were run the same test for other aggregators, Federated Averaging gets 25%, and the rest will achieve 33.3%, which clearly shows the ensemble method is superior.\nLastly, our ensemble technique achieves the highest mean accuracy compared to other aggregators.",
            "A summary of this paper’s contributions compared to some of the more related works is reported in Table 7.",
            "In this paper, we conducted a large-scale empirical study on the effect of faults and attacks on FL aggregators. We performed our experiments on two generic image datasets, each with three different distributions, one federated medical dataset, eight attacks and mutators, and four aggregation techniques resulting in 496 configurations.\nResults show that the Sign Flip and Backdoor attacks are the most effective attacks. Moreover, mutators do not significantly impact FL’s quality, except for the Overlap data mutator, which can affect Federated Averaging in the ADNI dataset. In addition, our study shows that there is no single best robust aggregator, and their accuracy depends on factors such as attack type, dataset, and data distribution. For instance, Krum is most robust in model poisoning attacks, but it is not acceptable in the Label Flip attacks. Inspired by the results of different aggregators, we show that an ensemble of these aggregators can be more robust than (or as good as) any single aggregator to improve the FL process quality in 75% of cases where the attacks and data distribution are unknown to the aggregator.\nIn the future, we plan to study different attack scenarios, e.g., a case where the attacker is aware of the aggregator used on the server. Also, we want to extend this study to other FL-exclusive issues, such as clients’ machines capabilities, learning frameworks, network failures, and arithmetic computation precision issues. Lastly, we want to extend the ensemble technique to make it effective against targeted attacks like the Backdoor attack and more efficient by using different heuristics while selecting the best aggregator in each round."
        ]
    },
    "S3.T6": {
        "caption": "Table 6: Comparison of available aggregators with the ensemble aggregator.",
        "table": "<table id=\"S3.T6.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T6.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt\"></th>\n<th id=\"S3.T6.1.1.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt\"></th>\n<th id=\"S3.T6.1.1.1.3\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"></th>\n<th id=\"S3.T6.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"5\">Aggregator</th>\n</tr>\n<tr id=\"S3.T6.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row\">Dataset</th>\n<th id=\"S3.T6.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row\">Attack</th>\n<th id=\"S3.T6.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r\">portion</th>\n<th id=\"S3.T6.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">FedAvg</th>\n<th id=\"S3.T6.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Krum</th>\n<th id=\"S3.T6.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Median</th>\n<th id=\"S3.T6.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Tri-Mean</th>\n<th id=\"S3.T6.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Ensemble</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T6.1.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" rowspan=\"8\"><span id=\"S3.T6.1.3.1.1.1\" class=\"ltx_text\">CIFAR-10</span></th>\n<th id=\"S3.T6.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" rowspan=\"3\"><span id=\"S3.T6.1.3.1.2.1\" class=\"ltx_text\">Label Flip</span></th>\n<th id=\"S3.T6.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\">0.1</th>\n<td id=\"S3.T6.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.3.1.4.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">74.58</span></td>\n<td id=\"S3.T6.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">49.49</td>\n<td id=\"S3.T6.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">70.34</td>\n<td id=\"S3.T6.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\">73.2</td>\n<td id=\"S3.T6.1.3.1.8\" class=\"ltx_td ltx_align_center ltx_border_tt\">73.31</td>\n</tr>\n<tr id=\"S3.T6.1.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.3</th>\n<td id=\"S3.T6.1.4.2.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.4.2.2.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">66.81</span></td>\n<td id=\"S3.T6.1.4.2.3\" class=\"ltx_td ltx_align_center\">41.02</td>\n<td id=\"S3.T6.1.4.2.4\" class=\"ltx_td ltx_align_center\">54.13</td>\n<td id=\"S3.T6.1.4.2.5\" class=\"ltx_td ltx_align_center\">59.01</td>\n<td id=\"S3.T6.1.4.2.6\" class=\"ltx_td ltx_align_center\">64.85</td>\n</tr>\n<tr id=\"S3.T6.1.5.3\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.5</th>\n<td id=\"S3.T6.1.5.3.2\" class=\"ltx_td ltx_align_center\">36.4</td>\n<td id=\"S3.T6.1.5.3.3\" class=\"ltx_td ltx_align_center\">29.41</td>\n<td id=\"S3.T6.1.5.3.4\" class=\"ltx_td ltx_align_center\">27.59</td>\n<td id=\"S3.T6.1.5.3.5\" class=\"ltx_td ltx_align_center\">31.84</td>\n<td id=\"S3.T6.1.5.3.6\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.5.3.6.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">60.53</span></td>\n</tr>\n<tr id=\"S3.T6.1.6.4\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" rowspan=\"3\"><span id=\"S3.T6.1.6.4.1.1\" class=\"ltx_text\">Sign Flip</span></th>\n<th id=\"S3.T6.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.1</th>\n<td id=\"S3.T6.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">10.0</td>\n<td id=\"S3.T6.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">61.0</td>\n<td id=\"S3.T6.1.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">70.96</td>\n<td id=\"S3.T6.1.6.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\">10.0</td>\n<td id=\"S3.T6.1.6.4.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.6.4.7.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">72.08</span></td>\n</tr>\n<tr id=\"S3.T6.1.7.5\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.7.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.3</th>\n<td id=\"S3.T6.1.7.5.2\" class=\"ltx_td ltx_align_center\">10.0</td>\n<td id=\"S3.T6.1.7.5.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.7.5.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">60.62</span></td>\n<td id=\"S3.T6.1.7.5.4\" class=\"ltx_td ltx_align_center\">10.0</td>\n<td id=\"S3.T6.1.7.5.5\" class=\"ltx_td ltx_align_center\">10.0</td>\n<td id=\"S3.T6.1.7.5.6\" class=\"ltx_td ltx_align_center\">59.77</td>\n</tr>\n<tr id=\"S3.T6.1.8.6\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.8.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.5</th>\n<td id=\"S3.T6.1.8.6.2\" class=\"ltx_td ltx_align_center\">10.0</td>\n<td id=\"S3.T6.1.8.6.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.8.6.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">59.13</span></td>\n<td id=\"S3.T6.1.8.6.4\" class=\"ltx_td ltx_align_center\">10.0</td>\n<td id=\"S3.T6.1.8.6.5\" class=\"ltx_td ltx_align_center\">10.0</td>\n<td id=\"S3.T6.1.8.6.6\" class=\"ltx_td ltx_align_center\">10.0</td>\n</tr>\n<tr id=\"S3.T6.1.9.7\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.9.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"2\">Average</th>\n<td id=\"S3.T6.1.9.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">34.63</td>\n<td id=\"S3.T6.1.9.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">50.11</td>\n<td id=\"S3.T6.1.9.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">40.5</td>\n<td id=\"S3.T6.1.9.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">32.34</td>\n<td id=\"S3.T6.1.9.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.9.7.6.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">56.75</span></td>\n</tr>\n<tr id=\"S3.T6.1.10.8\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.10.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" colspan=\"2\">Std</th>\n<td id=\"S3.T6.1.10.8.2\" class=\"ltx_td ltx_align_center\">27.25</td>\n<td id=\"S3.T6.1.10.8.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.10.8.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">11.70</span></td>\n<td id=\"S3.T6.1.10.8.4\" class=\"ltx_td ltx_align_center\">25.92</td>\n<td id=\"S3.T6.1.10.8.5\" class=\"ltx_td ltx_align_center\">25.42</td>\n<td id=\"S3.T6.1.10.8.6\" class=\"ltx_td ltx_align_center\">21.54</td>\n</tr>\n<tr id=\"S3.T6.1.11.9\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.11.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\" rowspan=\"8\"><span id=\"S3.T6.1.11.9.1.1\" class=\"ltx_text\">ADNI</span></th>\n<th id=\"S3.T6.1.11.9.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" rowspan=\"3\"><span id=\"S3.T6.1.11.9.2.1\" class=\"ltx_text\">Label Flip</span></th>\n<th id=\"S3.T6.1.11.9.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.1</th>\n<td id=\"S3.T6.1.11.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">69.09</td>\n<td id=\"S3.T6.1.11.9.5\" class=\"ltx_td ltx_align_center ltx_border_t\">61.07</td>\n<td id=\"S3.T6.1.11.9.6\" class=\"ltx_td ltx_align_center ltx_border_t\">69.68</td>\n<td id=\"S3.T6.1.11.9.7\" class=\"ltx_td ltx_align_center ltx_border_t\">69.1</td>\n<td id=\"S3.T6.1.11.9.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.11.9.8.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">70.03</span></td>\n</tr>\n<tr id=\"S3.T6.1.12.10\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.12.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.3</th>\n<td id=\"S3.T6.1.12.10.2\" class=\"ltx_td ltx_align_center\">58.2</td>\n<td id=\"S3.T6.1.12.10.3\" class=\"ltx_td ltx_align_center\">59.28</td>\n<td id=\"S3.T6.1.12.10.4\" class=\"ltx_td ltx_align_center\">61.01</td>\n<td id=\"S3.T6.1.12.10.5\" class=\"ltx_td ltx_align_center\">60.59</td>\n<td id=\"S3.T6.1.12.10.6\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.12.10.6.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">65.46</span></td>\n</tr>\n<tr id=\"S3.T6.1.13.11\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.13.11.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.5</th>\n<td id=\"S3.T6.1.13.11.2\" class=\"ltx_td ltx_align_center\">54.02</td>\n<td id=\"S3.T6.1.13.11.3\" class=\"ltx_td ltx_align_center\">45.39</td>\n<td id=\"S3.T6.1.13.11.4\" class=\"ltx_td ltx_align_center\">46.13</td>\n<td id=\"S3.T6.1.13.11.5\" class=\"ltx_td ltx_align_center\">48.41</td>\n<td id=\"S3.T6.1.13.11.6\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.13.11.6.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">65.83</span></td>\n</tr>\n<tr id=\"S3.T6.1.14.12\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.14.12.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" rowspan=\"3\"><span id=\"S3.T6.1.14.12.1.1\" class=\"ltx_text\">Sign Flip</span></th>\n<th id=\"S3.T6.1.14.12.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.1</th>\n<td id=\"S3.T6.1.14.12.3\" class=\"ltx_td ltx_align_center ltx_border_t\">34.49</td>\n<td id=\"S3.T6.1.14.12.4\" class=\"ltx_td ltx_align_center ltx_border_t\">63.46</td>\n<td id=\"S3.T6.1.14.12.5\" class=\"ltx_td ltx_align_center ltx_border_t\">71.61</td>\n<td id=\"S3.T6.1.14.12.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.14.12.6.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">72.9</span></td>\n<td id=\"S3.T6.1.14.12.7\" class=\"ltx_td ltx_align_center ltx_border_t\">71.5</td>\n</tr>\n<tr id=\"S3.T6.1.15.13\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.15.13.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.3</th>\n<td id=\"S3.T6.1.15.13.2\" class=\"ltx_td ltx_align_center\">34.49</td>\n<td id=\"S3.T6.1.15.13.3\" class=\"ltx_td ltx_align_center\">66.17</td>\n<td id=\"S3.T6.1.15.13.4\" class=\"ltx_td ltx_align_center\">67.75</td>\n<td id=\"S3.T6.1.15.13.5\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.15.13.5.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">69.12</span></td>\n<td id=\"S3.T6.1.15.13.6\" class=\"ltx_td ltx_align_center\">65.69</td>\n</tr>\n<tr id=\"S3.T6.1.16.14\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.16.14.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.5</th>\n<td id=\"S3.T6.1.16.14.2\" class=\"ltx_td ltx_align_center\">34.49</td>\n<td id=\"S3.T6.1.16.14.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.16.14.3.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">67.46</span></td>\n<td id=\"S3.T6.1.16.14.4\" class=\"ltx_td ltx_align_center\">34.49</td>\n<td id=\"S3.T6.1.16.14.5\" class=\"ltx_td ltx_align_center\">34.49</td>\n<td id=\"S3.T6.1.16.14.6\" class=\"ltx_td ltx_align_center\">49.34</td>\n</tr>\n<tr id=\"S3.T6.1.17.15\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.17.15.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"2\">Average</th>\n<td id=\"S3.T6.1.17.15.2\" class=\"ltx_td ltx_align_center ltx_border_t\">47.46</td>\n<td id=\"S3.T6.1.17.15.3\" class=\"ltx_td ltx_align_center ltx_border_t\">60.47</td>\n<td id=\"S3.T6.1.17.15.4\" class=\"ltx_td ltx_align_center ltx_border_t\">58.45</td>\n<td id=\"S3.T6.1.17.15.5\" class=\"ltx_td ltx_align_center ltx_border_t\">59.1</td>\n<td id=\"S3.T6.1.17.15.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.17.15.6.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">64.64</span></td>\n</tr>\n<tr id=\"S3.T6.1.18.16\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.18.16.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" colspan=\"2\">Std</th>\n<td id=\"S3.T6.1.18.16.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">13.73</td>\n<td id=\"S3.T6.1.18.16.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">7.30</td>\n<td id=\"S3.T6.1.18.16.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">13.65</td>\n<td id=\"S3.T6.1.18.16.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">13.62</td>\n<td id=\"S3.T6.1.18.16.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"background-color:#DFDFDF;\"><span id=\"S3.T6.1.18.16.6.1\" class=\"ltx_text\" style=\"background-color:#DFDFDF;\">7.23</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We report the results in Table 6. Out of these 12 configurations, the ensemble aggregator is the best option in Five cases, according to the median accuracies. Running statistical tests (Mann-Whitney U Test) shows that the ensemble is significantly better than the second technique in three cases out of five. However, in the remaining two cases, there is no significant difference. Furthermore, this difference is insignificant in four cases out of the seven remaining cases where the ensemble is not the best. As a result, in 75% of cases, the ensemble aggregator is the most reasonable choice. If were run the same test for other aggregators, Federated Averaging gets 25%, and the rest will achieve 33.3%, which clearly shows the ensemble method is superior.\nLastly, our ensemble technique achieves the highest mean accuracy compared to other aggregators."
        ]
    },
    "S4.T7": {
        "caption": "Table 7: Contributions of this study compared to related works.",
        "table": "<table id=\"S4.T7.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T7.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T7.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" style=\"width:60.7pt;\"></th>\n<th id=\"S4.T7.1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.1.1.2.1.1\" class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_cite\">Li et al. (<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">2019</a>)</cite></span>\n</span>\n</th>\n<th id=\"S4.T7.1.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.1.1.3.1.1\" class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_cite\">Wan and Chen (<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">2021</a>)</cite></span>\n</span>\n</th>\n<th id=\"S4.T7.1.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.1.1.4.1.1\" class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_cite\">Fang et al. (<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></span>\n</span>\n</th>\n<th id=\"S4.T7.1.1.1.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.1.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.1.1.5.1.1\" class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_cite\">Bhagoji et al. (<a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">2019</a>)</cite></span>\n</span>\n</th>\n<th id=\"S4.T7.1.1.1.6\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.1.1.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.1.1.6.1.1\" class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_cite\">Lyu et al. (<a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></span>\n</span>\n</th>\n<th id=\"S4.T7.1.1.1.7\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.1.1.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.1.1.7.1.1\" class=\"ltx_p\">Our study</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T7.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T7.1.2.1.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_tt\" style=\"width:60.7pt;\">\n<span id=\"S4.T7.1.2.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.2.1.1.1.1\" class=\"ltx_p\">Aggregators</span>\n</span>\n</td>\n<td id=\"S4.T7.1.2.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.2.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.2.1.2.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.2.1.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.2.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.2.1.3.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.2.1.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.2.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.2.1.4.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.2.1.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.2.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.2.1.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.2.1.6\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.2.1.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.2.1.6.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.2.1.7\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_tt\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.2.1.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.2.1.7.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T7.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T7.1.3.2.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:60.7pt;\">\n<span id=\"S4.T7.1.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.3.2.1.1.1\" class=\"ltx_p\">Untargeted</span>\n<span id=\"S4.T7.1.3.2.1.1.2\" class=\"ltx_p\">attacks</span>\n</span>\n</td>\n<td id=\"S4.T7.1.3.2.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.3.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.3.2.2.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.3.2.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.3.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.3.2.3.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.3.2.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.3.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.3.2.4.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.3.2.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.3.2.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.3.2.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.3.2.6\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.3.2.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.3.2.6.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.3.2.7\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.3.2.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.3.2.7.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T7.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T7.1.4.3.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:60.7pt;\">\n<span id=\"S4.T7.1.4.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.4.3.1.1.1\" class=\"ltx_p\">Targeted</span>\n<span id=\"S4.T7.1.4.3.1.1.2\" class=\"ltx_p\">attacks</span>\n</span>\n</td>\n<td id=\"S4.T7.1.4.3.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.4.3.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.4.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.4.3.3.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.4.3.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.4.3.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.4.3.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.4.3.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.4.3.6\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.4.3.7\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.4.3.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.4.3.7.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T7.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T7.1.5.4.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:60.7pt;\">\n<span id=\"S4.T7.1.5.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.5.4.1.1.1\" class=\"ltx_p\">Faults</span>\n</span>\n</td>\n<td id=\"S4.T7.1.5.4.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.5.4.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.5.4.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.5.4.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.5.4.6\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.5.4.7\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.5.4.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.5.4.7.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T7.1.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T7.1.6.5.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:60.7pt;\">\n<span id=\"S4.T7.1.6.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.6.5.1.1.1\" class=\"ltx_p\">Cross-device</span>\n</span>\n</td>\n<td id=\"S4.T7.1.6.5.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.6.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.6.5.2.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.6.5.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.6.5.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.6.5.3.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.6.5.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.6.5.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.6.5.4.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.6.5.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.6.5.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.6.5.5.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.6.5.6\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.6.5.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.6.5.6.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.6.5.7\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.6.5.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.6.5.7.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T7.1.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T7.1.7.6.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:60.7pt;\">\n<span id=\"S4.T7.1.7.6.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.7.6.1.1.1\" class=\"ltx_p\">Cross-silo</span>\n</span>\n</td>\n<td id=\"S4.T7.1.7.6.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.7.6.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.7.6.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.7.6.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.7.6.6\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.7.6.7\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.7.6.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.7.6.7.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T7.1.8.7\" class=\"ltx_tr\">\n<td id=\"S4.T7.1.8.7.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:60.7pt;\">\n<span id=\"S4.T7.1.8.7.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.8.7.1.1.1\" class=\"ltx_p\">Multiple distributions</span>\n</span>\n</td>\n<td id=\"S4.T7.1.8.7.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.8.7.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.8.7.2.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.8.7.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.8.7.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.8.7.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.8.7.4.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.8.7.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.8.7.6\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.8.7.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.8.7.6.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.8.7.7\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.8.7.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.8.7.7.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T7.1.9.8\" class=\"ltx_tr\">\n<td id=\"S4.T7.1.9.8.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:60.7pt;\">\n<span id=\"S4.T7.1.9.8.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.9.8.1.1.1\" class=\"ltx_p\">New aggregation</span>\n<span id=\"S4.T7.1.9.8.1.1.2\" class=\"ltx_p\">technique</span>\n</span>\n</td>\n<td id=\"S4.T7.1.9.8.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.9.8.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.9.8.2.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.9.8.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.9.8.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.9.8.3.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n<td id=\"S4.T7.1.9.8.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.9.8.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.9.8.6\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\"></td>\n<td id=\"S4.T7.1.9.8.7\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.9.8.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.9.8.7.1.1\" class=\"ltx_p\">✓</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T7.1.10.9\" class=\"ltx_tr\">\n<td id=\"S4.T7.1.10.9.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_t\" style=\"width:60.7pt;\">\n<span id=\"S4.T7.1.10.9.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.10.9.1.1.1\" class=\"ltx_p\">Limitations</span>\n</span>\n</td>\n<td id=\"S4.T7.1.10.9.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.10.9.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.10.9.2.1.1\" class=\"ltx_p\">Technique needs tuning for different cases</span>\n</span>\n</td>\n<td id=\"S4.T7.1.10.9.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.10.9.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.10.9.3.1.1\" class=\"ltx_p\">Not generaizable and scalable</span>\n</span>\n</td>\n<td id=\"S4.T7.1.10.9.4\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.10.9.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.10.9.4.1.1\" class=\"ltx_p\">Federated Averaging is not considered</span>\n</span>\n</td>\n<td id=\"S4.T7.1.10.9.5\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.10.9.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.10.9.5.1.1\" class=\"ltx_p\">Does not consider different proportion of attackers</span>\n</span>\n</td>\n<td id=\"S4.T7.1.10.9.6\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.10.9.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.10.9.6.1.1\" class=\"ltx_p\">The study is purely theoretical</span>\n</span>\n</td>\n<td id=\"S4.T7.1.10.9.7\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_t\" style=\"width:43.4pt;\">\n<span id=\"S4.T7.1.10.9.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T7.1.10.9.7.1.1\" class=\"ltx_p\">New technique works only on untargeted attacks</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "A summary of this paper’s contributions compared to some of the more related works is reported in Table 7."
        ]
    }
}