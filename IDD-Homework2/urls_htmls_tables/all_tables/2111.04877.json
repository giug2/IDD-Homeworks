{
    "PAPER'S NUMBER OF TABLES": 1,
    "S7.T1": {
        "caption": "Table 1: Test perplexity (lower is better) after 1 million client updates. Perplexity is a measure of language model accuracy. We partition clients into percentiles, based on the training data volume. All signifies all clients; 75% and 99% represent clients with data volume in the 75th and 99th percentiles, respectively. SyncFL w/o OS denotes SyncFL without over-selection and SyncFL w/ OS denotes SyncFL with over-selection",
        "table": "<table id=\"S7.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S7.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S7.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Method</th>\n<th id=\"S7.T1.1.1.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\">All</th>\n<th id=\"S7.T1.1.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\">75%</th>\n<th id=\"S7.T1.1.1.1.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\">99%</th>\n<th id=\"S7.T1.1.1.1.5\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\">Time (hour)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S7.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S7.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">SyncFL w/o OS</th>\n<td id=\"S7.T1.1.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\">68.38</td>\n<td id=\"S7.T1.1.2.1.3\" class=\"ltx_td ltx_align_right ltx_border_t\">66.64</td>\n<td id=\"S7.T1.1.2.1.4\" class=\"ltx_td ltx_align_right ltx_border_t\">47.82</td>\n<td id=\"S7.T1.1.2.1.5\" class=\"ltx_td ltx_align_right ltx_border_t\">130.60</td>\n</tr>\n<tr id=\"S7.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S7.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">SyncFL with OS</th>\n<td id=\"S7.T1.1.3.2.2\" class=\"ltx_td ltx_align_right\">72.97</td>\n<td id=\"S7.T1.1.3.2.3\" class=\"ltx_td ltx_align_right\">73.10</td>\n<td id=\"S7.T1.1.3.2.4\" class=\"ltx_td ltx_align_right\">73.24</td>\n<td id=\"S7.T1.1.3.2.5\" class=\"ltx_td ltx_align_right\">18.63</td>\n</tr>\n<tr id=\"S7.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S7.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">AsyncFL</th>\n<td id=\"S7.T1.1.4.3.2\" class=\"ltx_td ltx_align_right ltx_border_bb\">57.32</td>\n<td id=\"S7.T1.1.4.3.3\" class=\"ltx_td ltx_align_right ltx_border_bb\">55.71</td>\n<td id=\"S7.T1.1.4.3.4\" class=\"ltx_td ltx_align_right ltx_border_bb\">38.51</td>\n<td id=\"S7.T1.1.4.3.5\" class=\"ltx_td ltx_align_right ltx_border_bb\">18.28</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To compare the effectiveness of over-selection and asynchronous training in combating stragglers, we examine the distribution of participating clients, their execution time, and the number of training examples. ",
                "Figure",
                "¬†",
                "11",
                " illustrates the discrepancy between the client execution time distribution of SyncFL with and without over-selection. Since over-selection discards updates from some clients, the distribution of SyncFL without over-selection should be considered representative of the entire client population. ",
                "Figure",
                "¬†",
                "11",
                " (top-left) shows that over-selection drops slow clients, as desired. However, as illustrated in ",
                "Figure",
                "¬†",
                "11",
                " (top-right), the slowest clients often have more training examples.",
                "To rigorously assess the difference, we perform a two-sample Kolmogorov-Smirnov test¬†",
                "Chakravarti et¬†al. (",
                "1967",
                ")",
                " to measure the goodness of fit between AsyncFL, SyncFL with over-selection, and the ground truth distribution (SyncFL without over-selection). We find that the D-statistic, representing the absolute max distance between the cumulative distribution functions of the two samples, for AsyncFL and the ground truth is ",
                "8.8",
                "√ó",
                "10",
                "‚àí",
                "4",
                "8.8",
                "superscript",
                "10",
                "4",
                "8.8\\times 10^{-4}",
                " (",
                "p",
                "ùëù",
                "p",
                "-value = 0.98). In comparison, the D-statistic for SyncFL with over-selection and the ground truth is ",
                "6.6",
                "√ó",
                "10",
                "‚àí",
                "2",
                "6.6",
                "superscript",
                "10",
                "2",
                "6.6\\times 10^{-2}",
                " (",
                "p",
                "ùëù",
                "p",
                "-value = 0.0). This result shows that AsyncFL and the ground truth have similar distributions while SyncFL with over-selection does not.\nThus, over-selection introduces sampling bias while AsyncFL does not. The sampling probability is conditioned on the client‚Äôs device speed or the number of training examples. Next, we show that sampling bias hurts model performance, especially for clients with more training examples.",
                "Table",
                "¬†",
                "1",
                " reports the model quality in test perplexity for all clients and those with data volume in the 75% and 99% percentile. Perplexity is a measure of language model accuracy (lower is better). The sampling bias from over-selection in SyncFL causes a 6% drop in model quality overall and a 50% drop in model quality for clients with more examples. Although SyncFL without over-selection is unbiased, it is also 10",
                "√ó",
                "\\times",
                " slower. On the other hand, AsyncFL combines fast training with high model quality and no sampling bias. Meanwhile, SyncFL with over-selection has to choose between sampling bias or straggler resilence. In summary, AsyncFL is a more desirable method to address the impact of stragglers."
            ]
        ]
    }
}