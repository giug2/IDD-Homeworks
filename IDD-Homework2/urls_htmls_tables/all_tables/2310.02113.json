{
    "PAPER'S NUMBER OF TABLES": 4,
    "S5.T1": {
        "caption": "Table 1. Dataset description for different learning tasks.",
        "table": "<table id=\"S5.T1.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.6.7.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.6.7.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S5.T1.6.7.1.1.1\" class=\"ltx_text ltx_font_bold\">Application</span></th>\n<th id=\"S5.T1.6.7.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"3\"><span id=\"S5.T1.6.7.1.2.1\" class=\"ltx_text ltx_font_bold\">IC</span></th>\n<th id=\"S5.T1.6.7.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S5.T1.6.7.1.3.1\" class=\"ltx_text ltx_font_bold\">WP</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.6.8.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.6.8.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S5.T1.6.8.1.1.1\" class=\"ltx_text ltx_font_bold\">Datasets</span></th>\n<td id=\"S5.T1.6.8.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MNIST</td>\n<td id=\"S5.T1.6.8.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Fashion</td>\n<td id=\"S5.T1.6.8.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CIFAR-10</td>\n<td id=\"S5.T1.6.8.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Reddit</td>\n</tr>\n<tr id=\"S5.T1.6.9.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.6.9.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S5.T1.6.9.2.1.1\" class=\"ltx_text ltx_font_bold\">#Records</span></th>\n<td id=\"S5.T1.6.9.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">70K</td>\n<td id=\"S5.T1.6.9.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">70K</td>\n<td id=\"S5.T1.6.9.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">60K</td>\n<td id=\"S5.T1.6.9.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">20.6M</td>\n</tr>\n<tr id=\"S5.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S5.T1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<td id=\"S5.T1.1.1.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CNN</td>\n<td id=\"S5.T1.1.1.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CNN</td>\n<td id=\"S5.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S5.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\textnormal{ConvMixer}_{256/3}\" display=\"inline\"><semantics id=\"S5.T1.1.1.1.m1.1a\"><msub id=\"S5.T1.1.1.1.m1.1.1\" xref=\"S5.T1.1.1.1.m1.1.1.cmml\"><mtext id=\"S5.T1.1.1.1.m1.1.1.2\" xref=\"S5.T1.1.1.1.m1.1.1.2a.cmml\">ConvMixer</mtext><mrow id=\"S5.T1.1.1.1.m1.1.1.3\" xref=\"S5.T1.1.1.1.m1.1.1.3.cmml\"><mn id=\"S5.T1.1.1.1.m1.1.1.3.2\" xref=\"S5.T1.1.1.1.m1.1.1.3.2.cmml\">256</mn><mo id=\"S5.T1.1.1.1.m1.1.1.3.1\" xref=\"S5.T1.1.1.1.m1.1.1.3.1.cmml\">/</mo><mn id=\"S5.T1.1.1.1.m1.1.1.3.3\" xref=\"S5.T1.1.1.1.m1.1.1.3.3.cmml\">3</mn></mrow></msub><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.1.1.1.m1.1b\"><apply id=\"S5.T1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S5.T1.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T1.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S5.T1.1.1.1.m1.1.1.2a.cmml\" xref=\"S5.T1.1.1.1.m1.1.1.2\"><mtext id=\"S5.T1.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T1.1.1.1.m1.1.1.2\">ConvMixer</mtext></ci><apply id=\"S5.T1.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T1.1.1.1.m1.1.1.3\"><divide id=\"S5.T1.1.1.1.m1.1.1.3.1.cmml\" xref=\"S5.T1.1.1.1.m1.1.1.3.1\"></divide><cn type=\"integer\" id=\"S5.T1.1.1.1.m1.1.1.3.2.cmml\" xref=\"S5.T1.1.1.1.m1.1.1.3.2\">256</cn><cn type=\"integer\" id=\"S5.T1.1.1.1.m1.1.1.3.3.cmml\" xref=\"S5.T1.1.1.1.m1.1.1.3.3\">3</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.1.1.1.m1.1c\">\\textnormal{ConvMixer}_{256/3}</annotation></semantics></math></td>\n<td id=\"S5.T1.1.1.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">LSTM</td>\n</tr>\n<tr id=\"S5.T1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.5.5.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S5.T1.5.5.5.1\" class=\"ltx_text ltx_font_bold\">#params</span></th>\n<td id=\"S5.T1.2.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<math id=\"S5.T1.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sim 23\" display=\"inline\"><semantics id=\"S5.T1.2.2.1.m1.1a\"><mrow id=\"S5.T1.2.2.1.m1.1.1\" xref=\"S5.T1.2.2.1.m1.1.1.cmml\"><mi id=\"S5.T1.2.2.1.m1.1.1.2\" xref=\"S5.T1.2.2.1.m1.1.1.2.cmml\"></mi><mo id=\"S5.T1.2.2.1.m1.1.1.1\" xref=\"S5.T1.2.2.1.m1.1.1.1.cmml\">‚àº</mo><mn id=\"S5.T1.2.2.1.m1.1.1.3\" xref=\"S5.T1.2.2.1.m1.1.1.3.cmml\">23</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.2.2.1.m1.1b\"><apply id=\"S5.T1.2.2.1.m1.1.1.cmml\" xref=\"S5.T1.2.2.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S5.T1.2.2.1.m1.1.1.1.cmml\" xref=\"S5.T1.2.2.1.m1.1.1.1\">similar-to</csymbol><csymbol cd=\"latexml\" id=\"S5.T1.2.2.1.m1.1.1.2.cmml\" xref=\"S5.T1.2.2.1.m1.1.1.2\">absent</csymbol><cn type=\"integer\" id=\"S5.T1.2.2.1.m1.1.1.3.cmml\" xref=\"S5.T1.2.2.1.m1.1.1.3\">23</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.2.2.1.m1.1c\">\\sim 23</annotation></semantics></math>K</td>\n<td id=\"S5.T1.3.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<math id=\"S5.T1.3.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\sim 29\" display=\"inline\"><semantics id=\"S5.T1.3.3.2.m1.1a\"><mrow id=\"S5.T1.3.3.2.m1.1.1\" xref=\"S5.T1.3.3.2.m1.1.1.cmml\"><mi id=\"S5.T1.3.3.2.m1.1.1.2\" xref=\"S5.T1.3.3.2.m1.1.1.2.cmml\"></mi><mo id=\"S5.T1.3.3.2.m1.1.1.1\" xref=\"S5.T1.3.3.2.m1.1.1.1.cmml\">‚àº</mo><mn id=\"S5.T1.3.3.2.m1.1.1.3\" xref=\"S5.T1.3.3.2.m1.1.1.3.cmml\">29</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.3.3.2.m1.1b\"><apply id=\"S5.T1.3.3.2.m1.1.1.cmml\" xref=\"S5.T1.3.3.2.m1.1.1\"><csymbol cd=\"latexml\" id=\"S5.T1.3.3.2.m1.1.1.1.cmml\" xref=\"S5.T1.3.3.2.m1.1.1.1\">similar-to</csymbol><csymbol cd=\"latexml\" id=\"S5.T1.3.3.2.m1.1.1.2.cmml\" xref=\"S5.T1.3.3.2.m1.1.1.2\">absent</csymbol><cn type=\"integer\" id=\"S5.T1.3.3.2.m1.1.1.3.cmml\" xref=\"S5.T1.3.3.2.m1.1.1.3\">29</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.3.3.2.m1.1c\">\\sim 29</annotation></semantics></math>K</td>\n<td id=\"S5.T1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<math id=\"S5.T1.4.4.3.m1.1\" class=\"ltx_Math\" alttext=\"\\sim 234\" display=\"inline\"><semantics id=\"S5.T1.4.4.3.m1.1a\"><mrow id=\"S5.T1.4.4.3.m1.1.1\" xref=\"S5.T1.4.4.3.m1.1.1.cmml\"><mi id=\"S5.T1.4.4.3.m1.1.1.2\" xref=\"S5.T1.4.4.3.m1.1.1.2.cmml\"></mi><mo id=\"S5.T1.4.4.3.m1.1.1.1\" xref=\"S5.T1.4.4.3.m1.1.1.1.cmml\">‚àº</mo><mn id=\"S5.T1.4.4.3.m1.1.1.3\" xref=\"S5.T1.4.4.3.m1.1.1.3.cmml\">234</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.4.4.3.m1.1b\"><apply id=\"S5.T1.4.4.3.m1.1.1.cmml\" xref=\"S5.T1.4.4.3.m1.1.1\"><csymbol cd=\"latexml\" id=\"S5.T1.4.4.3.m1.1.1.1.cmml\" xref=\"S5.T1.4.4.3.m1.1.1.1\">similar-to</csymbol><csymbol cd=\"latexml\" id=\"S5.T1.4.4.3.m1.1.1.2.cmml\" xref=\"S5.T1.4.4.3.m1.1.1.2\">absent</csymbol><cn type=\"integer\" id=\"S5.T1.4.4.3.m1.1.1.3.cmml\" xref=\"S5.T1.4.4.3.m1.1.1.3\">234</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.4.4.3.m1.1c\">\\sim 234</annotation></semantics></math>K</td>\n<td id=\"S5.T1.5.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<math id=\"S5.T1.5.5.4.m1.1\" class=\"ltx_Math\" alttext=\"\\sim 20\" display=\"inline\"><semantics id=\"S5.T1.5.5.4.m1.1a\"><mrow id=\"S5.T1.5.5.4.m1.1.1\" xref=\"S5.T1.5.5.4.m1.1.1.cmml\"><mi id=\"S5.T1.5.5.4.m1.1.1.2\" xref=\"S5.T1.5.5.4.m1.1.1.2.cmml\"></mi><mo id=\"S5.T1.5.5.4.m1.1.1.1\" xref=\"S5.T1.5.5.4.m1.1.1.1.cmml\">‚àº</mo><mn id=\"S5.T1.5.5.4.m1.1.1.3\" xref=\"S5.T1.5.5.4.m1.1.1.3.cmml\">20</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.5.5.4.m1.1b\"><apply id=\"S5.T1.5.5.4.m1.1.1.cmml\" xref=\"S5.T1.5.5.4.m1.1.1\"><csymbol cd=\"latexml\" id=\"S5.T1.5.5.4.m1.1.1.1.cmml\" xref=\"S5.T1.5.5.4.m1.1.1.1\">similar-to</csymbol><csymbol cd=\"latexml\" id=\"S5.T1.5.5.4.m1.1.1.2.cmml\" xref=\"S5.T1.5.5.4.m1.1.1.2\">absent</csymbol><cn type=\"integer\" id=\"S5.T1.5.5.4.m1.1.1.3.cmml\" xref=\"S5.T1.5.5.4.m1.1.1.3\">20</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.5.5.4.m1.1c\">\\sim 20</annotation></semantics></math>M</td>\n</tr>\n<tr id=\"S5.T1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T1.6.6.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S5.T1.6.6.2.1\" class=\"ltx_text ltx_font_bold\">#ciphers</span></th>\n<td id=\"S5.T1.6.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">12</td>\n<td id=\"S5.T1.6.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">15</td>\n<td id=\"S5.T1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">115</td>\n<td id=\"S5.T1.6.6.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<math id=\"S5.T1.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sim 10.1\" display=\"inline\"><semantics id=\"S5.T1.6.6.1.m1.1a\"><mrow id=\"S5.T1.6.6.1.m1.1.1\" xref=\"S5.T1.6.6.1.m1.1.1.cmml\"><mi id=\"S5.T1.6.6.1.m1.1.1.2\" xref=\"S5.T1.6.6.1.m1.1.1.2.cmml\"></mi><mo id=\"S5.T1.6.6.1.m1.1.1.1\" xref=\"S5.T1.6.6.1.m1.1.1.1.cmml\">‚àº</mo><mn id=\"S5.T1.6.6.1.m1.1.1.3\" xref=\"S5.T1.6.6.1.m1.1.1.3.cmml\">10.1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.6.6.1.m1.1b\"><apply id=\"S5.T1.6.6.1.m1.1.1.cmml\" xref=\"S5.T1.6.6.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S5.T1.6.6.1.m1.1.1.1.cmml\" xref=\"S5.T1.6.6.1.m1.1.1.1\">similar-to</csymbol><csymbol cd=\"latexml\" id=\"S5.T1.6.6.1.m1.1.1.2.cmml\" xref=\"S5.T1.6.6.1.m1.1.1.2\">absent</csymbol><cn type=\"float\" id=\"S5.T1.6.6.1.m1.1.1.3.cmml\" xref=\"S5.T1.6.6.1.m1.1.1.3\">10.1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.6.6.1.m1.1c\">\\sim 10.1</annotation></semantics></math>K</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "The following sections illustrate our testbed, and describe the datasets and models used during evaluation. Note that a detailed list of evaluation metrics is provided in App.¬†",
                "E",
                ". \n",
                "Experimental Testbed.",
                " We simulate a generic blockchain using Hyperledger Fabric (HLF) to illustrate the practicality of our approach for other blockchain implementations. For experimental setup, we abstract away the complexities introduced by the consensus protocol, and instead focus on the computational entanglements added by FLEDGE. This is because FLEDGE relies solely on smart contracts rather than the underlying blockchain platform. To instantiate the simulation environment, we deploy docker containers on a Windows PC with Intel Core i7-9750H and 32 GB RAM. The blockchain test network is formed by a single ordering node operated by single organization with two peers transacting under a single communication channel.",
                "To fit multiple encrypted models within a single block, we increase the block size to 100MB. Note that this is 100 times larger than a Bitcoin block (1MB) ",
                "(Nakamoto, ",
                "2019",
                ")",
                ". We implement the gateway and defender contracts (chaincodes) using NodeJS and the Node-SEAL library. Node-SEAL\nis a NodeJS wrapper library used to interface with Microsoft SEAL ",
                "(Chen et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", an efficient and open-source HE library available in C++. Our HE setup uses a ",
                "PolyDeg",
                " of 4096 to encrypt local models. To evaluate models, we use Pytorch in an Ubuntu 20 server with 2 AMD EPYC 7302, 480 GB RAM, and 6 NVIDIA A100 (40 GB RAM each).\n",
                "Datasets and Models.",
                " To assess FLEDGE, we use two popular FL applications: word prediction (WP) ",
                "(McMahan et¬†al",
                ".",
                ", ",
                "2017a",
                ", ",
                "b",
                ")",
                ", and image classification (IC) ",
                "(Sheller et¬†al",
                ".",
                ", ",
                "2018",
                "; Chilimbi et¬†al",
                ".",
                ", ",
                "2014",
                "; Li et¬†al",
                ".",
                ", ",
                "2023",
                ")",
                ". Note that every model used for evaluation has been pre-trained to reach an acceptable accuracy level. Tab.¬†",
                "1",
                " describes the dataset types (Dataset), the rounded number of records per dataset (#Records), the AI models used for training (Model), the number of trainable parameters (#params) and the number of ciphers (#ciphers) found per model. We use smaller models with fewer trainable parameters for IC datasets, compared with WP, to evaluate how model complexity impacts FLEDGE.\n",
                "Word Prediction (WP).",
                " We use the Reddit dataset as example of WP for Natural Language Processing (NLP) applications, e.g., the real-world FL application G-Board¬†",
                "(McMahan and Ramage, ",
                "2017",
                ")",
                ". The dataset contains over 20M records of reddit users‚Äô posts from November 2017. Following previous work ",
                "(Rieger et¬†al",
                ".",
                ", ",
                "2022",
                "; Bagdasaryan et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " we use a 2-layer LSTM model.\n",
                "Image Classification (IC).",
                " We selected three popular IC datasets of different image complexity: MNIST, Fashion-MNIST (or Fashion for short) and CIFAR-10. They all consist of 10 evenly divided categories, where MNIST contains 70K handwritten digits, Fashion has 70K images of articles of clothing (i.e., shoe, dress, shirt), and CIFAR-10 has 60K pictures of objects (i.e., frog, airplane, car). For MNIST and Fashion, we use a simple CNN model comprised of 1 and 2 CNN layers, respectively. We customized the ConvMixer model ",
                "(Trockman and Kolter, ",
                "2022",
                ")",
                " to train CIFAR-10 with a width of 256. \n",
                "Backdoor Attacks.",
                " Aligned with earlier work¬†",
                "(Bagdasaryan et¬†al",
                ".",
                ", ",
                "2020",
                "; Andreina et¬†al",
                ".",
                ", ",
                "2021",
                "; Nguyen et¬†al",
                ".",
                ", ",
                "2022",
                ")",
                " we use the constrain-and-scale attack of Bagdsaryan ",
                "et¬†al.",
                "¬†",
                "(Bagdasaryan et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                ". Note that we focus on adaptive attacks, e.g., adversary adapts the loss function using the same metric as the defensive strategy. In other words, our adversary model leverages the ",
                "cosine distance",
                " in an attempt to evade our defense. For the Reddit dataset, the adversary aims to make the model predicting the word ‚Äùdelicious‚Äù after the trigger ‚Äùpasta from astoria tastes‚Äù¬†",
                "(Bagdasaryan et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                ". The CIFAR-10 backdoor shall make all cars in front of a striped background being classified as birds¬†",
                "(Bagdasaryan et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                ". For MNIST and Fashion MNIST, the backdoor forces models to predict the number 0, and t-shirt/top, respectively, when the image trigger is detected. The trigger is simply a white rectangle located at the bottom left corner of each poisoned image."
            ]
        ]
    },
    "S6.T2": {
        "caption": "Table 2. Effectiveness of FLEDGE against multiple poisoning attacks in terms of Backdoor Accuracy % (BA) and Main Task Accuracy % (MA).",
        "table": "<table id=\"S6.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" rowspan=\"2\"><span id=\"S6.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Poisoning Attack</span></th>\n<th id=\"S6.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" rowspan=\"2\"><span id=\"S6.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<td id=\"S6.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"2\"><span id=\"S6.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">No Defense</span></td>\n<td id=\"S6.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"2\"><span id=\"S6.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">FLEDGE</span></td>\n</tr>\n<tr id=\"S6.T2.1.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">BA</td>\n<td id=\"S6.T2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MA</td>\n<td id=\"S6.T2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">BA</td>\n<td id=\"S6.T2.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MA</td>\n</tr>\n<tr id=\"S6.T2.1.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" rowspan=\"4\"><span id=\"S6.T2.1.3.3.1.1\" class=\"ltx_text\">Untargeted <cite class=\"ltx_cite ltx_citemacro_citep\">(Hossain et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">2021</a>)</cite></span></th>\n<th id=\"S6.T2.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Reddit</th>\n<td id=\"S6.T2.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">‚Äì</td>\n<td id=\"S6.T2.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">15.8</td>\n<td id=\"S6.T2.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">‚Äì</td>\n<td id=\"S6.T2.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.7</td>\n</tr>\n<tr id=\"S6.T2.1.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MNIST</th>\n<td id=\"S6.T2.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">‚Äì</td>\n<td id=\"S6.T2.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">91.5</td>\n<td id=\"S6.T2.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">‚Äì</td>\n<td id=\"S6.T2.1.4.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">98.3</td>\n</tr>\n<tr id=\"S6.T2.1.5.5\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Fashion</th>\n<td id=\"S6.T2.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">‚Äì</td>\n<td id=\"S6.T2.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">41.1</td>\n<td id=\"S6.T2.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">‚Äì</td>\n<td id=\"S6.T2.1.5.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">90.0</td>\n</tr>\n<tr id=\"S6.T2.1.6.6\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CIFAR-10</th>\n<td id=\"S6.T2.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">‚Äì</td>\n<td id=\"S6.T2.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">28.9</td>\n<td id=\"S6.T2.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">‚Äì</td>\n<td id=\"S6.T2.1.6.6.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">83.0</td>\n</tr>\n<tr id=\"S6.T2.1.7.7\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" rowspan=\"4\"><span id=\"S6.T2.1.7.7.1.1\" class=\"ltx_text\">Constrain-and-Scale <cite class=\"ltx_cite ltx_citemacro_citep\">(Bagdasaryan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></span></th>\n<th id=\"S6.T2.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Reddit</th>\n<td id=\"S6.T2.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100</td>\n<td id=\"S6.T2.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.6</td>\n<td id=\"S6.T2.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.0</td>\n<td id=\"S6.T2.1.7.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.7</td>\n</tr>\n<tr id=\"S6.T2.1.8.8\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.8.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MNIST</th>\n<td id=\"S6.T2.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">98.0</td>\n<td id=\"S6.T2.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">87.7</td>\n<td id=\"S6.T2.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.4</td>\n<td id=\"S6.T2.1.8.8.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">98.3</td>\n</tr>\n<tr id=\"S6.T2.1.9.9\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.9.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Fashion</th>\n<td id=\"S6.T2.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100.0</td>\n<td id=\"S6.T2.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">69.3</td>\n<td id=\"S6.T2.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">2.4</td>\n<td id=\"S6.T2.1.9.9.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">90.6</td>\n</tr>\n<tr id=\"S6.T2.1.10.10\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.10.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CIFAR-10</th>\n<td id=\"S6.T2.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100.0</td>\n<td id=\"S6.T2.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">66.1</td>\n<td id=\"S6.T2.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.0</td>\n<td id=\"S6.T2.1.10.10.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">83.8</td>\n</tr>\n<tr id=\"S6.T2.1.11.11\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.11.11.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" rowspan=\"5\"><span id=\"S6.T2.1.11.11.1.1\" class=\"ltx_text\">DBA <cite class=\"ltx_cite ltx_citemacro_citep\">(Xie et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib67\" title=\"\" class=\"ltx_ref\">2019</a>)</cite></span></th>\n<th id=\"S6.T2.1.11.11.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Reddit</th>\n<td id=\"S6.T2.1.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100.0</td>\n<td id=\"S6.T2.1.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.6</td>\n<td id=\"S6.T2.1.11.11.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.0</td>\n<td id=\"S6.T2.1.11.11.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.7</td>\n</tr>\n<tr id=\"S6.T2.1.12.12\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.12.12.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MNIST</th>\n<td id=\"S6.T2.1.12.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">82.6</td>\n<td id=\"S6.T2.1.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">77.2</td>\n<td id=\"S6.T2.1.12.12.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.1</td>\n<td id=\"S6.T2.1.12.12.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">98.3</td>\n</tr>\n<tr id=\"S6.T2.1.13.13\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.13.13.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Fashion</th>\n<td id=\"S6.T2.1.13.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">99.7</td>\n<td id=\"S6.T2.1.13.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">36.7</td>\n<td id=\"S6.T2.1.13.13.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1.0</td>\n<td id=\"S6.T2.1.13.13.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">98.3</td>\n</tr>\n<tr id=\"S6.T2.1.14.14\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.14.14.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CIFAR-10</th>\n<td id=\"S6.T2.1.14.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">85.2</td>\n<td id=\"S6.T2.1.14.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">67.4</td>\n<td id=\"S6.T2.1.14.14.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">2.1</td>\n<td id=\"S6.T2.1.14.14.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">83.8</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "The following sections evaluate the privacy of FLEDGE under a naive setup, the security aspect of FLEDGE against poisoning attacks, and the behavior of the reward system in FLEDGE for aggregation services and clients. We also provide a run-time performance analysis of FLEDGE in App.¬†",
                "F",
                ", which is used to illustrate the increased complexity of our learning process."
            ]
        ]
    },
    "S6.T3": {
        "caption": "Table 3. Comparison of FLEDGE and five state-of-art defenses‚Äô efficiency to mitigate backdoor. BA refers to Backdoor Accuracy % and MA refers to Main Task Accuracy %.",
        "table": "<table id=\"S6.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" rowspan=\"2\"><span id=\"S6.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Defenses</span></th>\n<td id=\"S6.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"2\"><span id=\"S6.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Reddit</span></td>\n<td id=\"S6.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"2\"><span id=\"S6.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">MNIST</span></td>\n<td id=\"S6.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"2\"><span id=\"S6.T3.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Fashion</span></td>\n<td id=\"S6.T3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"2\"><span id=\"S6.T3.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">CIFAR-10</span></td>\n</tr>\n<tr id=\"S6.T3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.1.2.2.1\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">BA</td>\n<td id=\"S6.T3.1.2.2.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MA</td>\n<td id=\"S6.T3.1.2.2.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">BA</td>\n<td id=\"S6.T3.1.2.2.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MA</td>\n<td id=\"S6.T3.1.2.2.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">BA</td>\n<td id=\"S6.T3.1.2.2.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MA</td>\n<td id=\"S6.T3.1.2.2.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">BA</td>\n<td id=\"S6.T3.1.2.2.8\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MA</td>\n</tr>\n<tr id=\"S6.T3.1.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Benign Setting</th>\n<td id=\"S6.T3.1.3.3.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.0</td>\n<td id=\"S6.T3.1.3.3.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.7</td>\n<td id=\"S6.T3.1.3.3.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.5</td>\n<td id=\"S6.T3.1.3.3.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">98.3</td>\n<td id=\"S6.T3.1.3.3.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">3.7</td>\n<td id=\"S6.T3.1.3.3.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">90.9</td>\n<td id=\"S6.T3.1.3.3.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0</td>\n<td id=\"S6.T3.1.3.3.9\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">83.9</td>\n</tr>\n<tr id=\"S6.T3.1.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">No Defense</th>\n<td id=\"S6.T3.1.4.4.2\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100.0</td>\n<td id=\"S6.T3.1.4.4.3\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.7</td>\n<td id=\"S6.T3.1.4.4.4\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">98.0</td>\n<td id=\"S6.T3.1.4.4.5\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">87.7</td>\n<td id=\"S6.T3.1.4.4.6\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100.0</td>\n<td id=\"S6.T3.1.4.4.7\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">69.2</td>\n<td id=\"S6.T3.1.4.4.8\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100.0</td>\n<td id=\"S6.T3.1.4.4.9\" class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">66.1</td>\n</tr>\n<tr id=\"S6.T3.1.5.5\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Krum <cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</th>\n<td id=\"S6.T3.1.5.5.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100.0</td>\n<td id=\"S6.T3.1.5.5.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.6</td>\n<td id=\"S6.T3.1.5.5.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.6</td>\n<td id=\"S6.T3.1.5.5.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.5.5.5.1\" class=\"ltx_text ltx_font_bold\">98.3</span></td>\n<td id=\"S6.T3.1.5.5.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">2.8</td>\n<td id=\"S6.T3.1.5.5.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">90.1</td>\n<td id=\"S6.T3.1.5.5.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.5.5.8.1\" class=\"ltx_text ltx_font_bold\">0.0</span></td>\n<td id=\"S6.T3.1.5.5.9\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">83.0</td>\n</tr>\n<tr id=\"S6.T3.1.6.6\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">FoolsGold <cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</th>\n<td id=\"S6.T3.1.6.6.2\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.6.6.2.1\" class=\"ltx_text ltx_font_bold\">0.0</span></td>\n<td id=\"S6.T3.1.6.6.3\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.6.6.3.1\" class=\"ltx_text ltx_font_bold\">22.7</span></td>\n<td id=\"S6.T3.1.6.6.4\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.5</td>\n<td id=\"S6.T3.1.6.6.5\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.6.6.5.1\" class=\"ltx_text ltx_font_bold\">98.3</span></td>\n<td id=\"S6.T3.1.6.6.6\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">3.0</td>\n<td id=\"S6.T3.1.6.6.7\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">90.7</td>\n<td id=\"S6.T3.1.6.6.8\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.6.6.8.1\" class=\"ltx_text ltx_font_bold\">0.0</span></td>\n<td id=\"S6.T3.1.6.6.9\" class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">83.6</td>\n</tr>\n<tr id=\"S6.T3.1.7.7\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Auror <cite class=\"ltx_cite ltx_citemacro_citep\">(Shen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib59\" title=\"\" class=\"ltx_ref\">2016</a>)</cite>\n</th>\n<td id=\"S6.T3.1.7.7.2\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100.0</td>\n<td id=\"S6.T3.1.7.7.3\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.5</td>\n<td id=\"S6.T3.1.7.7.4\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.5</td>\n<td id=\"S6.T3.1.7.7.5\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.7.7.5.1\" class=\"ltx_text ltx_font_bold\">98.3</span></td>\n<td id=\"S6.T3.1.7.7.6\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">2.5</td>\n<td id=\"S6.T3.1.7.7.7\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.7.7.7.1\" class=\"ltx_text ltx_font_bold\">90.9</span></td>\n<td id=\"S6.T3.1.7.7.8\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.7.7.8.1\" class=\"ltx_text ltx_font_bold\">0.0</span></td>\n<td id=\"S6.T3.1.7.7.9\" class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.7.7.9.1\" class=\"ltx_text ltx_font_bold\">83.9</span></td>\n</tr>\n<tr id=\"S6.T3.1.8.8\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">AFA <cite class=\"ltx_cite ltx_citemacro_citep\">(Mu√±oz-Gonz√°lez et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib44\" title=\"\" class=\"ltx_ref\">2019</a>)</cite>\n</th>\n<td id=\"S6.T3.1.8.8.2\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100.0</td>\n<td id=\"S6.T3.1.8.8.3\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.6</td>\n<td id=\"S6.T3.1.8.8.4\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">83.1</td>\n<td id=\"S6.T3.1.8.8.5\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">94.2</td>\n<td id=\"S6.T3.1.8.8.6\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">97.9</td>\n<td id=\"S6.T3.1.8.8.7\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">87.3</td>\n<td id=\"S6.T3.1.8.8.8\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">100.0</td>\n<td id=\"S6.T3.1.8.8.9\" class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">66.5</td>\n</tr>\n<tr id=\"S6.T3.1.9.9\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">DP <cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib39\" title=\"\" class=\"ltx_ref\">2017b</a>)</cite>\n</th>\n<td id=\"S6.T3.1.9.9.2\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">77.0</td>\n<td id=\"S6.T3.1.9.9.3\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">22.0</td>\n<td id=\"S6.T3.1.9.9.4\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">26.5</td>\n<td id=\"S6.T3.1.9.9.5\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">97.3</td>\n<td id=\"S6.T3.1.9.9.6\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">52.2</td>\n<td id=\"S6.T3.1.9.9.7\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">88.6</td>\n<td id=\"S6.T3.1.9.9.8\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">60.0</td>\n<td id=\"S6.T3.1.9.9.9\" class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">76.6</td>\n</tr>\n<tr id=\"S6.T3.1.10.10\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">FLEDGE</th>\n<td id=\"S6.T3.1.10.10.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.10.10.2.1\" class=\"ltx_text ltx_font_bold\">0.0</span></td>\n<td id=\"S6.T3.1.10.10.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.10.10.3.1\" class=\"ltx_text ltx_font_bold\">22.7</span></td>\n<td id=\"S6.T3.1.10.10.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.10.10.4.1\" class=\"ltx_text ltx_font_bold\">0.4</span></td>\n<td id=\"S6.T3.1.10.10.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.10.10.5.1\" class=\"ltx_text ltx_font_bold\">98.3</span></td>\n<td id=\"S6.T3.1.10.10.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.10.10.6.1\" class=\"ltx_text ltx_font_bold\">2.4</span></td>\n<td id=\"S6.T3.1.10.10.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">90.6</td>\n<td id=\"S6.T3.1.10.10.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S6.T3.1.10.10.8.1\" class=\"ltx_text ltx_font_bold\">0.0</span></td>\n<td id=\"S6.T3.1.10.10.9\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">83.8</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Evaluation Baseline.",
                " We set PMR=0.5, non-IID=0.7, PDR=0.5 and ",
                "Œ±",
                "ùõº",
                "\\alpha",
                "=0.7 as baseline parameters for untargeted and targeted attacks (unless otherwise indicated). PMR (or Poisoned Model Rate) indicates the influence level of an attacker to the system, i.e., PMR of 0.5 denotes an attacker maliciously controls 50% of training clients. Non-IID data (or non-Independent and Identically Distributed) represents the number of training samples dispersed to a client that belongs to a specific class within a pre-defined group, i.e., non-IID of 0.7 means that clients should use 70% of training data from their given class while the rest 30% is from the remaining classes. We follow the approach in ",
                "(Fang et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " to prepare each dataset according to the number of output classes. PDR (or Poisoned Data Rate) determines the fraction of poisoned samples with respect to benign samples during training, i.e., PDR of 0.5 defines 50% of training data from a target class are poisoned samples. A higher PDR increases the success rate of the attacks. Similarly, the regularization term ",
                "Œ±",
                "ùõº",
                "\\alpha",
                ", as defined by Bagdasaryan ",
                "et¬†al.",
                " ",
                "(Bagdasaryan et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                ", balances the loss function of client models aiming at limiting the distance between local and global models. A high value of ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " allows the attacker to increase its success rate at the cost of visibility. \n",
                "Effectiveness of FLEDGE.",
                " We evaluate the resiliency of FLEDGE against different poisoning attacks such as untargeted poisoning¬†",
                "(Hossain et¬†al",
                ".",
                ", ",
                "2021",
                ")",
                ", constrain-and-scale¬†",
                "(Bagdasaryan et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and DBA¬†",
                "(Xie et¬†al",
                ".",
                ", ",
                "2019",
                ")",
                ". The experimental results illustrated in Tab.¬†",
                "2",
                " show that FLEDGE successfully mitigates these attacks without sacrificing benign performance (MA). For untargeted poisoning, the adversary successfully degrades model performance when no defenses are in place, reaching as low as 15.8% (22.7% original) for Reddit, and 28.9% (83.9% original) for CIFAR-10. During constrain-and-scale attacks, the adversary is able to inject a backdoor into the model with almost 100% accuracy. Similarly, for DBA, the backdoor is injected into the global model with 80+%. These attacks, however, are not effective against FLEDGE as BA",
                "‚âà",
                "\\approx",
                "0 for every evaluated dataset.",
                "10",
                "10",
                "10",
                "In some applications, misclassifications are counted in favor of the BA if MA",
                "<",
                "100",
                "%",
                "absent",
                "percent",
                "100",
                "<100\\%",
                ". For this reason, the BA is greater than 0%, e.g., 2.4% for Fashion, although the aggregated model does not contain the backdoor.",
                " Moreover, FLEDGE maintains or even increases MA. Note that for the rest of the evaluation, we focus on targeted (or backdoor) attacks since they are the most sophisticated type of poisoning attacks. \n",
                "Comparison to Existing Work.",
                " Tab.¬†",
                "3",
                " compares the effectiveness of FLEDGE with five state-of-the-art defense approaches¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                "; Fung et¬†al",
                ".",
                ", ",
                "2020",
                "; Shen et¬†al",
                ".",
                ", ",
                "2016",
                "; Mu√±oz-Gonz√°lez et¬†al",
                ".",
                ", ",
                "2019",
                "; McMahan et¬†al",
                ".",
                ", ",
                "2017a",
                ")",
                ". Notably, several defenses such as Krum¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " cannot handle non-IID scenarios. FoolsGold is the most resilient defense that mitigates backdoors for all four datasets as its BAs are very closed to 0, but still a little higher than FLEDGE‚Äôs BA rates.\nSimilar to FoolsGold, the other four defenses‚Äô BA rates are much higher than or equal to FLEDGE‚Äôs while MA rates are much lower than or equal to ours. Auror¬†",
                "(Shen et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " works well for the image datasets, where the clients‚Äô local datasets overlap and show similar distributions but fails for the intrinsic non-IID Reddit dataset. Therefore, FLEDGE is shown to provide the most resilient defense to mitigate state-of-the-art backdoors.\nAppendix ",
                "H",
                " and ",
                "I",
                " provide further experiment results for WP and IC tasks respectively, showing FLEDGE‚Äôs performance for different PDRs, PMRs, further attack strategies, and IID rates."
            ]
        ]
    },
    "A6.T4": {
        "caption": "Table 4. Training round efficiency of FLEDGE for the following processing tasks in seconds: Model Encryption, Model Upload, Model Filtering, and Model Aggregation.",
        "table": "<table id=\"A6.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A6.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"A6.T4.1.1.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"A6.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"A6.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"A6.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">MNIST</span></th>\n<th id=\"A6.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"A6.T4.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Fashion</span></th>\n<th id=\"A6.T4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"A6.T4.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">CIFAR-10</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A6.T4.1.2.1\" class=\"ltx_tr\">\n<th id=\"A6.T4.1.2.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"A6.T4.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Model Encryption</span></th>\n<td id=\"A6.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.12</td>\n<td id=\"A6.T4.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.14</td>\n<td id=\"A6.T4.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1.03</td>\n</tr>\n<tr id=\"A6.T4.1.3.2\" class=\"ltx_tr\">\n<th id=\"A6.T4.1.3.2.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"A6.T4.1.3.2.1.1\" class=\"ltx_text ltx_font_bold\">Model Upload</span></th>\n<td id=\"A6.T4.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">5.23</td>\n<td id=\"A6.T4.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">5.85</td>\n<td id=\"A6.T4.1.3.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">17.57</td>\n</tr>\n<tr id=\"A6.T4.1.4.3\" class=\"ltx_tr\">\n<th id=\"A6.T4.1.4.3.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"A6.T4.1.4.3.1.1\" class=\"ltx_text ltx_font_bold\">Model Filtering</span></th>\n<td id=\"A6.T4.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">2.07</td>\n<td id=\"A6.T4.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1.98</td>\n<td id=\"A6.T4.1.4.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1.91</td>\n</tr>\n<tr id=\"A6.T4.1.5.4\" class=\"ltx_tr\">\n<th id=\"A6.T4.1.5.4.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"A6.T4.1.5.4.1.1\" class=\"ltx_text ltx_font_bold\">Model Aggregation</span></th>\n<td id=\"A6.T4.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">8.44</td>\n<td id=\"A6.T4.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">9.73</td>\n<td id=\"A6.T4.1.5.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">56.09</td>\n</tr>\n<tr id=\"A6.T4.1.6.5\" class=\"ltx_tr\">\n<th id=\"A6.T4.1.6.5.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"A6.T4.1.6.5.1.1\" class=\"ltx_text ltx_font_bold\">Total</span></th>\n<td id=\"A6.T4.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">15.86</td>\n<td id=\"A6.T4.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">17.7</td>\n<td id=\"A6.T4.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">76.6</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "To assess the latency aspects of FLEDGE during any given round, we evaluate the following processes in terms of latency: model encryption, model upload, model filtering and model aggregation. Model encryption determines the time required to fully produce an encrypted model. Model upload defines the average time an encrypted model is committed and analyzed by FLEDGE such that it produces the distance score that corresponds to the uploaded encrypted model. Model filtering evaluates how long the poison defense takes to analyze anomaly scores to remove models from aggregation. Model aggregation determines the time it takes to produce a new global model. We perform experiments using MNIST, Fashion, and CIFAR-10 datasets. \nEffect of Model Complexity. For the following experiment we set the number of clients to be 50 to assess the impact of model complexity on system latency. Table¬†4 compiles the preliminary evaluation of FLEDGE.\nFor model encryption, we found there is negligible impact on latency with values of 0.12, 0.14, 0.56 and 1.03 seconds for each of the models evaluated. Note that model encryption behaves as O‚Äã(n2)ùëÇsuperscriptùëõ2O(n^{2}) as the number of trainable parameters increases, i.e., ‚àºsimilar-to\\sim 20.4M params are encrypted (10K ciphers) in ‚àºsimilar-to\\sim110s. Moreover, model upload shows an average latency of 5.23, 5.85, and 17.57 seconds for MNIST, Fashion, and CIFAR-10 tasks. The increased latency is mainly attributed to the distance score computation, where we use three BT2C rounds to compute the cosine distance. The values displayed for model filtering are close to 2s in each evaluated task. The reason is because this is the only process where HE is not used, as the Defender contract only analyzes the anomaly scores previously computed during model upload. In contrast, model aggregation is determined to be the most computationally expensive process in FLEDGE, showing values of 8.44, 9.73, and 56.09 seconds, respectively. As a consequence, FLEDGE successfully completes a single training round in 15.86s (MNIST), 17.7s (Fashion), and 76.6s (CIFAR-10). Therefore, the use of FLEDGE is best suited to protect the privacy of constrained environments, where local clients do not have the computational resources (e.g., GPU) to train a robust model with millions of parameters such as ResNet (He et¬†al., 2016) and VGG (Simonyan and Zisserman, 2014). However, they can operate lite models, i.e., lite-CNN and/or ConvMixer, to achieve good model performance while delegating every intensive computational task to blockchain via smart contracts. \nEffect of Number of Clients. In this experiment, we narrow our focus to the model aggregation process since it was determined to be the most computationally expensive process in FLEDGE. To further inspect this process, we vary the number of clients to {10,30,50}103050\\{10,30,50\\}. Fig.¬†5 shows the impact of model aggregation for the distinct learning tasks using a different number of clients. Here, we can visualize that not only does model aggregation scales according to model complexity, but it also shows a linear dependency w.r.t. the number of clients. Put differently, model aggregation is the major contributor of latency in FLEDGE as other components (i.e., model encryption, model upload) are only defined by the computational requirements of HE."
        ]
    }
}