{
    "id_table_1": {
        "caption": "TABLE I:  Performance Metrics for Condition Identification: Accuracy (Acc), Sensitivity (Sen), Specificity (Spec), and F1-score (F1)",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": []
    },
    "id_table_2": {
        "caption": "TABLE II:  Performance Metrics for Report Generation: Completeness (Comp), Coherence (Cohe), and Overall Quality Score (OQS)",
        "table": "S4.T2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_3": {
        "caption": "TABLE III:  Condition Identification Performance: Acc = Accuracy, Sen = Sensitivity, Spe = Specificity, F1 = F1-Score",
        "table": "S4.T3.1",
        "footnotes": [],
        "references": []
    },
    "id_table_4": {
        "caption": "TABLE IV:  Report Generation Performance: C = Content Relevance, F = Factual Correctness, R = Completeness, U = User Satisfaction",
        "table": "S4.T4.1",
        "footnotes": [],
        "references": []
    },
    "id_table_5": {
        "caption": "TABLE V:  Performance Metrics for Report Generation with CoT Module.    CR: Content Relevance, FC: Factual Correctness, C: Completeness, US: User Satisfaction",
        "table": "S4.T5.1",
        "footnotes": [],
        "references": []
    },
    "global_footnotes": []
}