{
    "PAPER'S NUMBER OF TABLES": 6,
    "S5.T1": {
        "caption": "Table 1: Tetouan dataset features used for load forecasting",
        "table": "<table id=\"S5.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S5.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Context</span></th>\n<th id=\"S5.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Features</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\">Calendar</th>\n<td id=\"S5.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"S5.T1.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:120%;\">\\small1‚Éù <span id=\"S5.T1.1.2.1.2.1.1\" class=\"ltx_text\" style=\"font-size:75%;\">Month </span>\\small2‚Éù <span id=\"S5.T1.1.2.1.2.1.2\" class=\"ltx_text\" style=\"font-size:75%;\">Day </span>\\small3‚Éù <span id=\"S5.T1.1.2.1.2.1.3\" class=\"ltx_text\" style=\"font-size:75%;\">Hour</span></span></td>\n</tr>\n<tr id=\"S5.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Weather</th>\n<td id=\"S5.T1.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">\n<table id=\"S5.T1.1.3.2.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.1.3.2.2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.3.2.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S5.T1.1.3.2.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:120%;\">\\small4‚Éù <span id=\"S5.T1.1.3.2.2.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:75%;\">Temperature </span>\\small5‚Éù <span id=\"S5.T1.1.3.2.2.1.1.1.1.2\" class=\"ltx_text\" style=\"font-size:75%;\">Humidity </span>\\small6‚Éù <span id=\"S5.T1.1.3.2.2.1.1.1.1.3\" class=\"ltx_text\" style=\"font-size:75%;\">Wind speed</span></span></td>\n</tr>\n<tr id=\"S5.T1.1.3.2.2.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.3.2.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S5.T1.1.3.2.2.1.2.1.1\" class=\"ltx_text\" style=\"font-size:120%;\">\\small7‚Éù <span id=\"S5.T1.1.3.2.2.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:75%;\">Diffuse flow </span>\\small8‚Éù <span id=\"S5.T1.1.3.2.2.1.2.1.1.2\" class=\"ltx_text\" style=\"font-size:75%;\">General diffuse flow</span></span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"S5.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_l ltx_border_r ltx_border_t\">Power</th>\n<td id=\"S5.T1.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:120%;\">\\small9‚Éù <span id=\"S5.T1.1.4.3.2.1.1\" class=\"ltx_text\" style=\"font-size:75%;\">PrevHourAgg</span></span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Since this study is intended to provide a practical framework capable of forecasting electricity load patterns in smart cities, it is essential to find an excellent dataset to evaluate the performance of FedTrees versus FedAvg. In this regard, the Tetouan power consumption dataset is selected for this purpose ",
                "[",
                "36",
                "]",
                ". This dataset was collected in 2017 at three different distribution substations from the zones: Quads, Boussafou, and Smir in Tetouan, a city located in north Morocco. In addition to providing power consumption information for every 10 minutes, the Tetouan dataset offers complementary data about the calendar and weather conditions. To prepare this dataset for our study, we initially converted the time scale from 10 minutes to 60 minutes because we are interested in predicting short-term loads for the next hour. Furthermore, we created two new dataset features; the aggregation feature that aggregates the power consumption of the three zones for use while performing centralised and distributed learning, and the previous hour aggregation (PrevHourAgg) feature that gives the aggregated feature reading of the previous hour. Fig. ",
                "5",
                " demonstrates the hourly aggregated load as well as zones‚Äô load information. Moreover, Table. ",
                "1",
                " shows the features that are considered to perform load forecasting.",
                "Before commencing the training process, the default scale of the features is normalised using MinMax scaler into the range [0,1]. Accordingly, all features have the chance of contributing equally to model fitting and avoiding biasing. For evaluation purposes, we use the most popular metrics of mean absolute error (MAE) and mean absolute percentage error (MAPE), which are defined as ",
                "[",
                "37",
                "]",
                ":",
                "Where ",
                "y",
                "i",
                "subscript",
                "ùë¶",
                "ùëñ",
                "y_{i}",
                " is the actual value, ",
                "y",
                "^",
                "i",
                "subscript",
                "^",
                "ùë¶",
                "ùëñ",
                "\\hat{y}_{i}",
                " is the predicted value, and ",
                "n",
                "ùëõ",
                "n",
                " represents the number of data samples."
            ]
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Performance comparison between LSTM and LGBM models when performing centralised model training.",
        "table": "<table id=\"S5.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">ML model</span></th>\n<th id=\"S5.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">MAE</span></th>\n<th id=\"S5.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">MAPE</span></th>\n<th id=\"S5.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Computation time</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt\">LSTM</td>\n<td id=\"S5.T2.1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">0.019</td>\n<td id=\"S5.T2.1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">3.04%</td>\n<td id=\"S5.T2.1.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">77 seconds</td>\n</tr>\n<tr id=\"S5.T2.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">LGBM</td>\n<td id=\"S5.T2.1.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0.017</td>\n<td id=\"S5.T2.1.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">2.69%</td>\n<td id=\"S5.T2.1.1.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">2 seconds</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We first investigate the performance of the selected models when performing the conventional approach of centralised training. Table 2 demonstrates the results of the evaluation metrics as well as the required computation time for each model. The MAE and MAPE for the LSTM model are 0.02 and 3.04%, respectively, while they are improved when using the LGBM model and reached 0.017 and 2.69%, respectively. The fast-computing merit of the LGBM model is confirmed in this table which shows that it needs only two seconds to converge, while the LSTM model requires more than 97% of computations compared to the LGBM model."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: A study to determine the best values of delta and window size for LSTM-based FedAvg.",
        "table": "<img src=\"/html/2210.00060/assets/x8.png\" id=\"S5.T3.g1\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" width=\"245\" height=\"102\" alt=\"[Uncaptioned image]\">\n\n",
        "footnotes": "",
        "references": [
            "Moving on to the FL setup, it is worth recalling that FedTrees is designed to accommodate cross-device and cross-silo settings. To the best of the authors‚Äô knowledge, FL has not been previously applied at the substation level in energy/power forecasting studies. Therefore, in this study, we focus on applying FedTrees and the FedAvg at the substation level. The FL setup for both algorithms comprises a central orchestrating server and three clients representing the three zones of the Tetouan dataset. The number of communication rounds is not fixed since we use the developed delta-based early stopping technique, discussed in Section 4.2, to find the best round that yields the optimal trained model while alleviating the computation and communication costs. An extensive study is carried out to determine the best delta and window size values for the stopping algorithm, the findings of this study are given in Tables 3 and 4. From Table 3, the most computationally efficient and the best MAE/MAPE for the LSTM model are obtained when the delta and window size values are 0.00001 and 55, respectively. Regarding LGBM, Table 4 demonstrates that best values for the delta and window size are 0.00001 and 10, respectively. Table 5 summarises the best results obtained for each of the Persistence, FedAvg, and FedTrees algorithms. The performance of the Persistence model is poor compared to other algorithms, and the FedAvg has the best performance, which is slightly better than that of FedTrees; however, FedTrees outperforms the FedAvg algorithm in terms of the communication rounds and the required computations. FedTrees only requires 65 rounds of communications that result in approximately 26 seconds of computations, while FedAvg requires a much higher number of communication rounds and computation time by a factor of 7.6 and 52.2, respectively, to achieve the same level of performance."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: A study to determine the best values of delta and window size for LGBM-based FedTrees.",
        "table": "<img src=\"/html/2210.00060/assets/x9.png\" id=\"S5.T4.g1\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" width=\"245\" height=\"102\" alt=\"[Uncaptioned image]\">\n\n",
        "footnotes": "",
        "references": [
            "Moving on to the FL setup, it is worth recalling that FedTrees is designed to accommodate cross-device and cross-silo settings. To the best of the authors‚Äô knowledge, FL has not been previously applied at the substation level in energy/power forecasting studies. Therefore, in this study, we focus on applying FedTrees and the FedAvg at the substation level. The FL setup for both algorithms comprises a central orchestrating server and three clients representing the three zones of the Tetouan dataset. The number of communication rounds is not fixed since we use the developed delta-based early stopping technique, discussed in Section 4.2, to find the best round that yields the optimal trained model while alleviating the computation and communication costs. An extensive study is carried out to determine the best delta and window size values for the stopping algorithm, the findings of this study are given in Tables 3 and 4. From Table 3, the most computationally efficient and the best MAE/MAPE for the LSTM model are obtained when the delta and window size values are 0.00001 and 55, respectively. Regarding LGBM, Table 4 demonstrates that best values for the delta and window size are 0.00001 and 10, respectively. Table 5 summarises the best results obtained for each of the Persistence, FedAvg, and FedTrees algorithms. The performance of the Persistence model is poor compared to other algorithms, and the FedAvg has the best performance, which is slightly better than that of FedTrees; however, FedTrees outperforms the FedAvg algorithm in terms of the communication rounds and the required computations. FedTrees only requires 65 rounds of communications that result in approximately 26 seconds of computations, while FedAvg requires a much higher number of communication rounds and computation time by a factor of 7.6 and 52.2, respectively, to achieve the same level of performance."
        ]
    },
    "S5.T5": {
        "caption": "Table 5: Performance results of the FedTrees compared to the FedAvg and the Persistence model. ",
        "table": "<table id=\"S5.T5.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T5.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Algorithm</span></th>\n<th id=\"S5.T5.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">MAE</span></th>\n<th id=\"S5.T5.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">MAPE%</span></th>\n<th id=\"S5.T5.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">No. of rounds</span></th>\n<th id=\"S5.T5.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Computation time</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt\">Persistence</td>\n<td id=\"S5.T5.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">0.08</td>\n<td id=\"S5.T5.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">6.64</td>\n<td id=\"S5.T5.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">N/A</td>\n<td id=\"S5.T5.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">N/A</td>\n</tr>\n<tr id=\"S5.T5.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedAvg</td>\n<td id=\"S5.T5.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0157</td>\n<td id=\"S5.T5.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.43</td>\n<td id=\"S5.T5.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">491</td>\n<td id=\"S5.T5.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1356 seconds</td>\n</tr>\n<tr id=\"S5.T5.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">FedTrees</td>\n<td id=\"S5.T5.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.0173</td>\n<td id=\"S5.T5.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">3.69</td>\n<td id=\"S5.T5.1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">65</td>\n<td id=\"S5.T5.1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">26.2 seconds</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Moving on to the FL setup, it is worth recalling that FedTrees is designed to accommodate cross-device and cross-silo settings. To the best of the authors‚Äô knowledge, FL has not been previously applied at the substation level in energy/power forecasting studies. Therefore, in this study, we focus on applying FedTrees and the FedAvg at the substation level. The FL setup for both algorithms comprises a central orchestrating server and three clients representing the three zones of the Tetouan dataset. The number of communication rounds is not fixed since we use the developed delta-based early stopping technique, discussed in Section 4.2, to find the best round that yields the optimal trained model while alleviating the computation and communication costs. An extensive study is carried out to determine the best delta and window size values for the stopping algorithm, the findings of this study are given in Tables 3 and 4. From Table 3, the most computationally efficient and the best MAE/MAPE for the LSTM model are obtained when the delta and window size values are 0.00001 and 55, respectively. Regarding LGBM, Table 4 demonstrates that best values for the delta and window size are 0.00001 and 10, respectively. Table 5 summarises the best results obtained for each of the Persistence, FedAvg, and FedTrees algorithms. The performance of the Persistence model is poor compared to other algorithms, and the FedAvg has the best performance, which is slightly better than that of FedTrees; however, FedTrees outperforms the FedAvg algorithm in terms of the communication rounds and the required computations. FedTrees only requires 65 rounds of communications that result in approximately 26 seconds of computations, while FedAvg requires a much higher number of communication rounds and computation time by a factor of 7.6 and 52.2, respectively, to achieve the same level of performance."
        ]
    },
    "S5.T6": {
        "caption": "Table 6: Performance results of the FedTrees compared to the FedAvg and Persistence model when considering only the top four features. ",
        "table": "<table id=\"S5.T6.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T6.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T6.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Algorithm</span></th>\n<th id=\"S5.T6.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">MAE</span></th>\n<th id=\"S5.T6.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">MAPE%</span></th>\n<th id=\"S5.T6.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">No. of rounds</span></th>\n<th id=\"S5.T6.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Computation time</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T6.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt\">Persistence</td>\n<td id=\"S5.T6.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">0.08</td>\n<td id=\"S5.T6.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">6.64</td>\n<td id=\"S5.T6.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">N/A</td>\n<td id=\"S5.T6.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">N/A</td>\n</tr>\n<tr id=\"S5.T6.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedAvg</td>\n<td id=\"S5.T6.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0177</td>\n<td id=\"S5.T6.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.93</td>\n<td id=\"S5.T6.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">465</td>\n<td id=\"S5.T6.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1293 seconds</td>\n</tr>\n<tr id=\"S5.T6.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T6.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">FedTrees</td>\n<td id=\"S5.T6.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.0168</td>\n<td id=\"S5.T6.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">3.54</td>\n<td id=\"S5.T6.1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">50</td>\n<td id=\"S5.T6.1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">8.8 seconds</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Another study was conducted by looking only at the four most important features to see the impact of using fewer features on the required number of communication rounds, computation time, and model performance. Table 6 gives the outcomes of this study and indicates that the performance of FedTrees is improved when removing the less important features. However, this is not the case with FedAvg, as this table shows that its performance is slightly degraded compared to using all the features. The number of communication rounds is slightly less than that in the full feature study for both algorithms; however, this study also shows the outstanding performance of FedTrees as it requires far fewer rounds of communications and computation costs. Similarly, Fig. 10 and 11 give the MAE convergence curve and the actual and forecasted power consumption for both algorithms, respectively. Also, these figures ensure the superb overall performance of FedTrees."
        ]
    }
}