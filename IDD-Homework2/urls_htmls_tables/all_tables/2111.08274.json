{
    "PAPER'S NUMBER OF TABLES": 1,
    "S3.T1": {
        "caption": "TABLE I: Time required to reach the maximum test accuracy",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"></th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\">ResNet-18 [3,3,1,1]</th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\">ResNet-18 [4,2,2,1]</th>\n<th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\">vgg-16 [3,3,1,1]</th>\n<th id=\"S3.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\">vgg-16 [4,2,2,1]</th>\n</tr>\n<tr id=\"S3.T1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.2.2.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r\"></th>\n<th id=\"S3.T1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">accuracy</th>\n<th id=\"S3.T1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">time</th>\n<th id=\"S3.T1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">accuracy</th>\n<th id=\"S3.T1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">time</th>\n<th id=\"S3.T1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">accuracy</th>\n<th id=\"S3.T1.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">time</th>\n<th id=\"S3.T1.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">accuracy</th>\n<th id=\"S3.T1.1.2.2.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">time</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.3.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Distributed training</td>\n<td id=\"S3.T1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">91%</td>\n<td id=\"S3.T1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2431.38 s</td>\n<td id=\"S3.T1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">91%</td>\n<td id=\"S3.T1.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4076.28 s</td>\n<td id=\"S3.T1.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">87%</td>\n<td id=\"S3.T1.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1349.73 s</td>\n<td id=\"S3.T1.1.3.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">87%</td>\n<td id=\"S3.T1.1.3.1.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1791.36 s</td>\n</tr>\n<tr id=\"S3.T1.1.4.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">Decentralized-FedAvg</td>\n<td id=\"S3.T1.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">91%</td>\n<td id=\"S3.T1.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">1699.05 s</td>\n<td id=\"S3.T1.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">91%</td>\n<td id=\"S3.T1.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">2747.12 s</td>\n<td id=\"S3.T1.1.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\">86%</td>\n<td id=\"S3.T1.1.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_r\">1952.01 s</td>\n<td id=\"S3.T1.1.4.2.8\" class=\"ltx_td ltx_align_center ltx_border_r\">86%</td>\n<td id=\"S3.T1.1.4.2.9\" class=\"ltx_td ltx_align_center ltx_border_r\">2424.12 s</td>\n</tr>\n<tr id=\"S3.T1.1.5.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r\">HADFL</td>\n<td id=\"S3.T1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">90%</td>\n<td id=\"S3.T1.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">805.00 s</td>\n<td id=\"S3.T1.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">91%</td>\n<td id=\"S3.T1.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">871.50 s</td>\n<td id=\"S3.T1.1.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">86%</td>\n<td id=\"S3.T1.1.5.3.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">794.02 s</td>\n<td id=\"S3.T1.1.5.3.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">86%</td>\n<td id=\"S3.T1.1.5.3.9\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">1324.04 s</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We run comparative experiments on system with two kind of heterogeneity distribution, [3,3,1,1]3311[3,3,1,1] and [4,2,2,1]4221[4,2,2,1]. The training data is spilt on four GPUs. We choose two GPUs to perform partial synchronization each time. The experiments are repeated three times. The experimental results are shown in Fig. 3. In addition, we record the average time required to reach the maximum test accuracy, as shown in Table I.",
            "The convergence speed: As shown in Fig. 3 (c), (f) and Table I, thanks to the heterogeneity-aware asynchronous strategy, HADFL converges faster than the other two schemes. When training ResNet-18, it achieves 3.02x speedup over distributed training and 2.11x speedup over decentralized-FedAvg in heterogeneous distribution of [3,3,1,1]3311[3,3,1,1], as well as 4.68x speedup over distributed training and 3.15x speedup over decentralized-FedAvg in heterogeneous distribution of [4,2,2,1]4221[4,2,2,1], respectively. When training vgg-16, it achieves 1.70x speedup over distributed training and 2.46x speedup over decentralized-FedAvg in heterogeneous distribution of [3,3,1,1]3311[3,3,1,1], as well as 1.35x speedup over distributed training and 1.83x speedup over decentralized-FedAvg in heterogeneous distribution of [4,2,2,1]4221[4,2,2,1], respectively. Itâ€™s worth noting that when training vgg-16 on decentralized-FedAvg, it needs more time to converge than distributed training. This is because the local update is conducted on the local model, which is slightly outdated and can bring loss of accuracy. As a result, it requires more epochs to converge. HADFL also suffers this accuracy loss."
        ]
    }
}