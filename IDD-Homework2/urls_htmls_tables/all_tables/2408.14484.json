{
    "id_table_1": {
        "caption": "Table 1.  Summary of the spatio-temporal datasets.",
        "table": "S4.T1.1.1",
        "footnotes": [],
        "references": [
            "Time series modeling underpins a vast spectrum of real-world applications, including demand planning  (Leonard,  2001 ) , anomaly detection  (Zhou et al . ,  2024a ) , inventory management  (Zhou et al . ,  2023a ) , energy load forecasting  (Liu et al . ,  2023 ) , weather modeling  (Pathak et al . ,  2022 ) , and many others. However, it is not without its challenges. High dimensionality, non-linearity, sparsity, and distribution shifts all pose significant hurdles. Successfully navigating these challenges in time series analysis applications necessitates both considerable domain knowledge and the design of neural network architectures tailored to address task-specific goals, leading to better performance. In contrast to task-specific approaches, which employ different architecture designs for time series analysis, foundational pretrained large language models (LLMs), such as OpenAIs GPT-4  (OpenAI,  2023 )  and Googles Gemini  (Reid et al . ,  2024 ; Team et al . ,  2023 ) , with their strong generalization and logical reasoning capabilities, have shown remarkable versatility across a broad spectrum of natural language processing (NLP) tasks, requiring minimal fine-tuning (Hu et al . ,  2021 )  or only a few demonstrations (Brown et al . ,  2020 )  for adaptation to niche tasks. Open-source, small-scale pretrained language models (SLMs), such as Google Gemma ( (Team et al . ,  2024 ) ) and Meta LLaMA ( (Touvron et al . ,  2023 ; AI@Meta,  2024 ) ), offer cost-effective domain customization through Parameter Efficient Fine-Tuning (PEFT) ( (Guo et al . ,  2023 ; Han et al . ,  2024 ) ) techniques using task-specific labeled datasets. Additionally, these smaller models can be further aligned with human preferences using Direct Preference Optimization (DPO)  (Christiano et al . ,  2017 ) , a fine-tuning technique that utilizes paired preference data, such as datasets of preferred and dispreferred responses. However, SLMs may lack the reasoning and generalization capabilities of large-scale proprietary language models. The potential of foundational SLMs designed for universal time series applications (a single-model-fits-all approach), such as diverse time series tasks like classification, anomaly detection, forecasting, imputation, and others, remains largely unexplored but holds great promise. This approach contrasts sharply with the traditional approach of using customized, task-specific methods ( (Zhang and Yan,  2022 ; Zhang et al . ,  2022a ; Xu et al . ,  2021 ) ) for time series modeling for various applications. Adapting SLMs designed for NLP tasks for time series modeling to capture trends and patterns within the complex data, though unconventional, offers a clear possibility for providing unique insights. However, this is a challenging task as SLMs are trained primarily on text corpora, which operates on discrete tokens, while time series data is inherently continuous. Furthermore, SLMs may lack the inherent ability to detect and interpret time series patterns and trends like seasonality, cyclicity, or outliers, due to the absence of related pretraining knowledge. Moreover, current LMs designed for time series analysis ( (Jin et al . ,  2023 ; Gruver et al . ,  2024 ; Zhou et al . ,  2024b ) ) rely on a fixed-length window of past observations to generate predictions, which may be inadequate for capturing complex patterns and trends present in time series data, thus hindering accurate modeling. Smaller window sizes may capture local patterns but miss broader trends, while larger window sizes can capture more context but may overlook finer details. In recent times, Retrieval-Augmented Generation (RAG) or Retrieval-Augmented Language Modeling (RALM) (Shi et al . ,  2023 ; Ram et al . ,  2023 ; Lin et al . ,  2023 )  combines pre-trained language models with information retrieval from external knowledge bases to augment text generation capabilities for open-ended question-answering(ODQA) (Siriwardhana et al . ,  2023 )  tasks or for improved language modeling for text summarization, completion with improved accuracy. While regular RAG methods augment generation with retrieved knowledge for ODQA tasks, Agentic RAGs take this further by being instruction-following agents that can tackle complex goals through multi-step reasoning and iterative refinement cycles using repeated retrievals over a knowledge base to ensure the final response aligns with the end user request. In this work, we propose an Agentic RAG framework for time series analysis to improve task-specific outcomes by addressing challenges like distributional shifts, fixed window limitations in time series data. Figure   1  illustrates the framework. Our Agentic RAG framework presents a hierarchical, multi-agent architecture composed of a master (top-level) agent and specialized sub-agents customized for specific time series tasks. The top-level agent acting as the orchestrator analyzes the incoming user request, determines its nature and complexity, and then routes (or delegates) it to the corresponding task-specific sub-agent to produce the desired output. Similarly to how regular RAG frameworks retrieve relevant information from external knowledge bases like documents, databases, or access the real world through APIs, this Agentic RAG framework leverages distinct prompt pools as internal knowledge bases for each sub-agent focused on specific time series tasks. As specialized knowledge repositories tailored to each sub-agents time series task, the prompt pools store both domain and task-specific knowledge as key-value pairs. This facilitates easy reuse and sharing within and across datasets, promoting knowledge sharing and transfer, reducing the need to relearn or rediscover patterns from scratch. Each key represents a specific pattern (seasonality, cyclicality, etc.), and the value contains details about that pattern. When processing new input data, the sub-agent retrieves the most relevant prompts from the pool based on similarity. These prompts provide contextual knowledge about related historical patterns and trends, improving generalization to new scenarios. This knowledge-augmentation approach, by conditioning on past patterns, allows the sub-agent access to a broad spectrum of task-specific knowledge regardless of historical occurrence, enabling it to learn and adapt to diverse trends within complex data for improved predictions. Each sub-agent utilizes pre-trained, SLMs like Gemma (Team et al . ,  2024 )  and Llama 3 (AI@Meta,  2024 ) . We fine-tune each SLM using instruction-tuning on task-specific datasets and optimize them for time series tasks such as forecasting, imputation, or other related tasks. Additionally, we fine-tune using DPO (Christiano et al . ,  2017 )  through a dynamic masking technique to align the SLMs task-specific outputs to preferred and non-preferred outcomes, providing adversarial feedback (Yoon et al . ,  2019 )  through a binary classification task. The master agent for sub-agent orchestration utilizes the ReAct prompting technique (Yao et al . ,  2022 ) , encouraging the general-purpose SLM to think step-by-step and use external tools (sub-agents, each utilizing a fine-tuned SLM for specific time series tasks) to generate responses. The master agent can even chain sub-agents together to handle complex, multi-step time series analysis tasks, addressing more intricate challenges. However, in this work, the sub-agents operate in isolation, each handling only a single, specific task.",
            "We evaluate the proposed Agentic-RAG framework on four tasks: forecasting, classification, anomaly detection, and imputation. To comprehensively evaluate the framework performance against several baselines, we conducted experiments using both univariate and multivariate benchmark datasets across multiple time series tasks. The variants include Agentic-RAG with SelfExtend-Gemma-2B-instruct, Gemma-7B-instruct, and Llama 3-8B-instruct. We utilized several real-world traffic-related datasets (PeMSD3, PeMSD4, PeMSD7, PeMSD7(M), PeMSD8) obtained from the Caltrans Performance Measurement System (PeMS)  (Chen et al . ,  2001 )  for forecasting, classification, and imputation. To ensure consistency with prior research (Choi et al . ,  2022 ) , these datasets are preprocessed by aggregating 30-second data points into 5-minute averages. Additionally, publicly available traffic prediction datasets (METR-LA, PEMS-BAY)  (Li et al . ,  2018 )  are utilized, with data aggregated into 5-minute intervals, resulting in 288 observations per day. Table  1  provides comprehensive details regarding the spatiotemporal multivariate datasets. For anomaly detection, we evaluate the proposed Agentic-RAG framework on publicly available multivariate datasets, conducting a comprehensive benchmark comparison against baseline methods. Table  2  provides an overview of the datasets used in this study. SWaT and WADI 1 1 1 https://itrust.sutd.edu.sg/itrust-labs/datasets/  are real-world datasets on water treatment facilities and distribution networks, respectively. SMAP and MSL are expert annotated open-source datasets of telemetry data sourced from NASA (Hundman et al . ,  2018 ) . The Tennessee Eastman Process (TEP) 2 2 2 https://dataverse.harvard.edu/dataverse/harvard  dataset is a simulated industrial benchmark designed for process monitoring and control, comprising 20 distinct fault types. The HAI 3 3 3 https://github.com/icsdataset/hai  dataset comprises time-series data from an industrial testbed for detecting adversarial attacks on industrial control systems, involving steam-turbine power generation and pumped-storage hydropower generation processes, with 38 different attack scenarios. In addition, we discuss the univariate datasets for forecasting and imputation in the technical appendix.",
            "each cluster/class and its overall effectiveness in classifying time series data based on inherent complex spatio-temporal regimes, paving the way for its practical application in real-world scenarios. The experimental results, presented in Tables  9  and  10 , show a comparison with the simple baselines.",
            "The ETT (Electricity Transformer) datasets (Zhou et al . ,  2021 ) , ETTh1, ETTh2, ETTm1, and ETTm2, are popular benchmarks used for evaluating and benchmarking univariate time series forecasting methods. They provide a challenging benchmark due to the presence of complex patterns, such as trends, seasonality, and irregularities, which are commonly found in real-world time series data. ETTh1 and ETTh2 are two hourly time series datasets containing observations of electricity transformers from two different locations. ETTm1 and ETTm2 are two monthly time series datasets containing observations of electricity transformers from two different locations. In this work, we utilize the ETT datasets (Zhou et al . ,  2021 )  to evaluate the Agentic-RAG framework for both forecasting and missing data imputation tasks. The Table  11  shows the performance of various methods on the multi-horizon forecasting task using a lookback window of size 512. It presents mean squared error (MSE) and mean absolute error (MAE) for nine models (GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG w/Gemma-2B, Agentic-RAG w/Gemma-7B, and Agentic-RAG w/Llama-8B) across four datasets (ETTh1, ETTh2, ETTm1, ETTm2) at different time horizons (96, 192, 336, 720). This allows for a comprehensive analysis of forecasting accuracy and robustness of Agentic-RAG framework across varying prediction lengths. The performance of various methods for imputing missing data (point and block missing) and their effectiveness in out-of-sample imputation settings are compared in Tables  12  and  13 . The evaluated methods include GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG with Gemma-2B, Agentic-RAG with Gemma-7B, and Agentic-RAG with Llama-8B. The evaluation employs a 512-step historical window for imputing 96-step-ahead (short-term prediction) and 720-step-ahead (long-term prediction) missing values in future data. The tables show results for four datasets (ETTh1, ETTh2, ETTm1, ETTm2) under three missing data scenarios: 0% missing (no missing data), 20% point missing, and 20% block missing. The proposed Agentic-RAG framework variants demonstrate strong performance on the benchmark datasets for both forecasting and imputation tasks, with lower errors.",
            "Our study investigates the impact of different components on the overall performance of the framework,  SelfExtend-Agentic-RAG W/Llama 3 - 8B , in time series forecasting, anomaly detection, and classification tasks across various benchmark datasets. We systematically disable each component (dynamic prompting mechanism (DPM), sub-agent specialization (SAS), instruction-tuning (IT), or direct preference optimization (DPO)) and compare the results to the full framework. Tables  14  and  15  detail the forecasting performance, highlighting that the original framework consistently achieves the lowest error rates in MAE, RMSE, and MAPE across different horizons and datasets. This indicates the crucial role of each component in improving forecasting accuracy. Table  16  focuses on anomaly detection tasks, showing the original frameworks superior precision, recall, and F1-score compared to its ablated variants. The original framework consistently achieves higher metrics scores across anomaly benchmark datasets such as SWaT, WADI, SMAP, MSL, and HAI. The significant performance drop observed in the ablated variants underscores the importance of the integrated components, demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original framework excels, as demonstrated in Tables  17  and  18 , achieving the highest accuracy, precision, and recall across datasets like PeMSD3, PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled with the significant drop observed in ablated variants, highlights the critical role each component plays in the original frameworks success. This comprehensive analysis underscores the importance of integrating all components to maximize performance across forecasting, anomaly detection, and classification tasks. The synergistic contribution of the dynamic prompting mechanism, sub-agent specialization, instruction-tuning, and direct preference optimization is evident in the consistent superiority of the Agentic-RAG framework compared to its ablated variants."
        ]
    },
    "id_table_2": {
        "caption": "Table 2.  Statistical summary of benchmark datasets.    \\tau italic_  is the length of subsequences or historical window length.",
        "table": "S4.T3.1.1",
        "footnotes": [],
        "references": [
            "We evaluate the proposed Agentic-RAG framework on four tasks: forecasting, classification, anomaly detection, and imputation. To comprehensively evaluate the framework performance against several baselines, we conducted experiments using both univariate and multivariate benchmark datasets across multiple time series tasks. The variants include Agentic-RAG with SelfExtend-Gemma-2B-instruct, Gemma-7B-instruct, and Llama 3-8B-instruct. We utilized several real-world traffic-related datasets (PeMSD3, PeMSD4, PeMSD7, PeMSD7(M), PeMSD8) obtained from the Caltrans Performance Measurement System (PeMS)  (Chen et al . ,  2001 )  for forecasting, classification, and imputation. To ensure consistency with prior research (Choi et al . ,  2022 ) , these datasets are preprocessed by aggregating 30-second data points into 5-minute averages. Additionally, publicly available traffic prediction datasets (METR-LA, PEMS-BAY)  (Li et al . ,  2018 )  are utilized, with data aggregated into 5-minute intervals, resulting in 288 observations per day. Table  1  provides comprehensive details regarding the spatiotemporal multivariate datasets. For anomaly detection, we evaluate the proposed Agentic-RAG framework on publicly available multivariate datasets, conducting a comprehensive benchmark comparison against baseline methods. Table  2  provides an overview of the datasets used in this study. SWaT and WADI 1 1 1 https://itrust.sutd.edu.sg/itrust-labs/datasets/  are real-world datasets on water treatment facilities and distribution networks, respectively. SMAP and MSL are expert annotated open-source datasets of telemetry data sourced from NASA (Hundman et al . ,  2018 ) . The Tennessee Eastman Process (TEP) 2 2 2 https://dataverse.harvard.edu/dataverse/harvard  dataset is a simulated industrial benchmark designed for process monitoring and control, comprising 20 distinct fault types. The HAI 3 3 3 https://github.com/icsdataset/hai  dataset comprises time-series data from an industrial testbed for detecting adversarial attacks on industrial control systems, involving steam-turbine power generation and pumped-storage hydropower generation processes, with 38 different attack scenarios. In addition, we discuss the univariate datasets for forecasting and imputation in the technical appendix.",
            "For forecasting and imputation tasks, the performance of the proposed framework is evaluated using MAE, RMSE, and MAPE metrics on the original scale of the time series data. For classification tasks, we use accuracy. For anomaly detection, we utilize the standard evaluation metrics of precision (P in %), recall (R in %), and F1-score (F1 in %). We utilize a multi-metric approach for a fair and rigorous comparison with baseline models. To do this, we compute the confusion matrix: true positive (TP) for correctly detected anomalies, false negative (FN) for undetected anomalies, true negative (TN) for correctly identified normal points, and false positive (FP) for normal points mistakenly identified as anomalies. Precision (TP/(FP + TP)) represents the proportion of correctly detected anomalies among all identified anomalies, while recall (TP / (FN + TP)) represents the proportion of all true anomalies that were correctly detected. The F1-score is calculated as the harmonic mean of precision and recall. The threshold for identifying anomalies is set to the highest anomaly score(refer to Section  2.3 ) from the validation dataset. For the SWaT and WADI datasets, which contain contiguous anomaly segments, we adopt the point adjustment strategy  (Shen et al . ,  2020 ; Zhao et al . ,  2020 )  to flag the entire subsequence as an anomaly if the model predicts one. On the Tennessee Eastman dataset, we utilize the Fault Detection Rate (FDR, in %), defined as the ratio of the number of faults detected to the total number of faults that occur, to evaluate the effectiveness of our framework.",
            "The ETT (Electricity Transformer) datasets (Zhou et al . ,  2021 ) , ETTh1, ETTh2, ETTm1, and ETTm2, are popular benchmarks used for evaluating and benchmarking univariate time series forecasting methods. They provide a challenging benchmark due to the presence of complex patterns, such as trends, seasonality, and irregularities, which are commonly found in real-world time series data. ETTh1 and ETTh2 are two hourly time series datasets containing observations of electricity transformers from two different locations. ETTm1 and ETTm2 are two monthly time series datasets containing observations of electricity transformers from two different locations. In this work, we utilize the ETT datasets (Zhou et al . ,  2021 )  to evaluate the Agentic-RAG framework for both forecasting and missing data imputation tasks. The Table  11  shows the performance of various methods on the multi-horizon forecasting task using a lookback window of size 512. It presents mean squared error (MSE) and mean absolute error (MAE) for nine models (GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG w/Gemma-2B, Agentic-RAG w/Gemma-7B, and Agentic-RAG w/Llama-8B) across four datasets (ETTh1, ETTh2, ETTm1, ETTm2) at different time horizons (96, 192, 336, 720). This allows for a comprehensive analysis of forecasting accuracy and robustness of Agentic-RAG framework across varying prediction lengths. The performance of various methods for imputing missing data (point and block missing) and their effectiveness in out-of-sample imputation settings are compared in Tables  12  and  13 . The evaluated methods include GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG with Gemma-2B, Agentic-RAG with Gemma-7B, and Agentic-RAG with Llama-8B. The evaluation employs a 512-step historical window for imputing 96-step-ahead (short-term prediction) and 720-step-ahead (long-term prediction) missing values in future data. The tables show results for four datasets (ETTh1, ETTh2, ETTm1, ETTm2) under three missing data scenarios: 0% missing (no missing data), 20% point missing, and 20% block missing. The proposed Agentic-RAG framework variants demonstrate strong performance on the benchmark datasets for both forecasting and imputation tasks, with lower errors."
        ]
    },
    "id_table_3": {
        "caption": "Table 3.  The table compares various methods for 12-sequence-to-12-sequence forecasting tasks on benchmark datasets using multiple evaluation metrics. These methods use 12 past sequences to predict the next 12 sequences.",
        "table": "S4.T4.3.3",
        "footnotes": [],
        "references": [
            "For forecasting and imputation tasks, the performance of the proposed framework is evaluated using MAE, RMSE, and MAPE metrics on the original scale of the time series data. For classification tasks, we use accuracy. For anomaly detection, we utilize the standard evaluation metrics of precision (P in %), recall (R in %), and F1-score (F1 in %). We utilize a multi-metric approach for a fair and rigorous comparison with baseline models. To do this, we compute the confusion matrix: true positive (TP) for correctly detected anomalies, false negative (FN) for undetected anomalies, true negative (TN) for correctly identified normal points, and false positive (FP) for normal points mistakenly identified as anomalies. Precision (TP/(FP + TP)) represents the proportion of correctly detected anomalies among all identified anomalies, while recall (TP / (FN + TP)) represents the proportion of all true anomalies that were correctly detected. The F1-score is calculated as the harmonic mean of precision and recall. The threshold for identifying anomalies is set to the highest anomaly score(refer to Section  2.3 ) from the validation dataset. For the SWaT and WADI datasets, which contain contiguous anomaly segments, we adopt the point adjustment strategy  (Shen et al . ,  2020 ; Zhao et al . ,  2020 )  to flag the entire subsequence as an anomaly if the model predicts one. On the Tennessee Eastman dataset, we utilize the Fault Detection Rate (FDR, in %), defined as the ratio of the number of faults detected to the total number of faults that occur, to evaluate the effectiveness of our framework.",
            "Tables  3 - 4  present a performance comparison of the Agentic-RAG framework variants with baseline methods on seven benchmark datasets (PeMSD3, PeMSD4, PeMSD7, PeMSD7M, PeMSD8, METR-LA, and PEMS-BAY) on the forecasting task. We report experimental results from a previous study  (Choi et al . ,  2022 )  for a fair and rigorous comparison. Tables  5 - 6  show the performance of Agentic-RAG framework variants on time-series anomaly detection on benchmark datasets. We present experimental results of baseline methods from earlier studies  (Xu et al . ,  2021 ; Deng and Hooi,  2021 ; Chen et al . ,  2021 ; Fu and Xue,  2022 ) . Our proposed framework outperforms baseline methods across the benchmark datasets, showing significant improvements on the forecasting and anomaly detection tasks. We present experimental results on missing data imputation and classification tasks in the appendix. Experimental results on univariate datasets across all time series tasks are discussed in the appendix.",
            "The ETT (Electricity Transformer) datasets (Zhou et al . ,  2021 ) , ETTh1, ETTh2, ETTm1, and ETTm2, are popular benchmarks used for evaluating and benchmarking univariate time series forecasting methods. They provide a challenging benchmark due to the presence of complex patterns, such as trends, seasonality, and irregularities, which are commonly found in real-world time series data. ETTh1 and ETTh2 are two hourly time series datasets containing observations of electricity transformers from two different locations. ETTm1 and ETTm2 are two monthly time series datasets containing observations of electricity transformers from two different locations. In this work, we utilize the ETT datasets (Zhou et al . ,  2021 )  to evaluate the Agentic-RAG framework for both forecasting and missing data imputation tasks. The Table  11  shows the performance of various methods on the multi-horizon forecasting task using a lookback window of size 512. It presents mean squared error (MSE) and mean absolute error (MAE) for nine models (GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG w/Gemma-2B, Agentic-RAG w/Gemma-7B, and Agentic-RAG w/Llama-8B) across four datasets (ETTh1, ETTh2, ETTm1, ETTm2) at different time horizons (96, 192, 336, 720). This allows for a comprehensive analysis of forecasting accuracy and robustness of Agentic-RAG framework across varying prediction lengths. The performance of various methods for imputing missing data (point and block missing) and their effectiveness in out-of-sample imputation settings are compared in Tables  12  and  13 . The evaluated methods include GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG with Gemma-2B, Agentic-RAG with Gemma-7B, and Agentic-RAG with Llama-8B. The evaluation employs a 512-step historical window for imputing 96-step-ahead (short-term prediction) and 720-step-ahead (long-term prediction) missing values in future data. The tables show results for four datasets (ETTh1, ETTh2, ETTm1, ETTm2) under three missing data scenarios: 0% missing (no missing data), 20% point missing, and 20% block missing. The proposed Agentic-RAG framework variants demonstrate strong performance on the benchmark datasets for both forecasting and imputation tasks, with lower errors."
        ]
    },
    "id_table_4": {
        "caption": "Table 4.  The table compares the performance of various forecasting methods on the METR-LA and PEMS-BAY benchmark datasets using multiple evaluation metrics. All methods use 12 past sequences to predict 3, 6, or 12 future sequences.",
        "table": "S4.T5.1.1",
        "footnotes": [],
        "references": [
            "Tables  3 - 4  present a performance comparison of the Agentic-RAG framework variants with baseline methods on seven benchmark datasets (PeMSD3, PeMSD4, PeMSD7, PeMSD7M, PeMSD8, METR-LA, and PEMS-BAY) on the forecasting task. We report experimental results from a previous study  (Choi et al . ,  2022 )  for a fair and rigorous comparison. Tables  5 - 6  show the performance of Agentic-RAG framework variants on time-series anomaly detection on benchmark datasets. We present experimental results of baseline methods from earlier studies  (Xu et al . ,  2021 ; Deng and Hooi,  2021 ; Chen et al . ,  2021 ; Fu and Xue,  2022 ) . Our proposed framework outperforms baseline methods across the benchmark datasets, showing significant improvements on the forecasting and anomaly detection tasks. We present experimental results on missing data imputation and classification tasks in the appendix. Experimental results on univariate datasets across all time series tasks are discussed in the appendix.",
            "Our study investigates the impact of different components on the overall performance of the framework,  SelfExtend-Agentic-RAG W/Llama 3 - 8B , in time series forecasting, anomaly detection, and classification tasks across various benchmark datasets. We systematically disable each component (dynamic prompting mechanism (DPM), sub-agent specialization (SAS), instruction-tuning (IT), or direct preference optimization (DPO)) and compare the results to the full framework. Tables  14  and  15  detail the forecasting performance, highlighting that the original framework consistently achieves the lowest error rates in MAE, RMSE, and MAPE across different horizons and datasets. This indicates the crucial role of each component in improving forecasting accuracy. Table  16  focuses on anomaly detection tasks, showing the original frameworks superior precision, recall, and F1-score compared to its ablated variants. The original framework consistently achieves higher metrics scores across anomaly benchmark datasets such as SWaT, WADI, SMAP, MSL, and HAI. The significant performance drop observed in the ablated variants underscores the importance of the integrated components, demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original framework excels, as demonstrated in Tables  17  and  18 , achieving the highest accuracy, precision, and recall across datasets like PeMSD3, PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled with the significant drop observed in ablated variants, highlights the critical role each component plays in the original frameworks success. This comprehensive analysis underscores the importance of integrating all components to maximize performance across forecasting, anomaly detection, and classification tasks. The synergistic contribution of the dynamic prompting mechanism, sub-agent specialization, instruction-tuning, and direct preference optimization is evident in the consistent superiority of the Agentic-RAG framework compared to its ablated variants."
        ]
    },
    "id_table_5": {
        "caption": "Table 5.  Experimental results on the anomaly detection benchmark datasets in terms of precision, recall, and F1-score",
        "table": "S4.T6.1.1",
        "footnotes": [],
        "references": [
            "Tables  3 - 4  present a performance comparison of the Agentic-RAG framework variants with baseline methods on seven benchmark datasets (PeMSD3, PeMSD4, PeMSD7, PeMSD7M, PeMSD8, METR-LA, and PEMS-BAY) on the forecasting task. We report experimental results from a previous study  (Choi et al . ,  2022 )  for a fair and rigorous comparison. Tables  5 - 6  show the performance of Agentic-RAG framework variants on time-series anomaly detection on benchmark datasets. We present experimental results of baseline methods from earlier studies  (Xu et al . ,  2021 ; Deng and Hooi,  2021 ; Chen et al . ,  2021 ; Fu and Xue,  2022 ) . Our proposed framework outperforms baseline methods across the benchmark datasets, showing significant improvements on the forecasting and anomaly detection tasks. We present experimental results on missing data imputation and classification tasks in the appendix. Experimental results on univariate datasets across all time series tasks are discussed in the appendix.",
            "Our study investigates the impact of different components on the overall performance of the framework,  SelfExtend-Agentic-RAG W/Llama 3 - 8B , in time series forecasting, anomaly detection, and classification tasks across various benchmark datasets. We systematically disable each component (dynamic prompting mechanism (DPM), sub-agent specialization (SAS), instruction-tuning (IT), or direct preference optimization (DPO)) and compare the results to the full framework. Tables  14  and  15  detail the forecasting performance, highlighting that the original framework consistently achieves the lowest error rates in MAE, RMSE, and MAPE across different horizons and datasets. This indicates the crucial role of each component in improving forecasting accuracy. Table  16  focuses on anomaly detection tasks, showing the original frameworks superior precision, recall, and F1-score compared to its ablated variants. The original framework consistently achieves higher metrics scores across anomaly benchmark datasets such as SWaT, WADI, SMAP, MSL, and HAI. The significant performance drop observed in the ablated variants underscores the importance of the integrated components, demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original framework excels, as demonstrated in Tables  17  and  18 , achieving the highest accuracy, precision, and recall across datasets like PeMSD3, PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled with the significant drop observed in ablated variants, highlights the critical role each component plays in the original frameworks success. This comprehensive analysis underscores the importance of integrating all components to maximize performance across forecasting, anomaly detection, and classification tasks. The synergistic contribution of the dynamic prompting mechanism, sub-agent specialization, instruction-tuning, and direct preference optimization is evident in the consistent superiority of the Agentic-RAG framework compared to its ablated variants."
        ]
    },
    "id_table_6": {
        "caption": "Table 6.  Experimental results on simulated Tennessee Eastman dataset in terms of fault detection rate (FDR(%))",
        "table": "A1.T7.1.1",
        "footnotes": [],
        "references": [
            "Tables  3 - 4  present a performance comparison of the Agentic-RAG framework variants with baseline methods on seven benchmark datasets (PeMSD3, PeMSD4, PeMSD7, PeMSD7M, PeMSD8, METR-LA, and PEMS-BAY) on the forecasting task. We report experimental results from a previous study  (Choi et al . ,  2022 )  for a fair and rigorous comparison. Tables  5 - 6  show the performance of Agentic-RAG framework variants on time-series anomaly detection on benchmark datasets. We present experimental results of baseline methods from earlier studies  (Xu et al . ,  2021 ; Deng and Hooi,  2021 ; Chen et al . ,  2021 ; Fu and Xue,  2022 ) . Our proposed framework outperforms baseline methods across the benchmark datasets, showing significant improvements on the forecasting and anomaly detection tasks. We present experimental results on missing data imputation and classification tasks in the appendix. Experimental results on univariate datasets across all time series tasks are discussed in the appendix.",
            "Our study investigates the impact of different components on the overall performance of the framework,  SelfExtend-Agentic-RAG W/Llama 3 - 8B , in time series forecasting, anomaly detection, and classification tasks across various benchmark datasets. We systematically disable each component (dynamic prompting mechanism (DPM), sub-agent specialization (SAS), instruction-tuning (IT), or direct preference optimization (DPO)) and compare the results to the full framework. Tables  14  and  15  detail the forecasting performance, highlighting that the original framework consistently achieves the lowest error rates in MAE, RMSE, and MAPE across different horizons and datasets. This indicates the crucial role of each component in improving forecasting accuracy. Table  16  focuses on anomaly detection tasks, showing the original frameworks superior precision, recall, and F1-score compared to its ablated variants. The original framework consistently achieves higher metrics scores across anomaly benchmark datasets such as SWaT, WADI, SMAP, MSL, and HAI. The significant performance drop observed in the ablated variants underscores the importance of the integrated components, demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original framework excels, as demonstrated in Tables  17  and  18 , achieving the highest accuracy, precision, and recall across datasets like PeMSD3, PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled with the significant drop observed in ablated variants, highlights the critical role each component plays in the original frameworks success. This comprehensive analysis underscores the importance of integrating all components to maximize performance across forecasting, anomaly detection, and classification tasks. The synergistic contribution of the dynamic prompting mechanism, sub-agent specialization, instruction-tuning, and direct preference optimization is evident in the consistent superiority of the Agentic-RAG framework compared to its ablated variants."
        ]
    },
    "id_table_7": {
        "caption": "Table 7.  The table presents the Agentic-RAG frameworks evaluation results on various metrics for missing data imputation across PeMSD3, PeMSD4, PeMSD7, and METR-LA benchmark datasets with diverse missing data patterns.",
        "table": "A1.T8.1.1",
        "footnotes": [],
        "references": [
            "Time series imputation is a critical step in time series analysis. It addresses a common issue in this field: missing values within datasets. These missing values can arise from sensor failures, data transmission errors, or incomplete records. By imputing these gaps, time series imputation ensures the quality and reliability of subsequent analyses. The Agentic-RAG framework achieves this by handling seasonality, trends and capturing the inherent spatio-temporal dependencies within the data. Ultimately, imputation improves data quality, enabling more accurate analysis, modeling, and decision-making. In essence, it plays a vital role by maintaining data integrity and enabling reliable analysis. To evaluate the Agentic-RAG frameworks ability to handle missing data, we simulated two types of missingness patterns: point missing and block missing (Roth and Liebig,  2022 ; Cini et al . ,  2021 ) . These patterns represent varying degrees of data availability. To achieve this, we introduced synthetic missingness into time series datasets following these patterns. For point missing, individual values were randomly omitted with a probability threshold ( p p p italic_p ), controlling the overall percentage of missing data. The block missing pattern involves removing contiguous, multi-period, multi-time series segments. This is done by randomly selecting start and end times, as well as start and end time series, to define uniform blocks with an average length of (). All data points within each block are then omitted. Furthermore, two block missing patterns are considered: temporal and spatial. For temporal block missing, contiguous multi-period segments are removed from a given time series. This is done by randomly selecting start and end times, creating stretches of unavailable temporal data. For spatial block missing, contiguous blocks are removed across multiple related time series at specific time points. This involves randomly selecting the start and end time series, resulting in missing spatial data at the chosen time points. Both patterns show varying levels of missing information in the time series data. In summary, point missing refers to sporadic gaps in the data, while block missing involves the absence of entire contiguous multi-period and multi-series segments. Block missing can further be categorized into two types: temporal block missing, where contiguous segments are removed within a single time series, and spatial block missing, where contiguous blocks are removed across multiple related time series, mimicking realistic scenarios of faulty data collection. In the context of time series imputation, in-sample and out-of-sample imputation refer to distinct evaluation settings. In-sample imputation involves the imputation method reconstructing missing values within a given fixed input sequence,  S t superscript S t S^{t} italic_S start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , using all available observed data within that sequence. Out-of-sample imputation involves training the imputation method using the fixed sequence  S t superscript S t S^{t} italic_S start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT  to impute missing points in a future sequence,  S t + 1 superscript S t 1 S^{t+1} italic_S start_POSTSUPERSCRIPT italic_t + 1 end_POSTSUPERSCRIPT . In this work, we utilize out-of-sample settings, as this approach mimics real-world scenarios and rigorously assesses the Agentic-RAG frameworks robustness and generalizability by evaluating its ability to handle new, unseen data. The simulated datasets with missing values were then used to evaluate the missing data handling capabilities of the proposed Agentic-RAG framework. We split multiple benchmark datasets in chronological order with a ratio of 7:1:2 for the METR-LA and PEMS-BAY datasets and a ratio of 6:2:2 for the other datasets into training, validation, and test sets. We evaluated the Agentic-RAG frameworks performance on simulated data using multiple imputation metrics (e.g., RMSE, MAE, and MAPE). This analysis helps us understand how well the framework handles time series data with missing values, particularly how its performance changes as the percentage of missing data increases. We establish the Agentic-RAG framework, trained on complete data (no missing values), as a strong performance benchmark. This benchmark allows us to evaluate the frameworks effectiveness in imputing missing data under different conditions of data incompleteness. Tables  7  and  8  present the imputation results on standard benchmark datasets with different missingness patterns, while the framework performs slightly worse than the baseline for minimal missing data. Its accuracy degrades more significantly as the data becomes more incomplete, regardless of the specific missingness pattern. Our proposed Agentic-RAG framework demonstrates robustness to missing data by focusing on the available observations for imputing missing values, thereby avoiding the introduction of potentially inaccurate estimates that could obscure the underlying trends and patterns within the time series data. Additionally, the Agentic-RAG framework effectively captures the complex non-linear intra- and inter-time series dependencies and this leads to more reliable imputation. The experiments show that our framework can learn the spatiotemporal dependencies from partially observed data with various missingness patterns, resulting in lower imputation errors.",
            "Our study investigates the impact of different components on the overall performance of the framework,  SelfExtend-Agentic-RAG W/Llama 3 - 8B , in time series forecasting, anomaly detection, and classification tasks across various benchmark datasets. We systematically disable each component (dynamic prompting mechanism (DPM), sub-agent specialization (SAS), instruction-tuning (IT), or direct preference optimization (DPO)) and compare the results to the full framework. Tables  14  and  15  detail the forecasting performance, highlighting that the original framework consistently achieves the lowest error rates in MAE, RMSE, and MAPE across different horizons and datasets. This indicates the crucial role of each component in improving forecasting accuracy. Table  16  focuses on anomaly detection tasks, showing the original frameworks superior precision, recall, and F1-score compared to its ablated variants. The original framework consistently achieves higher metrics scores across anomaly benchmark datasets such as SWaT, WADI, SMAP, MSL, and HAI. The significant performance drop observed in the ablated variants underscores the importance of the integrated components, demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original framework excels, as demonstrated in Tables  17  and  18 , achieving the highest accuracy, precision, and recall across datasets like PeMSD3, PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled with the significant drop observed in ablated variants, highlights the critical role each component plays in the original frameworks success. This comprehensive analysis underscores the importance of integrating all components to maximize performance across forecasting, anomaly detection, and classification tasks. The synergistic contribution of the dynamic prompting mechanism, sub-agent specialization, instruction-tuning, and direct preference optimization is evident in the consistent superiority of the Agentic-RAG framework compared to its ablated variants."
        ]
    },
    "id_table_8": {
        "caption": "Table 8.  The table presents the performance of the Agentic-RAG framework in imputing missing data on the PeMSD7(M), PeMSD8, and PEMS-BAY benchmark datasets with the various synthetic missing data patterns.",
        "table": "A1.T9.1.1",
        "footnotes": [],
        "references": [
            "Time series imputation is a critical step in time series analysis. It addresses a common issue in this field: missing values within datasets. These missing values can arise from sensor failures, data transmission errors, or incomplete records. By imputing these gaps, time series imputation ensures the quality and reliability of subsequent analyses. The Agentic-RAG framework achieves this by handling seasonality, trends and capturing the inherent spatio-temporal dependencies within the data. Ultimately, imputation improves data quality, enabling more accurate analysis, modeling, and decision-making. In essence, it plays a vital role by maintaining data integrity and enabling reliable analysis. To evaluate the Agentic-RAG frameworks ability to handle missing data, we simulated two types of missingness patterns: point missing and block missing (Roth and Liebig,  2022 ; Cini et al . ,  2021 ) . These patterns represent varying degrees of data availability. To achieve this, we introduced synthetic missingness into time series datasets following these patterns. For point missing, individual values were randomly omitted with a probability threshold ( p p p italic_p ), controlling the overall percentage of missing data. The block missing pattern involves removing contiguous, multi-period, multi-time series segments. This is done by randomly selecting start and end times, as well as start and end time series, to define uniform blocks with an average length of (). All data points within each block are then omitted. Furthermore, two block missing patterns are considered: temporal and spatial. For temporal block missing, contiguous multi-period segments are removed from a given time series. This is done by randomly selecting start and end times, creating stretches of unavailable temporal data. For spatial block missing, contiguous blocks are removed across multiple related time series at specific time points. This involves randomly selecting the start and end time series, resulting in missing spatial data at the chosen time points. Both patterns show varying levels of missing information in the time series data. In summary, point missing refers to sporadic gaps in the data, while block missing involves the absence of entire contiguous multi-period and multi-series segments. Block missing can further be categorized into two types: temporal block missing, where contiguous segments are removed within a single time series, and spatial block missing, where contiguous blocks are removed across multiple related time series, mimicking realistic scenarios of faulty data collection. In the context of time series imputation, in-sample and out-of-sample imputation refer to distinct evaluation settings. In-sample imputation involves the imputation method reconstructing missing values within a given fixed input sequence,  S t superscript S t S^{t} italic_S start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , using all available observed data within that sequence. Out-of-sample imputation involves training the imputation method using the fixed sequence  S t superscript S t S^{t} italic_S start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT  to impute missing points in a future sequence,  S t + 1 superscript S t 1 S^{t+1} italic_S start_POSTSUPERSCRIPT italic_t + 1 end_POSTSUPERSCRIPT . In this work, we utilize out-of-sample settings, as this approach mimics real-world scenarios and rigorously assesses the Agentic-RAG frameworks robustness and generalizability by evaluating its ability to handle new, unseen data. The simulated datasets with missing values were then used to evaluate the missing data handling capabilities of the proposed Agentic-RAG framework. We split multiple benchmark datasets in chronological order with a ratio of 7:1:2 for the METR-LA and PEMS-BAY datasets and a ratio of 6:2:2 for the other datasets into training, validation, and test sets. We evaluated the Agentic-RAG frameworks performance on simulated data using multiple imputation metrics (e.g., RMSE, MAE, and MAPE). This analysis helps us understand how well the framework handles time series data with missing values, particularly how its performance changes as the percentage of missing data increases. We establish the Agentic-RAG framework, trained on complete data (no missing values), as a strong performance benchmark. This benchmark allows us to evaluate the frameworks effectiveness in imputing missing data under different conditions of data incompleteness. Tables  7  and  8  present the imputation results on standard benchmark datasets with different missingness patterns, while the framework performs slightly worse than the baseline for minimal missing data. Its accuracy degrades more significantly as the data becomes more incomplete, regardless of the specific missingness pattern. Our proposed Agentic-RAG framework demonstrates robustness to missing data by focusing on the available observations for imputing missing values, thereby avoiding the introduction of potentially inaccurate estimates that could obscure the underlying trends and patterns within the time series data. Additionally, the Agentic-RAG framework effectively captures the complex non-linear intra- and inter-time series dependencies and this leads to more reliable imputation. The experiments show that our framework can learn the spatiotemporal dependencies from partially observed data with various missingness patterns, resulting in lower imputation errors.",
            "Our study investigates the impact of different components on the overall performance of the framework,  SelfExtend-Agentic-RAG W/Llama 3 - 8B , in time series forecasting, anomaly detection, and classification tasks across various benchmark datasets. We systematically disable each component (dynamic prompting mechanism (DPM), sub-agent specialization (SAS), instruction-tuning (IT), or direct preference optimization (DPO)) and compare the results to the full framework. Tables  14  and  15  detail the forecasting performance, highlighting that the original framework consistently achieves the lowest error rates in MAE, RMSE, and MAPE across different horizons and datasets. This indicates the crucial role of each component in improving forecasting accuracy. Table  16  focuses on anomaly detection tasks, showing the original frameworks superior precision, recall, and F1-score compared to its ablated variants. The original framework consistently achieves higher metrics scores across anomaly benchmark datasets such as SWaT, WADI, SMAP, MSL, and HAI. The significant performance drop observed in the ablated variants underscores the importance of the integrated components, demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original framework excels, as demonstrated in Tables  17  and  18 , achieving the highest accuracy, precision, and recall across datasets like PeMSD3, PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled with the significant drop observed in ablated variants, highlights the critical role each component plays in the original frameworks success. This comprehensive analysis underscores the importance of integrating all components to maximize performance across forecasting, anomaly detection, and classification tasks. The synergistic contribution of the dynamic prompting mechanism, sub-agent specialization, instruction-tuning, and direct preference optimization is evident in the consistent superiority of the Agentic-RAG framework compared to its ablated variants."
        ]
    },
    "id_table_9": {
        "caption": "Table 9.  The table shows the evaluation results of the Agentic-RAG framework variants performance on various metrics for time series classification on the PeMSD3, PeMSD4, PeMSD7, and METR-LA benchmark datasets.",
        "table": "A1.T10.1.1",
        "footnotes": [],
        "references": [
            "each cluster/class and its overall effectiveness in classifying time series data based on inherent complex spatio-temporal regimes, paving the way for its practical application in real-world scenarios. The experimental results, presented in Tables  9  and  10 , show a comparison with the simple baselines."
        ]
    },
    "id_table_10": {
        "caption": "Table 10.  The table presents a comparative evaluation of the Agentic-RAG framework variants performance on three benchmark datasets: PeMSD7(M), PeMSD8, and PEMS-BAY, across various metrics for time series classification.",
        "table": "A3.T11.1.1",
        "footnotes": [],
        "references": [
            "each cluster/class and its overall effectiveness in classifying time series data based on inherent complex spatio-temporal regimes, paving the way for its practical application in real-world scenarios. The experimental results, presented in Tables  9  and  10 , show a comparison with the simple baselines."
        ]
    },
    "id_table_11": {
        "caption": "Table 11.  The table compares various methods for the multi-horizon forecasting task with a lookback window of size 512.",
        "table": "A3.T12.1.1",
        "footnotes": [],
        "references": [
            "The ETT (Electricity Transformer) datasets (Zhou et al . ,  2021 ) , ETTh1, ETTh2, ETTm1, and ETTm2, are popular benchmarks used for evaluating and benchmarking univariate time series forecasting methods. They provide a challenging benchmark due to the presence of complex patterns, such as trends, seasonality, and irregularities, which are commonly found in real-world time series data. ETTh1 and ETTh2 are two hourly time series datasets containing observations of electricity transformers from two different locations. ETTm1 and ETTm2 are two monthly time series datasets containing observations of electricity transformers from two different locations. In this work, we utilize the ETT datasets (Zhou et al . ,  2021 )  to evaluate the Agentic-RAG framework for both forecasting and missing data imputation tasks. The Table  11  shows the performance of various methods on the multi-horizon forecasting task using a lookback window of size 512. It presents mean squared error (MSE) and mean absolute error (MAE) for nine models (GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG w/Gemma-2B, Agentic-RAG w/Gemma-7B, and Agentic-RAG w/Llama-8B) across four datasets (ETTh1, ETTh2, ETTm1, ETTm2) at different time horizons (96, 192, 336, 720). This allows for a comprehensive analysis of forecasting accuracy and robustness of Agentic-RAG framework across varying prediction lengths. The performance of various methods for imputing missing data (point and block missing) and their effectiveness in out-of-sample imputation settings are compared in Tables  12  and  13 . The evaluated methods include GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG with Gemma-2B, Agentic-RAG with Gemma-7B, and Agentic-RAG with Llama-8B. The evaluation employs a 512-step historical window for imputing 96-step-ahead (short-term prediction) and 720-step-ahead (long-term prediction) missing values in future data. The tables show results for four datasets (ETTh1, ETTh2, ETTm1, ETTm2) under three missing data scenarios: 0% missing (no missing data), 20% point missing, and 20% block missing. The proposed Agentic-RAG framework variants demonstrate strong performance on the benchmark datasets for both forecasting and imputation tasks, with lower errors."
        ]
    },
    "id_table_12": {
        "caption": "Table 12.  The table compares different methods for imputing missing data, specifically for point missing (PM) and block missing (BM) scenarios, using a 512-step lookback window for forecasting 96 steps ahead.",
        "table": "A3.T13.1.1",
        "footnotes": [],
        "references": [
            "The ETT (Electricity Transformer) datasets (Zhou et al . ,  2021 ) , ETTh1, ETTh2, ETTm1, and ETTm2, are popular benchmarks used for evaluating and benchmarking univariate time series forecasting methods. They provide a challenging benchmark due to the presence of complex patterns, such as trends, seasonality, and irregularities, which are commonly found in real-world time series data. ETTh1 and ETTh2 are two hourly time series datasets containing observations of electricity transformers from two different locations. ETTm1 and ETTm2 are two monthly time series datasets containing observations of electricity transformers from two different locations. In this work, we utilize the ETT datasets (Zhou et al . ,  2021 )  to evaluate the Agentic-RAG framework for both forecasting and missing data imputation tasks. The Table  11  shows the performance of various methods on the multi-horizon forecasting task using a lookback window of size 512. It presents mean squared error (MSE) and mean absolute error (MAE) for nine models (GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG w/Gemma-2B, Agentic-RAG w/Gemma-7B, and Agentic-RAG w/Llama-8B) across four datasets (ETTh1, ETTh2, ETTm1, ETTm2) at different time horizons (96, 192, 336, 720). This allows for a comprehensive analysis of forecasting accuracy and robustness of Agentic-RAG framework across varying prediction lengths. The performance of various methods for imputing missing data (point and block missing) and their effectiveness in out-of-sample imputation settings are compared in Tables  12  and  13 . The evaluated methods include GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG with Gemma-2B, Agentic-RAG with Gemma-7B, and Agentic-RAG with Llama-8B. The evaluation employs a 512-step historical window for imputing 96-step-ahead (short-term prediction) and 720-step-ahead (long-term prediction) missing values in future data. The tables show results for four datasets (ETTh1, ETTh2, ETTm1, ETTm2) under three missing data scenarios: 0% missing (no missing data), 20% point missing, and 20% block missing. The proposed Agentic-RAG framework variants demonstrate strong performance on the benchmark datasets for both forecasting and imputation tasks, with lower errors."
        ]
    },
    "id_table_13": {
        "caption": "Table 13.  The table evaluates the effectiveness of various missing data imputation techniques (including point-wise and block-wise methods) for out-of-sample imputation, using a 512-step historical window to predict missing values in subsequent 720-step future data.",
        "table": "A5.T14.1.1",
        "footnotes": [],
        "references": [
            "The ETT (Electricity Transformer) datasets (Zhou et al . ,  2021 ) , ETTh1, ETTh2, ETTm1, and ETTm2, are popular benchmarks used for evaluating and benchmarking univariate time series forecasting methods. They provide a challenging benchmark due to the presence of complex patterns, such as trends, seasonality, and irregularities, which are commonly found in real-world time series data. ETTh1 and ETTh2 are two hourly time series datasets containing observations of electricity transformers from two different locations. ETTm1 and ETTm2 are two monthly time series datasets containing observations of electricity transformers from two different locations. In this work, we utilize the ETT datasets (Zhou et al . ,  2021 )  to evaluate the Agentic-RAG framework for both forecasting and missing data imputation tasks. The Table  11  shows the performance of various methods on the multi-horizon forecasting task using a lookback window of size 512. It presents mean squared error (MSE) and mean absolute error (MAE) for nine models (GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG w/Gemma-2B, Agentic-RAG w/Gemma-7B, and Agentic-RAG w/Llama-8B) across four datasets (ETTh1, ETTh2, ETTm1, ETTm2) at different time horizons (96, 192, 336, 720). This allows for a comprehensive analysis of forecasting accuracy and robustness of Agentic-RAG framework across varying prediction lengths. The performance of various methods for imputing missing data (point and block missing) and their effectiveness in out-of-sample imputation settings are compared in Tables  12  and  13 . The evaluated methods include GPT4TS (Zhou et al . ,  2023b ) , PatchTST (Nie et al . ,  2023 ) , TimesNet (Wu et al . ,  2023 ) , FEDFormer (Zhou et al . ,  2022 ) , LightTS (Zhang et al . ,  2022b ) , N-BEATS (Oreshkin et al . ,  2020 ) , Agentic-RAG with Gemma-2B, Agentic-RAG with Gemma-7B, and Agentic-RAG with Llama-8B. The evaluation employs a 512-step historical window for imputing 96-step-ahead (short-term prediction) and 720-step-ahead (long-term prediction) missing values in future data. The tables show results for four datasets (ETTh1, ETTh2, ETTm1, ETTm2) under three missing data scenarios: 0% missing (no missing data), 20% point missing, and 20% block missing. The proposed Agentic-RAG framework variants demonstrate strong performance on the benchmark datasets for both forecasting and imputation tasks, with lower errors."
        ]
    },
    "id_table_14": {
        "caption": "Table 14.  The table shows the ablation study results for 12-sequence-to-12-sequence forecasting tasks on benchmark datasets using multiple evaluation metrics. The performance of the ablated variants drops compared to the original framework.",
        "table": "A5.T15.3.3",
        "footnotes": [],
        "references": [
            "Our study investigates the impact of different components on the overall performance of the framework,  SelfExtend-Agentic-RAG W/Llama 3 - 8B , in time series forecasting, anomaly detection, and classification tasks across various benchmark datasets. We systematically disable each component (dynamic prompting mechanism (DPM), sub-agent specialization (SAS), instruction-tuning (IT), or direct preference optimization (DPO)) and compare the results to the full framework. Tables  14  and  15  detail the forecasting performance, highlighting that the original framework consistently achieves the lowest error rates in MAE, RMSE, and MAPE across different horizons and datasets. This indicates the crucial role of each component in improving forecasting accuracy. Table  16  focuses on anomaly detection tasks, showing the original frameworks superior precision, recall, and F1-score compared to its ablated variants. The original framework consistently achieves higher metrics scores across anomaly benchmark datasets such as SWaT, WADI, SMAP, MSL, and HAI. The significant performance drop observed in the ablated variants underscores the importance of the integrated components, demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original framework excels, as demonstrated in Tables  17  and  18 , achieving the highest accuracy, precision, and recall across datasets like PeMSD3, PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled with the significant drop observed in ablated variants, highlights the critical role each component plays in the original frameworks success. This comprehensive analysis underscores the importance of integrating all components to maximize performance across forecasting, anomaly detection, and classification tasks. The synergistic contribution of the dynamic prompting mechanism, sub-agent specialization, instruction-tuning, and direct preference optimization is evident in the consistent superiority of the Agentic-RAG framework compared to its ablated variants."
        ]
    },
    "id_table_15": {
        "caption": "Table 15.  The table presents the ablation study results for the forecasting task performed on the METR-LA and PEMS-BAY datasets, evaluated using multiple metrics. All methods utilized 12 historical sequences to forecast 3, 6, or 12 future sequences.",
        "table": "A5.T16.1.1",
        "footnotes": [],
        "references": [
            "Our study investigates the impact of different components on the overall performance of the framework,  SelfExtend-Agentic-RAG W/Llama 3 - 8B , in time series forecasting, anomaly detection, and classification tasks across various benchmark datasets. We systematically disable each component (dynamic prompting mechanism (DPM), sub-agent specialization (SAS), instruction-tuning (IT), or direct preference optimization (DPO)) and compare the results to the full framework. Tables  14  and  15  detail the forecasting performance, highlighting that the original framework consistently achieves the lowest error rates in MAE, RMSE, and MAPE across different horizons and datasets. This indicates the crucial role of each component in improving forecasting accuracy. Table  16  focuses on anomaly detection tasks, showing the original frameworks superior precision, recall, and F1-score compared to its ablated variants. The original framework consistently achieves higher metrics scores across anomaly benchmark datasets such as SWaT, WADI, SMAP, MSL, and HAI. The significant performance drop observed in the ablated variants underscores the importance of the integrated components, demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original framework excels, as demonstrated in Tables  17  and  18 , achieving the highest accuracy, precision, and recall across datasets like PeMSD3, PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled with the significant drop observed in ablated variants, highlights the critical role each component plays in the original frameworks success. This comprehensive analysis underscores the importance of integrating all components to maximize performance across forecasting, anomaly detection, and classification tasks. The synergistic contribution of the dynamic prompting mechanism, sub-agent specialization, instruction-tuning, and direct preference optimization is evident in the consistent superiority of the Agentic-RAG framework compared to its ablated variants."
        ]
    },
    "id_table_16": {
        "caption": "Table 16.  The table showcases the experimental findings from the ablation study conducted on anomaly detection benchmark datasets, reporting the precision, recall, and F1-score metrics.",
        "table": "A5.T17.1.1",
        "footnotes": [],
        "references": [
            "Our study investigates the impact of different components on the overall performance of the framework,  SelfExtend-Agentic-RAG W/Llama 3 - 8B , in time series forecasting, anomaly detection, and classification tasks across various benchmark datasets. We systematically disable each component (dynamic prompting mechanism (DPM), sub-agent specialization (SAS), instruction-tuning (IT), or direct preference optimization (DPO)) and compare the results to the full framework. Tables  14  and  15  detail the forecasting performance, highlighting that the original framework consistently achieves the lowest error rates in MAE, RMSE, and MAPE across different horizons and datasets. This indicates the crucial role of each component in improving forecasting accuracy. Table  16  focuses on anomaly detection tasks, showing the original frameworks superior precision, recall, and F1-score compared to its ablated variants. The original framework consistently achieves higher metrics scores across anomaly benchmark datasets such as SWaT, WADI, SMAP, MSL, and HAI. The significant performance drop observed in the ablated variants underscores the importance of the integrated components, demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original framework excels, as demonstrated in Tables  17  and  18 , achieving the highest accuracy, precision, and recall across datasets like PeMSD3, PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled with the significant drop observed in ablated variants, highlights the critical role each component plays in the original frameworks success. This comprehensive analysis underscores the importance of integrating all components to maximize performance across forecasting, anomaly detection, and classification tasks. The synergistic contribution of the dynamic prompting mechanism, sub-agent specialization, instruction-tuning, and direct preference optimization is evident in the consistent superiority of the Agentic-RAG framework compared to its ablated variants."
        ]
    },
    "id_table_17": {
        "caption": "Table 17.  The table presents the ablation study results, evaluating the performance across various metrics for time series classification tasks on the PeMSD3, PeMSD4, PeMSD7, and METR-LA benchmark datasets.",
        "table": "A5.T18.1.1",
        "footnotes": [],
        "references": [
            "Our study investigates the impact of different components on the overall performance of the framework,  SelfExtend-Agentic-RAG W/Llama 3 - 8B , in time series forecasting, anomaly detection, and classification tasks across various benchmark datasets. We systematically disable each component (dynamic prompting mechanism (DPM), sub-agent specialization (SAS), instruction-tuning (IT), or direct preference optimization (DPO)) and compare the results to the full framework. Tables  14  and  15  detail the forecasting performance, highlighting that the original framework consistently achieves the lowest error rates in MAE, RMSE, and MAPE across different horizons and datasets. This indicates the crucial role of each component in improving forecasting accuracy. Table  16  focuses on anomaly detection tasks, showing the original frameworks superior precision, recall, and F1-score compared to its ablated variants. The original framework consistently achieves higher metrics scores across anomaly benchmark datasets such as SWaT, WADI, SMAP, MSL, and HAI. The significant performance drop observed in the ablated variants underscores the importance of the integrated components, demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original framework excels, as demonstrated in Tables  17  and  18 , achieving the highest accuracy, precision, and recall across datasets like PeMSD3, PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled with the significant drop observed in ablated variants, highlights the critical role each component plays in the original frameworks success. This comprehensive analysis underscores the importance of integrating all components to maximize performance across forecasting, anomaly detection, and classification tasks. The synergistic contribution of the dynamic prompting mechanism, sub-agent specialization, instruction-tuning, and direct preference optimization is evident in the consistent superiority of the Agentic-RAG framework compared to its ablated variants."
        ]
    },
    "global_footnotes": [
        "https://itrust.sutd.edu.sg/itrust-labs/datasets/",
        "https://dataverse.harvard.edu/dataverse/harvard",
        "https://github.com/icsdataset/hai"
    ]
}