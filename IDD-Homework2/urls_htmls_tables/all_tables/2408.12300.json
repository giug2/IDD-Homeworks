{
    "PAPER'S NUMBER OF TABLES": 2,
    "S3.T2": {
        "caption": "",
        "table": "<table id=\"S3.T2.fig1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.fig1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.fig1.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\"><span id=\"S3.T2.fig1.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Method</span></th>\n<th id=\"S3.T2.fig1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"3\"><span id=\"S3.T2.fig1.3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Retina</span></th>\n<th id=\"S3.T2.fig1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T2.fig1.3.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">COVID-FL</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.fig1.3.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.fig1.3.2.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\"></th>\n<td id=\"S3.T2.fig1.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Split-1</span></td>\n<td id=\"S3.T2.fig1.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Split-2</span></td>\n<td id=\"S3.T2.fig1.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.2.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Split-3</span></td>\n<td id=\"S3.T2.fig1.3.2.1.5\" class=\"ltx_td ltx_border_t\"></td>\n</tr>\n<tr id=\"S3.T2.fig1.3.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.fig1.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S3.T2.fig1.3.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedAvg</span></th>\n<td id=\"S3.T2.fig1.3.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">83.63</span></td>\n<td id=\"S3.T2.fig1.3.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">82.26</span></td>\n<td id=\"S3.T2.fig1.3.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.3.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.13</span></td>\n<td id=\"S3.T2.fig1.3.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.3.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">79.86</span></td>\n</tr>\n<tr id=\"S3.T2.fig1.3.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.fig1.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S3.T2.fig1.3.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedProx</span></th>\n<td id=\"S3.T2.fig1.3.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">84.17</span></td>\n<td id=\"S3.T2.fig1.3.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">83.53</span></td>\n<td id=\"S3.T2.fig1.3.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.4.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.20</span></td>\n<td id=\"S3.T2.fig1.3.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.4.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.88</span></td>\n</tr>\n<tr id=\"S3.T2.fig1.3.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T2.fig1.3.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S3.T2.fig1.3.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedBN</span></th>\n<td id=\"S3.T2.fig1.3.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">83.91</span></td>\n<td id=\"S3.T2.fig1.3.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.5.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">75.91</span></td>\n<td id=\"S3.T2.fig1.3.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.5.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">65.25</span></td>\n<td id=\"S3.T2.fig1.3.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.5.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">56.34</span></td>\n</tr>\n<tr id=\"S3.T2.fig1.3.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T2.fig1.3.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S3.T2.fig1.3.6.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedPAC</span></th>\n<td id=\"S3.T2.fig1.3.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">78.01</span></td>\n<td id=\"S3.T2.fig1.3.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.6.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">71.64</span></td>\n<td id=\"S3.T2.fig1.3.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.6.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">52.81</span></td>\n<td id=\"S3.T2.fig1.3.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.6.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.63</span></td>\n</tr>\n<tr id=\"S3.T2.fig1.3.7.6\" class=\"ltx_tr\">\n<th id=\"S3.T2.fig1.3.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S3.T2.fig1.3.7.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedGH</span></th>\n<td id=\"S3.T2.fig1.3.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.7.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">83.90</span></td>\n<td id=\"S3.T2.fig1.3.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.7.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">83.33</span></td>\n<td id=\"S3.T2.fig1.3.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.7.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.56</span></td>\n<td id=\"S3.T2.fig1.3.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.fig1.3.7.6.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">82.26</span></td>\n</tr>\n<tr id=\"S3.T2.fig1.3.8.7\" class=\"ltx_tr\">\n<th id=\"S3.T2.fig1.3.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\"><span id=\"S3.T2.fig1.3.8.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours</span></th>\n<td id=\"S3.T2.fig1.3.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S3.T2.fig1.3.8.7.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">85.20</span></td>\n<td id=\"S3.T2.fig1.3.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S3.T2.fig1.3.8.7.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">83.83</span></td>\n<td id=\"S3.T2.fig1.3.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S3.T2.fig1.3.8.7.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">82.30</span></td>\n<td id=\"S3.T2.fig1.3.8.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S3.T2.fig1.3.8.7.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">83.87</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "However, a comprehensive joint effort to minimize all three terms - local loss, distribution shift loss, and aggregation loss - is currently limited in the literature. To fill this gap, we propose a novel FL method based on global loss decomposition, called FedLD, to jointly reduce these three loss terms, as shown in Fig.¬†1. Our FedLD involves a margin control regularization in local training to reduce the distribution shift loss, and a principal gradient-based server aggregation strategy to minimize the aggregation loss. Specifically, our margin control regularization encourages local models to learn stable features instead of shortcut features by adding the l2subscriptùëô2l_{2}-norm of the output logits to the standard cross entropy loss, thereby reducing the distribution shift loss. On the other hand, the local models trained on heterogeneous data distribution in FL may exhibit different or even conflicting judgments, leading to potential conflicts in clients‚Äô gradients. Naively aggregating these conflicting gradients in FL may lead to increased aggregation loss, thus resulting in poorly performing global model. Therefore, we propose a principal gradient-based server aggregation strategy to mitigate conflicting gradients by prioritizing principal directions that benefit all clients while discarding conflict-contributing directions, ultimately reducing the aggregation loss."
        ]
    },
    "S3.T3": {
        "caption": "Table 3: The comparison of final test accuracy (%) of different methods on Retina with 50 clients. We apply client sampling with rate 0.1 for FL training.",
        "table": "<table id=\"S3.T3.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S3.T3.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Method</span></th>\n<td id=\"S3.T3.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedAvg</span></td>\n<td id=\"S3.T3.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.3.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedProx</span></td>\n<td id=\"S3.T3.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.3.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedBN</span></td>\n<td id=\"S3.T3.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.3.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedPAC</span></td>\n<td id=\"S3.T3.3.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.3.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedGH</span></td>\n<td id=\"S3.T3.3.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.3.1.1.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours</span></td>\n</tr>\n<tr id=\"S3.T3.3.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\"><span id=\"S3.T3.3.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Accuracy (%)</span></th>\n<td id=\"S3.T3.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S3.T3.3.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">67.43</span></td>\n<td id=\"S3.T3.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S3.T3.3.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">69.87</span></td>\n<td id=\"S3.T3.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S3.T3.3.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">68.40</span></td>\n<td id=\"S3.T3.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S3.T3.3.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">66.59</span></td>\n<td id=\"S3.T3.3.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S3.T3.3.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">70.33</span></td>\n<td id=\"S3.T3.3.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S3.T3.3.2.2.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">71.30</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "As demonstrated in Table ",
                "2",
                ", our method outperforms all compared methods in all datasets with all levels of data heterogeneity. Importantly, as the data heterogeneity increases (i.e., from Split-1 to Split-3 in Retina), the performance improvement compared to the second-best method (i.e., FedGH) also increases (i.e., from 0.04% to 2.20%), which demonstrates the ability of our method to effectively alleviate the negative impact of data heterogeneity."
            ]
        ]
    }
}