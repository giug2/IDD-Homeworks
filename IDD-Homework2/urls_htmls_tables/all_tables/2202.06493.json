{
    "PAPER'S NUMBER OF TABLES": 3,
    "Sx2.T1": {
        "caption": "Table 1: FLHub command lists.",
        "table": "<table id=\"Sx2.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"Sx2.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"Sx2.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Command</th>\n<th id=\"Sx2.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Action</th>\n<th id=\"Sx2.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Meaning</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx2.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"Sx2.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Branch</td>\n<td id=\"Sx2.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Create new branch</td>\n<td id=\"Sx2.T1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Ready for next federated round</td>\n</tr>\n<tr id=\"Sx2.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"Sx2.T1.1.3.2.1\" class=\"ltx_td ltx_align_left\">Fork (All)</td>\n<td id=\"Sx2.T1.1.3.2.2\" class=\"ltx_td ltx_align_left\">Clone the model</td>\n<td id=\"Sx2.T1.1.3.2.3\" class=\"ltx_td ltx_align_left\">Prepare to participate in learning</td>\n</tr>\n<tr id=\"Sx2.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"Sx2.T1.1.4.3.1\" class=\"ltx_td ltx_align_left\">Fork (Feature layer only)</td>\n<td id=\"Sx2.T1.1.4.3.2\" class=\"ltx_td ltx_align_left\">Clone feature layer only</td>\n<td id=\"Sx2.T1.1.4.3.3\" class=\"ltx_td ltx_align_left\">Prepare transfer learning model</td>\n</tr>\n<tr id=\"Sx2.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"Sx2.T1.1.5.4.1\" class=\"ltx_td ltx_align_left\">Commit</td>\n<td id=\"Sx2.T1.1.5.4.2\" class=\"ltx_td ltx_align_left\">Update model weights</td>\n<td id=\"Sx2.T1.1.5.4.3\" class=\"ltx_td ltx_align_left\">Local epoch in local training</td>\n</tr>\n<tr id=\"Sx2.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"Sx2.T1.1.6.5.1\" class=\"ltx_td ltx_align_left\">Pull Request (All)</td>\n<td id=\"Sx2.T1.1.6.5.2\" class=\"ltx_td ltx_align_left\">Federated aggregation</td>\n<td id=\"Sx2.T1.1.6.5.3\" class=\"ltx_td ltx_align_left\">Request to participate in learning</td>\n</tr>\n<tr id=\"Sx2.T1.1.7.6\" class=\"ltx_tr\">\n<td id=\"Sx2.T1.1.7.6.1\" class=\"ltx_td ltx_align_left\">Pull Request (Feature layer only)</td>\n<td id=\"Sx2.T1.1.7.6.2\" class=\"ltx_td ltx_align_left\">Multi task federated learning</td>\n<td id=\"Sx2.T1.1.7.6.3\" class=\"ltx_td ltx_align_left\">Request to participate in learning</td>\n</tr>\n<tr id=\"Sx2.T1.1.8.7\" class=\"ltx_tr\">\n<td id=\"Sx2.T1.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Merge</td>\n<td id=\"Sx2.T1.1.8.7.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">Update global model</td>\n<td id=\"Sx2.T1.1.8.7.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">Deploy new model with aggregated weights</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Due to FLHub, it is possible to participate in asynchronous model learning by simply managing the model as a network and to create a new model by forking the public model to use in a new domain.\nFor example, federated learning developers and administrators can fork a learning model published in the Fashion MNIST repository and change it to a CIFAR10 model, as shown in Fig. 3.\nSince FLHub processed a series of fork-commits like transfer learning, the forked model uses the knowledge (weight parameters) learned from the source domain in the target domain.\nIn addition, if necessary, model managers can learn the feature layer together and perform federated multi-task learning (FMTL) with each prediction layer.\nTable 1 shows the representative commands and operations of FLHub, and designed similarly to those of Git, GitHub, and DockerHub for user convenience."
        ]
    },
    "Sx2.T2": {
        "caption": "Table 2: Federated Learning Hub gRPC Messages",
        "table": "<table id=\"Sx2.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"Sx2.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"Sx2.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">gRPC Messages</th>\n<th id=\"Sx2.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Function</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx2.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">GetInformation</td>\n<td id=\"Sx2.T2.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Retrieve model name,</td>\n</tr>\n<tr id=\"Sx2.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.1.3.2.1\" class=\"ltx_td\"></td>\n<td id=\"Sx2.T2.1.3.2.2\" class=\"ltx_td ltx_align_left\">version</td>\n</tr>\n<tr id=\"Sx2.T2.1.4.3\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.1.4.3.1\" class=\"ltx_td ltx_align_left\">GetModel</td>\n<td id=\"Sx2.T2.1.4.3.2\" class=\"ltx_td ltx_align_left\">Download architecture,</td>\n</tr>\n<tr id=\"Sx2.T2.1.5.4\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.1.5.4.1\" class=\"ltx_td\"></td>\n<td id=\"Sx2.T2.1.5.4.2\" class=\"ltx_td ltx_align_left\">parameter, and etc. of model</td>\n</tr>\n<tr id=\"Sx2.T2.1.6.5\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.1.6.5.1\" class=\"ltx_td ltx_align_left\">PushTrainResult</td>\n<td id=\"Sx2.T2.1.6.5.2\" class=\"ltx_td ltx_align_left\">Upload learning result</td>\n</tr>\n<tr id=\"Sx2.T2.1.7.6\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.1.7.6.1\" class=\"ltx_td ltx_align_left\">GetStatus</td>\n<td id=\"Sx2.T2.1.7.6.2\" class=\"ltx_td ltx_align_left\">Retrieve learning result</td>\n</tr>\n<tr id=\"Sx2.T2.1.8.7\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.1.8.7.1\" class=\"ltx_td\"></td>\n<td id=\"Sx2.T2.1.8.7.2\" class=\"ltx_td ltx_align_left\">for target model</td>\n</tr>\n<tr id=\"Sx2.T2.1.9.8\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.1.9.8.1\" class=\"ltx_td ltx_align_left\">PushControl</td>\n<td id=\"Sx2.T2.1.9.8.2\" class=\"ltx_td ltx_align_left\">Perform federated aggregation</td>\n</tr>\n<tr id=\"Sx2.T2.1.10.9\" class=\"ltx_tr\">\n<td id=\"Sx2.T2.1.10.9.1\" class=\"ltx_td ltx_border_bb\"></td>\n<td id=\"Sx2.T2.1.10.9.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">or mark ignoring learning result</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "The FLHub service consists of a web server and database with the communication of ",
                "gRPC",
                " (Figure ",
                "2",
                ").\nFLHub users are consist of model managers and learning participants with different roles like GitHub.\nThe model manager is responsible for maintaining and merging models, and participants upload the updated learning model with their private data.\nWhen participants are to contribute the model by sending a pull request like GitHub, the model manager examines the learning results contributed by each participant and issues a merge command if it is effective.",
                "The following is a simple usage scenario of the FLHub service in four steps (Fig. ",
                "2",
                ").",
                "The model manager uploads and opens a new model with attributes of name, shape, initial weight, and learning method (compile information, optimizer).",
                "A private image classification dataset participant downloads the publicly available model from the FLHub server and trains the model with their data.",
                "After the participants complete the learning process asynchronously, they send the results to the FLHub server.",
                "The model manager issues a model merge command with the model name and reference version as factors if the learning result contributes to the model.",
                "After merging the model contributions, the HLHub web server updates the learning results to the model version, performs a federated aggregation, and records the model version in the database.",
                "In the FLHub service, the model name and model version are essential elements to provide multiple models simultaneously and to merge the asynchronously returned training results.\nThe model name identifies the target model.\nThe model version increments each time FL model merging proceeds, and it distinguishes different model versions.\nIn addition, participants can prevent duplicate contributions with the model name and version.\nThe learning manager handles the learning results asynchronously with the reference version.\nWhen FLHub reports multiple training results with different versions, the learning manager ignores the old learning result and selects the recent model version.\nAlternatively, the model manager can create a new branch based on the old version.",
                "FLHub identifies models and contributions by model name and version (major, minor, micro).\nAs shown in Fig. ",
                "3",
                ", FLHub identifies a model as a version and draws a network to manage asynchronous participation and model differentiation.\nTherefore, when the model manager creates a branch for the next federated round (federated branch in Fig. ",
                "3",
                "), each participant asynchronously commits the learning result with their data and sends a pull request to the model manager (learning participant branch in Fig. ",
                "3",
                ").\nThe learning model history is displayed as a commit within the branch through local epoch, global update, etc.",
                "Due to FLHub, it is possible to participate in asynchronous model learning by simply managing the model as a network and to create a new model by forking the public model to use in a new domain.\nFor example, federated learning developers and administrators can fork a learning model published in the ",
                "Fashion MNIST",
                " repository and change it to a ",
                "CIFAR10",
                " model, as shown in Fig. ",
                "3",
                ".\nSince FLHub processed a series of fork-commits like transfer learning, the forked model uses the knowledge (weight parameters) learned from the source domain in the target domain.\nIn addition, if necessary, model managers can learn the feature layer together and perform federated multi-task learning (FMTL) with each prediction layer.\nTable ",
                "1",
                " shows the representative commands and operations of FLHub, and designed similarly to those of ",
                "Git",
                ", ",
                "GitHub",
                ", and ",
                "DockerHub",
                " for user convenience.",
                "FLHub is served through a web page or by directly communicating with the model handler and ",
                "gRPC",
                " at the code level.\nWhen a user communicates with ",
                "gRPC",
                ", FLHub performs authentication using an API key, and an authenticated user can issue merge and pull request commands only to authorized models.\nModel parameters, architecture, and compile information are serialized and stored in the RDBMS.\nThe model structure and weight information are described in ",
                "JavaScript object notation (JSON)",
                " and ",
                "Binary large object (BLOB)",
                " format.\nListing ",
                "1",
                " is a code sample for training a ",
                "TensorFlow",
                " model by communicating with FLHub directly with ",
                "gRPC",
                " in ",
                "Python 3",
                ", which is very similar to the code for creating and training a model in ",
                "TensorFlow",
                "."
            ]
        ]
    },
    "Sx3.T3": {
        "caption": "Table 3: Dataset for experiments",
        "table": "<table id=\"Sx3.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx3.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"Sx3.T3.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<td id=\"Sx3.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<table id=\"Sx3.T3.1.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"Sx3.T3.1.1.1.2.1.1\" class=\"ltx_tr\">\n<td id=\"Sx3.T3.1.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Fashion</td>\n</tr>\n<tr id=\"Sx3.T3.1.1.1.2.1.2\" class=\"ltx_tr\">\n<td id=\"Sx3.T3.1.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">MNIST</td>\n</tr>\n</table>\n</td>\n<td id=\"Sx3.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">CIFAR10</td>\n<td id=\"Sx3.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<table id=\"Sx3.T3.1.1.1.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"Sx3.T3.1.1.1.4.1.1\" class=\"ltx_tr\">\n<td id=\"Sx3.T3.1.1.1.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Caltech</td>\n</tr>\n<tr id=\"Sx3.T3.1.1.1.4.1.2\" class=\"ltx_tr\">\n<td id=\"Sx3.T3.1.1.1.4.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Birds</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"Sx3.T3.1.2.2\" class=\"ltx_tr\">\n<th id=\"Sx3.T3.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Domain</th>\n<td id=\"Sx3.T3.1.2.2.2\" class=\"ltx_td ltx_align_right ltx_border_t\">Clothing</td>\n<td id=\"Sx3.T3.1.2.2.3\" class=\"ltx_td ltx_align_right ltx_border_t\">Vehicle, Animal</td>\n<td id=\"Sx3.T3.1.2.2.4\" class=\"ltx_td ltx_align_right ltx_border_t\">Bird</td>\n</tr>\n<tr id=\"Sx3.T3.1.3.3\" class=\"ltx_tr\">\n<th id=\"Sx3.T3.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Train data</th>\n<td id=\"Sx3.T3.1.3.3.2\" class=\"ltx_td ltx_align_right\">60,000</td>\n<td id=\"Sx3.T3.1.3.3.3\" class=\"ltx_td ltx_align_right\">50,000</td>\n<td id=\"Sx3.T3.1.3.3.4\" class=\"ltx_td ltx_align_right\" rowspan=\"2\"><span id=\"Sx3.T3.1.3.3.4.1\" class=\"ltx_text\">17821</span></td>\n</tr>\n<tr id=\"Sx3.T3.1.4.4\" class=\"ltx_tr\">\n<th id=\"Sx3.T3.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Test data</th>\n<td id=\"Sx3.T3.1.4.4.2\" class=\"ltx_td ltx_align_right\">10,000</td>\n<td id=\"Sx3.T3.1.4.4.3\" class=\"ltx_td ltx_align_right\">10,000</td>\n</tr>\n<tr id=\"Sx3.T3.1.5.5\" class=\"ltx_tr\">\n<th id=\"Sx3.T3.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Classes</th>\n<td id=\"Sx3.T3.1.5.5.2\" class=\"ltx_td ltx_align_right\">10</td>\n<td id=\"Sx3.T3.1.5.5.3\" class=\"ltx_td ltx_align_right\">10</td>\n<td id=\"Sx3.T3.1.5.5.4\" class=\"ltx_td ltx_align_right\">200</td>\n</tr>\n<tr id=\"Sx3.T3.1.6.6\" class=\"ltx_tr\">\n<th id=\"Sx3.T3.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Clients</th>\n<td id=\"Sx3.T3.1.6.6.2\" class=\"ltx_td ltx_align_right\">3</td>\n<td id=\"Sx3.T3.1.6.6.3\" class=\"ltx_td ltx_align_right\">5</td>\n<td id=\"Sx3.T3.1.6.6.4\" class=\"ltx_td ltx_align_right\">10</td>\n</tr>\n<tr id=\"Sx3.T3.1.7.7\" class=\"ltx_tr\">\n<th id=\"Sx3.T3.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">Samples</th>\n<td id=\"Sx3.T3.1.7.7.2\" class=\"ltx_td ltx_align_right ltx_border_bb\">6,400</td>\n<td id=\"Sx3.T3.1.7.7.3\" class=\"ltx_td ltx_align_right ltx_border_bb\">6,400</td>\n<td id=\"Sx3.T3.1.7.7.4\" class=\"ltx_td ltx_align_right ltx_border_bb\">3,200</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We conduct experiments to examine two questions on FLHub using table 3.\nFirst, does the forked model complete the training faster than the model trained in another domain compared to a randomly initialized model?\nSecond, between the model trained on simple data and the model trained on various data, which model should be forked and perform better?\nWe use Fashion MNIST, CIFAR10, and Caltech Bird 200 data available in the TensorFlow Datasets.\nSince a client participating in learning in the real world does not always have the same data, the client randomly sampled many data from the training dataset every round.\nFLHub and experimental source code are available on Github."
        ]
    }
}