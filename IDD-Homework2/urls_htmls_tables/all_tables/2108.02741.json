{
    "PAPER'S NUMBER OF TABLES": 6,
    "S5.T1": {
        "caption": "Table 1: Data Structure of FEMNIST-3-groups",
        "table": "<table id=\"S5.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Group</span></td>\n<td id=\"S5.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Data Type</span></td>\n<td id=\"S5.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Number of Images</span></td>\n<td id=\"S5.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Number of Devices</span></td>\n</tr>\n<tr id=\"S5.T1.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Group 1</span></td>\n<td id=\"S5.T1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Capital Letters + Digits</span></td>\n<td id=\"S5.T1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">800</span></td>\n<td id=\"S5.T1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">60</span></td>\n</tr>\n<tr id=\"S5.T1.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Group 2</span></td>\n<td id=\"S5.T1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Lowercase Letters + Digits</span></td>\n<td id=\"S5.T1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">1,000</span></td>\n<td id=\"S5.T1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.1.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">100</span></td>\n</tr>\n<tr id=\"S5.T1.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T1.1.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Group 3</span></td>\n<td id=\"S5.T1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T1.1.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Capital/Lowercase Letters + Digits</span></td>\n<td id=\"S5.T1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T1.1.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">600</span></td>\n<td id=\"S5.T1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T1.1.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">40</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Group Fairness (FEMNIST-3-groups, d=3𝑑3d=3) We manually divide FEMNIST data into three groups. See Table 1 for the detailed assignment. This assignment is inspired by the statistic that most people prefer to write in lowercase letters while a small amount of people use capital letters or a mixed of two types (Jones and Mewhort 2004). In such cases, it is important to assure that an FL algorithm is capable of achieving similar performance between such groups. Results are reported in Table 4."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Empirical results on FEMNIST-skewed. Each experiment is repeated 5 times.",
        "table": "<table id=\"S5.T2.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T2.2.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.2.3.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Algorithm</span></td>\n<td id=\"S5.T2.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.2.3.2.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">FedAvg</span></td>\n<td id=\"S5.T2.2.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.2.3.3.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">q-FFL</span></td>\n<td id=\"S5.T2.2.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.2.3.4.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">TERM</span></td>\n<td id=\"S5.T2.2.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.2.3.5.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">FedMGDA+</span></td>\n<td id=\"S5.T2.2.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.2.3.6.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">Ditto</span></td>\n<td id=\"S5.T2.2.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.2.3.7.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">GIFAIR-FL-Global</span></td>\n<td id=\"S5.T2.2.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.2.3.8.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">GIFAIR-FL-Per</span></td>\n</tr>\n<tr id=\"S5.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S5.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bar{a}\" display=\"inline\"><semantics id=\"S5.T2.1.1.1.m1.1a\"><mover accent=\"true\" id=\"S5.T2.1.1.1.m1.1.1\" xref=\"S5.T2.1.1.1.m1.1.1.cmml\"><mi mathsize=\"80%\" id=\"S5.T2.1.1.1.m1.1.1.2\" xref=\"S5.T2.1.1.1.m1.1.1.2.cmml\">a</mi><mo mathsize=\"80%\" id=\"S5.T2.1.1.1.m1.1.1.1\" xref=\"S5.T2.1.1.1.m1.1.1.1.cmml\">¯</mo></mover><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.1.1.1.m1.1b\"><apply id=\"S5.T2.1.1.1.m1.1.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1\"><ci id=\"S5.T2.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.1\">¯</ci><ci id=\"S5.T2.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.2\">𝑎</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.1.1.1.m1.1c\">\\bar{a}</annotation></semantics></math></td>\n<td id=\"S5.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">79.2 (1.0)</span></td>\n<td id=\"S5.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.1.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">84.6 (1.9)</span></td>\n<td id=\"S5.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.1.1.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">84.2 (1.3)</span></td>\n<td id=\"S5.T2.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.1.1.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">85.0 (1.7)</span></td>\n<td id=\"S5.T2.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.1.1.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">92.5 (3.1)</span></td>\n<td id=\"S5.T2.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.1.1.7.1\" class=\"ltx_text\" style=\"font-size:80%;\">87.9 (0.9)</span></td>\n<td id=\"S5.T2.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<span id=\"S5.T2.1.1.8.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">93.0</span><span id=\"S5.T2.1.1.8.2\" class=\"ltx_text\" style=\"font-size:80%;\"> (1.1)</span>\n</td>\n</tr>\n<tr id=\"S5.T2.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><math id=\"S5.T2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sqrt{Var(a)}\" display=\"inline\"><semantics id=\"S5.T2.2.2.1.m1.1a\"><msqrt id=\"S5.T2.2.2.1.m1.1.1\" xref=\"S5.T2.2.2.1.m1.1.1.cmml\"><mrow id=\"S5.T2.2.2.1.m1.1.1.1\" xref=\"S5.T2.2.2.1.m1.1.1.1.cmml\"><mi mathsize=\"80%\" id=\"S5.T2.2.2.1.m1.1.1.1.3\" xref=\"S5.T2.2.2.1.m1.1.1.1.3.cmml\">V</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.2.2.1.m1.1.1.1.2\" xref=\"S5.T2.2.2.1.m1.1.1.1.2.cmml\">​</mo><mi mathsize=\"80%\" id=\"S5.T2.2.2.1.m1.1.1.1.4\" xref=\"S5.T2.2.2.1.m1.1.1.1.4.cmml\">a</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.2.2.1.m1.1.1.1.2a\" xref=\"S5.T2.2.2.1.m1.1.1.1.2.cmml\">​</mo><mi mathsize=\"80%\" id=\"S5.T2.2.2.1.m1.1.1.1.5\" xref=\"S5.T2.2.2.1.m1.1.1.1.5.cmml\">r</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.2.2.1.m1.1.1.1.2b\" xref=\"S5.T2.2.2.1.m1.1.1.1.2.cmml\">​</mo><mrow id=\"S5.T2.2.2.1.m1.1.1.1.6.2\" xref=\"S5.T2.2.2.1.m1.1.1.1.cmml\"><mo maxsize=\"80%\" minsize=\"80%\" id=\"S5.T2.2.2.1.m1.1.1.1.6.2.1\" xref=\"S5.T2.2.2.1.m1.1.1.1.cmml\">(</mo><mi mathsize=\"80%\" id=\"S5.T2.2.2.1.m1.1.1.1.1\" xref=\"S5.T2.2.2.1.m1.1.1.1.1.cmml\">a</mi><mo maxsize=\"80%\" minsize=\"80%\" id=\"S5.T2.2.2.1.m1.1.1.1.6.2.2\" xref=\"S5.T2.2.2.1.m1.1.1.1.cmml\">)</mo></mrow></mrow></msqrt><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.2.2.1.m1.1b\"><apply id=\"S5.T2.2.2.1.m1.1.1.cmml\" xref=\"S5.T2.2.2.1.m1.1.1\"><root id=\"S5.T2.2.2.1.m1.1.1a.cmml\" xref=\"S5.T2.2.2.1.m1.1.1\"></root><apply id=\"S5.T2.2.2.1.m1.1.1.1.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.1\"><times id=\"S5.T2.2.2.1.m1.1.1.1.2.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.1.2\"></times><ci id=\"S5.T2.2.2.1.m1.1.1.1.3.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.1.3\">𝑉</ci><ci id=\"S5.T2.2.2.1.m1.1.1.1.4.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.1.4\">𝑎</ci><ci id=\"S5.T2.2.2.1.m1.1.1.1.5.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.1.5\">𝑟</ci><ci id=\"S5.T2.2.2.1.m1.1.1.1.1.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.1.1\">𝑎</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.2.2.1.m1.1c\">\\sqrt{Var(a)}</annotation></semantics></math></td>\n<td id=\"S5.T2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T2.2.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">22.3 (1.1)</span></td>\n<td id=\"S5.T2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T2.2.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">18.5 (1.2)</span></td>\n<td id=\"S5.T2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T2.2.2.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">13.8 (1.0)</span></td>\n<td id=\"S5.T2.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T2.2.2.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">14.9 (1.6)</span></td>\n<td id=\"S5.T2.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T2.2.2.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">14.3 (1.0)</span></td>\n<td id=\"S5.T2.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">\n<span id=\"S5.T2.2.2.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">5.7</span><span id=\"S5.T2.2.2.7.2\" class=\"ltx_text\" style=\"font-size:80%;\"> (0.8)</span>\n</td>\n<td id=\"S5.T2.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T2.2.2.8.1\" class=\"ltx_text\" style=\"font-size:80%;\">6.2 (0.9)</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Individual Fairness (FEMNIST-skewed, d=100𝑑100d=100) Following the setting in (Li et al. 2018), we first sample 10 lower case characters (‘a’-‘j’) from Extended MNIST (EMNIST) (Cohen et al. 2017) and distribute 5 classes of images to each device. Each local device has 500 images. There are 100 devices in total.\nResults are reported in Table 2. (FEMNIST-original, d=500𝑑500d=500) Following the setting in (Li et al. 2021), we sample 500 devices and train models using the default data stored in each device.\nResults are reported in Table 3.",
            "Based on Table 2-6, we can obtain important insights. First, compared to other benchmark models, GIFAIR-FL-Global/GIFAIR-FL-Per lead to significantly more fair solutions. As shown in Tables 2, 3 and 5, our algorithm significantly reduces the variance of testing accuracy of all devices (i.e., V​a​r​(a)𝑉𝑎𝑟𝑎Var(a)) while the average testing accuracy remains consistent. Second, from Tables 4 and 6, it can be seen that GIFAIR-FL-Global/GIFAIR-FL-Per boosted the performance of the group with the worst testing accuracy and achieved the smallest discrepancy. Notably, this boost did not affect the performance of other groups. This indicates that GIFAIR-FL-Global/GIFAIR-FL-Per is capable of ensuring fairness among different groups while retaining a superior or similar prediction accuracy compared to existing benchmark models. Finally, we note that GIFAIR-FL-Global sometimes achieves lower prediction performance than Ditto. This is understandable as Ditto provides a personalized solution to each device k𝑘k while our model only returns a global parameter 𝜽¯bold-¯𝜽\\bm{\\bar{\\theta}}. Yet, as shown in the last column, if we use GIFAIR-FL-Per, then the prediction performance can be significantly improved without sacrificing fairness. However, even without personalization, GIFAIR-FL-Global achieves superior testing performance compared to existing fair FL benchmark models."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Test accuracy on FEMNIST-original. Each experiment is repeated 5 times.",
        "table": "<table id=\"S5.T3.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T3.2.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.2.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.2.3.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Algorithm</span></td>\n<td id=\"S5.T3.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.2.3.2.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">FedAvg</span></td>\n<td id=\"S5.T3.2.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.2.3.3.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">q-FFL</span></td>\n<td id=\"S5.T3.2.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.2.3.4.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">TERM</span></td>\n<td id=\"S5.T3.2.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.2.3.5.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">AFL</span></td>\n<td id=\"S5.T3.2.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.2.3.6.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">Ditto</span></td>\n<td id=\"S5.T3.2.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.2.3.7.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">GIFAIR-FL-Global</span></td>\n<td id=\"S5.T3.2.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.2.3.8.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">GIFAIR-FL-Per</span></td>\n</tr>\n<tr id=\"S5.T3.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S5.T3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bar{a}\" display=\"inline\"><semantics id=\"S5.T3.1.1.1.m1.1a\"><mover accent=\"true\" id=\"S5.T3.1.1.1.m1.1.1\" xref=\"S5.T3.1.1.1.m1.1.1.cmml\"><mi mathsize=\"80%\" id=\"S5.T3.1.1.1.m1.1.1.2\" xref=\"S5.T3.1.1.1.m1.1.1.2.cmml\">a</mi><mo mathsize=\"80%\" id=\"S5.T3.1.1.1.m1.1.1.1\" xref=\"S5.T3.1.1.1.m1.1.1.1.cmml\">¯</mo></mover><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.1.1.1.m1.1b\"><apply id=\"S5.T3.1.1.1.m1.1.1.cmml\" xref=\"S5.T3.1.1.1.m1.1.1\"><ci id=\"S5.T3.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T3.1.1.1.m1.1.1.1\">¯</ci><ci id=\"S5.T3.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T3.1.1.1.m1.1.1.2\">𝑎</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.1.1.1.m1.1c\">\\bar{a}</annotation></semantics></math></td>\n<td id=\"S5.T3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">80.4 (1.3)</span></td>\n<td id=\"S5.T3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">80.9 (1.1)</span></td>\n<td id=\"S5.T3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.1.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">81.0 (1.0)</span></td>\n<td id=\"S5.T3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.1.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">82.4 (1.0)</span></td>\n<td id=\"S5.T3.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.1.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">83.7 (1.9)</span></td>\n<td id=\"S5.T3.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.1.7.1\" class=\"ltx_text\" style=\"font-size:80%;\">83.2 (0.7)</span></td>\n<td id=\"S5.T3.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.1.8.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">84.1 (1.2)</span></td>\n</tr>\n<tr id=\"S5.T3.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><math id=\"S5.T3.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sqrt{Var(a)}\" display=\"inline\"><semantics id=\"S5.T3.2.2.1.m1.1a\"><msqrt id=\"S5.T3.2.2.1.m1.1.1\" xref=\"S5.T3.2.2.1.m1.1.1.cmml\"><mrow id=\"S5.T3.2.2.1.m1.1.1.1\" xref=\"S5.T3.2.2.1.m1.1.1.1.cmml\"><mi mathsize=\"80%\" id=\"S5.T3.2.2.1.m1.1.1.1.3\" xref=\"S5.T3.2.2.1.m1.1.1.1.3.cmml\">V</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T3.2.2.1.m1.1.1.1.2\" xref=\"S5.T3.2.2.1.m1.1.1.1.2.cmml\">​</mo><mi mathsize=\"80%\" id=\"S5.T3.2.2.1.m1.1.1.1.4\" xref=\"S5.T3.2.2.1.m1.1.1.1.4.cmml\">a</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T3.2.2.1.m1.1.1.1.2a\" xref=\"S5.T3.2.2.1.m1.1.1.1.2.cmml\">​</mo><mi mathsize=\"80%\" id=\"S5.T3.2.2.1.m1.1.1.1.5\" xref=\"S5.T3.2.2.1.m1.1.1.1.5.cmml\">r</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T3.2.2.1.m1.1.1.1.2b\" xref=\"S5.T3.2.2.1.m1.1.1.1.2.cmml\">​</mo><mrow id=\"S5.T3.2.2.1.m1.1.1.1.6.2\" xref=\"S5.T3.2.2.1.m1.1.1.1.cmml\"><mo maxsize=\"80%\" minsize=\"80%\" id=\"S5.T3.2.2.1.m1.1.1.1.6.2.1\" xref=\"S5.T3.2.2.1.m1.1.1.1.cmml\">(</mo><mi mathsize=\"80%\" id=\"S5.T3.2.2.1.m1.1.1.1.1\" xref=\"S5.T3.2.2.1.m1.1.1.1.1.cmml\">a</mi><mo maxsize=\"80%\" minsize=\"80%\" id=\"S5.T3.2.2.1.m1.1.1.1.6.2.2\" xref=\"S5.T3.2.2.1.m1.1.1.1.cmml\">)</mo></mrow></mrow></msqrt><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.2.2.1.m1.1b\"><apply id=\"S5.T3.2.2.1.m1.1.1.cmml\" xref=\"S5.T3.2.2.1.m1.1.1\"><root id=\"S5.T3.2.2.1.m1.1.1a.cmml\" xref=\"S5.T3.2.2.1.m1.1.1\"></root><apply id=\"S5.T3.2.2.1.m1.1.1.1.cmml\" xref=\"S5.T3.2.2.1.m1.1.1.1\"><times id=\"S5.T3.2.2.1.m1.1.1.1.2.cmml\" xref=\"S5.T3.2.2.1.m1.1.1.1.2\"></times><ci id=\"S5.T3.2.2.1.m1.1.1.1.3.cmml\" xref=\"S5.T3.2.2.1.m1.1.1.1.3\">𝑉</ci><ci id=\"S5.T3.2.2.1.m1.1.1.1.4.cmml\" xref=\"S5.T3.2.2.1.m1.1.1.1.4\">𝑎</ci><ci id=\"S5.T3.2.2.1.m1.1.1.1.5.cmml\" xref=\"S5.T3.2.2.1.m1.1.1.1.5\">𝑟</ci><ci id=\"S5.T3.2.2.1.m1.1.1.1.1.cmml\" xref=\"S5.T3.2.2.1.m1.1.1.1.1\">𝑎</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.2.2.1.m1.1c\">\\sqrt{Var(a)}</annotation></semantics></math></td>\n<td id=\"S5.T3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T3.2.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">11.1 (1.4)</span></td>\n<td id=\"S5.T3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T3.2.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">10.6 (1.3)</span></td>\n<td id=\"S5.T3.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T3.2.2.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">10.3 (1.2)</span></td>\n<td id=\"S5.T3.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T3.2.2.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">9.85 (0.9)</span></td>\n<td id=\"S5.T3.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T3.2.2.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">10.1 (1.6)</span></td>\n<td id=\"S5.T3.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T3.2.2.7.1\" class=\"ltx_text\" style=\"font-size:80%;\">5.2 (0.8)</span></td>\n<td id=\"S5.T3.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T3.2.2.8.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">4.5 (0.8)</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Individual Fairness (FEMNIST-skewed, d=100𝑑100d=100) Following the setting in (Li et al. 2018), we first sample 10 lower case characters (‘a’-‘j’) from Extended MNIST (EMNIST) (Cohen et al. 2017) and distribute 5 classes of images to each device. Each local device has 500 images. There are 100 devices in total.\nResults are reported in Table 2. (FEMNIST-original, d=500𝑑500d=500) Following the setting in (Li et al. 2021), we sample 500 devices and train models using the default data stored in each device.\nResults are reported in Table 3."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Test accuracy on FEMNIST-3-groups. Each experiment is repeated 5 times. Discrepancy is the difference between the largest accuracy and the smallest accuracy.",
        "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle\">\n<tr id=\"S5.T4.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Algorithm</span></td>\n<td id=\"S5.T4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.1.2.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">FedAvg</span></td>\n<td id=\"S5.T4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.1.3.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">q-FFL</span></td>\n<td id=\"S5.T4.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.1.4.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">TERM</span></td>\n<td id=\"S5.T4.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.1.5.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">FedMGDA+</span></td>\n<td id=\"S5.T4.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.1.6.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">Ditto</span></td>\n</tr>\n<tr id=\"S5.T4.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Group 1</span></td>\n<td id=\"S5.T4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">79.72 (2.08)</span></td>\n<td id=\"S5.T4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.15 (1.97)</span></td>\n<td id=\"S5.T4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.29 (1.45)</span></td>\n<td id=\"S5.T4.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.03 (2.28)</span></td>\n<td id=\"S5.T4.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">82.37 (2.06)</span></td>\n</tr>\n<tr id=\"S5.T4.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Group 2</span></td>\n<td id=\"S5.T4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">90.93 (2.35)</span></td>\n<td id=\"S5.T4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">88.24 (2.13)</span></td>\n<td id=\"S5.T4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">88.08 (1.09)</span></td>\n<td id=\"S5.T4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">89.12 (1.74)</span></td>\n<td id=\"S5.T4.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.3.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">92.05 (2.00)</span></td>\n</tr>\n<tr id=\"S5.T4.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Group 3</span></td>\n<td id=\"S5.T4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">80.21 (2.91)</span></td>\n<td id=\"S5.T4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">80.93 (1.86)</span></td>\n<td id=\"S5.T4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.84 (1.44)</span></td>\n<td id=\"S5.T4.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.33 (1.59)</span></td>\n<td id=\"S5.T4.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">83.03 (2.18)</span></td>\n</tr>\n<tr id=\"S5.T4.1.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T4.1.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Discrepancy</span></td>\n<td id=\"S5.T4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T4.1.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.21</span></td>\n<td id=\"S5.T4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T4.1.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">7.31</span></td>\n<td id=\"S5.T4.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T4.1.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.79</span></td>\n<td id=\"S5.T4.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T4.1.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">8.09</span></td>\n<td id=\"S5.T4.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T4.1.5.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">9.02</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Group Fairness (FEMNIST-3-groups, d=3𝑑3d=3) We manually divide FEMNIST data into three groups. See Table 1 for the detailed assignment. This assignment is inspired by the statistic that most people prefer to write in lowercase letters while a small amount of people use capital letters or a mixed of two types (Jones and Mewhort 2004). In such cases, it is important to assure that an FL algorithm is capable of achieving similar performance between such groups. Results are reported in Table 4."
        ]
    },
    "S5.T5": {
        "caption": "Table 5: Mean and standard deviation of test accuracy on Shakespeare (d=31)𝑑31(d=31). Each experiment is repeated 5 times.",
        "table": "<table id=\"S5.T5.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T5.2.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.2.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.2.3.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Algorithm</span></td>\n<td id=\"S5.T5.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.2.3.2.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">FedAvg</span></td>\n<td id=\"S5.T5.2.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.2.3.3.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">q-FFL</span></td>\n<td id=\"S5.T5.2.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.2.3.4.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">AFL</span></td>\n<td id=\"S5.T5.2.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.2.3.5.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">Ditto</span></td>\n<td id=\"S5.T5.2.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.2.3.6.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">GIFAIR-FL-Global</span></td>\n<td id=\"S5.T5.2.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.2.3.7.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">GIFAIR-FL-Per</span></td>\n</tr>\n<tr id=\"S5.T5.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S5.T5.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bar{a}\" display=\"inline\"><semantics id=\"S5.T5.1.1.1.m1.1a\"><mover accent=\"true\" id=\"S5.T5.1.1.1.m1.1.1\" xref=\"S5.T5.1.1.1.m1.1.1.cmml\"><mi mathsize=\"80%\" id=\"S5.T5.1.1.1.m1.1.1.2\" xref=\"S5.T5.1.1.1.m1.1.1.2.cmml\">a</mi><mo mathsize=\"80%\" id=\"S5.T5.1.1.1.m1.1.1.1\" xref=\"S5.T5.1.1.1.m1.1.1.1.cmml\">¯</mo></mover><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.1.1.1.m1.1b\"><apply id=\"S5.T5.1.1.1.m1.1.1.cmml\" xref=\"S5.T5.1.1.1.m1.1.1\"><ci id=\"S5.T5.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T5.1.1.1.m1.1.1.1\">¯</ci><ci id=\"S5.T5.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T5.1.1.1.m1.1.1.2\">𝑎</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.1.1.1.m1.1c\">\\bar{a}</annotation></semantics></math></td>\n<td id=\"S5.T5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">53.21 (0.31)</span></td>\n<td id=\"S5.T5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.1.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">53.90 (0.30)</span></td>\n<td id=\"S5.T5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.1.1.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">54.58 (0.14)</span></td>\n<td id=\"S5.T5.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.1.1.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">60.74 (0.42)</span></td>\n<td id=\"S5.T5.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.1.1.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">57.04 (0.23)</span></td>\n<td id=\"S5.T5.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.1.1.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">61.58 (0.14)</span></td>\n</tr>\n<tr id=\"S5.T5.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><math id=\"S5.T5.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sqrt{Var(a)}\" display=\"inline\"><semantics id=\"S5.T5.2.2.1.m1.1a\"><msqrt id=\"S5.T5.2.2.1.m1.1.1\" xref=\"S5.T5.2.2.1.m1.1.1.cmml\"><mrow id=\"S5.T5.2.2.1.m1.1.1.1\" xref=\"S5.T5.2.2.1.m1.1.1.1.cmml\"><mi mathsize=\"80%\" id=\"S5.T5.2.2.1.m1.1.1.1.3\" xref=\"S5.T5.2.2.1.m1.1.1.1.3.cmml\">V</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T5.2.2.1.m1.1.1.1.2\" xref=\"S5.T5.2.2.1.m1.1.1.1.2.cmml\">​</mo><mi mathsize=\"80%\" id=\"S5.T5.2.2.1.m1.1.1.1.4\" xref=\"S5.T5.2.2.1.m1.1.1.1.4.cmml\">a</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T5.2.2.1.m1.1.1.1.2a\" xref=\"S5.T5.2.2.1.m1.1.1.1.2.cmml\">​</mo><mi mathsize=\"80%\" id=\"S5.T5.2.2.1.m1.1.1.1.5\" xref=\"S5.T5.2.2.1.m1.1.1.1.5.cmml\">r</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T5.2.2.1.m1.1.1.1.2b\" xref=\"S5.T5.2.2.1.m1.1.1.1.2.cmml\">​</mo><mrow id=\"S5.T5.2.2.1.m1.1.1.1.6.2\" xref=\"S5.T5.2.2.1.m1.1.1.1.cmml\"><mo maxsize=\"80%\" minsize=\"80%\" id=\"S5.T5.2.2.1.m1.1.1.1.6.2.1\" xref=\"S5.T5.2.2.1.m1.1.1.1.cmml\">(</mo><mi mathsize=\"80%\" id=\"S5.T5.2.2.1.m1.1.1.1.1\" xref=\"S5.T5.2.2.1.m1.1.1.1.1.cmml\">a</mi><mo maxsize=\"80%\" minsize=\"80%\" id=\"S5.T5.2.2.1.m1.1.1.1.6.2.2\" xref=\"S5.T5.2.2.1.m1.1.1.1.cmml\">)</mo></mrow></mrow></msqrt><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.2.2.1.m1.1b\"><apply id=\"S5.T5.2.2.1.m1.1.1.cmml\" xref=\"S5.T5.2.2.1.m1.1.1\"><root id=\"S5.T5.2.2.1.m1.1.1a.cmml\" xref=\"S5.T5.2.2.1.m1.1.1\"></root><apply id=\"S5.T5.2.2.1.m1.1.1.1.cmml\" xref=\"S5.T5.2.2.1.m1.1.1.1\"><times id=\"S5.T5.2.2.1.m1.1.1.1.2.cmml\" xref=\"S5.T5.2.2.1.m1.1.1.1.2\"></times><ci id=\"S5.T5.2.2.1.m1.1.1.1.3.cmml\" xref=\"S5.T5.2.2.1.m1.1.1.1.3\">𝑉</ci><ci id=\"S5.T5.2.2.1.m1.1.1.1.4.cmml\" xref=\"S5.T5.2.2.1.m1.1.1.1.4\">𝑎</ci><ci id=\"S5.T5.2.2.1.m1.1.1.1.5.cmml\" xref=\"S5.T5.2.2.1.m1.1.1.1.5\">𝑟</ci><ci id=\"S5.T5.2.2.1.m1.1.1.1.1.cmml\" xref=\"S5.T5.2.2.1.m1.1.1.1.1\">𝑎</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.2.2.1.m1.1c\">\\sqrt{Var(a)}</annotation></semantics></math></td>\n<td id=\"S5.T5.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">9.25 (6.17)</span></td>\n<td id=\"S5.T5.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">7.52 (5.10)</span></td>\n<td id=\"S5.T5.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.2.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">8.44 (5.65)</span></td>\n<td id=\"S5.T5.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.2.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">8.32 (4.77)</span></td>\n<td id=\"S5.T5.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.2.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">3.14 (1.25)</span></td>\n<td id=\"S5.T5.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T5.2.2.7.1\" class=\"ltx_text\" style=\"font-size:80%;\">4.33 (1.25)</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Following the setting in McMahan et al. (2017) and Li et al. (2019a), we subsample 31 roles (d=31𝑑31d=31). The RNN model takes a 80-character sequence as the input, and outputs one character after two LSTM layers and one densely-connected layer. For FedAvg, q-FFL and Ditto, the best initial learning rate is 0.8 and decay rate is 0.95 (Li et al. 2021). We also adopt this setting to GIFAIR-FL-Global and GIFAIR-FL-Per. The batch size is set to be 10. The number of local epochs is fixed to be 1 and all models are trained for 500 epochs. Results are reported in Table 5."
        ]
    },
    "S5.T6": {
        "caption": "Table 6: Test accuracy on Shakespeare (d=2𝑑2d=2). Each experiment is repeated 5 times. ",
        "table": "<table id=\"S5.T6.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T6.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Algorithm</span></td>\n<td id=\"S5.T6.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.1.2.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">FedAvg</span></td>\n<td id=\"S5.T6.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.1.3.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">q-FFL</span></td>\n<td id=\"S5.T6.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.1.4.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">FedMGDA+</span></td>\n<td id=\"S5.T6.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.1.5.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">Ditto</span></td>\n<td id=\"S5.T6.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.1.6.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;\">GIFAIR-FL-Global</span></td>\n<td id=\"S5.T6.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.1.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">GIFAIR-FL-Per</span></td>\n</tr>\n<tr id=\"S5.T6.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Male</span></td>\n<td id=\"S5.T6.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">72.95 (1.70)</span></td>\n<td id=\"S5.T6.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">67.14 (2.18)</span></td>\n<td id=\"S5.T6.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.2.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">67.07 (2.11)</span></td>\n<td id=\"S5.T6.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">74.19 (3.75)</span></td>\n<td id=\"S5.T6.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.2.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">67.42(0.98)</span></td>\n<td id=\"S5.T6.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.2.7.1\" class=\"ltx_text\" style=\"font-size:80%;\">73.95 (0.59)</span></td>\n</tr>\n<tr id=\"S5.T6.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Female</span></td>\n<td id=\"S5.T6.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">40.39 (1.49)</span></td>\n<td id=\"S5.T6.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">43.26 (2.05)</span></td>\n<td id=\"S5.T6.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">43.85 (2.32)</span></td>\n<td id=\"S5.T6.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">45.73 (4.01)</span></td>\n<td id=\"S5.T6.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">52.04 (1.10)</span></td>\n<td id=\"S5.T6.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">54.88 (1.12)</span></td>\n</tr>\n<tr id=\"S5.T6.3.4\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T6.3.4.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Discrepancy</span></td>\n<td id=\"S5.T6.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T6.3.4.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">32.56</span></td>\n<td id=\"S5.T6.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T6.3.4.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">23.88</span></td>\n<td id=\"S5.T6.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T6.3.4.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">23.22</span></td>\n<td id=\"S5.T6.3.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T6.3.4.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">28.46</span></td>\n<td id=\"S5.T6.3.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T6.3.4.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">15.38</span></td>\n<td id=\"S5.T6.3.4.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T6.3.4.7.1\" class=\"ltx_text\" style=\"font-size:80%;\">19.07</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Group Fairness: We obtain the gender information from https://shakespeare.folger.edu/ and group speaking roles based on gender (d=2𝑑2d=2). It is known that the majority of characters in Shakespearean drama are males. Simply training a FedAvg model on this dataset will cause implicit bias towards male characters. On a par with this observation, we subsample 25 males and 10 females from “The Complete Works of William Shakespeare”. Here we note that each device in the male group implicitly has more text data. The setting of hyperparameters is same as that of individual fairness. Results are reported in Table 6."
        ]
    }
}