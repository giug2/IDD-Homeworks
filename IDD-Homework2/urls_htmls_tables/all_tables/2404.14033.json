{
    "PAPER'S NUMBER OF TABLES": 3,
    "S2.T1": {
        "caption": "TABLE I: Comparing strategies for straggler mitigation in FL. \\faThumbsOUpSupported. \\faThumbsDownNo support.",
        "table": "",
        "footnotes": "\n\n\n\n\n\n\n\n\nStrategy\n\n\n\n\nAttribute\n\n\nType\n\n\n\nFaaS\n\nSupport\n\n\n\n\nAsynchronous\n\nAggregation\n\n\n\n\nPerformance-based\n\nSelection\n\n\n\n\nClient Efficiency\n\nScoring\n\n\n\n\nAdaptive\n\nPenalty\n\n\nFedProx [37]\nSynchronous\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\nFedNova [38]\nSynchronous\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\nSCAFFOLD [29]\nSynchronous\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\nTiFL [26]\nSynchronous\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsOUp\n\\faThumbsDown\n\\faThumbsOUp\n\nAergia [39]\nSynchronous\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\nOort [40]\nSynchronous\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsOUp\n\\faThumbsDown\n\\faThumbsDown\n\nSAFA [30]\nSemi-asynchronous\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\nFedAT [41]\nSemi-asynchronous\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsOUp\n\\faThumbsDown\n\\faThumbsOUp\n\nFedAsync [42]\nAsynchronous\n\\faThumbsDown\n\\faThumbsOUp\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\nFedBuff [31]\nAsynchronous\n\\faThumbsDown\n\\faThumbsOUp\n\\faThumbsDown\n\\faThumbsDown\n\\faThumbsDown\n\nPisces [27]\nAsynchronous\n\\faThumbsDown\n\\faThumbsOUp\n\\faThumbsOUp\n\\faThumbsDown\n\\faThumbsOUp\n\nFedlesScan [8]\nSemi-asynchronous\n\\faThumbsOUp\n\\faThumbsDown\n\\faThumbsOUp\n\\faThumbsDown\n\\faThumbsOUp\n\nApodotiko (This work)\nAsynchronous\n\\faThumbsOUp\n\\faThumbsOUp\n\\faThumbsOUp\n\\faThumbsOUp\n\\faThumbsOUp\n\n\n",
        "references": [
            "Table I provides a comprehensive comparison between Apodotiko and the different strategies for straggler mitigation in FL. We differentiate these strategies based on five attributes: support for FaaS environments, asynchronous aggregation, performance-based selection, client-efficiency scoring, and adaptive penalty. FaaS support indicates compatibility with serverless environments. Asynchronous aggregation reflects the flexibility to separate client updates from training. Performance-based selection involves choosing clients based on their training duration. Client efficiency scoring accounts for hardware diversity during selection, while adaptive penalty reflects adjustments in client selection based on performance and availability over time. While FedProx, FedNova, SCAFFOLD, and Aergia primarily focus on optimizing the local training process and aggregation methods, they do not incorporate intelligent client selection to optimize round performance as done in Apodotiko. SAFA tracks the status of clients’ local models to ensure their synchronization with the global model but tends to overutilize clients and lacks suitability for FaaS environments. TiFL, FedAT, and FedlesScan group clients based on training duration into clusters, but they overlook the hardware and data heterogeneity during the client selection process and lack support for asynchronous aggregation. Although Oort considers data size and training duration in client selection, it overlooks the correlation between these factors and diverse hardware configurations, enforcing a strict penalty on slower clients. FedAsync and FedBuff focus on optimizing FL with asynchronous aggregation but adopt random client selection. In contrast, Pisces combines the methods from Oort and FedBuff, refining the scoring approach, yet it still overlooks clients’ efficiency during scoring (§III-C) and selection. Apodotiko overcomes these limitations by incorporating comprehensive scoring metrics that account for both hardware and data heterogeneity, ensuring intelligent client selection and efficient round performance."
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Comparing total training duration (min) across various FL strategies and datasets. The highlighted values represent the best-performing strategy for a particular dataset.",
        "table": "",
        "footnotes": "\n\n\n\n\n\n\n\n\nStrategy\n\n\n\n\nDataset\n\n\nMNIST (min)\nFEMNIST (min)\nShakespeare (min)\nSpeech (min)\n\n\n\nFedAvg [3]\n10.98\n(1.00x)\n22.44\n(1.00x)\n245.98\n(1.00x)\n49.78\n(1.00x)\n\nFedProx [37]\n15.03\n(0.73x)\n39.46\n(0.57x)\n273.58\n(0.90x)\n53.20\n(0.94x)\n\nFedLesScan [8]\n9.69\n(1.13x)\n25.88\n(0.87x)\n232.18\n(1.06x)\n26.59\n(1.87x)\n\nSCAFFOLD [29]\n14.31\n(0.77x)\n-\n252.07\n(0.98x)\n-\n\nApodotiko\nCR = 0.3\n11.83\n(0.93x)\n12.95\n(1.73x)\n34.98\n(7.03x)\n8.04\n(6.19x)\n\nCR = 0.6\n11.65\n(0.94x)\n18.28\n(1.23x)\n69.04\n(3.56x)\n12.18\n(4.09x)\n\nCR = 0.7\n12.21\n(0.90x)\n20.21\n(1.11x)\n51.28\n(4.80x)\n12.74\n(3.91x)\n\nCR = 0.8\n10.92\n(1.01x)\n22.72\n(0.99x)\n72.66\n(3.39x)\n16.42\n(3.03x)\n\n\n",
        "references": [
            "Table II compares the total training time for the different FL strategies across multiple datasets. In our experiments, we observe that Apodotiko consistently outperforms other training strategies, particularly with a CR value of 0.30.30.3. Table III compares the total training cost in USD for the different FL strategies and datasets. Although Apodotiko isn’t the most cost-effective strategy, it remains competitive with other methods. For instance, our strategy with a CR of 0.3 incurs a total training cost of 6.686.686.68 USD for the Shakespeare dataset and 2.722.722.72 USD for the Google Speech dataset. The increased costs can be attributed to the invocation of more clients, a consequence of the asynchronous nature of our strategy.",
            "Impact of different concurrencyRatios. Figures 6(a) and 6(b) show the effect of different CRs (§III-B) on Apodotiko for the Shakespeare and the Google Speech datasets respectively. Our experiments on both datasets demonstrate that Apodotiko with a CR of 0.3 exhibits the fastest convergence rate compared to other concurrency ratios. For the Shakespeare dataset, we observe a speedup of 1.341.341.34x with a CR of 0.30.30.3 compared to the ratio of 0.60.60.6. For the Speech dataset, this speedup factor further increases to 1.71.71.7x. This accelerated convergence is attributed to the controller’s ability to trigger model aggregation with only 30 clients, significantly reducing the time between model updates. Additionally, our client selection algorithm (§III-D) and stale weight aggregation function (§III-B) effectively identify and select high-quality clients, ensuring that the aggregated model does not diverge. Table II and III also highlight the performance/cost of our strategy with different CR values against other FL approaches."
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: Comparing total training cost (USD) across various FL strategies and datasets. The highlighted values represent the minimum costs for a particular dataset.",
        "table": "",
        "footnotes": "\n\n\n\n\n\n\n\n\nStrategy\n\n\n\n\nDataset\n\n\nMNIST (USD)\nFEMNIST (USD)\nShakespeare (USD)\nSpeech (USD)\n\n\n\nFedAvg [3]\n1.13\n2.74\n8.86\n2.14\n\nFedProx [37]\n1.90\n3.83\n10.63\n2.37\n\nFedLesScan [8]\n1.11\n3.68\n10.28\n1.85\n\nSCAFFOLD [29]\n1.52\n-\n8.41\n-\n\nApodotiko\nCR = 0.3\n11.97\n5.99\n6.68\n2.72\n\nCR = 0.6\n7.65\n9.05\n8.91\n4.05\n\nCR = 0.7\n7.35\n4.92\n9.47\n3.91\n\nCR = 0.8\n5.94\n9.71\n11.11\n3.14\n\n\n",
        "references": [
            "Table II compares the total training time for the different FL strategies across multiple datasets. In our experiments, we observe that Apodotiko consistently outperforms other training strategies, particularly with a CR value of 0.30.30.3. Table III compares the total training cost in USD for the different FL strategies and datasets. Although Apodotiko isn’t the most cost-effective strategy, it remains competitive with other methods. For instance, our strategy with a CR of 0.3 incurs a total training cost of 6.686.686.68 USD for the Shakespeare dataset and 2.722.722.72 USD for the Google Speech dataset. The increased costs can be attributed to the invocation of more clients, a consequence of the asynchronous nature of our strategy."
        ]
    }
}