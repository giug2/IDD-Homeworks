{
    "PAPER'S NUMBER OF TABLES": 6,
    "S2.T1": {
        "caption": "Table 1: The memory usage and the communication cost of the three variable types.",
        "table": "<table id=\"S2.T1.2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S2.T1.2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S2.T1.2.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"></th>\n<th id=\"S2.T1.2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Memory</th>\n<th id=\"S2.T1.2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Communication</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S2.T1.2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S2.T1.2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Additive Vectors</th>\n<td id=\"S2.T1.2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Low</td>\n<td id=\"S2.T1.2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Low</td>\n</tr>\n<tr id=\"S2.T1.2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S2.T1.2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">Multiplicative Vectors</th>\n<td id=\"S2.T1.2.1.3.2.2\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S2.T1.2.1.3.2.3\" class=\"ltx_td ltx_align_center\">Low</td>\n</tr>\n<tr id=\"S2.T1.2.1.4.3\" class=\"ltx_tr\">\n<th id=\"S2.T1.2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\">Multiplicative Matrices</th>\n<td id=\"S2.T1.2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">High</td>\n<td id=\"S2.T1.2.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">High</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 1 summarizes the memory usage and the communication cost of these three variable types. It is intuitive to freeze multiplicative matrices first, multiplicative vectors second, and additive vectors third. Moreover, prior knowledge on the target network, such as layer ambience [5], can be incorporated to further improve the effectiveness of PVT."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: The results of non-streaming Conformer on IID Librispeech. FProp refers to performing only forward passes.",
        "table": "<table id=\"S3.T2.2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.2.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" rowspan=\"2\"></th>\n<th id=\"S3.T2.2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T2.2.1.1.1.2.1\" class=\"ltx_text\">WERs</span></th>\n<th id=\"S3.T2.2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">Resource</th>\n</tr>\n<tr id=\"S3.T2.2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Peak Memory</th>\n<th id=\"S3.T2.2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">CtoS Comm.</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.2.1.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.2.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">FProp</th>\n<th id=\"S3.T2.2.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">-</th>\n<td id=\"S3.T2.2.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">761MB</td>\n<td id=\"S3.T2.2.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S3.T2.2.1.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.2.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">AVT</th>\n<th id=\"S3.T2.2.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">2.1/4.6/2.2/4.8</th>\n<td id=\"S3.T2.2.1.4.2.3\" class=\"ltx_td ltx_align_center\">1372MB</td>\n<td id=\"S3.T2.2.1.4.2.4\" class=\"ltx_td ltx_align_center\">452MB</td>\n</tr>\n<tr id=\"S3.T2.2.1.5.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.2.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\"><span id=\"S3.T2.2.1.5.3.1.1\" class=\"ltx_text ltx_font_bold\">PVT</span></th>\n<th id=\"S3.T2.2.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\"><span id=\"S3.T2.2.1.5.3.2.1\" class=\"ltx_text ltx_font_bold\">2.1/4.9/2.3/4.8</span></th>\n<td id=\"S3.T2.2.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.2.1.5.3.3.1\" class=\"ltx_text ltx_font_bold\">1074MB</span></td>\n<td id=\"S3.T2.2.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.2.1.5.3.4.1\" class=\"ltx_text ltx_font_bold\">46MB</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 2 summarizes the results of non-streaming Conformer on IID Librispeech. Compared with all-variable training (AVT), PVT can achieve similar WERs with much lower memory usage and CtoS communication cost. We observe that running forward passes alone requires 761MB, and AVT requires extra 611MB to allow running backward passes. In contrast, PVT only requires extra 313MB, which is 1.9×\\times lower than that of AVT. Moreover, PVT reduces the CtoS communication cost by 9.8×\\times."
        ]
    },
    "S3.T3": {
        "caption": "Table 3: The WERs of non-streaming Conformer on non-IID Librispeech.",
        "table": "<table id=\"S3.T3.2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.2.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt\"></th>\n<td id=\"S3.T3.2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">AVT</td>\n<td id=\"S3.T3.2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T3.2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">PVT</span></td>\n</tr>\n<tr id=\"S3.T3.2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T3.2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\">WER</th>\n<td id=\"S3.T3.2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">2.0/4.7/2.2/4.9</td>\n<td id=\"S3.T3.2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T3.2.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">2.1/4.8/2.2/5.0</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 3 summarizes the WERs of non-streaming Conformer on non-IID Librispeech. Even with non-IID data, PVT can still attain comparable WERs to AVT. The reduction in memory usage and CtoS communication cost is the same as the previous IID experiment and, hence, omitted in Table 3. These experiments show the versatility of PVT to work well with both IID and non-IID data."
        ]
    },
    "S3.T4": {
        "caption": "Table 4: The results of streaming Conformer on the multi-domain dataset. The WER is on the MF domain. FProp refers to performing only forward passes.",
        "table": "<table id=\"S3.T4.2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T4.2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T4.2.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" rowspan=\"2\"></th>\n<th id=\"S3.T4.2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T4.2.1.1.1.2.1\" class=\"ltx_text\">WER</span></th>\n<th id=\"S3.T4.2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">Resource</th>\n</tr>\n<tr id=\"S3.T4.2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T4.2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Peak Memory</th>\n<th id=\"S3.T4.2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">CtoS Comm.</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T4.2.1.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T4.2.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Before Refinement</th>\n<th id=\"S3.T4.2.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">6.9</th>\n<td id=\"S3.T4.2.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n<td id=\"S3.T4.2.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S3.T4.2.1.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T4.2.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">FProp</th>\n<th id=\"S3.T4.2.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">-</th>\n<td id=\"S3.T4.2.1.4.2.3\" class=\"ltx_td ltx_align_center\">836MB</td>\n<td id=\"S3.T4.2.1.4.2.4\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S3.T4.2.1.5.3\" class=\"ltx_tr\">\n<th id=\"S3.T4.2.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">AVT</th>\n<th id=\"S3.T4.2.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">4.5</th>\n<td id=\"S3.T4.2.1.5.3.3\" class=\"ltx_td ltx_align_center\">1606MB</td>\n<td id=\"S3.T4.2.1.5.3.4\" class=\"ltx_td ltx_align_center\">522MB</td>\n</tr>\n<tr id=\"S3.T4.2.1.6.4\" class=\"ltx_tr\">\n<th id=\"S3.T4.2.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\"><span id=\"S3.T4.2.1.6.4.1.1\" class=\"ltx_text ltx_font_bold\">PVT</span></th>\n<th id=\"S3.T4.2.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\"><span id=\"S3.T4.2.1.6.4.2.1\" class=\"ltx_text ltx_font_bold\">4.6</span></th>\n<td id=\"S3.T4.2.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T4.2.1.6.4.3.1\" class=\"ltx_text ltx_font_bold\">1448MB</span></td>\n<td id=\"S3.T4.2.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T4.2.1.6.4.4.1\" class=\"ltx_text ltx_font_bold\">0.9MB</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We observe that domain adaptation may allow training fewer variables than from-scratch training. In this experiment, only training biases (i.e., freezing all freezable variables) is enough for providing high accuracy. Table 4 summarizes the results of streaming Conformer on the multi-domain dataset. Compared to AVT, PVT can achieve similar WERs with 1.3×\\times reduction in extra memory usage on top of running forward passes and 593×\\times reduction in communication cost. This experiment demonstrates the effectiveness of PVT on domain adaptation and large-scale datasets."
        ]
    },
    "S3.T5": {
        "caption": "Table 5: The comparison among various numbers of local steps with non-streaming Conformer on IID Librispeech.",
        "table": "<table id=\"S3.T5.2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T5.2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T5.2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Number of Local Steps</th>\n<th id=\"S3.T5.2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WER</th>\n<th id=\"S3.T5.2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Number of Rounds</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T5.2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T5.2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">1</th>\n<td id=\"S3.T5.2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">2.2/5.5/2.4/5.4</td>\n<td id=\"S3.T5.2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">350K</td>\n</tr>\n<tr id=\"S3.T5.2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T5.2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">5</th>\n<td id=\"S3.T5.2.1.3.2.2\" class=\"ltx_td ltx_align_center\">2.1/4.9/2.2/4.9</td>\n<td id=\"S3.T5.2.1.3.2.3\" class=\"ltx_td ltx_align_center\">155K</td>\n</tr>\n<tr id=\"S3.T5.2.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T5.2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\">128</th>\n<td id=\"S3.T5.2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">2.0/4.8/2.2/4.6</td>\n<td id=\"S3.T5.2.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">15K</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 5 compares the WERs and the required numbers of rounds when various numbers of local training steps are used. We observe that using more local training steps improves WERs and speeds up convergence. Moreover, in this experiment, PVT allows as many as 128 local training steps and still provides converged results."
        ]
    },
    "S3.T6": {
        "caption": "Table 6: The comparison among various numbers of clients with non-streaming Conformer on IID Librispeech.",
        "table": "<table id=\"S3.T6.2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T6.2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T6.2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Number of Clients</th>\n<th id=\"S3.T6.2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WER</th>\n<th id=\"S3.T6.2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Number of Rounds</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T6.2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T6.2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">128</th>\n<td id=\"S3.T6.2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">2.2/5.5/2.4/5.4</td>\n<td id=\"S3.T6.2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">350K</td>\n</tr>\n<tr id=\"S3.T6.2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T6.2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">1024</th>\n<td id=\"S3.T6.2.1.3.2.2\" class=\"ltx_td ltx_align_center\">2.1/5.0/2.3/4.9</td>\n<td id=\"S3.T6.2.1.3.2.3\" class=\"ltx_td ltx_align_center\">205K</td>\n</tr>\n<tr id=\"S3.T6.2.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T6.2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">2048</th>\n<td id=\"S3.T6.2.1.4.3.2\" class=\"ltx_td ltx_align_center\">2.1/5.1/2.2/5.0</td>\n<td id=\"S3.T6.2.1.4.3.3\" class=\"ltx_td ltx_align_center\">90K</td>\n</tr>\n<tr id=\"S3.T6.2.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T6.2.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\">4096</th>\n<td id=\"S3.T6.2.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">2.1/5.1/2.2/5.0</td>\n<td id=\"S3.T6.2.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">60K</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 6 compares the WERs and the required numbers of rounds when various numbers of clients are used. Similar to numbers of local training steps, WERs and convergence speed improve as we use more clients. This study shows that the loss of WERs and convergence speed caused by freezing variables can be compensated by using more clients, which is a favorable property for large-scale federated learning."
        ]
    }
}