{
    "S5.T1": {
        "caption": "Table 1: The results of the VisDrone experiment, including benchmark results \n\u2217 results taken from Kiefer et al. [14].",
        "table": "<table id=\"S5.T1.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.2.3.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><span id=\"S5.T1.2.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Backbone</span></th>\n<td id=\"S5.T1.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.2.3.1.2.1\" class=\"ltx_text ltx_font_bold\">Architecture</span></td>\n<td id=\"S5.T1.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.2.3.1.3.1\" class=\"ltx_text ltx_font_bold\">Parameters</span></td>\n<td id=\"S5.T1.2.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.2.3.1.4.1\" class=\"ltx_text ltx_font_bold\">Data augmentation</span></td>\n<td id=\"S5.T1.2.3.1.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.2.3.1.5.1\" class=\"ltx_text ltx_font_bold\">mAP@50</span></td>\n</tr>\n<tr id=\"S5.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">ResNeXt-101 64x4d<sup id=\"S5.T1.1.1.1.1\" class=\"ltx_sup\">&#8727;</sup>\n</th>\n<td id=\"S5.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Faster R-CNN</td>\n<td id=\"S5.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r\">127M</td>\n<td id=\"S5.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r\">low</td>\n<td id=\"S5.T1.1.1.5\" class=\"ltx_td ltx_align_center\">2.4</td>\n</tr>\n<tr id=\"S5.T1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">CSP-Darknet53<sup id=\"S5.T1.2.2.1.1\" class=\"ltx_sup\">&#8727;</sup>\n</th>\n<td id=\"S5.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">YOLOv5-X</td>\n<td id=\"S5.T1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">86.7M</td>\n<td id=\"S5.T1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>\n<td id=\"S5.T1.2.2.5\" class=\"ltx_td ltx_align_center\">10.2</td>\n</tr>\n<tr id=\"S5.T1.2.4.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">Swin-S</th>\n<td id=\"S5.T1.2.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Faster R-CNN</td>\n<td id=\"S5.T1.2.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">66.1M</td>\n<td id=\"S5.T1.2.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">low</td>\n<td id=\"S5.T1.2.4.2.5\" class=\"ltx_td ltx_align_center\">7.8</td>\n</tr>\n<tr id=\"S5.T1.2.5.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">Swin-S</th>\n<td id=\"S5.T1.2.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Faster R-CNN</td>\n<td id=\"S5.T1.2.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">66.1M</td>\n<td id=\"S5.T1.2.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>\n<td id=\"S5.T1.2.5.3.5\" class=\"ltx_td ltx_align_center\">16.2</td>\n</tr>\n<tr id=\"S5.T1.2.6.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.6.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">Swin-L</th>\n<td id=\"S5.T1.2.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">DINO 5-scale</td>\n<td id=\"S5.T1.2.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">218M</td>\n<td id=\"S5.T1.2.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>\n<td id=\"S5.T1.2.6.4.5\" class=\"ltx_td ltx_align_center\">26.1</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Table 1 shows the results of the VisDrone experiment. The results demonstrate improvements to the benchmark performance both through applying the Transformer architecture as well as enhancing augmentations. The benchmark ResNeXt-101 in particular had resulted in low performance, potentially caused by the lack of data augmentations in the orginal setup. The YOLOv5 benchmark already achieved better results, leveraging strong augmentation methods and thus preventing overfitting on synthetic data through domain randomization, to some extend [14]. However, the Transformer architecture, by leveraging a combination of data augmentation to prevent overfitting and leaning into the shape bias to make effective use of the consistency in shape from synthetic to real data, achieves significantly higher results with a lower parameter count. Our experiment with a combination of Transformer backbone and little data augmentations, demonstrated that proper augmentation remains crucial for high detection performance. Lastly, the experiment with the high-capacity DINO architecture and Swin-L backbone shows that even with suboptimal synthetic training data the model is able to reach impressive performance on the real VisDrone data."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: The results of the RarePlanes experiment, including benchmark results \n\u2217 results taken from Shermeyer et al. [13].",
        "table": "<table id=\"S5.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><span id=\"S5.T2.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Backbone</span></th>\n<td id=\"S5.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">Architecture</span></td>\n<td id=\"S5.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.2.1.3.1\" class=\"ltx_text ltx_font_bold\">Parameters</span></td>\n<td id=\"S5.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">Data augmentation</span></td>\n<td id=\"S5.T2.1.2.1.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.2.1.5.1\" class=\"ltx_text ltx_font_bold\">mAP</span></td>\n</tr>\n<tr id=\"S5.T2.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">ResNet-50<sup id=\"S5.T2.1.1.1.1\" class=\"ltx_sup\">&#8727;</sup>\n</th>\n<td id=\"S5.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Faster R-CNN</td>\n<td id=\"S5.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r\">41.4M</td>\n<td id=\"S5.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r\">medium</td>\n<td id=\"S5.T2.1.1.5\" class=\"ltx_td ltx_align_center\">35.9</td>\n</tr>\n<tr id=\"S5.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">Swin-T</th>\n<td id=\"S5.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Faster R-CNN</td>\n<td id=\"S5.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">45.2M</td>\n<td id=\"S5.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">medium</td>\n<td id=\"S5.T2.1.3.2.5\" class=\"ltx_td ltx_align_center\">40.8</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Table 2 shows the results of the RarePlanes experiment. The results demonstrate a slight improvement to the baseline when using a Transformer backbone. As previously stated, a limited set of data augmentations was used for this experiment, thus we only evaluate the use of the Transformer backbone here. The Transformer backbone does show some improvement in mAP, but the performance gain is limited. The shape of an airplane is very distinctive, potentially working to the advantage of a Transformer backbone. However, the distinction between airplane classes is only based on size and therefore the shape bias does not offer as strong of an advantage here, leaving limited room for improvement by the Transformer backbone. Furthermore, even though the task seems relatively simple, the detection performance has been observed to be lowered predominantly due to the test dataset being tiled. This has resulted in a large number of planes for which just a small part of the wing or fuselage is visible. In such cases it is difficult to judge the actual size of the airplane, even for humans, and the coordinates of the bounding box corners are ambiguous due to the remainder of the plane not being visible. In addition to this, there is no occlusion or cloud cover in the real and the synthetic dataset, which are two other factors under which Transformers would be expected to perform relatively well."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: The results of the vehicle detection experiment. \n\u2217 result taken from Eker et al. [2]",
        "table": "<table id=\"S5.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Backbone</span></td>\n<td id=\"S5.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">Architecture</span></td>\n<td id=\"S5.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.2.1.3.1\" class=\"ltx_text ltx_font_bold\">Parameters</span></td>\n<td id=\"S5.T3.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">Data augmentation</span></td>\n<td id=\"S5.T3.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.2.1.5.1\" class=\"ltx_text ltx_font_bold\">mAP@50</span></td>\n<td id=\"S5.T3.1.2.1.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.2.1.6.1\" class=\"ltx_text ltx_font_bold\">mAP</span></td>\n</tr>\n<tr id=\"S5.T3.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">ResNet-101</td>\n<td id=\"S5.T3.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Faster R-CNN</td>\n<td id=\"S5.T3.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.4M</td>\n<td id=\"S5.T3.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>\n<td id=\"S5.T3.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">78.0</td>\n<td id=\"S5.T3.1.3.2.6\" class=\"ltx_td ltx_align_center\">55.0</td>\n</tr>\n<tr id=\"S5.T3.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">ResNeXt-101 64x4d</td>\n<td id=\"S5.T3.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Cascade R-CNN</td>\n<td id=\"S5.T3.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">127M</td>\n<td id=\"S5.T3.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>\n<td id=\"S5.T3.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">87.5</td>\n<td id=\"S5.T3.1.4.3.6\" class=\"ltx_td ltx_align_center\">66.0</td>\n</tr>\n<tr id=\"S5.T3.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Swin-S</td>\n<td id=\"S5.T3.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Faster R-CNN</td>\n<td id=\"S5.T3.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">66.1M</td>\n<td id=\"S5.T3.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>\n<td id=\"S5.T3.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\">94.8</td>\n<td id=\"S5.T3.1.5.4.6\" class=\"ltx_td ltx_align_center\">80.1</td>\n</tr>\n<tr id=\"S5.T3.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Swin-T<sup id=\"S5.T3.1.1.1.1\" class=\"ltx_sup\">&#8727;</sup>\n</td>\n<td id=\"S5.T3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Faster R-CNN</td>\n<td id=\"S5.T3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r\">45.2M</td>\n<td id=\"S5.T3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>\n<td id=\"S5.T3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r\">95.4</td>\n<td id=\"S5.T3.1.1.6\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Table 3 shows the results of the experiments with the in-house vehicle detection dataset. In this case, a strong improvement is demonstrated over the ResNet and ResNeXt architectures, reaching near-perfect object detection performance on the real dataset for a model trained solely with synthetic data. The high performance of the Transformer model could be the result of the strong emphasis on shape for classifying vehicles. This method focused strongly on shape and the images did not include depth or shadow, making them a particularly good fit for the Transfomer backbone and potentially harming their usefulness for a convolutional backbone. Even a larger convolutional model, the ResNeXt-101 64x4d, was not able to reach a similar performance to the Transformer, which was almost half its size in terms of parameter count."
        ]
    }
}