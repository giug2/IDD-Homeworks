{
    "id_table_1": {
        "caption": "Table 1:  Quantitative evaluation of MALADE.  Effect-based captures the classification between the presence and the absence of any ADE, while ADE-based represents the ability of MALADE to distinguish drugs with increased risk from those with decreased risk or no effect.",
        "table": "A1.T4.26.26",
        "footnotes": [
            "Note that in reality, separator tokens are added to distinguish messages, and the messages are tagged with metadata indicating the sender, among other things."
        ],
        "references": [
            "In this paper, we introduce MALADE  1 1 1 Pronounced like the French word  malade  meaning sick or ill. ( M ultiple  A gents powered by  L LMs for  ADE  Extraction),  the first effective multi-agent Retrieval-Augmented Generation  (RAG) system for ADE Extraction.  Our approach leverages two key techniques to address the above two limitations respectively:  (a) RAG, equipping an LLM with up-to-date knowledge by augmenting an input  query with relevant portions of text data, and prompting the LLM to generate responses  consistent with the augmented information  [ 15 ] ;  and (b) strategic orchestration of multiple LLM-based agents,  each responsible for a relatively smaller sub-task of the overall ADE Extraction task  [ 41 ] .  Specifically, our system has agents for these sub-tasks (see Figure  1 ):  (1) identifying representative drugs for each drug category from  a medical database ( e.g. , MIMIC-IV),  (2) gathering information on side effects of those drugs from external  text knowledge bases ( e.g. , FDA drug label database), and finally,  (3) composing final answers summarizing the effect of the drug category on an adverse event.  Each agent is assigned a specific sub-task and collaborates with others to accomplish the  the ultimate goal of ADE identification.  Furthermore, we enhance the reliability of our multi-agent system even further by pairing each agent with a critic agent,  whose role is to verify the behaviors and responses of its counterpart.",
            "The design of MALADE offers key features essential for  high-stakes applications like ADE identification:  (1) A structured format for drug-to-outcome associations, including scores  indicating the strength of the association and rarity of the adverse event;  this is important to ensure robust downstream processing of the extracted associations.  (2) Justifications for the extracted drug-outcome associations,  allowing human experts to understand and validate the associations.  This is possible due to the RAG component of the MALADE architecture,  which allows leveraging various external sources such as medical literature, drug labels,  FDA tools ( e.g. , OpenFDA drug information API), as well as common  clinical data sources such as OMOP or PCORI, and even specific EHR systems where available.  (3) Observability,  i.e. , complete, detailed logs of inter-agent dialogs and intermediate steps;  these are essential for debugging and auditing the systems behavior.  See Figure  1  for a real-world demonstration of MALADE.",
            "While todays LLMs exhibit impressive capabilities, they remain constrained by technical and practical limitations such as brittleness, non-determinism, limited context window, inference costs, and latency  [ 17 ] ,  with the implication that one cannot simply give high-level instructions to an LLM and expect it to accomplish a complex task.  Consequently, to best harness the capabilities of LLMs as components of a complex application, it is necessary to decompose the task into smaller sub-tasks and manage multiple LLM conversations, each with its own set of specifically-defined instructions, state, and data sources. This leads naturally to the notion of an  agent  as an LLM-powered entity responsible for a well-defined small sub-task.  In Section  3.1 , we introduce the key abstractions and  components needed for agent-oriented programming, and  Section  3.2  describes multi-agent orchestration.  Our implementation leverages the open-source multi-agent LLM framework   Langroid   [ 3 ] ,  which supports these abstractions and mechanisms.",
            "An LLM is essentially a text transformer;  i.e. , in response to some input text (known as a  prompt ), it produces a response. Free-form text responses are ideal when we want to generate a description, answer, or summary for human consumption, or even a question for another agent to answer.  However, in some cases, we would like the responses to trigger external  actions , such as an API call, code execution, or a database query. In such cases, we would instruct the LLM to produce a  structured  output, typically in JSON format, with various pre-specified fields, such as code, an SQL query, parameters of an API call, and so on. These structured responses have come to be known as  tools , and the LLM is said to  use  a tool when it produces a structured response corresponding to a specific tool. To elicit a tool response from an LLM, it needs to be instructed on the expected tool format and the conditions under which it should use the tool.  To actually use a tool emitted by an LLM, a  tool handler  method must be defined as well.  The tool handler for a given tool is triggered when it is recognized in the LLMs response.  See Appendix  A.1  for a description of the LLMs interaction with a database.",
            "In this section, we describe our RAG-based Multi-Agent architecture, MALADE, for identifying  associations between drug categories and outcomes.  We first give a high-level outline of the objectives of the key sub-tasks in Section  4.1 ,  and delve into their implementation details in Section  4.2  -  4.5 .  See Figure  1  for an illustrative depiction of the overall pipeline.",
            "CategoryAgent  is an Agent/Critic system that performs the final classification step;  its goal is to generate a label identifying whether a category of drugs increases or decreases the risk of a condition, or has no effect.  In addition to the label,  CategoryAgent  produces a number of additional outputs, all of which are combined into a JSON-structured string, including:  (a) a  confidence  score in [0,1], indicating the confidence in the assigned label,  (c)  strength of evidence,  one of none, weak, or strong, and  (d)  frequency of the effect,  one of none, rare, or common.  In this sense,  DrugAgent  serves as a function of the following type:   [string]    \\rightarrow   {increase,decrease,no-effect}   \\times   [0,1]   \\times   {non-   e,weak,strong}   \\times   {none,rare,,common} .  The structured output of  CategoryAgent  facilitates downstream post-processing to produce a final evaluation,  with no further LLM involvement (Section  5.1 ).",
            "This paper presents MALADE, the first LLM-based multi-agent architecture that is capable of producing a structured report with characterizations and scores  related to the risk of an adverse health outcome  H H H italic_H  from a drug category  C C C italic_C ,  based on FDA drug label data.  We evaluate our method against a widely used benchmark,  the OMOP Evaluation Ground Truth task  [ 19 ] , henceforth referred to as the OMOP ADE task (Section  5.1 ), to answer the following three research questions:   {adjustwidth} 1cm",
            "In the evaluations of MALADE, we consider two LLMs, GPT-4 Turbo and GPT-4o. For GPT-4o, we limit the number of rounds of feedback from Critics to 5, after which it is required to accept.  Figure  4  compares the ground truth labels of OMOP ADE task with ADE labels identified by MALADE (with GPT-4 Turbo).  Considering the uncertainty inherent in the label of certain (drug category, outcome) pairs  [ 19 ] , these indicate strong performance on the task.  See Figure  10  of Appendix  B  for results on GPT-4o.  We also present the confusion matrix of the MALADE labels in Figure  5 .",
            "Moreover, we report the performance of MALADE in terms of AUC and F1 metrics (see Table  1 ).  Recall that  CategoryAgent  outputs a confidence score ranging from 0 to 1 for its predicted labels, namely increase, no-effect, or decrease..  This score reflects the agents certainty regarding the accuracy of the predicted outcome.  For quantitative evaluation as in Table  1 , we transform these tripartite label-confidence scores into binary classification probabilities, suitable for effect-based or adverse drug event (ADE)-based analysis.  Converting the three-class labels to a binary format requires a clear method for correlating each confidence score with a probabilistic value for the respective binary classification task.",
            "The results in Table  1  indicate that  the confidence scores output by the model are well-calibrated.  We observe that MALADE performs well both at distinguishing ADEs from non-ADEs and at identifying the presence/absence of an effect in general.  We include ROC curves and sensitivity vs. specificity curves in Figure  11  and Figure  12  of Appendix  B , respectively. We conduct experiments with additional scoring functions, in particular, the models estimates of the  probabilities  that  C C C italic_C  will cause or prevent  H H H italic_H ; see Appendix  B.1 .",
            "The ground truth for the OMOP ADE task is shown in Figure  8 . As noted in Section  5.1 , while the OMOP ADE task permits only three output labels for the effect of a drug category on an outcome, some drug category, outcome pairs are considered uncertain (which we treat as a no-effect label which is not used in evaluation). In Figure  8  the No Effect cells considered reliable are shown in blue, while the uncertain no-effect cells are those in white. In particular, the cells in white are  not  used in evaluation ( i.e. , for AUC computation, confusion matrices, and F1 scores). The cells used for evaluation are shown in red, blue, and green.",
            "In this subsection, we illustrate that the postprocessing of labels in Section  5.1  significantly improves the accuracy of ADE identification by MALADE instantiated with GPT-4 Turbo.",
            "Results are obtained by the OMOP ADE task evaluation with the corresponding modified versions of MALADE, all of which were run with GPT-4 Turbo.  To alleviate the computational burden of ablations, when an ablated systems configuration is identical to MALADEs ( i.e. , Critics on all agents and RAG enabled) up to a given step of the pipeline, we retain the output originally produced by MALADE.  We address the effects of variance due to random sampling from the LLM in Appendix  E .  We maintain consistency with the evaluation metrics and output label post-processing as detailed in Section  5.1 , reporting ADE and effect-based AUC scores (with both the output confidence scores and probabilities) and ADE- and effect-based F1 scores.",
            "We proceed by selecting three representative cells from the OMOP table, restricting ourselves to the cells used for evaluation and, to ensure a well-defined ground truth label for each representative, to drug categories without subcategories.  Each representative corresponds to one of the three ground truth labels (increased risk, decreased risk, and no effect). We then run ten trials on each cell with ablated versions of MALADE (constructed as in Appendix  D ; however, we only consider enabling or disabling Critics on all agents, including  DrugFinder  here).  The results are shown in Figure  13 ; these experiments were run with GPT-4 Turbo.",
            "Now, to understand the significance of these effects, we will perform paired t-tests for each pair of ablated variants of MALADE, for each representative. The results for decrease are in Table  9 , results for no-effect are shown in Table  10 , and results for increase are shown in Table  11 . Overall, we have that the mean confidence in ADE for the representative for decrease is lowest (i.e. the confidence in decrease is highest) in the case with neither Critics nor RAG, and we have that confidence in ADE for the representative of no-effect is lower (and so confidence in no-effect is higher) in the case that we have neither Critics nor RAG as compared to the cases with both Critics and RAG and RAG alone and, in addition, that confidence in ADE is  increased  (with RAG alone as compared with Critics alone, all with p-values below 0.05 for each pair.",
            "Note that, while, as seen in Figure  13 , by far the largest absolute shift in confidence occurs between RAG alone and all others for the no-effect representative, the large variance observed in that case is responsible for the reduced significance."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Ablation results on MALADE.",
        "table": "A2.T6.1.1",
        "footnotes": [
            "Note that in reality, separator tokens are added to distinguish messages, and the messages are tagged with metadata indicating the sender, among other things."
        ],
        "references": [
            "While todays LLMs exhibit impressive capabilities, they remain constrained by technical and practical limitations such as brittleness, non-determinism, limited context window, inference costs, and latency  [ 17 ] ,  with the implication that one cannot simply give high-level instructions to an LLM and expect it to accomplish a complex task.  Consequently, to best harness the capabilities of LLMs as components of a complex application, it is necessary to decompose the task into smaller sub-tasks and manage multiple LLM conversations, each with its own set of specifically-defined instructions, state, and data sources. This leads naturally to the notion of an  agent  as an LLM-powered entity responsible for a well-defined small sub-task.  In Section  3.1 , we introduce the key abstractions and  components needed for agent-oriented programming, and  Section  3.2  describes multi-agent orchestration.  Our implementation leverages the open-source multi-agent LLM framework   Langroid   [ 3 ] ,  which supports these abstractions and mechanisms.",
            "Using an LLM in isolation has two major constraints: (a) the responses are confined to the knowledge from its pre-training, hence cannot answer questions specific to private/enterprise documents, or up-to-date information past its training cutoff date; and (b) there is no way to verify the validity of the generated answers.  RAG is the most popular technique to address both limitations by making LLMs generate responses based on specific documents or data and justify the answer by presenting source citations  [ 15 ] .  The basic idea of RAG is as follows: when a query  Q Q Q italic_Q  is made to an LLM-agent, a set of  k k k italic_k  documents (or portions thereof)   D = { d 1 , d 2 , ... , d k } D subscript d 1 subscript d 2 ... subscript d k D=\\{d_{1},d_{2},\\ldots,d_{k}\\} italic_D = { italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT }  most relevant to the query are  retrieved  from a document-store,  and the original query  Q Q Q italic_Q  is  augmented  with  D D D italic_D  to a new prompt of the form,  Given the passages below: [ d 1 subscript d 1 d_{1} italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ,  d 2 subscript d 2 d_{2} italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ...,  d k subscript d k d_{k} italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ], answer this question:  Q Q Q italic_Q  based ONLY on these passages,  and indicate which passages support your answer.  See Appendix  A.2  for more details on RAG.",
            "As in Figure  2 , the orchestration mechanism is encapsulated in a Task class that wraps an Agent,  and one initiates a task by invoking its  run  method which has type  signature  string    \\rightarrow   string , identical to the type signature  of an Agents own native response methods  (corresponding to the LLM, tool-handler, and human user).  The Task maintains a current pending message (CPM) to be acted on by one of the responders of the Task, which includes the agents own response methods as well as  run  methods of sub-tasks.  The  run  method executes a series of steps until a task termination condition is reached. In each step, a valid response to the CPM is sought by iterating over the responders, and  the CPM is updated with the response.  See Appendix  A.4  for more details.",
            "In this section, we describe our RAG-based Multi-Agent architecture, MALADE, for identifying  associations between drug categories and outcomes.  We first give a high-level outline of the objectives of the key sub-tasks in Section  4.1 ,  and delve into their implementation details in Section  4.2  -  4.5 .  See Figure  1  for an illustrative depiction of the overall pipeline.",
            "Each of  DrugFinder ,  DrugAgent , and  CategoryAgent  is coupled with a Critic agent, which provides feedback on the primary agents output.  The primary agent then regenerates its output based on this feedback.  This Agent-Critic interaction continues until the Critic approves the agents response.  This design pattern significantly enhances the reliability of our system, as detailed further in Section  4.2 .",
            "How effectively does MALADE identify ADEs? (Section  5.2 )",
            "The results in Table  1  indicate that  the confidence scores output by the model are well-calibrated.  We observe that MALADE performs well both at distinguishing ADEs from non-ADEs and at identifying the presence/absence of an effect in general.  We include ROC curves and sensitivity vs. specificity curves in Figure  11  and Figure  12  of Appendix  B , respectively. We conduct experiments with additional scoring functions, in particular, the models estimates of the  probabilities  that  C C C italic_C  will cause or prevent  H H H italic_H ; see Appendix  B.1 .",
            "The Agent/Critic pattern, as discussed in Section  4 , is essential to the design of our system, and  serves as a powerful tool to enhance accuracy of an LLM-based system. Indeed, we have observed  several instances where the Critic corrected the parent Agents initial response,  as in the example mentioned in Section  4.2 .  However, we should note that if improperly configured, Critics can be harmful to  the performance of a system, both in terms of efficiency (since the repeated rounds of interaction  between the Agent and Critic can significantly increase token cost and runtime),  and reliability.  Since a Critic strictly enforces the provided guidelines,  incorrect guidelines can significantly harm performance; in some cases, excessively strict requirements can lead to infinite  loops, as the Agent and Critic will deadlock, neither able to satisfy the others requirements. We observed this  effect in early versions of MALADE; resolving the infinite loop issue required specific instructions listing  acceptable behavior. For instance, the Critic for  DrugAgent  needed to be explicitly told to accept statements  that the effect of a drug was uncertain due to a lack of information from the FDA labels; without this, infinite loops occurred in some drug-outcome combinations.",
            "Figure  2  shows a schematic of the task orchestration and delegation mechanism.",
            "We obtain an effect-based F1 score of 0.5294 without postprocessing, and 0.6087 with postprocessing.  We obtain an ADE-based F1 score of 0.4828 without postprocessing, and 0.5556 with postprocessing.  Figures  9  and  9  show the confusion matrices and predictions, respectively, of MALADE without postprocessing on GPT-4 Turbo (compared to the results in Section  5.2 )."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Percentage of agent responses corrected by the Critic.",
        "table": "A2.T7.1",
        "footnotes": [
            "Note that in reality, separator tokens are added to distinguish messages, and the messages are tagged with metadata indicating the sender, among other things."
        ],
        "references": [
            "Our proposed multi-agent architecture is agnostic to LLMs and data sources and is based  on design primitives intended to be universal building blocks for the orchestration of  multiple LLM-based agents (Section  3 ).  Hence, although MALADE is instantiated specifically for ADE identification,  our design methodology provides a generalizable blueprint for the  effective construction of multi-agent systems  for trustworthy medical knowledge synthesis and summarization with wide-ranging medical applications.",
            "While todays LLMs exhibit impressive capabilities, they remain constrained by technical and practical limitations such as brittleness, non-determinism, limited context window, inference costs, and latency  [ 17 ] ,  with the implication that one cannot simply give high-level instructions to an LLM and expect it to accomplish a complex task.  Consequently, to best harness the capabilities of LLMs as components of a complex application, it is necessary to decompose the task into smaller sub-tasks and manage multiple LLM conversations, each with its own set of specifically-defined instructions, state, and data sources. This leads naturally to the notion of an  agent  as an LLM-powered entity responsible for a well-defined small sub-task.  In Section  3.1 , we introduce the key abstractions and  components needed for agent-oriented programming, and  Section  3.2  describes multi-agent orchestration.  Our implementation leverages the open-source multi-agent LLM framework   Langroid   [ 3 ] ,  which supports these abstractions and mechanisms.",
            "Starting with the view of an LLM as a text transformer, it turns out that one can express the notion  of an agent, a tool, and other related concepts in terms of different function signatures,  as shown in Table  4  in Appendix  A.3 .",
            "This is another agent, paired with the one described above.  The Critics role is to validate the Agents reasoning steps and compliance with instructions, and provide  feedback to the Agent, which has been shown to improve the quality of LLM-generated outputs  [ 18 ] . The Agent iterates on its response based on this feedback, until the Critic is satisfied,  at which point the Agent signals completion and outputs the results (see Figure  3 ).",
            "Does Agent-Critic interaction, the core design pattern underlying MALADE, effectively enhance the reliability of the system? (Section  5.3 )",
            "The objective of OMOP ADE task is to assign one of three labels (increase, decrease, and no-effect) to each ( C C C italic_C ,  H H H italic_H ) pair, denoting whether  C C C italic_C  increases, decreases, or has no effect on the risk of  H H H italic_H , respectively.  There are 10 drug categories, some of which consist of a single drug, and 10 health outcomes (refer to Table  6  for the complete list).  Notably, while only three labels are valid outputs, not all ( C C C italic_C ,  H H H italic_H ) pairs are deemed sufficiently certain to be used in the evaluation.  The authors of OMOP ADE task mark certain pairs as  uncertain , to which we assign no-effect labels  with the special restriction that it should not be used in the evaluation. See Appendix  B.3  for further details.",
            "Our primary tool to analyze the effectiveness of the Agent-Critic pattern in MALADE is by ablation; in particular, we evaluate modified versions of MALADE, with and without feedback from the Critic components of  DrugAgent  and  CategoryAgent , with and without RAG for FDAHandler. The results are shown in Table  3 .",
            "We continue our investigation of the effectiveness of Agent-Critic interaction  by analyzing the frequency of Critic interventions to  rectify errors in Agent responses.  We identify corrections made by the Critic as examples in which the Agent and Critic engaged in more than one round of interaction. Results are shown in Table  3 .",
            "We find that the frequency with which the Critic catches a flaw varies significantly by Agent.   CategoryAgent  in particular incurs errors, necessitating the help of the Critic  and is generally corrected due to flaws in its medical reasoning, hence the Critic can directly prevent an incorrect response.  In the example of an actual run of MALADE(Figure  3 ), when asked about the effects of benzodiazepines on hip fracture,  CategoryAgent  first answered no-effect,  which was flagged as an error, as the sedative and muscle relaxant properties of benzodiazepines can increase the risk of falls and hence hip fractures, and as  DrugAgent  had noted that traumatic fractures were listed as an ADE in the drug labels. This feedback was forwarded to  CategoryAgent  and used to revise its answer to increase.  We find that  DrugAgent  generally produces reliable responses; however note that it occasionally makes no calls to the Critic, hence the Agent fails to validate its answer.  We observe that this can occur when the FDA drug label does not contain information related to the condition, and the Agent concludes that no validation is necessary.",
            "The principle of decomposition, mirroring the analogous principle of general software development, is the Unix philosophy as applied to multi-agent systems. Individual agents should be minimal, in that they should  do one thing and do it well. This decomposition principle is evident in the hierarchy of specialized agents in the design of MALADE ( i.e. ,  DrugFinder ,  DrugAgent , and  CategoryAgent  taking charge of each sub-task in Section  4.3  -  4.5 ).  In addition to promoting modularity and maintainability, decomposition also promotes reliability,  especially when combined with another key design principle,  LLM only when necessary.",
            "We proceed by selecting three representative cells from the OMOP table, restricting ourselves to the cells used for evaluation and, to ensure a well-defined ground truth label for each representative, to drug categories without subcategories.  Each representative corresponds to one of the three ground truth labels (increased risk, decreased risk, and no effect). We then run ten trials on each cell with ablated versions of MALADE (constructed as in Appendix  D ; however, we only consider enabling or disabling Critics on all agents, including  DrugFinder  here).  The results are shown in Figure  13 ; these experiments were run with GPT-4 Turbo.",
            "Note that, while, as seen in Figure  13 , by far the largest absolute shift in confidence occurs between RAG alone and all others for the no-effect representative, the large variance observed in that case is responsible for the reduced significance.",
            "As discussed in Section  5.3 , we consider RAG an essential component of a generalizable pharmacovigilance system. Hence, we focus on the results in the case with RAG, in which case these results suggest that the Critic components of MALADE improve reliability."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  From LLM to agent-oriented programming.   An LLM is essentially a message transformer. Adding tool (or function calling) capability to LLM requires a parser and a callback that performs arbitrary computation and returns a string.  The serialized instances of  T  correspond to a language  L L L italic_L ; as, by assumption, the LLM is capable of producing outputs in  L L L italic_L , this allows the LLM to express the intention to execute Callback with arbitrary instances of  T . Finally, we incorporate state by making Agent and Callback transducers, and have the general form in the last row.",
        "table": "A5.T9.12",
        "footnotes": [
            "Note that in reality, separator tokens are added to distinguish messages, and the messages are tagged with metadata indicating the sender, among other things."
        ],
        "references": [
            "Starting with the view of an LLM as a text transformer, it turns out that one can express the notion  of an agent, a tool, and other related concepts in terms of different function signatures,  as shown in Table  4  in Appendix  A.3 .",
            "As in Figure  2 , the orchestration mechanism is encapsulated in a Task class that wraps an Agent,  and one initiates a task by invoking its  run  method which has type  signature  string    \\rightarrow   string , identical to the type signature  of an Agents own native response methods  (corresponding to the LLM, tool-handler, and human user).  The Task maintains a current pending message (CPM) to be acted on by one of the responders of the Task, which includes the agents own response methods as well as  run  methods of sub-tasks.  The  run  method executes a series of steps until a task termination condition is reached. In each step, a valid response to the CPM is sought by iterating over the responders, and  the CPM is updated with the response.  See Appendix  A.4  for more details.",
            "In this section, we describe our RAG-based Multi-Agent architecture, MALADE, for identifying  associations between drug categories and outcomes.  We first give a high-level outline of the objectives of the key sub-tasks in Section  4.1 ,  and delve into their implementation details in Section  4.2  -  4.5 .  See Figure  1  for an illustrative depiction of the overall pipeline.",
            "Each of  DrugFinder ,  DrugAgent , and  CategoryAgent  is coupled with a Critic agent, which provides feedback on the primary agents output.  The primary agent then regenerates its output based on this feedback.  This Agent-Critic interaction continues until the Critic approves the agents response.  This design pattern significantly enhances the reliability of our system, as detailed further in Section  4.2 .",
            "What useful insights do the justifications by MALADE provide for further system improvement? (Section  5.4 )",
            "In the evaluations of MALADE, we consider two LLMs, GPT-4 Turbo and GPT-4o. For GPT-4o, we limit the number of rounds of feedback from Critics to 5, after which it is required to accept.  Figure  4  compares the ground truth labels of OMOP ADE task with ADE labels identified by MALADE (with GPT-4 Turbo).  Considering the uncertainty inherent in the label of certain (drug category, outcome) pairs  [ 19 ] , these indicate strong performance on the task.  See Figure  10  of Appendix  B  for results on GPT-4o.  We also present the confusion matrix of the MALADE labels in Figure  5 .",
            "The Agent/Critic pattern, as discussed in Section  4 , is essential to the design of our system, and  serves as a powerful tool to enhance accuracy of an LLM-based system. Indeed, we have observed  several instances where the Critic corrected the parent Agents initial response,  as in the example mentioned in Section  4.2 .  However, we should note that if improperly configured, Critics can be harmful to  the performance of a system, both in terms of efficiency (since the repeated rounds of interaction  between the Agent and Critic can significantly increase token cost and runtime),  and reliability.  Since a Critic strictly enforces the provided guidelines,  incorrect guidelines can significantly harm performance; in some cases, excessively strict requirements can lead to infinite  loops, as the Agent and Critic will deadlock, neither able to satisfy the others requirements. We observed this  effect in early versions of MALADE; resolving the infinite loop issue required specific instructions listing  acceptable behavior. For instance, the Critic for  DrugAgent  needed to be explicitly told to accept statements  that the effect of a drug was uncertain due to a lack of information from the FDA labels; without this, infinite loops occurred in some drug-outcome combinations.",
            "The principle of decomposition, mirroring the analogous principle of general software development, is the Unix philosophy as applied to multi-agent systems. Individual agents should be minimal, in that they should  do one thing and do it well. This decomposition principle is evident in the hierarchy of specialized agents in the design of MALADE ( i.e. ,  DrugFinder ,  DrugAgent , and  CategoryAgent  taking charge of each sub-task in Section  4.3  -  4.5 ).  In addition to promoting modularity and maintainability, decomposition also promotes reliability,  especially when combined with another key design principle,  LLM only when necessary.",
            "One key limitation of MALADE is that we rely entirely on textual FDA label data. In particular, if the information is not specifically included in the label data, MALADE cannot reliably identify the strength of any associations raised in the data. This resulted in several flawed predictions, as discussed in Section  5.4 .  To remedy this, we envision that extracting ADEs from EHR data is a promising direction for future work. As a first step, this would enable estimating the rarity of certain adverse events noted without further detail in the label data; in principle, a multi-agent system with access to EHR data may be able to identify ADEs directly. This would require the LLM to perform causal discovery from historical data (answering, Is the drug causing this event?).",
            "If we view an LLM as a function with signature  string    \\rightarrow   string ,  it is possible to express the concept of an agent, tool, and other constructs  in terms of derived function signatures, as shown in  Table  4 .",
            "As in Section  5.4 , we extract the justifications produced by  DrugFinder  in a run of MALADE for review by a clinician. The most common flaw in its reasoning is that  DrugFinder  frequently fails to recognize OMOP categories which consist of a single drug; beyond that, the agents justifications are generally correct, with only one significant other error occurring."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Comparison of confidence and probability based scoring for MALADE.  Effect-based captures the classification between the presence and the absence of any ADE, while ADE-based represents the ability of MALADE to distinguish drugs with increased risk from those with decreased risk or no effect.",
        "table": "A5.T10.12",
        "footnotes": [
            "Note that in reality, separator tokens are added to distinguish messages, and the messages are tagged with metadata indicating the sender, among other things."
        ],
        "references": [
            "In contrast to simpler systems that only produce a binary label indicating whether or not a drug category  C C C italic_C  is associated with an adverse event  E E E italic_E ,  our method produces distinct scores, including a confidence score that indicates how confident an LLM is about its label assignment.  These scores permit a rigorous quantitative evaluation against the well-established  Observational Medical Outcomes Partnership (OMOP) Ground Truth table of ADEs associated with common drug classes  [ 19 ] .  We achieve an Area Under the ROC Curve (AUC) of approximately 0.85 with GPT-4 Turbo, and 0.90 with GPT-4o (Section  5 ).  To the best of our knowledge, this is the best performance among the baselines, even though the direct comparison may be limited  2 2 2 Because none of the original clinical data-based analyses reached this high of accuracy, followup investigations have since argued that roughly this level is the best achievable by any method based on any sources for the OMOP task.  In 2016, Gruber  et al.   [ 6 ]  argued there were reproducible errors that could be blamed on the OMOP 2010 ground truth itself that could place a ceiling on the AUC achievable, and Hauben  et al.   [ 7 ]  more specifically argued that on the negative-labeled drug event pairs the error in the ground truth should be estimated at 17%.  There may be disagreement on varying strengths of different literature evidence, but  if their estimate is exactly right, it could place a ceiling as low as 0.83 on the AUC achievable. .",
            "In this section, we describe our RAG-based Multi-Agent architecture, MALADE, for identifying  associations between drug categories and outcomes.  We first give a high-level outline of the objectives of the key sub-tasks in Section  4.1 ,  and delve into their implementation details in Section  4.2  -  4.5 .  See Figure  1  for an illustrative depiction of the overall pipeline.",
            "CategoryAgent  is an Agent/Critic system that performs the final classification step;  its goal is to generate a label identifying whether a category of drugs increases or decreases the risk of a condition, or has no effect.  In addition to the label,  CategoryAgent  produces a number of additional outputs, all of which are combined into a JSON-structured string, including:  (a) a  confidence  score in [0,1], indicating the confidence in the assigned label,  (c)  strength of evidence,  one of none, weak, or strong, and  (d)  frequency of the effect,  one of none, rare, or common.  In this sense,  DrugAgent  serves as a function of the following type:   [string]    \\rightarrow   {increase,decrease,no-effect}   \\times   [0,1]   \\times   {non-   e,weak,strong}   \\times   {none,rare,,common} .  The structured output of  CategoryAgent  facilitates downstream post-processing to produce a final evaluation,  with no further LLM involvement (Section  5.1 ).",
            "This paper presents MALADE, the first LLM-based multi-agent architecture that is capable of producing a structured report with characterizations and scores  related to the risk of an adverse health outcome  H H H italic_H  from a drug category  C C C italic_C ,  based on FDA drug label data.  We evaluate our method against a widely used benchmark,  the OMOP Evaluation Ground Truth task  [ 19 ] , henceforth referred to as the OMOP ADE task (Section  5.1 ), to answer the following three research questions:   {adjustwidth} 1cm",
            "How effectively does MALADE identify ADEs? (Section  5.2 )",
            "Does Agent-Critic interaction, the core design pattern underlying MALADE, effectively enhance the reliability of the system? (Section  5.3 )",
            "What useful insights do the justifications by MALADE provide for further system improvement? (Section  5.4 )",
            "In the evaluations of MALADE, we consider two LLMs, GPT-4 Turbo and GPT-4o. For GPT-4o, we limit the number of rounds of feedback from Critics to 5, after which it is required to accept.  Figure  4  compares the ground truth labels of OMOP ADE task with ADE labels identified by MALADE (with GPT-4 Turbo).  Considering the uncertainty inherent in the label of certain (drug category, outcome) pairs  [ 19 ] , these indicate strong performance on the task.  See Figure  10  of Appendix  B  for results on GPT-4o.  We also present the confusion matrix of the MALADE labels in Figure  5 .",
            "While MALADE exhibits correct medical reasoning in general and hence achieves strong and reliable performance on ADE identification, we highlight that understanding its failures is essential for its further improvements, as discussed in Section  6 .  Extracts from the logs showing both correct and incorrect behavior by MALADE are in Appendix  C .  See Appendix  B.5  for a discussion of the justifications produced by  DrugFinder .",
            "The principle of decomposition, mirroring the analogous principle of general software development, is the Unix philosophy as applied to multi-agent systems. Individual agents should be minimal, in that they should  do one thing and do it well. This decomposition principle is evident in the hierarchy of specialized agents in the design of MALADE ( i.e. ,  DrugFinder ,  DrugAgent , and  CategoryAgent  taking charge of each sub-task in Section  4.3  -  4.5 ).  In addition to promoting modularity and maintainability, decomposition also promotes reliability,  especially when combined with another key design principle,  LLM only when necessary.",
            "One key limitation of MALADE is that we rely entirely on textual FDA label data. In particular, if the information is not specifically included in the label data, MALADE cannot reliably identify the strength of any associations raised in the data. This resulted in several flawed predictions, as discussed in Section  5.4 .  To remedy this, we envision that extracting ADEs from EHR data is a promising direction for future work. As a first step, this would enable estimating the rarity of certain adverse events noted without further detail in the label data; in principle, a multi-agent system with access to EHR data may be able to identify ADEs directly. This would require the LLM to perform causal discovery from historical data (answering, Is the drug causing this event?).",
            "In addition to the confidence-based scoring discussed in Section  5 , we consider probability-based scoring. In particular, we ask the model to specify the probability of an evant, specifically, the event that a drug in category  C C C italic_C  causes or prevents  H H H italic_H .",
            "As in Section  5 , we must derive confidence scores in ADE and effects from the output probability estimate; as the probability is already in terms of the probability of any effect, either harmful or beneficial, we use the probability directly for Effect AUC. For ADE AUC, we use the tranformation shown in Figure  7 .",
            "The results with probability-based scoring are shown in Table  5 , we observe that the probabilities are less reliable (unsurprising as the FDA label data does not always contain the information necessary for a reliable estimate).  See Appendix  D  for further discussion on the potential unreliability of the probability estimates.",
            "The ground truth for the OMOP ADE task is shown in Figure  8 . As noted in Section  5.1 , while the OMOP ADE task permits only three output labels for the effect of a drug category on an outcome, some drug category, outcome pairs are considered uncertain (which we treat as a no-effect label which is not used in evaluation). In Figure  8  the No Effect cells considered reliable are shown in blue, while the uncertain no-effect cells are those in white. In particular, the cells in white are  not  used in evaluation ( i.e. , for AUC computation, confusion matrices, and F1 scores). The cells used for evaluation are shown in red, blue, and green.",
            "In this subsection, we illustrate that the postprocessing of labels in Section  5.1  significantly improves the accuracy of ADE identification by MALADE instantiated with GPT-4 Turbo.",
            "We obtain an effect-based F1 score of 0.5294 without postprocessing, and 0.6087 with postprocessing.  We obtain an ADE-based F1 score of 0.4828 without postprocessing, and 0.5556 with postprocessing.  Figures  9  and  9  show the confusion matrices and predictions, respectively, of MALADE without postprocessing on GPT-4 Turbo (compared to the results in Section  5.2 ).",
            "As in Section  5.4 , we extract the justifications produced by  DrugFinder  in a run of MALADE for review by a clinician. The most common flaw in its reasoning is that  DrugFinder  frequently fails to recognize OMOP categories which consist of a single drug; beyond that, the agents justifications are generally correct, with only one significant other error occurring.",
            "Results are obtained by the OMOP ADE task evaluation with the corresponding modified versions of MALADE, all of which were run with GPT-4 Turbo.  To alleviate the computational burden of ablations, when an ablated systems configuration is identical to MALADEs ( i.e. , Critics on all agents and RAG enabled) up to a given step of the pipeline, we retain the output originally produced by MALADE.  We address the effects of variance due to random sampling from the LLM in Appendix  E .  We maintain consistency with the evaluation metrics and output label post-processing as detailed in Section  5.1 , reporting ADE and effect-based AUC scores (with both the output confidence scores and probabilities) and ADE- and effect-based F1 scores.",
            "As discussed in Section  5.3 , we consider RAG an essential component of a generalizable pharmacovigilance system. Hence, we focus on the results in the case with RAG, in which case these results suggest that the Critic components of MALADE improve reliability."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  OMOP drug categories and conditions. Parenthesized lists contain the subcategories of the broad drug category considered.",
        "table": "A5.T11.12",
        "footnotes": [
            "Note that in reality, separator tokens are added to distinguish messages, and the messages are tagged with metadata indicating the sender, among other things."
        ],
        "references": [
            "The objective of OMOP ADE task is to assign one of three labels (increase, decrease, and no-effect) to each ( C C C italic_C ,  H H H italic_H ) pair, denoting whether  C C C italic_C  increases, decreases, or has no effect on the risk of  H H H italic_H , respectively.  There are 10 drug categories, some of which consist of a single drug, and 10 health outcomes (refer to Table  6  for the complete list).  Notably, while only three labels are valid outputs, not all ( C C C italic_C ,  H H H italic_H ) pairs are deemed sufficiently certain to be used in the evaluation.  The authors of OMOP ADE task mark certain pairs as  uncertain , to which we assign no-effect labels  with the special restriction that it should not be used in the evaluation. See Appendix  B.3  for further details.",
            "While MALADE exhibits correct medical reasoning in general and hence achieves strong and reliable performance on ADE identification, we highlight that understanding its failures is essential for its further improvements, as discussed in Section  6 .  Extracts from the logs showing both correct and incorrect behavior by MALADE are in Appendix  C .  See Appendix  B.5  for a discussion of the justifications produced by  DrugFinder .",
            "RAG involves two phases: (a) a  ingestion  phase, where documents are sharded into reasonable-size chunks and ingested into a suitable type of document-store, and (b) a query phase, where top- k k k italic_k  document-chunks most  relevant  to the query are retrieved from the document-store, and the LLM is prompted to answer the query given these chunks (see Figure  6  for illustrative description).  Not surprisingly, the performance ( i.e. , precision and recall of answers) of a RAG system depends critically on how we define the relevance of document chunks to the query so that they will contain sufficient information for the LLM to compose a reasonable answer.  In this work, we use a combination of two standard notions of relevance: (a)  lexical  relevance, which is based on word overlap between the query and the document-chunk ( i.e. , keyword search), while (b)  semantic  relevance focuses on the similarity of meaning. The latter is based on the intuition that specially-trained embedding models  can encode text as fixed-length  embedding vectors  that roughly capture the meaning of the text,  and thus two texts are considered semantically similar if their embedding vectors are close as measured  by a metric such as cosine similarity  [ 20 ,  24 ,  4 ] .  During the ingestion phase, each document chunk is mapped to an embedding vector using an embedding model and this vector is indexed into a  vector database , along with a pointer to the chunk contents as metadata.  During the query phase, the same embedding model is used to map the query into a vector, and then the top- k k k italic_k  nearest-neighbors of this vector (based on cosine similarity) are found from the vector database, and their corresponding document chunks are retrieved."
        ]
    },
    "global_footnotes": [
        "Pronounced like the French word",
        "meaning sick or ill.",
        "Because none of the original clinical data-based analyses reached this high of accuracy, followup investigations have since argued that roughly this level is the best achievable by any method based on any sources for the OMOP task.  In 2016, Gruber",
        "",
        "argued there were reproducible errors that could be blamed on the OMOP 2010 ground truth itself that could place a ceiling on the AUC achievable, and Hauben",
        "",
        "more specifically argued that on the negative-labeled drug event pairs the error in the ground truth should be estimated at 17%.  There may be disagreement on varying strengths of different literature evidence, but  if their estimate is exactly right, it could place a ceiling as low as 0.83 on the AUC achievable.",
        "For any OMOP drug categories which contain multiple sub-categories, we execute the full process for each sub-category (identifying a set of representatives for each sub-category), merging the outputs of the classification agent, taking the highest risk indicated for any sub-category as the risk for the full category.",
        "We observe that GPT-4 Turbo tends to assign increase rather confidently even when the evidence is weak. To further enhance the reliability of the assigned labels, we take an additional postprocessing step; replacing",
        "predictions with no-effect. See Appendix",
        "for detailed discussions on label postprocessing.",
        "Note that in reality, separator tokens are added to distinguish messages, and the messages are tagged with metadata indicating the sender, among other things."
    ]
}