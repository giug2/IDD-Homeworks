{
    "id_table_1": {
        "caption": "",
        "table": "S4.Ex3",
        "footnotes": [],
        "references": [
            "The detailed proof is provided in Appendix  A . Theorem  1  shows that when the sketch size is insufficient to capture most of the spectral information, sketch-based linear bandit methods will suffer from linear regret. Furthermore, as illustrated in Figure  1 , we observe that an incorrect selection of the pre-set sketch size can significantly degrade performance.",
            "Algorithm  1  presents the pseudo-code of Dyadic Block Sketching. When a new row  x t subscript x t \\bm{x}_{t} bold_italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  is received, we first verify the maintenance of Invariant  2  (see Line  1 ). If the block count reaches its upper limit, the error from the streaming sketch becomes intolerable, necessitating the full preservation of the streaming rows information. Therefore, we execute a complete rank-1 update on the sketch matrix.",
            "In Lines  1    1 , we control the errors to ensure the maintenance of Invariant  3 . If the size of the active block exceeds the specified limit, we store the current blocks information and create a new block with double the previous length to prevent further errors.",
            "In Lines  1    1 , we update the active blocks information with  x t subscript x t \\bm{x}_{t} bold_italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT . During this process, we can query the sketch matrices  S B subscript S B \\bm{S}_{B} bold_italic_S start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT  and  M B subscript M B \\bm{M}_{B} bold_italic_M start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT  in the active block (details in Appendix  D ). Additionally, the shrinkage of the deterministic sketch provides us with the blocks current rank if the sketch size exceeds the blocks rank. We use the variable  r  a  n  k r a n k rank italic_r italic_a italic_n italic_k  to track this value. If the shrinking value is non-zero, we set  r  a  n  k r a n k rank italic_r italic_a italic_n italic_k  to  B  [ B ] . l  e  n  g  t  h formulae-sequence B delimited-[] B l e n g t h \\bm{\\mathcal{B}}[B].{length} bold_caligraphic_B [ italic_B ] . italic_l italic_e italic_n italic_g italic_t italic_h ; otherwise, we assign  r  a  n  k r a n k rank italic_r italic_a italic_n italic_k  to the blocks rank.",
            "In Lines  1    1 , we query the sketch of the entire stream. To retrieve the sketch matrix  S ( t ) superscript S t \\bm{S}^{(t)} bold_italic_S start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  and  M ( t ) superscript M t \\bm{M}^{(t)} bold_italic_M start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT , we combine them with the previous matrices as follows",
            "Experimental results in Figure  1  (in Section  2.2 ),  4(a)  show that DBSLinUCB using FD and RFD consistently outperforms the other sketch-based algorithms in terms of the regret of online learning. We observe that when  l = 300 l 300 l=300 italic_l = 300 , SOFUL and CBSCFD perform significantly worse than DBSLinUCB, with SOFUL exhibiting nearly linear regret. Moreover, DBSLinUCB achieves sublinear regret similar to OFUL by providing a constrained global error bound. Our experimental results confirm our analysis in Section  2.2 , indicating that for all existing sketch-based linear bandit algorithms, inappropriate sketch size selection can lead to the pitfall of linear regret.",
            "When   italic- \\epsilon italic_  is small, the block length grows exponentially. By Invariant  1 , the length of the last active block will be exactly greater than  k k k italic_k , i.e.,  2 B  1  l 0  k  2 B  l 0 superscript 2 B 1 subscript l 0 k superscript 2 B subscript l 0 2^{B-1}l_{0}\\leq k\\leq 2^{B}l_{0} 2 start_POSTSUPERSCRIPT italic_B - 1 end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  italic_k  2 start_POSTSUPERSCRIPT italic_B end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT .",
            "Combining all  B + 1 B 1 B+1 italic_B + 1  sketches, we use  S  = [ S 0  , S 1  , ... , S B  ] superscript S top superscript subscript S 0 top superscript subscript S 1 top ... superscript subscript S B top \\bm{S}^{\\top}=\\left[\\bm{S}_{0}^{\\top},\\bm{S}_{1}^{\\top},\\dots,\\bm{S}_{B}^{\\top% }\\right] bold_italic_S start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT = [ bold_italic_S start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , bold_italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , ... , bold_italic_S start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ]  to approximate  X X \\bm{X} bold_italic_X . By Lemma  1 , this provides the following error guarantee for the entire streaming matrix:",
            "In accordance with the decomposability of matrix sketches, as detailed in Lemma  1 , we have",
            "Therefore, the ratios of norms on the right-hand side of equation  15  can be bounded as",
            "Substituting equation  17  and Proposition  1  into equation  15  gives",
            "Sum up the bias error and the variance error and divide both sides of equation  11  by    ^ t     A ^ ( t ) subscript norm subscript ^  t subscript   superscript ^ A t \\left\\|\\hat{\\bm{\\theta}}_{t}-\\bm{\\theta}_{\\star}\\right\\|_{\\hat{\\bm{A}}^{(t)}}  over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - bold_italic_ start_POSTSUBSCRIPT  end_POSTSUBSCRIPT  start_POSTSUBSCRIPT over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  simultaneously, we have",
            "Now, we are prepared to establish the upper bound of regret. Utilizing equation  19  and Cauchy-Schwartz inequality, we derive the following bound",
            "Combining equation  21 , equation  20  and Proposition  2 , assume  L   L  L\\geq\\sqrt{\\lambda} italic_L  square-root start_ARG italic_ end_ARG , we have",
            "By Proposition  1 , we can bound the variance error term as follows",
            "which concludes the proof.  Next, we start to prove the regret. Similar to the case using FD, since the algorithm uses the principle of optimism in the face of uncertainty to select the arm, we can bound instantaneous regret by equation  19 . Utilizing equation  19  and Cauchy-Schwartz inequality, we derive the following bound",
            "Since  min  ( 1 , x )  2  ln  ( 1 + x ) 1 x 2 1 x \\min{(1,x)}\\leq 2\\ln{(1+x)} roman_min ( 1 , italic_x )  2 roman_ln ( 1 + italic_x )  for all  x  0 x 0 x\\geq 0 italic_x  0 , using equation  31 , we can derive the following bound"
        ]
    },
    "id_table_2": {
        "caption": "",
        "table": "S4.Ex4",
        "footnotes": [],
        "references": [
            "The remainder of this paper is structured as follows: Section  2  revisits matrix sketching methods in linear bandits and highlights the current pitfalls. Section  3  presents a novel multi-scale sketching method for achieving a constrained global error bound. Section  4  introduces a new framework for efficient sketch-based linear bandits. Section  5  provides a detailed report of the experimental results. Finally, Section  6  concludes the paper and offers a discussion. All proofs and additional algorithmic details are provided in the appendices.",
            "The computation in equation  2  requires    ( d 2 )  superscript d 2 \\Omega\\left(d^{2}\\right) roman_ ( italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  time. To improve efficiency, sketch-based methods replace  ( A ( t ) )  1 superscript superscript A t 1 \\left({\\bm{A}}^{(t)}\\right)^{-1} ( bold_italic_A start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT  with  ( A ^ ( t ) )  1 superscript superscript ^ A t 1 \\left(\\hat{\\bm{A}}^{(t)}\\right)^{-1} ( over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT . Notably,  ( A ^ ( t ) )  1 superscript superscript ^ A t 1 \\left(\\hat{\\bm{A}}^{(t)}\\right)^{-1} ( over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT  can be updated implicitly using the sketch matrix  S ( t ) superscript S t \\bm{S}^{(t)} bold_italic_S start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  and  M ( t ) superscript M t \\bm{M}^{(t)} bold_italic_M start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  in equation  4 . Since matrix-vector multiplications with  S ( t ) superscript S t \\bm{S}^{(t)} bold_italic_S start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  take  O  ( l  d ) O l d O(ld) italic_O ( italic_l italic_d )  time and matrix-matrix multiplications with  M ( t ) superscript M t \\bm{M}^{(t)} bold_italic_M start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  take  O  ( l 2 ) O superscript l 2 O\\left(l^{2}\\right) italic_O ( italic_l start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  time, the computation involving the inverse of the sketched covariance matrix is accelerated from    ( d 2 )  superscript d 2 \\Omega\\left(d^{2}\\right) roman_ ( italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  to  O  ( l  d + l 2 ) O l d superscript l 2 O\\left(ld+l^{2}\\right) italic_O ( italic_l italic_d + italic_l start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) .",
            "The high-level idea is illustrated in Figure  2 . We establish a logarithmic number of sketch sizes, each partitioning the stream into blocks. The sketch size of each subsequent block is double that of the previous one, thereby halving the maximum error caused by sketching. By maintaining a streaming sketch for each block, we can concatenate all the sketches to approximate the streaming matrix, with the error bounded by the decomposability property.",
            "We further define two states for the blocks: active and inactive. An active block receives updates, while an inactive block remains entirely fixed. As illustrated in Figure  2 , there is always exactly one active block in the stream. Additionally, three key invariants must be maintained:",
            "Algorithm  1  presents the pseudo-code of Dyadic Block Sketching. When a new row  x t subscript x t \\bm{x}_{t} bold_italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  is received, we first verify the maintenance of Invariant  2  (see Line  1 ). If the block count reaches its upper limit, the error from the streaming sketch becomes intolerable, necessitating the full preservation of the streaming rows information. Therefore, we execute a complete rank-1 update on the sketch matrix.",
            "This algorithm employs the FD sketch for each block in the Dyadic Block Sketching framework. Recall that with a given error parameter    \\eta italic_ , the FD sketch requires a space of  l  = O  ( 1 /  ) subscript l  O 1  \\ell_{\\eta}=O(1/\\eta) roman_l start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT = italic_O ( 1 / italic_ )  and processes updates at an amortized cost of    = O  ( d /  ) subscript   O d  \\mu_{\\eta}=O(d/\\eta) italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT = italic_O ( italic_d / italic_ ) . As outlined in Theorem  2 , we derive the following corollary:",
            "In this section, we introduce a novel framework for efficient sketch-based linear bandits, termed DBSLinUCB, which leverages Dyadic Block Sketching. As outlined in Section  2.2 , a key limitation of previous methods stems from their reliance on single-scale matrix sketching, resulting in a  space-bounded  linear bandit approach. The use of a fixed sketch size leads to uncontrollable spectral loss,   T subscript  T \\Delta_{T} roman_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , ultimately causing linear regret.",
            "The procedure, detailed in Algorithm  2 , builds on prior sketch-based algorithms but incorporates the Dyadic Block Sketching method to effectively manage the error in approximating the covariance matrix. At each round  t t t italic_t , we employ the sketch matrix  S ( t ) superscript S t \\bm{S}^{(t)} bold_italic_S start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  to approximate the covariance matrix, from which we derive the sketched regularized least squares estimator as follows",
            "Assume that      2  H subscript norm subscript   2 H \\|\\bm{\\theta}_{\\star}\\|_{2}\\leq H  bold_italic_ start_POSTSUBSCRIPT  end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  italic_H ,   x  2  L subscript norm x 2 L \\|\\bm{x}\\|_{2}\\leq L  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  italic_L , and  L   L  L\\geq\\sqrt{\\lambda} italic_L  square-root start_ARG italic_ end_ARG . Suppose that the noise is conditionally  R R R italic_R -subgaussian, where  R R R italic_R  is a fixed constant. The sketch size in the active block at round  t t t italic_t  is denoted as  l B t subscript l subscript B t l_{B_{t}} italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT . Given the error parameter   italic- \\epsilon italic_ , then with a probability of  1  1 T 1 1 T 1-\\frac{1}{T} 1 - divide start_ARG 1 end_ARG start_ARG italic_T end_ARG , the regret of Algorithm  2  utilizing  Sk = FD Sk FD \\textup{Sk}=\\textup{FD} Sk = FD  is",
            "Assume that      2  H subscript norm subscript   2 H \\|\\bm{\\theta}_{\\star}\\|_{2}\\leq H  bold_italic_ start_POSTSUBSCRIPT  end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  italic_H ,   x  2  L subscript norm x 2 L \\|\\bm{x}\\|_{2}\\leq L  bold_italic_x  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  italic_L , and  L   L  L\\geq\\sqrt{\\lambda} italic_L  square-root start_ARG italic_ end_ARG . Suppose that the noise is conditionally R-subgaussian, where  R R R italic_R  is a fixed constant. The sketch size in the active block at round  t t t italic_t  is denoted as  l B t subscript l subscript B t l_{B_{t}} italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT . Given the error parameter   italic- \\epsilon italic_ , then with a probability of  1  1 T 1 1 T 1-\\frac{1}{T} 1 - divide start_ARG 1 end_ARG start_ARG italic_T end_ARG , the regret of Algorithm  2  utilizing  Sk = RFD Sk RFD \\textup{Sk}=\\textup{RFD} Sk = RFD  is",
            "Experimental results in Figure  1  (in Section  2.2 ),  4(a)  show that DBSLinUCB using FD and RFD consistently outperforms the other sketch-based algorithms in terms of the regret of online learning. We observe that when  l = 300 l 300 l=300 italic_l = 300 , SOFUL and CBSCFD perform significantly worse than DBSLinUCB, with SOFUL exhibiting nearly linear regret. Moreover, DBSLinUCB achieves sublinear regret similar to OFUL by providing a constrained global error bound. Our experimental results confirm our analysis in Section  2.2 , indicating that for all existing sketch-based linear bandit algorithms, inappropriate sketch size selection can lead to the pitfall of linear regret.",
            "According to Algorithm  2 , the approximate covariance matrix is",
            "According to Lemma  2 , we finally bound the variance error term as follows",
            "Combining equation  21 , equation  20  and Proposition  2 , assume  L   L  L\\geq\\sqrt{\\lambda} italic_L  square-root start_ARG italic_ end_ARG , we have",
            "According to Theorem  2 , we can bound the spectral error by error   italic- \\epsilon italic_ , which is",
            "According to Theroem  2 , we can get",
            "Bring the above equation into equation  23 , since   i = 1 B t  i ( t ) =  i = 1 B t    i superscript subscript i 1 subscript B t superscript subscript  i t superscript subscript i 1 subscript B t subscript    i \\sum_{i=1}^{B_{t}}\\alpha_{i}^{(t)}=\\sum_{i=1}^{B_{t}}\\overline{\\sigma}_{i}  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT =  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT over  start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , we can bound the spectral norm of  D t subscript D t \\bm{D}_{t} bold_italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  as follows",
            "By Cauchy-Schwartz inequality and the triangle inequality, we can bound equation  22  by",
            "According to equation  27 , we have  | A ^ ( t ) |  | A ( t ) | superscript ^ A t superscript A t \\left|\\hat{\\bm{A}}^{(t)}\\right|\\geq\\left|\\bm{A}^{(t)}\\right| | over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT |  | bold_italic_A start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT | . For any  t  [ T ] t delimited-[] T t\\in[T] italic_t  [ italic_T ] , since the rank of  A ^ ( t ) superscript ^ A t \\hat{\\bm{A}}^{(t)} over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  is at most  2  l B t 2 subscript l subscript B t 2l_{B_{t}} 2 italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT , we can bound the determinant of  A ^ ( t ) superscript ^ A t \\hat{\\bm{A}}^{(t)} over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  as follows",
            "where the last step holds by equation  29  and  h T =  i = 1 B T    i   i = 1 B T l i     i 2  l B T subscript h T superscript subscript i 1 subscript B T subscript    i superscript subscript i 1 subscript B T  subscript l i subscript    i 2 subscript l subscript B T h_{T}=\\sum_{i=1}^{B_{T}}\\overline{\\sigma}_{i}-\\frac{\\sum_{i=1}^{B_{T}}l_{i}% \\cdot\\overline{\\sigma}_{i}}{2l_{B_{T}}} italic_h start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT =  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUPERSCRIPT over  start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - divide start_ARG  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  over  start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG 2 italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_ARG .",
            "According to Theorem  2 , we can bound the spectral error by error   italic- \\epsilon italic_ , which is"
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "A8.EGx1",
        "footnotes": [],
        "references": [
            "The remainder of this paper is structured as follows: Section  2  revisits matrix sketching methods in linear bandits and highlights the current pitfalls. Section  3  presents a novel multi-scale sketching method for achieving a constrained global error bound. Section  4  introduces a new framework for efficient sketch-based linear bandits. Section  5  provides a detailed report of the experimental results. Finally, Section  6  concludes the paper and offers a discussion. All proofs and additional algorithmic details are provided in the appendices.",
            "In Lines  1    1 , we control the errors to ensure the maintenance of Invariant  3 . If the size of the active block exceeds the specified limit, we store the current blocks information and create a new block with double the previous length to prevent further errors.",
            "The primary computational costs of the algorithm include calculating the SVD to obtain  S ( t ) superscript S t \\bm{S}^{(t)} bold_italic_S start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  and performing matrix multiplication to compute  M ( t ) superscript M t \\bm{M}^{(t)} bold_italic_M start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT , both of which cost  O  ( d  l 2 ) O d superscript l 2 O(dl^{2}) italic_O ( italic_d italic_l start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) , where  l l l italic_l  is the current sketch size. However, the amortized update cost can be effectively reduced from  O  ( d  l 2 ) O d superscript l 2 O(dl^{2}) italic_O ( italic_d italic_l start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  to  O  ( d  l ) O d l O(dl) italic_O ( italic_d italic_l )  either by doubling the space, as detailed in Algorithm  3  in Appendix  C , or by employing the Gu-Eisenstat procedure  (Gu & Eisenstat,  1993 ) .",
            "Figure  3  shows the spectral norm error   A t   A t  S t   S t  2 subscript norm superscript subscript A t top subscript A t superscript subscript S t top subscript S t 2 \\|\\bm{A}_{t}^{\\top}\\bm{A}_{t}-\\bm{S}_{t}^{\\top}\\bm{S}_{t}\\|_{2}  bold_italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT bold_italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - bold_italic_S start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT bold_italic_S start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  and its upper bound for matrix sketching, where  A t subscript A t \\bm{A}_{t} bold_italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  is the steaming matrix at round  t t t italic_t  and  S t subscript S t \\bm{S}_{t} bold_italic_S start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  is the skech matrix at round  t t t italic_t . We observe that Dyadic Block Sketching provides a constrained global error bound for matrix sketching. Compared with FD, the rate of error growth in Dyadic Block Sketching decreases over time, effectively limiting the linear growth of the spectral tail.",
            "According to Invariant  3 , each submatrix  X i subscript X i \\bm{X}_{i} bold_italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  in block  i i i italic_i  contains at least     l 0  italic- subscript l 0 \\lfloor\\epsilon l_{0}\\rfloor  italic_ italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT   rows. Since there are  T T T italic_T  rows available for allocation in the entire matrix, the maximum number of blocks is   T   l 0  T italic- subscript l 0 \\left\\lceil\\frac{T}{\\epsilon l_{0}}\\right\\rceil  divide start_ARG italic_T end_ARG start_ARG italic_ italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG  .",
            "By maintaining Invariant  3 , the size of the  i i i italic_i -th inactive block is bounded by  l 0   subscript l 0 italic- l_{0}\\epsilon italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_ . Additionally, the  i i i italic_i -th block employs a streaming matrix sketch with an error parameter of  1 2 i  l 0 1 superscript 2 i subscript l 0 \\frac{1}{2^{i}l_{0}} divide start_ARG 1 end_ARG start_ARG 2 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG , thereby ensuring that the maximum error introduced by a sketch at the  i i i italic_i -th block is at most   2 i italic- superscript 2 i \\frac{\\epsilon}{2^{i}} divide start_ARG italic_ end_ARG start_ARG 2 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG .",
            "The computational cost of FD and RFD, as detailed in Algorithm  4  and  5 , is primarily driven by the singular value decomposition (SVD) operations. At round  t t t italic_t , with  B t + 1 subscript B t 1 B_{t}+1 italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + 1  blocks, we denote  l i subscript l i l_{i} italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  as the sketch size for the  i i i italic_i -th block. It incurs an amortized time of  O  ( d  l B t 2 ) O d superscript subscript l subscript B t 2 O\\left(dl_{B_{t}}^{2}\\right) italic_O ( italic_d italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  due to standard SVD processes in the active block. Additionally, the operation to compute  M ( t ) superscript M t \\bm{M}^{(t)} bold_italic_M start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  via matrix multiplication and matrix inversion also requires  O  (  i = 0 B t  1 l i  l B t  d + (  i = 0 B t l i ) 3 ) = O  ( d  l B t 2 ) O superscript subscript i 0 subscript B t 1  subscript l i subscript l subscript B t d superscript superscript subscript i 0 subscript B t subscript l i 3 O d superscript subscript l subscript B t 2 O\\left(\\sum_{i=0}^{B_{t}-1}l_{i}\\cdot l_{B_{t}}\\cdot d+\\left(\\sum_{i=0}^{B_{t}% }l_{i}\\right)^{3}\\right)=O\\left(dl_{B_{t}}^{2}\\right) italic_O (  start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - 1 end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT  italic_d + (  start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) = italic_O ( italic_d italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) . We can enhance the efficiency of our Dyadic Block Sketching by doubling the sketch size, as detailed in Algorithm  3 .",
            "Bring the above equation into equation  23 , since   i = 1 B t  i ( t ) =  i = 1 B t    i superscript subscript i 1 subscript B t superscript subscript  i t superscript subscript i 1 subscript B t subscript    i \\sum_{i=1}^{B_{t}}\\alpha_{i}^{(t)}=\\sum_{i=1}^{B_{t}}\\overline{\\sigma}_{i}  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT =  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT over  start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , we can bound the spectral norm of  D t subscript D t \\bm{D}_{t} bold_italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  as follows",
            "Since  min  ( 1 , x )  2  ln  ( 1 + x ) 1 x 2 1 x \\min{(1,x)}\\leq 2\\ln{(1+x)} roman_min ( 1 , italic_x )  2 roman_ln ( 1 + italic_x )  for all  x  0 x 0 x\\geq 0 italic_x  0 , using equation  31 , we can derive the following bound",
            "We combine equation  30 , Theorem  6  and Lemma  3 . Assume  L   L  L\\geq\\sqrt{\\lambda} italic_L  square-root start_ARG italic_ end_ARG , we have"
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "A8.EGx2",
        "footnotes": [],
        "references": [
            "The remainder of this paper is structured as follows: Section  2  revisits matrix sketching methods in linear bandits and highlights the current pitfalls. Section  3  presents a novel multi-scale sketching method for achieving a constrained global error bound. Section  4  introduces a new framework for efficient sketch-based linear bandits. Section  5  provides a detailed report of the experimental results. Finally, Section  6  concludes the paper and offers a discussion. All proofs and additional algorithmic details are provided in the appendices.",
            "The computation in equation  2  requires    ( d 2 )  superscript d 2 \\Omega\\left(d^{2}\\right) roman_ ( italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  time. To improve efficiency, sketch-based methods replace  ( A ( t ) )  1 superscript superscript A t 1 \\left({\\bm{A}}^{(t)}\\right)^{-1} ( bold_italic_A start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT  with  ( A ^ ( t ) )  1 superscript superscript ^ A t 1 \\left(\\hat{\\bm{A}}^{(t)}\\right)^{-1} ( over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT . Notably,  ( A ^ ( t ) )  1 superscript superscript ^ A t 1 \\left(\\hat{\\bm{A}}^{(t)}\\right)^{-1} ( over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT  can be updated implicitly using the sketch matrix  S ( t ) superscript S t \\bm{S}^{(t)} bold_italic_S start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  and  M ( t ) superscript M t \\bm{M}^{(t)} bold_italic_M start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  in equation  4 . Since matrix-vector multiplications with  S ( t ) superscript S t \\bm{S}^{(t)} bold_italic_S start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  take  O  ( l  d ) O l d O(ld) italic_O ( italic_l italic_d )  time and matrix-matrix multiplications with  M ( t ) superscript M t \\bm{M}^{(t)} bold_italic_M start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  take  O  ( l 2 ) O superscript l 2 O\\left(l^{2}\\right) italic_O ( italic_l start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  time, the computation involving the inverse of the sketched covariance matrix is accelerated from    ( d 2 )  superscript d 2 \\Omega\\left(d^{2}\\right) roman_ ( italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  to  O  ( l  d + l 2 ) O l d superscript l 2 O\\left(ld+l^{2}\\right) italic_O ( italic_l italic_d + italic_l start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) .",
            "The updates to the sketched regularized least squares estimator and the calculations for the confidence ellipsoid can be efficiently completed in  O  ( d  l B t + l B t 2 ) O d subscript l subscript B t superscript subscript l subscript B t 2 O\\left(dl_{B_{t}}+l_{B_{t}}^{2}\\right) italic_O ( italic_d italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT + italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  time using the Woodbury identity as stated in equation  4 . This makes DBSLinUCB significantly more efficient than traditional linear bandit algorithms, which require    ( d 2 )  superscript d 2 \\Omega\\left(d^{2}\\right) roman_ ( italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  in both time and space.",
            "We explore the Frequent Directions (FD) (see Algorithm  4 ), a deterministic sketching method  (Liberty,  2013 ; Ghashami et al.,  2016 ) . FD uniquely maintains the invariant that the last row of the sketch matrix,  S S \\bm{S} bold_italic_S , is always zero. In each round, a new row  a t subscript a t \\bm{a}_{t} bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  is inserted into this last row of  S S \\bm{S} bold_italic_S , and the matrix undergoes singular value decomposition into  U    V  U  superscript V top \\bm{U\\Sigma V^{\\top}} bold_italic_U bold_ bold_italic_V start_POSTSUPERSCRIPT bold_ end_POSTSUPERSCRIPT . Subsequently,  S S \\bm{S} bold_italic_S  is updated to   l 2    I  V l   superscript subscript  l 2  I superscript subscript V l top \\sqrt{\\bm{\\Sigma}_{l}^{2}-\\sigma\\bm{I}}\\cdot\\bm{V}_{l}^{\\top} square-root start_ARG bold_ start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_ bold_italic_I end_ARG  bold_italic_V start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , where    \\sigma italic_  represents the square of the  l l l italic_l -th singular value. Given that the rows of  S S \\bm{S} bold_italic_S  are orthogonal,  M = ( S  S  +   I )  1 M superscript S superscript S top  I 1 \\bm{M}=(\\bm{S}\\bm{S}^{\\top}+\\lambda\\bm{I})^{-1} bold_italic_M = ( bold_italic_S bold_italic_S start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT + italic_ bold_italic_I ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT  remains a diagonal matrix, facilitating efficient maintenance. We integrate FD into DBSLinUCB and established the following regret bound:",
            "Experimental results in Figure  1  (in Section  2.2 ),  4(a)  show that DBSLinUCB using FD and RFD consistently outperforms the other sketch-based algorithms in terms of the regret of online learning. We observe that when  l = 300 l 300 l=300 italic_l = 300 , SOFUL and CBSCFD perform significantly worse than DBSLinUCB, with SOFUL exhibiting nearly linear regret. Moreover, DBSLinUCB achieves sublinear regret similar to OFUL by providing a constrained global error bound. Our experimental results confirm our analysis in Section  2.2 , indicating that for all existing sketch-based linear bandit algorithms, inappropriate sketch size selection can lead to the pitfall of linear regret.",
            "Figures  4(b)  and  4(c)  compare the online mistakes and running times of different algorithms. Our findings indicate that, for a given dataset, there exists an optimal sketch size (e.g.,  l = 200 l 200 l=200 italic_l = 200 ) that captures most of the spectral information of the original matrix, thereby accelerating the algorithm without significantly compromising performance. However, selecting this optimal sketch size for SOFUL is challenging due to the lack of prior knowledge about the data. When  l = 20 l 20 l=20 italic_l = 20  or  l = 100 l 100 l=100 italic_l = 100 , the regret of SOFUL is significantly worse than that of the non-sketched method, OFUL. In contrast, DBSLinUCB matches the performance of OFUL by adaptively adjusting the sketch size to the near-optimal value of  l = 200 l 200 l=200 italic_l = 200  while being significantly faster than OFUL.",
            "The computational cost of FD and RFD, as detailed in Algorithm  4  and  5 , is primarily driven by the singular value decomposition (SVD) operations. At round  t t t italic_t , with  B t + 1 subscript B t 1 B_{t}+1 italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + 1  blocks, we denote  l i subscript l i l_{i} italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  as the sketch size for the  i i i italic_i -th block. It incurs an amortized time of  O  ( d  l B t 2 ) O d superscript subscript l subscript B t 2 O\\left(dl_{B_{t}}^{2}\\right) italic_O ( italic_d italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  due to standard SVD processes in the active block. Additionally, the operation to compute  M ( t ) superscript M t \\bm{M}^{(t)} bold_italic_M start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  via matrix multiplication and matrix inversion also requires  O  (  i = 0 B t  1 l i  l B t  d + (  i = 0 B t l i ) 3 ) = O  ( d  l B t 2 ) O superscript subscript i 0 subscript B t 1  subscript l i subscript l subscript B t d superscript superscript subscript i 0 subscript B t subscript l i 3 O d superscript subscript l subscript B t 2 O\\left(\\sum_{i=0}^{B_{t}-1}l_{i}\\cdot l_{B_{t}}\\cdot d+\\left(\\sum_{i=0}^{B_{t}% }l_{i}\\right)^{3}\\right)=O\\left(dl_{B_{t}}^{2}\\right) italic_O (  start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - 1 end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT  italic_d + (  start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) = italic_O ( italic_d italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) . We can enhance the efficiency of our Dyadic Block Sketching by doubling the sketch size, as detailed in Algorithm  3 .",
            "The pseudo-code for deterministic matrix sketching methods is displayed in Algorithm  4  and Algorithm  5 . Note that these deterministic matrix sketching methods can be accelerated by doubling the sketch size. More details can be found in Appendix  C ."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "A8.EGx3",
        "footnotes": [],
        "references": [
            "The remainder of this paper is structured as follows: Section  2  revisits matrix sketching methods in linear bandits and highlights the current pitfalls. Section  3  presents a novel multi-scale sketching method for achieving a constrained global error bound. Section  4  introduces a new framework for efficient sketch-based linear bandits. Section  5  provides a detailed report of the experimental results. Finally, Section  6  concludes the paper and offers a discussion. All proofs and additional algorithmic details are provided in the appendices.",
            "Denote  k  subscript k  k_{\\star} italic_k start_POSTSUBSCRIPT  end_POSTSUBSCRIPT  as the minimizer of equation  5 . Ignoring logarithmic terms, we assume   T = T  subscript  T superscript T  \\Delta_{T}=T^{\\gamma} roman_ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = italic_T start_POSTSUPERSCRIPT italic_ end_POSTSUPERSCRIPT . When   > 1 3  1 3 \\gamma>\\frac{1}{3} italic_ > divide start_ARG 1 end_ARG start_ARG 3 end_ARG , the regret will exceed  O  ( T ) O T O(T) italic_O ( italic_T ) . More precisely, when the spectral tail   X ( T )  X [ k  ] ( T )  F 2 =   ( ( l  k  ) 2 3  T 1 3 ) superscript subscript norm superscript X T subscript superscript X T delimited-[] subscript k  F 2  superscript l subscript k  2 3 superscript T 1 3 \\left\\|\\bm{X}^{(T)}-\\bm{X}^{(T)}_{[k_{\\star}]}\\right\\|_{F}^{2}=\\Omega\\left((l-% k_{\\star})^{\\frac{2}{3}}T^{\\frac{1}{3}}\\right)  bold_italic_X start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT - bold_italic_X start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT [ italic_k start_POSTSUBSCRIPT  end_POSTSUBSCRIPT ] end_POSTSUBSCRIPT  start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = roman_ ( ( italic_l - italic_k start_POSTSUBSCRIPT  end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG 2 end_ARG start_ARG 3 end_ARG end_POSTSUPERSCRIPT italic_T start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 3 end_ARG end_POSTSUPERSCRIPT ) , the invalid linear regret will emerge.",
            "We employ the Robust Frequent Directions (RFD) sketch (see Algorithm  5 ), a sketching strategy designed to address the rank deficiency issue inherent in FD  (Luo et al.,  2019 ) . RFD reduces the approximation error of FD by maintaining a counter    \\alpha italic_ , which quantifies the spectral error. More precisely, RFD employs  S   S +   I superscript S top S  I \\bm{S}^{\\top}\\bm{S}+\\alpha\\bm{I} bold_italic_S start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT bold_italic_S + italic_ bold_italic_I  to approximate  A   A superscript A top A \\bm{A}^{\\top}\\bm{A} bold_italic_A start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT bold_italic_A . We integrate RFD into DBSLinUCB and established the following regret bound:",
            "The computational cost of FD and RFD, as detailed in Algorithm  4  and  5 , is primarily driven by the singular value decomposition (SVD) operations. At round  t t t italic_t , with  B t + 1 subscript B t 1 B_{t}+1 italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + 1  blocks, we denote  l i subscript l i l_{i} italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  as the sketch size for the  i i i italic_i -th block. It incurs an amortized time of  O  ( d  l B t 2 ) O d superscript subscript l subscript B t 2 O\\left(dl_{B_{t}}^{2}\\right) italic_O ( italic_d italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  due to standard SVD processes in the active block. Additionally, the operation to compute  M ( t ) superscript M t \\bm{M}^{(t)} bold_italic_M start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  via matrix multiplication and matrix inversion also requires  O  (  i = 0 B t  1 l i  l B t  d + (  i = 0 B t l i ) 3 ) = O  ( d  l B t 2 ) O superscript subscript i 0 subscript B t 1  subscript l i subscript l subscript B t d superscript superscript subscript i 0 subscript B t subscript l i 3 O d superscript subscript l subscript B t 2 O\\left(\\sum_{i=0}^{B_{t}-1}l_{i}\\cdot l_{B_{t}}\\cdot d+\\left(\\sum_{i=0}^{B_{t}% }l_{i}\\right)^{3}\\right)=O\\left(dl_{B_{t}}^{2}\\right) italic_O (  start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - 1 end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT  italic_d + (  start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) = italic_O ( italic_d italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) . We can enhance the efficiency of our Dyadic Block Sketching by doubling the sketch size, as detailed in Algorithm  3 .",
            "The pseudo-code for deterministic matrix sketching methods is displayed in Algorithm  4  and Algorithm  5 . Note that these deterministic matrix sketching methods can be accelerated by doubling the sketch size. More details can be found in Appendix  C .",
            "Therefore, the ratios of norms on the right-hand side of equation  15  can be bounded as",
            "Substituting equation  17  and Proposition  1  into equation  15  gives",
            "We further bound the terms in the above. In particular, we formulate   ^ T  (  ) subscript ^  T  \\hat{\\beta}_{T}(\\delta) over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_ )  by Theorem  5  as follows"
        ]
    },
    "id_table_6": {
        "caption": "",
        "table": "A5.E11",
        "footnotes": [],
        "references": [
            "The remainder of this paper is structured as follows: Section  2  revisits matrix sketching methods in linear bandits and highlights the current pitfalls. Section  3  presents a novel multi-scale sketching method for achieving a constrained global error bound. Section  4  introduces a new framework for efficient sketch-based linear bandits. Section  5  provides a detailed report of the experimental results. Finally, Section  6  concludes the paper and offers a discussion. All proofs and additional algorithmic details are provided in the appendices.",
            "Note that the accumulated shrinking value is upper-bounded by the spectral loss. According to the regret in equation  6 , we conclude that the regret upper bound is    ( T 2 )  superscript T 2 \\Omega\\left(T^{2}\\right) roman_ ( italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )  in expectation.",
            "We combine equation  30 , Theorem  6  and Lemma  3 . Assume  L   L  L\\geq\\sqrt{\\lambda} italic_L  square-root start_ARG italic_ end_ARG , we have"
        ]
    },
    "id_table_7": {
        "caption": "",
        "table": "A5.E12",
        "footnotes": [],
        "references": [
            "Since the inactive blocks remain fixed, we can store the combined result of the sketch matrix in the inactive blocks. In practice, we can avoid the looped calculation of equation  7  and perform the combination only with the active block.",
            "Substituting equation  17  and Proposition  1  into equation  15  gives",
            "According to equation  27 , we have  | A ^ ( t ) |  | A ( t ) | superscript ^ A t superscript A t \\left|\\hat{\\bm{A}}^{(t)}\\right|\\geq\\left|\\bm{A}^{(t)}\\right| | over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT |  | bold_italic_A start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT | . For any  t  [ T ] t delimited-[] T t\\in[T] italic_t  [ italic_T ] , since the rank of  A ^ ( t ) superscript ^ A t \\hat{\\bm{A}}^{(t)} over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  is at most  2  l B t 2 subscript l subscript B t 2l_{B_{t}} 2 italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT , we can bound the determinant of  A ^ ( t ) superscript ^ A t \\hat{\\bm{A}}^{(t)} over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  as follows"
        ]
    },
    "id_table_8": {
        "caption": "",
        "table": "A5.E14",
        "footnotes": [],
        "references": []
    },
    "id_table_9": {
        "caption": "",
        "table": "A5.E15",
        "footnotes": [],
        "references": [
            "Now, we are prepared to establish the upper bound of regret. Utilizing equation  19  and Cauchy-Schwartz inequality, we derive the following bound",
            "which concludes the proof.  Next, we start to prove the regret. Similar to the case using FD, since the algorithm uses the principle of optimism in the face of uncertainty to select the arm, we can bound instantaneous regret by equation  19 . Utilizing equation  19  and Cauchy-Schwartz inequality, we derive the following bound",
            "where the last step holds by equation  29  and  h T =  i = 1 B T    i   i = 1 B T l i     i 2  l B T subscript h T superscript subscript i 1 subscript B T subscript    i superscript subscript i 1 subscript B T  subscript l i subscript    i 2 subscript l subscript B T h_{T}=\\sum_{i=1}^{B_{T}}\\overline{\\sigma}_{i}-\\frac{\\sum_{i=1}^{B_{T}}l_{i}% \\cdot\\overline{\\sigma}_{i}}{2l_{B_{T}}} italic_h start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT =  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUPERSCRIPT over  start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - divide start_ARG  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  over  start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG 2 italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_ARG ."
        ]
    },
    "id_table_10": {
        "caption": "",
        "table": "A5.E16",
        "footnotes": [],
        "references": []
    },
    "id_table_11": {
        "caption": "",
        "table": "A5.E17",
        "footnotes": [],
        "references": [
            "Sum up the bias error and the variance error and divide both sides of equation  11  by    ^ t     A ^ ( t ) subscript norm subscript ^  t subscript   superscript ^ A t \\left\\|\\hat{\\bm{\\theta}}_{t}-\\bm{\\theta}_{\\star}\\right\\|_{\\hat{\\bm{A}}^{(t)}}  over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - bold_italic_ start_POSTSUBSCRIPT  end_POSTSUBSCRIPT  start_POSTSUBSCRIPT over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  simultaneously, we have"
        ]
    },
    "id_table_12": {
        "caption": "",
        "table": "A5.E18",
        "footnotes": [],
        "references": []
    },
    "id_table_13": {
        "caption": "",
        "table": "A5.Ex19",
        "footnotes": [],
        "references": []
    },
    "id_table_14": {
        "caption": "",
        "table": "A5.Ex20",
        "footnotes": [],
        "references": []
    },
    "id_table_15": {
        "caption": "",
        "table": "A5.Ex21",
        "footnotes": [],
        "references": [
            "Therefore, the ratios of norms on the right-hand side of equation  15  can be bounded as",
            "Substituting equation  17  and Proposition  1  into equation  15  gives"
        ]
    },
    "id_table_16": {
        "caption": "",
        "table": "A5.Ex22",
        "footnotes": [],
        "references": []
    },
    "id_table_17": {
        "caption": "",
        "table": "A5.Ex23",
        "footnotes": [],
        "references": [
            "Substituting equation  17  and Proposition  1  into equation  15  gives"
        ]
    },
    "id_table_18": {
        "caption": "",
        "table": "A5.E19",
        "footnotes": [],
        "references": []
    },
    "id_table_19": {
        "caption": "",
        "table": "A5.E20",
        "footnotes": [],
        "references": [
            "Now, we are prepared to establish the upper bound of regret. Utilizing equation  19  and Cauchy-Schwartz inequality, we derive the following bound",
            "which concludes the proof.  Next, we start to prove the regret. Similar to the case using FD, since the algorithm uses the principle of optimism in the face of uncertainty to select the arm, we can bound instantaneous regret by equation  19 . Utilizing equation  19  and Cauchy-Schwartz inequality, we derive the following bound"
        ]
    },
    "id_table_20": {
        "caption": "",
        "table": "A5.E21",
        "footnotes": [],
        "references": [
            "Combining equation  21 , equation  20  and Proposition  2 , assume  L   L  L\\geq\\sqrt{\\lambda} italic_L  square-root start_ARG italic_ end_ARG , we have"
        ]
    },
    "id_table_21": {
        "caption": "",
        "table": "A5.Ex24",
        "footnotes": [],
        "references": [
            "Combining equation  21 , equation  20  and Proposition  2 , assume  L   L  L\\geq\\sqrt{\\lambda} italic_L  square-root start_ARG italic_ end_ARG , we have"
        ]
    },
    "id_table_22": {
        "caption": "",
        "table": "A5.Ex25",
        "footnotes": [],
        "references": [
            "By Cauchy-Schwartz inequality and the triangle inequality, we can bound equation  22  by"
        ]
    },
    "id_table_23": {
        "caption": "",
        "table": "A5.Ex26",
        "footnotes": [],
        "references": [
            "Bring the above equation into equation  23 , since   i = 1 B t  i ( t ) =  i = 1 B t    i superscript subscript i 1 subscript B t superscript subscript  i t superscript subscript i 1 subscript B t subscript    i \\sum_{i=1}^{B_{t}}\\alpha_{i}^{(t)}=\\sum_{i=1}^{B_{t}}\\overline{\\sigma}_{i}  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT =  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT over  start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , we can bound the spectral norm of  D t subscript D t \\bm{D}_{t} bold_italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  as follows"
        ]
    },
    "id_table_24": {
        "caption": "",
        "table": "A8.EGx4",
        "footnotes": [],
        "references": []
    },
    "id_table_25": {
        "caption": "",
        "table": "A8.EGx5",
        "footnotes": [],
        "references": []
    },
    "id_table_26": {
        "caption": "",
        "table": "A6.E22",
        "footnotes": [],
        "references": []
    },
    "id_table_27": {
        "caption": "",
        "table": "A6.E23",
        "footnotes": [],
        "references": [
            "According to equation  27 , we have  | A ^ ( t ) |  | A ( t ) | superscript ^ A t superscript A t \\left|\\hat{\\bm{A}}^{(t)}\\right|\\geq\\left|\\bm{A}^{(t)}\\right| | over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT |  | bold_italic_A start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT | . For any  t  [ T ] t delimited-[] T t\\in[T] italic_t  [ italic_T ] , since the rank of  A ^ ( t ) superscript ^ A t \\hat{\\bm{A}}^{(t)} over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  is at most  2  l B t 2 subscript l subscript B t 2l_{B_{t}} 2 italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT , we can bound the determinant of  A ^ ( t ) superscript ^ A t \\hat{\\bm{A}}^{(t)} over^ start_ARG bold_italic_A end_ARG start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT  as follows"
        ]
    },
    "id_table_28": {
        "caption": "",
        "table": "A6.E24",
        "footnotes": [],
        "references": []
    },
    "id_table_29": {
        "caption": "",
        "table": "A6.E25",
        "footnotes": [],
        "references": [
            "where the last step holds by equation  29  and  h T =  i = 1 B T    i   i = 1 B T l i     i 2  l B T subscript h T superscript subscript i 1 subscript B T subscript    i superscript subscript i 1 subscript B T  subscript l i subscript    i 2 subscript l subscript B T h_{T}=\\sum_{i=1}^{B_{T}}\\overline{\\sigma}_{i}-\\frac{\\sum_{i=1}^{B_{T}}l_{i}% \\cdot\\overline{\\sigma}_{i}}{2l_{B_{T}}} italic_h start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT =  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUPERSCRIPT over  start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - divide start_ARG  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  over  start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG 2 italic_l start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_ARG ."
        ]
    },
    "id_table_30": {
        "caption": "",
        "table": "A6.E26",
        "footnotes": [],
        "references": [
            "We combine equation  30 , Theorem  6  and Lemma  3 . Assume  L   L  L\\geq\\sqrt{\\lambda} italic_L  square-root start_ARG italic_ end_ARG , we have"
        ]
    },
    "id_table_31": {
        "caption": "",
        "table": "A6.E27",
        "footnotes": [],
        "references": [
            "Since  min  ( 1 , x )  2  ln  ( 1 + x ) 1 x 2 1 x \\min{(1,x)}\\leq 2\\ln{(1+x)} roman_min ( 1 , italic_x )  2 roman_ln ( 1 + italic_x )  for all  x  0 x 0 x\\geq 0 italic_x  0 , using equation  31 , we can derive the following bound"
        ]
    },
    "id_table_32": {
        "caption": "",
        "table": "A6.E28",
        "footnotes": [],
        "references": []
    },
    "id_table_33": {
        "caption": "",
        "table": "A6.E29",
        "footnotes": [],
        "references": []
    },
    "id_table_34": {
        "caption": "",
        "table": "A6.Ex36",
        "footnotes": [],
        "references": []
    },
    "id_table_35": {
        "caption": "",
        "table": "A6.Ex37",
        "footnotes": [],
        "references": []
    },
    "id_table_36": {
        "caption": "",
        "table": "A6.Ex38",
        "footnotes": [],
        "references": []
    },
    "id_table_37": {
        "caption": "",
        "table": "A6.E30",
        "footnotes": [],
        "references": []
    },
    "id_table_38": {
        "caption": "",
        "table": "A6.Ex39",
        "footnotes": [],
        "references": []
    },
    "id_table_39": {
        "caption": "",
        "table": "A6.E31",
        "footnotes": [],
        "references": []
    },
    "id_table_40": {
        "caption": "",
        "table": "A6.Ex40",
        "footnotes": [],
        "references": []
    },
    "id_table_41": {
        "caption": "",
        "table": "A6.Ex41",
        "footnotes": [],
        "references": []
    },
    "id_table_42": {
        "caption": "",
        "table": "A6.Ex42",
        "footnotes": [],
        "references": []
    },
    "id_table_43": {
        "caption": "",
        "table": "A6.Ex43",
        "footnotes": [],
        "references": []
    },
    "id_table_44": {
        "caption": "",
        "table": "A7.E32",
        "footnotes": [],
        "references": []
    },
    "id_table_45": {
        "caption": "",
        "table": "A7.Ex45",
        "footnotes": [],
        "references": []
    },
    "id_table_46": {
        "caption": "",
        "table": "A7.Ex46",
        "footnotes": [],
        "references": []
    },
    "id_table_47": {
        "caption": "",
        "table": "A7.Ex47",
        "footnotes": [],
        "references": []
    },
    "id_table_48": {
        "caption": "",
        "table": "A7.Ex48",
        "footnotes": [],
        "references": []
    }
}