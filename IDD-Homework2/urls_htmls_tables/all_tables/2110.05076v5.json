{
    "S4.T1": {
        "caption": "Table 1: \nClassification accuracies with ResNet12 on miniImageNet, tieredImageNet, CIFARFS, and FC100 of ProtoNet, linear-evaluation-based methods [3], centering with L2subscriptğ¿2L_{2}-norm [24], and ours. The Baseline without linear-evaluation methods with accuracy greater than the lower 95%percent9595\\% confidence margin of the accuracy of ProtoNet and Baseline are in bold. Regarding to Baseline++, Baseline++ without linear-evaluation methods with accuracy greater than the lower 95%percent9595\\% confidence margin of the accuracy of ProtoNet and Baseline++ are in bold. All the methods are our reimplementation .",
        "table": null,
        "footnotes": [],
        "references": [
            "We present the experimental results of standard object recognition in Table 1 on the basis of backbones with ResNet12 for a comprehensive comparison. We show the result of backbones with ResNet18 in Table 3. We present the discussion on cross-dataset scenario and the result of the scenario in A.7.",
            "From Table 1, we can observe that the prototype classifier with L2subscriptğ¿2L_{2}-norm, EST+L2subscriptğ¿2L_{2}-norm, LDA+L2subscriptğ¿2L_{2}-norm performs comparably with ProtoNet and the linear-evaluation-based approach in all settings. Comparing the feature-transformation methods described in Section 3.4 with centering+L2subscriptğ¿2L_{2}-norm, centering+L2subscriptğ¿2L_{2}-norm can slightly improve the performance of the prototype classifier in several 111-shot settings . However, in 555-shot settings, the boost decreases and even performs worse than linear-evaluation methods, e.g. miniImageNet and tieredImageNet.",
            "Table 2 shows the performance of MetaOptNet [36], TapNet [17] and feature-transformation methods that performs comparable with ProtoNet or linear-evaluation-based methods in Table 1. We can observe that a prototype classifier can achieve comparable performance with current studies in most of the settings with the feature transformations. Moreover, we can further boost the performance of a prototype classifier by combining L2subscriptğ¿2L_{2}-norm and the methods to reduce the ratio of the within-class variance to the between-class variance, e.g. CIFAR-FS and FC100.",
            "We show in Table 3 the detailed performance results of standard object recognition in this section with 95%percent9595\\% confidence margin. The table shows the similar result with Table 1. We can observe that the prototype classifier with L2subscriptğ¿2L_{2}-norm, EST+L2subscriptğ¿2L_{2}-norm, LDA+L2subscriptğ¿2L_{2}-norm performs comparably with ProtoNet and the linear-evaluation-based approach in most of the settings."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: \nClassification accuracies with ResNet12 on miniImageNet, tieredImageNet, CIFARFS, and FC100 of methods in current studies and ours. The best performing methods and any other runs\nwithin 959595% confidence margin are in bold. Methods with â€  show the results of our reimplementation following Section 4.2",
        "table": null,
        "footnotes": [],
        "references": [
            "Table 2 shows the performance of MetaOptNet [36], TapNet [17] and feature-transformation methods that performs comparable with ProtoNet or linear-evaluation-based methods in Table 1. We can observe that a prototype classifier can achieve comparable performance with current studies in most of the settings with the feature transformations. Moreover, we can further boost the performance of a prototype classifier by combining L2subscriptğ¿2L_{2}-norm and the methods to reduce the ratio of the within-class variance to the between-class variance, e.g. CIFAR-FS and FC100."
        ]
    },
    "A1.T3": {
        "caption": "Table 3: \nClassification accuracies with ResNet18 on miniImageNet, tieredImageNet, CIFARFS, and FC100 of ProtoNet, linear-evaluation-based methods [3], centering with L2subscriptğ¿2L_{2}-norm [24], and ours. The Baseline without linear-evaluation methods with accuracy greater than the lower 95%percent9595\\% confidence margin of the accuracy of ProtoNet and Baseline are in bold. Regarding to Baseline++, Baseline++ without linear-evaluation methods with accuracy greater than the lower 95%percent9595\\% confidence margin of the accuracy of ProtoNet and Baseline++ are in bold.",
        "table": null,
        "footnotes": [],
        "references": [
            "We present the experimental results of standard object recognition in Table 1 on the basis of backbones with ResNet12 for a comprehensive comparison. We show the result of backbones with ResNet18 in Table 3. We present the discussion on cross-dataset scenario and the result of the scenario in A.7.",
            "We show in Table 3 the detailed performance results of standard object recognition in this section with 95%percent9595\\% confidence margin. The table shows the similar result with Table 1. We can observe that the prototype classifier with L2subscriptğ¿2L_{2}-norm, EST+L2subscriptğ¿2L_{2}-norm, LDA+L2subscriptğ¿2L_{2}-norm performs comparably with ProtoNet and the linear-evaluation-based approach in most of the settings."
        ]
    },
    "A1.T4": {
        "caption": "Table 4: \nClassification accuracies with ResNet12 and ResNet18 on cross-domain scenario (miniImageNet â†’â†’\\rightarrow CUB) of ProtoNet, linear-evaluation-based methods [3], centering with L2subscriptğ¿2L_{2}-norm [24], and ours. The Baseline without linear-evaluation methods with accuracy greater than the lower 95%percent9595\\% confidence margin of the accuracy of ProtoNet and Baseline are in bold. Regarding to Baseline++, Baseline++ without linear-evaluation methods with accuracy greater than the lower 95%percent9595\\% confidence margin of the accuracy of ProtoNet and Baseline++ are in bold.",
        "table": null,
        "footnotes": [],
        "references": [
            "We show in Table 4 the performance results of cross-dataset scenario in this section with 95%percent9595\\% confidence margin. From the table, we can observe that the prototype classifier with L2subscriptğ¿2L_{2}-norm, EST+L2subscriptğ¿2L_{2}-norm and LDA+L2subscriptğ¿2L_{2}-norm performs comparably with linear-evaluation-based methods.\nTherefore, our analysis results still hold on the cross-domain scenario."
        ]
    }
}