{
    "S3.T1": {
        "caption": "Table 1: Generation time and storage size for a dataset of 10.000 images. Comparison between various resolutions and render mode (path tracing compared to rasterization). Measured on a RTX2070 Super GPU and an i7-10700KF CPU at 3.80GHz.",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"6\"><span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Rendering 10.000 images</span></td>\n</tr>\n<tr id=\"S3.T1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Resolution</span></td>\n<td id=\"S3.T1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">\n<table id=\"S3.T1.1.2.2.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.2.2.2.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Path tracing</span></td>\n</tr>\n<tr id=\"S3.T1.1.2.2.2.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.2.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">500 samples</span></td>\n</tr>\n<tr id=\"S3.T1.1.2.2.2.1.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.2.1.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.2.1.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">time (hours)</span></td>\n</tr>\n</table>\n</td>\n<td id=\"S3.T1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">\n<table id=\"S3.T1.1.2.2.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.2.2.3.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Rasterization</span></td>\n</tr>\n<tr id=\"S3.T1.1.2.2.3.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.3.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">time (hours)</span></td>\n</tr>\n</table>\n</td>\n<td id=\"S3.T1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S3.T1.1.2.2.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.2.2.4.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.4.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Memory</span></td>\n</tr>\n<tr id=\"S3.T1.1.2.2.4.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.4.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.4.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">(GB)</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"S3.T1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.3.1\" class=\"ltx_td ltx_border_l ltx_border_r\"></td>\n<td id=\"S3.T1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_l\"><span id=\"S3.T1.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">DLSS</span></td>\n<td id=\"S3.T1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S3.T1.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:80%;text-decoration:line-through; text-decoration-color:;\">DLSS</span></td>\n<td id=\"S3.T1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_l\"><span id=\"S3.T1.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">DLSS</span></td>\n<td id=\"S3.T1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S3.T1.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:80%;text-decoration:line-through; text-decoration-color:;\">DLSS</span></td>\n<td id=\"S3.T1.1.3.3.6\" class=\"ltx_td ltx_border_r\"></td>\n</tr>\n<tr id=\"S3.T1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.4.1\" class=\"ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">1280 x 720</span></td>\n<td id=\"S3.T1.1.4.4.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">7.9</span></td>\n<td id=\"S3.T1.1.4.4.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">7.8</span></td>\n<td id=\"S3.T1.1.4.4.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">2.3</span></td>\n<td id=\"S3.T1.1.4.4.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">2.3</span></td>\n<td id=\"S3.T1.1.4.4.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">5.4</span></td>\n</tr>\n<tr id=\"S3.T1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.5.5.1\" class=\"ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.5.5.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">1920 x 1080</span></td>\n<td id=\"S3.T1.1.5.5.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.5.5.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">8.3</span></td>\n<td id=\"S3.T1.1.5.5.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.5.5.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">13.2</span></td>\n<td id=\"S3.T1.1.5.5.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.5.5.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">2.4</span></td>\n<td id=\"S3.T1.1.5.5.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.5.5.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">2.4</span></td>\n<td id=\"S3.T1.1.5.5.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.5.5.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">11.3</span></td>\n</tr>\n<tr id=\"S3.T1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.6.6.1\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.6.6.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">3840 x 2160</span></td>\n<td id=\"S3.T1.1.6.6.2\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.6.6.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">22.3</span></td>\n<td id=\"S3.T1.1.6.6.3\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">30.0</span></td>\n<td id=\"S3.T1.1.6.6.4\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.6.6.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">3.4</span></td>\n<td id=\"S3.T1.1.6.6.5\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.6.6.5.1\" class=\"ltx_text\" style=\"font-size:80%;\">3.6</span></td>\n<td id=\"S3.T1.1.6.6.6\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.6.6.6.1\" class=\"ltx_text\" style=\"font-size:80%;\">43.8</span></td>\n</tr>\n</tbody>\n</table>\n<table id=\"S3.T1.1.2.2.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.2.2.2.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Path tracing</span></td>\n</tr>\n<tr id=\"S3.T1.1.2.2.2.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.2.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">500 samples</span></td>\n</tr>\n<tr id=\"S3.T1.1.2.2.2.1.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.2.1.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.2.1.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">time (hours)</span></td>\n</tr>\n</table>\n<table id=\"S3.T1.1.2.2.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.2.2.3.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Rasterization</span></td>\n</tr>\n<tr id=\"S3.T1.1.2.2.3.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.3.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">time (hours)</span></td>\n</tr>\n</table>\n<table id=\"S3.T1.1.2.2.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.2.2.4.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.4.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Memory</span></td>\n</tr>\n<tr id=\"S3.T1.1.2.2.4.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.4.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.2.2.4.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">(GB)</span></td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "Table\u00a01 gives an overview of the rendering time compared to the resolution between path tracing (at 500 rays per pixel) and rasterization. All measurements were taken with the template scene of the CAD2Render repository on a RTX2070S GPU and an i7-10700KF CPU. Based on empirical observations, enabling the denoiser and rendering 1/101101/10 of the samples will introduce no noticeable artifacts or noise, allowing for an additional speedup factor of 10. However, further research is required to prove this does not impact the performance of the machine learning models."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Validation Results of the position estimation for Metal Plates on the ChArUco board.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">pos</span></th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Std Dev [mm]</span></th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">Max dev [mm]</span></th>\n<th id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">Min dev [mm]</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">x</span></td>\n<td id=\"S4.T2.1.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.91</span></td>\n<td id=\"S4.T2.1.2.1.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.2.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">7.50</span></td>\n<td id=\"S4.T2.1.2.1.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.2.1.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.040</span></td>\n</tr>\n<tr id=\"S4.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">y</span></td>\n<td id=\"S4.T2.1.3.2.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">1.37</span></td>\n<td id=\"S4.T2.1.3.2.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.3.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">9.92</span></td>\n<td id=\"S4.T2.1.3.2.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.3.2.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.002</span></td>\n</tr>\n<tr id=\"S4.T2.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">z</span></td>\n<td id=\"S4.T2.1.4.3.2\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">11.16</span></td>\n<td id=\"S4.T2.1.4.3.3\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.4.3.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">57.90</span></td>\n<td id=\"S4.T2.1.4.3.4\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.4.3.4.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.220</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Table 2 shows the statistical analysis of the combined results. It can be seen that the standard deviation in the Y-direction is slightly larger compared to the X-direction, which can be explained by the fact that the used camera sensor is not square and therefore there are more pixels in the Y-direction. This means that these pixels fall in the more heavily curved part of the lens, increasing the deviation.\nMore generally, it is shown that, provided good camera calibration, the models can be accurate to close to 1 mm in both X and Y directions, which will be more than good enough in most pick-and-place applications. The estimation in the Z-direction is large, however this is a classic issue with height estimations from 2D images that can be improved in the future with a multi-camera setup. \n\nRobustness against harsh light conditions \nTo demonstrate the robustness of the developed algorithms against harsh lighting conditions, a simple physical setup was conceived on which an object at a known location and orientation could be subjected to either high or low lighting conditions. A dataset was rendered following the method explained in 3.1.3, this time using a slightly larger metallic object. A simple method of counting the saturated pixels on the surface of the object under test gave an approximate value of light intensity. From Table 3, we can see that under all but the most harsh conditions, the XY-deviation, calculated as the Euclidean distance between the ground-truth and the estimated location, is low. It can be observed that when the light intensity reaches more than 70%, the deviation reaches around 1cm, which can be considered to be extreme."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Deviation of the estimated XY-location of an object under a wide range of light intensities.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Intensity (%)</span></th>\n<th id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">XY Deviation [cm]</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.2.1.1\" class=\"ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.000</span></td>\n<td id=\"S4.T3.1.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.276</span></td>\n</tr>\n<tr id=\"S4.T3.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.3.2.1\" class=\"ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">35.440</span></td>\n<td id=\"S4.T3.1.3.2.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.340</span></td>\n</tr>\n<tr id=\"S4.T3.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.4.3.1\" class=\"ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">44.090</span></td>\n<td id=\"S4.T3.1.4.3.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.742</span></td>\n</tr>\n<tr id=\"S4.T3.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.5.4.1\" class=\"ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.5.4.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">69.990</span></td>\n<td id=\"S4.T3.1.5.4.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.5.4.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.565</span></td>\n</tr>\n<tr id=\"S4.T3.1.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.6.5.1\" class=\"ltx_td ltx_align_right ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.6.5.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">73.170</span></td>\n<td id=\"S4.T3.1.6.5.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.6.5.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">1.460</span></td>\n</tr>\n<tr id=\"S4.T3.1.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.7.6.1\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.7.6.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">83.660</span></td>\n<td id=\"S4.T3.1.7.6.2\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.7.6.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">2.444</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Table 2 shows the statistical analysis of the combined results. It can be seen that the standard deviation in the Y-direction is slightly larger compared to the X-direction, which can be explained by the fact that the used camera sensor is not square and therefore there are more pixels in the Y-direction. This means that these pixels fall in the more heavily curved part of the lens, increasing the deviation.\nMore generally, it is shown that, provided good camera calibration, the models can be accurate to close to 1 mm in both X and Y directions, which will be more than good enough in most pick-and-place applications. The estimation in the Z-direction is large, however this is a classic issue with height estimations from 2D images that can be improved in the future with a multi-camera setup. \n\nRobustness against harsh light conditions \nTo demonstrate the robustness of the developed algorithms against harsh lighting conditions, a simple physical setup was conceived on which an object at a known location and orientation could be subjected to either high or low lighting conditions. A dataset was rendered following the method explained in 3.1.3, this time using a slightly larger metallic object. A simple method of counting the saturated pixels on the surface of the object under test gave an approximate value of light intensity. From Table 3, we can see that under all but the most harsh conditions, the XY-deviation, calculated as the Euclidean distance between the ground-truth and the estimated location, is low. It can be observed that when the light intensity reaches more than 70%, the deviation reaches around 1cm, which can be considered to be extreme."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Accuracy of the keypoint detection models for each tool trained on the synthetic data. Performance is measured in PCK0.1subscriptPCK0.1\\textrm{PCK}_{0.1} over the validation set of real images\u00a0[27].",
        "table": "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Tool</span></th>\n<th id=\"S4.T4.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><math id=\"S4.T4.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\textrm{PCK}_{0.1}\" display=\"inline\"><semantics id=\"S4.T4.1.1.1.m1.1a\"><msub id=\"S4.T4.1.1.1.m1.1.1\" xref=\"S4.T4.1.1.1.m1.1.1.cmml\"><mtext mathsize=\"80%\" id=\"S4.T4.1.1.1.m1.1.1.2\" xref=\"S4.T4.1.1.1.m1.1.1.2a.cmml\">PCK</mtext><mn mathsize=\"80%\" id=\"S4.T4.1.1.1.m1.1.1.3\" xref=\"S4.T4.1.1.1.m1.1.1.3.cmml\">0.1</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.1.1.1.m1.1b\"><apply id=\"S4.T4.1.1.1.m1.1.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T4.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T4.1.1.1.m1.1.1.2a.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.2\"><mtext mathsize=\"80%\" id=\"S4.T4.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.2\">PCK</mtext></ci><cn type=\"float\" id=\"S4.T4.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3\">0.1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.1.1.1.m1.1c\">\\textrm{PCK}_{0.1}</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Screwdriver</span></th>\n<td id=\"S4.T4.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S4.T4.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">86.1</span></td>\n</tr>\n<tr id=\"S4.T4.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r\"><span id=\"S4.T4.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Wrench</span></th>\n<td id=\"S4.T4.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S4.T4.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">88.9</span></td>\n</tr>\n<tr id=\"S4.T4.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r\"><span id=\"S4.T4.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Combination Wrench</span></th>\n<td id=\"S4.T4.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S4.T4.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">86.1</span></td>\n</tr>\n<tr id=\"S4.T4.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><span id=\"S4.T4.1.5.4.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Hammer</span></th>\n<td id=\"S4.T4.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\"><span id=\"S4.T4.1.5.4.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">84.4</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Validation Results \nTo measure the model\u2019s performance we use the Percentage of Correct Keypoints\u00a0(PCK)\u00a0[30] metric with an \u03b1\ud835\udefc\\alpha of 1.0. The results are shown in Table\u00a04. The models were trained on synthetic images, created randomly without taking domain knowledge into account. Yet, these models are able to detect keypoints in the unseen real images with good accuracy. This shows that the CAD2Render toolkit is able to create synthetic images that are suitable for this problem space and that images produced by the faster hybrid rendering mode can produce good models as well. Additionally, research has shown that models trained on images generated by CAD2Render perform better on this task than models trained on images generated by simple 2D image augmentations\u00a0[26]. This shows the benefit of using 3D information to generate training data."
        ]
    }
}