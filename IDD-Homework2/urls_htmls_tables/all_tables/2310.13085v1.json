{
    "S4.T1": {
        "caption": "TABLE I: The test accuracy (%) of unsupervised meta-learning for 5-way 1-shot (5W1S) and 20-way 1-shot (20W1S) classification using mini-Imagenet dataset. For MAML, different temperatures (denoted by T𝑇{T}) are applied in the meta-inner loop.",
        "table": null,
        "footnotes": [],
        "references": [
            "Selecting the most effective data augmentation is an essential part of our research for unsupervised learning. We experimented with different augmentation methods on a trial-and-error basis and found the SimCLR augmentation with an additional augmentation gave the best output for the mini-Imagenet dataset. This section lists the results from different augmentation methods in this research. We focus on the mini-Imagenet dataset for the augmentation part because the Omniglot dataset does not require heavy data augmentation. We also try to explain why our chosen augmentation works the best for our dataset. Table I lists the outputs from different augmentation methods using unsupervised learning. Note that all the outputs are obtained by re-implementing different methods using our own hyperparameters, which may provide different results than other literature.",
            "From Table I, we observe the outputs from unsupervised learning for various augmentation functions. Let us discuss the accuracy of MAML first. First of all, we use the traditional meta-learning where the temperature parameter in the meta-inner loop for the SoftMax activation function is 1. A temperature of 1 means basically no temperature parameter. For MAML, we discovered that using the optimal temperature in the inner loop increased the accuracy of all the augmentation functions. It is because, when the temperature is 1, the training classifier overfits a lot due to the query set not being very challenging for the support set. When we apply the temperature, the classifier becomes less confident of the classes and can learn more features because of the introduced uncertainty. First, we apply the auto-augment function for query sample generation, which achieved slightly higher accuracy than the SimCLR augmentation function in all cases. Our augmentation function achieved 33.8% and 13.65% accuracy, which is the highest of all. We introduce temperature parameters as 100 and 10 for 5-way and 20-way, respectively. All the classifier exhibits improved accuracy for the optimal temperature, and our proposed method obtained the highest accuracy. The temperature is a hyperparameter that shows different performances for different values. In Figure 2 we illustrated the output accuracy from different temperatures to select the optimal ones. As observed, temperature 100 and 10 provides the highest accuracy for 5-way and 20-way, respectively."
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: The test accuracy (%) of unsupervised meta-learning for 5W1S and 20W1S classification using Omniglot dataset.",
        "table": null,
        "footnotes": [],
        "references": [
            "We also present the outputs from the Omniglot dataset in Table II to show the domain adaptability of our proposed method. In Omniglot, the support samples are quite similar to the query samples. As a result, our experiment found that doing any hard augmentation on the samples hurts the performance. Therefore, we perform a minimum augmentation to keep the features intact and yet introduce some information in the augmented samples. Moreover, since the samples are grayscale, we could not follow the color distortion function from SimCLR. So, we only applied affine transformation within 30∘superscript3030^{\\circ} to obtain the best transformation. This transformation distorts the samples slightly but keeps the meaning intact. In the case of SimCLR, we only apply resized crop and Gaussian blur as the color distortions do not apply to this dataset. Proof of the effectiveness of our method can be found in the experimental outputs. In this case, the SimCLR augmentation achieved higher accuracy for both MAML and RN in all 5-way 1-shot and 5-way 20-shot classifications. Our proposed method achieves the highest accuracy in all comparisons."
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: The test accuracy (%) and drop of the proposed unsupervised meta-learning for n-way, 1-shot multi-query.",
        "table": null,
        "footnotes": [],
        "references": [
            "Our proposed method can be technically extended to an n-way 1-shot multi-query classification. Because we can generate different augmented samples in each run for multiple query generation. However, we found an accuracy drop in our proposed model when applied to multiple queries. We suspect it happens because the classifier gets overfit from multiple queries as they are not very visibly distinguishable. Table III represents outputs from MAML for multiple queries. The accuracy drop was significant in all 5-way 5-query and 20-way 5-query shot classifications. Therefore, we do not suggest using our method to n-query shot. One should rather apply 1-shot unsupervised learning and then transfer the learned parameters to supervised learning. We only applied a 5-way 5-query shot to RN and opted out 20-way 5-query shot because it requires substantial computational resources for a backbone of ResNet-18. We used a 12GB Nvidia 3080Ti GPU to train our MAML module. For the RN module, we used parallel computing on two 12GB Nvidia 3090Ti GPUs and Google Cloud Platform GPUs. In the Omniglot dataset, the accuracy drop for 5-way 5-shot and 20-way 5-shot were 3.68% and 0.73% for MAML and 3.87% and 5.71% for RN. For mini-Imagenet, the drops are 3.04% and 1.52% for MAML and 11% for RN (N.B. no experiments conducted for 20W1S5Q RN)."
        ]
    },
    "S4.T4": {
        "caption": "TABLE IV: The test accuracy (%) of the supervised meta-learning for the Omniglot dataset.",
        "table": null,
        "footnotes": [],
        "references": [
            "Table IV presents the accuracy for the original method and our proposed method for the Omniglot and mini-Imagenet datasets. We also present the outputs from the Baseline model to emphasize the effectiveness of MAML and RN. For Omniglot, our method achieves improved accuracy than the original method and proves its model-agnostic ability. In MAML, we observe significantly higher accuracy for 1-shot learning and slightly improved accuracy for 5-shot learning in both 5-way and 20-way setups. Our SSML MAML improves the accuracy of MAML further. In RN, the performance improvement is not as significant as in MAML, as the original RN already achieved very high accuracy. Nevertheless, we achieve 100% accuracy on 5W1S1Q, which improves from 99.38%. However, in both 5W5S5Q, both RN and SSML RN achieved 100% accuracy. We observe a tiny improvement for 20-way SSML MAML. In SSML RN, we observe a 4% improvement in accuracy in both 5W1S1Q and 5W5S5Q. All the outputs from MAML and RN are re-implemented in our code."
        ]
    },
    "S4.T5": {
        "caption": "TABLE V: Transferablity of SSML MAML for different datasets.",
        "table": null,
        "footnotes": [],
        "references": [
            "We initialize SSML MAML with miniImageNet representation and fine-tune on both datasets. The outputs are listed in Table V. In all cases, SSML MAML improves accuracy over MAML. The most significant improvement is for CIFAR-FS 5W1S1Q, which is 3.6%. This proves that the proposed method can also transfer the learned representations to different domains for improved accuracy."
        ]
    },
    "S6.T6": {
        "caption": "TABLE VI: Accuracy drop (%) of supervised meta-learning for the partially labeled mini-Imagenet training set.",
        "table": null,
        "footnotes": [],
        "references": [
            "Additionally, we highlight that our method can obtain high accuracy or less accuracy loss for partially labeled datasets (Table VI). We test our hypothesis on mini-Imagenet only because it contains 600 samples per class, whereas Omniglot only has 20 samples per class. We randomly select 50% (300) and 25% (150) training samples from the mini-Imagenet data and train our classifier to compare the proposed and original methods. This time we report the percentage accuracy drop from the main output (trained on 100% samples) to have a fair comparison between the original method and SSML. It is obtained as ((a​l​l​l​a​b​e​l​e​d​a​c​c​u​r​a​c​y−p​a​r​t​i​a​l​l​y​l​a​b​e​l​e​d​a​c​c​u​r​a​c​y)/a​l​l​l​a​b​e​l​e​d​a​c​c​u​r​a​c​y)×100%𝑎𝑙𝑙𝑙𝑎𝑏𝑒𝑙𝑒𝑑𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦𝑝𝑎𝑟𝑡𝑖𝑎𝑙𝑙𝑦𝑙𝑎𝑏𝑒𝑙𝑒𝑑𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦𝑎𝑙𝑙𝑙𝑎𝑏𝑒𝑙𝑒𝑑𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦percent100((all\\>labeled\\>accuracy-partially\\>labeled\\>accuracy)/all\\>labeled\\>accuracy)\\times 100\\%. In most outputs, our proposed method has less drop except for SSML RN with 50% and 25% labeled data for 5W5S5Q and 5W1S1Q, respectively. In MAML and SSML MAML, for 5W1S1Q, we have negative accuracy drop percentages. This is because the accuracy, in fact, increases when we train MAML with 50% data in this setup. We hypothesize this improvement is due to the episode generation with fewer samples in each class. Some research points out that having a large number of meta-training data can counter-intuitively hurt performance. Because of multiple possibilities for generating each episode, the probability of all the samples appearing in the episodes will be lower. For example, Triantafillou et al. [26] found that having a large meta-dataset hurts the accuracy of the mini-Imagenet dataset. Setlur et al. [6] showed that having a fixed support set and having less diversity can improve accuracy. This new research direction deals with the optimal number of samples in meta-training and a more effective way of generating the episodes. We aim to focus on this area in our future research."
        ]
    }
}