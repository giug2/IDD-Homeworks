{
    "PAPER'S NUMBER OF TABLES": 4,
    "S3.T1": {
        "caption": "Table 1: Comparison among diverse types of aggregation algorithms. “Complexity” represents the complexity to implement the algorithms (“H” represents high complexity, “M” represents medium complexity, and “L” represents low complexity). “Trust” represents whether the aggregation algorithms require that the data owners trust the centralized server. “Imbalance” represents whether the algorithms can address the unbalanced data. “High-latency” represents whether the algorithms can support the high-latency model or gradient data transfer. “Y” represents that the algorithms support the functionality while “N” represents that the algorithms do not support the functionality.",
        "table": "<table id=\"S3.T1.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Type</td>\n<td id=\"S3.T1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Complexity</td>\n<td id=\"S3.T1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Trust</td>\n<td id=\"S3.T1.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Imbalance</td>\n<td id=\"S3.T1.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">High-latency</td>\n</tr>\n<tr id=\"S3.T1.3.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.3.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Centralized</td>\n<td id=\"S3.T1.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L</td>\n<td id=\"S3.T1.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Y</td>\n<td id=\"S3.T1.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T1.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n</tr>\n<tr id=\"S3.T1.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Hierarchical</td>\n<td id=\"S3.T1.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">M</td>\n<td id=\"S3.T1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Y</td>\n<td id=\"S3.T1.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Y</td>\n<td id=\"S3.T1.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Y</td>\n</tr>\n<tr id=\"S3.T1.3.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.3.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Decentralized</td>\n<td id=\"S3.T1.3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">H</td>\n<td id=\"S3.T1.3.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T1.3.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T1.3.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">Y</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "With the horizontal FL and data parallelism, aggregation algorithms are used to aggregate the models or gradients generated from the forward and backward propagation in each computing resource. The aggregation algorithms can be either centralized, or hierarchical, and decentralized. The centralized aggregation algorithms generally rely on a centralized server, i.e., a parameter server, to synchronize or schedule the execution of distributed computing resources, while hierarchical aggregation algorithms rely on multiple parameter servers for the model aggregation.\nThe decentralized aggregation algorithms make each computing resource equally perform the calculation based on a predefined protocol, without relying on a centralized server. ",
                "Please refer to ",
                "Wang2021Guide ",
                " for the details of federated optimization. The characteristics are summarized in Table ",
                "1",
                ", which can be used to choose appropriate algorithms in a specific situation. "
            ]
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Comparison among aggregation algorithms. “Reg” represents regularization. Heterogeneity represents that the computing resources are heterogeneous. “Firness” represents that the data distribution among multiple users can be equally considered without the influence of unrelated factors. “Permutation” refers to the permutation of data processing nodes during the training process. “C-E” represents communication efficient. “S” represents that the algorithm supports the functionality, while “N” represents that the algorithm does not have support. ",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Algorithm</td>\n<td id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Reg</td>\n<td id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Fairness</td>\n<td id=\"S3.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Heterogeneity</td>\n<td id=\"S3.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Permutation</td>\n<td id=\"S3.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">C-E</td>\n</tr>\n<tr id=\"S3.T2.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedAvg</td>\n<td id=\"S3.T2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n</tr>\n<tr id=\"S3.T2.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedBCD</td>\n<td id=\"S3.T2.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">S</td>\n<td id=\"S3.T2.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">S</td>\n</tr>\n<tr id=\"S3.T2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">SAFL</td>\n<td id=\"S3.T2.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">S</td>\n<td id=\"S3.T2.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n</tr>\n<tr id=\"S3.T2.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedMGDA+</td>\n<td id=\"S3.T2.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">S</td>\n<td id=\"S3.T2.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">S</td>\n</tr>\n<tr id=\"S3.T2.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedProx</td>\n<td id=\"S3.T2.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">S</td>\n<td id=\"S3.T2.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">S</td>\n</tr>\n<tr id=\"S3.T2.1.7.7\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedMA</td>\n<td id=\"S3.T2.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">S</td>\n<td id=\"S3.T2.1.7.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">S</td>\n</tr>\n<tr id=\"S3.T2.1.8.8\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.8.8.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">SCAFFOLD</td>\n<td id=\"S3.T2.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.8.8.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">S</td>\n</tr>\n<tr id=\"S3.T2.1.9.9\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.9.9.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">FedAttOpt</td>\n<td id=\"S3.T2.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">N</td>\n<td id=\"S3.T2.1.9.9.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">S</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "where F𝐹F, D𝐷D, ℋℋ\\mathcal{H} are the same as those in Formula 1, while γ​(⋅)𝛾⋅\\gamma(\\cdot) denotes the regularizer and λ𝜆\\lambda is the hyper-parameter. The regularization is exploited to improve the generalization capacity of the trained machine learning model. As the fairness among multiple users is important for an FL system, the Stochastic Agnostic Federated Learning (SAFL) mohri2019agnostic  algorithm and the FedMGDA+ hu2020fedmgda  algorithm are proposed to achieve fairness during the training process of FL. The fairness represents that the data distribution among multiple users can be equally considered without the influence of unrelated factors.\nFairness may also refer to two other concepts: (1) A user gets a final model according to the contribution lyu2020towards ; and/or (2) Uniform accuracy distribution among all the distributed computing resources li2019fair , which are out of the scope of this paper.\nIn addition, while the computing resources may be heterogeneous, FedProx Li2020  is proposed to tackle the heterogeneity in an FL system. FedProx enables multiple iterations in each computing resource, while minimizing a cost function based on the local loss function and the global model. Furthermore, in order to address permutation of data processing nodes during the training process, Federated Matched Averaging (FedMA) Wang2020Federated  is proposed. FedMA exploits an existing approach, i.e., BBP-MAP yurochkin2019bayesian , to generate a matrix, in order to align the data processing nodes of the models from computing resources and the server. SCAFFOLD karimireddy2020scaffold  is proposed to reduce the communication rounds, using stateful variables in the distributed computing resources. Attention-augmented mechanism is exploited in Attentive Federated Aggregation (FedAttOpt) jiang2020decentralized  to aggregate the knowledge generated from each computing resource (client), based on the contribution of the model from each client.\nWhen the data distribution is heterogeneous among users, personalization remains an open problem. In order to address this problem, the model can be split into local layers and global layers, which has been proposed in adaptive personalized federated learning (APFL) deng2020adaptive , FedPer arivazhagan2019federated , and pFedMe dinh2020personalized . The local layers are trained with the decentralized data in each computing resource of users, while the global layers are trained in the computing resources of users and the server. However, it is difficult to choose a dataset and its partition among clients to measure the personalization brought by APFL or FedPer, so as to prove the improvement compared with FedAvg.\nThe attention-augmented mechanism helps reduce the communication rounds.\nIn addition, knowledge distillation can also be exploited to aggregate the models, while requiring that there is data in the centralized server He2020Group .\nAll these algorithms can handle non-IID data. A comparison among the aforementioned algorithms is proposed in Table 2."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Comparison among diverse frameworks. “Aggregation” represents the type of aggregation algorithms. “Textual” represents the textual UI, while “Web” represents Web portal.",
        "table": "<table id=\"S5.T3.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.3.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Framework</td>\n<td id=\"S5.T3.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Engine</td>\n<td id=\"S5.T3.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Aggregation</td>\n<td id=\"S5.T3.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">UI</td>\n<td id=\"S5.T3.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Parallelism</td>\n<td id=\"S5.T3.3.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Security</td>\n</tr>\n<tr id=\"S5.T3.3.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.3.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">PaddleFL</td>\n<td id=\"S5.T3.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Paddle</td>\n<td id=\"S5.T3.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Centralized</td>\n<td id=\"S5.T3.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">textual</td>\n<td id=\"S5.T3.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Data/Model/Pipeline</td>\n<td id=\"S5.T3.3.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">DP/HE</td>\n</tr>\n<tr id=\"S5.T3.3.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">TFF</td>\n<td id=\"S5.T3.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">TensorFlow</td>\n<td id=\"S5.T3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Centralized</td>\n<td id=\"S5.T3.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">textual</td>\n<td id=\"S5.T3.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Data/Model</td>\n<td id=\"S5.T3.3.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">DP/HE</td>\n</tr>\n<tr id=\"S5.T3.3.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T3.3.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FATE</td>\n<td id=\"S5.T3.3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">TensorFlow</td>\n<td id=\"S5.T3.3.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Centralized</td>\n<td id=\"S5.T3.3.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Web</td>\n<td id=\"S5.T3.3.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Data/Model</td>\n<td id=\"S5.T3.3.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">DP/HE</td>\n</tr>\n<tr id=\"S5.T3.3.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T3.3.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">PySyft</td>\n<td id=\"S5.T3.3.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">PyTorch</td>\n<td id=\"S5.T3.3.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">Centralized</td>\n<td id=\"S5.T3.3.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">textual</td>\n<td id=\"S5.T3.3.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">Data</td>\n<td id=\"S5.T3.3.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">DP/HE</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Diverse FL frameworks exist while each has its advantage. We summarize the characteristics of each framework in Table ",
                "3",
                ", so as to help select a proper framework for use. From the table, we can see that all the frameworks implement the centralized aggregation algorithms, while employing DP and HE for the data security. PaddleFL can exploit Paddle to realize data, model, and pipeline parallelism. FATE and TFF are based on Tensorflow as the engine, while FATE can provide Web portal UI, which is convenient for novices. PySyft is compatible with PyTorch, which can easily handle the PyTorch-based tasks, while PaddleFL is compatible with Paddle, which can easily deal with rich pre-trained models published in PaddleHub ",
                "PaddleHub ",
                ".",
                "Table ",
                "4",
                " represents the support of diverse types of FL in terms of data distribution. All the frameworks support horizontal FL, while vertical FL is supported by three frameworks except TFF. PySyft cannot directly support the vertical FL, while PyVertical ",
                "Romanini2021 ",
                ", which is built upon PySyft, can be used to support vertical FL with the compatibility of PyTorch models. The hybrid FL is only supported by Paddle and FATE. In addition, all the frameworks support the execution with GPU. In practice, although PaddleFL may correspond to slightly longer time, the accuracy of the trained model can be higher that of TFF and FATE, while PySyft may generate “out of memory” errors ",
                "Kholod2021 ",
                "."
            ]
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Comparison among diverse frameworks for the support of diverse FL types, e.g., horizontal FL, vertical FL, and hybrid FL, and GPU. ∥∥\\|✓∥∥\\| represents that the support is not realized by itself but a close one.",
        "table": "<table id=\"S5.T4.6\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.6.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.6.3.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\"></td>\n<td id=\"S5.T4.6.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">PaddleFL</td>\n<td id=\"S5.T4.6.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">TFF</td>\n<td id=\"S5.T4.6.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FATE</td>\n<td id=\"S5.T4.6.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">PySyft</td>\n</tr>\n<tr id=\"S5.T4.6.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.6.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"3\"><span id=\"S5.T4.6.4.2.1.1\" class=\"ltx_text\">Types</span></td>\n<td id=\"S5.T4.6.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Horizontal</td>\n<td id=\"S5.T4.6.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S5.T4.6.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S5.T4.6.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S5.T4.6.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✓</td>\n</tr>\n<tr id=\"S5.T4.6.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.6.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Vertical</td>\n<td id=\"S5.T4.6.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S5.T4.6.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✗</td>\n<td id=\"S5.T4.6.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S5.T4.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<math id=\"S5.T4.5.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\|\" display=\"inline\"><semantics id=\"S5.T4.5.1.1.m1.1a\"><mo id=\"S5.T4.5.1.1.m1.1.1\" xref=\"S5.T4.5.1.1.m1.1.1.cmml\">∥</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.5.1.1.m1.1b\"><ci id=\"S5.T4.5.1.1.m1.1.1.cmml\" xref=\"S5.T4.5.1.1.m1.1.1\">∥</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.5.1.1.m1.1c\">\\|</annotation></semantics></math>✓<math id=\"S5.T4.6.2.2.m2.1\" class=\"ltx_Math\" alttext=\"\\|\" display=\"inline\"><semantics id=\"S5.T4.6.2.2.m2.1a\"><mo id=\"S5.T4.6.2.2.m2.1.1\" xref=\"S5.T4.6.2.2.m2.1.1.cmml\">∥</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.6.2.2.m2.1b\"><ci id=\"S5.T4.6.2.2.m2.1.1.cmml\" xref=\"S5.T4.6.2.2.m2.1.1\">∥</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.6.2.2.m2.1c\">\\|</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S5.T4.6.5.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.6.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Hybrid</td>\n<td id=\"S5.T4.6.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S5.T4.6.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✗</td>\n<td id=\"S5.T4.6.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S5.T4.6.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">✗</td>\n</tr>\n<tr id=\"S5.T4.6.6.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.6.6.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">GPU</td>\n<td id=\"S5.T4.6.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S5.T4.6.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S5.T4.6.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">✓</td>\n<td id=\"S5.T4.6.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">✓</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Diverse FL frameworks exist while each has its advantage. We summarize the characteristics of each framework in Table ",
                "3",
                ", so as to help select a proper framework for use. From the table, we can see that all the frameworks implement the centralized aggregation algorithms, while employing DP and HE for the data security. PaddleFL can exploit Paddle to realize data, model, and pipeline parallelism. FATE and TFF are based on Tensorflow as the engine, while FATE can provide Web portal UI, which is convenient for novices. PySyft is compatible with PyTorch, which can easily handle the PyTorch-based tasks, while PaddleFL is compatible with Paddle, which can easily deal with rich pre-trained models published in PaddleHub ",
                "PaddleHub ",
                ".",
                "Table ",
                "4",
                " represents the support of diverse types of FL in terms of data distribution. All the frameworks support horizontal FL, while vertical FL is supported by three frameworks except TFF. PySyft cannot directly support the vertical FL, while PyVertical ",
                "Romanini2021 ",
                ", which is built upon PySyft, can be used to support vertical FL with the compatibility of PyTorch models. The hybrid FL is only supported by Paddle and FATE. In addition, all the frameworks support the execution with GPU. In practice, although PaddleFL may correspond to slightly longer time, the accuracy of the trained model can be higher that of TFF and FATE, while PySyft may generate “out of memory” errors ",
                "Kholod2021 ",
                "."
            ]
        ]
    }
}