{
    "S3.T1.4": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T1.4\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T1.4.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S3.T1.4.1.1.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.4.1.1.1.1\">\n<tr class=\"ltx_tr\" id=\"S3.T1.4.1.1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S3.T1.4.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.1.1.1.1.1\">#subjects</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.1.1.1.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S3.T1.4.1.1.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.1.1.2.1.1\">(#slices)</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T1.4.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.2.1\">Baseline</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T1.4.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.3.1\">SimCLR</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T1.4.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.4.1\">PCL</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T1.4.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.5.1\">DINO</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T1.4.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.6.1\">MIM</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.4.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T1.4.2.1.1\">296 (6738)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.2.1.2\">0.89 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.2.1.3\">0.89 &#177; 0.002</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.2.1.4\">0.89 &#177; 0.003</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.2.1.5\">0.89 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.2.1.6\">0.89 &#177; 0.001</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T1.4.3.2.1\">50 (1151)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.3.2.2\">0.87 &#177; 0.007</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.3.2.3\">0.87 &#177; 0.011</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.3.2.4\">0.88 &#177; 0.005</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.3.2.5\">0.87 &#177; 0.006</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.3.2.6\">0.88 &#177; 0.006</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T1.4.4.3.1\">25 (582)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.4.3.2\">0.86 &#177; 0.003</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.4.3.3\">0.86 &#177; 0.014</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.4.3.4\">0.85 &#177; 0.014</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.4.3.5\">0.84 &#177; 0.002</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.4.3.6\">0.87 &#177; 0.007</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T1.4.5.4.1\">15 (349)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.5.4.2\">0.84 &#177; 0.007</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.5.4.3\">0.83 &#177; 0.024</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.5.4.4\">0.85 &#177; 0.009</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.5.4.5\">0.79 &#177; 0.009</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.5.4.6\">0.86 &#177; 0.015</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T1.4.6.5.1\">10 (231)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.6.5.2\">0.82 &#177; 0.009</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.6.5.3\">0.80 &#177; 0.024</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.6.5.4\">0.84 &#177; 0.009</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.6.5.5\">0.74 &#177; 0.022</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.4.6.5.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.6.5.6.1\">0.86 &#177; 0.007</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 1 :  Mean test DSC across all 140 test subjects and foreground classes for the baseline and fine-tuned SSP models, for varying numbers of labeled subjects ± sample standard deviation across different training seeds. For each number of labeled subjects, the average number of slices across all training seeds is shown. The biggest performance increase compared to the baseline is indicated in bold.",
        "footnotes": [],
        "references": [
            "The mean test DSCs across all foreground classes and varying numbers of fine-tuning subjects can be seen in table 1. All models show similar performances when trained or fine-tuned on all available labeled training data. This also holds when looking at individual classes. All models showed mean 3D test DSCs of 0.93, 0.85, and 0.90 for the LV, MYO, and RV classes respectively. More details are shown in supplementary material 0.B.",
            "As shown in table 1, PCL and MIM pretraining outperform the baseline performance for smaller labeled fine-tuning subsets. The biggest increase compared to the baseline can be seen for MIM pretraining and fine-tuning on the smallest labeled subset. SimCLR and DINO pretraining, on the other hand, show a performance decrease for fine-tuning on smaller labeled subsets, as well as a higher sample standard deviation.",
            "Table 1 indicates that SSP with unlabeled data only yields an improvement in CMR cine segmentation when very limited amounts of labeled data are available for fine-tuning. Moreover, choice of SSP method is important. PCL and MIM showed performance increases for small labeled fine-tuning datasets, indicating that these methods contribute useful information for the problem. MIM may be the most effective because it pretrains both the encoder and decoder of the U-Net architecture."
        ]
    },
    "S3.T1.4.1.1.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.4.1.1.1.1\">\n<tr class=\"ltx_tr\" id=\"S3.T1.4.1.1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S3.T1.4.1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.1.1.1.1.1\">#subjects</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.4.1.1.1.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S3.T1.4.1.1.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.4.1.1.1.1.2.1.1\">(#slices)</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 1 :  Mean test DSC across all 140 test subjects and foreground classes for the baseline and fine-tuned SSP models, for varying numbers of labeled subjects ± sample standard deviation across different training seeds. For each number of labeled subjects, the average number of slices across all training seeds is shown. The biggest performance increase compared to the baseline is indicated in bold.",
        "footnotes": [],
        "references": [
            "The mean test DSCs across all foreground classes and varying numbers of fine-tuning subjects can be seen in table 1. All models show similar performances when trained or fine-tuned on all available labeled training data. This also holds when looking at individual classes. All models showed mean 3D test DSCs of 0.93, 0.85, and 0.90 for the LV, MYO, and RV classes respectively. More details are shown in supplementary material 0.B.",
            "As shown in table 1, PCL and MIM pretraining outperform the baseline performance for smaller labeled fine-tuning subsets. The biggest increase compared to the baseline can be seen for MIM pretraining and fine-tuning on the smallest labeled subset. SimCLR and DINO pretraining, on the other hand, show a performance decrease for fine-tuning on smaller labeled subsets, as well as a higher sample standard deviation.",
            "Table 1 indicates that SSP with unlabeled data only yields an improvement in CMR cine segmentation when very limited amounts of labeled data are available for fine-tuning. Moreover, choice of SSP method is important. PCL and MIM showed performance increases for small labeled fine-tuning datasets, indicating that these methods contribute useful information for the problem. MIM may be the most effective because it pretrains both the encoder and decoder of the U-Net architecture."
        ]
    },
    "S3.T2.4": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T2.4\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S3.T2.4.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.1.1\">Pretraining</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S3.T2.4.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.2.1\">Fine-tuning</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T2.4.1.1.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T2.4.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.3.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.3.1.1.1.1\">Both time</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.3.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.3.1.2.1.1\">frames</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T2.4.1.1.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T2.4.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.4.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.4.1.1.1.1\">ED time</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.4.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.4.1.2.1.1\">frames</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T2.4.1.1.5\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T2.4.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.5.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.5.1.1.1.1\">ES time</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.5.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.5.1.2.1.1\">frames</span></td>\n</tr>\n</table>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.4.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.4.2.1.1\">None</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.4.2.1.2\">ED time frames</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.2.1.3\">0.88 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.2.1.4\">0.90 &#177; 0.002</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.2.1.5\">0.86 &#177; 0.002</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.4.3.2.1\">All data</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.4.3.2.2\">ED time frames</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.3.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.3.2.3.1\">0.89 &#177; 0.001</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.3.2.4\">0.90 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.3.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.3.2.5.1\">0.87 &#177; 0.001</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.4.4.3.1\">None</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.4.4.3.2\">ES time frames</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.4.3.3\">0.88 &#177; 0.007</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.4.3.4\">0.88 &#177; 0.012</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.4.3.5\">0.88 &#177; 0.002</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.4.5.4.1\">All data</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T2.4.5.4.2\">ES time frames</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.5.4.3\">0.88 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.5.4.4\">0.88 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.4.5.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.5.4.5.1\">0.89 &#177; 0.000</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 2 :  Mean test DSC ± sample standard deviation, comparing fine-tuned model generalization to unseen cardiac phases. Improvements after SSP are indicated in bold.",
        "footnotes": [],
        "references": [
            "Since MIM pretraining consistently showed the best results, MIM was used for the generalization evaluation. Tables 2 and 3 show the results for the first two generalization experiments, investigating fine-tuned model generalization to unseen (during fine-tuning) cardiac phases and vendors. Both experiments showed similar overall, in-domain, and out-of-domain baseline performances. For labeled ED time frames fine-tuning, both overall and out-of-domain performances increased slightly with SSP. Contrastingly, labeled ES time frames fine-tuning only showed a slight in-domain performance increase with SSP. SSP did not result in changes in performance when fine-tuning on labeled vendors A and B. A slight increase in out-of-domain performance can be seen after fine-tuning on labeled vendors C and D."
        ]
    },
    "S3.T2.4.1.1.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T2.4.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.3.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.3.1.1.1.1\">Both time</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.3.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.3.1.2.1.1\">frames</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 2 :  Mean test DSC ± sample standard deviation, comparing fine-tuned model generalization to unseen cardiac phases. Improvements after SSP are indicated in bold.",
        "footnotes": [],
        "references": [
            "Since MIM pretraining consistently showed the best results, MIM was used for the generalization evaluation. Tables 2 and 3 show the results for the first two generalization experiments, investigating fine-tuned model generalization to unseen (during fine-tuning) cardiac phases and vendors. Both experiments showed similar overall, in-domain, and out-of-domain baseline performances. For labeled ED time frames fine-tuning, both overall and out-of-domain performances increased slightly with SSP. Contrastingly, labeled ES time frames fine-tuning only showed a slight in-domain performance increase with SSP. SSP did not result in changes in performance when fine-tuning on labeled vendors A and B. A slight increase in out-of-domain performance can be seen after fine-tuning on labeled vendors C and D."
        ]
    },
    "S3.T2.4.1.1.4.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T2.4.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.4.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.4.1.1.1.1\">ED time</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.4.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.4.1.2.1.1\">frames</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 2 :  Mean test DSC ± sample standard deviation, comparing fine-tuned model generalization to unseen cardiac phases. Improvements after SSP are indicated in bold.",
        "footnotes": [],
        "references": [
            "Since MIM pretraining consistently showed the best results, MIM was used for the generalization evaluation. Tables 2 and 3 show the results for the first two generalization experiments, investigating fine-tuned model generalization to unseen (during fine-tuning) cardiac phases and vendors. Both experiments showed similar overall, in-domain, and out-of-domain baseline performances. For labeled ED time frames fine-tuning, both overall and out-of-domain performances increased slightly with SSP. Contrastingly, labeled ES time frames fine-tuning only showed a slight in-domain performance increase with SSP. SSP did not result in changes in performance when fine-tuning on labeled vendors A and B. A slight increase in out-of-domain performance can be seen after fine-tuning on labeled vendors C and D."
        ]
    },
    "S3.T2.4.1.1.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T2.4.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.5.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.5.1.1.1.1\">ES time</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.4.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.4.1.1.5.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.4.1.1.5.1.2.1.1\">frames</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 2 :  Mean test DSC ± sample standard deviation, comparing fine-tuned model generalization to unseen cardiac phases. Improvements after SSP are indicated in bold.",
        "footnotes": [],
        "references": [
            "Since MIM pretraining consistently showed the best results, MIM was used for the generalization evaluation. Tables 2 and 3 show the results for the first two generalization experiments, investigating fine-tuned model generalization to unseen (during fine-tuning) cardiac phases and vendors. Both experiments showed similar overall, in-domain, and out-of-domain baseline performances. For labeled ED time frames fine-tuning, both overall and out-of-domain performances increased slightly with SSP. Contrastingly, labeled ES time frames fine-tuning only showed a slight in-domain performance increase with SSP. SSP did not result in changes in performance when fine-tuning on labeled vendors A and B. A slight increase in out-of-domain performance can be seen after fine-tuning on labeled vendors C and D."
        ]
    },
    "S3.T3.4": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T3.4\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T3.4.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.4.1.1.1.1\">Pretraining</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.4.1.1.2.1\">Fine-tuning</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.4.1.1.3.1\">All vendors</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.4.1.1.4.1\">Vendors A+B</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.4.1.1.5.1\">Vendors C+D</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.4.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.2.2.1\">None</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.2.2.2\">Vendors A+B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.2.2.3\">0.89 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.2.2.4\">0.89 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.2.2.5\">0.88 &#177; 0.002</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.4.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.3.3.1\">All data</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.3.3.2\">Vendors A+B</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.3.3.3\">0.89 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.3.3.4\">0.89 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.3.3.5\">0.88 &#177; 0.000</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.4.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.4.4.1\">None</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.4.4.2\">Vendors C+D</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.4.4.3\">0.88 &#177; 0.002</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.4.4.4\">0.87 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.4.4.5\">0.89 &#177; 0.004</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.4.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.5.5.1\">All data</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.4.5.5.2\">Vendors C+D</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.5.5.3\">0.88 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.5.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.4.5.5.4.1\">0.88 &#177; 0.002</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.4.5.5.5\">0.89 &#177; 0.002</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 3 :  Mean test DSC ± sample standard deviation, comparing fine-tuned model generalization to unseen vendors. Improvements after SSP are indicated in bold.",
        "footnotes": [],
        "references": [
            "Since MIM pretraining consistently showed the best results, MIM was used for the generalization evaluation. Tables 2 and 3 show the results for the first two generalization experiments, investigating fine-tuned model generalization to unseen (during fine-tuning) cardiac phases and vendors. Both experiments showed similar overall, in-domain, and out-of-domain baseline performances. For labeled ED time frames fine-tuning, both overall and out-of-domain performances increased slightly with SSP. Contrastingly, labeled ES time frames fine-tuning only showed a slight in-domain performance increase with SSP. SSP did not result in changes in performance when fine-tuning on labeled vendors A and B. A slight increase in out-of-domain performance can be seen after fine-tuning on labeled vendors C and D."
        ]
    },
    "S3.T4.4": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S3.T4.4\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S3.T4.4.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.1.1\">Data augmentation</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T4.4.1.1.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T4.4.1.1.2.1\">\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.2.1.1.1.1\">ED time</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.2.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.2.1.2.1.1\">frames</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T4.4.1.1.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T4.4.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.3.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.3.1.1.1.1\">ES time</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.3.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.3.1.2.1.1\">frames</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T4.4.1.1.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T4.4.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.4.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.4.1.1.1.1\">Vendors</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.4.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.4.1.2.1.1\">A+B</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S3.T4.4.1.1.5\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T4.4.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.5.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.5.1.1.1.1\">Vendors</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.5.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.5.1.2.1.1\">C+D</span></td>\n</tr>\n</table>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T4.4.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T4.4.2.1.1\">Yes</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.4.2.1.2\">0.90 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.4.2.1.3\">0.88 &#177; 0.003</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.4.2.1.4\">0.89 &#177; 0.001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.4.2.1.5\">0.89 &#177; 0.006</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.4.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T4.4.3.2.1\">No</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.4.3.2.2\">0.71 &#177; 0.042</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.4.3.2.3\">0.66 &#177; 0.036</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.4.3.2.4\">0.72 &#177; 0.036</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.4.3.2.5\">0.61 &#177; 0.049</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 4 :  Mean test DSC ± standard deviation, for varying cardiac phases and vendor subsets, for baseline models with and without data augmentation.",
        "footnotes": [],
        "references": [
            "The DSCs for varying cardiac phase and vendor subsets for baseline models trained on all labeled data with and without data augmentation can be seen in table 4. This shows that without data augmentation, there is a large difference in DSC between ED and ES time frames, as well as between both vendor groups. With data augmentation the performance gap between times frames is mostly bridged, while the performance gap between vendors is bridged completely.",
            "The cardiac phase generalization experiment shows a slight benefit in SSP in generalizing to unseen (during fine-tuning) cardiac phases. Out-of-domain performances can slightly increase with SSP, while in-domain performances did not decrease. This indicates that there may be benefit in SSP in this situation. However, the baseline models already show the ability to generalize to unseen cardiac phases, leaving little room for improvement as a result of SSP. This could be explained by the data augmentation. Table 4 shows that there is a performance gap between cardiac phases when training on all labeled data without data augmentation. However, adding data augmentation largely closes this gap, indicating that data augmentation accounts for most of the generalizability shown in the unseen cardiac phase experiment.",
            "Similar results can be seen for the unseen vendor experiment, showing a small out-of-domain performance increase. For the two vendor groups, table 4 also shows a large performance gap without data augmentation, which is closed with data augmentation. While these models were trained on all labeled data, these results do indicate the importance of data augmentation in general model performance and generalizability to unseen data. The results of the data augmentation experiment in combination with MIM pretraining further show the importance of data augmentation, even when using SSP. While SSP shows a clear benefit when not using data augmentation in fine-tuning and training from scratch, data augmentation is still necessary to achieve the best performance. This indicates that data augmentation can better cover the data distribution compared to our SSP methods with larger unlabeled datasets. These results support claims that data augmentation can mostly meet or exceed the benefits of SSP, when appropriately selected for the downstream task [16]. However, our results also indicate that data augmentation is a crucial step in enabling the possible benefits of SSP."
        ]
    },
    "S3.T4.4.1.1.2.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T4.4.1.1.2.1\">\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.2.1.1.1.1\">ED time</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.2.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.2.1.2.1.1\">frames</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 4 :  Mean test DSC ± standard deviation, for varying cardiac phases and vendor subsets, for baseline models with and without data augmentation.",
        "footnotes": [],
        "references": [
            "The DSCs for varying cardiac phase and vendor subsets for baseline models trained on all labeled data with and without data augmentation can be seen in table 4. This shows that without data augmentation, there is a large difference in DSC between ED and ES time frames, as well as between both vendor groups. With data augmentation the performance gap between times frames is mostly bridged, while the performance gap between vendors is bridged completely.",
            "The cardiac phase generalization experiment shows a slight benefit in SSP in generalizing to unseen (during fine-tuning) cardiac phases. Out-of-domain performances can slightly increase with SSP, while in-domain performances did not decrease. This indicates that there may be benefit in SSP in this situation. However, the baseline models already show the ability to generalize to unseen cardiac phases, leaving little room for improvement as a result of SSP. This could be explained by the data augmentation. Table 4 shows that there is a performance gap between cardiac phases when training on all labeled data without data augmentation. However, adding data augmentation largely closes this gap, indicating that data augmentation accounts for most of the generalizability shown in the unseen cardiac phase experiment.",
            "Similar results can be seen for the unseen vendor experiment, showing a small out-of-domain performance increase. For the two vendor groups, table 4 also shows a large performance gap without data augmentation, which is closed with data augmentation. While these models were trained on all labeled data, these results do indicate the importance of data augmentation in general model performance and generalizability to unseen data. The results of the data augmentation experiment in combination with MIM pretraining further show the importance of data augmentation, even when using SSP. While SSP shows a clear benefit when not using data augmentation in fine-tuning and training from scratch, data augmentation is still necessary to achieve the best performance. This indicates that data augmentation can better cover the data distribution compared to our SSP methods with larger unlabeled datasets. These results support claims that data augmentation can mostly meet or exceed the benefits of SSP, when appropriately selected for the downstream task [16]. However, our results also indicate that data augmentation is a crucial step in enabling the possible benefits of SSP."
        ]
    },
    "S3.T4.4.1.1.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T4.4.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.3.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.3.1.1.1.1\">ES time</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.3.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.3.1.2.1.1\">frames</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 4 :  Mean test DSC ± standard deviation, for varying cardiac phases and vendor subsets, for baseline models with and without data augmentation.",
        "footnotes": [],
        "references": [
            "The DSCs for varying cardiac phase and vendor subsets for baseline models trained on all labeled data with and without data augmentation can be seen in table 4. This shows that without data augmentation, there is a large difference in DSC between ED and ES time frames, as well as between both vendor groups. With data augmentation the performance gap between times frames is mostly bridged, while the performance gap between vendors is bridged completely.",
            "The cardiac phase generalization experiment shows a slight benefit in SSP in generalizing to unseen (during fine-tuning) cardiac phases. Out-of-domain performances can slightly increase with SSP, while in-domain performances did not decrease. This indicates that there may be benefit in SSP in this situation. However, the baseline models already show the ability to generalize to unseen cardiac phases, leaving little room for improvement as a result of SSP. This could be explained by the data augmentation. Table 4 shows that there is a performance gap between cardiac phases when training on all labeled data without data augmentation. However, adding data augmentation largely closes this gap, indicating that data augmentation accounts for most of the generalizability shown in the unseen cardiac phase experiment.",
            "Similar results can be seen for the unseen vendor experiment, showing a small out-of-domain performance increase. For the two vendor groups, table 4 also shows a large performance gap without data augmentation, which is closed with data augmentation. While these models were trained on all labeled data, these results do indicate the importance of data augmentation in general model performance and generalizability to unseen data. The results of the data augmentation experiment in combination with MIM pretraining further show the importance of data augmentation, even when using SSP. While SSP shows a clear benefit when not using data augmentation in fine-tuning and training from scratch, data augmentation is still necessary to achieve the best performance. This indicates that data augmentation can better cover the data distribution compared to our SSP methods with larger unlabeled datasets. These results support claims that data augmentation can mostly meet or exceed the benefits of SSP, when appropriately selected for the downstream task [16]. However, our results also indicate that data augmentation is a crucial step in enabling the possible benefits of SSP."
        ]
    },
    "S3.T4.4.1.1.4.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T4.4.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.4.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.4.1.1.1.1\">Vendors</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.4.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.4.1.2.1.1\">A+B</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 4 :  Mean test DSC ± standard deviation, for varying cardiac phases and vendor subsets, for baseline models with and without data augmentation.",
        "footnotes": [],
        "references": [
            "The DSCs for varying cardiac phase and vendor subsets for baseline models trained on all labeled data with and without data augmentation can be seen in table 4. This shows that without data augmentation, there is a large difference in DSC between ED and ES time frames, as well as between both vendor groups. With data augmentation the performance gap between times frames is mostly bridged, while the performance gap between vendors is bridged completely.",
            "The cardiac phase generalization experiment shows a slight benefit in SSP in generalizing to unseen (during fine-tuning) cardiac phases. Out-of-domain performances can slightly increase with SSP, while in-domain performances did not decrease. This indicates that there may be benefit in SSP in this situation. However, the baseline models already show the ability to generalize to unseen cardiac phases, leaving little room for improvement as a result of SSP. This could be explained by the data augmentation. Table 4 shows that there is a performance gap between cardiac phases when training on all labeled data without data augmentation. However, adding data augmentation largely closes this gap, indicating that data augmentation accounts for most of the generalizability shown in the unseen cardiac phase experiment.",
            "Similar results can be seen for the unseen vendor experiment, showing a small out-of-domain performance increase. For the two vendor groups, table 4 also shows a large performance gap without data augmentation, which is closed with data augmentation. While these models were trained on all labeled data, these results do indicate the importance of data augmentation in general model performance and generalizability to unseen data. The results of the data augmentation experiment in combination with MIM pretraining further show the importance of data augmentation, even when using SSP. While SSP shows a clear benefit when not using data augmentation in fine-tuning and training from scratch, data augmentation is still necessary to achieve the best performance. This indicates that data augmentation can better cover the data distribution compared to our SSP methods with larger unlabeled datasets. These results support claims that data augmentation can mostly meet or exceed the benefits of SSP, when appropriately selected for the downstream task [16]. However, our results also indicate that data augmentation is a crucial step in enabling the possible benefits of SSP."
        ]
    },
    "S3.T4.4.1.1.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T4.4.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.5.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.5.1.1.1.1\">Vendors</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.4.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T4.4.1.1.5.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.4.1.1.5.1.2.1.1\">C+D</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 4 :  Mean test DSC ± standard deviation, for varying cardiac phases and vendor subsets, for baseline models with and without data augmentation.",
        "footnotes": [],
        "references": [
            "The DSCs for varying cardiac phase and vendor subsets for baseline models trained on all labeled data with and without data augmentation can be seen in table 4. This shows that without data augmentation, there is a large difference in DSC between ED and ES time frames, as well as between both vendor groups. With data augmentation the performance gap between times frames is mostly bridged, while the performance gap between vendors is bridged completely.",
            "The cardiac phase generalization experiment shows a slight benefit in SSP in generalizing to unseen (during fine-tuning) cardiac phases. Out-of-domain performances can slightly increase with SSP, while in-domain performances did not decrease. This indicates that there may be benefit in SSP in this situation. However, the baseline models already show the ability to generalize to unseen cardiac phases, leaving little room for improvement as a result of SSP. This could be explained by the data augmentation. Table 4 shows that there is a performance gap between cardiac phases when training on all labeled data without data augmentation. However, adding data augmentation largely closes this gap, indicating that data augmentation accounts for most of the generalizability shown in the unseen cardiac phase experiment.",
            "Similar results can be seen for the unseen vendor experiment, showing a small out-of-domain performance increase. For the two vendor groups, table 4 also shows a large performance gap without data augmentation, which is closed with data augmentation. While these models were trained on all labeled data, these results do indicate the importance of data augmentation in general model performance and generalizability to unseen data. The results of the data augmentation experiment in combination with MIM pretraining further show the importance of data augmentation, even when using SSP. While SSP shows a clear benefit when not using data augmentation in fine-tuning and training from scratch, data augmentation is still necessary to achieve the best performance. This indicates that data augmentation can better cover the data distribution compared to our SSP methods with larger unlabeled datasets. These results support claims that data augmentation can mostly meet or exceed the benefits of SSP, when appropriately selected for the downstream task [16]. However, our results also indicate that data augmentation is a crucial step in enabling the possible benefits of SSP."
        ]
    }
}