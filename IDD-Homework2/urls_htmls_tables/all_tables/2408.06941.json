{
    "id_table_1": {
        "caption": "Table 1:  Human Preference compared with Perplexity AI outcome. Win means that the current method beats Perplexity AI. More Win times means a superior application.",
        "table": "S5.T1.1",
        "footnotes": [],
        "references": [
            "Besides, both academic and industry applications serve as  passive  assistants, focusing solely on responding to user inquiries rather than engaging in active communication. To address these issues in academic and industry contexts, we developed OpenResearcher, an open-source project that harnesses AI to accelerate scientific research. Its main workflow is shown in Figure  1 , and its main contributions are as follows:",
            "OpenResearcher is designed to leverage AI to speed up the research process by efficiently responding to researchers inquiries. As shown in  1 , OpenResearcher employs RAG to combine LLMs internal knowledge with the latest external information. We design a Data Routing strategy for quick and precise information retrieval that can meet time and domain requirements. Lastly, we have developed multiple tools, including query tools, retrieval tools, post-processing tools, generation tools, and refinement tools. OpenResearcher can flexibly use these tools to customize a workflow for each query.",
            "The result is shown in Table  1  with an overall agreement of 90.67%. Our OpenResearcher achieves superior information correctness, relevance, and richness compared to all other applications. OpenResearcher significantly outperforms Perplexity AI with more Win than Lose. Specifically, compared to Naive RAG, OpenResearcher demonstrates better performance in all metrics. This suggests that our various tools significantly enhance the quality of the answers."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  GPT-4 Preference Results compared with Perplexity AI outcome.",
        "table": "S5.T2.1",
        "footnotes": [],
        "references": [
            "Figure  2 , whose completed screenshot is shown in Figure  3  of Section  A , demonstrates the strong capability of OpenResearcher. Firstly, OpenResearcher can flexibly construct a tailored workflow for different queries, including simple queries and complex queries. For simple questions like What is PPO?, it directly employs LLMs to produce answers. For more complex queries like Summarize the recent latest developments and variants of PPO?, it utilizes multiple tools and provides users with essential details, including active queries, rewritten query, decomposed sub-queries and their sub-answers, retrieved outcomes of each sub-query after post-processing, generated final answer, and citation. This example can showcase its flexibility in handling different queries. With this benefit, our OpenResearcher can speed up responses and reduce computational costs.",
            "Thirdly, Figure  2  demonstrates that OpenResearcher supports conversational question answering, enabling users to engage in multi-turn dialogues. This feature allows for continuous and deeper discussions within OpenResearcher.",
            "The results are shown in Table  2 . This supplemental LLM evaluation further demonstrates our systems powerful performance. These results show our OpenResearcher achieves the best information relevance and richness among all applications. Furthermore, OpenResearcher surpasses Naive RAG in both metrics, demonstrating its superior performance due to our design."
        ]
    },
    "global_footnotes": [
        "Equal contribution.",
        "Equal contribution.",
        "Equal contribution.",
        "Equal contribution."
    ]
}