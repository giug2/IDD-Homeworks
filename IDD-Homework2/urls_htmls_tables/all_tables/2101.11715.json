{
    "PAPER'S NUMBER OF TABLES": 20,
    "S2.T1": {
        "caption": "Table 1: Research Works on Failure Prediction in Bosch Production Line",
        "table": "<table id=\"S2.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S2.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S2.T1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.1.1.1.1\" class=\"ltx_p\" style=\"width:48.4pt;\"><span id=\"S2.T1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Objectives</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S2.T1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Ref</span></td>\n<td id=\"S2.T1.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S2.T1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.1.3.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Learning Method</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S2.T1.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.1.4.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Contribution</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S2.T1.1.2\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" rowspan=\"7\">\n<span id=\"S2.T1.1.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.2.1.1.1\" class=\"ltx_p\" style=\"width:48.4pt;\"><span id=\"S2.T1.1.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\"><span id=\"S2.T1.1.2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Improving predictive model without time-series features</span></span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\">Carbery et al. <span id=\"S2.T1.1.2.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">2018</a><span id=\"S2.T1.1.2.2.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></td>\n<td id=\"S2.T1.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S2.T1.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.2.3.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">XGBoost, BN</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S2.T1.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.2.4.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.2.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">BN model performs well in failure prediction.</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S2.T1.1.3\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.3.1\" class=\"ltx_td ltx_align_center\"><cite class=\"ltx_cite ltx_citemacro_cite\">Zhang et al. <span id=\"S2.T1.1.3.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib60\" title=\"\" class=\"ltx_ref\">2016</a><span id=\"S2.T1.1.3.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></td>\n<td id=\"S2.T1.1.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.3.2.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.3.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">RF, Gradient Boosting, LR, NB, DT</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.3.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">RF performs better on different clusters.</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S2.T1.1.4\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.4.1\" class=\"ltx_td ltx_align_center\"><cite class=\"ltx_cite ltx_citemacro_cite\">Khoza and Grobler <span id=\"S2.T1.1.4.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib21\" title=\"\" class=\"ltx_ref\">2019</a><span id=\"S2.T1.1.4.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></td>\n<td id=\"S2.T1.1.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.4.2.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.4.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">RF, SVM, NB, SPC</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.4.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.4.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">RF outperforms other models.</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S2.T1.1.5\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.5.1\" class=\"ltx_td ltx_align_center\"><cite class=\"ltx_cite ltx_citemacro_cite\">Kotenko et al. <span id=\"S2.T1.1.5.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">2019</a><span id=\"S2.T1.1.5.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></td>\n<td id=\"S2.T1.1.5.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.5.2.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.5.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">SVM, KNN, Perceptron, LR, DT, MV</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.5.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.5.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.5.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.5.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">SVM and MV outperform other models.</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S2.T1.1.6\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.6.1\" class=\"ltx_td ltx_align_center\"><cite class=\"ltx_cite ltx_citemacro_cite\">Mangal and Kumar <span id=\"S2.T1.1.6.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib35\" title=\"\" class=\"ltx_ref\">2016</a><span id=\"S2.T1.1.6.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></td>\n<td id=\"S2.T1.1.6.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.6.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.6.2.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.6.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">LR, Extra Trees Classifier, RF, XGBoost</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.6.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.6.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.6.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.6.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">XGBoost and RF outperform other methods.</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S2.T1.1.7\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.7.1\" class=\"ltx_td ltx_align_center\"><cite class=\"ltx_cite ltx_citemacro_cite\">Hebert <span id=\"S2.T1.1.7.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">2016</a><span id=\"S2.T1.1.7.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></td>\n<td id=\"S2.T1.1.7.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.7.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.7.2.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.7.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">LR, RF, XGBoost</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.7.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.7.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.7.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.7.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">RF and XGBoost can properly identify conditions leading to failure events.</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S2.T1.1.8\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.8.1\" class=\"ltx_td ltx_align_center\"><cite class=\"ltx_cite ltx_citemacro_cite\">Maurya <span id=\"S2.T1.1.8.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">2016</a><span id=\"S2.T1.1.8.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></td>\n<td id=\"S2.T1.1.8.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.8.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.8.2.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.8.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">XGBoost</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.8.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.8.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.8.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.8.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Optimize MCC by using GBM as a base classifier.</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S2.T1.1.9\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.9.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" rowspan=\"4\">\n<span id=\"S2.T1.1.9.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.9.1.1.1\" class=\"ltx_p\" style=\"width:48.4pt;\"><span id=\"S2.T1.1.9.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Improving predictive model with time-series features</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\">Huang et al. <span id=\"S2.T1.1.9.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib18\" title=\"\" class=\"ltx_ref\">2019b</a><span id=\"S2.T1.1.9.2.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></td>\n<td id=\"S2.T1.1.9.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S2.T1.1.9.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.9.3.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.9.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Ontology-based LSTM neural network</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.9.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S2.T1.1.9.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.9.4.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.9.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Ontology-based LSTM neural network yields a better performance</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S2.T1.1.10\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.10.1\" class=\"ltx_td ltx_align_center\"><cite class=\"ltx_cite ltx_citemacro_cite\">Moldovan et al. <span id=\"S2.T1.1.10.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">2019</a><span id=\"S2.T1.1.10.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></td>\n<td id=\"S2.T1.1.10.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.10.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.10.2.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.10.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">RF, GBT, NB, KNN, SVM, and MPC</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.10.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S2.T1.1.10.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.10.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.10.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">The LSTM RNN model outperform others.</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S2.T1.1.11\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.11.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><cite class=\"ltx_cite ltx_citemacro_cite\">Liu et al. <span id=\"S2.T1.1.11.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib31\" title=\"\" class=\"ltx_ref\">2020d</a><span id=\"S2.T1.1.11.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></td>\n<td id=\"S2.T1.1.11.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S2.T1.1.11.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.11.2.1.1\" class=\"ltx_p\" style=\"width:130.9pt;\"><span id=\"S2.T1.1.11.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">SP-LSTM models</span></span>\n</span>\n</td>\n<td id=\"S2.T1.1.11.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S2.T1.1.11.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S2.T1.1.11.3.1.1\" class=\"ltx_p\" style=\"width:170.7pt;\"><span id=\"S2.T1.1.11.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">The A-Bi-SP-LSTM model outperforms other models.</span></span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Bosch is one of the worldwide leading manufacturing companies. It ensures high quality of the production by monitoring its parts in the manufacturing processes. Because Bosch records detailed data for each step on the assembly lines, they can apply advanced techniques to improve the manufacturing processes. To this end, Bosch has published a dataset on the Kaggle competition platform to predict internal failures by thousands of measurements and tests made for each component along the assembly line. Some studies have analyzed the dataset and carried out approaches to predicting product quality based on CL algorithms excluding time-series features Carbery et al. (2019, 2018); Zhang et al. (2016); Khoza and Grobler (2019); Kotenko et al. (2019); Mangal and Kumar (2016); Hebert (2016); Maurya (2016) or including time-series features Huang et al. (2019b); Moldovan et al. (2019); Liu et al. (2020d), as summarized in Table 1. These works were conducted based on a set of learning methods, including Logistic Regression (LR), Gradient Boosting Machine (GBM), Random Forest (RF), Gradient Boosted Trees (GBT), Naive Bayes (NB), Bayesian Network (BN), K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Multilayer Perceptron Classifier (MPC), Majority Voting (MV), Decision Tree (DT), Statistical Process Control (SPC), etc.",
            "The experimental results are shown in Table 11. There are outliers in the test results, so the sum of the samples in each cluster is less than 100. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedSVM is heterogeneous. It enforces the conclusion that FedSVM and SVM have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "The experimental results are shown in Table 12. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedRF is heterogeneous. It enforces the conclusion that FedRF and RF have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "Another threat to construct validity is the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2) used in the experiment. In the industry, the threshold value is set according to the production needs. We have performed a hypothesis test for the difference between the two approaches’ performances to explain that the difference between FL and CL is within the threshold. The original hypothesis H0 is difference >δabsent𝛿>\\delta, and the alternative hypothesis H1 is difference <δabsent𝛿<\\delta, where the difference = CL – FL on the same random partial testing data group. Suppose α𝛼\\alpha = 0.05. The p-value of the evaluation metrics for FedSVM vs. SVM and FedForest vs. RForest is shown in Table 13 and Table 14, respectively. As a​l​p​h​a>𝑎𝑙𝑝ℎ𝑎absentalpha> p-value for all metrics, the alternative hypothesis H1 is accepted, which means that the difference between CL and FL is less than the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2)."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Improvement of FedRF",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S3.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S3.T2.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\"><span id=\"S3.T2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Algo.</span></span>\n</span>\n</td>\n<td id=\"S3.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">ACC</span></td>\n<td id=\"S3.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">PRE</span></td>\n<td id=\"S3.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.1.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">F1</span></td>\n<td id=\"S3.T2.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.1.1.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">MCC</span></td>\n<td id=\"S3.T2.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.1.1.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">AUC</span></td>\n</tr>\n<tr id=\"S3.T2.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T2.1.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T2.1.2.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\"><span id=\"S3.T2.1.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">FedForest </span><cite class=\"ltx_cite ltx_citemacro_cite\">Liu et al. <span id=\"S3.T2.1.2.1.1.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">(</span><a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">2020a</a><span id=\"S3.T2.1.2.1.1.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">)</span></cite></span>\n</span>\n</td>\n<td id=\"S3.T2.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.552</span></td>\n<td id=\"S3.T2.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.2.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.493</span></td>\n<td id=\"S3.T2.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.2.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.550</span></td>\n<td id=\"S3.T2.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.2.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.118</span></td>\n<td id=\"S3.T2.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.2.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.559</span></td>\n</tr>\n<tr id=\"S3.T2.1.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S3.T2.1.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T2.1.3.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\"><span id=\"S3.T2.1.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">FedRF (Ours)</span></span>\n</span>\n</td>\n<td id=\"S3.T2.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.1.3.2.1\" class=\"ltx_text ltx_framed ltx_framed_rectangle\" style=\"font-size:70%;background-color:#BFBFBF;border-color: #BFBFBF;\">0.825</span></td>\n<td id=\"S3.T2.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.1.3.3.1\" class=\"ltx_text ltx_framed ltx_framed_rectangle\" style=\"font-size:70%;background-color:#BFBFBF;border-color: #BFBFBF;\">0.802</span></td>\n<td id=\"S3.T2.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.1.3.4.1\" class=\"ltx_text ltx_framed ltx_framed_rectangle\" style=\"font-size:70%;background-color:#BFBFBF;border-color: #BFBFBF;\">0.883</span></td>\n<td id=\"S3.T2.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.1.3.5.1\" class=\"ltx_text ltx_framed ltx_framed_rectangle\" style=\"font-size:70%;background-color:#BFBFBF;border-color: #BFBFBF;\">0.593</span></td>\n<td id=\"S3.T2.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.1.3.6.1\" class=\"ltx_text ltx_framed ltx_framed_rectangle\" style=\"font-size:70%;background-color:#BFBFBF;border-color: #BFBFBF;\">0.866</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We have experimented to evaluate the improvement of FedRF.\nIn this experiment, we constructed a VFL scenario with two clients sharing data features using the Bosch dataset. There are 50 independent features in each client, which are extracted after performing the principal component analysis (PCA) from different production lines and the same 11154 samples. The experiment results are shown in Table 2.\nIt can be seen that we get better prediction results than the federated random forest algorithm proposed in Liu et al. (2020a)."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Measurements",
        "table": "<table id=\"S4.T3.4\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T3.4.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.5.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T3.4.5.1.1\" class=\"ltx_text ltx_font_bold\">Measurement</span></td>\n<td id=\"S4.T3.4.5.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S4.T3.4.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.5.2.1.1\" class=\"ltx_p\" style=\"width:150.8pt;\"><span id=\"S4.T3.4.5.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Formula</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-bottom:10.0pt;\">ACC</td>\n<td id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" style=\"padding-bottom:10.0pt;\">\n<span id=\"S4.T3.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.1.1.1.1.1\" class=\"ltx_p\" style=\"width:150.8pt;\"><math id=\"S4.T3.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathtt{\\dfrac{TP+TN}{TP+FN+TN+FP}}\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.1.1.m1.1a\"><mstyle displaystyle=\"true\" id=\"S4.T3.1.1.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.cmml\"><mfrac id=\"S4.T3.1.1.1.1.1.m1.1.1a\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.cmml\"><mrow id=\"S4.T3.1.1.1.1.1.m1.1.1.2\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.2.cmml\"><mi id=\"S4.T3.1.1.1.1.1.m1.1.1.2.2\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.2.2.cmml\">𝚃𝙿</mi><mo id=\"S4.T3.1.1.1.1.1.m1.1.1.2.1\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.2.1.cmml\">+</mo><mi id=\"S4.T3.1.1.1.1.1.m1.1.1.2.3\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.2.3.cmml\">𝚃𝙽</mi></mrow><mrow id=\"S4.T3.1.1.1.1.1.m1.1.1.3\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.cmml\"><mi id=\"S4.T3.1.1.1.1.1.m1.1.1.3.2\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.2.cmml\">𝚃𝙿</mi><mo id=\"S4.T3.1.1.1.1.1.m1.1.1.3.1\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.1.cmml\">+</mo><mi id=\"S4.T3.1.1.1.1.1.m1.1.1.3.3\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.3.cmml\">𝙵𝙽</mi><mo id=\"S4.T3.1.1.1.1.1.m1.1.1.3.1a\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.1.cmml\">+</mo><mi id=\"S4.T3.1.1.1.1.1.m1.1.1.3.4\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.4.cmml\">𝚃𝙽</mi><mo id=\"S4.T3.1.1.1.1.1.m1.1.1.3.1b\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.1.cmml\">+</mo><mi id=\"S4.T3.1.1.1.1.1.m1.1.1.3.5\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.5.cmml\">𝙵𝙿</mi></mrow></mfrac></mstyle><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.1.1.m1.1b\"><apply id=\"S4.T3.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1\"><divide id=\"S4.T3.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1\"></divide><apply id=\"S4.T3.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.2\"><plus id=\"S4.T3.1.1.1.1.1.m1.1.1.2.1.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.2.1\"></plus><ci id=\"S4.T3.1.1.1.1.1.m1.1.1.2.2.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.2.2\">𝚃𝙿</ci><ci id=\"S4.T3.1.1.1.1.1.m1.1.1.2.3.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.2.3\">𝚃𝙽</ci></apply><apply id=\"S4.T3.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3\"><plus id=\"S4.T3.1.1.1.1.1.m1.1.1.3.1.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.1\"></plus><ci id=\"S4.T3.1.1.1.1.1.m1.1.1.3.2.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.2\">𝚃𝙿</ci><ci id=\"S4.T3.1.1.1.1.1.m1.1.1.3.3.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.3\">𝙵𝙽</ci><ci id=\"S4.T3.1.1.1.1.1.m1.1.1.3.4.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.4\">𝚃𝙽</ci><ci id=\"S4.T3.1.1.1.1.1.m1.1.1.3.5.cmml\" xref=\"S4.T3.1.1.1.1.1.m1.1.1.3.5\">𝙵𝙿</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.1.1.m1.1c\">\\mathtt{\\dfrac{TP+TN}{TP+FN+TN+FP}}</annotation></semantics></math></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-bottom:10.0pt;\">PRE</td>\n<td id=\"S4.T3.2.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-bottom:10.0pt;\">\n<span id=\"S4.T3.2.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.2.2.1.1.1\" class=\"ltx_p\" style=\"width:150.8pt;\"><math id=\"S4.T3.2.2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathtt{\\dfrac{TP}{TP+FP}}\" display=\"inline\"><semantics id=\"S4.T3.2.2.1.1.1.m1.1a\"><mstyle displaystyle=\"true\" id=\"S4.T3.2.2.1.1.1.m1.1.1\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.cmml\"><mfrac id=\"S4.T3.2.2.1.1.1.m1.1.1a\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T3.2.2.1.1.1.m1.1.1.2\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.2.cmml\">𝚃𝙿</mi><mrow id=\"S4.T3.2.2.1.1.1.m1.1.1.3\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.3.cmml\"><mi id=\"S4.T3.2.2.1.1.1.m1.1.1.3.2\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.3.2.cmml\">𝚃𝙿</mi><mo id=\"S4.T3.2.2.1.1.1.m1.1.1.3.1\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.3.1.cmml\">+</mo><mi id=\"S4.T3.2.2.1.1.1.m1.1.1.3.3\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.3.3.cmml\">𝙵𝙿</mi></mrow></mfrac></mstyle><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.1.1.1.m1.1b\"><apply id=\"S4.T3.2.2.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.2.2.1.1.1.m1.1.1\"><divide id=\"S4.T3.2.2.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T3.2.2.1.1.1.m1.1.1\"></divide><ci id=\"S4.T3.2.2.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.2\">𝚃𝙿</ci><apply id=\"S4.T3.2.2.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.3\"><plus id=\"S4.T3.2.2.1.1.1.m1.1.1.3.1.cmml\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.3.1\"></plus><ci id=\"S4.T3.2.2.1.1.1.m1.1.1.3.2.cmml\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.3.2\">𝚃𝙿</ci><ci id=\"S4.T3.2.2.1.1.1.m1.1.1.3.3.cmml\" xref=\"S4.T3.2.2.1.1.1.m1.1.1.3.3\">𝙵𝙿</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.1.1.1.m1.1c\">\\mathtt{\\dfrac{TP}{TP+FP}}</annotation></semantics></math></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-bottom:10.0pt;\">F1</td>\n<td id=\"S4.T3.3.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-bottom:10.0pt;\">\n<span id=\"S4.T3.3.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.3.3.1.1.1\" class=\"ltx_p\" style=\"width:150.8pt;\"><math id=\"S4.T3.3.3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathtt{\\dfrac{2TP}{2TP+FP+FN}}\" display=\"inline\"><semantics id=\"S4.T3.3.3.1.1.1.m1.1a\"><mstyle displaystyle=\"true\" id=\"S4.T3.3.3.1.1.1.m1.1.1\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.cmml\"><mfrac id=\"S4.T3.3.3.1.1.1.m1.1.1a\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.cmml\"><mrow id=\"S4.T3.3.3.1.1.1.m1.1.1.2\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2.cmml\"><mn id=\"S4.T3.3.3.1.1.1.m1.1.1.2.2\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2.2.cmml\">𝟸</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.3.3.1.1.1.m1.1.1.2.1\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2.1.cmml\">​</mo><mi id=\"S4.T3.3.3.1.1.1.m1.1.1.2.3\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2.3.cmml\">𝚃</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.3.3.1.1.1.m1.1.1.2.1a\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2.1.cmml\">​</mo><mi id=\"S4.T3.3.3.1.1.1.m1.1.1.2.4\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2.4.cmml\">𝙿</mi></mrow><mrow id=\"S4.T3.3.3.1.1.1.m1.1.1.3\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.cmml\"><mrow id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.cmml\"><mn id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.2\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.2.cmml\">𝟸</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.1\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.1.cmml\">​</mo><mi id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.3\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.3.cmml\">𝚃</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.1a\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.1.cmml\">​</mo><mi id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.4\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.4.cmml\">𝙿</mi></mrow><mo id=\"S4.T3.3.3.1.1.1.m1.1.1.3.1\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.1.cmml\">+</mo><mi id=\"S4.T3.3.3.1.1.1.m1.1.1.3.3\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.3.cmml\">𝙵𝙿</mi><mo id=\"S4.T3.3.3.1.1.1.m1.1.1.3.1a\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.1.cmml\">+</mo><mi id=\"S4.T3.3.3.1.1.1.m1.1.1.3.4\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.4.cmml\">𝙵𝙽</mi></mrow></mfrac></mstyle><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.3.3.1.1.1.m1.1b\"><apply id=\"S4.T3.3.3.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1\"><divide id=\"S4.T3.3.3.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1\"></divide><apply id=\"S4.T3.3.3.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2\"><times id=\"S4.T3.3.3.1.1.1.m1.1.1.2.1.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2.1\"></times><cn type=\"integer\" id=\"S4.T3.3.3.1.1.1.m1.1.1.2.2.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2.2\">2</cn><ci id=\"S4.T3.3.3.1.1.1.m1.1.1.2.3.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2.3\">𝚃</ci><ci id=\"S4.T3.3.3.1.1.1.m1.1.1.2.4.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.2.4\">𝙿</ci></apply><apply id=\"S4.T3.3.3.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3\"><plus id=\"S4.T3.3.3.1.1.1.m1.1.1.3.1.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.1\"></plus><apply id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2\"><times id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.1.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.1\"></times><cn type=\"integer\" id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.2.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.2\">2</cn><ci id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.3.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.3\">𝚃</ci><ci id=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.4.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.2.4\">𝙿</ci></apply><ci id=\"S4.T3.3.3.1.1.1.m1.1.1.3.3.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.3\">𝙵𝙿</ci><ci id=\"S4.T3.3.3.1.1.1.m1.1.1.3.4.cmml\" xref=\"S4.T3.3.3.1.1.1.m1.1.1.3.4\">𝙵𝙽</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.3.3.1.1.1.m1.1c\">\\mathtt{\\dfrac{2TP}{2TP+FP+FN}}</annotation></semantics></math></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-bottom:10.0pt;\">MCC</td>\n<td id=\"S4.T3.4.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-bottom:10.0pt;\">\n<span id=\"S4.T3.4.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.4.1.1.1\" class=\"ltx_p\" style=\"width:150.8pt;\"><math id=\"S4.T3.4.4.1.1.1.m1.4\" class=\"ltx_Math\" alttext=\"\\mathtt{\\dfrac{TP\\times TN-FP\\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}}\" display=\"inline\"><semantics id=\"S4.T3.4.4.1.1.1.m1.4a\"><mstyle displaystyle=\"true\" id=\"S4.T3.4.4.1.1.1.m1.4.4\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.cmml\"><mfrac id=\"S4.T3.4.4.1.1.1.m1.4.4a\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.cmml\"><mrow id=\"S4.T3.4.4.1.1.1.m1.4.4.6\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.cmml\"><mrow id=\"S4.T3.4.4.1.1.1.m1.4.4.6.2\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.cmml\"><mi id=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.2\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.2.cmml\">𝚃𝙿</mi><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.1\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.1.cmml\">×</mo><mi id=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.3\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.3.cmml\">𝚃𝙽</mi></mrow><mo id=\"S4.T3.4.4.1.1.1.m1.4.4.6.1\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.1.cmml\">−</mo><mrow id=\"S4.T3.4.4.1.1.1.m1.4.4.6.3\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.cmml\"><mi id=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.2\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.2.cmml\">𝙵𝙿</mi><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.1\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.1.cmml\">×</mo><mi id=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.3\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.3.cmml\">𝙵𝙽</mi></mrow></mrow><msqrt id=\"S4.T3.4.4.1.1.1.m1.4.4.4\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.cmml\"><mrow id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.cmml\"><mrow id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.cmml\"><mo stretchy=\"false\" id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.2\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.2\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.2.cmml\">𝚃𝙿</mi><mo id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.1\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\">+</mo><mi id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.3\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.3.cmml\">𝙵𝙿</mi></mrow><mo stretchy=\"false\" id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.3\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.cmml\">)</mo></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.5\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.5.cmml\">​</mo><mrow id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.cmml\"><mo stretchy=\"false\" id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.2\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.cmml\">(</mo><mrow id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.cmml\"><mi id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.2\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.2.cmml\">𝚃𝙿</mi><mo id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.1\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.1.cmml\">+</mo><mi id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.3\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.3.cmml\">𝙵𝙽</mi></mrow><mo stretchy=\"false\" id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.3\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.cmml\">)</mo></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.5a\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.5.cmml\">​</mo><mrow id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.cmml\"><mo stretchy=\"false\" id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.2\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.cmml\">(</mo><mrow id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.cmml\"><mi id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.2\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.2.cmml\">𝚃𝙽</mi><mo id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.1\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.1.cmml\">+</mo><mi id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.3\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.3.cmml\">𝙵𝙿</mi></mrow><mo stretchy=\"false\" id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.3\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.cmml\">)</mo></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.5b\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.5.cmml\">​</mo><mrow id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.cmml\"><mo stretchy=\"false\" id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.2\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.cmml\">(</mo><mrow id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.cmml\"><mi id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.2\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.2.cmml\">𝚃𝙽</mi><mo id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.1\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.1.cmml\">+</mo><mi id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.3\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.3.cmml\">𝙵𝙽</mi></mrow><mo stretchy=\"false\" id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.3\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.cmml\">)</mo></mrow></mrow></msqrt></mfrac></mstyle><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.4.4.1.1.1.m1.4b\"><apply id=\"S4.T3.4.4.1.1.1.m1.4.4.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4\"><divide id=\"S4.T3.4.4.1.1.1.m1.4.4.5.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4\"></divide><apply id=\"S4.T3.4.4.1.1.1.m1.4.4.6.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6\"><minus id=\"S4.T3.4.4.1.1.1.m1.4.4.6.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.1\"></minus><apply id=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.2\"><times id=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.1\"></times><ci id=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.2.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.2\">𝚃𝙿</ci><ci id=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.3.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.2.3\">𝚃𝙽</ci></apply><apply id=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.3\"><times id=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.1\"></times><ci id=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.2.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.2\">𝙵𝙿</ci><ci id=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.3.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.6.3.3\">𝙵𝙽</ci></apply></apply><apply id=\"S4.T3.4.4.1.1.1.m1.4.4.4.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4\"><root id=\"S4.T3.4.4.1.1.1.m1.4.4.4a.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4\"></root><apply id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4\"><times id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.5.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.5\"></times><apply id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1\"><plus id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.1\"></plus><ci id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.2\">𝚃𝙿</ci><ci id=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.3\">𝙵𝙿</ci></apply><apply id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1\"><plus id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.1\"></plus><ci id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.2.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.2\">𝚃𝙿</ci><ci id=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.3.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.2.2.2.2.2.2.1.1.3\">𝙵𝙽</ci></apply><apply id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1\"><plus id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.1\"></plus><ci id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.2.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.2\">𝚃𝙽</ci><ci id=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.3.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.3.3.3.3.3.3.1.1.3\">𝙵𝙿</ci></apply><apply id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1\"><plus id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.1.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.1\"></plus><ci id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.2.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.2\">𝚃𝙽</ci><ci id=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.3.cmml\" xref=\"S4.T3.4.4.1.1.1.m1.4.4.4.4.4.4.1.1.3\">𝙵𝙽</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.4.4.1.1.1.m1.4c\">\\mathtt{\\dfrac{TP\\times TN-FP\\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}}</annotation></semantics></math></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.4.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.6.1\" class=\"ltx_td ltx_align_center\" style=\"padding-bottom:10.0pt;\">AUC</td>\n<td id=\"S4.T3.4.6.2\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-bottom:10.0pt;\">\n<span id=\"S4.T3.4.6.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.6.2.1.1\" class=\"ltx_p\" style=\"width:150.8pt;\">The area enclosed by the ROC curve and the reference line</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.4.7\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-bottom:10.0pt;\">Stability</td>\n<td id=\"S4.T3.4.7.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" style=\"padding-bottom:10.0pt;\">\n<span id=\"S4.T3.4.7.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.7.2.1.1\" class=\"ltx_p\" style=\"width:150.8pt;\">The tendency of accuracy for N groups of random selected continuous data group.</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "MSA is one of the commonly used analysis methods in manufacturing Montgomery (2007). The learning-based failure prediction method can be seen as a product quality measurement system. Taking the Bosch company’s product quality testing results as a benchmark, we can analyze the FL and CL algorithms through the MSA method. The evaluation measurements in MSA mainly include Accuracy (ACC), Precision (PRE), and Stability. On this basis, F1, AUC, and Matthew’s Correlation Coefficient (MCC) are also involved. The six measurements we use in the empirical study are provided in Table 3, where P represents the number of GT positive cases, N is the number of GT negative cases, TP (hit) is true positive, TN (correct rejection) is true negative, FP (false alarm) is false positive, and FN (miss) is false negative."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Bosch dataset",
        "table": "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T4.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\"><span id=\"S4.T4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Sample Num (1184687)</span></td>\n<td id=\"S4.T4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\"><span id=\"S4.T4.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Features Num (968)</span></td>\n</tr>\n<tr id=\"S4.T4.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.2.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.2.1.1\" class=\"ltx_text ltx_font_bold\">Positive</span></td>\n<td id=\"S4.T4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T4.1.2.2.1\" class=\"ltx_text ltx_font_bold\">Negative</span></td>\n<td id=\"S4.T4.1.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.2.3.1\" class=\"ltx_text ltx_font_bold\">L0</span></td>\n<td id=\"S4.T4.1.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.2.4.1\" class=\"ltx_text ltx_font_bold\">L1</span></td>\n<td id=\"S4.T4.1.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.2.5.1\" class=\"ltx_text ltx_font_bold\">L2</span></td>\n<td id=\"S4.T4.1.2.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.2.6.1\" class=\"ltx_text ltx_font_bold\">L3</span></td>\n</tr>\n<tr id=\"S4.T4.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">1177808</td>\n<td id=\"S4.T4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">6879</td>\n<td id=\"S4.T4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">168</td>\n<td id=\"S4.T4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">513</td>\n<td id=\"S4.T4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">42</td>\n<td id=\"S4.T4.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">245</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The data features are shown in Table 4. There are 1184687 products in the dataset, including 1177808 positive samples (Pos) and 6879 negative ones (Neg). In the feature space, the dataset has 968 features. These features are collected from 51 workstations (S1-S51) on 4 production lines L0-L3 that contain 168, 513, 42, and 245 features, respectively. L1_S24_F1695 indicates that the feature No.1695 was observed at the No.24 workstation of the L1 production line. The label Response represents whether the final product is qualified (label = 0) or not (label = 1). From the perspective of data items, only a few items (0.58%) in the dataset result are qualified, and the data is extremely unbalanced. The data is also extremely sparse, with only a few workstations collecting data from most products Carbery et al. (2019)."
        ]
    },
    "S4.T5": {
        "caption": "Table 5: Data Description of HFL Scenario",
        "table": "<table id=\"S4.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T5.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T5.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Sample Num.</span></td>\n<td id=\"S4.T5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T5.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Positive</span></td>\n<td id=\"S4.T5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T5.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Negative</span></td>\n<td id=\"S4.T5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T5.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Feature Num.</span></td>\n</tr>\n<tr id=\"S4.T5.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T5.1.2.1.1\" class=\"ltx_text ltx_font_bold\">Total</span></td>\n<td id=\"S4.T5.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">12000</td>\n<td id=\"S4.T5.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">6000</td>\n<td id=\"S4.T5.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"2\"><span id=\"S4.T5.1.2.4.1\" class=\"ltx_text\">713 selected</span></td>\n</tr>\n<tr id=\"S4.T5.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.1.3.1.1\" class=\"ltx_text ltx_font_bold\">Per client</span></td>\n<td id=\"S4.T5.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">3000</td>\n<td id=\"S4.T5.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">1500</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "To compare FedSVM and SVM on the testing data, we form four workshops A, B, C, and D that do not share manufacturing data but have the same structure and configuration of the production line. Under the premise that the product features are aligned, they contain different samples, and each sample has a unique ID. Each workshop can be regarded as an independent client. Table 5 shows the data used in this experiment. The number of samples on the 4 clients is basically the same. In the experiment, the data set is randomly distributed to all clients on average, each of which possesses 3000 positive and 1500 negative samples. The four workshops have 713 common features of data."
        ]
    },
    "S4.T6": {
        "caption": "Table 6: Data Description for VFL Scenario",
        "table": "<table id=\"S4.T6.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T6.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T6.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Sample Num</span></td>\n<td id=\"S4.T6.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T6.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Positive</span></td>\n<td id=\"S4.T6.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T6.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Negative</span></td>\n<td id=\"S4.T6.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"S4.T6.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Feature Num</span></td>\n</tr>\n<tr id=\"S4.T6.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.1.2.1.1\" class=\"ltx_text ltx_font_bold\">Total</span></td>\n<td id=\"S4.T6.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"3\"><span id=\"S4.T6.1.2.2.1\" class=\"ltx_text\">12000</span></td>\n<td id=\"S4.T6.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"3\"><span id=\"S4.T6.1.2.3.1\" class=\"ltx_text\">6000</span></td>\n<td id=\"S4.T6.1.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">44 (F1 - F44)</td>\n</tr>\n<tr id=\"S4.T6.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.3.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T6.1.3.1.1\" class=\"ltx_text ltx_font_bold\">Client O1</span></td>\n<td id=\"S4.T6.1.3.2\" class=\"ltx_td ltx_align_left\">22 (F1 - F22)</td>\n</tr>\n<tr id=\"S4.T6.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T6.1.4.1.1\" class=\"ltx_text ltx_font_bold\">Client O2</span></td>\n<td id=\"S4.T6.1.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">22 (F23 - F44)</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "To compare FedRF and RF on the given testing data, it is assumed that the first three production lines (L0, L1, L2) of the Bosch dataset belong to the same organization O1, and the L3 production line belongs to another organization O2. O1 and O2 are independent. Since the samples in O1 and O2 have the same ID and different characteristics, VFL is applied. The data set used in the FedRF experiment is shown in Table 6. We extract the features belonging to L0, L1, and L2 as a group, and the features belonging to L3 as another group. Then we perform principal component analysis (PCA) to reduce the feature dimension in O1/O2 from 723/245 to 22/22, respectively. According to the overall analysis of PCA results, the first 22 dimensions can represent more than 95% of the variance, so reducing to 22 dimensions, respectively, which will not cause too much information loss Zhang et al. (2016). The positive and negative sample numbers are 12000 and 6000, respectively."
        ]
    },
    "S5.T7": {
        "caption": "Table 7: Experiment Results of RQ1 on FedSVM/SVM",
        "table": "<table id=\"S5.T7.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T7.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T7.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T7.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Algo.</span></td>\n<td id=\"S5.T7.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T7.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">ACC</span></td>\n<td id=\"S5.T7.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T7.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">PRE</span></td>\n<td id=\"S5.T7.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T7.1.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">F1</span></td>\n<td id=\"S5.T7.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T7.1.1.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">MCC</span></td>\n<td id=\"S5.T7.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T7.1.1.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">AUC</span></td>\n<td id=\"S5.T7.1.1.7\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T7.1.1.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T7.1.1.7.1.1\" class=\"ltx_p\" style=\"width:22.8pt;\"><span id=\"S5.T7.1.1.7.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Stab. (Var)</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T7.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T7.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T7.1.2.1.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:70%;\">FedSVM</span></td>\n<td id=\"S5.T7.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T7.1.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.825</span></td>\n<td id=\"S5.T7.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T7.1.2.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.859</span></td>\n<td id=\"S5.T7.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T7.1.2.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.869</span></td>\n<td id=\"S5.T7.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T7.1.2.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.607</span></td>\n<td id=\"S5.T7.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T7.1.2.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.807</span></td>\n<td id=\"S5.T7.1.2.7\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T7.1.2.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T7.1.2.7.1.1\" class=\"ltx_p\" style=\"width:22.8pt;\"><span id=\"S5.T7.1.2.7.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.005</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T7.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T7.1.3.1\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T7.1.3.1.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:70%;\">SVM</span></td>\n<td id=\"S5.T7.1.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T7.1.3.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.859</span></td>\n<td id=\"S5.T7.1.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T7.1.3.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.828</span></td>\n<td id=\"S5.T7.1.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T7.1.3.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.903</span></td>\n<td id=\"S5.T7.1.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T7.1.3.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.690</span></td>\n<td id=\"S5.T7.1.3.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T7.1.3.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.902</span></td>\n<td id=\"S5.T7.1.3.7\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T7.1.3.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T7.1.3.7.1.1\" class=\"ltx_p\" style=\"width:22.8pt;\"><span id=\"S5.T7.1.3.7.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.003</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T7.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T7.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.1.4.1.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:70%;\">Diff</span></td>\n<td id=\"S5.T7.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.1.4.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">-0.034</span></td>\n<td id=\"S5.T7.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.1.4.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.031</span></td>\n<td id=\"S5.T7.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.1.4.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">-0.046</span></td>\n<td id=\"S5.T7.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.1.4.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">-0.083</span></td>\n<td id=\"S5.T7.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.1.4.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">-0.095</span></td>\n<td id=\"S5.T7.1.4.7\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T7.1.4.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T7.1.4.7.1.1\" class=\"ltx_p\" style=\"width:22.8pt;\"><span id=\"S5.T7.1.4.7.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.002</span></span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 7 shows the experimental results. To ensure that the data set and the algorithm kernel are consistent, the baseline is the result of FedSVM when the number of clients is set to 1, ie., FedSVM degenerates into SVM. Under this premise, the results of FedSVM and SVM are compared. When analyzing the stability, the experiment data is ordered by time-series and then divided into 10 groups on average. The measurements of each group are calculated. The overall results of stability are shown in Fig. 5. The average value of stability is above 0.7 for FedSVM and SVM. The variance of the stability is given as Stability (Var) in Table 7.",
            "In Figure 5, FedSVM performs slightly better than SVM on two test groups, namely 1 and 7. Similar results are also shown for the Precision measure in Table 7. This effect is only shown in the HFL scenario, where the clients contribute local data features to the central server. If the amount of data on each client is small, FL’s effect can be better than CL because FL expands the number of IID data samples in the HFL scenario."
        ]
    },
    "S5.T8": {
        "caption": "Table 8: Experiment Results of RQ1 on FedRF/RF",
        "table": "<table id=\"S5.T8.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T8.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T8.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T8.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Algo.</span></td>\n<td id=\"S5.T8.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T8.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">ACC</span></td>\n<td id=\"S5.T8.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T8.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">PRE</span></td>\n<td id=\"S5.T8.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T8.1.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">F1</span></td>\n<td id=\"S5.T8.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T8.1.1.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">MCC</span></td>\n<td id=\"S5.T8.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T8.1.1.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">AUC</span></td>\n<td id=\"S5.T8.1.1.7\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T8.1.1.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T8.1.1.7.1.1\" class=\"ltx_p\" style=\"width:22.8pt;\"><span id=\"S5.T8.1.1.7.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Stab. (Var)</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T8.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T8.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T8.1.2.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">FedRF</span></td>\n<td id=\"S5.T8.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T8.1.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.843</span></td>\n<td id=\"S5.T8.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T8.1.2.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.808</span></td>\n<td id=\"S5.T8.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T8.1.2.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.894</span></td>\n<td id=\"S5.T8.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T8.1.2.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.659</span></td>\n<td id=\"S5.T8.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T8.1.2.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.902</span></td>\n<td id=\"S5.T8.1.2.7\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T8.1.2.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T8.1.2.7.1.1\" class=\"ltx_p\" style=\"width:22.8pt;\"><span id=\"S5.T8.1.2.7.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.004</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T8.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T8.1.3.1\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T8.1.3.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">RF</span></td>\n<td id=\"S5.T8.1.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T8.1.3.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.868</span></td>\n<td id=\"S5.T8.1.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T8.1.3.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.836</span></td>\n<td id=\"S5.T8.1.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T8.1.3.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.909</span></td>\n<td id=\"S5.T8.1.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T8.1.3.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.713</span></td>\n<td id=\"S5.T8.1.3.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T8.1.3.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.912</span></td>\n<td id=\"S5.T8.1.3.7\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T8.1.3.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T8.1.3.7.1.1\" class=\"ltx_p\" style=\"width:22.8pt;\"><span id=\"S5.T8.1.3.7.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.002</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T8.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T8.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T8.1.4.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Diff</span></td>\n<td id=\"S5.T8.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T8.1.4.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">-0.025</span></td>\n<td id=\"S5.T8.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T8.1.4.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">-0.028</span></td>\n<td id=\"S5.T8.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T8.1.4.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">-0.015</span></td>\n<td id=\"S5.T8.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T8.1.4.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">-0.054</span></td>\n<td id=\"S5.T8.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T8.1.4.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">-0.010</span></td>\n<td id=\"S5.T8.1.4.7\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T8.1.4.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T8.1.4.7.1.1\" class=\"ltx_p\" style=\"width:22.8pt;\"><span id=\"S5.T8.1.4.7.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.002</span></span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The experimental results are shown in Table 8. FedRF degenerates into RF by combining two clients so that the effect of FedRF and RF can be compared under the premise of ensuring the consistency of the testing data and the algorithm kernel. When analyzing the stability, the test set is divided into 10 groups on average according to the time-series, and the measurements of each group are calculated. The variance of the stability is given in Table 8, and the overall results of stability are shown in Fig. 6."
        ]
    },
    "S5.T9": {
        "caption": "Table 9: Experiment Results of RQ3 on FedSVM/SVM ",
        "table": "<table id=\"S5.T9.sf1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T9.sf1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.1.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">State</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.1.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.1.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf1.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.1.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf1.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf1.1.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf1.1.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.2.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf1.1.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.2.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.882</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf1.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.2.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.113</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf1.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.2.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.005</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf1.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf1.1.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.715</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.280</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.005</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf1.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf1.1.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf1.1.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.4.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf1.1.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.4.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.813</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf1.1.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.4.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.062</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.4.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf1.1.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.4.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.125</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We first constructed a timed state sequence indicating the prediction error using FedSVM and SVM, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table ",
                "LABEL:tab:RQ3-SVM_resa",
                " and ",
                "LABEL:tab:RQ3-SVM_resa",
                ". The value difference between each pair of parameters is calculated in Table ",
                "LABEL:tab:RQ3-SVM_resc",
                ".\nThe average difference value between each pair of parameters is 0.054. The maximum difference value is 0.096. It means that there exists no significant difference between the two Markov models, and the prediction error between FedSVM and SVM are almost equally distributed on the estimated unknown Bosch data. Therefore, ",
                "the performance of FedSVM and SVM in the subsequent Bosch production was not significantly different."
            ]
        ]
    },
    "S5.T9.sf1": {
        "caption": "(a) Markov Model Parameters of Prediction Error using FedSVM",
        "table": "<table id=\"S5.T9.sf1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T9.sf1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.1.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">State</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.1.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.1.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf1.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.1.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf1.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf1.1.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf1.1.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.2.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf1.1.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.2.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.882</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf1.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.2.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.113</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf1.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.2.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.005</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf1.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf1.1.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.715</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.280</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.3.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.005</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf1.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf1.1.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf1.1.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.4.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf1.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf1.1.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.4.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.813</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf1.1.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.4.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.062</span>\n</span>\n</td>\n<td id=\"S5.T9.sf1.1.4.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf1.1.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf1.1.4.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.125</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Bosch is one of the worldwide leading manufacturing companies. It ensures high quality of the production by monitoring its parts in the manufacturing processes. Because Bosch records detailed data for each step on the assembly lines, they can apply advanced techniques to improve the manufacturing processes. To this end, Bosch has published a dataset on the Kaggle competition platform to predict internal failures by thousands of measurements and tests made for each component along the assembly line. Some studies have analyzed the dataset and carried out approaches to predicting product quality based on CL algorithms excluding time-series features Carbery et al. (2019, 2018); Zhang et al. (2016); Khoza and Grobler (2019); Kotenko et al. (2019); Mangal and Kumar (2016); Hebert (2016); Maurya (2016) or including time-series features Huang et al. (2019b); Moldovan et al. (2019); Liu et al. (2020d), as summarized in Table 1. These works were conducted based on a set of learning methods, including Logistic Regression (LR), Gradient Boosting Machine (GBM), Random Forest (RF), Gradient Boosted Trees (GBT), Naive Bayes (NB), Bayesian Network (BN), K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Multilayer Perceptron Classifier (MPC), Majority Voting (MV), Decision Tree (DT), Statistical Process Control (SPC), etc.",
            "As a supervised learning algorithm, SVM is suitable for classification and regression analysis. The effectiveness of SVM mainly depends on how to select 1) the kernel, 2) the kernel’s parameters, and 3) the soft margin parameter. In this work, we use FedSVM with a linear kernel. SVM specifies parameters and intercepts, which can be directly weighted. In FL, the SVM models generated on different clients can be integrated by averaging the parameters and intercepts to meet the need of the server. The FedSVM algorithm is first proposed in Bakopoulou et al. (2019) for mobile packet classification. We have adapted their FedSVM to our failure prediction problem. Its training process is shown in Fig. 1. The algorithm of the client and server is given by Algo. 1 and Algo. 2, respectively. The main steps of FedSVM are explained hereafter.",
            "We have experimented to evaluate the improvement of FedRF.\nIn this experiment, we constructed a VFL scenario with two clients sharing data features using the Bosch dataset. There are 50 independent features in each client, which are extracted after performing the principal component analysis (PCA) from different production lines and the same 11154 samples. The experiment results are shown in Table 2.\nIt can be seen that we get better prediction results than the federated random forest algorithm proposed in Liu et al. (2020a).",
            "S1. Construct prediction table. We first construct a prediction table containing the ground truth (GT) label, the prediction results (Pre) of CL and FL algorithms of products ordered by timestamp (ts).",
            "MSA is one of the commonly used analysis methods in manufacturing Montgomery (2007). The learning-based failure prediction method can be seen as a product quality measurement system. Taking the Bosch company’s product quality testing results as a benchmark, we can analyze the FL and CL algorithms through the MSA method. The evaluation measurements in MSA mainly include Accuracy (ACC), Precision (PRE), and Stability. On this basis, F1, AUC, and Matthew’s Correlation Coefficient (MCC) are also involved. The six measurements we use in the empirical study are provided in Table 3, where P represents the number of GT positive cases, N is the number of GT negative cases, TP (hit) is true positive, TN (correct rejection) is true negative, FP (false alarm) is false positive, and FN (miss) is false negative.",
            "MCC is suitable for evaluating the prediction results of unbalanced data. AUC is a commonly used two-category evaluation method, and its value is the area enclosed by the ROC curve and the reference line. The x-axis of a ROC curve is the false positive rate, and the y-axis of a ROC curve is the true positive rate. It shows the relationship between clinical sensitivity and specificity for every possible cut-off. It is a graph with: The x-axis showing 1-specificity (=𝙵𝙿/(𝙵𝙿+𝚃𝙽)absent𝙵𝙿𝙵𝙿𝚃𝙽\\mathtt{=FP/(FP+TN)}) The y-axis showing sensitivity (=𝚃𝙿/(𝚃𝙿+𝙵𝙽)absent𝚃𝙿𝚃𝙿𝙵𝙽\\mathtt{=TP/(TP+FN)}). The range of AUC value is between 0 and 1.",
            "The data features are shown in Table 4. There are 1184687 products in the dataset, including 1177808 positive samples (Pos) and 6879 negative ones (Neg). In the feature space, the dataset has 968 features. These features are collected from 51 workstations (S1-S51) on 4 production lines L0-L3 that contain 168, 513, 42, and 245 features, respectively. L1_S24_F1695 indicates that the feature No.1695 was observed at the No.24 workstation of the L1 production line. The label Response represents whether the final product is qualified (label = 0) or not (label = 1). From the perspective of data items, only a few items (0.58%) in the dataset result are qualified, and the data is extremely unbalanced. The data is also extremely sparse, with only a few workstations collecting data from most products Carbery et al. (2019).",
            "To compare FedSVM and SVM on the testing data, we form four workshops A, B, C, and D that do not share manufacturing data but have the same structure and configuration of the production line. Under the premise that the product features are aligned, they contain different samples, and each sample has a unique ID. Each workshop can be regarded as an independent client. Table 5 shows the data used in this experiment. The number of samples on the 4 clients is basically the same. In the experiment, the data set is randomly distributed to all clients on average, each of which possesses 3000 positive and 1500 negative samples. The four workshops have 713 common features of data.",
            "To compare FedRF and RF on the given testing data, it is assumed that the first three production lines (L0, L1, L2) of the Bosch dataset belong to the same organization O1, and the L3 production line belongs to another organization O2. O1 and O2 are independent. Since the samples in O1 and O2 have the same ID and different characteristics, VFL is applied. The data set used in the FedRF experiment is shown in Table 6. We extract the features belonging to L0, L1, and L2 as a group, and the features belonging to L3 as another group. Then we perform principal component analysis (PCA) to reduce the feature dimension in O1/O2 from 723/245 to 22/22, respectively. According to the overall analysis of PCA results, the first 22 dimensions can represent more than 95% of the variance, so reducing to 22 dimensions, respectively, which will not cause too much information loss Zhang et al. (2016). The positive and negative sample numbers are 12000 and 6000, respectively.",
            "Table 7 shows the experimental results. To ensure that the data set and the algorithm kernel are consistent, the baseline is the result of FedSVM when the number of clients is set to 1, ie., FedSVM degenerates into SVM. Under this premise, the results of FedSVM and SVM are compared. When analyzing the stability, the experiment data is ordered by time-series and then divided into 10 groups on average. The measurements of each group are calculated. The overall results of stability are shown in Fig. 5. The average value of stability is above 0.7 for FedSVM and SVM. The variance of the stability is given as Stability (Var) in Table 7.",
            "In Figure 5, FedSVM performs slightly better than SVM on two test groups, namely 1 and 7. Similar results are also shown for the Precision measure in Table 7. This effect is only shown in the HFL scenario, where the clients contribute local data features to the central server. If the amount of data on each client is small, FL’s effect can be better than CL because FL expands the number of IID data samples in the HFL scenario.",
            "The experimental results are shown in Table 8. FedRF degenerates into RF by combining two clients so that the effect of FedRF and RF can be compared under the premise of ensuring the consistency of the testing data and the algorithm kernel. When analyzing the stability, the test set is divided into 10 groups on average according to the time-series, and the measurements of each group are calculated. The variance of the stability is given in Table 8, and the overall results of stability are shown in Fig. 6.",
            "We first constructed a timed state sequence indicating the prediction error using FedSVM and SVM, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-SVM_resa and LABEL:tab:RQ3-SVM_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-SVM_resc.\nThe average difference value between each pair of parameters is 0.054. The maximum difference value is 0.096. It means that there exists no significant difference between the two Markov models, and the prediction error between FedSVM and SVM are almost equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedSVM and SVM in the subsequent Bosch production was not significantly different.",
            "We first constructed a timed state sequence indicating the prediction error using FedRF and RF, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-RF_resa and LABEL:tab:RQ3-RF_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-RF_resc.\nThe average difference value between each pair of parameters is 0.035. The maximum difference value is 0.100. It means that there exists no significant difference between the two Markov models, and the prediction error between FedRF and RF are equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedRF and RF in the subsequent Bosch production was not significantly different.",
            "The experimental results are shown in Table 11. There are outliers in the test results, so the sum of the samples in each cluster is less than 100. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedSVM is heterogeneous. It enforces the conclusion that FedSVM and SVM have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "The experimental results are shown in Table 12. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedRF is heterogeneous. It enforces the conclusion that FedRF and RF have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "Another threat to construct validity is the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2) used in the experiment. In the industry, the threshold value is set according to the production needs. We have performed a hypothesis test for the difference between the two approaches’ performances to explain that the difference between FL and CL is within the threshold. The original hypothesis H0 is difference >δabsent𝛿>\\delta, and the alternative hypothesis H1 is difference <δabsent𝛿<\\delta, where the difference = CL – FL on the same random partial testing data group. Suppose α𝛼\\alpha = 0.05. The p-value of the evaluation metrics for FedSVM vs. SVM and FedForest vs. RForest is shown in Table 13 and Table 14, respectively. As a​l​p​h​a>𝑎𝑙𝑝ℎ𝑎absentalpha> p-value for all metrics, the alternative hypothesis H1 is accepted, which means that the difference between CL and FL is less than the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2).",
            "Besides, some works have shown that the effect of FL is also related to encryption algorithms R et al. (2019); Tao et al. (2020); Feng et al. (2020); Olivia et al. (2019); Lu et al. (2020); Li et al. (2019, 2020b). If the encryption strength increases, the information loss on the data will be worse. So that the effect of FL decreases. The trade-off between data privacy protection and the accuracy of the trained model is still inevitable. It is still considered an open question of how the effect of FL is related to other factors."
        ]
    },
    "S5.T9.sf2": {
        "caption": "(b) Markov Model Parameters of Prediction Error using SVM ",
        "table": "<table id=\"S5.T9.sf2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T9.sf2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf2.1.1.1\" class=\"ltx_td ltx_align_top ltx_border_tt\"></td>\n<td id=\"S5.T9.sf2.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf2.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.1.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf2.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf2.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.1.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf2.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf2.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.1.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf2.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf2.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf2.1.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf2.1.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.2.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf2.1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf2.1.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.2.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.851</span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf2.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.2.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.077</span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf2.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.2.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.072</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf2.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf2.1.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf2.1.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.3.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf2.1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf2.1.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.3.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.690</span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf2.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.3.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.225</span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf2.1.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.3.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.085</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf2.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf2.1.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf2.1.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.4.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf2.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf2.1.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.4.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.717</span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf2.1.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.4.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.125</span>\n</span>\n</td>\n<td id=\"S5.T9.sf2.1.4.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf2.1.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf2.1.4.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.158</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Bosch is one of the worldwide leading manufacturing companies. It ensures high quality of the production by monitoring its parts in the manufacturing processes. Because Bosch records detailed data for each step on the assembly lines, they can apply advanced techniques to improve the manufacturing processes. To this end, Bosch has published a dataset on the Kaggle competition platform to predict internal failures by thousands of measurements and tests made for each component along the assembly line. Some studies have analyzed the dataset and carried out approaches to predicting product quality based on CL algorithms excluding time-series features Carbery et al. (2019, 2018); Zhang et al. (2016); Khoza and Grobler (2019); Kotenko et al. (2019); Mangal and Kumar (2016); Hebert (2016); Maurya (2016) or including time-series features Huang et al. (2019b); Moldovan et al. (2019); Liu et al. (2020d), as summarized in Table 1. These works were conducted based on a set of learning methods, including Logistic Regression (LR), Gradient Boosting Machine (GBM), Random Forest (RF), Gradient Boosted Trees (GBT), Naive Bayes (NB), Bayesian Network (BN), K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Multilayer Perceptron Classifier (MPC), Majority Voting (MV), Decision Tree (DT), Statistical Process Control (SPC), etc.",
            "As a supervised learning algorithm, SVM is suitable for classification and regression analysis. The effectiveness of SVM mainly depends on how to select 1) the kernel, 2) the kernel’s parameters, and 3) the soft margin parameter. In this work, we use FedSVM with a linear kernel. SVM specifies parameters and intercepts, which can be directly weighted. In FL, the SVM models generated on different clients can be integrated by averaging the parameters and intercepts to meet the need of the server. The FedSVM algorithm is first proposed in Bakopoulou et al. (2019) for mobile packet classification. We have adapted their FedSVM to our failure prediction problem. Its training process is shown in Fig. 1. The algorithm of the client and server is given by Algo. 1 and Algo. 2, respectively. The main steps of FedSVM are explained hereafter.",
            "We have experimented to evaluate the improvement of FedRF.\nIn this experiment, we constructed a VFL scenario with two clients sharing data features using the Bosch dataset. There are 50 independent features in each client, which are extracted after performing the principal component analysis (PCA) from different production lines and the same 11154 samples. The experiment results are shown in Table 2.\nIt can be seen that we get better prediction results than the federated random forest algorithm proposed in Liu et al. (2020a).",
            "S1. Construct prediction table. We first construct a prediction table containing the ground truth (GT) label, the prediction results (Pre) of CL and FL algorithms of products ordered by timestamp (ts).",
            "MSA is one of the commonly used analysis methods in manufacturing Montgomery (2007). The learning-based failure prediction method can be seen as a product quality measurement system. Taking the Bosch company’s product quality testing results as a benchmark, we can analyze the FL and CL algorithms through the MSA method. The evaluation measurements in MSA mainly include Accuracy (ACC), Precision (PRE), and Stability. On this basis, F1, AUC, and Matthew’s Correlation Coefficient (MCC) are also involved. The six measurements we use in the empirical study are provided in Table 3, where P represents the number of GT positive cases, N is the number of GT negative cases, TP (hit) is true positive, TN (correct rejection) is true negative, FP (false alarm) is false positive, and FN (miss) is false negative.",
            "MCC is suitable for evaluating the prediction results of unbalanced data. AUC is a commonly used two-category evaluation method, and its value is the area enclosed by the ROC curve and the reference line. The x-axis of a ROC curve is the false positive rate, and the y-axis of a ROC curve is the true positive rate. It shows the relationship between clinical sensitivity and specificity for every possible cut-off. It is a graph with: The x-axis showing 1-specificity (=𝙵𝙿/(𝙵𝙿+𝚃𝙽)absent𝙵𝙿𝙵𝙿𝚃𝙽\\mathtt{=FP/(FP+TN)}) The y-axis showing sensitivity (=𝚃𝙿/(𝚃𝙿+𝙵𝙽)absent𝚃𝙿𝚃𝙿𝙵𝙽\\mathtt{=TP/(TP+FN)}). The range of AUC value is between 0 and 1.",
            "The data features are shown in Table 4. There are 1184687 products in the dataset, including 1177808 positive samples (Pos) and 6879 negative ones (Neg). In the feature space, the dataset has 968 features. These features are collected from 51 workstations (S1-S51) on 4 production lines L0-L3 that contain 168, 513, 42, and 245 features, respectively. L1_S24_F1695 indicates that the feature No.1695 was observed at the No.24 workstation of the L1 production line. The label Response represents whether the final product is qualified (label = 0) or not (label = 1). From the perspective of data items, only a few items (0.58%) in the dataset result are qualified, and the data is extremely unbalanced. The data is also extremely sparse, with only a few workstations collecting data from most products Carbery et al. (2019).",
            "To compare FedSVM and SVM on the testing data, we form four workshops A, B, C, and D that do not share manufacturing data but have the same structure and configuration of the production line. Under the premise that the product features are aligned, they contain different samples, and each sample has a unique ID. Each workshop can be regarded as an independent client. Table 5 shows the data used in this experiment. The number of samples on the 4 clients is basically the same. In the experiment, the data set is randomly distributed to all clients on average, each of which possesses 3000 positive and 1500 negative samples. The four workshops have 713 common features of data.",
            "To compare FedRF and RF on the given testing data, it is assumed that the first three production lines (L0, L1, L2) of the Bosch dataset belong to the same organization O1, and the L3 production line belongs to another organization O2. O1 and O2 are independent. Since the samples in O1 and O2 have the same ID and different characteristics, VFL is applied. The data set used in the FedRF experiment is shown in Table 6. We extract the features belonging to L0, L1, and L2 as a group, and the features belonging to L3 as another group. Then we perform principal component analysis (PCA) to reduce the feature dimension in O1/O2 from 723/245 to 22/22, respectively. According to the overall analysis of PCA results, the first 22 dimensions can represent more than 95% of the variance, so reducing to 22 dimensions, respectively, which will not cause too much information loss Zhang et al. (2016). The positive and negative sample numbers are 12000 and 6000, respectively.",
            "Table 7 shows the experimental results. To ensure that the data set and the algorithm kernel are consistent, the baseline is the result of FedSVM when the number of clients is set to 1, ie., FedSVM degenerates into SVM. Under this premise, the results of FedSVM and SVM are compared. When analyzing the stability, the experiment data is ordered by time-series and then divided into 10 groups on average. The measurements of each group are calculated. The overall results of stability are shown in Fig. 5. The average value of stability is above 0.7 for FedSVM and SVM. The variance of the stability is given as Stability (Var) in Table 7.",
            "In Figure 5, FedSVM performs slightly better than SVM on two test groups, namely 1 and 7. Similar results are also shown for the Precision measure in Table 7. This effect is only shown in the HFL scenario, where the clients contribute local data features to the central server. If the amount of data on each client is small, FL’s effect can be better than CL because FL expands the number of IID data samples in the HFL scenario.",
            "The experimental results are shown in Table 8. FedRF degenerates into RF by combining two clients so that the effect of FedRF and RF can be compared under the premise of ensuring the consistency of the testing data and the algorithm kernel. When analyzing the stability, the test set is divided into 10 groups on average according to the time-series, and the measurements of each group are calculated. The variance of the stability is given in Table 8, and the overall results of stability are shown in Fig. 6.",
            "We first constructed a timed state sequence indicating the prediction error using FedSVM and SVM, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-SVM_resa and LABEL:tab:RQ3-SVM_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-SVM_resc.\nThe average difference value between each pair of parameters is 0.054. The maximum difference value is 0.096. It means that there exists no significant difference between the two Markov models, and the prediction error between FedSVM and SVM are almost equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedSVM and SVM in the subsequent Bosch production was not significantly different.",
            "We first constructed a timed state sequence indicating the prediction error using FedRF and RF, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-RF_resa and LABEL:tab:RQ3-RF_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-RF_resc.\nThe average difference value between each pair of parameters is 0.035. The maximum difference value is 0.100. It means that there exists no significant difference between the two Markov models, and the prediction error between FedRF and RF are equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedRF and RF in the subsequent Bosch production was not significantly different.",
            "The experimental results are shown in Table 11. There are outliers in the test results, so the sum of the samples in each cluster is less than 100. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedSVM is heterogeneous. It enforces the conclusion that FedSVM and SVM have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "The experimental results are shown in Table 12. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedRF is heterogeneous. It enforces the conclusion that FedRF and RF have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "Another threat to construct validity is the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2) used in the experiment. In the industry, the threshold value is set according to the production needs. We have performed a hypothesis test for the difference between the two approaches’ performances to explain that the difference between FL and CL is within the threshold. The original hypothesis H0 is difference >δabsent𝛿>\\delta, and the alternative hypothesis H1 is difference <δabsent𝛿<\\delta, where the difference = CL – FL on the same random partial testing data group. Suppose α𝛼\\alpha = 0.05. The p-value of the evaluation metrics for FedSVM vs. SVM and FedForest vs. RForest is shown in Table 13 and Table 14, respectively. As a​l​p​h​a>𝑎𝑙𝑝ℎ𝑎absentalpha> p-value for all metrics, the alternative hypothesis H1 is accepted, which means that the difference between CL and FL is less than the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2).",
            "Besides, some works have shown that the effect of FL is also related to encryption algorithms R et al. (2019); Tao et al. (2020); Feng et al. (2020); Olivia et al. (2019); Lu et al. (2020); Li et al. (2019, 2020b). If the encryption strength increases, the information loss on the data will be worse. So that the effect of FL decreases. The trade-off between data privacy protection and the accuracy of the trained model is still inevitable. It is still considered an open question of how the effect of FL is related to other factors."
        ]
    },
    "S5.T9.sf3": {
        "caption": "(c) Comparison of Two Markov Model Parameters",
        "table": "<table id=\"S5.T9.sf3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T9.sf3.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf3.1.1.1\" class=\"ltx_td ltx_align_top ltx_border_tt\"></td>\n<td id=\"S5.T9.sf3.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf3.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.1.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf3.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf3.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.1.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf3.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T9.sf3.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.1.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf3.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf3.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf3.1.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf3.1.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.2.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf3.1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf3.1.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.2.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.031</span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf3.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.2.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.036</span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T9.sf3.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.2.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.067</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf3.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf3.1.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf3.1.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.3.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf3.1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf3.1.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.3.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.025</span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf3.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.3.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.055</span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T9.sf3.1.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.3.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.080</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T9.sf3.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T9.sf3.1.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf3.1.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.4.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T9.sf3.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf3.1.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.4.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.096</span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf3.1.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.4.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.063</span>\n</span>\n</td>\n<td id=\"S5.T9.sf3.1.4.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T9.sf3.1.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T9.sf3.1.4.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.033</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Bosch is one of the worldwide leading manufacturing companies. It ensures high quality of the production by monitoring its parts in the manufacturing processes. Because Bosch records detailed data for each step on the assembly lines, they can apply advanced techniques to improve the manufacturing processes. To this end, Bosch has published a dataset on the Kaggle competition platform to predict internal failures by thousands of measurements and tests made for each component along the assembly line. Some studies have analyzed the dataset and carried out approaches to predicting product quality based on CL algorithms excluding time-series features Carbery et al. (2019, 2018); Zhang et al. (2016); Khoza and Grobler (2019); Kotenko et al. (2019); Mangal and Kumar (2016); Hebert (2016); Maurya (2016) or including time-series features Huang et al. (2019b); Moldovan et al. (2019); Liu et al. (2020d), as summarized in Table 1. These works were conducted based on a set of learning methods, including Logistic Regression (LR), Gradient Boosting Machine (GBM), Random Forest (RF), Gradient Boosted Trees (GBT), Naive Bayes (NB), Bayesian Network (BN), K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Multilayer Perceptron Classifier (MPC), Majority Voting (MV), Decision Tree (DT), Statistical Process Control (SPC), etc.",
            "As a supervised learning algorithm, SVM is suitable for classification and regression analysis. The effectiveness of SVM mainly depends on how to select 1) the kernel, 2) the kernel’s parameters, and 3) the soft margin parameter. In this work, we use FedSVM with a linear kernel. SVM specifies parameters and intercepts, which can be directly weighted. In FL, the SVM models generated on different clients can be integrated by averaging the parameters and intercepts to meet the need of the server. The FedSVM algorithm is first proposed in Bakopoulou et al. (2019) for mobile packet classification. We have adapted their FedSVM to our failure prediction problem. Its training process is shown in Fig. 1. The algorithm of the client and server is given by Algo. 1 and Algo. 2, respectively. The main steps of FedSVM are explained hereafter.",
            "We have experimented to evaluate the improvement of FedRF.\nIn this experiment, we constructed a VFL scenario with two clients sharing data features using the Bosch dataset. There are 50 independent features in each client, which are extracted after performing the principal component analysis (PCA) from different production lines and the same 11154 samples. The experiment results are shown in Table 2.\nIt can be seen that we get better prediction results than the federated random forest algorithm proposed in Liu et al. (2020a).",
            "S1. Construct prediction table. We first construct a prediction table containing the ground truth (GT) label, the prediction results (Pre) of CL and FL algorithms of products ordered by timestamp (ts).",
            "MSA is one of the commonly used analysis methods in manufacturing Montgomery (2007). The learning-based failure prediction method can be seen as a product quality measurement system. Taking the Bosch company’s product quality testing results as a benchmark, we can analyze the FL and CL algorithms through the MSA method. The evaluation measurements in MSA mainly include Accuracy (ACC), Precision (PRE), and Stability. On this basis, F1, AUC, and Matthew’s Correlation Coefficient (MCC) are also involved. The six measurements we use in the empirical study are provided in Table 3, where P represents the number of GT positive cases, N is the number of GT negative cases, TP (hit) is true positive, TN (correct rejection) is true negative, FP (false alarm) is false positive, and FN (miss) is false negative.",
            "MCC is suitable for evaluating the prediction results of unbalanced data. AUC is a commonly used two-category evaluation method, and its value is the area enclosed by the ROC curve and the reference line. The x-axis of a ROC curve is the false positive rate, and the y-axis of a ROC curve is the true positive rate. It shows the relationship between clinical sensitivity and specificity for every possible cut-off. It is a graph with: The x-axis showing 1-specificity (=𝙵𝙿/(𝙵𝙿+𝚃𝙽)absent𝙵𝙿𝙵𝙿𝚃𝙽\\mathtt{=FP/(FP+TN)}) The y-axis showing sensitivity (=𝚃𝙿/(𝚃𝙿+𝙵𝙽)absent𝚃𝙿𝚃𝙿𝙵𝙽\\mathtt{=TP/(TP+FN)}). The range of AUC value is between 0 and 1.",
            "The data features are shown in Table 4. There are 1184687 products in the dataset, including 1177808 positive samples (Pos) and 6879 negative ones (Neg). In the feature space, the dataset has 968 features. These features are collected from 51 workstations (S1-S51) on 4 production lines L0-L3 that contain 168, 513, 42, and 245 features, respectively. L1_S24_F1695 indicates that the feature No.1695 was observed at the No.24 workstation of the L1 production line. The label Response represents whether the final product is qualified (label = 0) or not (label = 1). From the perspective of data items, only a few items (0.58%) in the dataset result are qualified, and the data is extremely unbalanced. The data is also extremely sparse, with only a few workstations collecting data from most products Carbery et al. (2019).",
            "To compare FedSVM and SVM on the testing data, we form four workshops A, B, C, and D that do not share manufacturing data but have the same structure and configuration of the production line. Under the premise that the product features are aligned, they contain different samples, and each sample has a unique ID. Each workshop can be regarded as an independent client. Table 5 shows the data used in this experiment. The number of samples on the 4 clients is basically the same. In the experiment, the data set is randomly distributed to all clients on average, each of which possesses 3000 positive and 1500 negative samples. The four workshops have 713 common features of data.",
            "To compare FedRF and RF on the given testing data, it is assumed that the first three production lines (L0, L1, L2) of the Bosch dataset belong to the same organization O1, and the L3 production line belongs to another organization O2. O1 and O2 are independent. Since the samples in O1 and O2 have the same ID and different characteristics, VFL is applied. The data set used in the FedRF experiment is shown in Table 6. We extract the features belonging to L0, L1, and L2 as a group, and the features belonging to L3 as another group. Then we perform principal component analysis (PCA) to reduce the feature dimension in O1/O2 from 723/245 to 22/22, respectively. According to the overall analysis of PCA results, the first 22 dimensions can represent more than 95% of the variance, so reducing to 22 dimensions, respectively, which will not cause too much information loss Zhang et al. (2016). The positive and negative sample numbers are 12000 and 6000, respectively.",
            "Table 7 shows the experimental results. To ensure that the data set and the algorithm kernel are consistent, the baseline is the result of FedSVM when the number of clients is set to 1, ie., FedSVM degenerates into SVM. Under this premise, the results of FedSVM and SVM are compared. When analyzing the stability, the experiment data is ordered by time-series and then divided into 10 groups on average. The measurements of each group are calculated. The overall results of stability are shown in Fig. 5. The average value of stability is above 0.7 for FedSVM and SVM. The variance of the stability is given as Stability (Var) in Table 7.",
            "In Figure 5, FedSVM performs slightly better than SVM on two test groups, namely 1 and 7. Similar results are also shown for the Precision measure in Table 7. This effect is only shown in the HFL scenario, where the clients contribute local data features to the central server. If the amount of data on each client is small, FL’s effect can be better than CL because FL expands the number of IID data samples in the HFL scenario.",
            "The experimental results are shown in Table 8. FedRF degenerates into RF by combining two clients so that the effect of FedRF and RF can be compared under the premise of ensuring the consistency of the testing data and the algorithm kernel. When analyzing the stability, the test set is divided into 10 groups on average according to the time-series, and the measurements of each group are calculated. The variance of the stability is given in Table 8, and the overall results of stability are shown in Fig. 6.",
            "We first constructed a timed state sequence indicating the prediction error using FedSVM and SVM, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-SVM_resa and LABEL:tab:RQ3-SVM_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-SVM_resc.\nThe average difference value between each pair of parameters is 0.054. The maximum difference value is 0.096. It means that there exists no significant difference between the two Markov models, and the prediction error between FedSVM and SVM are almost equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedSVM and SVM in the subsequent Bosch production was not significantly different.",
            "We first constructed a timed state sequence indicating the prediction error using FedRF and RF, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-RF_resa and LABEL:tab:RQ3-RF_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-RF_resc.\nThe average difference value between each pair of parameters is 0.035. The maximum difference value is 0.100. It means that there exists no significant difference between the two Markov models, and the prediction error between FedRF and RF are equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedRF and RF in the subsequent Bosch production was not significantly different.",
            "The experimental results are shown in Table 11. There are outliers in the test results, so the sum of the samples in each cluster is less than 100. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedSVM is heterogeneous. It enforces the conclusion that FedSVM and SVM have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "The experimental results are shown in Table 12. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedRF is heterogeneous. It enforces the conclusion that FedRF and RF have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "Another threat to construct validity is the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2) used in the experiment. In the industry, the threshold value is set according to the production needs. We have performed a hypothesis test for the difference between the two approaches’ performances to explain that the difference between FL and CL is within the threshold. The original hypothesis H0 is difference >δabsent𝛿>\\delta, and the alternative hypothesis H1 is difference <δabsent𝛿<\\delta, where the difference = CL – FL on the same random partial testing data group. Suppose α𝛼\\alpha = 0.05. The p-value of the evaluation metrics for FedSVM vs. SVM and FedForest vs. RForest is shown in Table 13 and Table 14, respectively. As a​l​p​h​a>𝑎𝑙𝑝ℎ𝑎absentalpha> p-value for all metrics, the alternative hypothesis H1 is accepted, which means that the difference between CL and FL is less than the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2).",
            "Besides, some works have shown that the effect of FL is also related to encryption algorithms R et al. (2019); Tao et al. (2020); Feng et al. (2020); Olivia et al. (2019); Lu et al. (2020); Li et al. (2019, 2020b). If the encryption strength increases, the information loss on the data will be worse. So that the effect of FL decreases. The trade-off between data privacy protection and the accuracy of the trained model is still inevitable. It is still considered an open question of how the effect of FL is related to other factors."
        ]
    },
    "S5.T10": {
        "caption": "Table 10: Experiment Results of RQ3 on FedRF/RF ",
        "table": "<table id=\"S5.T10.sf1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T10.sf1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf1.1.1.1\" class=\"ltx_td ltx_align_top ltx_border_tt\"></td>\n<td id=\"S5.T10.sf1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.1.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.1.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf1.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.1.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf1.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf1.1.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf1.1.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.2.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf1.1.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.2.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.869</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf1.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.2.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.130</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf1.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.2.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.001</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf1.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf1.1.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.701</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.299</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.000</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf1.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf1.1.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf1.1.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.4.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf1.1.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.4.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">1.000</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf1.1.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.4.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.000</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.4.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf1.1.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.4.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.000</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We first constructed a timed state sequence indicating the prediction error using FedRF and RF, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table ",
                "LABEL:tab:RQ3-RF_resa",
                " and ",
                "LABEL:tab:RQ3-RF_resa",
                ". The value difference between each pair of parameters is calculated in Table ",
                "LABEL:tab:RQ3-RF_resc",
                ".\nThe average difference value between each pair of parameters is 0.035. The maximum difference value is 0.100. It means that there exists no significant difference between the two Markov models, and the prediction error between FedRF and RF are equally distributed on the estimated unknown Bosch data. Therefore, ",
                "the performance of FedRF and RF in the subsequent Bosch production was not significantly different."
            ]
        ]
    },
    "S5.T10.sf1": {
        "caption": "(a) Markov Model Parameters of Prediction Error using FedRF",
        "table": "<table id=\"S5.T10.sf1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T10.sf1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf1.1.1.1\" class=\"ltx_td ltx_align_top ltx_border_tt\"></td>\n<td id=\"S5.T10.sf1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.1.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.1.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf1.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.1.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf1.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf1.1.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf1.1.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.2.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf1.1.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.2.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.869</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf1.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.2.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.130</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf1.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.2.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.001</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf1.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf1.1.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.701</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.299</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.3.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.000</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf1.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf1.1.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf1.1.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.4.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf1.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf1.1.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.4.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">1.000</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf1.1.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.4.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.000</span>\n</span>\n</td>\n<td id=\"S5.T10.sf1.1.4.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf1.1.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf1.1.4.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.000</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Bosch is one of the worldwide leading manufacturing companies. It ensures high quality of the production by monitoring its parts in the manufacturing processes. Because Bosch records detailed data for each step on the assembly lines, they can apply advanced techniques to improve the manufacturing processes. To this end, Bosch has published a dataset on the Kaggle competition platform to predict internal failures by thousands of measurements and tests made for each component along the assembly line. Some studies have analyzed the dataset and carried out approaches to predicting product quality based on CL algorithms excluding time-series features Carbery et al. (2019, 2018); Zhang et al. (2016); Khoza and Grobler (2019); Kotenko et al. (2019); Mangal and Kumar (2016); Hebert (2016); Maurya (2016) or including time-series features Huang et al. (2019b); Moldovan et al. (2019); Liu et al. (2020d), as summarized in Table 1. These works were conducted based on a set of learning methods, including Logistic Regression (LR), Gradient Boosting Machine (GBM), Random Forest (RF), Gradient Boosted Trees (GBT), Naive Bayes (NB), Bayesian Network (BN), K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Multilayer Perceptron Classifier (MPC), Majority Voting (MV), Decision Tree (DT), Statistical Process Control (SPC), etc.",
            "As a supervised learning algorithm, SVM is suitable for classification and regression analysis. The effectiveness of SVM mainly depends on how to select 1) the kernel, 2) the kernel’s parameters, and 3) the soft margin parameter. In this work, we use FedSVM with a linear kernel. SVM specifies parameters and intercepts, which can be directly weighted. In FL, the SVM models generated on different clients can be integrated by averaging the parameters and intercepts to meet the need of the server. The FedSVM algorithm is first proposed in Bakopoulou et al. (2019) for mobile packet classification. We have adapted their FedSVM to our failure prediction problem. Its training process is shown in Fig. 1. The algorithm of the client and server is given by Algo. 1 and Algo. 2, respectively. The main steps of FedSVM are explained hereafter.",
            "We have experimented to evaluate the improvement of FedRF.\nIn this experiment, we constructed a VFL scenario with two clients sharing data features using the Bosch dataset. There are 50 independent features in each client, which are extracted after performing the principal component analysis (PCA) from different production lines and the same 11154 samples. The experiment results are shown in Table 2.\nIt can be seen that we get better prediction results than the federated random forest algorithm proposed in Liu et al. (2020a).",
            "S1. Construct prediction table. We first construct a prediction table containing the ground truth (GT) label, the prediction results (Pre) of CL and FL algorithms of products ordered by timestamp (ts).",
            "MSA is one of the commonly used analysis methods in manufacturing Montgomery (2007). The learning-based failure prediction method can be seen as a product quality measurement system. Taking the Bosch company’s product quality testing results as a benchmark, we can analyze the FL and CL algorithms through the MSA method. The evaluation measurements in MSA mainly include Accuracy (ACC), Precision (PRE), and Stability. On this basis, F1, AUC, and Matthew’s Correlation Coefficient (MCC) are also involved. The six measurements we use in the empirical study are provided in Table 3, where P represents the number of GT positive cases, N is the number of GT negative cases, TP (hit) is true positive, TN (correct rejection) is true negative, FP (false alarm) is false positive, and FN (miss) is false negative.",
            "MCC is suitable for evaluating the prediction results of unbalanced data. AUC is a commonly used two-category evaluation method, and its value is the area enclosed by the ROC curve and the reference line. The x-axis of a ROC curve is the false positive rate, and the y-axis of a ROC curve is the true positive rate. It shows the relationship between clinical sensitivity and specificity for every possible cut-off. It is a graph with: The x-axis showing 1-specificity (=𝙵𝙿/(𝙵𝙿+𝚃𝙽)absent𝙵𝙿𝙵𝙿𝚃𝙽\\mathtt{=FP/(FP+TN)}) The y-axis showing sensitivity (=𝚃𝙿/(𝚃𝙿+𝙵𝙽)absent𝚃𝙿𝚃𝙿𝙵𝙽\\mathtt{=TP/(TP+FN)}). The range of AUC value is between 0 and 1.",
            "The data features are shown in Table 4. There are 1184687 products in the dataset, including 1177808 positive samples (Pos) and 6879 negative ones (Neg). In the feature space, the dataset has 968 features. These features are collected from 51 workstations (S1-S51) on 4 production lines L0-L3 that contain 168, 513, 42, and 245 features, respectively. L1_S24_F1695 indicates that the feature No.1695 was observed at the No.24 workstation of the L1 production line. The label Response represents whether the final product is qualified (label = 0) or not (label = 1). From the perspective of data items, only a few items (0.58%) in the dataset result are qualified, and the data is extremely unbalanced. The data is also extremely sparse, with only a few workstations collecting data from most products Carbery et al. (2019).",
            "To compare FedSVM and SVM on the testing data, we form four workshops A, B, C, and D that do not share manufacturing data but have the same structure and configuration of the production line. Under the premise that the product features are aligned, they contain different samples, and each sample has a unique ID. Each workshop can be regarded as an independent client. Table 5 shows the data used in this experiment. The number of samples on the 4 clients is basically the same. In the experiment, the data set is randomly distributed to all clients on average, each of which possesses 3000 positive and 1500 negative samples. The four workshops have 713 common features of data.",
            "To compare FedRF and RF on the given testing data, it is assumed that the first three production lines (L0, L1, L2) of the Bosch dataset belong to the same organization O1, and the L3 production line belongs to another organization O2. O1 and O2 are independent. Since the samples in O1 and O2 have the same ID and different characteristics, VFL is applied. The data set used in the FedRF experiment is shown in Table 6. We extract the features belonging to L0, L1, and L2 as a group, and the features belonging to L3 as another group. Then we perform principal component analysis (PCA) to reduce the feature dimension in O1/O2 from 723/245 to 22/22, respectively. According to the overall analysis of PCA results, the first 22 dimensions can represent more than 95% of the variance, so reducing to 22 dimensions, respectively, which will not cause too much information loss Zhang et al. (2016). The positive and negative sample numbers are 12000 and 6000, respectively.",
            "Table 7 shows the experimental results. To ensure that the data set and the algorithm kernel are consistent, the baseline is the result of FedSVM when the number of clients is set to 1, ie., FedSVM degenerates into SVM. Under this premise, the results of FedSVM and SVM are compared. When analyzing the stability, the experiment data is ordered by time-series and then divided into 10 groups on average. The measurements of each group are calculated. The overall results of stability are shown in Fig. 5. The average value of stability is above 0.7 for FedSVM and SVM. The variance of the stability is given as Stability (Var) in Table 7.",
            "In Figure 5, FedSVM performs slightly better than SVM on two test groups, namely 1 and 7. Similar results are also shown for the Precision measure in Table 7. This effect is only shown in the HFL scenario, where the clients contribute local data features to the central server. If the amount of data on each client is small, FL’s effect can be better than CL because FL expands the number of IID data samples in the HFL scenario.",
            "The experimental results are shown in Table 8. FedRF degenerates into RF by combining two clients so that the effect of FedRF and RF can be compared under the premise of ensuring the consistency of the testing data and the algorithm kernel. When analyzing the stability, the test set is divided into 10 groups on average according to the time-series, and the measurements of each group are calculated. The variance of the stability is given in Table 8, and the overall results of stability are shown in Fig. 6.",
            "We first constructed a timed state sequence indicating the prediction error using FedSVM and SVM, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-SVM_resa and LABEL:tab:RQ3-SVM_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-SVM_resc.\nThe average difference value between each pair of parameters is 0.054. The maximum difference value is 0.096. It means that there exists no significant difference between the two Markov models, and the prediction error between FedSVM and SVM are almost equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedSVM and SVM in the subsequent Bosch production was not significantly different.",
            "We first constructed a timed state sequence indicating the prediction error using FedRF and RF, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-RF_resa and LABEL:tab:RQ3-RF_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-RF_resc.\nThe average difference value between each pair of parameters is 0.035. The maximum difference value is 0.100. It means that there exists no significant difference between the two Markov models, and the prediction error between FedRF and RF are equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedRF and RF in the subsequent Bosch production was not significantly different.",
            "The experimental results are shown in Table 11. There are outliers in the test results, so the sum of the samples in each cluster is less than 100. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedSVM is heterogeneous. It enforces the conclusion that FedSVM and SVM have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "The experimental results are shown in Table 12. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedRF is heterogeneous. It enforces the conclusion that FedRF and RF have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "Another threat to construct validity is the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2) used in the experiment. In the industry, the threshold value is set according to the production needs. We have performed a hypothesis test for the difference between the two approaches’ performances to explain that the difference between FL and CL is within the threshold. The original hypothesis H0 is difference >δabsent𝛿>\\delta, and the alternative hypothesis H1 is difference <δabsent𝛿<\\delta, where the difference = CL – FL on the same random partial testing data group. Suppose α𝛼\\alpha = 0.05. The p-value of the evaluation metrics for FedSVM vs. SVM and FedForest vs. RForest is shown in Table 13 and Table 14, respectively. As a​l​p​h​a>𝑎𝑙𝑝ℎ𝑎absentalpha> p-value for all metrics, the alternative hypothesis H1 is accepted, which means that the difference between CL and FL is less than the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2).",
            "Besides, some works have shown that the effect of FL is also related to encryption algorithms R et al. (2019); Tao et al. (2020); Feng et al. (2020); Olivia et al. (2019); Lu et al. (2020); Li et al. (2019, 2020b). If the encryption strength increases, the information loss on the data will be worse. So that the effect of FL decreases. The trade-off between data privacy protection and the accuracy of the trained model is still inevitable. It is still considered an open question of how the effect of FL is related to other factors."
        ]
    },
    "S5.T10.sf2": {
        "caption": "(b) Markov Model Parameters of Prediction Error using RF",
        "table": "<table id=\"S5.T10.sf2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T10.sf2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf2.1.1.1\" class=\"ltx_td ltx_align_top ltx_border_tt\"></td>\n<td id=\"S5.T10.sf2.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf2.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.1.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf2.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf2.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.1.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf2.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf2.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.1.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf2.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf2.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf2.1.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf2.1.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.2.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf2.1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf2.1.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.2.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.888</span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf2.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.2.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.109</span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf2.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.2.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.003</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf2.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf2.1.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf2.1.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.3.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf2.1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf2.1.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.3.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.735</span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf2.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.3.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.263</span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf2.1.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.3.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.002</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf2.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf2.1.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf2.1.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.4.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf2.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf2.1.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.4.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.900</span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf2.1.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.4.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.100</span>\n</span>\n</td>\n<td id=\"S5.T10.sf2.1.4.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf2.1.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf2.1.4.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.000</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Bosch is one of the worldwide leading manufacturing companies. It ensures high quality of the production by monitoring its parts in the manufacturing processes. Because Bosch records detailed data for each step on the assembly lines, they can apply advanced techniques to improve the manufacturing processes. To this end, Bosch has published a dataset on the Kaggle competition platform to predict internal failures by thousands of measurements and tests made for each component along the assembly line. Some studies have analyzed the dataset and carried out approaches to predicting product quality based on CL algorithms excluding time-series features Carbery et al. (2019, 2018); Zhang et al. (2016); Khoza and Grobler (2019); Kotenko et al. (2019); Mangal and Kumar (2016); Hebert (2016); Maurya (2016) or including time-series features Huang et al. (2019b); Moldovan et al. (2019); Liu et al. (2020d), as summarized in Table 1. These works were conducted based on a set of learning methods, including Logistic Regression (LR), Gradient Boosting Machine (GBM), Random Forest (RF), Gradient Boosted Trees (GBT), Naive Bayes (NB), Bayesian Network (BN), K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Multilayer Perceptron Classifier (MPC), Majority Voting (MV), Decision Tree (DT), Statistical Process Control (SPC), etc.",
            "As a supervised learning algorithm, SVM is suitable for classification and regression analysis. The effectiveness of SVM mainly depends on how to select 1) the kernel, 2) the kernel’s parameters, and 3) the soft margin parameter. In this work, we use FedSVM with a linear kernel. SVM specifies parameters and intercepts, which can be directly weighted. In FL, the SVM models generated on different clients can be integrated by averaging the parameters and intercepts to meet the need of the server. The FedSVM algorithm is first proposed in Bakopoulou et al. (2019) for mobile packet classification. We have adapted their FedSVM to our failure prediction problem. Its training process is shown in Fig. 1. The algorithm of the client and server is given by Algo. 1 and Algo. 2, respectively. The main steps of FedSVM are explained hereafter.",
            "We have experimented to evaluate the improvement of FedRF.\nIn this experiment, we constructed a VFL scenario with two clients sharing data features using the Bosch dataset. There are 50 independent features in each client, which are extracted after performing the principal component analysis (PCA) from different production lines and the same 11154 samples. The experiment results are shown in Table 2.\nIt can be seen that we get better prediction results than the federated random forest algorithm proposed in Liu et al. (2020a).",
            "S1. Construct prediction table. We first construct a prediction table containing the ground truth (GT) label, the prediction results (Pre) of CL and FL algorithms of products ordered by timestamp (ts).",
            "MSA is one of the commonly used analysis methods in manufacturing Montgomery (2007). The learning-based failure prediction method can be seen as a product quality measurement system. Taking the Bosch company’s product quality testing results as a benchmark, we can analyze the FL and CL algorithms through the MSA method. The evaluation measurements in MSA mainly include Accuracy (ACC), Precision (PRE), and Stability. On this basis, F1, AUC, and Matthew’s Correlation Coefficient (MCC) are also involved. The six measurements we use in the empirical study are provided in Table 3, where P represents the number of GT positive cases, N is the number of GT negative cases, TP (hit) is true positive, TN (correct rejection) is true negative, FP (false alarm) is false positive, and FN (miss) is false negative.",
            "MCC is suitable for evaluating the prediction results of unbalanced data. AUC is a commonly used two-category evaluation method, and its value is the area enclosed by the ROC curve and the reference line. The x-axis of a ROC curve is the false positive rate, and the y-axis of a ROC curve is the true positive rate. It shows the relationship between clinical sensitivity and specificity for every possible cut-off. It is a graph with: The x-axis showing 1-specificity (=𝙵𝙿/(𝙵𝙿+𝚃𝙽)absent𝙵𝙿𝙵𝙿𝚃𝙽\\mathtt{=FP/(FP+TN)}) The y-axis showing sensitivity (=𝚃𝙿/(𝚃𝙿+𝙵𝙽)absent𝚃𝙿𝚃𝙿𝙵𝙽\\mathtt{=TP/(TP+FN)}). The range of AUC value is between 0 and 1.",
            "The data features are shown in Table 4. There are 1184687 products in the dataset, including 1177808 positive samples (Pos) and 6879 negative ones (Neg). In the feature space, the dataset has 968 features. These features are collected from 51 workstations (S1-S51) on 4 production lines L0-L3 that contain 168, 513, 42, and 245 features, respectively. L1_S24_F1695 indicates that the feature No.1695 was observed at the No.24 workstation of the L1 production line. The label Response represents whether the final product is qualified (label = 0) or not (label = 1). From the perspective of data items, only a few items (0.58%) in the dataset result are qualified, and the data is extremely unbalanced. The data is also extremely sparse, with only a few workstations collecting data from most products Carbery et al. (2019).",
            "To compare FedSVM and SVM on the testing data, we form four workshops A, B, C, and D that do not share manufacturing data but have the same structure and configuration of the production line. Under the premise that the product features are aligned, they contain different samples, and each sample has a unique ID. Each workshop can be regarded as an independent client. Table 5 shows the data used in this experiment. The number of samples on the 4 clients is basically the same. In the experiment, the data set is randomly distributed to all clients on average, each of which possesses 3000 positive and 1500 negative samples. The four workshops have 713 common features of data.",
            "To compare FedRF and RF on the given testing data, it is assumed that the first three production lines (L0, L1, L2) of the Bosch dataset belong to the same organization O1, and the L3 production line belongs to another organization O2. O1 and O2 are independent. Since the samples in O1 and O2 have the same ID and different characteristics, VFL is applied. The data set used in the FedRF experiment is shown in Table 6. We extract the features belonging to L0, L1, and L2 as a group, and the features belonging to L3 as another group. Then we perform principal component analysis (PCA) to reduce the feature dimension in O1/O2 from 723/245 to 22/22, respectively. According to the overall analysis of PCA results, the first 22 dimensions can represent more than 95% of the variance, so reducing to 22 dimensions, respectively, which will not cause too much information loss Zhang et al. (2016). The positive and negative sample numbers are 12000 and 6000, respectively.",
            "Table 7 shows the experimental results. To ensure that the data set and the algorithm kernel are consistent, the baseline is the result of FedSVM when the number of clients is set to 1, ie., FedSVM degenerates into SVM. Under this premise, the results of FedSVM and SVM are compared. When analyzing the stability, the experiment data is ordered by time-series and then divided into 10 groups on average. The measurements of each group are calculated. The overall results of stability are shown in Fig. 5. The average value of stability is above 0.7 for FedSVM and SVM. The variance of the stability is given as Stability (Var) in Table 7.",
            "In Figure 5, FedSVM performs slightly better than SVM on two test groups, namely 1 and 7. Similar results are also shown for the Precision measure in Table 7. This effect is only shown in the HFL scenario, where the clients contribute local data features to the central server. If the amount of data on each client is small, FL’s effect can be better than CL because FL expands the number of IID data samples in the HFL scenario.",
            "The experimental results are shown in Table 8. FedRF degenerates into RF by combining two clients so that the effect of FedRF and RF can be compared under the premise of ensuring the consistency of the testing data and the algorithm kernel. When analyzing the stability, the test set is divided into 10 groups on average according to the time-series, and the measurements of each group are calculated. The variance of the stability is given in Table 8, and the overall results of stability are shown in Fig. 6.",
            "We first constructed a timed state sequence indicating the prediction error using FedSVM and SVM, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-SVM_resa and LABEL:tab:RQ3-SVM_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-SVM_resc.\nThe average difference value between each pair of parameters is 0.054. The maximum difference value is 0.096. It means that there exists no significant difference between the two Markov models, and the prediction error between FedSVM and SVM are almost equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedSVM and SVM in the subsequent Bosch production was not significantly different.",
            "We first constructed a timed state sequence indicating the prediction error using FedRF and RF, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-RF_resa and LABEL:tab:RQ3-RF_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-RF_resc.\nThe average difference value between each pair of parameters is 0.035. The maximum difference value is 0.100. It means that there exists no significant difference between the two Markov models, and the prediction error between FedRF and RF are equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedRF and RF in the subsequent Bosch production was not significantly different.",
            "The experimental results are shown in Table 11. There are outliers in the test results, so the sum of the samples in each cluster is less than 100. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedSVM is heterogeneous. It enforces the conclusion that FedSVM and SVM have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "The experimental results are shown in Table 12. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedRF is heterogeneous. It enforces the conclusion that FedRF and RF have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "Another threat to construct validity is the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2) used in the experiment. In the industry, the threshold value is set according to the production needs. We have performed a hypothesis test for the difference between the two approaches’ performances to explain that the difference between FL and CL is within the threshold. The original hypothesis H0 is difference >δabsent𝛿>\\delta, and the alternative hypothesis H1 is difference <δabsent𝛿<\\delta, where the difference = CL – FL on the same random partial testing data group. Suppose α𝛼\\alpha = 0.05. The p-value of the evaluation metrics for FedSVM vs. SVM and FedForest vs. RForest is shown in Table 13 and Table 14, respectively. As a​l​p​h​a>𝑎𝑙𝑝ℎ𝑎absentalpha> p-value for all metrics, the alternative hypothesis H1 is accepted, which means that the difference between CL and FL is less than the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2).",
            "Besides, some works have shown that the effect of FL is also related to encryption algorithms R et al. (2019); Tao et al. (2020); Feng et al. (2020); Olivia et al. (2019); Lu et al. (2020); Li et al. (2019, 2020b). If the encryption strength increases, the information loss on the data will be worse. So that the effect of FL decreases. The trade-off between data privacy protection and the accuracy of the trained model is still inevitable. It is still considered an open question of how the effect of FL is related to other factors."
        ]
    },
    "S5.T10.sf3": {
        "caption": "(c) Comparison of Two Markov Model Parameters",
        "table": "<table id=\"S5.T10.sf3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T10.sf3.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf3.1.1.1\" class=\"ltx_td ltx_align_top ltx_border_tt\"></td>\n<td id=\"S5.T10.sf3.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf3.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.1.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf3.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf3.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.1.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf3.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T10.sf3.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.1.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf3.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf3.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf3.1.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf3.1.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.2.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf3.1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Hit</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf3.1.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.2.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.019</span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf3.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.2.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.021</span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T10.sf3.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.2.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.002</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf3.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf3.1.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf3.1.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.3.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf3.1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Miss</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf3.1.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.3.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.034</span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf3.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.3.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.036</span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S5.T10.sf3.1.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.3.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.002</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T10.sf3.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T10.sf3.1.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf3.1.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.4.1.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\"><span id=\"S5.T10.sf3.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Mistake</span></span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf3.1.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.4.2.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.100</span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf3.1.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.4.3.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.100</span>\n</span>\n</td>\n<td id=\"S5.T10.sf3.1.4.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T10.sf3.1.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T10.sf3.1.4.4.1.1\" class=\"ltx_p\" style=\"width:42.7pt;\">0.000</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Bosch is one of the worldwide leading manufacturing companies. It ensures high quality of the production by monitoring its parts in the manufacturing processes. Because Bosch records detailed data for each step on the assembly lines, they can apply advanced techniques to improve the manufacturing processes. To this end, Bosch has published a dataset on the Kaggle competition platform to predict internal failures by thousands of measurements and tests made for each component along the assembly line. Some studies have analyzed the dataset and carried out approaches to predicting product quality based on CL algorithms excluding time-series features Carbery et al. (2019, 2018); Zhang et al. (2016); Khoza and Grobler (2019); Kotenko et al. (2019); Mangal and Kumar (2016); Hebert (2016); Maurya (2016) or including time-series features Huang et al. (2019b); Moldovan et al. (2019); Liu et al. (2020d), as summarized in Table 1. These works were conducted based on a set of learning methods, including Logistic Regression (LR), Gradient Boosting Machine (GBM), Random Forest (RF), Gradient Boosted Trees (GBT), Naive Bayes (NB), Bayesian Network (BN), K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Multilayer Perceptron Classifier (MPC), Majority Voting (MV), Decision Tree (DT), Statistical Process Control (SPC), etc.",
            "As a supervised learning algorithm, SVM is suitable for classification and regression analysis. The effectiveness of SVM mainly depends on how to select 1) the kernel, 2) the kernel’s parameters, and 3) the soft margin parameter. In this work, we use FedSVM with a linear kernel. SVM specifies parameters and intercepts, which can be directly weighted. In FL, the SVM models generated on different clients can be integrated by averaging the parameters and intercepts to meet the need of the server. The FedSVM algorithm is first proposed in Bakopoulou et al. (2019) for mobile packet classification. We have adapted their FedSVM to our failure prediction problem. Its training process is shown in Fig. 1. The algorithm of the client and server is given by Algo. 1 and Algo. 2, respectively. The main steps of FedSVM are explained hereafter.",
            "We have experimented to evaluate the improvement of FedRF.\nIn this experiment, we constructed a VFL scenario with two clients sharing data features using the Bosch dataset. There are 50 independent features in each client, which are extracted after performing the principal component analysis (PCA) from different production lines and the same 11154 samples. The experiment results are shown in Table 2.\nIt can be seen that we get better prediction results than the federated random forest algorithm proposed in Liu et al. (2020a).",
            "S1. Construct prediction table. We first construct a prediction table containing the ground truth (GT) label, the prediction results (Pre) of CL and FL algorithms of products ordered by timestamp (ts).",
            "MSA is one of the commonly used analysis methods in manufacturing Montgomery (2007). The learning-based failure prediction method can be seen as a product quality measurement system. Taking the Bosch company’s product quality testing results as a benchmark, we can analyze the FL and CL algorithms through the MSA method. The evaluation measurements in MSA mainly include Accuracy (ACC), Precision (PRE), and Stability. On this basis, F1, AUC, and Matthew’s Correlation Coefficient (MCC) are also involved. The six measurements we use in the empirical study are provided in Table 3, where P represents the number of GT positive cases, N is the number of GT negative cases, TP (hit) is true positive, TN (correct rejection) is true negative, FP (false alarm) is false positive, and FN (miss) is false negative.",
            "MCC is suitable for evaluating the prediction results of unbalanced data. AUC is a commonly used two-category evaluation method, and its value is the area enclosed by the ROC curve and the reference line. The x-axis of a ROC curve is the false positive rate, and the y-axis of a ROC curve is the true positive rate. It shows the relationship between clinical sensitivity and specificity for every possible cut-off. It is a graph with: The x-axis showing 1-specificity (=𝙵𝙿/(𝙵𝙿+𝚃𝙽)absent𝙵𝙿𝙵𝙿𝚃𝙽\\mathtt{=FP/(FP+TN)}) The y-axis showing sensitivity (=𝚃𝙿/(𝚃𝙿+𝙵𝙽)absent𝚃𝙿𝚃𝙿𝙵𝙽\\mathtt{=TP/(TP+FN)}). The range of AUC value is between 0 and 1.",
            "The data features are shown in Table 4. There are 1184687 products in the dataset, including 1177808 positive samples (Pos) and 6879 negative ones (Neg). In the feature space, the dataset has 968 features. These features are collected from 51 workstations (S1-S51) on 4 production lines L0-L3 that contain 168, 513, 42, and 245 features, respectively. L1_S24_F1695 indicates that the feature No.1695 was observed at the No.24 workstation of the L1 production line. The label Response represents whether the final product is qualified (label = 0) or not (label = 1). From the perspective of data items, only a few items (0.58%) in the dataset result are qualified, and the data is extremely unbalanced. The data is also extremely sparse, with only a few workstations collecting data from most products Carbery et al. (2019).",
            "To compare FedSVM and SVM on the testing data, we form four workshops A, B, C, and D that do not share manufacturing data but have the same structure and configuration of the production line. Under the premise that the product features are aligned, they contain different samples, and each sample has a unique ID. Each workshop can be regarded as an independent client. Table 5 shows the data used in this experiment. The number of samples on the 4 clients is basically the same. In the experiment, the data set is randomly distributed to all clients on average, each of which possesses 3000 positive and 1500 negative samples. The four workshops have 713 common features of data.",
            "To compare FedRF and RF on the given testing data, it is assumed that the first three production lines (L0, L1, L2) of the Bosch dataset belong to the same organization O1, and the L3 production line belongs to another organization O2. O1 and O2 are independent. Since the samples in O1 and O2 have the same ID and different characteristics, VFL is applied. The data set used in the FedRF experiment is shown in Table 6. We extract the features belonging to L0, L1, and L2 as a group, and the features belonging to L3 as another group. Then we perform principal component analysis (PCA) to reduce the feature dimension in O1/O2 from 723/245 to 22/22, respectively. According to the overall analysis of PCA results, the first 22 dimensions can represent more than 95% of the variance, so reducing to 22 dimensions, respectively, which will not cause too much information loss Zhang et al. (2016). The positive and negative sample numbers are 12000 and 6000, respectively.",
            "Table 7 shows the experimental results. To ensure that the data set and the algorithm kernel are consistent, the baseline is the result of FedSVM when the number of clients is set to 1, ie., FedSVM degenerates into SVM. Under this premise, the results of FedSVM and SVM are compared. When analyzing the stability, the experiment data is ordered by time-series and then divided into 10 groups on average. The measurements of each group are calculated. The overall results of stability are shown in Fig. 5. The average value of stability is above 0.7 for FedSVM and SVM. The variance of the stability is given as Stability (Var) in Table 7.",
            "In Figure 5, FedSVM performs slightly better than SVM on two test groups, namely 1 and 7. Similar results are also shown for the Precision measure in Table 7. This effect is only shown in the HFL scenario, where the clients contribute local data features to the central server. If the amount of data on each client is small, FL’s effect can be better than CL because FL expands the number of IID data samples in the HFL scenario.",
            "The experimental results are shown in Table 8. FedRF degenerates into RF by combining two clients so that the effect of FedRF and RF can be compared under the premise of ensuring the consistency of the testing data and the algorithm kernel. When analyzing the stability, the test set is divided into 10 groups on average according to the time-series, and the measurements of each group are calculated. The variance of the stability is given in Table 8, and the overall results of stability are shown in Fig. 6.",
            "We first constructed a timed state sequence indicating the prediction error using FedSVM and SVM, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-SVM_resa and LABEL:tab:RQ3-SVM_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-SVM_resc.\nThe average difference value between each pair of parameters is 0.054. The maximum difference value is 0.096. It means that there exists no significant difference between the two Markov models, and the prediction error between FedSVM and SVM are almost equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedSVM and SVM in the subsequent Bosch production was not significantly different.",
            "We first constructed a timed state sequence indicating the prediction error using FedRF and RF, respectively, based on which their Markov models are fitted. The parameters of two Markov models are given in Table LABEL:tab:RQ3-RF_resa and LABEL:tab:RQ3-RF_resa. The value difference between each pair of parameters is calculated in Table LABEL:tab:RQ3-RF_resc.\nThe average difference value between each pair of parameters is 0.035. The maximum difference value is 0.100. It means that there exists no significant difference between the two Markov models, and the prediction error between FedRF and RF are equally distributed on the estimated unknown Bosch data. Therefore, the performance of FedRF and RF in the subsequent Bosch production was not significantly different.",
            "The experimental results are shown in Table 11. There are outliers in the test results, so the sum of the samples in each cluster is less than 100. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedSVM is heterogeneous. It enforces the conclusion that FedSVM and SVM have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "The experimental results are shown in Table 12. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedRF is heterogeneous. It enforces the conclusion that FedRF and RF have no significant difference on heterogeneous manufacturing data for the problem of failure prediction.",
            "Another threat to construct validity is the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2) used in the experiment. In the industry, the threshold value is set according to the production needs. We have performed a hypothesis test for the difference between the two approaches’ performances to explain that the difference between FL and CL is within the threshold. The original hypothesis H0 is difference >δabsent𝛿>\\delta, and the alternative hypothesis H1 is difference <δabsent𝛿<\\delta, where the difference = CL – FL on the same random partial testing data group. Suppose α𝛼\\alpha = 0.05. The p-value of the evaluation metrics for FedSVM vs. SVM and FedForest vs. RForest is shown in Table 13 and Table 14, respectively. As a​l​p​h​a>𝑎𝑙𝑝ℎ𝑎absentalpha> p-value for all metrics, the alternative hypothesis H1 is accepted, which means that the difference between CL and FL is less than the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2).",
            "Besides, some works have shown that the effect of FL is also related to encryption algorithms R et al. (2019); Tao et al. (2020); Feng et al. (2020); Olivia et al. (2019); Lu et al. (2020); Li et al. (2019, 2020b). If the encryption strength increases, the information loss on the data will be worse. So that the effect of FL decreases. The trade-off between data privacy protection and the accuracy of the trained model is still inevitable. It is still considered an open question of how the effect of FL is related to other factors."
        ]
    },
    "S5.T11": {
        "caption": "Table 11: Experiment Results of RQ4 on FedSVM",
        "table": "<table id=\"S5.T11.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T11.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T11.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T11.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Step</span></td>\n<td id=\"S5.T11.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T11.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Clusters</span></td>\n<td id=\"S5.T11.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T11.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T11.1.1.1.1.1\" class=\"ltx_p\" style=\"width:51.2pt;\"><span id=\"S5.T11.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Distance threshold (<sup id=\"S5.T11.1.1.1.1.1.1.1\" class=\"ltx_sup\"><span id=\"S5.T11.1.1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_medium ltx_font_italic\">∘</span></sup>)</span></span>\n</span>\n</td>\n<td id=\"S5.T11.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T11.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T11.1.1.4.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T11.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Contour factor</span></span>\n</span>\n</td>\n<td id=\"S5.T11.1.1.5\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T11.1.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T11.1.1.5.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T11.1.1.5.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Samples / cluster</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T11.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T11.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T11.1.2.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">k = 1</span></td>\n<td id=\"S5.T11.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T11.1.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">2</span></td>\n<td id=\"S5.T11.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T11.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T11.1.2.3.1.1\" class=\"ltx_p\" style=\"width:51.2pt;\"><span id=\"S5.T11.1.2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">5</span></span>\n</span>\n</td>\n<td id=\"S5.T11.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T11.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T11.1.2.4.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T11.1.2.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.456</span></span>\n</span>\n</td>\n<td id=\"S5.T11.1.2.5\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T11.1.2.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T11.1.2.5.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T11.1.2.5.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">92 / 6</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T11.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T11.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T11.1.3.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">k = 2</span></td>\n<td id=\"S5.T11.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T11.1.3.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">2</span></td>\n<td id=\"S5.T11.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T11.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T11.1.3.3.1.1\" class=\"ltx_p\" style=\"width:51.2pt;\"><span id=\"S5.T11.1.3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">8</span></span>\n</span>\n</td>\n<td id=\"S5.T11.1.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T11.1.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T11.1.3.4.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T11.1.3.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.421</span></span>\n</span>\n</td>\n<td id=\"S5.T11.1.3.5\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T11.1.3.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T11.1.3.5.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T11.1.3.5.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">89 / 6</span></span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The experimental results are shown in Table 11. There are outliers in the test results, so the sum of the samples in each cluster is less than 100. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedSVM is heterogeneous. It enforces the conclusion that FedSVM and SVM have no significant difference on heterogeneous manufacturing data for the problem of failure prediction."
        ]
    },
    "S5.T12": {
        "caption": "Table 12: Experiment Results of RQ4 on FedRF",
        "table": "<table id=\"S5.T12.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T12.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T12.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T12.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Step</span></td>\n<td id=\"S5.T12.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T12.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Clusters</span></td>\n<td id=\"S5.T12.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T12.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T12.1.1.1.1.1\" class=\"ltx_p\" style=\"width:51.2pt;\"><span id=\"S5.T12.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Distance threshold (<sup id=\"S5.T12.1.1.1.1.1.1.1\" class=\"ltx_sup\"><span id=\"S5.T12.1.1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_medium ltx_font_italic\">∘</span></sup>)</span></span>\n</span>\n</td>\n<td id=\"S5.T12.1.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T12.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T12.1.1.4.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T12.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Contour factor</span></span>\n</span>\n</td>\n<td id=\"S5.T12.1.1.5\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S5.T12.1.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T12.1.1.5.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T12.1.1.5.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Samples / cluster</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T12.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T12.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T12.1.2.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">k = 1</span></td>\n<td id=\"S5.T12.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T12.1.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">2</span></td>\n<td id=\"S5.T12.1.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T12.1.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T12.1.2.3.1.1\" class=\"ltx_p\" style=\"width:51.2pt;\"><span id=\"S5.T12.1.2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">4</span></span>\n</span>\n</td>\n<td id=\"S5.T12.1.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T12.1.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T12.1.2.4.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T12.1.2.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.524</span></span>\n</span>\n</td>\n<td id=\"S5.T12.1.2.5\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S5.T12.1.2.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T12.1.2.5.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T12.1.2.5.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">94 / 6</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T12.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T12.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T12.1.3.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">k = 2</span></td>\n<td id=\"S5.T12.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T12.1.3.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">2</span></td>\n<td id=\"S5.T12.1.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T12.1.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T12.1.3.3.1.1\" class=\"ltx_p\" style=\"width:51.2pt;\"><span id=\"S5.T12.1.3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">8</span></span>\n</span>\n</td>\n<td id=\"S5.T12.1.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T12.1.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T12.1.3.4.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T12.1.3.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">0.473</span></span>\n</span>\n</td>\n<td id=\"S5.T12.1.3.5\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S5.T12.1.3.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T12.1.3.5.1.1\" class=\"ltx_p\" style=\"width:37.0pt;\"><span id=\"S5.T12.1.3.5.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">78 / 22</span></span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The experimental results are shown in Table 12. It can be seen that the testing data is divided into 2 clusters. The difference between clusters is no less than the distance threshold, which means that the data used in the experiment of FedRF is heterogeneous. It enforces the conclusion that FedRF and RF have no significant difference on heterogeneous manufacturing data for the problem of failure prediction."
        ]
    },
    "S6.T13": {
        "caption": "Table 13: P-value of FedSVM vs. SVM (α𝛼\\alpha = 0.05)",
        "table": "<table id=\"S6.T13.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S6.T13.3.1\" class=\"ltx_tr\">\n<td id=\"S6.T13.3.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S6.T13.3.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T13.3.1.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">Metrics</span>\n</span>\n</td>\n<td id=\"S6.T13.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Threshold</td>\n<td id=\"S6.T13.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Statistics</td>\n<td id=\"S6.T13.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">p-value</td>\n</tr>\n<tr id=\"S6.T13.3.2\" class=\"ltx_tr\">\n<td id=\"S6.T13.3.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S6.T13.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T13.3.2.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">ACC</span>\n</span>\n</td>\n<td id=\"S6.T13.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1</td>\n<td id=\"S6.T13.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">-22.48877</td>\n<td id=\"S6.T13.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">5.44616e-41</td>\n</tr>\n<tr id=\"S6.T13.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T13.3.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S6.T13.3.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T13.3.3.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">Precision</span>\n</span>\n</td>\n<td id=\"S6.T13.3.3.2\" class=\"ltx_td ltx_align_center\">0.1</td>\n<td id=\"S6.T13.3.3.3\" class=\"ltx_td ltx_align_center\">-83.57313</td>\n<td id=\"S6.T13.3.3.4\" class=\"ltx_td ltx_align_center\">6.33511e-94</td>\n</tr>\n<tr id=\"S6.T13.3.4\" class=\"ltx_tr\">\n<td id=\"S6.T13.3.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S6.T13.3.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T13.3.4.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">F1</span>\n</span>\n</td>\n<td id=\"S6.T13.3.4.2\" class=\"ltx_td ltx_align_center\">0.1</td>\n<td id=\"S6.T13.3.4.3\" class=\"ltx_td ltx_align_center\">-17.48523</td>\n<td id=\"S6.T13.3.4.4\" class=\"ltx_td ltx_align_center\">2.45813e-32</td>\n</tr>\n<tr id=\"S6.T13.3.5\" class=\"ltx_tr\">\n<td id=\"S6.T13.3.5.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S6.T13.3.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T13.3.5.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">MCC</span>\n</span>\n</td>\n<td id=\"S6.T13.3.5.2\" class=\"ltx_td ltx_align_center\">0.2</td>\n<td id=\"S6.T13.3.5.3\" class=\"ltx_td ltx_align_center\">-20.44888</td>\n<td id=\"S6.T13.3.5.4\" class=\"ltx_td ltx_align_center\">1.27870e-37</td>\n</tr>\n<tr id=\"S6.T13.3.6\" class=\"ltx_tr\">\n<td id=\"S6.T13.3.6.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S6.T13.3.6.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T13.3.6.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">AUC</span>\n</span>\n</td>\n<td id=\"S6.T13.3.6.2\" class=\"ltx_td ltx_align_center\">0.2</td>\n<td id=\"S6.T13.3.6.3\" class=\"ltx_td ltx_align_center\">-26.63278</td>\n<td id=\"S6.T13.3.6.4\" class=\"ltx_td ltx_align_center\">3.08126e-47</td>\n</tr>\n<tr id=\"S6.T13.3.7\" class=\"ltx_tr\">\n<td id=\"S6.T13.3.7.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S6.T13.3.7.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T13.3.7.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">stability</span>\n</span>\n</td>\n<td id=\"S6.T13.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.1</td>\n<td id=\"S6.T13.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">-5.40692</td>\n<td id=\"S6.T13.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.00021</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Another threat to construct validity is the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2) used in the experiment. In the industry, the threshold value is set according to the production needs. We have performed a hypothesis test for the difference between the two approaches’ performances to explain that the difference between FL and CL is within the threshold. The original hypothesis H0 is difference >δabsent𝛿>\\delta, and the alternative hypothesis H1 is difference <δabsent𝛿<\\delta, where the difference = CL – FL on the same random partial testing data group. Suppose α𝛼\\alpha = 0.05. The p-value of the evaluation metrics for FedSVM vs. SVM and FedForest vs. RForest is shown in Table 13 and Table 14, respectively. As a​l​p​h​a>𝑎𝑙𝑝ℎ𝑎absentalpha> p-value for all metrics, the alternative hypothesis H1 is accepted, which means that the difference between CL and FL is less than the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2)."
        ]
    },
    "S6.T14": {
        "caption": "Table 14: P-value of FedForest vs. RForest (α𝛼\\alpha = 0.05)",
        "table": "<table id=\"S6.T14.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S6.T14.3.1\" class=\"ltx_tr\">\n<td id=\"S6.T14.3.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span id=\"S6.T14.3.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T14.3.1.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">Metrics</span>\n</span>\n</td>\n<td id=\"S6.T14.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Threshold</td>\n<td id=\"S6.T14.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Statistics</td>\n<td id=\"S6.T14.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">p-value</td>\n</tr>\n<tr id=\"S6.T14.3.2\" class=\"ltx_tr\">\n<td id=\"S6.T14.3.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S6.T14.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T14.3.2.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">ACC</span>\n</span>\n</td>\n<td id=\"S6.T14.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1</td>\n<td id=\"S6.T14.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">-34.44843</td>\n<td id=\"S6.T14.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">3.16706e-57</td>\n</tr>\n<tr id=\"S6.T14.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T14.3.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S6.T14.3.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T14.3.3.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">Precision</span>\n</span>\n</td>\n<td id=\"S6.T14.3.3.2\" class=\"ltx_td ltx_align_center\">0.1</td>\n<td id=\"S6.T14.3.3.3\" class=\"ltx_td ltx_align_center\">-48.40227</td>\n<td id=\"S6.T14.3.3.4\" class=\"ltx_td ltx_align_center\">5.04976e-71</td>\n</tr>\n<tr id=\"S6.T14.3.4\" class=\"ltx_tr\">\n<td id=\"S6.T14.3.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S6.T14.3.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T14.3.4.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">F1</span>\n</span>\n</td>\n<td id=\"S6.T14.3.4.2\" class=\"ltx_td ltx_align_center\">0.1</td>\n<td id=\"S6.T14.3.4.3\" class=\"ltx_td ltx_align_center\">-75.16218</td>\n<td id=\"S6.T14.3.4.4\" class=\"ltx_td ltx_align_center\">1.95987e-89</td>\n</tr>\n<tr id=\"S6.T14.3.5\" class=\"ltx_tr\">\n<td id=\"S6.T14.3.5.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S6.T14.3.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T14.3.5.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">MCC</span>\n</span>\n</td>\n<td id=\"S6.T14.3.5.2\" class=\"ltx_td ltx_align_center\">0.2</td>\n<td id=\"S6.T14.3.5.3\" class=\"ltx_td ltx_align_center\">-12.90324</td>\n<td id=\"S6.T14.3.5.4\" class=\"ltx_td ltx_align_center\">3.11933e-23</td>\n</tr>\n<tr id=\"S6.T14.3.6\" class=\"ltx_tr\">\n<td id=\"S6.T14.3.6.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S6.T14.3.6.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T14.3.6.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">AUC</span>\n</span>\n</td>\n<td id=\"S6.T14.3.6.2\" class=\"ltx_td ltx_align_center\">0.2</td>\n<td id=\"S6.T14.3.6.3\" class=\"ltx_td ltx_align_center\">-16.77851</td>\n<td id=\"S6.T14.3.6.4\" class=\"ltx_td ltx_align_center\">5.26331e-31</td>\n</tr>\n<tr id=\"S6.T14.3.7\" class=\"ltx_tr\">\n<td id=\"S6.T14.3.7.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S6.T14.3.7.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S6.T14.3.7.1.1.1\" class=\"ltx_p\" style=\"width:39.8pt;\">stability</span>\n</span>\n</td>\n<td id=\"S6.T14.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.1</td>\n<td id=\"S6.T14.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">-9.83780</td>\n<td id=\"S6.T14.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">2.04964e-06</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Another threat to construct validity is the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2) used in the experiment. In the industry, the threshold value is set according to the production needs. We have performed a hypothesis test for the difference between the two approaches’ performances to explain that the difference between FL and CL is within the threshold. The original hypothesis H0 is difference >δabsent𝛿>\\delta, and the alternative hypothesis H1 is difference <δabsent𝛿<\\delta, where the difference = CL – FL on the same random partial testing data group. Suppose α𝛼\\alpha = 0.05. The p-value of the evaluation metrics for FedSVM vs. SVM and FedForest vs. RForest is shown in Table 13 and Table 14, respectively. As a​l​p​h​a>𝑎𝑙𝑝ℎ𝑎absentalpha> p-value for all metrics, the alternative hypothesis H1 is accepted, which means that the difference between CL and FL is less than the threshold δ𝛿\\delta ( δ=0.1𝛿0.1\\delta=0.1 or δ=0.2𝛿0.2\\delta=0.2)."
        ]
    }
}