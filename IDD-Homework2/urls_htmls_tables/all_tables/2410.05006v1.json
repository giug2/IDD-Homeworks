{
    "S2.T1": {
        "caption": "Table 1: Examples of related skill pairs in SkillMatch.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S2.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S2.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.1.1\">Skill 1</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S2.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.2.1\">Skill 2</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S2.T1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.3.1\">Frequency</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.2.1.1\">HTML</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.2.1.2\">CSS</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S2.T1.1.2.1.3\">705</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.3.2.1\">grammar</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.3.2.2\">spelling</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.3.2.3\">137</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.4.3.1\">deep learning</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.4.3.2\">natural language processing</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.4.3.3\">66</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.5.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.5.4.1\">GDPR</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.5.4.2\">CCPA</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.5.4.3\">41</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.6.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.6.5.1\">AS9100</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.6.5.2\">ISO 9001</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.6.5.3\">14</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.7.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.7.6.1\">paid search</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.7.6.2\">paid social</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.7.6.3\">7</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.8.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.8.7.1\">Single Sign-On (SSO)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.8.7.2\">Multi-Factor Authentication (MFA)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T1.1.8.7.3\">6</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.9.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S2.T1.1.9.8.1\">payroll software</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S2.T1.1.9.8.2\">benefits software</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S2.T1.1.9.8.3\">5</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "The related skills are extracted from the sentence using a simple few-shot learning strategy, constructing a prompt with examples.\nWe use the recently introduced Gemini 1.5 Flash<sup class=\"ltx_note_mark\">1</sup>\n1<sup class=\"ltx_note_mark\">1</sup>\n11https://deepmind.google/technologies/gemini/flash/ model for its strong performance and cost efficiency.\nWe refer to Appendix\u00a0A for details on the prompt.\nAfterwards, the casing of all extracted skills is normalized towards its most frequent form, such that for example both \u201ccss\u201d and \u201cCSS\u201d are represented by their most common variant \u201cCSS\u201d.\nFinally, related skill pairs are defined as those that co-occur at least 3 times, and have a conditional probability of 25% or above, in each direction.\nThis dual criterion ensures that only closely related skills are considered as positive examples.\nNegative pairs were generated by randomly selecting skills that never appeared together in the lexical patterns, maintaining an equal number of negative and positive pairs to balance the benchmark.\nThe complete benchmark contains 1,000 positive pairs and an equal amount of negative pairs.\nSome examples of related skill pairs in SkillMatch are shown in Table\u00a01."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Comparison of model performance for the skill relatedness task. For the static vector models, the domain-specific versions refer to the models trained from scratch on job ads. For Sentence-BERT, the domain-specific model refers to its fine-tuned variant based on the proposed self-supervised skill co-occurrence objective.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.1.1\">Method</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.2.1\">AUC-PR</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S4.T2.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.3.1\">MRR</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.2.2.1\">Word2Vec</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.2.2\">0.844</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.2.3\">0.187</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.3.3.1\">Word2Vec<sup class=\"ltx_sup\" id=\"S4.T2.1.3.3.1.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T2.1.3.3.1.1.1\">ds</span></sup>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.3.3.2\">0.922</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.3.3.3\">0.300</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.4.4.1\">fastText</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.4.4.2\">0.913</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.4.4.3\">0.262</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.5.5.1\">fastText<sup class=\"ltx_sup\" id=\"S4.T2.1.5.5.1.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T2.1.5.5.1.1.1\">ds</span></sup>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.5.5.2\">0.941</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.5.5.3\">0.325</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.6.6.1\">Sentence-BERT</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.6.6.2\">0.876</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.6.6.3\">0.145</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.1.7.7.1\">Sentence-BERT<sup class=\"ltx_sup\" id=\"S4.T2.1.7.7.1.1\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"S4.T2.1.7.7.1.1.1\">ds</span></sup><span class=\"ltx_text ltx_phantom\" id=\"S4.T2.1.7.7.1.2\"><span style=\"visibility:hidden\">x</span></span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.7.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.7.7.2.1\">0.969</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.7.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.7.7.3.1\">0.357</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [
            "= domain-specific versions."
        ],
        "references": [
            "The performance on SkillMatch for each method is shown in Table\u00a02.\nOur contrastive learning objective for the Sentence-BERT model significantly outperforms all other models.\nThis shows the effectiveness of modeling skill relatedness based on skill co-occurrence in job ads.\nThe domain-specific static vectors outperform their generic versions, despite being trained on fewer data.\nNotably, the generic Word2Vec model performs much worse compared to the fastText model.\nFurther analysis reveals that this is due to words not being modeled in the generic Word2Vec model.\nThe number of skill phrases in SkillMatch without a Word2Vec representation drops from 193 to 36 when using the domain-specific model.\nfastText does not suffer from this out-of-vocabulary issue by design."
        ]
    }
}