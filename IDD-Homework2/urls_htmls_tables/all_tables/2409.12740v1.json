{
    "S4.T1": {
        "caption": "Table 1: Statics of PixelRec and Amazon Book Reviews.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.1.1.1.1\">Dataset</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.2\">#User</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.3\">#Item</th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.4\">#Interaction</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.1.2.1.1\">Pixel200K</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.2.1.2\">200,000</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T1.1.2.1.3\">96,282</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_t\" id=\"S4.T1.1.2.1.4\">3,965,656</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.3.2.1\">Pixel1M</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.3.2.2\">1,001,822</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.3.2.3\">100,541</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right\" id=\"S4.T1.1.3.2.4\">19,886,579</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.4.3.1\">Pixel8M</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.4.3.2\">8,886,078</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T1.1.4.3.3\">407,082</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right\" id=\"S4.T1.1.4.3.4\">158,488,652</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.1.5.4.1\">Books</th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.1.5.4.2\">694,898</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T1.1.5.4.3\">686,624</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_bb\" id=\"S4.T1.1.5.4.4\">10,053,086</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "For offline experiments, we evaluate HLLM on two large-scale datasets: PixelRec (including three subsets: 200K, 1M, and 8M)\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib5\" title=\"\">2024</a>)</cite>, and Amazon Book Reviews (Books)&#160;\n(Cheng et\u00a0al. 2024), and Amazon Book Reviews (Books)\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(McAuley et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib20\" title=\"\">2015</a>)</cite>. Consistent with previous works&#160;\n(McAuley et\u00a0al. 2015). Consistent with previous works\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib5\" title=\"\">2024</a>; Zhai et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib37\" title=\"\">2024</a>)</cite>, we adopt the same data preprocessing and evaluation protocols to ensure a fair comparison. A more detailed analysis of these datasets after preprocessing is presented in Table&#160;\n(Cheng et\u00a0al. 2024; Zhai et\u00a0al. 2024), we adopt the same data preprocessing and evaluation protocols to ensure a fair comparison. A more detailed analysis of these datasets after preprocessing is presented in Table\u00a01 and Figure\u00a05. We utilize a leave-one-out approach to split the data into training, validation, and testing sets. Performance is measured using the metrics Recall@K (R@K) and NDCG@K (N@K). All open-source datasets are employed solely for training and evaluating in offline experiments."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Ablation studies of pre-training on Pixel200K with HLLM-1B.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.1\">Item LLM</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.2\">User LLM</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.3\">R@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.4\">R@10</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.5\">N@5</th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.6\">N@10</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T2.1.2.1.1\">Scratch</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T2.1.2.1.2\">Scratch</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T2.1.2.1.3\">3.330</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T2.1.2.1.4\">5.063</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T2.1.2.1.5\">2.199</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S4.T2.1.2.1.6\">2.755</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.3.2.1\">Scratch</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.3.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.3.2.2.1\">Pre-trained</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.3.2.3\">3.556</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.3.2.4\">5.416</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.3.2.5\">2.371</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T2.1.3.2.6\">2.969</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.4.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.4.3.1.1\">Pre-trained</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.4.3.2\">Scratch</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.4.3.3\">3.521</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.4.3.4\">5.331</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T2.1.4.3.5\">2.358</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T2.1.4.3.6\">2.940</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.5.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T2.1.5.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.5.4.1.1\">Pre-trained</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T2.1.5.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.5.4.2.1\">Pre-trained</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T2.1.5.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.5.4.3.1\">3.755</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T2.1.5.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.5.4.4.1\">5.581</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T2.1.5.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.5.4.5.1\">2.513</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\" id=\"S4.T2.1.5.4.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.5.4.6.1\">3.100</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "As clearly seen from Table\u00a02, pre-trained weights are beneficial for HLLM, including both item feature extraction and user interest modeling. Furthermore, as shown in Table\u00a03, the performance is positively correlated with the number of pre-trained tokens, indicating that the quality of pre-trained weights also impacts the recommendation task.\nHowever, supervised fine-tuning (SFT) on conversation data can result in slight negative effects, probably because world knowledge is primarily acquired during the pre-training stage, and SFT mainly enhances instruction-following abilities, which do not aid in recommendation tasks\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Zhou et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib42\" title=\"\">2024</a>)</cite>.\n(Zhou et\u00a0al. 2024)."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: The impact of different pre-training token counts on Pixel200K with HLLM-1B. \u201c+chat\u201d means SFT on conversation data.\nThe CSR metric is the average performance on the common sense reasoning tasks.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.2\">#Tokens</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.3\">R@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.4\">R@10</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.5\">N@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.6\">N@10</th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T3.1.1.1\">CSR <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T3.1.1.1.m1.1\"><semantics id=\"S4.T3.1.1.1.m1.1a\"><mo id=\"S4.T3.1.1.1.m1.1.1\" stretchy=\"false\" xref=\"S4.T3.1.1.1.m1.1.1.cmml\">&#8593;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.m1.1b\"><ci id=\"S4.T3.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.m1.1.1\">&#8593;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.m1.1c\">\\uparrow</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T3.1.1.1.m1.1d\">&#8593;</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.2.1.1\">0T</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.2.1.2\">3.330</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.2.1.3\">5.047</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.2.1.4\">2.199</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.2.1.5\">2.755</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S4.T3.1.2.1.6\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.3.2.1\">0.1T</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.3.2.2\">3.539</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.3.2.3\">5.142</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.3.2.4\">2.399</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.3.2.5\">2.915</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T3.1.3.2.6\">46.11</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.4.3.1\">1T</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.4.3.2\">3.613</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.4.3.3\">5.409</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.4.3.4\">2.414</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.4.3.5\">2.993</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T3.1.4.3.6\">50.22</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.5.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.5.4.1\">1T+chat</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.5.4.2\">3.610</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.5.4.3\">5.387</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.5.4.4\">2.411</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.5.4.5\">2.984</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T3.1.5.4.6\">51.36</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.6.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.6.5.1\">2T</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.6.5.2\">3.650</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.6.5.3\">5.510</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.6.5.4\">2.466</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.6.5.5\">3.063</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T3.1.6.5.6\">51.64</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.7.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T3.1.7.6.1\">3T</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T3.1.7.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.7.6.2.1\">3.755</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T3.1.7.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.7.6.3.1\">5.581</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T3.1.7.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.7.6.4.1\">2.513</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T3.1.7.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.7.6.5.1\">3.100</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\" id=\"S4.T3.1.7.6.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.7.6.6.1\">52.99</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "As clearly seen from Table\u00a02, pre-trained weights are beneficial for HLLM, including both item feature extraction and user interest modeling. Furthermore, as shown in Table\u00a03, the performance is positively correlated with the number of pre-trained tokens, indicating that the quality of pre-trained weights also impacts the recommendation task.\nHowever, supervised fine-tuning (SFT) on conversation data can result in slight negative effects, probably because world knowledge is primarily acquired during the pre-training stage, and SFT mainly enhances instruction-following abilities, which do not aid in recommendation tasks\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Zhou et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib42\" title=\"\">2024</a>)</cite>.\n(Zhou et\u00a0al. 2024)."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Ablation studies of fine-tuning on Pixel200K with HLLM-1B.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.1\">Item LLM</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.2\">User LLM</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.3\">R@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.4\">R@10</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.5\">N@5</th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T4.1.1.1.6\">N@10</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.2.1.1\">Frozen</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.2.1.2.1\">Learnable</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.2.1.3\">0.588</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.2.1.4\">0.945</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T4.1.2.1.5\">0.372</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S4.T4.1.2.1.6\">0.486</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.3.2.1.1\">Learnable</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.3.2.2\">Frozen</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.3.2.3\">1.619</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.3.2.4\">2.470</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.3.2.5\">1.070</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T4.1.3.2.6\">1.343</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.4.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.4.3.1.1\">Learnable</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.4.3.2.1\">Learnable</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.4.3.3.1\">3.755</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.4.3.4.1\">5.581</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T4.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.4.3.5.1\">2.513</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T4.1.4.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.4.3.6.1\">3.100</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" colspan=\"2\" id=\"S4.T4.1.5.4.1\">SASRec-1B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S4.T4.1.5.4.2\">1.973</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S4.T4.1.5.4.3\">2.868</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S4.T4.1.5.4.4\">1.352</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t\" id=\"S4.T4.1.5.4.5\">1.640</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "It is also evident that fine-tuning both the Item LLM and User LLM is crucial for outperforming ID-based models, as shown in Table\u00a04.\nWhen we freeze the Item LLM and only fine-tune the User LLM, using mean pooling of all token outputs in the last layer of TinyLlama-1.1B as item features, we find that the performance is very poor. This indicates that LLMs trained on predicting the next token are not directly suitable as feature extractors.\nSimilarly, when we use an Item LLM that has been fine-tuned on Pixel200K and freeze the pre-trained User LLM, the performance remains critically low."
        ]
    },
    "S4.T5": {
        "caption": "Table 5: Experiments with different sizes of the item model on Pixel200K. SASRec is used as the user model for all.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T5.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.1\">Item Model</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.2\">#Params</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.3\">R@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.4\">R@10</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.5\">N@5</th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.6\">N@10</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.2.1.1\">BERT-Base</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.2.1.2\">110M</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.2.1.3\">2.576</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.2.1.4\">4.020</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T5.1.2.1.5\">1.694</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S4.T5.1.2.1.6\">2.158</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.1.3.2.1\">BERT-Large</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.1.3.2.2\">340M</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.1.3.2.3\">3.032</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.1.3.2.4\">4.635</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T5.1.3.2.5\">1.993</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T5.1.3.2.6\">2.508</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T5.1.4.3.1\">TinyLlama</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T5.1.4.3.2\">1.1B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T5.1.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.4.3.3.1\">3.484</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T5.1.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.4.3.4.1\">5.239</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T5.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.4.3.5.1\">2.319</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\" id=\"S4.T5.1.4.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.4.3.6.1\">2.883</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "The experimental results for increasing the model\u2019s parameter count are shown in Table\u00a05 and Table\u00a06. It can be observed that the growth in the number of parameters for both Item LLM and User LLM consistently leads to performance improvements.\nFinally, we scale up both the Item LLM and User LLM from 1 billion parameters to 7 billion parameters on the Amazon Books. As shown in Table\u00a07, this leads to further performance improvements, demonstrating that HLLM has excellent scalability."
        ]
    },
    "S4.T6": {
        "caption": "Table 6: Experiments with different sizes of the user model on Pixel200K. Llama-2L maintains the same architecture as Llama but uses only 2 decoder layers. TinyLlama-1.1B is used as the item model for all. All user models are trained from scratch.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T6.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T6.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.1.1.1.1\">User Model</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.1.1.1.2\">#Params</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.1.1.1.3\">R@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.1.1.1.4\">R@10</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.1.1.1.5\">N@5</th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T6.1.1.1.6\">N@10</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T6.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.1.2.1.1\">SASRec</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.1.2.1.2\">4M</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.1.2.1.3\">3.484</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.1.2.1.4\">5.239</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.1.2.1.5\">2.319</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S4.T6.1.2.1.6\">2.883</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.1.3.2.1\">Llama-2L</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.1.3.2.2\">0.1B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.1.3.2.3\">3.494</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.1.3.2.4\">5.233</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T6.1.3.2.5\">2.338</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T6.1.3.2.6\">2.898</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.1.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T6.1.4.3.1\">TinyLlama</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T6.1.4.3.2\">1.1B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T6.1.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.4.3.3.1\">3.521</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T6.1.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.4.3.4.1\">5.331</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T6.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.4.3.5.1\">2.358</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\" id=\"S4.T6.1.4.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.1.4.3.6.1\">2.940</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "The experimental results for increasing the model\u2019s parameter count are shown in Table\u00a05 and Table\u00a06. It can be observed that the growth in the number of parameters for both Item LLM and User LLM consistently leads to performance improvements.\nFinally, we scale up both the Item LLM and User LLM from 1 billion parameters to 7 billion parameters on the Amazon Books. As shown in Table\u00a07, this leads to further performance improvements, demonstrating that HLLM has excellent scalability."
        ]
    },
    "S4.T7": {
        "caption": "Table 7: Performance comparison of HLLM with SOTA models. <math alttext=\"\\text{SASRec}_{\\text{vit}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T7.17.m1.1\">\n  <semantics id=\"S4.T7.17.m1.1b\">\n    <msub id=\"S4.T7.17.m1.1.1\" xref=\"S4.T7.17.m1.1.1.cmml\">\n      <mtext id=\"S4.T7.17.m1.1.1.2\" xref=\"S4.T7.17.m1.1.1.2a.cmml\">SASRec</mtext>\n      <mtext id=\"S4.T7.17.m1.1.1.3\" xref=\"S4.T7.17.m1.1.1.3a.cmml\">vit</mtext>\n    </msub>\n    <annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.17.m1.1c\">\n      <apply id=\"S4.T7.17.m1.1.1.cmml\" xref=\"S4.T7.17.m1.1.1\">\n        <csymbol cd=\"ambiguous\" id=\"S4.T7.17.m1.1.1.1.cmml\" xref=\"S4.T7.17.m1.1.1\">subscript</csymbol>\n        <ci id=\"S4.T7.17.m1.1.1.2a.cmml\" xref=\"S4.T7.17.m1.1.1.2\">\n          <mtext id=\"S4.T7.17.m1.1.1.2.cmml\" xref=\"S4.T7.17.m1.1.1.2\">SASRec</mtext>\n        </ci>\n        <ci id=\"S4.T7.17.m1.1.1.3a.cmml\" xref=\"S4.T7.17.m1.1.1.3\">\n          <mtext id=\"S4.T7.17.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T7.17.m1.1.1.3\">vit</mtext>\n        </ci>\n      </apply>\n    </annotation-xml>\n    <annotation encoding=\"application/x-tex\" id=\"S4.T7.17.m1.1d\">\\text{SASRec}_{\\text{vit}}</annotation>\n    <annotation encoding=\"application/x-llamapun\" id=\"S4.T7.17.m1.1e\">SASRec start_POSTSUBSCRIPT vit end_POSTSUBSCRIPT</annotation>\n  </semantics>\n</math> means SASRec uses the ViT as an image encoder for item encoding and trained by BCE loss from&#160;\n<semantics id=\"S4.T7.17.m1.1b\">\n  <msub id=\"S4.T7.17.m1.1.1\" xref=\"S4.T7.17.m1.1.1.cmml\">\n    <mtext id=\"S4.T7.17.m1.1.1.2\" xref=\"S4.T7.17.m1.1.1.2a.cmml\">SASRec</mtext>\n    <mtext id=\"S4.T7.17.m1.1.1.3\" xref=\"S4.T7.17.m1.1.1.3a.cmml\">vit</mtext>\n  </msub>\n  <annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.17.m1.1c\">\n    <apply id=\"S4.T7.17.m1.1.1.cmml\" xref=\"S4.T7.17.m1.1.1\">\n      <csymbol cd=\"ambiguous\" id=\"S4.T7.17.m1.1.1.1.cmml\" xref=\"S4.T7.17.m1.1.1\">subscript</csymbol>\n      <ci id=\"S4.T7.17.m1.1.1.2a.cmml\" xref=\"S4.T7.17.m1.1.1.2\">\n        <mtext id=\"S4.T7.17.m1.1.1.2.cmml\" xref=\"S4.T7.17.m1.1.1.2\">SASRec</mtext>\n      </ci>\n      <ci id=\"S4.T7.17.m1.1.1.3a.cmml\" xref=\"S4.T7.17.m1.1.1.3\">\n        <mtext id=\"S4.T7.17.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T7.17.m1.1.1.3\">vit</mtext>\n      </ci>\n    </apply>\n  </annotation-xml>\n  <annotation encoding=\"application/x-tex\" id=\"S4.T7.17.m1.1d\">\\text{SASRec}_{\\text{vit}}</annotation>\n  <annotation encoding=\"application/x-llamapun\" id=\"S4.T7.17.m1.1e\">SASRec start_POSTSUBSCRIPT vit end_POSTSUBSCRIPT</annotation>\n</semantics>\n<msub id=\"S4.T7.17.m1.1.1\" xref=\"S4.T7.17.m1.1.1.cmml\">\n  <mtext id=\"S4.T7.17.m1.1.1.2\" xref=\"S4.T7.17.m1.1.1.2a.cmml\">SASRec</mtext>\n  <mtext id=\"S4.T7.17.m1.1.1.3\" xref=\"S4.T7.17.m1.1.1.3a.cmml\">vit</mtext>\n</msub>\n<mtext id=\"S4.T7.17.m1.1.1.2\" xref=\"S4.T7.17.m1.1.1.2a.cmml\">SASRec</mtext>\nSASRec<mtext id=\"S4.T7.17.m1.1.1.3\" xref=\"S4.T7.17.m1.1.1.3a.cmml\">vit</mtext>\nvit<annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.17.m1.1c\">\n  <apply id=\"S4.T7.17.m1.1.1.cmml\" xref=\"S4.T7.17.m1.1.1\">\n    <csymbol cd=\"ambiguous\" id=\"S4.T7.17.m1.1.1.1.cmml\" xref=\"S4.T7.17.m1.1.1\">subscript</csymbol>\n    <ci id=\"S4.T7.17.m1.1.1.2a.cmml\" xref=\"S4.T7.17.m1.1.1.2\">\n      <mtext id=\"S4.T7.17.m1.1.1.2.cmml\" xref=\"S4.T7.17.m1.1.1.2\">SASRec</mtext>\n    </ci>\n    <ci id=\"S4.T7.17.m1.1.1.3a.cmml\" xref=\"S4.T7.17.m1.1.1.3\">\n      <mtext id=\"S4.T7.17.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T7.17.m1.1.1.3\">vit</mtext>\n    </ci>\n  </apply>\n</annotation-xml>\n<apply id=\"S4.T7.17.m1.1.1.cmml\" xref=\"S4.T7.17.m1.1.1\">\n  <csymbol cd=\"ambiguous\" id=\"S4.T7.17.m1.1.1.1.cmml\" xref=\"S4.T7.17.m1.1.1\">subscript</csymbol>\n  <ci id=\"S4.T7.17.m1.1.1.2a.cmml\" xref=\"S4.T7.17.m1.1.1.2\">\n    <mtext id=\"S4.T7.17.m1.1.1.2.cmml\" xref=\"S4.T7.17.m1.1.1.2\">SASRec</mtext>\n  </ci>\n  <ci id=\"S4.T7.17.m1.1.1.3a.cmml\" xref=\"S4.T7.17.m1.1.1.3\">\n    <mtext id=\"S4.T7.17.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T7.17.m1.1.1.3\">vit</mtext>\n  </ci>\n</apply>\n<csymbol cd=\"ambiguous\" id=\"S4.T7.17.m1.1.1.1.cmml\" xref=\"S4.T7.17.m1.1.1\">subscript</csymbol>\nsubscript<ci id=\"S4.T7.17.m1.1.1.2a.cmml\" xref=\"S4.T7.17.m1.1.1.2\">\n  <mtext id=\"S4.T7.17.m1.1.1.2.cmml\" xref=\"S4.T7.17.m1.1.1.2\">SASRec</mtext>\n</ci>\n<mtext id=\"S4.T7.17.m1.1.1.2.cmml\" xref=\"S4.T7.17.m1.1.1.2\">SASRec</mtext>\nSASRec<ci id=\"S4.T7.17.m1.1.1.3a.cmml\" xref=\"S4.T7.17.m1.1.1.3\">\n  <mtext id=\"S4.T7.17.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T7.17.m1.1.1.3\">vit</mtext>\n</ci>\n<mtext id=\"S4.T7.17.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T7.17.m1.1.1.3\">vit</mtext>\nvit<annotation encoding=\"application/x-tex\" id=\"S4.T7.17.m1.1d\">\\text{SASRec}_{\\text{vit}}</annotation>\n\\text{SASRec}_{\\text{vit}}<annotation encoding=\"application/x-llamapun\" id=\"S4.T7.17.m1.1e\">SASRec start_POSTSUBSCRIPT vit end_POSTSUBSCRIPT</annotation>\nSASRec start_POSTSUBSCRIPT vit end_POSTSUBSCRIPT means SASRec uses the ViT as an image encoder for item encoding and trained by BCE loss from\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib5\" title=\"\">2024</a>)</cite>. \n(Cheng et\u00a0al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib5\" title=\"\">2024</a>)\n2024). <math alttext=\"*\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T7.18.m2.1\">\n  <semantics id=\"S4.T7.18.m2.1b\">\n    <mo id=\"S4.T7.18.m2.1.1\" xref=\"S4.T7.18.m2.1.1.cmml\">&#8727;</mo>\n    <annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.18.m2.1c\">\n      <times id=\"S4.T7.18.m2.1.1.cmml\" xref=\"S4.T7.18.m2.1.1\"/>\n    </annotation-xml>\n    <annotation encoding=\"application/x-tex\" id=\"S4.T7.18.m2.1d\">*</annotation>\n    <annotation encoding=\"application/x-llamapun\" id=\"S4.T7.18.m2.1e\">&#8727;</annotation>\n  </semantics>\n</math> indicates the result is reproduced by us.\n\n<semantics id=\"S4.T7.18.m2.1b\">\n  <mo id=\"S4.T7.18.m2.1.1\" xref=\"S4.T7.18.m2.1.1.cmml\">&#8727;</mo>\n  <annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.18.m2.1c\">\n    <times id=\"S4.T7.18.m2.1.1.cmml\" xref=\"S4.T7.18.m2.1.1\"/>\n  </annotation-xml>\n  <annotation encoding=\"application/x-tex\" id=\"S4.T7.18.m2.1d\">*</annotation>\n  <annotation encoding=\"application/x-llamapun\" id=\"S4.T7.18.m2.1e\">&#8727;</annotation>\n</semantics>\n<mo id=\"S4.T7.18.m2.1.1\" xref=\"S4.T7.18.m2.1.1.cmml\">&#8727;</mo>\n\u2217<annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.18.m2.1c\">\n  <times id=\"S4.T7.18.m2.1.1.cmml\" xref=\"S4.T7.18.m2.1.1\"/>\n</annotation-xml>\n<times id=\"S4.T7.18.m2.1.1.cmml\" xref=\"S4.T7.18.m2.1.1\"/>\n<annotation encoding=\"application/x-tex\" id=\"S4.T7.18.m2.1d\">*</annotation>\n*<annotation encoding=\"application/x-llamapun\" id=\"S4.T7.18.m2.1e\">&#8727;</annotation>\n\u2217 indicates the result is reproduced by us.\n<math alttext=\"\\dagger\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T7.19.m3.1\">\n  <semantics id=\"S4.T7.19.m3.1b\">\n    <mo id=\"S4.T7.19.m3.1.1\" xref=\"S4.T7.19.m3.1.1.cmml\">&#8224;</mo>\n    <annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.19.m3.1c\">\n      <ci id=\"S4.T7.19.m3.1.1.cmml\" xref=\"S4.T7.19.m3.1.1\">&#8224;</ci>\n    </annotation-xml>\n    <annotation encoding=\"application/x-tex\" id=\"S4.T7.19.m3.1d\">\\dagger</annotation>\n    <annotation encoding=\"application/x-llamapun\" id=\"S4.T7.19.m3.1e\">&#8224;</annotation>\n  </semantics>\n</math> indicates the number of negative samples and the batch size are increased from 512 and 128 to 28k and 512, respectively.\n&#8220;Scratch&#8221; indicates both Item LLM and User LLM are trained from scratch.\n<semantics id=\"S4.T7.19.m3.1b\">\n  <mo id=\"S4.T7.19.m3.1.1\" xref=\"S4.T7.19.m3.1.1.cmml\">&#8224;</mo>\n  <annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.19.m3.1c\">\n    <ci id=\"S4.T7.19.m3.1.1.cmml\" xref=\"S4.T7.19.m3.1.1\">&#8224;</ci>\n  </annotation-xml>\n  <annotation encoding=\"application/x-tex\" id=\"S4.T7.19.m3.1d\">\\dagger</annotation>\n  <annotation encoding=\"application/x-llamapun\" id=\"S4.T7.19.m3.1e\">&#8224;</annotation>\n</semantics>\n<mo id=\"S4.T7.19.m3.1.1\" xref=\"S4.T7.19.m3.1.1.cmml\">&#8224;</mo>\n\u2020<annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.19.m3.1c\">\n  <ci id=\"S4.T7.19.m3.1.1.cmml\" xref=\"S4.T7.19.m3.1.1\">&#8224;</ci>\n</annotation-xml>\n<ci id=\"S4.T7.19.m3.1.1.cmml\" xref=\"S4.T7.19.m3.1.1\">&#8224;</ci>\n\u2020<annotation encoding=\"application/x-tex\" id=\"S4.T7.19.m3.1d\">\\dagger</annotation>\n\\dagger<annotation encoding=\"application/x-llamapun\" id=\"S4.T7.19.m3.1e\">&#8224;</annotation>\n\u2020 indicates the number of negative samples and the batch size are increased from 512 and 128 to 28k and 512, respectively.\n\u201cScratch\u201d indicates both Item LLM and User LLM are trained from scratch.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T7.13\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T7.13.14.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T7.13.14.1.1\">Dataset</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T7.13.14.1.2\">Method</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.13.14.1.3\">R@10</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.13.14.1.4\">R@50</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.13.14.1.5\">R@200</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.13.14.1.6\">N@10</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.13.14.1.7\">N@50</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.13.14.1.8\">N@200</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T7.13.14.1.9\">Impv. (avg)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T7.1.1.2\" rowspan=\"6\"><span class=\"ltx_text\" id=\"S4.T7.1.1.2.1\">Pixel8M</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T7.1.1.1\">\n<math alttext=\"\\text{SASRec}_{\\text{vit}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T7.1.1.1.m1.1\"><semantics id=\"S4.T7.1.1.1.m1.1a\"><msub id=\"S4.T7.1.1.1.m1.1.1\" xref=\"S4.T7.1.1.1.m1.1.1.cmml\"><mtext id=\"S4.T7.1.1.1.m1.1.1.2\" xref=\"S4.T7.1.1.1.m1.1.1.2a.cmml\">SASRec</mtext><mtext id=\"S4.T7.1.1.1.m1.1.1.3\" xref=\"S4.T7.1.1.1.m1.1.1.3a.cmml\">vit</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.1.1.1.m1.1b\"><apply id=\"S4.T7.1.1.1.m1.1.1.cmml\" xref=\"S4.T7.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T7.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T7.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T7.1.1.1.m1.1.1.2a.cmml\" xref=\"S4.T7.1.1.1.m1.1.1.2\"><mtext id=\"S4.T7.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T7.1.1.1.m1.1.1.2\">SASRec</mtext></ci><ci id=\"S4.T7.1.1.1.m1.1.1.3a.cmml\" xref=\"S4.T7.1.1.1.m1.1.1.3\"><mtext id=\"S4.T7.1.1.1.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T7.1.1.1.m1.1.1.3\">vit</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T7.1.1.1.m1.1c\">\\text{SASRec}_{\\text{vit}}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T7.1.1.1.m1.1d\">SASRec start_POSTSUBSCRIPT vit end_POSTSUBSCRIPT</annotation></semantics></math>&#160;<cite class=\"ltx_cite ltx_citemacro_citeyearpar\">(<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib5\" title=\"\">2024</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.1.1.3\">3.589</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.1.1.4\">-</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.1.1.5\">-</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.1.1.6\">1.941</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.1.1.7\">-</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.1.1.8\">-</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.1.1.9\">-27.72%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.2.2.1\">HSTU<sup class=\"ltx_sup\" id=\"S4.T7.2.2.1.1\">&#8727;</sup>&#160;<cite class=\"ltx_cite ltx_citemacro_citeyearpar\">(<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib37\" title=\"\">2024</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.2.2.2\">4.848</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.2.2.3\">10.315</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.2.2.4\">18.327</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.2.2.5\">2.752</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.2.2.6\">3.939</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.2.2.7\">5.135</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.2.2.8\">+0.0%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.3.3.1\">SASRec<sup class=\"ltx_sup\" id=\"S4.T7.3.3.1.1\">&#8727;</sup>\n</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.3.3.2\">5.083</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.3.3.3\">10.667</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.3.3.4\">18.754</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.3.3.5\">2.911</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.3.3.6\">4.123</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.3.3.7\">5.331</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.3.3.8\">+3.82%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.4.4.1\">HSTU-1B<sup class=\"ltx_sup\" id=\"S4.T7.4.4.1.1\">&#8727;</sup>\n</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.4.4.2\">5.120</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.4.4.3\">11.010</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.4.4.4\">19.393</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.4.4.5\">2.879</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.4.4.6\">4.159</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.4.4.7\">5.411</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.4.4.8\">+5.37%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.5.5.1\">SASRec-1B<sup class=\"ltx_sup\" id=\"S4.T7.5.5.1.1\">&#8727;</sup>\n</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.5.5.2\">5.142</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.5.5.3\">10.899</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.5.5.4\">19.044</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.5.5.5\">2.915</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.5.5.6\">4.166</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.5.5.7\">5.383</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.5.5.8\">+4.83%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.13.15.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.13.15.1.1\">HLLM-1B (Ours)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.15.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.15.1.2.1\">6.129</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.15.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.15.1.3.1\">12.475</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.15.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.15.1.4.1\">21.179</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.15.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.15.1.5.1\">3.539</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.15.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.15.1.6.1\">4.919</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.15.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.15.1.7.1\">6.221</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.15.1.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.15.1.8.1\">+22.93%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.13.16.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S4.T7.13.16.2.1\" rowspan=\"12\"><span class=\"ltx_text\" id=\"S4.T7.13.16.2.1.1\">Amazon Books</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T7.13.16.2.2\">SASRec&#160;<cite class=\"ltx_cite ltx_citemacro_citeyearpar\">(<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib13\" title=\"\">2018</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.13.16.2.3\">3.06</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.13.16.2.4\">7.54</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.13.16.2.5\">14.31</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.13.16.2.6\">1.64</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.13.16.2.7\">2.60</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.13.16.2.8\">3.62</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.13.16.2.9\">+0.0%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.13.17.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.13.17.3.1\">LEARN&#160;<cite class=\"ltx_cite ltx_citemacro_citeyearpar\">(<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib12\" title=\"\">2024</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.17.3.2\">4.07</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.17.3.3\">9.79</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.17.3.4\">18.74</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.17.3.5\">2.24</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.17.3.6\">3.71</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.17.3.7\">4.83</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.17.3.8\">+34.42%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.13.18.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.13.18.4.1\">HSTU-large&#160;<cite class=\"ltx_cite ltx_citemacro_citeyearpar\">(<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib37\" title=\"\">2024</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.18.4.2\">4.78</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.18.4.3\">10.82</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.18.4.4\">19.08</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.18.4.5\">2.62</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.18.4.6\">3.93</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.18.4.7\">5.17</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.18.4.8\">+47.80%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.6.6.1\">SASRec<sup class=\"ltx_sup\" id=\"S4.T7.6.6.1.1\">&#8727;</sup>\n</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.6.6.2\">5.35</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.6.6.3\">11.91</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.6.6.4\">21.02</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.6.6.5\">2.98</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.6.6.6\">4.40</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.6.6.7\">5.76</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.6.6.8\">+64.96%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.7.7.1\">SASRec-1B<sup class=\"ltx_sup\" id=\"S4.T7.7.7.1.1\">&#8727;</sup>\n</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.7.7.2\">5.09</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.7.7.3\">11.11</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.7.7.4\">19.45</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.7.7.5\">2.86</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.7.7.6\">4.17</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.7.7.7\">5.42</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.7.7.8\">+55.68%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.8.8.1\">HSTU-large<sup class=\"ltx_sup\" id=\"S4.T7.8.8.1.1\">&#8727;</sup>\n</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.8.8.2\">5.00</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.8.8.3\">11.29</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.8.8.4\">20.13</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.8.8.5\">2.78</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.8.8.6\">4.14</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.8.8.7\">5.47</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.8.8.8\">+55.61%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.9.9.1\">HSTU-1B<sup class=\"ltx_sup\" id=\"S4.T7.9.9.1.1\">&#8727;</sup>\n</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.9.9.2\">5.25</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.9.9.3\">12.03</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.9.9.4\">21.60</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.9.9.5\">2.89</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.9.9.6\">4.36</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.9.9.7\">5.80</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.9.9.8\">+64.37%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.13.19.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.13.19.5.1\">HLLM-1B (Ours)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.19.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.19.5.2.1\">6.97</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.19.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.19.5.3.1\">14.61</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.19.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.19.5.4.1\">24.78</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.19.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.19.5.5.1\">3.98</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.19.5.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.19.5.6.1\">5.64</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.19.5.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.19.5.7.1\">7.16</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.13.19.5.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.19.5.8.1\">+108.68%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T7.10.10.1\">HSTU-large<sup class=\"ltx_sup\" id=\"S4.T7.10.10.1.1\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T7.10.10.1.1.1\">&#8224;&#8727;</span></sup>\n</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.10.10.2\">6.49</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.10.10.3\">12.22</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.10.10.4\">19.81</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.10.10.5\">3.99</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.10.10.6\">5.24</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.10.10.7\">6.38</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T7.10.10.8\">+88.94%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.11.11.1\">HLLM-1B-Scratch<sup class=\"ltx_sup\" id=\"S4.T7.11.11.1.1\">&#8224;</sup> (Ours)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.11.11.2\">6.85</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.11.11.3\">13.95</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.11.11.4\">23.19</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.11.11.5\">4.02</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.11.11.6\">5.56</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.11.11.7\">6.95</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.11.11.8\">+103.65%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T7.12.12.1\">HLLM-1B<sup class=\"ltx_sup\" id=\"S4.T7.12.12.1.1\">&#8224;</sup> (Ours)</th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.12.12.2\">9.28</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.12.12.3\">17.34</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.12.12.4\">27.22</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.12.12.5\">5.65</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.12.12.6\">7.41</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.12.12.7\">8.89</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T7.12.12.8\">+166.42%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.13.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T7.13.13.1\">HLLM-7B<sup class=\"ltx_sup\" id=\"S4.T7.13.13.1.1\">&#8224;</sup> (Ours)</th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T7.13.13.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.13.2.1\">9.39</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T7.13.13.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.13.3.1\">17.65</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T7.13.13.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.13.4.1\">27.59</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T7.13.13.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.13.5.1\">5.69</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T7.13.13.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.13.6.1\">7.50</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T7.13.13.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.13.7.1\">8.99</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" id=\"S4.T7.13.13.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T7.13.13.8.1\">+169.58%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "The experimental results for increasing the model\u2019s parameter count are shown in Table\u00a05 and Table\u00a06. It can be observed that the growth in the number of parameters for both Item LLM and User LLM consistently leads to performance improvements.\nFinally, we scale up both the Item LLM and User LLM from 1 billion parameters to 7 billion parameters on the Amazon Books. As shown in Table\u00a07, this leads to further performance improvements, demonstrating that HLLM has excellent scalability.",
            "In Table\u00a07, we compare the performance of HLLM with the current state-of-the-art models, including ID-based models such as SASRec\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Kang and McAuley <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib13\" title=\"\">2018</a>)</cite> and HSTU&#160;\n(Kang and McAuley 2018) and HSTU\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Zhai et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib37\" title=\"\">2024</a>)</cite>, as well as the text-based model LEARN&#160;\n(Zhai et\u00a0al. 2024), as well as the text-based model LEARN\u00a0<cite class=\"ltx_cite ltx_citemacro_citep\">(Jia et&#160;al. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.12740v1#bib.bib12\" title=\"\">2024</a>)</cite> on the Pixel8M and Amazon Book Reviews datasets. They all exhibit excellent performance and are dedicated to industrial practice.\n(Jia et\u00a0al. 2024) on the Pixel8M and Amazon Book Reviews datasets. They all exhibit excellent performance and are dedicated to industrial practice."
        ]
    },
    "S4.T8": {
        "caption": "Table 8: Experiments on the effectiveness of item caching. <math alttext=\"\\text{HLLM-1B}_{\\text{cache}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T8.3.m1.1\">\n  <semantics id=\"S4.T8.3.m1.1b\">\n    <msub id=\"S4.T8.3.m1.1.1\" xref=\"S4.T8.3.m1.1.1.cmml\">\n      <mtext id=\"S4.T8.3.m1.1.1.2\" xref=\"S4.T8.3.m1.1.1.2a.cmml\">HLLM-1B</mtext>\n      <mtext id=\"S4.T8.3.m1.1.1.3\" xref=\"S4.T8.3.m1.1.1.3a.cmml\">cache</mtext>\n    </msub>\n    <annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.3.m1.1c\">\n      <apply id=\"S4.T8.3.m1.1.1.cmml\" xref=\"S4.T8.3.m1.1.1\">\n        <csymbol cd=\"ambiguous\" id=\"S4.T8.3.m1.1.1.1.cmml\" xref=\"S4.T8.3.m1.1.1\">subscript</csymbol>\n        <ci id=\"S4.T8.3.m1.1.1.2a.cmml\" xref=\"S4.T8.3.m1.1.1.2\">\n          <mtext id=\"S4.T8.3.m1.1.1.2.cmml\" xref=\"S4.T8.3.m1.1.1.2\">HLLM-1B</mtext>\n        </ci>\n        <ci id=\"S4.T8.3.m1.1.1.3a.cmml\" xref=\"S4.T8.3.m1.1.1.3\">\n          <mtext id=\"S4.T8.3.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T8.3.m1.1.1.3\">cache</mtext>\n        </ci>\n      </apply>\n    </annotation-xml>\n    <annotation encoding=\"application/x-tex\" id=\"S4.T8.3.m1.1d\">\\text{HLLM-1B}_{\\text{cache}}</annotation>\n    <annotation encoding=\"application/x-llamapun\" id=\"S4.T8.3.m1.1e\">HLLM-1B start_POSTSUBSCRIPT cache end_POSTSUBSCRIPT</annotation>\n  </semantics>\n</math> utilizes a pre-trained item HLLM to extract item features, but the parameters are frozen.\n<semantics id=\"S4.T8.3.m1.1b\">\n  <msub id=\"S4.T8.3.m1.1.1\" xref=\"S4.T8.3.m1.1.1.cmml\">\n    <mtext id=\"S4.T8.3.m1.1.1.2\" xref=\"S4.T8.3.m1.1.1.2a.cmml\">HLLM-1B</mtext>\n    <mtext id=\"S4.T8.3.m1.1.1.3\" xref=\"S4.T8.3.m1.1.1.3a.cmml\">cache</mtext>\n  </msub>\n  <annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.3.m1.1c\">\n    <apply id=\"S4.T8.3.m1.1.1.cmml\" xref=\"S4.T8.3.m1.1.1\">\n      <csymbol cd=\"ambiguous\" id=\"S4.T8.3.m1.1.1.1.cmml\" xref=\"S4.T8.3.m1.1.1\">subscript</csymbol>\n      <ci id=\"S4.T8.3.m1.1.1.2a.cmml\" xref=\"S4.T8.3.m1.1.1.2\">\n        <mtext id=\"S4.T8.3.m1.1.1.2.cmml\" xref=\"S4.T8.3.m1.1.1.2\">HLLM-1B</mtext>\n      </ci>\n      <ci id=\"S4.T8.3.m1.1.1.3a.cmml\" xref=\"S4.T8.3.m1.1.1.3\">\n        <mtext id=\"S4.T8.3.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T8.3.m1.1.1.3\">cache</mtext>\n      </ci>\n    </apply>\n  </annotation-xml>\n  <annotation encoding=\"application/x-tex\" id=\"S4.T8.3.m1.1d\">\\text{HLLM-1B}_{\\text{cache}}</annotation>\n  <annotation encoding=\"application/x-llamapun\" id=\"S4.T8.3.m1.1e\">HLLM-1B start_POSTSUBSCRIPT cache end_POSTSUBSCRIPT</annotation>\n</semantics>\n<msub id=\"S4.T8.3.m1.1.1\" xref=\"S4.T8.3.m1.1.1.cmml\">\n  <mtext id=\"S4.T8.3.m1.1.1.2\" xref=\"S4.T8.3.m1.1.1.2a.cmml\">HLLM-1B</mtext>\n  <mtext id=\"S4.T8.3.m1.1.1.3\" xref=\"S4.T8.3.m1.1.1.3a.cmml\">cache</mtext>\n</msub>\n<mtext id=\"S4.T8.3.m1.1.1.2\" xref=\"S4.T8.3.m1.1.1.2a.cmml\">HLLM-1B</mtext>\nHLLM-1B<mtext id=\"S4.T8.3.m1.1.1.3\" xref=\"S4.T8.3.m1.1.1.3a.cmml\">cache</mtext>\ncache<annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.3.m1.1c\">\n  <apply id=\"S4.T8.3.m1.1.1.cmml\" xref=\"S4.T8.3.m1.1.1\">\n    <csymbol cd=\"ambiguous\" id=\"S4.T8.3.m1.1.1.1.cmml\" xref=\"S4.T8.3.m1.1.1\">subscript</csymbol>\n    <ci id=\"S4.T8.3.m1.1.1.2a.cmml\" xref=\"S4.T8.3.m1.1.1.2\">\n      <mtext id=\"S4.T8.3.m1.1.1.2.cmml\" xref=\"S4.T8.3.m1.1.1.2\">HLLM-1B</mtext>\n    </ci>\n    <ci id=\"S4.T8.3.m1.1.1.3a.cmml\" xref=\"S4.T8.3.m1.1.1.3\">\n      <mtext id=\"S4.T8.3.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T8.3.m1.1.1.3\">cache</mtext>\n    </ci>\n  </apply>\n</annotation-xml>\n<apply id=\"S4.T8.3.m1.1.1.cmml\" xref=\"S4.T8.3.m1.1.1\">\n  <csymbol cd=\"ambiguous\" id=\"S4.T8.3.m1.1.1.1.cmml\" xref=\"S4.T8.3.m1.1.1\">subscript</csymbol>\n  <ci id=\"S4.T8.3.m1.1.1.2a.cmml\" xref=\"S4.T8.3.m1.1.1.2\">\n    <mtext id=\"S4.T8.3.m1.1.1.2.cmml\" xref=\"S4.T8.3.m1.1.1.2\">HLLM-1B</mtext>\n  </ci>\n  <ci id=\"S4.T8.3.m1.1.1.3a.cmml\" xref=\"S4.T8.3.m1.1.1.3\">\n    <mtext id=\"S4.T8.3.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T8.3.m1.1.1.3\">cache</mtext>\n  </ci>\n</apply>\n<csymbol cd=\"ambiguous\" id=\"S4.T8.3.m1.1.1.1.cmml\" xref=\"S4.T8.3.m1.1.1\">subscript</csymbol>\nsubscript<ci id=\"S4.T8.3.m1.1.1.2a.cmml\" xref=\"S4.T8.3.m1.1.1.2\">\n  <mtext id=\"S4.T8.3.m1.1.1.2.cmml\" xref=\"S4.T8.3.m1.1.1.2\">HLLM-1B</mtext>\n</ci>\n<mtext id=\"S4.T8.3.m1.1.1.2.cmml\" xref=\"S4.T8.3.m1.1.1.2\">HLLM-1B</mtext>\nHLLM-1B<ci id=\"S4.T8.3.m1.1.1.3a.cmml\" xref=\"S4.T8.3.m1.1.1.3\">\n  <mtext id=\"S4.T8.3.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T8.3.m1.1.1.3\">cache</mtext>\n</ci>\n<mtext id=\"S4.T8.3.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T8.3.m1.1.1.3\">cache</mtext>\ncache<annotation encoding=\"application/x-tex\" id=\"S4.T8.3.m1.1d\">\\text{HLLM-1B}_{\\text{cache}}</annotation>\n\\text{HLLM-1B}_{\\text{cache}}<annotation encoding=\"application/x-llamapun\" id=\"S4.T8.3.m1.1e\">HLLM-1B start_POSTSUBSCRIPT cache end_POSTSUBSCRIPT</annotation>\nHLLM-1B start_POSTSUBSCRIPT cache end_POSTSUBSCRIPT utilizes a pre-trained item HLLM to extract item features, but the parameters are frozen.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T8.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T8.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T8.1.2.1.1\">Method</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T8.1.2.1.2\">R@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T8.1.2.1.3\">R@10</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T8.1.2.1.4\">N@5</th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T8.1.2.1.5\">N@10</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T8.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T8.1.3.1.1\">HSTU-1B</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T8.1.3.1.2\">3.501</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T8.1.3.1.3\">5.120</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T8.1.3.1.4\">2.358</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S4.T8.1.3.1.5\">2.879</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T8.1.1.1\"><math alttext=\"\\text{HLLM-1B}_{\\text{cache}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T8.1.1.1.m1.1\"><semantics id=\"S4.T8.1.1.1.m1.1a\"><msub id=\"S4.T8.1.1.1.m1.1.1\" xref=\"S4.T8.1.1.1.m1.1.1.cmml\"><mtext id=\"S4.T8.1.1.1.m1.1.1.2\" xref=\"S4.T8.1.1.1.m1.1.1.2a.cmml\">HLLM-1B</mtext><mtext id=\"S4.T8.1.1.1.m1.1.1.3\" xref=\"S4.T8.1.1.1.m1.1.1.3a.cmml\">cache</mtext></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T8.1.1.1.m1.1b\"><apply id=\"S4.T8.1.1.1.m1.1.1.cmml\" xref=\"S4.T8.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T8.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T8.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T8.1.1.1.m1.1.1.2a.cmml\" xref=\"S4.T8.1.1.1.m1.1.1.2\"><mtext id=\"S4.T8.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T8.1.1.1.m1.1.1.2\">HLLM-1B</mtext></ci><ci id=\"S4.T8.1.1.1.m1.1.1.3a.cmml\" xref=\"S4.T8.1.1.1.m1.1.1.3\"><mtext id=\"S4.T8.1.1.1.m1.1.1.3.cmml\" mathsize=\"70%\" xref=\"S4.T8.1.1.1.m1.1.1.3\">cache</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T8.1.1.1.m1.1c\">\\text{HLLM-1B}_{\\text{cache}}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T8.1.1.1.m1.1d\">HLLM-1B start_POSTSUBSCRIPT cache end_POSTSUBSCRIPT</annotation></semantics></math></th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T8.1.1.2\">3.585</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T8.1.1.3\">5.218</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T8.1.1.4\">2.432</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T8.1.1.5\">2.958</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T8.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T8.1.4.2.1\">HLLM-1B</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T8.1.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.4.2.2.1\">4.278</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T8.1.4.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.4.2.3.1\">6.106</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T8.1.4.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.4.2.4.1\">2.935</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\" id=\"S4.T8.1.4.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T8.1.4.2.5.1\">3.524</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Previous extensive experiments have shown that fully fine-tuning the entire HLLM significantly improves performance but requires real-time encoding of all items during inference, which is inefficient. Thanks to the decoupling of item and user encoding in HLLM, our architecture can reduce computational complexity by caching item embeddings in advance.\nTo demonstrate the feasibility of item caching, we pre-trained HLLM on sequences longer than 10 from the Pixel8M dataset, truncating sequences at the tenth position to avoid data leakage, covering 3 million users. Based on this pre-trained HLLM, we freeze the Item LLM and fine-tune only the User LLM on Pixel8M. Results in Table\u00a08 show that while freezing the Item LLM leads to some metric decreases, performance still exceeds ID-based models, proving item caching is more effective. Given that user behaviors in industrial scenarios far exceed the number of items, HLLM\u2019s training and serving costs can match those of ID-based models.\nNotably, our pre-training data constitutes less than half of Pixel8M, with some items not appearing in the pre-training data, yet we still achieve respectable performance. Experiments on industrial data show that as the amount of pre-training data increases, the gap between the item caching and the full fine-tuning is largely narrowed."
        ]
    },
    "A1.T9": {
        "caption": "Table 9: Ablation studies of text length and richness on Pixel200K.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\" id=\"A1.T9.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T9.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.1.1.1.1\">Tag</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.1.1.1.2\">Title</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.1.1.1.3\">Description</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.1.1.1.4\">Length</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.1.1.1.5\">R@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.1.1.1.6\">R@10</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T9.1.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T9.1.2.1.1\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.1.2.1.1.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_border_t\" id=\"A1.T9.1.2.1.2\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"A1.T9.1.2.1.3\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T9.1.2.1.4\">64</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T9.1.2.1.5\">0.082</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T9.1.2.1.6\">0.196</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.1.3.2\">\n<td class=\"ltx_td\" id=\"A1.T9.1.3.2.1\"/>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.1.3.2.2\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.1.3.2.2.1\">\\usym</span>2713</td>\n<td class=\"ltx_td\" id=\"A1.T9.1.3.2.3\"/>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.1.3.2.4\">64</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.1.3.2.5\">3.520</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.1.3.2.6\">5.317</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.1.4.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.1.4.3.1\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.1.4.3.1.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.1.4.3.2\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.1.4.3.2.1\">\\usym</span>2713</td>\n<td class=\"ltx_td\" id=\"A1.T9.1.4.3.3\"/>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.1.4.3.4\">64</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.1.4.3.5\">3.610</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.1.4.3.6\">5.439</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.1.5.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.1.5.4.1\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.1.5.4.1.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.1.5.4.2\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.1.5.4.2.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.1.5.4.3\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.1.5.4.3.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.1.5.4.4\">64</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.1.5.4.5\">3.647</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.1.5.4.6\">5.502</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.1.6.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T9.1.6.5.1\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.1.6.5.1.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T9.1.6.5.2\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.1.6.5.2.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T9.1.6.5.3\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.1.6.5.3.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T9.1.6.5.4\">256</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T9.1.6.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.6.5.5.1\">3.755</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T9.1.6.5.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.6.5.6.1\">5.581</span></td>\n</tr>\n</tbody>\n</table>\n\n<table class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\" id=\"A1.T9.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T9.2.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.2.1.1.1\">Tag</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.2.1.1.2\">Title</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.2.1.1.3\">Description</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.2.1.1.4\">Length</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.2.1.1.5\">N@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.2.1.1.6\">N@10</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T9.2.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A1.T9.2.2.1.1\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.2.2.1.1.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_border_t\" id=\"A1.T9.2.2.1.2\"/>\n<td class=\"ltx_td ltx_border_t\" id=\"A1.T9.2.2.1.3\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T9.2.2.1.4\">64</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T9.2.2.1.5\">0.049</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T9.2.2.1.6\">0.086</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.2.3.2\">\n<td class=\"ltx_td\" id=\"A1.T9.2.3.2.1\"/>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.2.3.2.2\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.2.3.2.2.1\">\\usym</span>2713</td>\n<td class=\"ltx_td\" id=\"A1.T9.2.3.2.3\"/>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.3.2.4\">64</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.3.2.5\">2.348</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.3.2.6\">2.926</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.2.4.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.2.4.3.1\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.2.4.3.1.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.2.4.3.2\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.2.4.3.2.1\">\\usym</span>2713</td>\n<td class=\"ltx_td\" id=\"A1.T9.2.4.3.3\"/>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.4.3.4\">64</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.4.3.5\">2.415</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.4.3.6\">3.003</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.2.5.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.2.5.4.1\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.2.5.4.1.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.2.5.4.2\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.2.5.4.2.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A1.T9.2.5.4.3\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.2.5.4.3.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.5.4.4\">64</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.5.4.5\">2.430</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T9.2.5.4.6\">3.026</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.2.6.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T9.2.6.5.1\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.2.6.5.1.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T9.2.6.5.2\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.2.6.5.2.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A1.T9.2.6.5.3\">\n<span class=\"ltx_ERROR undefined\" id=\"A1.T9.2.6.5.3.1\">\\usym</span>2713</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T9.2.6.5.4\">256</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T9.2.6.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.2.6.5.5.1\">2.513</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T9.2.6.5.6\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.2.6.5.6.1\">3.099</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "By default, we input all types of text information with a length of 256. Here, we conduct ablation experiments on text length and richness.\nTable\u00a09 shows that the text content has a significant impact on the final performance. Richer text content and longer text lengths allow the Item LLM to extract more detailed item features, better differentiate between items, and more effectively aid the User LLM in modeling user interests."
        ]
    },
    "A1.T10": {
        "caption": "Table 10: Ablation studies of Item LLM feature extraction method on Pixel200K. Mean pooling refers to using the mean pooling of hidden states from the last layer of the Item LLM as the item features. SASRec is used as the user model.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T10.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T10.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A1.T10.1.2.1.1\">Method</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T10.1.2.1.2\">R@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T10.1.2.1.3\">R@10</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T10.1.2.1.4\">N@5</th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T10.1.2.1.5\">N@10</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T10.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A1.T10.1.3.1.1\">Mean Pooling</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T10.1.3.1.2\">3.386</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T10.1.3.1.3\">5.159</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T10.1.3.1.4\">2.257</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"A1.T10.1.3.1.5\">2.826</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T10.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A1.T10.1.1.1\">\n<span class=\"ltx_text ltx_markedasmath ltx_font_typewriter\" id=\"A1.T10.1.1.1.1\">[ITEM]</span> Token</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T10.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T10.1.1.2.1\">3.484</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T10.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T10.1.1.3.1\">5.239</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T10.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T10.1.1.4.1\">2.319</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\" id=\"A1.T10.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T10.1.1.5.1\">2.883</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "To enable LLMs trained on next token prediction to have feature extraction capabilities, we add a special token [ITEM] at the end of the text input. Another feasible feature extraction approach is to take the average of the hidden states from the final layer of the LLM to represent the features of the entire sentence. Table\u00a010 shows the comparison results of these two methods.\nAs can be seen, using the [ITEM] token is better than mean pooling."
        ]
    },
    "A1.T11": {
        "caption": "Table 11: Experiments on the sequence length of User LLM on Pixel1M.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\" id=\"A1.T11.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T11.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A1.T11.1.1.1.1\">Length</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T11.1.1.1.2\">R@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T11.1.1.1.3\">R@10</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T11.1.1.1.4\">R@50</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T11.1.1.1.5\">R@200</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T11.1.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"A1.T11.1.2.1.1\">10</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T11.1.2.1.2\">5.201</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T11.1.2.1.3\">7.564</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T11.1.2.1.4\">16.220</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T11.1.2.1.5\">28.776</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T11.1.3.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A1.T11.1.3.2.1\">30</th>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T11.1.3.2.2\">5.235</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T11.1.3.2.3\">7.605</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T11.1.3.2.4\">16.293</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T11.1.3.2.5\">28.837</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T11.1.4.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"A1.T11.1.4.3.1\">50</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T11.1.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T11.1.4.3.2.1\">5.238</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T11.1.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T11.1.4.3.3.1\">7.631</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T11.1.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T11.1.4.3.4.1\">16.416</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T11.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T11.1.4.3.5.1\">28.959</span></td>\n</tr>\n</tbody>\n</table>\n\n<table class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\" id=\"A1.T11.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T11.2.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A1.T11.2.1.1.1\">Length</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T11.2.1.1.2\">N@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T11.2.1.1.3\">N@10</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T11.2.1.1.4\">N@50</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T11.2.1.1.5\">N@200</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T11.2.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"A1.T11.2.2.1.1\">10</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T11.2.2.1.2\">3.538</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T11.2.2.1.3\">4.299</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T11.2.2.1.4\">6.176</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T11.2.2.1.5\">8.052</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T11.2.3.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"A1.T11.2.3.2.1\">30</th>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T11.2.3.2.2\">3.556</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T11.2.3.2.3\">4.319</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T11.2.3.2.4\">6.205</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T11.2.3.2.5\">8.081</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T11.2.4.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"A1.T11.2.4.3.1\">50</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T11.2.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T11.2.4.3.2.1\">3.568</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T11.2.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T11.2.4.3.3.1\">4.338</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T11.2.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T11.2.4.3.4.1\">6.244</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T11.2.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T11.2.4.3.5.1\">8.119</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We explore the impact of input sequence length of User LLM on HLLM\u2019s recommendation performance in Table\u00a011. Similar to other sequential recommenders, HLLM can also benefit from expanding the length of the input sequence. Although the table shows only modest performance gains with increasing sequence length, we suspect this is likely because user sequence lengths are generally quite short in the academic dataset as shown in Figure\u00a05.\nAs shown in Appendix\u00a0B, in the real-world industrial systems, where user behavior sequences are typically very long, extending the sequence length allows HLLM to achieve stable performance improvement."
        ]
    },
    "A1.T12": {
        "caption": "Table 12: Ablation studies of input features of User LLM on Pixel1M. LLM Emb represents the item features extracted using the Item LLM based on textual descriptions.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T12.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T12.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T12.1.1.1.1\">Input Features</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T12.1.1.1.2\">R@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T12.1.1.1.3\">R@10</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T12.1.1.1.4\">N@5</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T12.1.1.1.5\">N@10</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T12.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T12.1.2.1.1\">Item ID</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T12.1.2.1.2\">4.105</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T12.1.2.1.3\">6.082</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T12.1.2.1.4\">2.773</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T12.1.2.1.5\">3.409</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T12.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T12.1.3.2.1\">LLM Emb</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T12.1.3.2.2\">5.201</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T12.1.3.2.3\">7.564</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T12.1.3.2.4\">3.538</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T12.1.3.2.5\">4.299</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T12.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T12.1.4.3.1\">LLM Emb + Item ID</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T12.1.4.3.2\">5.154</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T12.1.4.3.3\">7.501</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T12.1.4.3.4\">3.504</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T12.1.4.3.5\">4.260</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T12.1.5.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T12.1.5.4.1\">LLM Emb + Timestamp</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T12.1.5.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T12.1.5.4.2.1\">5.779</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T12.1.5.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T12.1.5.4.3.1\">8.319</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T12.1.5.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T12.1.5.4.4.1\">3.953</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T12.1.5.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T12.1.5.4.5.1\">4.770</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Here, we choose the raw item IDs and timestamps as ID features for validation.\nThe item IDs are transformed into id embeddings through an embedding lookup table.\nThe behavior\u2019s timestamp is first split into specific year, month, day, hour, minute, and second components, obtaining the timestamp embedding as Algorithm\u00a01.\nWe perform sum pooling with the ID features and item LLM embeddings before inputting them into the User LLM.\nThe prediction target during training remains the item embedding extracted by the Item LLM, and the experimental results are shown in Table\u00a012.\nThe introduction of item IDs actually results in a slight decrease in performance, likely because the item IDs do not provide incremental information beyond what is already captured by the textual descriptions, which comprehensively describe the item\u2019s characteristics and are sufficiently extracted by the Item LLM.\nHowever, the improvement resulting from the introduction of timestamps is very pronounced, as timestamps complement the textual descriptions. This also demonstrates that our method can be compatible with ID-based features."
        ]
    },
    "A2.T13": {
        "caption": "Table 13: Experiments on the sequence length of User LLM on the industrial dataset.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T13.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T13.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"A2.T13.1.1.1.1\">Sequence Length</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T13.1.1.1.2\">AUC</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T13.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"A2.T13.1.2.1.1\">200</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T13.1.2.1.2\">0.7429</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T13.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"A2.T13.1.3.2.1\">500</th>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T13.1.3.2.2\">0.7446</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T13.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"A2.T13.1.4.3.1\">1,000</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T13.1.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T13.1.4.3.2.1\">0.7458</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "The length of user behavior sequences in the industrial dataset is shown in Figure\u00a05.\nAnd table\u00a013 shows the impact of user sequence length, with HLLM\u2019s performance steadily increasing as the sequence length grows. This illustrates HLLM\u2019s substantial potential in modeling users with longer sequences."
        ]
    },
    "A2.T14": {
        "caption": "Table 14: Experiments with different sizes of Item LLM and User LLM on the industrial dataset.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T14.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T14.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T14.1.1.1.1\">Item LLM</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T14.1.1.1.2\">User LLM</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A2.T14.1.1.1.3\">AUC</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T14.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T14.1.2.1.1\">1B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T14.1.2.1.2\">1B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A2.T14.1.2.1.3\">0.7458</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T14.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T14.1.3.2.1\">1B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T14.1.3.2.2\">7B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T14.1.3.2.3\">0.7498</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T14.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T14.1.4.3.1\">7B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T14.1.4.3.2\">1B</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A2.T14.1.4.3.3\">0.7517</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T14.1.5.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T14.1.5.4.1\">7B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T14.1.5.4.2\">7B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A2.T14.1.5.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T14.1.5.4.3.1\">0.7533</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Table\u00a014 illustrates the impact of the parameters of HLLM in industrial scenario. For both Item LLM and User LLM, AUC consistently increases with the growth in the number of parameters."
        ]
    }
}