{
    "id_table_1": {
        "caption": "Table 1.  Comparison of Vectorization and Indexing Methods",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": [
            "Following the methodology outlined in Section 3.2, we retrieved the three closest results for each prompt and confirmed the number of keyword matches using the Chinese model loaded in SpaCy as  Algorithm 2 . The final results are as follows Table 1.",
            "As shown in  Table 1 , in terms of keyword hit rate, the TF-IDF vectorization method consistently outperformed the BERT vectorization method, with the maximum difference observed in the IVFSQ indexing method. Under the L2 space calculation method, the TF-IDF algorithms hit rate was 60.1770% higher than that of the BERT algorithm. The TF-IDF algorithm also had an average hit rate across various indexing methods that was 52.1495% higher than that of BERT. Additionally, due to differences in the principles of the two vectorization methods, the TF-IDF algorithm reduced vectorization time and performance requirements by approximately 60% and 47%, respectively (rough estimates)."
        ]
    },
    "id_table_2": {
        "caption": "Table 2.  Comparison of Large Language Model Performance with RAG Optimization and Fine-Tuning",
        "table": "S4.T2.1",
        "footnotes": [],
        "references": [
            "The results of the models optimized with RAG technology are as Table 2."
        ]
    },
    "global_footnotes": []
}