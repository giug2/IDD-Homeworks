{
    "PAPER'S NUMBER OF TABLES": 4,
    "S5.T1": {
        "caption": "TABLE I: Lâ€‹Pâ€‹Iâ€‹Pâ€‹Sâ†“â†“ğ¿ğ‘ƒğ¼ğ‘ƒğ‘†absentLPIPS\\downarrow scores comparing the performance of cocktail party (CP) and gradient matching (GM) attacks on FC-2 trained on CIFAR-10 and Tiny-ImageNet. CP (our proposal) significantly outperforms GM (prior work) across all batch sizes.",
        "table": "<table id=\"S5.T1.3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T1.3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Attack</span></th>\n<th id=\"S5.T1.3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"6\"><span id=\"S5.T1.3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Batch Size</span></th>\n</tr>\n<tr id=\"S5.T1.3.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">8</th>\n<th id=\"S5.T1.3.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">16</th>\n<th id=\"S5.T1.3.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">32</th>\n<th id=\"S5.T1.3.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">64</th>\n<th id=\"S5.T1.3.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">128</th>\n<th id=\"S5.T1.3.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">256</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.3.1.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.3.1.3.1.1\" class=\"ltx_td ltx_border_t\"></td>\n<th id=\"S5.T1.3.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"6\"><span id=\"S5.T1.3.1.3.1.2.1\" class=\"ltx_text ltx_font_bold\">CIFAR-10</span></th>\n</tr>\n<tr id=\"S5.T1.3.1.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.3.1.4.2.1\" class=\"ltx_td ltx_align_center\">GM</td>\n<td id=\"S5.T1.3.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.283</td>\n<td id=\"S5.T1.3.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.390</td>\n<td id=\"S5.T1.3.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.491</td>\n<td id=\"S5.T1.3.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.569</td>\n<td id=\"S5.T1.3.1.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.610</td>\n<td id=\"S5.T1.3.1.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.614</td>\n</tr>\n<tr id=\"S5.T1.3.1.5.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.3.1.5.3.1\" class=\"ltx_td ltx_align_center\">CP</td>\n<td id=\"S5.T1.3.1.5.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.3.1.5.3.2.1\" class=\"ltx_text ltx_font_bold\">0.101</span></td>\n<td id=\"S5.T1.3.1.5.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.3.1.5.3.3.1\" class=\"ltx_text ltx_font_bold\">0.160</span></td>\n<td id=\"S5.T1.3.1.5.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.3.1.5.3.4.1\" class=\"ltx_text ltx_font_bold\">0.197</span></td>\n<td id=\"S5.T1.3.1.5.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.3.1.5.3.5.1\" class=\"ltx_text ltx_font_bold\">0.352</span></td>\n<td id=\"S5.T1.3.1.5.3.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.3.1.5.3.6.1\" class=\"ltx_text ltx_font_bold\">0.521</span></td>\n<td id=\"S5.T1.3.1.5.3.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.3.1.5.3.7.1\" class=\"ltx_text ltx_font_bold\">0.610</span></td>\n</tr>\n<tr id=\"S5.T1.3.1.6.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.3.1.6.4.1\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T1.3.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"6\"><span id=\"S5.T1.3.1.6.4.2.1\" class=\"ltx_text ltx_font_bold\">Tiny-ImageNet</span></td>\n</tr>\n<tr id=\"S5.T1.3.1.7.5\" class=\"ltx_tr\">\n<td id=\"S5.T1.3.1.7.5.1\" class=\"ltx_td ltx_align_center\">GM</td>\n<td id=\"S5.T1.3.1.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.182</td>\n<td id=\"S5.T1.3.1.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.234</td>\n<td id=\"S5.T1.3.1.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.368</td>\n<td id=\"S5.T1.3.1.7.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.620</td>\n<td id=\"S5.T1.3.1.7.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.687</td>\n<td id=\"S5.T1.3.1.7.5.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.720</td>\n</tr>\n<tr id=\"S5.T1.3.1.8.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.3.1.8.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">CP</td>\n<td id=\"S5.T1.3.1.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.3.1.8.6.2.1\" class=\"ltx_text ltx_font_bold\">0.082</span></td>\n<td id=\"S5.T1.3.1.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.3.1.8.6.3.1\" class=\"ltx_text ltx_font_bold\">0.143</span></td>\n<td id=\"S5.T1.3.1.8.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.3.1.8.6.4.1\" class=\"ltx_text ltx_font_bold\">0.164</span></td>\n<td id=\"S5.T1.3.1.8.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.3.1.8.6.5.1\" class=\"ltx_text ltx_font_bold\">0.217</span></td>\n<td id=\"S5.T1.3.1.8.6.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.3.1.8.6.6.1\" class=\"ltx_text ltx_font_bold\">0.232</span></td>\n<td id=\"S5.T1.3.1.8.6.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.3.1.8.6.7.1\" class=\"ltx_text ltx_font_bold\">0.388</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We first present the results from our experiments on the FC-2 models trained on the CIFAR-10 and Tiny-ImageNet datasets. Fig.Â 5 shows qualitative results comparing CPA and GMA for Tiny-ImageNet with a batch size of 64. The images recovered by CPA have better quality and higher perceptual similarity with the original images, compared to the images recovered by GMA. TableÂ I shows quantitative results (LPIPS scores) comparing CPA and GMA with various batch sizes. A lower LPIPS value indicates better perceptual similarity and thus a better attack performance. Our result can be interpreted by considering the size of the optimization problem being solved by CPA and GMA."
        ]
    },
    "S5.T2": {
        "caption": "TABLE II: Lâ€‹Pâ€‹Iâ€‹Pâ€‹Sâ†“â†“ğ¿ğ‘ƒğ¼ğ‘ƒğ‘†absentLPIPS\\downarrow scores of images recovered using GM (prior work), CP+FI (our proposal) and CP+FI+GM (prior work + our proposal) attacks, with VGG-16 network trained on ImageNet.",
        "table": "<table id=\"S5.T2.3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T2.3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Attack</span></th>\n<th id=\"S5.T2.3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"6\"><span id=\"S5.T2.3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Batch Size</span></th>\n</tr>\n<tr id=\"S5.T2.3.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">32</th>\n<th id=\"S5.T2.3.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">64</th>\n<th id=\"S5.T2.3.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">128</th>\n<th id=\"S5.T2.3.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">256</th>\n<th id=\"S5.T2.3.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">512</th>\n<th id=\"S5.T2.3.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">1024</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.3.1.3.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">GM</th>\n<td id=\"S5.T2.3.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.536</td>\n<td id=\"S5.T2.3.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.594</td>\n<td id=\"S5.T2.3.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.609</td>\n<td id=\"S5.T2.3.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.652</td>\n<td id=\"S5.T2.3.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">OOM</td>\n<td id=\"S5.T2.3.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">OOM</td>\n</tr>\n<tr id=\"S5.T2.3.1.4.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">CP+FI</th>\n<td id=\"S5.T2.3.1.4.2.2\" class=\"ltx_td ltx_align_center\">0.483</td>\n<td id=\"S5.T2.3.1.4.2.3\" class=\"ltx_td ltx_align_center\">0.493</td>\n<td id=\"S5.T2.3.1.4.2.4\" class=\"ltx_td ltx_align_center\">0.479</td>\n<td id=\"S5.T2.3.1.4.2.5\" class=\"ltx_td ltx_align_center\">0.495</td>\n<td id=\"S5.T2.3.1.4.2.6\" class=\"ltx_td ltx_align_center\">0.507</td>\n<td id=\"S5.T2.3.1.4.2.7\" class=\"ltx_td ltx_align_center\">0.509</td>\n</tr>\n<tr id=\"S5.T2.3.1.5.3\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">CP+FI+GM</th>\n<td id=\"S5.T2.3.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.1.5.3.2.1\" class=\"ltx_text ltx_font_bold\">0.392</span></td>\n<td id=\"S5.T2.3.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.1.5.3.3.1\" class=\"ltx_text ltx_font_bold\">0.430</span></td>\n<td id=\"S5.T2.3.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.1.5.3.4.1\" class=\"ltx_text ltx_font_bold\">0.423</span></td>\n<td id=\"S5.T2.3.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.3.1.5.3.5.1\" class=\"ltx_text ltx_font_bold\">0.469</span></td>\n<td id=\"S5.T2.3.1.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">OOM</td>\n<td id=\"S5.T2.3.1.5.3.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">OOM</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Gradient Inversion: We use the embeddings recovered from CPA to estimate the inputs with a feature inversion attack. TableÂ II shows the Lâ€‹Pâ€‹Iâ€‹Pâ€‹Sğ¿ğ‘ƒğ¼ğ‘ƒğ‘†LPIPS scores comparing gradient matching attack (prior work), cocktail party + feature inversion attack (our proposal) and cocktail party + feature inversion + gradient matching attack (our proposal + prior work). We make the following key observations:"
        ]
    },
    "S6.T3": {
        "caption": "TABLE III: Lâ€‹Pâ€‹Iâ€‹Pâ€‹Sâ†“â†“ğ¿ğ‘ƒğ¼ğ‘ƒğ‘†absentLPIPS\\downarrow scores of recovered images from CP and GM attacks under varying magnitudes of DP noise.",
        "table": "<table id=\"S6.T3.5.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T3.3.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><math id=\"S6.T3.3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sigma\" display=\"inline\"><semantics id=\"S6.T3.3.1.1.1.m1.1a\"><mi id=\"S6.T3.3.1.1.1.m1.1.1\" xref=\"S6.T3.3.1.1.1.m1.1.1.cmml\">Ïƒ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.3.1.1.1.m1.1b\"><ci id=\"S6.T3.3.1.1.1.m1.1.1.cmml\" xref=\"S6.T3.3.1.1.1.m1.1.1\">ğœ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.3.1.1.1.m1.1c\">\\sigma</annotation></semantics></math></th>\n<th id=\"S6.T3.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">0</th>\n<th id=\"S6.T3.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.0001</th>\n<th id=\"S6.T3.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.001</th>\n<th id=\"S6.T3.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.01</th>\n</tr>\n<tr id=\"S6.T3.5.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T3.4.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row\"><math id=\"S6.T3.4.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\epsilon\" display=\"inline\"><semantics id=\"S6.T3.4.2.2.1.m1.1a\"><mi id=\"S6.T3.4.2.2.1.m1.1.1\" xref=\"S6.T3.4.2.2.1.m1.1.1.cmml\">Ïµ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.4.2.2.1.m1.1b\"><ci id=\"S6.T3.4.2.2.1.m1.1.1.cmml\" xref=\"S6.T3.4.2.2.1.m1.1.1\">italic-Ïµ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.4.2.2.1.m1.1c\">\\epsilon</annotation></semantics></math></th>\n<th id=\"S6.T3.5.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row\"><math id=\"S6.T3.5.3.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\infty\" display=\"inline\"><semantics id=\"S6.T3.5.3.3.2.m1.1a\"><mi mathvariant=\"normal\" id=\"S6.T3.5.3.3.2.m1.1.1\" xref=\"S6.T3.5.3.3.2.m1.1.1.cmml\">âˆ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T3.5.3.3.2.m1.1b\"><infinity id=\"S6.T3.5.3.3.2.m1.1.1.cmml\" xref=\"S6.T3.5.3.3.2.m1.1.1\"></infinity></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T3.5.3.3.2.m1.1c\">\\infty</annotation></semantics></math></th>\n<th id=\"S6.T3.5.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">6056.00</th>\n<th id=\"S6.T3.5.3.3.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">606.60</th>\n<th id=\"S6.T3.5.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">60.56</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T3.5.3.4.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.5.3.4.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">GM</th>\n<th id=\"S6.T3.5.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">0.182</th>\n<td id=\"S6.T3.5.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.426</td>\n<td id=\"S6.T3.5.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.728</td>\n<td id=\"S6.T3.5.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.701</td>\n</tr>\n<tr id=\"S6.T3.5.3.5.2\" class=\"ltx_tr\">\n<th id=\"S6.T3.5.3.5.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">CP</th>\n<th id=\"S6.T3.5.3.5.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">0.0082</th>\n<td id=\"S6.T3.5.3.5.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.474</td>\n<td id=\"S6.T3.5.3.5.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.721</td>\n<td id=\"S6.T3.5.3.5.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.723</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Differential Privacy (DP) Defense: TableÂ III shows the Lâ€‹Pâ€‹Iâ€‹Pâ€‹Sğ¿ğ‘ƒğ¼ğ‘ƒğ‘†LPIPS scores from CP and GM evaluated under DP noiseÂ [5, 1]. We use the FC2 model with Tiny-ImageNet dataset and a batch size of 8 for these experiments. We scale the gradients to have unit norm and perturb the gradients with different amounts of Gaussian noise. We also show the Ïµitalic-Ïµ\\epsilon values for (Ïµ,Î´)italic-Ïµğ›¿(\\epsilon,\\delta) DP with Î´=0.00001ğ›¿0.00001\\delta=0.00001 corresponding to different amounts of noise. Our evaluations show that DP noise provides an effective defense against our attack."
        ]
    },
    "A1.T4": {
        "caption": "TABLE IV: Ablation study to understand the relative importance of different terms in the optimization function.",
        "table": "<table id=\"A1.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T4.1.2.1\" class=\"ltx_tr\">\n<th id=\"A1.T4.1.2.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<td id=\"A1.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">NE+TV+MI</td>\n<td id=\"A1.T4.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">-NE</td>\n<td id=\"A1.T4.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">-TV</td>\n<td id=\"A1.T4.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">-MI</td>\n</tr>\n<tr id=\"A1.T4.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T4.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\">LPIPS <math id=\"A1.T4.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A1.T4.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"A1.T4.1.1.1.m1.1.1\" xref=\"A1.T4.1.1.1.m1.1.1.cmml\">â†“</mo><annotation-xml encoding=\"MathML-Content\" id=\"A1.T4.1.1.1.m1.1b\"><ci id=\"A1.T4.1.1.1.m1.1.1.cmml\" xref=\"A1.T4.1.1.1.m1.1.1\">â†“</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T4.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<td id=\"A1.T4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.081</td>\n<td id=\"A1.T4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.092</td>\n<td id=\"A1.T4.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.368</td>\n<td id=\"A1.T4.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.546</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "To understand the importance of these three terms, we perform an ablation study. We use the FC2 model trained on TinyImagenet with a batch size 32 for our study and measure LPIPS by carrying out the attack by excluding different loss terms to understand their importance. We perform hyperparameter sweeps in each case and report the best (i.e. lowest) value of LPIPS in TableÂ IV. A higher value of LPIPS indicates a higher degradation in the quality of the image recovered, which implies a high level of importance on the term being removed. Our results indicate that the MI term is the most important. We find that without the MI term the optimization recovers the same image multiple times. TV is the second most important term, indicating that even a simple image prior is quite powerful. The NE term which enforces non-Guassianity has the lowest marginal benefit as it only provides a very weak prior on the source signal."
        ]
    }
}