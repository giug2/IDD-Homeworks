{
    "PAPER'S NUMBER OF TABLES": 3,
    "S4.T1": {
        "caption": "Table 1. Attacker’s accuracy of membership inference.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\">\n<span id=\"S4.T1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">MI Attack Accuracy</span> <math id=\"S4.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\boldsymbol{\\downarrow}\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mo class=\"ltx_mathvariant_bold\" mathvariant=\"bold\" stretchy=\"false\" id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><ci id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">bold-↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">\\boldsymbol{\\downarrow}</annotation></semantics></math>\n</th>\n</tr>\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S4.T1.1.2.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.1.2.1.1.1.1\" class=\"ltx_p\" style=\"width:34.1pt;\"><span id=\"S4.T1.1.2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">UCI</span></span>\n</span>\n</th>\n<th id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S4.T1.1.2.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.1.2.1.2.1.1\" class=\"ltx_p\" style=\"width:34.1pt;\"><span id=\"S4.T1.1.2.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">MNIST</span></span>\n</span>\n</th>\n<th id=\"S4.T1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S4.T1.1.2.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.1.2.1.3.1.1\" class=\"ltx_p\" style=\"width:34.1pt;\"><span id=\"S4.T1.1.2.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">CIFAR</span></span>\n</span>\n</th>\n<th id=\"S4.T1.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S4.T1.1.2.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T1.1.2.1.4.1.1\" class=\"ltx_p\" style=\"width:34.1pt;\"><span id=\"S4.T1.1.2.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">NUS-W</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S4.T1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">unprotected</span></th>\n<td id=\"S4.T1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">51.52</td>\n<td id=\"S4.T1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">62.36</td>\n<td id=\"S4.T1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">65.75</td>\n<td id=\"S4.T1.1.3.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">71.19</td>\n</tr>\n<tr id=\"S4.T1.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T1.1.4.2.1.1\" class=\"ltx_text ltx_font_bold\">vanilla</span></th>\n<td id=\"S4.T1.1.4.2.2\" class=\"ltx_td ltx_align_center\">51.03</td>\n<td id=\"S4.T1.1.4.2.3\" class=\"ltx_td ltx_align_center\">51.75</td>\n<td id=\"S4.T1.1.4.2.4\" class=\"ltx_td ltx_align_center\">52.32</td>\n<td id=\"S4.T1.1.4.2.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">54.70</td>\n</tr>\n<tr id=\"S4.T1.1.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S4.T1.1.5.3.1.1\" class=\"ltx_text ltx_font_bold\">VFL-AFE</span></th>\n<td id=\"S4.T1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">51.12</td>\n<td id=\"S4.T1.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">53.19</td>\n<td id=\"S4.T1.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">54.65</td>\n<td id=\"S4.T1.1.5.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">55.23</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In addition to theoretical analyses, we experimentally study the privacy protection capability of VFL-AFE. The purpose of DP is to protect data confidentiality against privacy threats, namely, inversion and membership inference (MI) attacks. We here compare the unprotected, vanilla, and final VFL-AFEs under SOTA attacks ",
                "(Shokri et al",
                ".",
                ", ",
                "2017",
                "; Ye et al",
                ".",
                ", ",
                "2022a",
                ")",
                ".",
                "Inversion attack.",
                " The attacker aims to recover original samples ",
                "𝐗",
                "𝐗",
                "\\mathbf{X}",
                " of a victim passive party from the shared embeddings ",
                "𝐡",
                "𝐡",
                "\\mathbf{h}",
                " ",
                "(Ye et al",
                ".",
                ", ",
                "2022a",
                ")",
                ". We assume the attacker possesses some samples ",
                "𝐗",
                "a",
                "​",
                "t",
                "​",
                "k",
                "subscript",
                "𝐗",
                "𝑎",
                "𝑡",
                "𝑘",
                "\\mathbf{X}_{atk}",
                " that share similar distribution with ",
                "𝐗",
                "𝐗",
                "\\mathbf{X}",
                " and can query the victim’s ",
                "f",
                "𝑓",
                "f",
                " infinitely. Hence, it can train a decoder ",
                "f",
                "−",
                "1",
                "superscript",
                "𝑓",
                "1",
                "f^{-1}",
                " by minimizing ",
                "‖",
                "f",
                "−",
                "1",
                "​",
                "(",
                "f",
                "​",
                "(",
                "𝐗",
                "a",
                "​",
                "t",
                "​",
                "k",
                ")",
                ")",
                "−",
                "𝐗",
                "a",
                "​",
                "t",
                "​",
                "k",
                "‖",
                "norm",
                "superscript",
                "𝑓",
                "1",
                "𝑓",
                "subscript",
                "𝐗",
                "𝑎",
                "𝑡",
                "𝑘",
                "subscript",
                "𝐗",
                "𝑎",
                "𝑡",
                "𝑘",
                "||f^{-1}(f(\\mathbf{X}_{atk}))-\\mathbf{X}_{atk}||",
                ", and exploit the trained model on any received ",
                "𝐡",
                "𝐡",
                "\\mathbf{h}",
                ". We analyze the attack on MNIST: For each trained VFL model, we let train such an ",
                "f",
                "−",
                "1",
                "superscript",
                "𝑓",
                "1",
                "f^{-1}",
                " till it converges. By the visualization of results in ",
                "Fig.",
                " ",
                "10",
                ", we note: (1) Unprotected VFL shows almost no resiliency to inversions. (2) Both vanilla and final VFL-AFE profoundly safeguard ",
                "𝐗",
                "𝐗",
                "\\mathbf{X}",
                " from being revealed, as the recovered images are highly blurred. (3) Notably, they show similar capabilities in protection. This supports that our adaptive feature embedding techniques do not affect the protection of established privacy protections.",
                "Membership inference attack.",
                " The attacker aims to determine whether a specific ",
                "x",
                "𝑥",
                "x",
                " belongs to the training data ",
                "𝐗",
                "𝐗",
                "\\mathbf{X}",
                ". To this end,  ",
                "(Shokri et al",
                ".",
                ", ",
                "2017",
                ")",
                " proposes a two-step attack, to train multiple ",
                "shadow models",
                " that mimic the behavior of the victim’s ",
                "f",
                "𝑓",
                "f",
                ", and an ",
                "attack model",
                " that speculates the membership. We use an open-source implementation of the attack ",
                "(Koukyosyumei, ",
                "[n. d.]",
                ")",
                " and report the attacker’s accuracy (lower-bounded by 50%) on VFLs in ",
                "Tab.",
                " ",
                "1",
                ". Lower accuracy indicates better resiliency. The attack is effective on unprotected VFL for all datasets except UCI due to limited exploitable information of binary labels (further see ",
                "(Shokri et al",
                ".",
                ", ",
                "2017",
                ")",
                "). We remark: (1) Both vanilla and final VFL-AFE provide effective defenses against the attacks, as the attack accuracy is reduced to close to 50%. This testifies to the privacy protection of our DP mechanism. (2) The accuracy is slightly higher in the final VFL-AFE. We speculate it as a balance for accuracy, as the increased inter-class discrepancy (",
                "Sec.",
                " ",
                "3.3",
                ") is also favorable for the shadow models. Nonetheless, we note the trade-off is marginal and our DP guarantees still hold."
            ]
        ]
    },
    "S4.T2": {
        "caption": "Table 2. Contribution of each component to accuracy.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\"><span id=\"S4.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Test Accuracy</span></th>\n</tr>\n<tr id=\"S4.T2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S4.T2.1.2.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.1.2.2.1.1.1\" class=\"ltx_p\" style=\"width:34.1pt;\"><span id=\"S4.T2.1.2.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">UCI</span></span>\n</span>\n</th>\n<th id=\"S4.T2.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S4.T2.1.2.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.1.2.2.2.1.1\" class=\"ltx_p\" style=\"width:34.1pt;\"><span id=\"S4.T2.1.2.2.2.1.1.1\" class=\"ltx_text ltx_font_bold\">MNIST</span></span>\n</span>\n</th>\n<th id=\"S4.T2.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S4.T2.1.2.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.1.2.2.3.1.1\" class=\"ltx_p\" style=\"width:34.1pt;\"><span id=\"S4.T2.1.2.2.3.1.1.1\" class=\"ltx_text ltx_font_bold\">CIFAR</span></span>\n</span>\n</th>\n<th id=\"S4.T2.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S4.T2.1.2.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.1.2.2.4.1.1\" class=\"ltx_p\" style=\"width:34.1pt;\"><span id=\"S4.T2.1.2.2.4.1.1.1\" class=\"ltx_text ltx_font_bold\">NUS-W</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S4.T2.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">vanilla</span></th>\n<td id=\"S4.T2.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">77.16</td>\n<td id=\"S4.T2.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">90.48</td>\n<td id=\"S4.T2.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">48.83</td>\n<td id=\"S4.T2.1.3.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">66.87</td>\n</tr>\n<tr id=\"S4.T2.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T2.1.4.2.1.1\" class=\"ltx_text ltx_font_bold\">vanilla+R</span></th>\n<td id=\"S4.T2.1.4.2.2\" class=\"ltx_td ltx_align_center\">79.02</td>\n<td id=\"S4.T2.1.4.2.3\" class=\"ltx_td ltx_align_center\">95.12</td>\n<td id=\"S4.T2.1.4.2.4\" class=\"ltx_td ltx_align_center\">54.58</td>\n<td id=\"S4.T2.1.4.2.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">70.63</td>\n</tr>\n<tr id=\"S4.T2.1.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T2.1.5.3.1.1\" class=\"ltx_text ltx_font_bold\">vanilla+D</span></th>\n<td id=\"S4.T2.1.5.3.2\" class=\"ltx_td ltx_align_center\">77.70</td>\n<td id=\"S4.T2.1.5.3.3\" class=\"ltx_td ltx_align_center\">92.51</td>\n<td id=\"S4.T2.1.5.3.4\" class=\"ltx_td ltx_align_center\">49.53</td>\n<td id=\"S4.T2.1.5.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">68.01</td>\n</tr>\n<tr id=\"S4.T2.1.6.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S4.T2.1.6.4.1.1\" class=\"ltx_text ltx_font_bold\">VFL-AFE</span></th>\n<td id=\"S4.T2.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.6.4.2.1\" class=\"ltx_text ltx_font_bold\">79.31</span></td>\n<td id=\"S4.T2.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.6.4.3.1\" class=\"ltx_text ltx_font_bold\">96.53</span></td>\n<td id=\"S4.T2.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.6.4.4.1\" class=\"ltx_text ltx_font_bold\">55.06</span></td>\n<td id=\"S4.T2.1.6.4.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.6.4.5.1\" class=\"ltx_text ltx_font_bold\">71.18</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We analyze the independent contribution of rescaling (",
                "Sec.",
                " ",
                "3.2",
                ") and distribution adjusting (",
                "Sec.",
                " ",
                "3.3",
                ") to task utility. Results are summarized in ",
                "Tab.",
                " ",
                "2",
                " by test accuracy, where “vanilla+R” and “vanilla+D” represents the results of rescaling and distribution adjusting alone, respectively. We note: (1) Rescaling contributes the majority of utility gain. However, applying it is at the cost of higher run-time overheads (",
                "Sec.",
                " ",
                "4.5",
                "). Distribution adjusting also demonstrates stable effects with relatively low computational costs. (2) Both proposed techniques can be employed together to achieve better task utility.",
                "We defer further ablation studies to supplemental materials due to space limits, where we assume the readers may be interested in some key information, ",
                "e.g.",
                ", the choice of thresholds ",
                "t",
                ",",
                "c",
                "𝑡",
                "𝑐",
                "t,c",
                "."
            ]
        ]
    },
    "S4.T3": {
        "caption": "Table 3. Computational cost by training time.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<th id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">VFL</span></th>\n<th id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">+noise</span></th>\n<th id=\"S4.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">+R</span></th>\n<th id=\"S4.T3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">+D</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S4.T3.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">time (ms)</span></th>\n<td id=\"S4.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">349.89</td>\n<td id=\"S4.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">60.43</td>\n<td id=\"S4.T3.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">279.76</td>\n<td id=\"S4.T3.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">82.04</td>\n</tr>\n<tr id=\"S4.T3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S4.T3.1.3.2.1.1\" class=\"ltx_text ltx_font_bold\">time (%)</span></th>\n<td id=\"S4.T3.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">45.32%</td>\n<td id=\"S4.T3.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">7.83%</td>\n<td id=\"S4.T3.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">36.23%</td>\n<td id=\"S4.T3.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">10.63%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Table",
                " ",
                "3",
                " demonstrate the time cost of 5000 CIFAR-10 samples for baseline VFL, the addition of noise, rescaling (+R), and distribution adjusting (+D), respectively. We observe that the computation of pair-wise distances in rescaling consumes the most considerable time, which, nonetheless, could be believably improved by optimizing algorithms. Overall, we argue the time cost is within a decent scope regarding improved task utility. It is further worth noting that our method requires no extra communication rounds and overheads, which is more favorable than some prior arts ",
                "(Huang et al",
                ".",
                ", ",
                "2021",
                "; Hardy et al",
                ".",
                ", ",
                "2017",
                "; Yang et al",
                ".",
                ", ",
                "2019a",
                "; Xu et al",
                ".",
                ", ",
                "2021",
                ")",
                "."
            ]
        ]
    }
}