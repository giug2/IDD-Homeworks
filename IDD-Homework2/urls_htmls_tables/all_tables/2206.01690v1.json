{
    "S4.T1": {
        "caption": "Table 1: Performance scores on CIFAR-fs dataset, 5-way 5-shot setting for continuous pruning and discrete two-step (MetaDOCK) pruning at different budgets.",
        "table": null,
        "footnotes": [],
        "references": [
            "The results for continuous scheme as well as our approach on CIFAR-fs, 5-way, 5-shot are shown in Table 1. It can be clearly seen that our pruning method outperforms the continuous pruning baseline at both 25% and 12.5% budgets. At extreme budget (12.5%), our approach improves the performance significantly over the baseline. This clearly indicates that the two-step strategy with discrete projection employed in MetaDOCK is more stable and a better approach for pruning in meta-learning.",
            "To analyze the generaliziblity of MetaDOCK across other datasets, we also report results for mini-ImageNet in Tables 10, 10, 10 and 10. We observe that for this dataset as well, the pruned models consistently outperform the baseline model, except for very low budgets of less than 10%, where minor drops in performance are observed. Similar to CIFAR-fs, performance gains of up to 2% in accuracy are observed for this dataset as well. Clearly, with MetaDOCK, it is possible to learn compressed models that perform better than the baseline models in meta-learning.",
            "An interesting observation across both the datasets is that performing task-specific pruning of a larger model is more beneficial than just using an unpruned model of the same size. Intuitively, this seems right since the pruned model will have a more optimized distribution of kernels compared to the unpruned one. For example, we observe for both the datasets, that the 4-conv model when trained with 128 channels and pruned for 25% budget, attains higher accuracy than the pretrained 4-conv model comprising 64 channels - both these models have the same size. The former attains an average meta-test accuracy score of 70.15% on CIFAR-fs 5-way 1-shot (Table 6), while the latter scores 67.25%, thus increasing the performance by an absolute margin of 2.9%. Similarly, the corresponding increase in accuracy for mini-ImageNet dataset is ∼similar-to\\sim2.2% (Table 10 and 10). Similar trends can also be observed for other model pairs as well across datasets and different model settings. This suggests that pruning a large network to get task-specific models is better than using a pretrained model of similar size."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Performance of CIFAR-fs, 5-way 5-shot setting for global and task-specific pruning at different budgets",
        "table": null,
        "footnotes": [],
        "references": [
            "The results for global and task-specific pruning on CIFAR-FS, 5-way 5-shot are shown in Table 2. Task-specific pruning outperforms global pruning at both 12.5% and 6.25% budgets while achieving a greater degree of compression at the same time. This asserts the fact that based on the difficulty of the task, model should be able to compress or expand itself in a given range. This further motivates us to adopt task-specific pruning in all our further experiments."
        ]
    },
    "S4.T6": {
        "caption": "Table 3: Performance of 4-Conv model with 128 channels on CIFAR-fs with 5-way 5-Shot setting at different budgets.",
        "table": null,
        "footnotes": [],
        "references": [
            "We discuss here the results of task-specific pruning obtained using\nMetaDOCK on standard 4-Conv models with 64 and 128 channels for CIFAR-fs 5-way 1-shot and 5-way 5-shot settings. Related results are presented in Tables 6, 6, 6 and 6. Here, meta-budget indicates the fraction of kernels retained in the meta-model, and task-budget refers to the fraction remaining in the task-specific models. In general, we see that the performance of the pruned meta-models is higher than their unpruned counterparts and this gain is observed to be the highest for 5-way, 5-shot setting with 128 channels (Table 6). For this case, pruning greatly improves over the validation and test sets and the best performance is achieved at ∼similar-to\\sim7% budget increasing the performance over the base model by ∼similar-to\\sim2%. Similarly in 5-way, 1-shot setting with 128 channels (Table 6) pruning at 25% budget improves the base performance by ∼similar-to\\sim1%.",
            "An interesting observation across both the datasets is that performing task-specific pruning of a larger model is more beneficial than just using an unpruned model of the same size. Intuitively, this seems right since the pruned model will have a more optimized distribution of kernels compared to the unpruned one. For example, we observe for both the datasets, that the 4-conv model when trained with 128 channels and pruned for 25% budget, attains higher accuracy than the pretrained 4-conv model comprising 64 channels - both these models have the same size. The former attains an average meta-test accuracy score of 70.15% on CIFAR-fs 5-way 1-shot (Table 6), while the latter scores 67.25%, thus increasing the performance by an absolute margin of 2.9%. Similarly, the corresponding increase in accuracy for mini-ImageNet dataset is ∼similar-to\\sim2.2% (Table 10 and 10). Similar trends can also be observed for other model pairs as well across datasets and different model settings. This suggests that pruning a large network to get task-specific models is better than using a pretrained model of similar size."
        ]
    },
    "S4.T10": {
        "caption": "Table 7: Performance of 4-Conv model with 128 channels on mini-ImageNet with 5-way 5-Shot setting at different budgets.",
        "table": null,
        "footnotes": [],
        "references": [
            "To analyze the generaliziblity of MetaDOCK across other datasets, we also report results for mini-ImageNet in Tables 10, 10, 10 and 10. We observe that for this dataset as well, the pruned models consistently outperform the baseline model, except for very low budgets of less than 10%, where minor drops in performance are observed. Similar to CIFAR-fs, performance gains of up to 2% in accuracy are observed for this dataset as well. Clearly, with MetaDOCK, it is possible to learn compressed models that perform better than the baseline models in meta-learning.",
            "An interesting observation across both the datasets is that performing task-specific pruning of a larger model is more beneficial than just using an unpruned model of the same size. Intuitively, this seems right since the pruned model will have a more optimized distribution of kernels compared to the unpruned one. For example, we observe for both the datasets, that the 4-conv model when trained with 128 channels and pruned for 25% budget, attains higher accuracy than the pretrained 4-conv model comprising 64 channels - both these models have the same size. The former attains an average meta-test accuracy score of 70.15% on CIFAR-fs 5-way 1-shot (Table 6), while the latter scores 67.25%, thus increasing the performance by an absolute margin of 2.9%. Similarly, the corresponding increase in accuracy for mini-ImageNet dataset is ∼similar-to\\sim2.2% (Table 10 and 10). Similar trends can also be observed for other model pairs as well across datasets and different model settings. This suggests that pruning a large network to get task-specific models is better than using a pretrained model of similar size."
        ]
    }
}