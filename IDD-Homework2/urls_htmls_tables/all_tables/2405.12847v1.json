{
    "S2.T1": {
        "caption": "Table 1: Details of different audio tasks in the music memory game.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S2.T1.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S2.T1.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S2.T1.2.1.1.1\">Task Type</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S2.T1.2.1.1.2\"># of Audios</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S2.T1.2.1.1.3\"># of Repetition (min)</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S2.T1.2.1.1.4\"># of Repetition (max)</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S2.T1.2.1.1.5\"># of Repetition (avg)</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S2.T1.2.1.1.6\"># of Repetition (std)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S2.T1.2.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.2.2.1.1\">Filler</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.2.2.1.2\">65</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.2.2.1.3\">-</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.2.2.1.4\">-</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.2.2.1.5\">-</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.2.2.1.6\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.3.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.3.2.1\">Vigilance</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.3.2.2\">21</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.3.2.3\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.3.2.4\">10</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.3.2.5\">6.5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.3.2.6\">1.08</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.4.3.1\">Short-Term Target</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.4.3.2\">88</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.4.3.3\">10</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.4.3.4\">49</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.4.3.5\">25.23</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.4.3.6\">10.81</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.5.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.5.4.1\">Medium-Term Target</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.5.4.2\">41</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.5.4.3\">61</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.5.4.4\">131</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.5.4.5\">110.33</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.2.5.4.6\">16.32</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.6.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S2.T1.2.6.5.1\">Long-Term Target</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S2.T1.2.6.5.2\">20</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S2.T1.2.6.5.3\">155</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S2.T1.2.6.5.4\">276</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S2.T1.2.6.5.5\">222.05</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S2.T1.2.6.5.6\">36.64</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "To make the ground truth unbeknownst to all participants, music excerpts are split into three task categories: \u201cvigilance\u201d, \u201ctarget\u201d, and \u201cfiller\u201d. Targets and vigilance targets are both repeated in the experiment, while the former are collected to be the true labels and the latter is used to make sure participants are attentive when labeling data. Moreover, fillers are used to stuff the spacing between the first and second repetition of a target and therefore is only presented once. The overview of the music memory game experimenting procedure is shown in Figure\u00a01. The target-vigilance-filler split details can be found in Table\u00a01. Rigorous criteria are enforced to monitor the performances of data annotators and preserve the quality of memorability labels. Specifically, annotations from users who detect vigilance repetition with an accuracy lower than 60% are automatically discarded. Furthermore, to prevent gathering biased memorability, all annotators only engage in labeling once. We recruited a total of 218 users from campus, with 163 clearing the vigilance accuracy level, 17% of passed annotators having professional music education backgrounds, and over 98% being between the ages of 20 and 29."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Explainable handcraft features.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.2.1.1\">\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.2.1.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.1.1.1.1.1\" style=\"width:39.2pt;\">Level</span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.2.1.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.1.1.2.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.1.1.2.1.1\" style=\"width:53.8pt;\">Category</span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.2.1.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.1.1.3.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.1.1.3.1.1\" style=\"width:107.7pt;\">Feature Implementation</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.2.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S4.T2.2.2.1.1\" rowspan=\"4\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.2.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.2.1.1.1.1\" style=\"width:39.2pt;\"><span class=\"ltx_text\" id=\"S4.T2.2.2.1.1.1.1.1\">Low-level</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S4.T2.2.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.2.1.2.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.2.1.2.1.1\" style=\"width:53.8pt;\">Harmony</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" id=\"S4.T2.2.2.1.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.2.1.3.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.2.1.3.1.1\" style=\"width:107.7pt;\">mean, std of 12 pitch class</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.3.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T2.2.3.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.3.2.1.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.3.2.1.1.1\" style=\"width:53.8pt;\">Rhythm</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T2.2.3.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.3.2.2.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.3.2.2.1.1\" style=\"width:107.7pt;\">beat per minute (bpm)</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.4.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T2.2.4.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.4.3.1.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.4.3.1.1.1\" style=\"width:53.8pt;\">Timbre</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T2.2.4.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.4.3.2.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.4.3.2.1.1\" style=\"width:107.7pt;\">mean, std of 4-tracks (Vocals, Bass, Drums, Others)</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.5.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T2.2.5.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.5.4.1.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.5.4.1.1.1\" style=\"width:53.8pt;\">Zero Crossing</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" id=\"S4.T2.2.5.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.5.4.2.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.5.4.2.1.1\" style=\"width:107.7pt;\"># of zero crossings &amp; avg, median of zero crossings rate</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.6.5\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t\" id=\"S4.T2.2.6.5.1\" rowspan=\"2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.6.5.1.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.6.5.1.1.1\" style=\"width:39.2pt;\"><span class=\"ltx_text\" id=\"S4.T2.2.6.5.1.1.1.1\">High-level</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S4.T2.2.6.5.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.6.5.2.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.6.5.2.1.1\" style=\"width:53.8pt;\">Mood</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"S4.T2.2.6.5.3\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.6.5.3.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.6.5.3.1.1\" style=\"width:107.7pt;\">valence, arousal</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.2.7.6\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b\" id=\"S4.T2.2.7.6.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.7.6.1.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.7.6.1.1.1\" style=\"width:53.8pt;\">Genre</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b\" id=\"S4.T2.2.7.6.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.T2.2.7.6.2.1\">\n<span class=\"ltx_p\" id=\"S4.T2.2.7.6.2.1.1\" style=\"width:107.7pt;\">Music, Musical Instrument</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Although feature extractions for deep learning models can be data-driven without being handcrafted, leading to a better result given sufficient training data, handcrafted features provide interpretable information for more insights. Therefore, we propose handcrafted features that can more accurately depict the low-level acoustic features or high-level semantic features of musical clips as shown in Table\u00a02. For the low-level acoustic features that can be directly derived from the audio signal of music segments, we leverage the harmony, rhythm and timbre since they are most easily recognizable fragments of a piece of music <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.12847v1#bib.bib17\" title=\"\">17</a>]</cite> and describe the fundamental elements of a tune. Moreover, zero crossings and zero crossing rate are also extracted since they give the impressions into the frequency content of a signal. On the other hand, high-level semantic features are more abstract descriptions. Since the previous works in Psychology \n[17] and describe the fundamental elements of a tune. Moreover, zero crossings and zero crossing rate are also extracted since they give the impressions into the frequency content of a signal. On the other hand, high-level semantic features are more abstract descriptions. Since the previous works in Psychology <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.12847v1#bib.bib28\" title=\"\">28</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.12847v1#bib.bib29\" title=\"\">29</a>]</cite> mention the link between music emotion and memory, we introduce valence and arousal, which represent the mood of music pieces as features.\n[28, 29] mention the link between music emotion and memory, we introduce valence and arousal, which represent the mood of music pieces as features."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Spearman\u2019s rank correlation and MSE loss between predicted and ground truth music memorability score using different models. Note that EHC features stand for explainable handcrafted features, PS stands for pitch shift data augmentation, and Corr. represents Spearman\u2019s rank correlation.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T3.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T3.2.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.1.1.1\">Method</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.1.1.2\">Corr.</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.1.1.3\">MSE</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S5.T3.2.1.1.4\">MSE STD</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T3.2.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T3.2.2.1.1\">chroma + MLP</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T3.2.2.1.2\">0.1740</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T3.2.2.1.3\">0.0326</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T3.2.2.1.4\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.3.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.3.2.1\">MFCCs + MLP</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.3.2.2\">0.1179</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.3.2.3\">0.0353</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.3.2.4\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.4.3.1\">convnet features&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.12847v1#bib.bib38\" title=\"\">38</a>]</cite> + MLP</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.4.3.2\">0.1889</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.4.3.3\">0.0314</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.4.3.4\">-</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.5.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.5.4.1\">EHC features + SVR</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.5.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.2.5.4.2.1\">0.2988</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.5.4.3\">0.0339</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.5.4.4\">0.0128</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.6.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.6.5.1\">EHC features + SVR + PS</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.6.5.2\">0.2084</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.6.5.3\">0.0391</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.6.5.4\">0.0129</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.7.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.7.6.1\">EHC features + MLP</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.7.6.2\">0.2656</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.7.6.3\">0.0263</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.7.6.4\">0.0058</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.8.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.8.7.1\">EHC features + MLP + PS</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.8.7.2\">0.2388</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.8.7.3\">0.0275</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.8.7.4\">0.0059</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.9.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.9.8.1\">mel-spectrograms + SSAST</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.9.8.2\">0.0124</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.9.8.3\">0.0298</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T3.2.9.8.4\">0.0061</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.2.10.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S5.T3.2.10.9.1\">mel-spectrograms + SSAST + PS</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S5.T3.2.10.9.2\">0.2658</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S5.T3.2.10.9.3\">0.0265</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S5.T3.2.10.9.4\">0.0074</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Table\u00a03 compares the results of different prediction models, where SVR and MLP take explainable handcrafted features as inputs, and SSAST takes mel-spectrograms as inputs. The results indicate that chroma and MFCCs produce the worst results due to the ineffective feature extraction. For convnet features, the performance is better than chroma and MFCCs due to the pretraining. However, the amount of training data is too small to finetune the model on the music memorability regression task. SSAST outperforms other baselines since it incorporates the prior knowledge of spectrograms pre-trained by using advanced methods. Finally, Explainable Handcrafted Features (EHC) method produces the best correlation results by combining both low- and high-level features that help improve music memorability. These quantitative findings manifest that data-driven MIR tasks are notably reliant on huge data quantities to be resilient and general.",
            "Table 4 shows an ablation study on feature selection for handcrafted features, indicating that selecting top-25 features leads to the best overall correlation results. Moreover, Table 3 also shows an ablation study on extra pitch shifting for data augmentations. Small pitch shifts (less than 5 semitones) make the altered audio seem natural to the human ear according to <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.12847v1#bib.bib40\" title=\"\">40</a>]</cite>. Therefore, we add semitone shifts of -5 to 5 to our data. The results manifest that pitch shifting is effective for the models that take sequence information into account because applying mean pooling across time on harmony features in non-sequential models like SVR and MLP just forces the model to forecast the same value using multiple static chroma information. This may confuse the model on harmony characteristics. On the other hand, models with sequential information, such as SSAST, learn pitch-invariance after pitch shifting. The performance of SSAST notably decreases without pitch shift data augmentation, possibly due to its data-hungry nature as a Transformer-based model, \n[40]. Therefore, we add semitone shifts of -5 to 5 to our data. The results manifest that pitch shifting is effective for the models that take sequence information into account because applying mean pooling across time on harmony features in non-sequential models like SVR and MLP just forces the model to forecast the same value using multiple static chroma information. This may confuse the model on harmony characteristics. On the other hand, models with sequential information, such as SSAST, learn pitch-invariance after pitch shifting. The performance of SSAST notably decreases without pitch shift data augmentation, possibly due to its data-hungry nature as a Transformer-based model, i.e. requiring more data for optimal parameter tuning."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Spearman\u2019s rank correlation and MSE loss for MLP/SVR models with different top-k feature selection.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T4.2\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T4.2.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.1.1.1\">Model</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.1.1.2\">Top-k feature selection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.1.1.3\">Corr.</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.1.1.4\">MSE</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T4.2.2.2.1\">MLP</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T4.2.2.2.2\">k = 40 (no feature selection)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T4.2.2.2.3\">0.2160</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T4.2.2.2.4\">0.0272</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.3.3.1\">MLP</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.3.3.2\">k = 35</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.3.3.3\">0.2324</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.3.3.4\">0.0270</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.4.4.1\">MLP</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.4.4.2\">k = 25</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.4.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.4.3.1\">0.2656</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.4.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.4.4.4.1\">0.0263</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.5.5.1\">MLP</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.5.5.2\">k = 20</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.5.5.3\">0.2018</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.5.5.4\">0.0271</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T4.2.6.6.1\">SVR</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T4.2.6.6.2\">k = 40 (no feature selection)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T4.2.6.6.3\">0.2168</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S5.T4.2.6.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.6.6.4.1\">0.0324</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.7.7.1\">SVR</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.7.7.2\">k = 35</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.7.7.3\">0.2291</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.7.7.4\">0.0340</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.8.8.1\">SVR</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.8.8.2\">k = 25</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.8.8.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.2.8.8.3.1\">0.2988</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T4.2.8.8.4\">0.0339</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.2.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S5.T4.2.9.9.1\">SVR</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S5.T4.2.9.9.2\">k = 20</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S5.T4.2.9.9.3\">0.2630</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S5.T4.2.9.9.4\">0.0354</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Table 4 shows an ablation study on feature selection for handcrafted features, indicating that selecting top-25 features leads to the best overall correlation results. Moreover, Table 3 also shows an ablation study on extra pitch shifting for data augmentations. Small pitch shifts (less than 5 semitones) make the altered audio seem natural to the human ear according to <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.12847v1#bib.bib40\" title=\"\">40</a>]</cite>. Therefore, we add semitone shifts of -5 to 5 to our data. The results manifest that pitch shifting is effective for the models that take sequence information into account because applying mean pooling across time on harmony features in non-sequential models like SVR and MLP just forces the model to forecast the same value using multiple static chroma information. This may confuse the model on harmony characteristics. On the other hand, models with sequential information, such as SSAST, learn pitch-invariance after pitch shifting. The performance of SSAST notably decreases without pitch shift data augmentation, possibly due to its data-hungry nature as a Transformer-based model, \n[40]. Therefore, we add semitone shifts of -5 to 5 to our data. The results manifest that pitch shifting is effective for the models that take sequence information into account because applying mean pooling across time on harmony features in non-sequential models like SVR and MLP just forces the model to forecast the same value using multiple static chroma information. This may confuse the model on harmony characteristics. On the other hand, models with sequential information, such as SSAST, learn pitch-invariance after pitch shifting. The performance of SSAST notably decreases without pitch shift data augmentation, possibly due to its data-hungry nature as a Transformer-based model, i.e. requiring more data for optimal parameter tuning."
        ]
    }
}