{
    "id_table_1": {
        "caption": "Table 1 :  Demographic representation within the synthetic datasets used in our study.",
        "table": "S3.T1.2.1",
        "footnotes": [
            "",
            "",
            ""
        ],
        "references": [
            "This section is dedicated to describing the experimental protocol we followed (Fig.  1 ), including the datasets involved in the experiments, both authentic and synthetic, the training methodologies adopted to combine both types of face data, and the metrics used for model evaluation.",
            "The synthetic datasets were unbalanced towards the Caucasian group, as determined by labeling all the data using a ResNet18  [ 28 ]  backbone trained on BUPT-BalancedFace  [ 60 ]  to predict the ethnicity label of each identity. The inferred ethnicity pseudo-labels are reported in Table  1 . For our experiments, we required 5K unique, demographically balanced identities, aiming for a total of 1,250 identities per demographic group in each synthetic dataset. To achieve this, we (i) randomly sampled 1,250 identities (or the available number, if fewer) from the synthetic datasets and (ii) generated new identities for each demographic group until reaching our targets by guiding the generation process with the above-mentioned ResNet18  [ 28 ]  backbone. For each synthetic dataset, the additional identities were generated using the pre-trained models made publicly available by the original authors without further training. We denote the synthetic subsets sampled in the first step as GC sub , DC sub , and IDF sub , and the ones generated in the second step as GC gen , DC gen , and IDF gen , using GANControl, DCFace, and IDiff-Face, respectively. Finally, the synthetic, demographically balanced datasets, each comprising 5K identities and derived from the union of the two respective datasets for each method, are referred to as GC bal , DC bal , and IDF bal  for the sake of clarity.",
            "Our experiments initially aimed to assess whether an FR model trained on a demographically balanced synthetic dataset could achieve competitive accuracy compared to an FR model trained on an authentic dataset with the same number of identities and demographic representation (Section  4.1 ). Subsequently, we explored the impact on verification accuracy by training FR models on combined synthetic and authentic data (Section  4.2 ) and investigated the impact on the fairness of each setting involved in our study (Section  4.3 )."
        ]
    },
    "id_table_2": {
        "caption": "Table 2 :  Verification accuracy of FR models trained on 5K identities  without data augmentation . The results are reported for models trained: (i) only on authentic data, averaged across 10 iterations, (ii) only on authentic data, for the best performing iteration, and (iii) only on synthetic, demographically balanced data. The best results for each group are highlighted in bold.",
        "table": "S4.T2.7.7",
        "footnotes": [],
        "references": [
            "The rest of the paper is structured as follows. Section  2  discusses recent progress in face recognition methods and synthetic face generation. Section  3  then describes the data preparation, model creation and training, and model evaluation adopted in our study. Section  4  examines the differences in verification accuracy and fairness between FR models trained on synthetic and/or authentic data. Finally, Section  5  summarizes our findings and provides directions for future research. Code and data are available at  https://cutt.ly/AeQy1K5G .",
            "Our experiments initially aimed to assess whether an FR model trained on a demographically balanced synthetic dataset could achieve competitive accuracy compared to an FR model trained on an authentic dataset with the same number of identities and demographic representation (Section  4.1 ). Subsequently, we explored the impact on verification accuracy by training FR models on combined synthetic and authentic data (Section  4.2 ) and investigated the impact on the fairness of each setting involved in our study (Section  4.3 ).",
            "In a first analysis, we assessed whether an FR model trained on a demographically balanced synthetic dataset can achieve competitive accuracy compared to an FR model trained on an authentic dataset with the same number of identities and demographic representation. To this end, Tab.  2  (without data augmentation) and  3  (with data augmentation) present the accuracy of the FR models trained on authentic and synthetic datasets, separately, with 5K identities.",
            "In our investigation, models trained exclusively on authentic data without the application of data augmentation (Tab.  2 , first two groups) consistently exhibited superior verification accuracy when trained on subsets of the CASIA-WebFace dataset. This trend was observed both when considering average performance across iterations (WF avg ) and the best iteration outcomes (WF sub ), with these models showing an approximately 15% improvement in verification accuracy w.r.t. the respective one trained on demographically balanced subsets of BUPT (BUPT avg  and BUPT sub ). In contrast, among the models trained solely on synthetic images (Tab.  2 , third group), the model trained on the DC bal  subset achieved the highest verification accuracy across all evaluation benchmarks. Specifically, the latter model outperformed the one trained on the IDF bal  subset by an average of 3.35% and the one trained on the GC bal  subset by a substantial 20.16%. Interestingly, we observed a pronounced accuracy degradation of the FR model trained on the GC bal  subset, when evaluated on cross-age benchmarks (AgeDB-30 and CA-LFW columns). For instance, compared to the models trained on DC bal , GC bal -trained models exhibited a 30.66% reduction on AgeDB-30 and a 19.39% decrease on CA-LFW. Comparing between models trained with the two different types of sources separately (authentic and synthetic), models trained exclusively on synthetic data from DC bal  and IDF bal  generally achieved better verification accuracy compared to models trained on the authentic, demographically-balanced BUPT sub  subset. Specifically, the model trained on the DC bal  subset obtained 9.82% higher average verification accuracy, while training on the IDF bal  subset led to a 6.25% gain, on average. Despite the promising results achieved by training an FR model on the best-performing synthetic dataset (DC bal ), a substantial gap of 5.40% in average verification accuracy remains when compared to the best-performing authentic dataset (CASIA sub )."
        ]
    },
    "id_table_3": {
        "caption": "Table 3 :  Verification accuracy of FR models trained on 5K identities  with data augmentation . The results are reported for models trained: (i) only on authentic data, averaged across 10 iterations, (ii) only on authentic data, for the best performing iteration, and (iii) only on synthetic, demographically balanced data. The best results for each group are highlighted in bold.",
        "table": "S4.T3.5.5",
        "footnotes": [],
        "references": [
            "The rest of the paper is structured as follows. Section  2  discusses recent progress in face recognition methods and synthetic face generation. Section  3  then describes the data preparation, model creation and training, and model evaluation adopted in our study. Section  4  examines the differences in verification accuracy and fairness between FR models trained on synthetic and/or authentic data. Finally, Section  5  summarizes our findings and provides directions for future research. Code and data are available at  https://cutt.ly/AeQy1K5G .",
            "Our experiments initially aimed to assess whether an FR model trained on a demographically balanced synthetic dataset could achieve competitive accuracy compared to an FR model trained on an authentic dataset with the same number of identities and demographic representation (Section  4.1 ). Subsequently, we explored the impact on verification accuracy by training FR models on combined synthetic and authentic data (Section  4.2 ) and investigated the impact on the fairness of each setting involved in our study (Section  4.3 ).",
            "In a first analysis, we assessed whether an FR model trained on a demographically balanced synthetic dataset can achieve competitive accuracy compared to an FR model trained on an authentic dataset with the same number of identities and demographic representation. To this end, Tab.  2  (without data augmentation) and  3  (with data augmentation) present the accuracy of the FR models trained on authentic and synthetic datasets, separately, with 5K identities.",
            "The impact of data augmentation on models trained solely on synthetic data (Tab.  3 , second group) was notably pronounced, especially for GC bal . The model trained on the latter, augmented subset, led to an average accuracy improvement of 11.75% compared to the corresponding model trained without augmentation. This improvement was particularly pronounced on cross-age benchmarks, with a remarkable 34.42% increase in verification accuracy on AgeDB-30 and a 15.59% increase on CA-LFW. Furthermore, all the models trained on synthetic datasets still reported higher verification accuracy compared to those trained on the balanced, augmented authentic data (BUPT sub ), with the smallest improvement observed while training on GC bal  (0.72%) and the highest improvement measured while training on DC bal  (9.54%). On the other hand, adding data augmentation to the training pipeline of models trained exclusively on authentic data (Tab.  3 , first group) resulted in only marginal improvements, where the maximum increase in accuracy was limited to 1.40% (BUPT sub ). Comparing results obtained by training an FR model on DC bal  and CASIA sub  while applying data augmentation, it can be noted that the accuracy gap between training on authentic and synthetic data is reduced (4.19%) with respect to the gap obtained by training on the same datasets without data augmentation."
        ]
    },
    "id_table_4": {
        "caption": "Table 4 :  Verification accuracy of FR models trained on 10K identities  without data augmentation . Results are reported for models (i) trained only on authentic data and (ii) trained on demographically balanced, combined data. BUPT 10K  denotes a demographically balanced subset of 10K identities (2.5K per group) from BUPT-Balancedface, whereas CASIA-WebFace was not demographically balanced. Best results for each group are highlighted in bold.",
        "table": "S4.T4.10.10",
        "footnotes": [],
        "references": [
            "The rest of the paper is structured as follows. Section  2  discusses recent progress in face recognition methods and synthetic face generation. Section  3  then describes the data preparation, model creation and training, and model evaluation adopted in our study. Section  4  examines the differences in verification accuracy and fairness between FR models trained on synthetic and/or authentic data. Finally, Section  5  summarizes our findings and provides directions for future research. Code and data are available at  https://cutt.ly/AeQy1K5G .",
            "Our experiments initially aimed to assess whether an FR model trained on a demographically balanced synthetic dataset could achieve competitive accuracy compared to an FR model trained on an authentic dataset with the same number of identities and demographic representation (Section  4.1 ). Subsequently, we explored the impact on verification accuracy by training FR models on combined synthetic and authentic data (Section  4.2 ) and investigated the impact on the fairness of each setting involved in our study (Section  4.3 ).",
            "In a second analysis, we explored the impact on verification accuracy by training FR models using a combination of synthetic and authentic data. To this end, Tab.  4  (without data augmentation) and  5  (with data augmentation) report the verification accuracy of FR models trained on datasets (either entirely authentic or combined), each composed of 10K identities.",
            "Models trained exclusively on authentic data without data augmentation (Tab.  4 , first group) highlighted (again) a substantial gap in verification accuracy between the model trained on CASIA-WebFace and the one trained on BUPT 10K , with a 14.32% difference. FR models trained on a demographically balanced combination of synthetic and authentic data without data augmentation (Tab.  4 , second group) consistently outperformed the baseline model trained solely on BUPT 10K . Specifically, these models obtained 4.04% (BUPT sub    \\cup   GC bal ), 7.36% (BUPT sub    \\cup   IDF bal ), and 9.71% (BUPT sub    \\cup   DC bal ) higher verification accuracy. Notably, when training an FR model on the combined BUPT sub    \\cup   GC bal  dataset without data augmentation, the accuracy degradation identified on cross-age benchmarks in the previous subsection was not observed, suggesting that the inclusion of a balanced authentic data subset (BUPT sub ) effectively mitigates these issues. The best verification accuracy across all benchmarks was achieved by models trained on the combined dataset including DC bal  as the synthetic component (BUPT sub    \\cup   DC bal ). This model showed an average accuracy increase of 1.18% over the one trained on BUPT sub    \\cup   IDF bal  and 5.44% over the one trained on BUPT sub    \\cup   GC bal . Comparing results obtained by training an FR model on BUPT sub    \\cup   DC bal  and CASIA-WebFace, it can be noted that while the accuracy gap between training on authentic and combined (authentic and synthetic) data is reduced, it remains remarkable, with a 4.20% difference."
        ]
    },
    "id_table_5": {
        "caption": "Table 5 :  Verification accuracy of FR models trained on 10K identities  with data augmentation . Results are reported for models (i) trained only on authentic data and (ii) trained on demographically balanced, combined data. BUPT 10K  denotes a demographically balanced subset of 10K identities (2.5K per group) from BUPT-Balancedface, whereas CASIA-WebFace was not demographically balanced. Best results for each group are highlighted in bold.",
        "table": "S4.T5.10.10",
        "footnotes": [],
        "references": [
            "The rest of the paper is structured as follows. Section  2  discusses recent progress in face recognition methods and synthetic face generation. Section  3  then describes the data preparation, model creation and training, and model evaluation adopted in our study. Section  4  examines the differences in verification accuracy and fairness between FR models trained on synthetic and/or authentic data. Finally, Section  5  summarizes our findings and provides directions for future research. Code and data are available at  https://cutt.ly/AeQy1K5G .",
            "In a second analysis, we explored the impact on verification accuracy by training FR models using a combination of synthetic and authentic data. To this end, Tab.  4  (without data augmentation) and  5  (with data augmentation) report the verification accuracy of FR models trained on datasets (either entirely authentic or combined), each composed of 10K identities.",
            "FR models trained with data augmentation only on authentic data (Tab.  5 , first group) showed slight decreases in verification accuracy w.r.t. the non-augmented counterpart, with degradations of 2.67% (BUPT 10K ) and 0.11% (CASIA-WebFace). Conversely, while the impact of data augmentation on models trained on combined synthetic and authentic data (Tab.  5 , second group) was generally positive, the improvement was minimal. The models reported an increase in average verification accuracy of 0.88% when trained on BUPT sub    \\cup   GC bal , 0.45% on BUPT sub    \\cup   IDF bal , and 0.52% on BUPT sub    \\cup   DC bal . As previously observed, including data augmentation in the training pipeline positively affects the verification accuracy gap observed when comparing the results of the FR model trained on the best-performing authentic (CASIA-WebFace) and combined (BUPT sub    \\cup   DC bal ) datasets, leading to a reduced 3.54% difference."
        ]
    },
    "id_table_6": {
        "caption": "Table 6 :  Fairness on RFW demographic groups  without data augmentation . We report the verification accuracy, standard deviation, and skewed error for FR models trained: (i) only on authentic data (10K), (ii) on demographically balanced, combined data (10K), (iii) only on authentic data, averaged across ten iterations (5K), (iv) only on authentic data, on the best iteration (5K), and (v) only on synthetic, demographically balanced data. BUPT 10K  denotes a demographically balanced subset of 10K identities (2.5K per group) from BUPT-Balancedface, whereas CASIA-WebFace was not demographically balanced. Best results for each group are highlighted in bold.",
        "table": "S4.T6.24.24",
        "footnotes": [],
        "references": [
            "In the third and final analysis, we investigated the impact on fairness of each setting involved in our study. To this end, Tab.  6  (without data augmentation) and  7  (with data augmentation) present the verification accuracy for each demographic group, as well as the standard deviation (STD) and the skewed error ratio (SER) on the RFW datasets benchmark used to evaluate the fairness of FR models. Higher values of STD and SER indicate a higher level of unfairness.",
            "On the RFW benchmark, models trained exclusively on authentic data without data augmentation (Tab.  6 , first group) revealed that training on the balanced dataset (BUPT 10K ) led to lower verification accuracy compared to CASIA-WebFace, with a notable gap of 16.19%. Although training on BUPT 10K  led to a slight improvement in terms of fairness, as indicated by a 6.52% reduction in STD, it also showed a slight negative impact on SER. A similar trend was observed when training FR models on smaller subsets with 5K identities, BUPT sub  and WF sub  (Tab.  6 , third and fourth groups), where the balanced subset showed marginally better fairness but still under-performed in verification accuracy.",
            "The results achieved by training FR models on synthetic balanced subsets (Tab.  6 , second and fifth groups), either alone or in combination with BUPT sub , slightly diverged from previous observations. Among the models trained solely on synthetic data (Tab.  6 , second group), the model trained on IDF bal  achieved the highest average verification accuracy, outperforming those trained on DC bal  by 1.06% and on GC bal  by 22.23%. Additionally, the model trained on IDF bal  reported the best SER (1.02), while the model trained on GC bal  achieved the lowest STD. Training on combined balanced datasets (Tab.  6 , fifth group) led to similar patterns. The model trained on BUPT sub    \\cup   IDF bal  exhibited the best average accuracy across demographic groups (82.78%) and the lowest SER and STD (1.07 and 2.33, respectively). Models trained on the other combined datasets (BUPT sub    \\cup   GC bal  and BUPT sub    \\cup   DC bal ) reported a SER of 1.09, but differences were noted in average STD and verification accuracy. Specifically, the model trained on BUPT sub    \\cup   DC bal  achieved 8.06% higher accuracy but a worse STD (-26.97%) compared to the model trained on BUPT sub    \\cup   GC bal ."
        ]
    },
    "id_table_7": {
        "caption": "Table 7 :  Fairness on RFW demographic groups  with data augmentation . We report the verification accuracy, standard deviation, and skewed error for FR models trained: (i) only on authentic data (10K), (ii) on demographically balanced, combined data (10K), (iii) only on authentic data, averaged across ten iterations (5K), (iv) only on authentic data, on the best iteration (5K), and (v) only on synthetic, demographically balanced data. BUPT 10K  denotes a demographically balanced subset of 10K identities (2.5K per group) from BUPT-Balancedface, whereas CASIA-WebFace was not demographically balanced. Best results for each group are highlighted in bold.",
        "table": "S4.T7.22.22",
        "footnotes": [],
        "references": [
            "In the third and final analysis, we investigated the impact on fairness of each setting involved in our study. To this end, Tab.  6  (without data augmentation) and  7  (with data augmentation) present the verification accuracy for each demographic group, as well as the standard deviation (STD) and the skewed error ratio (SER) on the RFW datasets benchmark used to evaluate the fairness of FR models. Higher values of STD and SER indicate a higher level of unfairness.",
            "Training with data augmentation (Tab.  7 ) had a generally negative impact on models trained solely on authentic data (Tab.  7 , first and third groups), worsening both average verification accuracy and fairness metrics on both the employed authentic datasets. This trend was consistent across the study, with data augmentation resulting in a substantial deterioration of fairness metrics for all models, except for the STD in models trained on DC bal , IDF bal , and BUPT sub    \\cup   DC bal . Interestingly, training with data augmentation led to gains in accuracy across all models trained on combined or synthetic datasets (Tab.  7 , second and fourth groups), exception made for BUPT sub    \\cup   DC bal ."
        ]
    }
}