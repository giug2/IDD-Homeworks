{
    "S3.T1": {
        "caption": "Table 1: Model‚Äôs performance on the multimodal 5-shot regression with two or three modes. Gaussian noise with Œº=0ùúá0\\mu=0 and œÉ=0.3ùúé0.3\\sigma=0.3 is applied. The three mode regression is in general more difficult (thus higher error). In Multi-MAML, the GT modulation represents using ground-truth task identification to select different MAML models for each task mode. MuMoMAML (wt. FiLM) outperforms other methods by a significant margin.",
        "table": null,
        "footnotes": [],
        "references": [
            "As a baseline beside MAML, we propose Multi-MAML, which consists of MùëÄM\n(the number of modes) separate MAML models which are chosen for each query based\non ground-truth task-mode labels.\nThis baseline serves as an upper-bound for the performance of MAML\nwhen the task-mode labels are available.\nThe quantitative results are shown in Table 1.\nWe observe that Multi-MAML outperforms MAML, showing that MAML‚Äôs performance degrades on\nmultimodal task distributions.\nMuMoMAML consistently achieves better results than Multi-MAML, demonstrating\nthat our model is able to discover and exploit transferable\nknowledge across the modes to improve its performance.\nThe marginal gap between the performance of our model in two and three mode settings\nindicates that MuMoMAML is able to clearly identify the task modes and has sufficient\ncapacity for all modes.",
            "As shown in the quantitative results (Table 1),\nusing FiLM as a modulation method achieves\nbetter results comparing to attention mechanism with Sigmoid or Softmax.\nWe therefore use FiLM for further experiments."
        ]
    },
    "A2.T2": {
        "caption": "Table 2:  5-way and 20-way, 1-shot and 5-shot classification accuracy on Omniglot Dataset.\nFor each task, the best-performing method is highlighted.\nMuMoMAML achieves comparable or better results against state-of-the-art few-shot learning algorithms for image classification.",
        "table": null,
        "footnotes": [],
        "references": [
            "The task of few-shot image classification considers a problem of\nclassifying images into N classes with a small number (K) of labeled samples available.\nTo evaluate our model on this task, we conduct experiments on\nOmniglot, a widely used handwritten character dataset of binary images.\nThe results are shown in Table 2, demonstrating that\nour method achieves comparable or better results against state-of-the-art algorithms."
        ]
    }
}