{
    "S4.T1": {
        "caption": "TABLE I: Categories of baseline methods",
        "table": null,
        "footnotes": [],
        "references": [
            "In this section, we present the empirical experimental results to establish following points: (i) SchemaWalk¬†can effectively and efficiently generate meta-paths without relation-specific evidence (multi-relation inductive setting, as in Sec. 4.1.1), (ii) SchemaWalk¬†is competitive against state-of-the-art KB reasoning baselines in the query answering task (multi-relation transductive setting, as in Sec. 4.1.2), (iii) SchemaWalk¬†is effective in reasoning general HINs (per-relation transductive setting, as in Sec. 4.2). The distinctions between the three settings are illustrated in Fig. 3. In the per-relation transductive setting (which is prevalent in the current HIN reasoning experiments), the agent is trained and tested over entity pairs connected by a specific relation in each run. For the two multi-relation settings, we train and test our model on entity pairs associated with multiple relations. In the multi-relation inductive setting, the trained and test relations do not overlap. Overall, we compare against the baselines shown in Table I."
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Meta-path space for some relations in YAGO26K-906",
        "table": null,
        "footnotes": [],
        "references": [
            "Datasets. We use two large KBs: YAGO26K-906 and Dbpedia for multi-relation settings. The meta-path space for some relations in YAGO26K-906 is showcased in Table II. We can see that, even in YAGO26K-906 which has comparatively fewer entity types and relations, each relation entails a million-scale meta-path space to search over and has extremely low valid rate. Here, a meta-path is valid if it has any meta-path instance in the ùí¢Isubscriptùí¢ùêº\\mathcal{G}_{I}, and low valid rate reflect the difficulty of mining meaningful meta-paths from the meta-path space. Besides, for DB111K-174, which contains 305 relations, we train and test on sampled relations. A detailed description on the two datasets and the chosen train/test relations could be found at Appendix VII."
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: Inductive KG reasoning results on YAGO26K-906 and DB111K-174, averaged over 5 runs. Enumeration cannot scale to DB111K-174 and hence the results are not reported. The best/second best metrics are bolded/underline",
        "table": null,
        "footnotes": [],
        "references": [
            "Observations. Table III displays the multi-relation inductive results on YAGO26K-906 and DB111K-174. SchemaWalk¬†significantly outperforms random walk in terms of efficiency and effectiveness. Even when we increase the search attempts for random walk by a factor of ten, it still cannot beat the accuracy of our approach on YAGO26K-906. On DB111K-174, SchemaWalk¬†exhibits more significant superiority over the random walk method.\nEnumeration present the best prediction answers on YAGO26K-906, but at an enormous computational cost (consuming nearly 498 times the inference time than SchemaWalk). Furthermore, enumeration cannot scale to DB111K-174 given the enormous meta-path space.\nNotably, SchemaWalk¬†produces meta-paths with significantly higher valid rate compared to other methods, which is about 6.5 times the valid rate obtained using random walk, and 13 times obtained using enumeration. This indicates that SchemaWalk¬†indeed learns the mechanism to generate meaningful and relevant meta-paths."
        ]
    },
    "S4.T4": {
        "caption": "TABLE IV: Transductive KG reasoning results on YAGO26K-906 and DB111K-174, averaged over 5 runs. The best/second best metrics are bolded/underlined.",
        "table": null,
        "footnotes": [],
        "references": [
            "Observations. In Table IV, we show the multi-relation transductive results on YAGO26K-906 and DB111K-174. SchemaWalk¬†demonstrates superior performance over three embedding-based methods, namely TransE, DistMult, and ComplEx, and wins a noticeable advantage over the path-based MINERVA. On YAGO26K-906, SchemaWalk¬†outperforms all other models in the Hits@10 metric and performs comparably with the rule-learning RNNLogic across all metrics. Additionally, on DB111K-174, SchemaWalk¬†achieves the highest scores for Hits@3, Hits@10, and the second-highest score for MRR. Overall, SchemaWalk¬†competes strongly with state-of-the-art models for transductive KG query-answering."
        ]
    },
    "S4.T5": {
        "caption": "TABLE V: Per-relation link prediction results for YAGO26K-906, NELL and Chem2Bio2RDF, averaged over 5 runs. The bold/underlined results respectively indicate the best/second best performances for each relation among all methods.",
        "table": null,
        "footnotes": [],
        "references": [
            "The ROC-AUC and AP for SchemaWalk¬†and the baselines for the link prediction task on the six selected relations are presented in Table V. SchemaWalk¬†excels in all relations in YAGO26K-906 and the relation WorksFor in NELL, only lagging behind by RotatE for relations PlaysAgainst and CompetesWith in NELL.",
            "We show the link prediction results on Chem2Bio2RDF in Table V. As demonstrated by the results, the meta-paths generated by SchemaWalk¬†can distinguish all positive facts from negative facts. Besides, SchemaWalk¬†only takes an average of 30 iterations (or roughly 400 seconds) to learn all the necessary meta-paths for link prediction. In contrast, other baselines are much more time-consuming, often taking several hours due to the gigantic instance graph of Chem2Bio2RDF. Our model is effective and efficient for general HINs."
        ]
    },
    "S5.T6": {
        "caption": "TABLE VI: Example meta-paths outputted/inferred by SchemaWalk",
        "table": null,
        "footnotes": [],
        "references": [
            "We examine the generated meta-paths and select those meta-paths with high rewards, which are presented in Table VI. All these meta-paths accurately conveyed the semantic meaning of the given relations. We also observe that our model is capable of using synonymous relations to explain target relations, as demonstrated by utilizing CompetesWith for PlayAgainst and Nationality for StateOfOrigin).\nIn multi-relation inductive settings, SchemaWalk¬†also infer high-quality meta-paths for untrained relations (e.g., StateOfOrigin and MusicalBand in DB111K-174)."
        ]
    },
    "A2.T7": {
        "caption": "TABLE VII: Statistics of real-world datasets",
        "table": null,
        "footnotes": [],
        "references": [
            "Datasets. We use two large KBs: YAGO26K-906 and Dbpedia for multi-relation settings. The meta-path space for some relations in YAGO26K-906 is showcased in Table II. We can see that, even in YAGO26K-906 which has comparatively fewer entity types and relations, each relation entails a million-scale meta-path space to search over and has extremely low valid rate. Here, a meta-path is valid if it has any meta-path instance in the ùí¢Isubscriptùí¢ùêº\\mathcal{G}_{I}, and low valid rate reflect the difficulty of mining meaningful meta-paths from the meta-path space. Besides, for DB111K-174, which contains 305 relations, we train and test on sampled relations. A detailed description on the two datasets and the chosen train/test relations could be found at Appendix VII.",
            "Datasets.\nTo validate SchemaWalk‚Äôs relation-wise reasoning ability on schema-complex HINs, we run experiments on YAGO26K-906 and NELL.\nWe also include a schema-simple HIN, Chem2Bio2RDF, to demonstrate that SchemaWalk¬†is also useful for general HINs. The details about the chosen datasets are in Appendix VII. We consider three relations each for the two KBs: {isCitizenOf, DiedIn, GraduatedFrom} for YAGO26K-906 and {WorksFor, CompetesWith, PlaysAgainst} for NELL. For Chem2Bio2RDF, we focus on predicting drug-target connectivity, i.e., the relation bind.",
            "The statistics of the datasets are summarized in Table VII."
        ]
    },
    "A2.T8": {
        "caption": "TABLE VIII: Hyper-parameters",
        "table": null,
        "footnotes": [],
        "references": [
            "We conduct experiments on a desktop computer with a 10-core CPU, a 32GB memory and a 12GB RTX-2080Ti GPU. We use sparse matrix to compute coverage and confidence for all necessary meta-paths during training. The calculated numerical values for the explored meta-paths are stored in memory during training to reduce unnecessary computation. See Table VIII for hyper-parameters."
        ]
    }
}