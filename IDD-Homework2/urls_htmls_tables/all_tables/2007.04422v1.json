{
    "S3.T1": {
        "caption": "Table 1: Consistency and robustness performance on rule-based validation, VQA-Implications and VQA-Rephrasings dataset. Consistency and robustness are defined as percentage of correctly answered implications and rephrasings respectively, generated only on correctly answered original questions. All the models trained with our approach outperform their respective baselines in all categories, keeping the validation accuracy almost same.",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" rowspan=\"2\"><span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" rowspan=\"2\"><span id=\"S3.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Val acc</span></th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" colspan=\"4\"><span id=\"S3.T1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Consistency(rule-based)</span></th>\n<th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" rowspan=\"2\"><span id=\"S3.T1.1.1.1.4.1\" class=\"ltx_text\">\n<span id=\"S3.T1.1.1.1.4.1.1\" class=\"ltx_inline-block ltx_parbox ltx_align_middle\" style=\"width:56.9pt;\">\n<span id=\"S3.T1.1.1.1.4.1.1.1\" class=\"ltx_p\"><span id=\"S3.T1.1.1.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Consistency</span></span>\n<span id=\"S3.T1.1.1.1.4.1.1.2\" class=\"ltx_p ltx_align_center\"><span id=\"S3.T1.1.1.1.4.1.1.2.1\" class=\"ltx_text ltx_font_bold\">(VQA-Imp)</span></span>\n</span></span></th>\n<th id=\"S3.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" rowspan=\"2\"><span id=\"S3.T1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Robustness</span></th>\n</tr>\n<tr id=\"S3.T1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">Logeq</td>\n<td id=\"S3.T1.1.2.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">Nec</td>\n<td id=\"S3.T1.1.2.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">Mutex</td>\n<td id=\"S3.T1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">Overall</td>\n</tr>\n<tr id=\"S3.T1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">BUTD <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\">2</a>]</cite>\n</th>\n<th id=\"S3.T1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">63.62</th>\n<th id=\"S3.T1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">64.3</th>\n<th id=\"S3.T1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">71.1</th>\n<th id=\"S3.T1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">59.8</th>\n<th id=\"S3.T1.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">65.3</th>\n<th id=\"S3.T1.1.3.3.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">67.14</th>\n<th id=\"S3.T1.1.3.3.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">79.21</th>\n</tr>\n<tr id=\"S3.T1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\" style=\"padding-top:1pt;padding-bottom:1pt;\">BUTD + IQ</th>\n<th id=\"S3.T1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">63.57</th>\n<td id=\"S3.T1.1.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.4.4.3.1\" class=\"ltx_text ltx_font_bold\">88.5</span></td>\n<td id=\"S3.T1.1.4.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.4.4.4.1\" class=\"ltx_text ltx_font_bold\">96.7</span></td>\n<td id=\"S3.T1.1.4.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.4.4.5.1\" class=\"ltx_text ltx_font_bold\">77.0</span></td>\n<td id=\"S3.T1.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.4.4.6.1\" class=\"ltx_text ltx_font_bold\">88.1</span></td>\n<td id=\"S3.T1.1.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.4.4.7.1\" class=\"ltx_text ltx_font_bold\">74.38</span></td>\n<td id=\"S3.T1.1.4.4.8\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.4.4.8.1\" class=\"ltx_text ltx_font_bold\">80.77</span></td>\n</tr>\n<tr id=\"S3.T1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">BAN <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">7</a>]</cite>\n</th>\n<th id=\"S3.T1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">65.37</th>\n<th id=\"S3.T1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">67.1</th>\n<th id=\"S3.T1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">77.6</th>\n<th id=\"S3.T1.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">61.1</th>\n<th id=\"S3.T1.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">69.0</th>\n<th id=\"S3.T1.1.5.5.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">66.57</th>\n<th id=\"S3.T1.1.5.5.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">79.93</th>\n</tr>\n<tr id=\"S3.T1.1.6.6\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\" style=\"padding-top:1pt;padding-bottom:1pt;\">BAN + IQ</th>\n<th id=\"S3.T1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">65.28</th>\n<td id=\"S3.T1.1.6.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.6.6.3.1\" class=\"ltx_text ltx_font_bold\">89.3</span></td>\n<td id=\"S3.T1.1.6.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.6.6.4.1\" class=\"ltx_text ltx_font_bold\">97.9</span></td>\n<td id=\"S3.T1.1.6.6.5\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.6.6.5.1\" class=\"ltx_text ltx_font_bold\">79.8</span></td>\n<td id=\"S3.T1.1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.6.6.6.1\" class=\"ltx_text ltx_font_bold\">89.6</span></td>\n<td id=\"S3.T1.1.6.6.7\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.6.6.7.1\" class=\"ltx_text ltx_font_bold\">74.61</span></td>\n<td id=\"S3.T1.1.6.6.8\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.6.6.8.1\" class=\"ltx_text ltx_font_bold\">81.62</span></td>\n</tr>\n<tr id=\"S3.T1.1.7.7\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Pythia <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">24</a>]</cite>\n</th>\n<th id=\"S3.T1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">64.70</th>\n<th id=\"S3.T1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">69.7</th>\n<th id=\"S3.T1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">76.4</th>\n<th id=\"S3.T1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">67.7</th>\n<th id=\"S3.T1.1.7.7.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">70.0</th>\n<th id=\"S3.T1.1.7.7.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">70.89</th>\n<th id=\"S3.T1.1.7.7.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">79.31</th>\n</tr>\n<tr id=\"S3.T1.1.8.8\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l\" style=\"padding-top:1pt;padding-bottom:1pt;\">Pythia + IQ</th>\n<th id=\"S3.T1.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">65.60</th>\n<td id=\"S3.T1.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.8.8.3.1\" class=\"ltx_text ltx_font_bold\">88.7</span></td>\n<td id=\"S3.T1.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.8.8.4.1\" class=\"ltx_text ltx_font_bold\">97.6</span></td>\n<td id=\"S3.T1.1.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.8.8.5.1\" class=\"ltx_text ltx_font_bold\">79.0</span></td>\n<td id=\"S3.T1.1.8.8.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.8.8.6.1\" class=\"ltx_text ltx_font_bold\">88.7</span></td>\n<td id=\"S3.T1.1.8.8.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.8.8.7.1\" class=\"ltx_text ltx_font_bold\">76.55</span></td>\n<td id=\"S3.T1.1.8.8.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S3.T1.1.8.8.8.1\" class=\"ltx_text ltx_font_bold\">82.40</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "As seen in Table 1 All the 3 models achieve an average consistency score of ~70%. i.e. they fail 30% of the times on implications of correctly predicted questions. Intuitively, Nec-implication serves as the neccessary condition which the models should know in order to answer the question. For eg: In order to answer ”How many birds are there?”, they should understand if ”Are there any birds in the picture?” Consistency score of ~75% Nec-implication shows the lack of image understanding in these models. Using our approach, the three models achieve ~97% on Nec-implication.",
            "We evaluate our framework’s robustness performance on the VQA-Rephrasings dataset introduced in [18]. Robustness is evaluated only on correctly answered original questions. Note that just like the models in [18], we also do not train our models on the VQA-Rephrasings dataset. The results in Table 1 show that models trained using our approach are more robust compared to baseline. This is consistent with the hypotheses that our models learn to improve on a stronger linguistic variation than rephrasings by learning on implications and hence improvement in robustness is expected."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Implication generation performance on rule-based Implication validation dataset. Note that using the knob mechanism instead of an implied answer gives significant improvement.",
        "table": "<table id=\"S5.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S5.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">BLEU-1</span></th>\n<th id=\"S5.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">BLEU-2</span></th>\n<th id=\"S5.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">BLEU-3</span></th>\n<th id=\"S5.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">BLEU-4</span></th>\n<th id=\"S5.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">ROUGE-L</span></th>\n<th id=\"S5.T2.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.1.1.7.1\" class=\"ltx_text ltx_font_bold\">METEOR</span></th>\n<th id=\"S5.T2.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.1.1.8.1\" class=\"ltx_text ltx_font_bold\">CIDEr</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">Pythia + IQ</th>\n<td id=\"S5.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">0.627</td>\n<td id=\"S5.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">0.520</td>\n<td id=\"S5.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">0.443</td>\n<td id=\"S5.T2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">0.381</td>\n<td id=\"S5.T2.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">0.632</td>\n<td id=\"S5.T2.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">0.288</td>\n<td id=\"S5.T2.1.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">3.343</td>\n</tr>\n<tr id=\"S5.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\">Pythia + IQ + Knob</th>\n<td id=\"S5.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.3.2.2.1\" class=\"ltx_text ltx_font_bold\">0.785</span></td>\n<td id=\"S5.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\">0.715</span></td>\n<td id=\"S5.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">0.647</span></td>\n<td id=\"S5.T2.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.3.2.5.1\" class=\"ltx_text ltx_font_bold\">0.581</span></td>\n<td id=\"S5.T2.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.3.2.6.1\" class=\"ltx_text ltx_font_bold\">0.795</span></td>\n<td id=\"S5.T2.1.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.3.2.7.1\" class=\"ltx_text ltx_font_bold\">0.409</span></td>\n<td id=\"S5.T2.1.3.2.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:2.5pt;padding-bottom:2.5pt;\"><span id=\"S5.T2.1.3.2.8.1\" class=\"ltx_text ltx_font_bold\">5.263</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "We train our implication generator on the rule-based training dataset and evaluate our module on rule-based validation split. We use common question generator metrics such as BLEU [13], ROUGE-L [11], METEOR [4] and CIDEr [22] scores for evaluation. We also demonstrate the importance of using the knob mechanism instead of an implied answer as input to the module. Table 2 shows the results of the implication generator module."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Attention map analysis. Logeq (Rephrasing) denotes the mean Euclidean distance between attention maps of original question and Logeq (Rephrasing). Models trained with our approach produce better results highlighting stronger multi-modal understanding.",
        "table": "<table id=\"S5.T3.2.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.2.2.3.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.2.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\" rowspan=\"2\"><span id=\"S5.T3.2.2.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<td id=\"S5.T3.2.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T3.2.2.3.1.2.1\" class=\"ltx_text ltx_font_bold\">Logeq</span></td>\n<td id=\"S5.T3.2.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T3.2.2.3.1.3.1\" class=\"ltx_text ltx_font_bold\">Rephrasing</span></td>\n</tr>\n<tr id=\"S5.T3.2.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">(<math id=\"S5.T3.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\times 10^{-4}\" display=\"inline\"><semantics id=\"S5.T3.1.1.1.1.1.m1.1a\"><mrow id=\"S5.T3.1.1.1.1.1.m1.1.1\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"S5.T3.1.1.1.1.1.m1.1.1.2\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.2.cmml\"></mi><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S5.T3.1.1.1.1.1.m1.1.1.1\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.1.cmml\">×</mo><msup id=\"S5.T3.1.1.1.1.1.m1.1.1.3\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3.cmml\"><mn id=\"S5.T3.1.1.1.1.1.m1.1.1.3.2\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3.2.cmml\">10</mn><mrow id=\"S5.T3.1.1.1.1.1.m1.1.1.3.3\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3.3.cmml\"><mo id=\"S5.T3.1.1.1.1.1.m1.1.1.3.3a\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3.3.cmml\">−</mo><mn id=\"S5.T3.1.1.1.1.1.m1.1.1.3.3.2\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3.3.2.cmml\">4</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.1.1.1.1.1.m1.1b\"><apply id=\"S5.T3.1.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T3.1.1.1.1.1.m1.1.1\"><times id=\"S5.T3.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.1\"></times><csymbol cd=\"latexml\" id=\"S5.T3.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.2\">absent</csymbol><apply id=\"S5.T3.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S5.T3.1.1.1.1.1.m1.1.1.3.1.cmml\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3\">superscript</csymbol><cn type=\"integer\" id=\"S5.T3.1.1.1.1.1.m1.1.1.3.2.cmml\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3.2\">10</cn><apply id=\"S5.T3.1.1.1.1.1.m1.1.1.3.3.cmml\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3.3\"><minus id=\"S5.T3.1.1.1.1.1.m1.1.1.3.3.1.cmml\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3.3\"></minus><cn type=\"integer\" id=\"S5.T3.1.1.1.1.1.m1.1.1.3.3.2.cmml\" xref=\"S5.T3.1.1.1.1.1.m1.1.1.3.3.2\">4</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.1.1.1.1.1.m1.1c\">\\times 10^{-4}</annotation></semantics></math>)</span></td>\n<td id=\"S5.T3.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T3.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">(<math id=\"S5.T3.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\times 10^{-4}\" display=\"inline\"><semantics id=\"S5.T3.2.2.2.2.1.m1.1a\"><mrow id=\"S5.T3.2.2.2.2.1.m1.1.1\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.cmml\"><mi id=\"S5.T3.2.2.2.2.1.m1.1.1.2\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.2.cmml\"></mi><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S5.T3.2.2.2.2.1.m1.1.1.1\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.1.cmml\">×</mo><msup id=\"S5.T3.2.2.2.2.1.m1.1.1.3\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3.cmml\"><mn id=\"S5.T3.2.2.2.2.1.m1.1.1.3.2\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3.2.cmml\">10</mn><mrow id=\"S5.T3.2.2.2.2.1.m1.1.1.3.3\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3.3.cmml\"><mo id=\"S5.T3.2.2.2.2.1.m1.1.1.3.3a\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3.3.cmml\">−</mo><mn id=\"S5.T3.2.2.2.2.1.m1.1.1.3.3.2\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3.3.2.cmml\">4</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.2.2.2.2.1.m1.1b\"><apply id=\"S5.T3.2.2.2.2.1.m1.1.1.cmml\" xref=\"S5.T3.2.2.2.2.1.m1.1.1\"><times id=\"S5.T3.2.2.2.2.1.m1.1.1.1.cmml\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.1\"></times><csymbol cd=\"latexml\" id=\"S5.T3.2.2.2.2.1.m1.1.1.2.cmml\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.2\">absent</csymbol><apply id=\"S5.T3.2.2.2.2.1.m1.1.1.3.cmml\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S5.T3.2.2.2.2.1.m1.1.1.3.1.cmml\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3\">superscript</csymbol><cn type=\"integer\" id=\"S5.T3.2.2.2.2.1.m1.1.1.3.2.cmml\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3.2\">10</cn><apply id=\"S5.T3.2.2.2.2.1.m1.1.1.3.3.cmml\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3.3\"><minus id=\"S5.T3.2.2.2.2.1.m1.1.1.3.3.1.cmml\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3.3\"></minus><cn type=\"integer\" id=\"S5.T3.2.2.2.2.1.m1.1.1.3.3.2.cmml\" xref=\"S5.T3.2.2.2.2.1.m1.1.1.3.3.2\">4</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.2.2.2.2.1.m1.1c\">\\times 10^{-4}</annotation></semantics></math>)</span></td>\n</tr>\n<tr id=\"S5.T3.2.2.4.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.2.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">BUTD <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\">2</a>]</cite>\n</th>\n<td id=\"S5.T3.2.2.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">31.72</td>\n<td id=\"S5.T3.2.2.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">15.51</td>\n</tr>\n<tr id=\"S5.T3.2.2.5.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.2.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\" style=\"padding-top:1pt;padding-bottom:1pt;\">BUTD + IQ <span id=\"S5.T3.2.2.5.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(ours)</span>\n</th>\n<td id=\"S5.T3.2.2.5.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T3.2.2.5.3.2.1\" class=\"ltx_text ltx_font_bold\">26.73</span></td>\n<td id=\"S5.T3.2.2.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T3.2.2.5.3.3.1\" class=\"ltx_text ltx_font_bold\">13.88</span></td>\n</tr>\n<tr id=\"S5.T3.2.2.6.4\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.2.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">BAN <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">7</a>]</cite>\n</th>\n<td id=\"S5.T3.2.2.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">8.09</td>\n<td id=\"S5.T3.2.2.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">5.03</td>\n</tr>\n<tr id=\"S5.T3.2.2.7.5\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.2.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\" style=\"padding-top:1pt;padding-bottom:1pt;\">BAN + IQ <span id=\"S5.T3.2.2.7.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(ours)</span>\n</th>\n<td id=\"S5.T3.2.2.7.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T3.2.2.7.5.2.1\" class=\"ltx_text ltx_font_bold\">5.41</span></td>\n<td id=\"S5.T3.2.2.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T3.2.2.7.5.3.1\" class=\"ltx_text ltx_font_bold\">3.64</span></td>\n</tr>\n<tr id=\"S5.T3.2.2.8.6\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.2.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Pythia <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">24</a>]</cite>\n</th>\n<td id=\"S5.T3.2.2.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">11.41</td>\n<td id=\"S5.T3.2.2.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">5.40</td>\n</tr>\n<tr id=\"S5.T3.2.2.9.7\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.2.9.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l\" style=\"padding-top:1pt;padding-bottom:1pt;\">Pythia + IQ <span id=\"S5.T3.2.2.9.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(ours)</span>\n</th>\n<td id=\"S5.T3.2.2.9.7.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T3.2.2.9.7.2.1\" class=\"ltx_text ltx_font_bold\">5.83</span></td>\n<td id=\"S5.T3.2.2.9.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T3.2.2.9.7.3.1\" class=\"ltx_text ltx_font_bold\">3.37</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "To ensure appropriate visual grounding, we believe that the model should look at same regions as original question for logically equivalent and rephrased questions. As a quantitative comparison, we compute the mean Euclidean distance between attention weights for logically equivalent (Logeq) and rephrased questions with their respective original question. Table 3 shows that models trained with our approach tend to focus on same regions to answer the original question, its rephrasing and its logical equivalent counterpart. These analysis show that multi-modal understanding of vision and language is enhanced using our approach."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Consistency comparison of data augmentation vs our approach. VQA-Imp denotes our VQA-Implications dataset and DA stands for models finetuned on rule-based training implications. Even though our models lack on rule-based dataset, they consistently outperform their respective baselines on the VQA-Implication dataset.",
        "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_rule\" style=\"width:0.0pt;height:15.0pt;background:black;display:inline-block;\"></span><span id=\"S5.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span>\n</th>\n<td id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;\">\n<span id=\"S5.T4.1.1.1.2.1\" class=\"ltx_ERROR undefined\">\\pbox</span>20cm<span id=\"S5.T4.1.1.1.2.2\" class=\"ltx_text ltx_font_bold\">Consistency</span>\n</td>\n<td id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_border_t\" style=\"padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;\"></td>\n</tr>\n<tr id=\"S5.T4.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\" style=\"padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T4.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">(rule-based)</span></th>\n<td id=\"S5.T4.1.2.2.2\" class=\"ltx_td ltx_align_right\" style=\"padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;\">\n<span id=\"S5.T4.1.2.2.2.1\" class=\"ltx_ERROR undefined\">\\pbox</span>20cm<span id=\"S5.T4.1.2.2.2.2\" class=\"ltx_text ltx_font_bold\">Consistency</span>\n</td>\n<td id=\"S5.T4.1.2.2.3\" class=\"ltx_td\" style=\"padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;\"></td>\n</tr>\n<tr id=\"S5.T4.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.3.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_l\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T4.1.3.3.1.1\" class=\"ltx_text ltx_font_bold\">(VQA-Imp)</span></th>\n<td id=\"S5.T4.1.3.3.2\" class=\"ltx_td\" style=\"padding-top:1pt;padding-bottom:1pt;\"></td>\n<td id=\"S5.T4.1.3.3.3\" class=\"ltx_td\" style=\"padding-top:1pt;padding-bottom:1pt;\"></td>\n</tr>\n<tr id=\"S5.T4.1.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">BUTD + DA</th>\n<td id=\"S5.T4.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T4.1.4.4.2.1\" class=\"ltx_text ltx_font_bold\">93.1</span></td>\n<td id=\"S5.T4.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.24</td>\n</tr>\n<tr id=\"S5.T4.1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\" style=\"padding-top:1pt;padding-bottom:1pt;\">BUTD + IQ <span id=\"S5.T4.1.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(ours)</span>\n</th>\n<td id=\"S5.T4.1.5.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\">88.1</td>\n<td id=\"S5.T4.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T4.1.5.5.3.1\" class=\"ltx_text ltx_font_bold\">74.38</span></td>\n</tr>\n<tr id=\"S5.T4.1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">BAN + DA</th>\n<td id=\"S5.T4.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">87.6</td>\n<td id=\"S5.T4.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">74.33</td>\n</tr>\n<tr id=\"S5.T4.1.7.7\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\" style=\"padding-top:1pt;padding-bottom:1pt;\">BAN + IQ <span id=\"S5.T4.1.7.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(ours)</span>\n</th>\n<td id=\"S5.T4.1.7.7.2\" class=\"ltx_td ltx_align_center\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T4.1.7.7.2.1\" class=\"ltx_text ltx_font_bold\">89.6</span></td>\n<td id=\"S5.T4.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T4.1.7.7.3.1\" class=\"ltx_text ltx_font_bold\">74.61</span></td>\n</tr>\n<tr id=\"S5.T4.1.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Pythia + DA</th>\n<td id=\"S5.T4.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T4.1.8.8.2.1\" class=\"ltx_text ltx_font_bold\">89.7</span></td>\n<td id=\"S5.T4.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">76.19</td>\n</tr>\n<tr id=\"S5.T4.1.9.9\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l\" style=\"padding-top:1pt;padding-bottom:1pt;\">Pythia + IQ <span id=\"S5.T4.1.9.9.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(ours)</span>\n</th>\n<td id=\"S5.T4.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-top:1pt;padding-bottom:1pt;\">88.7</td>\n<td id=\"S5.T4.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"S5.T4.1.9.9.3.1\" class=\"ltx_text ltx_font_bold\">76.55</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Since we are using an extra dataset (rule-based implications) in addition to VQA v2.0 to train our models, we also compare our models’ consistency with models finetuned using data augmentation. Table 4 summarizes these results. Better performance of our models on the human annotated VQA-Implications dataset shows that models trained with our approach generalize better and hence would do better than data augmentation in the outside world."
        ]
    }
}