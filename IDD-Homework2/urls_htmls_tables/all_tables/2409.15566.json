{
    "id_table_1": {
        "caption": "TABLE I:  Results on the QuALITY dev dataset for all embedding, LLM and RAG pairs.",
        "table": "S3.T1.1",
        "footnotes": [],
        "references": [
            "Motivated by human cognition, we propose Graphical Eigen Memories For Retrieval Augmented Generation (GEM-RAG). Given a corpus of text, our method splits the text into chunks and then generates several relevant utility questions using an LLM. The embeddings of these utility questions help build a complete weighted graph, where the weight between two nodes is the similarity of the utility questions. With this memory graph, and motivated by the observation that humans tend to synthesize information that is often retrieved together, we perform a random-walk analysis on the graph, by using the spectral decomposition of the normalized graph Laplacian. The intuition is that the eigenvectors of this decomposition provides an understanding of the key orthogonal themes present in the passage, by providing the different modes based on memory node similarity. We use the top components of important eigenvectors to then produce eigenthemes or summary nodes, which capture the higher-level structure of the text. This synthesized graph constitutes the graphical eigen memory, or GEM. At retrieval time, we find the most similar utility question to the prompt/question, and then perform best first search on the GEM, to retrieve a sub-graph containing the context chunks ultimately passed to the LLM. A schematic of our method can be seen in Figure  1 .",
            "Our method at a high level involves several steps to first construct the graph, by chunking the text, generating utility questions, building the initial graph, and finally using the eigenvectors from spectral decomposition of normalized graph Laplacian to build the summary nodes. Then, with the GEM produced, we show how it can be used to perform RAG. The specifics of our implementation are discussed in the experiments section. A schematic of our method can be seen in Figure  1 .",
            "Given a built GEM, our method is then ready to answer prompts/question about the given dataset. The process works as follows, given a prompt/question  p p p italic_p , and some budget  B B \\mathcal{B} caligraphic_B  of nodes to return, we first produce an embedding of the prompt to give  v p = E  ( p ) subscript v p E p v_{p}=E(p) italic_v start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT = italic_E ( italic_p ) . We then find, out of the entire graph, the utility question that has the highest  SIM SIM \\mathtt{SIM} typewriter_SIM . Specifically, let  Q = { q 1 , q 2 , ... , q n } Q subscript q 1 subscript q 2 ... subscript q n \\mathcal{Q}=\\{q_{1},q_{2},\\ldots,q_{n}\\} caligraphic_Q = { italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }  be the set of all utility questions, find  q  = argmax q  Q  SIM  ( v p , E  ( q ) ) superscript q q Q argmax SIM subscript v p E q q^{*}=\\underset{q\\in\\mathcal{Q}}{\\mathrm{argmax}}\\,\\mathtt{SIM}(v_{p},E(q)) italic_q start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT = start_UNDERACCENT italic_q  caligraphic_Q end_UNDERACCENT start_ARG roman_argmax end_ARG typewriter_SIM ( italic_v start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_E ( italic_q ) ) .  Then, from the associated node with  q  superscript q q^{*} italic_q start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  we perform a best first search, to find the next nodes, up to  B B \\mathcal{B} caligraphic_B  to include in the context set. Once we reach the budget we return the context. The full details can be seen in Algorithm  1 ."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Results on the Qasper data set for all embedding, LLM and RAG pairs.",
        "table": "S4.T2.1",
        "footnotes": [],
        "references": [
            "Ablation Study   In order to test the tuneable hyperparameters of our model, the number of eigencomponents and the number of utility questions, we performed three ablation experiments, the results of which can be seen in Figure  2 . In the first we keep the number of components constant at ten, and vary the number of utility questions. We observe that the accuracy with respect to the number of utility questions increased up until three, but quickly becomes saturated. Zero utility questions indicates that we just compare the embedding of each text chunk directly. Conversely, for the second plot, we hold the number of utility questions at five, and vary the number of eigencompnents. Here we observe the actual best performance is with two components."
        ]
    },
    "id_table_3": {
        "caption": "TABLE III:  Percent of returned nodes that are eigen/summary nodes.",
        "table": "S4.T3.1",
        "footnotes": [],
        "references": []
    },
    "global_footnotes": []
}