{
    "id_table_1": {
        "caption": "Table 1:  Material knowledge as background prompts: synthesis condition definition and numerical/textual/structural constraints.",
        "table": "S2.T2.1",
        "footnotes": [],
        "references": [
            "In this work, we set out to overcome the notable limitations when applying primitive zero-shot LLMs to the problem of MOFs synthesis condition extraction from scientific texts. The main theme of this paper is to introduce the few-shot in-context learning paradigm as the standard approach to augment general-purpose LLMs on the material synthesis condition extraction problem. As shown by our experiment results of Figure  1 , in a dataset randomly sampled from 84,898 well-defined MOFs, the proposed few-shot method achieves much higher average F1 performance (0.93 vs. 0.81, +14.8%) than the native zero-shot LLMs, both using the state-of-the-art GPT-4 Turbo model    The latest GPT-4v model has enhanced video and image analysis capability, but not for text analysis.   [ 1 ] , as shown in Figure  1 .",
            "As shown in our technology pipeline of Figure  2 , the MOFs literature dataset are first collected and pre-processed into compatible input format for LLMs (see Sec.  5.1  for details). The latest high-performance LLM (i.e., GPT-4) is employed to extract 10 essential conditions for the synthesis of each MOF: metal precursor name & amount, organic linker name & amount, solvent name & amount, modulator name & amount, and synthesis reaction duration & temperature. The synthesis extraction result is first evaluated on their literal accuracy with respect to an expert-curated ground-truth dataset, and then tested on the real-world scenarios of material structure inference and design. On the randomly sampled 123 MOFs synthesis literature from all the 36177 MOFs, the extraction of 1230 synthesis conditions using the proposed few-shot LLM model achieves a best average F1 metric of 0.93 (ACC = 0.90), using a few-shot demonstration of only 4 examples. The full performance result is illustrated in Figure  1 (a), in comparison to the baseline zero-shot approach with an average F1 of 0.81 (ACC = 0.77) in Figure  1 (b). The dataset statistics is listed in Figure  4 .",
            "Here we note that the F1 and ACC (overall accuracy) metrics used follow the standard definition computed from TP (true positive), FP (false positive), TN (true negative), FN (false negative), throughout this work. The LLM output on each synthesis condition of a MOF will be classified into one of TP/FP/TN/FN by comparing with the predefined ground-truth annotation, as described in the confusion matrix of Figure  1 (c). Note that our definition is different from the previous research in Zheng et al.  [ 24 ]  where the TP/FP/TN/FN classification is evaluated by human experts case by case. We argue that the subjective human evaluation may introduce bias while the fully objective classification will ensure a consistent format in retrieved synthesis conditions, which is beneficial for the follow-up material applications (see Sec.  5.3  for more details).",
            "The details of newly introduced MOFs synthesis definitions and constraints as background prompts are listed in Table  1 . Notably, we summarize three types of constraints on synthesis conditions:  numerical  that the value of a condition should fall into certain range according to prior knowledge,  textual  that an extracted condition by text should adhere to certain format to speedup follow-up material application, and  structural  that certain rules related to the condition are followed in all MOFs synthesis process.",
            "To train the machine learning model for synthesis paragraph detection, we first annotate a dataset of 440 papers randomly sampled from the large dataset of Sec.  5.1 . Details can be accessed in Sec.  5.2 . Finally, this process yields 1,349 synthesis paragraphs as positive samples. To train the classifier, negative samples by non-synthesis paragraphs are obtained after removing all annotated paragraphs from a paper, leading to 11,783 negative samples. We employed the standard BERT model, specifically the pre-trained  bert-base-uncased  model from HuggingFace, for training. The training and validation processes utilized a 5-fold cross-validation method. Given the imbalance dataset, we used stratified 5-fold cross-validation to ensure that the ratio of positive to negative samples remained consistent in each split. The final classification performance is quite high, with an ACC of 0.989, precision of 0.955, recall of 0.947, and F1 = 0.951.",
            "The evaluation data is a subset of the CSD database  [ 14 ] , which encompasses 5269 MOFs. As detailed in Sec.  5.1 , these MOFs are carefully selected so that each MOF is described by only one scientific literature and the literature will only have one synthesis paragraph. The resulting dataset ensures the validity of evaluation by exact correspondence between a MOFs microscopic structure and its extracted synthesis conditions.",
            "Using the few-shot/zero-shot LLMs and other benchmark methods, the 10 synthesis conditions under study are extracted from a unique synthesis paragraph linked to each of the 5269 MOFs. The raw textual conditions extracted are post-processed to improve data quality, such as synonym merging and standardization of temperature/time scales (Sec.  5.3 ). On the LLM output by the few-shot method, the top 100, 135, and 20 precursor names of metals, linkers, and solvents are selected, which leads to a smaller dataset of 800 MOFs. On the LLM by zero-shot method, the distribution of conditions are less longer-tailed, so that a stricter filter is applied to obtain the same number of 800 MOFs. These precursor names are embedded into one length-198 feature vector by the methods in Sec.  5.3 , where serves as the input features in the material inference task. The target outcome variables are the four microstructure property of a MOF. Their calculation procedure is described in Sec.  5.1 .",
            "Next, the PDF of each MOF is converted to plain text  [ 20 ]  and segmented into paragraphs. The high performance classification model in Sec.  3.1  is applied to detect synthesis paragraphs enclosing the desired synthesis condition information. Again, for the sake of convenience and accuracy, we only consider the 5,269 MOFs/publications that contain exactly one synthesis paragraph. Another 12,606 publications do not have any synthesis paragraph, probably because these papers are not related to MOFs experiments. The other 4,586 publications have more than one synthesis paragraphs, as they are describing multiple MOFs or synthesis routes. Our pipeline could work with papers having more than one suite of synthesis conditions, but the potential MOF-synthesis mismatch may downgrade the application performance in evaluation. Therefore, throughout this work we stick to the core dataset of 5,269 MOFs/publications and their unique synthesis paragraph.",
            "We randomly selected 200 papers from the paper database constructed in  5.1 , with each paper only contains less than 3 MOFs IDs. The annotation process can be divided into five sections: task configuration, GPT pre-extraction annotation, pilot annotation, batch annotation, and data curation.",
            "After data cleansing and standardization, the distribution of different synthesis conditions becomes more centralized. As shown in Figure  10 , the entity lists of both metal source and solvent are shortened. The number of unique organic linkers remains high due to its long-tailed distribution. In the application of MOFs microstructure property inference, we will only select these MOFs synthesized by top entities in metal source, organic linker, and solvent. For example, by default we apply a filter of (100, 135, 20), which select the MOFs having top-100 metal source in the ranked list of Figure  10 (a), top-135 organic linker, and top-20 solvent. Note that for LLM models in comparison, different filters may be applied to ensure the same number of MOFs in the dataset.",
            "To streamline the entire workflow and efficiently organize the extraction results from related papers, we developed the Visual MOFs Synthesis Extraction Engine and Database.  Using our approach, we processed over 30,000 papers and extracted 57,081 synthesis paragraphs, on which we then performed synthesis condition extraction. To better view and analyze the vast amount of extraction results, we built a comprehensive database with 2 features: 1) Basic Statistics: The database provides basic statistics on all extraction results, including data on synthesis paragraphs and various synthesis conditions (Figure  11 ). 2) Advanced Search Capabilities: This database is designed to support logical expression searches for specific fields, allowing users to search for synthesis conditions, paper titles, and synthesis paragraph content with precision, and enables visualization of the retrieval results.",
            "The visualization system we designed can support users in analyzing synthesis paragraphs. Initially, users upload batch PDF papers and process through the LLM. Once extraction is complete, users can utilize the filtering panel to select specific paragraphs for analysis. The overall performance panel (Fig. 12 (a)) then displays four key performance metrics of the LLM resolution, with a default HeatMap (Fig. 12 (b).I) providing a detailed view of entity resolution performance across all evaluation metrics. Suppose further detail on specific metrics is needed. In that case, users can access the second tab (Fig. 12 (b).II), sliding down to the relevant rows to view the distribution of paragraph performance across various parameters in bar charts. To explore similarities with other paragraphs in the database, users can switch to the third tab (Fig. 12 (b).III). Here, red dots indicate newly extracted paragraphs; users can look for nearby black dots representing similar paragraphs in the database to compare specific composite parameters. Should users decide to replace or re-examine certain paragraphs, they can reselect them in the filtering panel (Fig. 12 (c)). This action triggers an automatic update of the corresponding performance metrics and visual charts, allowing users to repeat the analysis as needed."
        ]
    },
    "global_footnotes": [
        "The latest GPT-4v model has enhanced video and image analysis capability, but not for text analysis."
    ]
}