{
    "PAPER'S NUMBER OF TABLES": 3,
    "S3.T1": {
        "caption": "Table 1: Datasets properties",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Dataset</th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Clients</th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Data Samples</th>\n<th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Activities</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">UCI</th>\n<th id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">5</th>\n<td id=\"S3.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10,299</td>\n<td id=\"S3.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">6 (ST,SD,W,U,D,L)</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">HHAR</th>\n<th id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">51</th>\n<td id=\"S3.T1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">85,567</td>\n<td id=\"S3.T1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">6 (ST,SD,W,U,D,BK)</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">REALWORLD</th>\n<th id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">15</th>\n<td id=\"S3.T1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">356,427</td>\n<td id=\"S3.T1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">8 (ST,SD,W,U,D,J,L,R)</td>\n</tr>\n<tr id=\"S3.T1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\">SHL</th>\n<th id=\"S3.T1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\">9</th>\n<td id=\"S3.T1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">640,144</td>\n<td id=\"S3.T1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">8 (ST,W,R,BK,C,BS,T,SW)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In order to best replicate a realistic non-iid environment, where system and statistical heterogeneity along with class/data imbalance plays a large role between clients, we combined four different publicly available datasets to have 80 diverse clients. We selected the following datasets: the UCI dataset [12] – the standard benchmark dataset in the HAR community – which, in our experiments, represents five homogeneous clients, the Heterogeneity Human Activity Recognition (HHAR) dataset [13] which comprises 51 heterogeneous clients, the REALWORLD dataset [14] – a large dataset with a high diversity of device positioning – which adds 15 clients and finally the very large Sussex-Huawei Locomotion (SHL) dataset [15] that adds further nine clients. Each dataset brings sets of clients with unique properties to the combined dataset. More so, each of the datasets has its own set of activities, as shown in table 1 with only some overlapping. The combined dataset deals with a total of 13 unique activities: Walk (W), Upstairs (U), Downstairs (D), Sit (ST), Stand (SD), Lay (L), Jump (J), Run (R), Bike (BK), Car (C), Bus (BS), Train (T), Subway (SW). In terms of class distribution, shown in figure 2, “Jump” is the minority class while there is a large number of samples for the “Stand” and “Walk” classes."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: The performance of experiments on the combined datasets",
        "table": "<table id=\"S4.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\" rowspan=\"2\"><span id=\"S4.T2.1.1.1.1.1.1\" class=\"ltx_text\">Learning Method</span></th>\n<th id=\"S4.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" colspan=\"5\">Datasets (Macro F-score)</th>\n</tr>\n<tr id=\"S4.T2.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\">Combined</th>\n<td id=\"S4.T2.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">UCI</td>\n<td id=\"S4.T2.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">HHAR</td>\n<td id=\"S4.T2.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">REALWORLD</td>\n<td id=\"S4.T2.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SHL</td>\n</tr>\n<tr id=\"S4.T2.1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">FL + Autoencoder</th>\n<th id=\"S4.T2.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\">71.29</th>\n<td id=\"S4.T2.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">73.51</td>\n<td id=\"S4.T2.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">82.84</td>\n<td id=\"S4.T2.1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.3.3.5.1\" class=\"ltx_text ltx_font_bold\">77.98</span></td>\n<td id=\"S4.T2.1.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">68.81</td>\n</tr>\n<tr id=\"S4.T2.1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Conventional</th>\n<th id=\"S4.T2.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S4.T2.1.1.4.4.2.1\" class=\"ltx_text ltx_font_bold\">71.96</span></th>\n<td id=\"S4.T2.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.4.4.3.1\" class=\"ltx_text ltx_font_bold\">78.92</span></td>\n<td id=\"S4.T2.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.4.4.4.1\" class=\"ltx_text ltx_font_bold\">82.92</span></td>\n<td id=\"S4.T2.1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">76.84</td>\n<td id=\"S4.T2.1.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.4.4.6.1\" class=\"ltx_text ltx_font_bold\">70.44</span></td>\n</tr>\n<tr id=\"S4.T2.1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr\">Conventional + Autoencoder</th>\n<th id=\"S4.T2.1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_rr\">69.04</th>\n<td id=\"S4.T2.1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">73.06</td>\n<td id=\"S4.T2.1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">78.58</td>\n<td id=\"S4.T2.1.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">75.48</td>\n<td id=\"S4.T2.1.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">66.52</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The overall results of the study are reported in Table 2.\nThe AE learned using the FL method (FL+AE) exhibits an F-score of 71.29% on the combined test sets. On the classifier using conventional learning – which consisted in classical centralized supervised learning on the labeled data only. The conventional approach shows an F-score of 71.96% on the combined test sets. It seems thus that either the FL learning or the AE are not able to benefit from the large set of unlabeled data. When the AE is trained in a centralized way (Conventional + AutoEncoder), no improvement on the combined dataset is observed (69.04%) while there is instead a slight decrease. It seems thus that the AE does not learn a representation helpful for the classification task.",
            "Second, collaborative feature learning, as we have done by training the AE using FedAvg, presents an orientation and scaling issue when the server model is aggregated. Given the same data samples to multiple client models that have just finished local training to embed/project the data into their respective latent space, we would see that the projections across all the clients would be different. The problem has been well raised in [5] and the study shows that a global set of rules of directions are needed in order to aggregate a suitable feature extractor that represents all client’s data. The aggregation by FedAvg as done in our experiments, however, is a naive approach [8, 19] and does not handle the mentioned problems. As shown in Figure 7 where the T-SNE dimensions reduced embeddings of the different classes are mostly intertwined with each other without distinct separations. The aggregation method would thus require more complex policies to properly merge the learned feature extractors of all the 80 clients in this study, favorably an aggregator that would preserve specialization and increase generalization.\nOn the other hand, the AE architecture is lightweight but very much decrepit. This claim can be further supported by the results seen in table 2, where the conventional approach was able to outperform the conventional with AE approach. The feature-learning done with the AE is an expensive training process, in both the federated and conventional means, yet did not bring improvements. This lacking thus calls for newer feature learning architectures such as CPC [22], SimCLR [23], and Moco [24] which has exhibited improved feature extraction and may be the route for improved performance if hardware constraints are properly taken into account."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Average storage footprint of local data and model",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Dataset/Model</th>\n<th id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Size (MBs)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">UCI</th>\n<td id=\"S4.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"> 3.87</td>\n</tr>\n<tr id=\"S4.T3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">HHAR</th>\n<td id=\"S4.T3.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"> 3.15</td>\n</tr>\n<tr id=\"S4.T3.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">REALWORLD</th>\n<td id=\"S4.T3.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\"> 89.11</td>\n</tr>\n<tr id=\"S4.T3.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">SHL</th>\n<td id=\"S4.T3.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\"> 266.73</td>\n</tr>\n<tr id=\"S4.T3.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Autoencoder</th>\n<td id=\"S4.T3.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"> 0.38</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Details relating to memory footprint, where the data are stored in an HDF5 format[17], is shown in table 3 where the average local data size of clients from the four different datasets vary significantly. Specifically, clients of UCI and HHAR contains around 3MB of data on average, while clients of REALWORLD have an average of 89.11 MBs, and SHL clients have an average size of 266.73 MBs. On the other hand, the communicated AE has a size of 0.38 MBs. Thus, we can establish that the communication cost for each client after 200 rounds of training in FL would be 76 MBs."
        ]
    }
}