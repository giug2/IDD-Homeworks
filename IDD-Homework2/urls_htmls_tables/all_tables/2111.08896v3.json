{
    "S3.T1": {
        "caption": "Table 1: VQA Data Statistics.",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"></th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Images</th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Questions</th>\n<th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Yes/No</th>\n<th id=\"S3.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Number</th>\n<th id=\"S3.T1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\">Other</th>\n<th id=\"S3.T1.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Answers</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Training</th>\n<th id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">80K</th>\n<td id=\"S3.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">443K</td>\n<td id=\"S3.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">169K</td>\n<td id=\"S3.T1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">58K</td>\n<td id=\"S3.T1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">219K</td>\n<td id=\"S3.T1.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">4.4M</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">Validation</th>\n<th id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">40K</th>\n<td id=\"S3.T1.1.3.2.3\" class=\"ltx_td ltx_align_center\">214K</td>\n<td id=\"S3.T1.1.3.2.4\" class=\"ltx_td ltx_align_center\">81K</td>\n<td id=\"S3.T1.1.3.2.5\" class=\"ltx_td ltx_align_center\">28K</td>\n<td id=\"S3.T1.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\">106K</td>\n<td id=\"S3.T1.1.3.2.7\" class=\"ltx_td ltx_align_center\">2.1M</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\">Test</th>\n<th id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\">80K</th>\n<td id=\"S3.T1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">447K</td>\n<td id=\"S3.T1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">-</td>\n<td id=\"S3.T1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">-</td>\n<td id=\"S3.T1.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">-</td>\n<td id=\"S3.T1.1.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">-</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Visual Question Answering (VQA) is a dataset containing open-ended questions about images (Antol et al., 2015). These questions require understanding of vision, language and commonsense knowledge to answer. It contains a large number of labeled question-image-answer triplets with 10 human annotators for each question. The detailed statistics for VQA training/validation/test data splits is shown in Table 1.",
            "The ablation study of MoE is shown in Table 10. With only visual understanding expert, the model gives a strong performance of accuracy 80.05 on the VQA Test-dev set. Adding text reading expert increases the overall performance by more than 1%, which already achieves human parity of 80.83. Adding clock reading expert further boosts the performance to 81.27, where the performance on the “Number” type increases by more than 4%. The gating network of MoE mimics human who is able to identify domain experts based on the nature of tasks. This knowledge-guided MoE framework can also be easily extended to incorporate more specialized experts for continual self-evolution.",
            "A comparative study of AliceMind-MMU and human on visual question answering has been conducted. Table 11 and Table 12 show the overall and per-category performance of AliceMind-MMU and human on the val split, respectively, from which there are the following observations:\n(i) AliceMind-MMU outperforms human annotators on the two largest categories, Commonsense Knowledge and Relational Reasoning. It shows AliceMind-MMU ’s superiority of identifying common scene objects in daily life and leveraging commonsense knowledge such as colors and weathers. This result also demonstrates the power of AliceMind-MMU in reasoning over relative positions, such as the left sign on a wall, to answer a spatial reasoning question. Besides, it is surprising that AliceMind-MMU can reason over simple comparison, such as which object is the tallest.\n(ii) The questions in the Object Counting category seem rather difficult for AliceMind-MMU to answer. AliceMind-MMU is found to be good at counting a small number (<10) of objects. It would give an incorrect count when encountering a large number of small objects and/or requiring reasoning over them.\n(iii) AliceMind-MMU significantly surpasses human performance on Visual Recognition which requires specialized knowledge. It is expected that AliceMind-MMU , as a machine learner trained with large data, is skilled in memorizing specialized/professional knowledge with visual recognition, compared with non-professional human annotators.\n(iv) AliceMind-MMU is more capable of reading time shown in a clock than human, as demonstrated by the result of Clock Reading. On text reading, however, there is still a big gap between AliceMind-MMU and human in recognizing and understanding text in an image, as shown by the result of Textual Recognition. Some research progress has been made on text-reading VQA tasks, such as TextVQA (Singh et al., 2019)."
        ]
    },
    "S3.T2": {
        "caption": "Table 2:  Text-reading VQA Data Statistics.",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Images</span></th>\n<th id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Questions</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">VQA-Subset</th>\n<td id=\"S3.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">20k</td>\n<td id=\"S3.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">21k</td>\n</tr>\n<tr id=\"S3.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">TextVQA</th>\n<td id=\"S3.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">25k</td>\n<td id=\"S3.T2.1.3.2.3\" class=\"ltx_td ltx_align_center\">39k</td>\n</tr>\n<tr id=\"S3.T2.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">ST-VQA</th>\n<td id=\"S3.T2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">19k</td>\n<td id=\"S3.T2.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">26k</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "For training Text Reading Expert, three text-reading VQA datasets is used including a subset of VQA data (Antol et al., 2015), TextVQA (Singh et al., 2019) and ST-VQA (Biten et al., 2019). A classification model is trained to extract text-reading samples from VQA data. The questions of TextVQA and ST-VQA are treated as positive samples, and the questions on images without text in VQA are treated as negative samples. The detailed statistics for the three text-reading VQA datasets is shown in Table 2."
        ]
    },
    "S3.T3": {
        "caption": "Table 3: VQA Challenge Leaderboard.",
        "table": "<table id=\"S3.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" colspan=\"5\">VQA Challenge Leaderboard (Test-std)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Models</th>\n<th id=\"S3.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Overall</th>\n<td id=\"S3.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Yes/No</td>\n<td id=\"S3.T3.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Number</td>\n<td id=\"S3.T3.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Other</td>\n</tr>\n<tr id=\"S3.T3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Human</th>\n<th id=\"S3.T3.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">80.83</th>\n<td id=\"S3.T3.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\">95.48</span></td>\n<td id=\"S3.T3.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">81.29</span></td>\n<td id=\"S3.T3.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">67.97</td>\n</tr>\n<tr id=\"S3.T3.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">LXMERT (<cite class=\"ltx_cite ltx_citemacro_cite\">Tan and Bansal (<a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">2019</a>)</cite>)</th>\n<th id=\"S3.T3.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">74.34</th>\n<td id=\"S3.T3.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">89.45</td>\n<td id=\"S3.T3.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">56.69</td>\n<td id=\"S3.T3.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">65.22</td>\n</tr>\n<tr id=\"S3.T3.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">MCAN (<cite class=\"ltx_cite ltx_citemacro_cite\">Yu et al. (<a href=\"#bib.bib53\" title=\"\" class=\"ltx_ref\">2019a</a>)</cite>)</th>\n<th id=\"S3.T3.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">75.23</th>\n<td id=\"S3.T3.1.5.4.3\" class=\"ltx_td ltx_align_center\">90.36</td>\n<td id=\"S3.T3.1.5.4.4\" class=\"ltx_td ltx_align_center\">59.17</td>\n<td id=\"S3.T3.1.5.4.5\" class=\"ltx_td ltx_align_center\">65.75</td>\n</tr>\n<tr id=\"S3.T3.1.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">VILLA (<cite class=\"ltx_cite ltx_citemacro_cite\">Gan et al. (<a href=\"#bib.bib54\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>)</th>\n<th id=\"S3.T3.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">75.85</th>\n<td id=\"S3.T3.1.6.5.3\" class=\"ltx_td ltx_align_center\">91.30</td>\n<td id=\"S3.T3.1.6.5.4\" class=\"ltx_td ltx_align_center\">59.23</td>\n<td id=\"S3.T3.1.6.5.5\" class=\"ltx_td ltx_align_center\">66.20</td>\n</tr>\n<tr id=\"S3.T3.1.7.6\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">BGN (<cite class=\"ltx_cite ltx_citemacro_cite\">Guo et al. (<a href=\"#bib.bib55\" title=\"\" class=\"ltx_ref\">2019</a>)</cite>)</th>\n<th id=\"S3.T3.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">75.92</th>\n<td id=\"S3.T3.1.7.6.3\" class=\"ltx_td ltx_align_center\">90.89</td>\n<td id=\"S3.T3.1.7.6.4\" class=\"ltx_td ltx_align_center\">61.13</td>\n<td id=\"S3.T3.1.7.6.5\" class=\"ltx_td ltx_align_center\">66.28</td>\n</tr>\n<tr id=\"S3.T3.1.8.7\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">InterBERT (<cite class=\"ltx_cite ltx_citemacro_cite\">Lin et al. (<a href=\"#bib.bib56\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>)</th>\n<th id=\"S3.T3.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">76.10</th>\n<td id=\"S3.T3.1.8.7.3\" class=\"ltx_td ltx_align_center\">91.67</td>\n<td id=\"S3.T3.1.8.7.4\" class=\"ltx_td ltx_align_center\">59.24</td>\n<td id=\"S3.T3.1.8.7.5\" class=\"ltx_td ltx_align_center\">66.40</td>\n</tr>\n<tr id=\"S3.T3.1.9.8\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">GridFeat+MoVie (<cite class=\"ltx_cite ltx_citemacro_cite\">Jiang et al. (<a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>)</th>\n<th id=\"S3.T3.1.9.8.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">76.29</th>\n<td id=\"S3.T3.1.9.8.3\" class=\"ltx_td ltx_align_center\">90.81</td>\n<td id=\"S3.T3.1.9.8.4\" class=\"ltx_td ltx_align_center\">61.53</td>\n<td id=\"S3.T3.1.9.8.5\" class=\"ltx_td ltx_align_center\">67.04</td>\n</tr>\n<tr id=\"S3.T3.1.10.9\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">VinVL (<cite class=\"ltx_cite ltx_citemacro_cite\">Zhang et al. (<a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>)</th>\n<th id=\"S3.T3.1.10.9.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">77.45</th>\n<td id=\"S3.T3.1.10.9.3\" class=\"ltx_td ltx_align_center\">92.38</td>\n<td id=\"S3.T3.1.10.9.4\" class=\"ltx_td ltx_align_center\">62.55</td>\n<td id=\"S3.T3.1.10.9.5\" class=\"ltx_td ltx_align_center\">67.87</td>\n</tr>\n<tr id=\"S3.T3.1.11.10\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.11.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">ROSITA (<cite class=\"ltx_cite ltx_citemacro_cite\">Cui et al. (<a href=\"#bib.bib57\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>)</th>\n<th id=\"S3.T3.1.11.10.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">78.34</th>\n<td id=\"S3.T3.1.11.10.3\" class=\"ltx_td ltx_align_center\">92.66</td>\n<td id=\"S3.T3.1.11.10.4\" class=\"ltx_td ltx_align_center\">63.24</td>\n<td id=\"S3.T3.1.11.10.5\" class=\"ltx_td ltx_align_center\">69.33</td>\n</tr>\n<tr id=\"S3.T3.1.12.11\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.12.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">UNIMO (<cite class=\"ltx_cite ltx_citemacro_cite\">Li et al. (<a href=\"#bib.bib58\" title=\"\" class=\"ltx_ref\">2020a</a>)</cite>)</th>\n<th id=\"S3.T3.1.12.11.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">78.40</th>\n<td id=\"S3.T3.1.12.11.3\" class=\"ltx_td ltx_align_center\">93.10</td>\n<td id=\"S3.T3.1.12.11.4\" class=\"ltx_td ltx_align_center\">63.06</td>\n<td id=\"S3.T3.1.12.11.5\" class=\"ltx_td ltx_align_center\">69.12</td>\n</tr>\n<tr id=\"S3.T3.1.13.12\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.13.12.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">VQA Challenge 2021 winner</th>\n<th id=\"S3.T3.1.13.12.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">79.34</th>\n<td id=\"S3.T3.1.13.12.3\" class=\"ltx_td ltx_align_center\">93.28</td>\n<td id=\"S3.T3.1.13.12.4\" class=\"ltx_td ltx_align_center\">65.36</td>\n<td id=\"S3.T3.1.13.12.5\" class=\"ltx_td ltx_align_center\">70.40</td>\n</tr>\n<tr id=\"S3.T3.1.14.13\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.14.13.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">PASH-SFE</th>\n<th id=\"S3.T3.1.14.13.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">79.47</th>\n<td id=\"S3.T3.1.14.13.3\" class=\"ltx_td ltx_align_center\">92.45</td>\n<td id=\"S3.T3.1.14.13.4\" class=\"ltx_td ltx_align_center\">76.57</td>\n<td id=\"S3.T3.1.14.13.5\" class=\"ltx_td ltx_align_center\">68.82</td>\n</tr>\n<tr id=\"S3.T3.1.15.14\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.15.14.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">SimVLM (<cite class=\"ltx_cite ltx_citemacro_cite\">Wang et al. (<a href=\"#bib.bib59\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>)</th>\n<th id=\"S3.T3.1.15.14.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">80.34</th>\n<td id=\"S3.T3.1.15.14.3\" class=\"ltx_td ltx_align_center\">93.29</td>\n<td id=\"S3.T3.1.15.14.4\" class=\"ltx_td ltx_align_center\">66.54</td>\n<td id=\"S3.T3.1.15.14.5\" class=\"ltx_td ltx_align_center\">72.23</td>\n</tr>\n<tr id=\"S3.T3.1.16.15\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.16.15.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S3.T3.1.16.15.1.1\" class=\"ltx_text ltx_font_smallcaps\">AliceMind-MMU</span></th>\n<th id=\"S3.T3.1.16.15.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S3.T3.1.16.15.2.1\" class=\"ltx_text ltx_font_bold\">81.26</span></th>\n<td id=\"S3.T3.1.16.15.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">93.55</td>\n<td id=\"S3.T3.1.16.15.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">72.01</td>\n<td id=\"S3.T3.1.16.15.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T3.1.16.15.5.1\" class=\"ltx_text ltx_font_bold\">72.67</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Table 3 presents our main results compared with all the previous public and unpublic best results on the VQA Challenge Leaderboard. From the results, it can be observed that: 1) Our VQA architecture AliceMind-MMU represents the first to achieve human parity on VQA Challenge Leaderboard outperforming all the previous state-of-the-art methods by a large margin, which demonstrates the effectiveness of our framework. 2) With regard to a breakdown of performance on different question types, AliceMind-MMU performs much better on the “Other” type than human do, and gives comparable results on “Yes/No” questions. AliceMind-MMU performs worse than human do on type “Number” for the two reasons: a) in the “Number” type, there are many questions about reading OCR text, which are easier for human to answer; and b) there are many object counting questions that are more difficult for AliceMind-MMU to answer."
        ]
    },
    "S3.T4": {
        "caption": "Table 4: Performance comparison with other single models.",
        "table": "<table id=\"S3.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_row ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" colspan=\"8\">Performance of Single Models</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T4.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.2.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" rowspan=\"2\"><span id=\"S3.T4.1.2.1.1.1\" class=\"ltx_text\">Models</span></th>\n<th id=\"S3.T4.1.2.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" rowspan=\"2\"><span id=\"S3.T4.1.2.1.2.1\" class=\"ltx_text\">Feature Type</span></th>\n<td id=\"S3.T4.1.2.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" colspan=\"3\">BASE</td>\n<td id=\"S3.T4.1.2.1.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" colspan=\"3\">LARGE</td>\n</tr>\n<tr id=\"S3.T4.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T4.1.3.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Params</td>\n<td id=\"S3.T4.1.3.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Test-dev</td>\n<td id=\"S3.T4.1.3.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Test-std</td>\n<td id=\"S3.T4.1.3.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Params</td>\n<td id=\"S3.T4.1.3.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Test-dev</td>\n<td id=\"S3.T4.1.3.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Test-std</td>\n</tr>\n<tr id=\"S3.T4.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.4.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">VLBERT (<cite class=\"ltx_cite ltx_citemacro_cite\">Su et al. (<a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">2019</a>)</cite>)</th>\n<th id=\"S3.T4.1.4.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region</th>\n<td id=\"S3.T4.1.4.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">110M</td>\n<td id=\"S3.T4.1.4.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">71.16</td>\n<td id=\"S3.T4.1.4.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.4.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">345M</td>\n<td id=\"S3.T4.1.4.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">71.79</td>\n<td id=\"S3.T4.1.4.3.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">72.22</td>\n</tr>\n<tr id=\"S3.T4.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.5.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">UNITER (<cite class=\"ltx_cite ltx_citemacro_cite\">Chen et al. (<a href=\"#bib.bib8\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>)</th>\n<th id=\"S3.T4.1.5.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region</th>\n<td id=\"S3.T4.1.5.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">110M</td>\n<td id=\"S3.T4.1.5.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">72.70</td>\n<td id=\"S3.T4.1.5.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">72.91</td>\n<td id=\"S3.T4.1.5.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">345M</td>\n<td id=\"S3.T4.1.5.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">73.82</td>\n<td id=\"S3.T4.1.5.4.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">74.02</td>\n</tr>\n<tr id=\"S3.T4.1.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.6.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">OSCAR (<cite class=\"ltx_cite ltx_citemacro_cite\">Li et al. (<a href=\"#bib.bib60\" title=\"\" class=\"ltx_ref\">2020b</a>)</cite>)</th>\n<th id=\"S3.T4.1.6.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region</th>\n<td id=\"S3.T4.1.6.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">110M</td>\n<td id=\"S3.T4.1.6.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">73.16</td>\n<td id=\"S3.T4.1.6.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">73.44</td>\n<td id=\"S3.T4.1.6.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">345M</td>\n<td id=\"S3.T4.1.6.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">73.61</td>\n<td id=\"S3.T4.1.6.5.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">73.82</td>\n</tr>\n<tr id=\"S3.T4.1.7.6\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.7.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">UNIMO (<cite class=\"ltx_cite ltx_citemacro_cite\">Li et al. (<a href=\"#bib.bib58\" title=\"\" class=\"ltx_ref\">2020a</a>)</cite>)</th>\n<th id=\"S3.T4.1.7.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region</th>\n<td id=\"S3.T4.1.7.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">110M</td>\n<td id=\"S3.T4.1.7.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">73.79</td>\n<td id=\"S3.T4.1.7.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">74.02</td>\n<td id=\"S3.T4.1.7.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">345M</td>\n<td id=\"S3.T4.1.7.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">75.06</td>\n<td id=\"S3.T4.1.7.6.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">75.27</td>\n</tr>\n<tr id=\"S3.T4.1.8.7\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.8.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">VinVL (<cite class=\"ltx_cite ltx_citemacro_cite\">Zhang et al. (<a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite> )</th>\n<th id=\"S3.T4.1.8.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region</th>\n<td id=\"S3.T4.1.8.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">110M</td>\n<td id=\"S3.T4.1.8.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">75.95</td>\n<td id=\"S3.T4.1.8.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">76.12</td>\n<td id=\"S3.T4.1.8.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">345M</td>\n<td id=\"S3.T4.1.8.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">76.52</td>\n<td id=\"S3.T4.1.8.7.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">76.60</td>\n</tr>\n<tr id=\"S3.T4.1.9.8\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.9.8.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">ViLBERT (<cite class=\"ltx_cite ltx_citemacro_cite\">Lu et al. (<a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2019</a>)</cite>)</th>\n<th id=\"S3.T4.1.9.8.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region</th>\n<td id=\"S3.T4.1.9.8.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">221M</td>\n<td id=\"S3.T4.1.9.8.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">70.55</td>\n<td id=\"S3.T4.1.9.8.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">70.92</td>\n<td id=\"S3.T4.1.9.8.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.9.8.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.9.8.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n</tr>\n<tr id=\"S3.T4.1.10.9\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.10.9.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">12-in-1 (<cite class=\"ltx_cite ltx_citemacro_cite\">Lu et al. (<a href=\"#bib.bib62\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>)</th>\n<th id=\"S3.T4.1.10.9.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region</th>\n<td id=\"S3.T4.1.10.9.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">221M</td>\n<td id=\"S3.T4.1.10.9.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">73.15</td>\n<td id=\"S3.T4.1.10.9.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.10.9.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.10.9.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.10.9.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n</tr>\n<tr id=\"S3.T4.1.11.10\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.11.10.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">LXMERT (<cite class=\"ltx_cite ltx_citemacro_cite\">Tan and Bansal (<a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">2019</a>)</cite> )</th>\n<th id=\"S3.T4.1.11.10.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region</th>\n<td id=\"S3.T4.1.11.10.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">183M</td>\n<td id=\"S3.T4.1.11.10.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">72.42</td>\n<td id=\"S3.T4.1.11.10.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">72.54</td>\n<td id=\"S3.T4.1.11.10.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.11.10.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.11.10.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"></td>\n</tr>\n<tr id=\"S3.T4.1.12.11\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.12.11.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">ERNIE-ViL (<cite class=\"ltx_cite ltx_citemacro_cite\">Yu et al. (<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2021</a>)</cite> )</th>\n<th id=\"S3.T4.1.12.11.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region</th>\n<td id=\"S3.T4.1.12.11.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">250M</td>\n<td id=\"S3.T4.1.12.11.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">73.18</td>\n<td id=\"S3.T4.1.12.11.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">73.36</td>\n<td id=\"S3.T4.1.12.11.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">510M</td>\n<td id=\"S3.T4.1.12.11.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">74.95</td>\n<td id=\"S3.T4.1.12.11.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">75.10</td>\n</tr>\n<tr id=\"S3.T4.1.13.12\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.13.12.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">PixelBERT (<cite class=\"ltx_cite ltx_citemacro_cite\">Huang et al. (<a href=\"#bib.bib16\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>)</th>\n<th id=\"S3.T4.1.13.12.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Grid</th>\n<td id=\"S3.T4.1.13.12.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">170M</td>\n<td id=\"S3.T4.1.13.12.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">74.45</td>\n<td id=\"S3.T4.1.13.12.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">74.55</td>\n<td id=\"S3.T4.1.13.12.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.13.12.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.13.12.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n</tr>\n<tr id=\"S3.T4.1.14.13\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.14.13.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">ViLT (<cite class=\"ltx_cite ltx_citemacro_cite\">Kim et al. (<a href=\"#bib.bib29\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>)</th>\n<th id=\"S3.T4.1.14.13.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Patch</th>\n<td id=\"S3.T4.1.14.13.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">110M</td>\n<td id=\"S3.T4.1.14.13.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">71.26</td>\n<td id=\"S3.T4.1.14.13.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.14.13.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.14.13.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.14.13.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n</tr>\n<tr id=\"S3.T4.1.15.14\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.15.14.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region-VLP</th>\n<th id=\"S3.T4.1.15.14.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region</th>\n<td id=\"S3.T4.1.15.14.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">110M</td>\n<td id=\"S3.T4.1.15.14.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">76.25</td>\n<td id=\"S3.T4.1.15.14.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.15.14.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">345M</td>\n<td id=\"S3.T4.1.15.14.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">77.17</td>\n<td id=\"S3.T4.1.15.14.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n</tr>\n<tr id=\"S3.T4.1.16.15\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.16.15.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Grid-VLP</th>\n<th id=\"S3.T4.1.16.15.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Grid</th>\n<td id=\"S3.T4.1.16.15.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">110M</td>\n<td id=\"S3.T4.1.16.15.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">76.50</td>\n<td id=\"S3.T4.1.16.15.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.16.15.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">345M</td>\n<td id=\"S3.T4.1.16.15.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">77.13</td>\n<td id=\"S3.T4.1.16.15.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n</tr>\n<tr id=\"S3.T4.1.17.16\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.17.16.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Patch-VLP</th>\n<th id=\"S3.T4.1.17.16.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Patch</th>\n<td id=\"S3.T4.1.17.16.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">110M</td>\n<td id=\"S3.T4.1.17.16.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">71.61</td>\n<td id=\"S3.T4.1.17.16.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.17.16.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">345M</td>\n<td id=\"S3.T4.1.17.16.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n<td id=\"S3.T4.1.17.16.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">-</td>\n</tr>\n<tr id=\"S3.T4.1.18.17\" class=\"ltx_tr\">\n<th id=\"S3.T4.1.18.17.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Fusion-VLP</th>\n<th id=\"S3.T4.1.18.17.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Region+Grid+Patch</th>\n<td id=\"S3.T4.1.18.17.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">110M</td>\n<td id=\"S3.T4.1.18.17.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T4.1.18.17.4.1\" class=\"ltx_text ltx_font_bold\">76.80</span></td>\n<td id=\"S3.T4.1.18.17.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T4.1.18.17.5.1\" class=\"ltx_text ltx_font_bold\">76.78</span></td>\n<td id=\"S3.T4.1.18.17.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">345M</td>\n<td id=\"S3.T4.1.18.17.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T4.1.18.17.7.1\" class=\"ltx_text ltx_font_bold\">77.59</span></td>\n<td id=\"S3.T4.1.18.17.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T4.1.18.17.8.1\" class=\"ltx_text ltx_font_bold\">77.61</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Table 4 presents the detailed results of our single VLP models compared with other state-of-the-art methods. From the results, it is observed that: 1) the proposed VLP model outperforms the others on every kind of visual feature (region / grid / patch), respectively. It demonstrates the effectiveness of the proposed cross-modal interaction with learning to attend mechanism. 2) The methods with self-attention on patch feature perform worse than the region-based and grid-based methods do. There are two weaknesses of patch-based methods: a) the visual semantic information is not well-captured in existing patch-based VLP methods. How to inject visual semantics into patch representation remains largely unexplored; b) the image-text pre-training data is not enough for large-scale patch-based pre-training; 3) Fusion-VLP gives the best performance by fusing all the three classes of visual features as input, which validates the effectiveness of comprehensive feature representation."
        ]
    },
    "S3.T5": {
        "caption": "Table 5: Ablation study of visual features on VQA Test-dev.",
        "table": "<table id=\"S3.T5.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T5.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<th id=\"S3.T5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Overall</th>\n<th id=\"S3.T5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Yes/No</th>\n<th id=\"S3.T5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Number</th>\n<th id=\"S3.T5.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Other</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T5.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T5.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Fusion-VLP</th>\n<td id=\"S3.T5.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T5.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">77.59</span></td>\n<td id=\"S3.T5.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">91.91</td>\n<td id=\"S3.T5.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T5.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">64.29</span></td>\n<td id=\"S3.T5.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T5.1.2.1.5.1\" class=\"ltx_text ltx_font_bold\">68.33</span></td>\n</tr>\n<tr id=\"S3.T5.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T5.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Region-VLP</th>\n<td id=\"S3.T5.1.3.2.2\" class=\"ltx_td ltx_align_center\">77.17</td>\n<td id=\"S3.T5.1.3.2.3\" class=\"ltx_td ltx_align_center\">91.62</td>\n<td id=\"S3.T5.1.3.2.4\" class=\"ltx_td ltx_align_center\">63.69</td>\n<td id=\"S3.T5.1.3.2.5\" class=\"ltx_td ltx_align_center\">67.84</td>\n</tr>\n<tr id=\"S3.T5.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T5.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Grid-VLP</th>\n<td id=\"S3.T5.1.4.3.2\" class=\"ltx_td ltx_align_center\">77.13</td>\n<td id=\"S3.T5.1.4.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T5.1.4.3.3.1\" class=\"ltx_text ltx_font_bold\">92.20</span></td>\n<td id=\"S3.T5.1.4.3.4\" class=\"ltx_td ltx_align_center\">59.99</td>\n<td id=\"S3.T5.1.4.3.5\" class=\"ltx_td ltx_align_center\">68.15</td>\n</tr>\n<tr id=\"S3.T5.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T5.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Patch-VLP</th>\n<td id=\"S3.T5.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">71.61</td>\n<td id=\"S3.T5.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">88.17</td>\n<td id=\"S3.T5.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">49.44</td>\n<td id=\"S3.T5.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">62.54</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Here presents the ablation study to assess the importance of different visual features for VLP on the VQA test-dev set. The results shown in Table 5 indicate that: 1) The VLP methods based on region and grid features achieve much better performance than the ones based on patch feature do, as stated in Section 3.3. When examining by individual question types, Region-VLP performs better on the “Number” type, while Grid-VLP does better on the “Yes/No” and “Other” types. The difference can be attributed to the fact that region feature captures more local information of an image at the object level, and thus is more effective in address the visual counting problem by identifying local objects in an image. On the other hand, grid feature captures globally visual context in an image, which helps to answer the “Yes/No” and “Other” questions; 2) by combining the three classes of features in the way of early fusion, Fusion-VLP performs the best among all the single models. It shows that the different kinds of features can complement well with each other."
        ]
    },
    "S3.T6": {
        "caption": "Table 6: Ablation study of learning to attend on VQA Test-dev.",
        "table": "<table id=\"S3.T6.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T6.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T6.3.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<th id=\"S3.T6.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Overall</th>\n<th id=\"S3.T6.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Yes/no</th>\n<th id=\"S3.T6.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Number</th>\n<th id=\"S3.T6.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Other</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T6.3.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T6.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Region-VLP (Baseline)</th>\n<td id=\"S3.T6.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">76.75</td>\n<td id=\"S3.T6.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">91.28</td>\n<td id=\"S3.T6.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">63.31</td>\n<td id=\"S3.T6.3.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">67.34</td>\n</tr>\n<tr id=\"S3.T6.3.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T6.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">   + Learning to Attend (FFN)</th>\n<td id=\"S3.T6.3.3.2.2\" class=\"ltx_td ltx_align_center\">77.09</td>\n<td id=\"S3.T6.3.3.2.3\" class=\"ltx_td ltx_align_center\">91.58</td>\n<td id=\"S3.T6.3.3.2.4\" class=\"ltx_td ltx_align_center\">63.54</td>\n<td id=\"S3.T6.3.3.2.5\" class=\"ltx_td ltx_align_center\">67.74</td>\n</tr>\n<tr id=\"S3.T6.3.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T6.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">   + Learning to Attend (Param)</th>\n<td id=\"S3.T6.3.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T6.3.4.3.2.1\" class=\"ltx_text ltx_font_bold\">77.17</span></td>\n<td id=\"S3.T6.3.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T6.3.4.3.3.1\" class=\"ltx_text ltx_font_bold\">91.62</span></td>\n<td id=\"S3.T6.3.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T6.3.4.3.4.1\" class=\"ltx_text ltx_font_bold\">63.69</span></td>\n<td id=\"S3.T6.3.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T6.3.4.3.5.1\" class=\"ltx_text ltx_font_bold\">67.84</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": []
    },
    "S3.T7": {
        "caption": "Table 7: Ablation study of text reading expert on the VQA Test-dev.",
        "table": "<table id=\"S3.T7.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T7.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T7.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt\"></th>\n<th id=\"S3.T7.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Overall</th>\n<th id=\"S3.T7.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Yes/No</th>\n<th id=\"S3.T7.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Number</th>\n<th id=\"S3.T7.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\">Other</th>\n<th id=\"S3.T7.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">ANLS</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T7.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T7.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Visual Understanding Expert</th>\n<td id=\"S3.T7.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">79.44</td>\n<td id=\"S3.T7.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">93.31</td>\n<td id=\"S3.T7.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">65.70</td>\n<td id=\"S3.T7.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">71.16</td>\n<td id=\"S3.T7.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S3.T7.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T7.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">+ Text-reading VQA data</th>\n<td id=\"S3.T7.1.3.2.2\" class=\"ltx_td ltx_align_center\">80.35</td>\n<td id=\"S3.T7.1.3.2.3\" class=\"ltx_td ltx_align_center\">93.31</td>\n<td id=\"S3.T7.1.3.2.4\" class=\"ltx_td ltx_align_center\">69.81</td>\n<td id=\"S3.T7.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">71.49</td>\n<td id=\"S3.T7.1.3.2.6\" class=\"ltx_td ltx_align_center\">79.85</td>\n</tr>\n<tr id=\"S3.T7.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T7.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">      + add separator</th>\n<td id=\"S3.T7.1.4.3.2\" class=\"ltx_td ltx_align_center\">80.41</td>\n<td id=\"S3.T7.1.4.3.3\" class=\"ltx_td ltx_align_center\">93.31</td>\n<td id=\"S3.T7.1.4.3.4\" class=\"ltx_td ltx_align_center\">69.82</td>\n<td id=\"S3.T7.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">71.64</td>\n<td id=\"S3.T7.1.4.3.6\" class=\"ltx_td ltx_align_center\">79.96</td>\n</tr>\n<tr id=\"S3.T7.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T7.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">        + continue pre-training</th>\n<td id=\"S3.T7.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T7.1.5.4.2.1\" class=\"ltx_text ltx_font_bold\">80.63</span></td>\n<td id=\"S3.T7.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">93.31</td>\n<td id=\"S3.T7.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T7.1.5.4.4.1\" class=\"ltx_text ltx_font_bold\">69.97</span></td>\n<td id=\"S3.T7.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S3.T7.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\">72.01</span></td>\n<td id=\"S3.T7.1.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T7.1.5.4.6.1\" class=\"ltx_text ltx_font_bold\">80.33</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": []
    },
    "S3.T8": {
        "caption": "Table 8: Quantitative analysis on the clustering results of different clustering methods.",
        "table": "<table id=\"S3.T8.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T8.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T8.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"></th>\n<th id=\"S3.T8.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Acc</th>\n<th id=\"S3.T8.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">P</th>\n<th id=\"S3.T8.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">R</th>\n<th id=\"S3.T8.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Macro-F1</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T8.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T8.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">DBSCAN (eps=0.5)</th>\n<th id=\"S3.T8.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.1544</th>\n<td id=\"S3.T8.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.4605</td>\n<td id=\"S3.T8.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.3861</td>\n<td id=\"S3.T8.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1466</td>\n</tr>\n<tr id=\"S3.T8.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T8.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">K-Means (K=3)</th>\n<th id=\"S3.T8.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.4969</th>\n<td id=\"S3.T8.1.3.2.3\" class=\"ltx_td ltx_align_center\">0.6487</td>\n<td id=\"S3.T8.1.3.2.4\" class=\"ltx_td ltx_align_center\">0.662</td>\n<td id=\"S3.T8.1.3.2.5\" class=\"ltx_td ltx_align_center\">0.6163</td>\n</tr>\n<tr id=\"S3.T8.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T8.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">K-Means (K=4)</th>\n<th id=\"S3.T8.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.7894</th>\n<td id=\"S3.T8.1.4.3.3\" class=\"ltx_td ltx_align_center\">0.8239</td>\n<td id=\"S3.T8.1.4.3.4\" class=\"ltx_td ltx_align_center\">0.8219</td>\n<td id=\"S3.T8.1.4.3.5\" class=\"ltx_td ltx_align_center\">0.8195</td>\n</tr>\n<tr id=\"S3.T8.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T8.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">K-Means (K=5)</th>\n<th id=\"S3.T8.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><span id=\"S3.T8.1.5.4.2.1\" class=\"ltx_text ltx_font_bold\">0.8448</span></th>\n<td id=\"S3.T8.1.5.4.3\" class=\"ltx_td ltx_align_center\">0.8659</td>\n<td id=\"S3.T8.1.5.4.4\" class=\"ltx_td ltx_align_center\">0.8898</td>\n<td id=\"S3.T8.1.5.4.5\" class=\"ltx_td ltx_align_center\">0.8739</td>\n</tr>\n<tr id=\"S3.T8.1.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T8.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">K-Means (K=6)</th>\n<th id=\"S3.T8.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\">0.8443</th>\n<td id=\"S3.T8.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T8.1.6.5.3.1\" class=\"ltx_text ltx_font_bold\">0.8668</span></td>\n<td id=\"S3.T8.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T8.1.6.5.4.1\" class=\"ltx_text ltx_font_bold\">0.8918</span></td>\n<td id=\"S3.T8.1.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T8.1.6.5.5.1\" class=\"ltx_text ltx_font_bold\">0.8740</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "To measure the consistency of the clustering result to the classification labels, we also provide detailed quantitative analysis on different clustering methods. We manually build a three-label classifier (OCR, clock and vision) with 95% accuracy as in Section 2.4.5 and apply it to evaluate the consistence of each cluster. We project each cluster to the corresponding label heuristically. For example, in Figure 4, Cluster 1 is assigned to clock label, Cluster 3 and Cluster 4 are to OCR label, and Cluster 5 is to vision label. We then compare the assigned label of each cluster to that of the classification label (95% accuracy). We use accuracy, macro-precision, macro-recall and macro-f1 to measure how consistent the compared label in each cluster is. As list in Table 8, K-Means (K=5) achieves the best performance with 0.8448 accuracy and 0.8739 macro-F1, which shows that the clustering result is highly consistent with the assumed classification labels on OCR/clock/vision."
        ]
    },
    "S3.T9": {
        "caption": "Table 9: Ablation study of clock reading expert.",
        "table": "<table id=\"S3.T9.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T9.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T9.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\">Clock Detector</th>\n<th id=\"S3.T9.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"4\">Clock Reader</th>\n<th id=\"S3.T9.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">VQA Test-dev</th>\n</tr>\n<tr id=\"S3.T9.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T9.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Detection(mAP)</th>\n<th id=\"S3.T9.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Cls</th>\n<th id=\"S3.T9.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Regression Loss</th>\n<th id=\"S3.T9.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Self-supervised Loss</th>\n<th id=\"S3.T9.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Clock Accuracy</th>\n<th id=\"S3.T9.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Number</th>\n<th id=\"S3.T9.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Overall</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T9.1.3.1\" class=\"ltx_tr\">\n<td id=\"S3.T9.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Baseline</td>\n<td id=\"S3.T9.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">–</td>\n<td id=\"S3.T9.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">–</td>\n<td id=\"S3.T9.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">–</td>\n<td id=\"S3.T9.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">–</td>\n<td id=\"S3.T9.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">59.93</td>\n<td id=\"S3.T9.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">76.51</td>\n</tr>\n<tr id=\"S3.T9.1.4.2\" class=\"ltx_tr\">\n<td id=\"S3.T9.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" rowspan=\"3\"><span id=\"S3.T9.1.4.2.1.1\" class=\"ltx_text\">79.30</span></td>\n<td id=\"S3.T9.1.4.2.2\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S3.T9.1.4.2.3\" class=\"ltx_td\"></td>\n<td id=\"S3.T9.1.4.2.4\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S3.T9.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">72.5</td>\n<td id=\"S3.T9.1.4.2.6\" class=\"ltx_td ltx_align_center\">62.52</td>\n<td id=\"S3.T9.1.4.2.7\" class=\"ltx_td ltx_align_center\">76.79</td>\n</tr>\n<tr id=\"S3.T9.1.5.3\" class=\"ltx_tr\">\n<td id=\"S3.T9.1.5.3.1\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S3.T9.1.5.3.2\" class=\"ltx_td ltx_align_center\">✓</td>\n<td id=\"S3.T9.1.5.3.3\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S3.T9.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">73.0</td>\n<td id=\"S3.T9.1.5.3.5\" class=\"ltx_td ltx_align_center\">62.59</td>\n<td id=\"S3.T9.1.5.3.6\" class=\"ltx_td ltx_align_center\">76.80</td>\n</tr>\n<tr id=\"S3.T9.1.6.4\" class=\"ltx_tr\">\n<td id=\"S3.T9.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">✓</td>\n<td id=\"S3.T9.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">✓</td>\n<td id=\"S3.T9.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">✓</td>\n<td id=\"S3.T9.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S3.T9.1.6.4.4.1\" class=\"ltx_text ltx_font_bold\">74.7</span></td>\n<td id=\"S3.T9.1.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T9.1.6.4.5.1\" class=\"ltx_text ltx_font_bold\">62.65</span></td>\n<td id=\"S3.T9.1.6.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T9.1.6.4.6.1\" class=\"ltx_text ltx_font_bold\">76.81</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "The ablation study of clock reading expert is shown in Table 9, where only the results on the “Number” and “Overall” types are given, because questions on reading clocks are only present in the “Number” type. Adding clock reading expert results in more than 4.5% performance improvement on the “Number” type (from 59.93 to 62.65), which demonstrates the effectiveness of proposed ideas in the clock reading expert.\nSpecifically, the proposed regression loss is prone to provide a larger gradient when there is a bigger difference between the predicted time and the ground truth, which benefits prediction of the clock reader. Moreover, it can be observed that the self-supervised loss boosts the performance significantly, as the relationship prior constrains hour and minute branches both, which eliminates the confusion of hour and minute hands."
        ]
    },
    "S3.T10": {
        "caption": "Table 10: Ablation study of MoE on the VQA Test-dev.",
        "table": "<table id=\"S3.T10.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T10.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T10.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S3.T10.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Overall</th>\n<th id=\"S3.T10.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Yes/No</th>\n<th id=\"S3.T10.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Number</th>\n<th id=\"S3.T10.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Other</th>\n</tr>\n<tr id=\"S3.T10.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T10.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Visual Understanding Expert</td>\n<td id=\"S3.T10.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">80.05</td>\n<td id=\"S3.T10.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">93.67</td>\n<td id=\"S3.T10.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">66.78</td>\n<td id=\"S3.T10.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">71.40</td>\n</tr>\n<tr id=\"S3.T10.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T10.1.3.3.1\" class=\"ltx_td ltx_align_left\">   + Text Reading Expert (MoE)</td>\n<td id=\"S3.T10.1.3.3.2\" class=\"ltx_td ltx_align_center\">81.00</td>\n<td id=\"S3.T10.1.3.3.3\" class=\"ltx_td ltx_align_center\">93.67</td>\n<td id=\"S3.T10.1.3.3.4\" class=\"ltx_td ltx_align_center\">69.75</td>\n<td id=\"S3.T10.1.3.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T10.1.3.3.5.1\" class=\"ltx_text ltx_font_bold\">72.69</span></td>\n</tr>\n<tr id=\"S3.T10.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T10.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">    + Clock Reading Expert (MoE)</td>\n<td id=\"S3.T10.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T10.1.4.4.2.1\" class=\"ltx_text ltx_font_bold\">81.27</span></td>\n<td id=\"S3.T10.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">93.67</td>\n<td id=\"S3.T10.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T10.1.4.4.4.1\" class=\"ltx_text ltx_font_bold\">72.55</span></td>\n<td id=\"S3.T10.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">72.60</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "The ablation study of MoE is shown in Table 10. With only visual understanding expert, the model gives a strong performance of accuracy 80.05 on the VQA Test-dev set. Adding text reading expert increases the overall performance by more than 1%, which already achieves human parity of 80.83. Adding clock reading expert further boosts the performance to 81.27, where the performance on the “Number” type increases by more than 4%. The gating network of MoE mimics human who is able to identify domain experts based on the nature of tasks. This knowledge-guided MoE framework can also be easily extended to incorporate more specialized experts for continual self-evolution."
        ]
    },
    "S3.T11": {
        "caption": "Table 11: The overall performance of AliceMind-MMU and human on val split.",
        "table": "<table id=\"S3.T11.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T11.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T11.3.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" rowspan=\"2\"></th>\n<th id=\"S3.T11.3.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Test-std</th>\n<th id=\"S3.T11.3.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" colspan=\"4\">Val</th>\n</tr>\n<tr id=\"S3.T11.3.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T11.3.2.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Overall</th>\n<th id=\"S3.T11.3.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Overall</th>\n<th id=\"S3.T11.3.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Yes/no</th>\n<th id=\"S3.T11.3.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Number</th>\n<th id=\"S3.T11.3.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Other</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T11.3.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T11.3.3.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">VLP</th>\n<th id=\"S3.T11.3.3.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T11.3.3.1.2.1\" class=\"ltx_text ltx_font_bold\">81.26</span></th>\n<td id=\"S3.T11.3.3.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">79.54</td>\n<td id=\"S3.T11.3.3.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">92.47</td>\n<td id=\"S3.T11.3.3.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">70.63</td>\n<td id=\"S3.T11.3.3.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T11.3.3.1.6.1\" class=\"ltx_text ltx_font_bold\">72.00</span></td>\n</tr>\n<tr id=\"S3.T11.3.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T11.3.4.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Human</th>\n<th id=\"S3.T11.3.4.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">80.83</th>\n<td id=\"S3.T11.3.4.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">78.69</td>\n<td id=\"S3.T11.3.4.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T11.3.4.2.4.1\" class=\"ltx_text ltx_font_bold\">94.87</span></td>\n<td id=\"S3.T11.3.4.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T11.3.4.2.5.1\" class=\"ltx_text ltx_font_bold\">78.79</span></td>\n<td id=\"S3.T11.3.4.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">66.34</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "A comparative study of AliceMind-MMU and human on visual question answering has been conducted. Table 11 and Table 12 show the overall and per-category performance of AliceMind-MMU and human on the val split, respectively, from which there are the following observations:\n(i) AliceMind-MMU outperforms human annotators on the two largest categories, Commonsense Knowledge and Relational Reasoning. It shows AliceMind-MMU ’s superiority of identifying common scene objects in daily life and leveraging commonsense knowledge such as colors and weathers. This result also demonstrates the power of AliceMind-MMU in reasoning over relative positions, such as the left sign on a wall, to answer a spatial reasoning question. Besides, it is surprising that AliceMind-MMU can reason over simple comparison, such as which object is the tallest.\n(ii) The questions in the Object Counting category seem rather difficult for AliceMind-MMU to answer. AliceMind-MMU is found to be good at counting a small number (<10) of objects. It would give an incorrect count when encountering a large number of small objects and/or requiring reasoning over them.\n(iii) AliceMind-MMU significantly surpasses human performance on Visual Recognition which requires specialized knowledge. It is expected that AliceMind-MMU , as a machine learner trained with large data, is skilled in memorizing specialized/professional knowledge with visual recognition, compared with non-professional human annotators.\n(iv) AliceMind-MMU is more capable of reading time shown in a clock than human, as demonstrated by the result of Clock Reading. On text reading, however, there is still a big gap between AliceMind-MMU and human in recognizing and understanding text in an image, as shown by the result of Textual Recognition. Some research progress has been made on text-reading VQA tasks, such as TextVQA (Singh et al., 2019)."
        ]
    },
    "S3.T12": {
        "caption": "Table 12: The performance of AliceMind-MMU and human by category.",
        "table": "<table id=\"S3.T12.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T12.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T12.3.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"></th>\n<th id=\"S3.T12.3.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">\n<table id=\"S3.T12.3.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T12.3.1.1.2.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Commonsense</td>\n</tr>\n<tr id=\"S3.T12.3.1.1.2.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Knowledge</td>\n</tr>\n</table>\n</th>\n<th id=\"S3.T12.3.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">\n<table id=\"S3.T12.3.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T12.3.1.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Relational</td>\n</tr>\n<tr id=\"S3.T12.3.1.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Reasoning</td>\n</tr>\n</table>\n</th>\n<th id=\"S3.T12.3.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Object Counting</th>\n<th id=\"S3.T12.3.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Visual Recognition</th>\n<th id=\"S3.T12.3.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">\n<table id=\"S3.T12.3.1.1.6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T12.3.1.1.6.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.6.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Textual Recognition</td>\n</tr>\n<tr id=\"S3.T12.3.1.1.6.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.6.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">(OCR)</td>\n</tr>\n</table>\n</th>\n<th id=\"S3.T12.3.1.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Clock Reading</th>\n<th id=\"S3.T12.3.1.1.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Other</th>\n</tr>\n<tr id=\"S3.T12.3.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T12.3.2.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"></th>\n<th id=\"S3.T12.3.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">767</th>\n<th id=\"S3.T12.3.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">159</th>\n<th id=\"S3.T12.3.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">103</th>\n<th id=\"S3.T12.3.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">70</th>\n<th id=\"S3.T12.3.2.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">74</th>\n<th id=\"S3.T12.3.2.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">7</th>\n<th id=\"S3.T12.3.2.2.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">5</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T12.3.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T12.3.3.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">VLP</th>\n<td id=\"S3.T12.3.3.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T12.3.3.1.2.1\" class=\"ltx_text ltx_font_bold\">83.60</span></td>\n<td id=\"S3.T12.3.3.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T12.3.3.1.3.1\" class=\"ltx_text ltx_font_bold\">71.19</span></td>\n<td id=\"S3.T12.3.3.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">77.76</td>\n<td id=\"S3.T12.3.3.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T12.3.3.1.5.1\" class=\"ltx_text ltx_font_bold\">68.14</span></td>\n<td id=\"S3.T12.3.3.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">52.03</td>\n<td id=\"S3.T12.3.3.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T12.3.3.1.7.1\" class=\"ltx_text ltx_font_bold\">86.00</span></td>\n<td id=\"S3.T12.3.3.1.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T12.3.3.1.8.1\" class=\"ltx_text ltx_font_bold\">70.00</span></td>\n</tr>\n<tr id=\"S3.T12.3.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T12.3.4.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Human</th>\n<td id=\"S3.T12.3.4.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">80.04</td>\n<td id=\"S3.T12.3.4.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">70.20</td>\n<td id=\"S3.T12.3.4.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T12.3.4.2.4.1\" class=\"ltx_text ltx_font_bold\">81.29</span></td>\n<td id=\"S3.T12.3.4.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">59.76</td>\n<td id=\"S3.T12.3.4.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S3.T12.3.4.2.6.1\" class=\"ltx_text ltx_font_bold\">76.62</span></td>\n<td id=\"S3.T12.3.4.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">60.66</td>\n<td id=\"S3.T12.3.4.2.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">49.52</td>\n</tr>\n</tbody>\n</table>\n<table id=\"S3.T12.3.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T12.3.1.1.2.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Commonsense</td>\n</tr>\n<tr id=\"S3.T12.3.1.1.2.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Knowledge</td>\n</tr>\n</table>\n<table id=\"S3.T12.3.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T12.3.1.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Relational</td>\n</tr>\n<tr id=\"S3.T12.3.1.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Reasoning</td>\n</tr>\n</table>\n<table id=\"S3.T12.3.1.1.6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T12.3.1.1.6.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.6.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">Textual Recognition</td>\n</tr>\n<tr id=\"S3.T12.3.1.1.6.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T12.3.1.1.6.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">(OCR)</td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "A comparative study of AliceMind-MMU and human on visual question answering has been conducted. Table 11 and Table 12 show the overall and per-category performance of AliceMind-MMU and human on the val split, respectively, from which there are the following observations:\n(i) AliceMind-MMU outperforms human annotators on the two largest categories, Commonsense Knowledge and Relational Reasoning. It shows AliceMind-MMU ’s superiority of identifying common scene objects in daily life and leveraging commonsense knowledge such as colors and weathers. This result also demonstrates the power of AliceMind-MMU in reasoning over relative positions, such as the left sign on a wall, to answer a spatial reasoning question. Besides, it is surprising that AliceMind-MMU can reason over simple comparison, such as which object is the tallest.\n(ii) The questions in the Object Counting category seem rather difficult for AliceMind-MMU to answer. AliceMind-MMU is found to be good at counting a small number (<10) of objects. It would give an incorrect count when encountering a large number of small objects and/or requiring reasoning over them.\n(iii) AliceMind-MMU significantly surpasses human performance on Visual Recognition which requires specialized knowledge. It is expected that AliceMind-MMU , as a machine learner trained with large data, is skilled in memorizing specialized/professional knowledge with visual recognition, compared with non-professional human annotators.\n(iv) AliceMind-MMU is more capable of reading time shown in a clock than human, as demonstrated by the result of Clock Reading. On text reading, however, there is still a big gap between AliceMind-MMU and human in recognizing and understanding text in an image, as shown by the result of Textual Recognition. Some research progress has been made on text-reading VQA tasks, such as TextVQA (Singh et al., 2019)."
        ]
    }
}