{
    "PAPER'S NUMBER OF TABLES": 2,
    "S5.T1": {
        "caption": "Table 1. Performance of local learners with all samples",
        "table": "<table id=\"S5.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"></th>\n<th id=\"S5.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\">MNIST</th>\n<th id=\"S5.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\">FMNIST</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Model</td>\n<td id=\"S5.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Accuracy</td>\n<td id=\"S5.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Loss</td>\n<td id=\"S5.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Accuracy</td>\n<td id=\"S5.T1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Loss</td>\n</tr>\n<tr id=\"S5.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">LeNet</td>\n<td id=\"S5.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97%</td>\n<td id=\"S5.T1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.089</td>\n<td id=\"S5.T1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">83%</td>\n<td id=\"S5.T1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.46</td>\n</tr>\n<tr id=\"S5.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">LeNet CAE</td>\n<td id=\"S5.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.006</td>\n<td id=\"S5.T1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.015</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We implemented the system in Python 3.9 using Pytorch Lightning 1.8, a framework built on Pytorch. The learners have access to an MLFlow instance to store information about their training. The MLFlow instance relied on a PostgreSQL database to store its data. All nodes were deployed in Docker containers on a bare metal server running Ubuntu 22.04. The server uses dual Intel Xeon Gold 5118 CPU totalling 48 cores with 126GB of RAM. All the nodes in the network are doing training and aggregation. Nodes send messages peer-to-peer through an MQTT instance configured to broadcast messages. Moreover, learners do not communicate their models directly. Instead, they save their models to a location accessible to other peers and the model‚Äôs url is shared.",
                "Dataset:",
                " The network was tested using two computer vision problems with MNIST and FashionMNIST datasets. MNIST consists of handwritten digits while FMNIST contains pictures of clothing items. While these datasets are typically balanced, we intentionally distributed samples in various non-IID ways. The specifics of these distributions are detailed prior to the experimental results. This methodology for generating non-IID data has been previously used in many papers such as ",
                "(Li et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and ",
                "(Wang et¬†al",
                ".",
                ", ",
                "[n.‚Äâd.]",
                ")",
                ". These dataset are ideal for concept validation using the same input dimensions and well-known comparable benchmarks. At the start of every experience, the dataset is split among all the learners. Data samples are not reused between learners. All the tests are run using 38 learners for 102 rounds with two epochs per round.",
                "Models:",
                " The LeNet",
                "(LeCun et¬†al",
                ".",
                ", ",
                "1989",
                ")",
                " is used for the classification tasks. While the LeNet model works for supervised problems, we also want to demonstrate the ability of the network to work with unsupervised learning problems. For this reason, we chose to train autoencoders. They are a type of neural network that tries to replicate its inputs to the outputs by encoding the features in smaller latent spaces. The architecture of our autoencoders repurposes the first two convolutional layers of the LeNet model as the encoder and mirrors them for the decoder. The baseline local training achieved a satisfying level of accuracy with ten epochs.",
                "Baseline Solution:",
                " We implemented the baseline solution by reusing the architecture of our proposed approach. As a result, the baseline solution is a decentralised learning network in which all learners participate in each round, performing aggregation with the FedAvg algorithm.",
                "Metrics:",
                " The performance of the models is measured on the learners dataset after the aggregation phase, without fine-tuning. For classification problems, we use accuracy as shown in Equation ",
                "3",
                ". TP stands for true positive, TN stands for true negative, FP stands for false positive, and FN stands for false negative.",
                "The Mean Squared Error (Equation ",
                "4",
                ") is used for the autoencoder task. ",
                "y",
                "i",
                "subscript",
                "ùë¶",
                "ùëñ",
                "y_{i}",
                " stands for the target prediction while ",
                "y",
                "^",
                "i",
                "subscript",
                "^",
                "ùë¶",
                "ùëñ",
                "\\hat{y}_{i}",
                " stands for the model output."
            ]
        ]
    },
    "S5.T2": {
        "caption": "Table 2. Performance Networks on IID Dataset",
        "table": "<table id=\"S5.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\">Algorithm</th>\n<th id=\"S5.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Minimum</th>\n<th id=\"S5.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Average</th>\n<th id=\"S5.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Maximum</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedAvg</td>\n<td id=\"S5.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">96.2%</td>\n<td id=\"S5.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">98.2%</td>\n<td id=\"S5.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">99.5%</td>\n</tr>\n<tr id=\"S5.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">MCFL</td>\n<td id=\"S5.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">98.1%</td>\n<td id=\"S5.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">99.2%</td>\n<td id=\"S5.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">99.8%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The first results in Table 2 show the weight divergence selection mechanism is helpful to outperform FedAvg even on IID datasets. For this experience, the dataset was distributed uniformly. MultiConfederated Learning¬†outperformed the FedAvg implementation, with the worst performer from MultiConfederated Learning¬†almost outperforming the average learner in the baseline solution. As a result of the limited weight divergence between aggregated updates, the aggregated models‚Äô performances are more predictable, and the gap between the worst and best results is smaller than with FedAvg. Moreover, the selection algorithm only selects the best-aggregated cluster, which helps with a slightly faster convergence rate in this scenario. In fact, the average performance is 20% higher with the proposed approach for the first round but fades to 2-3% improvements by the fifth round."
        ]
    }
}