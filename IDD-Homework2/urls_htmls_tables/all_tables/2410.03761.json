{
    "id_table_1": {
        "caption": "Table 1:  Results of literature review generation by pure LLMs, naive RAG-based LLMs, AutoSurvey and HiReview. The best performance is in  Bold . LLM   indicates the LLM is provided top-500 relevant papers retrieved by naive BM25.   \\uparrow   indicates that a higher metric value corresponds to better model performance.",
        "table": "S5.T1.41",
        "footnotes": [],
        "references": [
            "Literature reviews play a crucial role in synthesizing knowledge from large bodies of work, helping to organize and summarize relevant research. However, manual literature reviews are labor-intensive and time-consuming, especially when addressing fields with complex, hierarchical topics. Consequently, there is growing interest in automating literature review generation (LRG) to reduce this burden. As shown in  Fig.   1 , an automated LRG system should accurately retrieve relevant papers, identify relationships between them, organize the papers and generate reliable, factually accurate content for the literature review.",
            "In this section, we present our  taxonomy-then-generation  framework ( Fig.   2 ). First, we introduce a graph retrieval strategy to address  Challenge 1 , which aggregates neighbor relevance scores during retrieval ( Section   4.1 ). Next, we propose an end-to-end hierarchical taxonomy tree generation model, consisting of hierarchical clustering and hierarchical generation. Specifically, we introduce a novel hierarchical graph clustering approach that considers relationships between nodes across different levels of the hierarchy to tackle  Challenge 2  ( Section   4.2.1 ), categorizing papers in a citation network hierarchically. Then, in  Section   4.2.2 , we propose a bottom-up iterative generation approach to determine the central topic of each cluster at every hierarchical level, ultimately forming a taxonomy to address  Challenge 3 . Finally, we leverage the hierarchical taxonomy to guide the literature review generation process, producing high-quality, citation-aware literature reviews.",
            "We manually collected 518 high-quality literature review articles with clear taxonomy or well-defined article structures from arXiv 4 4 4 https://arxiv.org/ . Most of these review papers were published within the past three years. For each literature review, we extracted its taxonomy tree and gathered its 2-hop citation network, which includes the direct citations of the review paper and the citations of the reviews references. The mutual citation relationships among these references form a complex citation network for each literature review. These 2-hop citation networks contain an average of 6,658.4 papers and 11,632.9 edges, accommodating isolated papers. More details are in  Appendix   A.1 .",
            "Main Results.  As shown in  Table   1 , Our method HiReview consistently outperforms the other review generation methods in all metrics. It excels across all LLMScore categories, with notably high structure (0.9484) and relevance (0.9428) scores. AutoSurvey employs a structured methodology that combines retrieval, outline generation, and section drafting, leading to superior content generation compared to naive systems (with average LLMScore of 0.8957).",
            "RQ2.  As shown in  Table   1 , HiReview, which incorporates a taxonomy tree, outperforms all other models, particularly in  Structure , achieving a score of 0.9484. In contrast, AutoSurvey, which follows an outline-then-generation approach without hierarchical taxonomy, shows lower scores, such as a  Structure  score of 0.9122. The ablation study further supports this. When the taxonomy is removed, the structure score drops significantly (as in  Table   2 ). This demonstrates that the taxonomy tree plays a critical role in organizing and guiding the content generation process, especially when maintaining a clear structure is crucial for a literature review. The taxonomy ensures more coherent and relevant summaries. Without providing the taxonomy tree, the generation loses its hierarchical guidance, leading to less structured and less comprehensive content.",
            "We experimented with different retrieval models and strategies, testing two representative methods: the sparse retrieval model, BM25  (Robertson et al.,  2009 ) , and the dense retrieval model, SentenceBert  (Reimers,  2019 ) . In citation networks, neighbor information and the topological structure play a crucial role in retrieval, as papers on the same topic often cite each other. To assess the impact of using neighbor information, we applied two retrieval strategies for both models: one incorporating neighbor information as described in  Section   4.1  ( Retrieval w/ Neighbor ) and the other excluding neighbor information ( Retrieval w/o Neighbor ). Given a topic (specifically, the title of a review paper), we retrieved papers related to this topic from the citation network and measured the accuracy by calculating how many of the retrieved papers appeared in the references of the corresponding literature review. The number of retrieved papers was not fixed, but matched the reference count for each review paper."
        ]
    },
    "id_table_2": {
        "caption": "Table 4:  Results of retrieval on the citation network corresponding to 50 review papers.  2-hop  and  3-hop  represent citation networks of review papers at different scales.  1-hop (merged)  refers to the 1-hop citation network of a review paper, merged with all other 1-hop citation networks, different review papers. Similarly,  2-hop (merged)  is constructed by merging the 2-hop citation network of a review with all other 49 review papers.",
        "table": "S5.SS3.5.5",
        "footnotes": [],
        "references": [
            "In this section, we present our  taxonomy-then-generation  framework ( Fig.   2 ). First, we introduce a graph retrieval strategy to address  Challenge 1 , which aggregates neighbor relevance scores during retrieval ( Section   4.1 ). Next, we propose an end-to-end hierarchical taxonomy tree generation model, consisting of hierarchical clustering and hierarchical generation. Specifically, we introduce a novel hierarchical graph clustering approach that considers relationships between nodes across different levels of the hierarchy to tackle  Challenge 2  ( Section   4.2.1 ), categorizing papers in a citation network hierarchically. Then, in  Section   4.2.2 , we propose a bottom-up iterative generation approach to determine the central topic of each cluster at every hierarchical level, ultimately forming a taxonomy to address  Challenge 3 . Finally, we leverage the hierarchical taxonomy to guide the literature review generation process, producing high-quality, citation-aware literature reviews.",
            "Setup.  The fine-tuned topic generator is LLaMA  (Touvron et al.,  2023 ) , while GPT-4o serves as the content generator 3 3 3 Specifically, we use LLaMA-2-7b and gpt-4o-2024-05-13. . For hierarchical clustering, we employ the GAT  (Velickovic et al.,  2017 )  in hierarchical clustering. Implementation details can be found in  Appendix   A.2 .",
            "Impacts of Components.  As shown in  Table   2 , we test three variants of HiReiview mode.  HiReview w/o retrieval  refers to the variant where the graph retrieval module is removed, and all papers in the citation network are used. A significant drop is observed across all metrics, particularly in  Coverage  (0.9163    \\rightarrow   0.6705) and  Relevance  (0.9428    \\rightarrow   0.7073). This indicates that the inclusion of unrelated papers introduces substantial noise, negatively impacting both the taxonomy tree generation (due to an excess of negative samples in hierarchical clustering) and content generation (where the noise hinders the creation of precise summaries). As a result, the quality opf generated summaries is even worse than those produced by zero-shot LLMs.",
            "RQ2.  As shown in  Table   1 , HiReview, which incorporates a taxonomy tree, outperforms all other models, particularly in  Structure , achieving a score of 0.9484. In contrast, AutoSurvey, which follows an outline-then-generation approach without hierarchical taxonomy, shows lower scores, such as a  Structure  score of 0.9122. The ablation study further supports this. When the taxonomy is removed, the structure score drops significantly (as in  Table   2 ). This demonstrates that the taxonomy tree plays a critical role in organizing and guiding the content generation process, especially when maintaining a clear structure is crucial for a literature review. The taxonomy ensures more coherent and relevant summaries. Without providing the taxonomy tree, the generation loses its hierarchical guidance, leading to less structured and less comprehensive content."
        ]
    },
    "id_table_3": {
        "caption": "Table 5:  Performance of different GNN on hierarchical clustering.",
        "table": "S5.SS3.fig1.1",
        "footnotes": [],
        "references": [
            "where  N  ( u ) N u \\mathcal{N}(u) caligraphic_N ( italic_u )  denotes the set of neighbors of  u u u italic_u  in  G G G italic_G , and    \\alpha italic_  is a pre-defined weighting factor that controls the influence of neighboring papers. We empirically find that aggregating the relevance scores of neighbors leads to a significant improvement in retrieval accuracy. This approach is effective because the relevance of a papers neighbors offers valuable contextual information that enhances its overall relevance to the topic. Further details are provided in  Appendix   A.3 . The top- k k k italic_k  nodes with the highest aggregated scores are selected to form the subset  V  superscript V  V^{\\prime} italic_V start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT . Subsequently, we construct the subgraph  G   ( V  , E  , { T u } u  V  ) superscript G  superscript V  superscript E  subscript subscript T u u superscript V  G^{\\prime}(V^{\\prime},E^{\\prime},\\{T_{u}\\}_{u\\in V^{\\prime}}) italic_G start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_V start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , italic_E start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , { italic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_u  italic_V start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) , where  V  superscript V  V^{\\prime} italic_V start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  is the set of selected nodes,  E  = { ( u , v )  E  u , v  V  } superscript E  conditional-set u v E u v superscript V  E^{\\prime}=\\{(u,v)\\in E\\mid u,v\\in V^{\\prime}\\} italic_E start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT = { ( italic_u , italic_v )  italic_E  italic_u , italic_v  italic_V start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT } . We retain only the edges between the selected top- k k k italic_k  papers, thereby preserving the citation relationships among the most relevant papers.",
            "RQ1.  We consider two baseline methods for the hierarchical clustering module: one that utilizes an LLM (i.e., GPT-4o) to cluster papers and another that applies  K K K italic_K -means, adjusting the number of clusters to represent different levels. However, neither method can be jointly trained with the topic generator. Even disregarding the training requirement, the hierarchical nature of the literature reviews taxonomy tree requires soft clustering at the initial layer and hard clustering at subsequent layersan issue that no existing work addresses. As shown in  Table   3 , when considering the clustering task alone, both baselines underperform compared to our hierarchical approach. Although the LLM is prompted to perform soft clustering at the first level, offering a slight improvement over  K K K italic_K -means, it still does not achieve the effectiveness of our hierarchical clustering approach.",
            "Comparison.  As illustrated in  Fig.   4  and  Fig.   5 , both the human-designed taxonomy and the taxonomy generated by HiReview for Lifelong Learning of LLMs provide a clear and cohesive hierarchical structure. In contrast, the outline in  Fig.   3  covers plausible approaches and concepts related to lifelong learning and organizes these elements. The outline provides a broad structure covering everything from basics to future trends. For instance, it includes  Introduction  and  Future Directions and Emerging Trends , allowing for an overview of the literature review. The taxonomy clearly outlines specific applications like  Continual Relation Extraction , allowing for a more focused discussion on particular areas of lifelong learning. Therefore, use outline-then-generation for comprehensive, structured reviews that cover both theoretical and practical aspects, making it particularly effective for diverse audiences. In contrast, use taxonomy-then-generation for more focused, task-specific reviews, especially when the emphasis is on core concepts, and the audience is already familiar with the basics of a specific domain."
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "A1.T4.1",
        "footnotes": [],
        "references": [
            "In this section, we present our  taxonomy-then-generation  framework ( Fig.   2 ). First, we introduce a graph retrieval strategy to address  Challenge 1 , which aggregates neighbor relevance scores during retrieval ( Section   4.1 ). Next, we propose an end-to-end hierarchical taxonomy tree generation model, consisting of hierarchical clustering and hierarchical generation. Specifically, we introduce a novel hierarchical graph clustering approach that considers relationships between nodes across different levels of the hierarchy to tackle  Challenge 2  ( Section   4.2.1 ), categorizing papers in a citation network hierarchically. Then, in  Section   4.2.2 , we propose a bottom-up iterative generation approach to determine the central topic of each cluster at every hierarchical level, ultimately forming a taxonomy to address  Challenge 3 . Finally, we leverage the hierarchical taxonomy to guide the literature review generation process, producing high-quality, citation-aware literature reviews.",
            "We experimented with different retrieval models and strategies, testing two representative methods: the sparse retrieval model, BM25  (Robertson et al.,  2009 ) , and the dense retrieval model, SentenceBert  (Reimers,  2019 ) . In citation networks, neighbor information and the topological structure play a crucial role in retrieval, as papers on the same topic often cite each other. To assess the impact of using neighbor information, we applied two retrieval strategies for both models: one incorporating neighbor information as described in  Section   4.1  ( Retrieval w/ Neighbor ) and the other excluding neighbor information ( Retrieval w/o Neighbor ). Given a topic (specifically, the title of a review paper), we retrieved papers related to this topic from the citation network and measured the accuracy by calculating how many of the retrieved papers appeared in the references of the corresponding literature review. The number of retrieved papers was not fixed, but matched the reference count for each review paper.",
            "As shown in  Table   4 , SentenceBert consistently outperforms BM25 across all scales when neighbor information is not used. For example, in the  1-hop merged  case, SentenceBert achieves an accuracy of 0.5234, significantly higher than BM25s 0.3308. However, both methods show relatively low accuracy without neighbor information, and their performance declines as the size of citation networks increases, indicating that retrieving relevant papers becomes more challenging as the network expands. In contrast, BM25 significantly outperforms SentenceBert when neighbor information is utilized. For instance, in the  1-hop merged  case, BM25 reaches an accuracy of 0.7445, while SentenceBerts accuracy drops sharply to 0.2602. BM25 maintains much higher accuracy across all scales with neighbor information. BM25, as a sparse retrieval model, relies on exact term matches, which is particularly advantageous in structured environments like citation networks, where specific terms (e.g., paper titles or keywords) are highly relevant. The inclusion of neighbor information allows BM25 to better capture relationships between papers by focusing on direct term matches in titles or citations. When neighbor information is introduced, the context around the target paper becomes more critical. BM25 effectively leverages this by prioritizing exact matches from neighboring papers, while SentenceBert, which focuses on semantic similarity, may lose precision when handling a broader context that includes less directly related papers.",
            "Comparison.  As illustrated in  Fig.   4  and  Fig.   5 , both the human-designed taxonomy and the taxonomy generated by HiReview for Lifelong Learning of LLMs provide a clear and cohesive hierarchical structure. In contrast, the outline in  Fig.   3  covers plausible approaches and concepts related to lifelong learning and organizes these elements. The outline provides a broad structure covering everything from basics to future trends. For instance, it includes  Introduction  and  Future Directions and Emerging Trends , allowing for an overview of the literature review. The taxonomy clearly outlines specific applications like  Continual Relation Extraction , allowing for a more focused discussion on particular areas of lifelong learning. Therefore, use outline-then-generation for comprehensive, structured reviews that cover both theoretical and practical aspects, making it particularly effective for diverse audiences. In contrast, use taxonomy-then-generation for more focused, task-specific reviews, especially when the emphasis is on core concepts, and the audience is already familiar with the basics of a specific domain."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "A1.T5.1",
        "footnotes": [],
        "references": [
            "Pure LLMs and naive RAG-based LLMs struggle with both stability and performance, which makes them unreliable for consistent literature review generation. AutoSurvey reduces this instability through prompt design and multi-output generation, achieving  Structure  0.05 and  Relevance  0.04lower deviations than those of pure and naive RAG-based LLMs. HiReview, however, outperforms all other models across all metrics, with consistently low standard deviations. This demonstrates HiReviews superior stability and consistency in generating high-quality reviews ( RQ3 ). Its success can be attributed not only to HiReviews use of a graph-context-aware retrieval method but also to the taxonomy tree, which provides hierarchical context for domain-specific concerns within the large language model. A detailed analysis contrasting the  outline-then-generation  with the  taxonomy-then-generation , based on a specific generation example, is provided in  Appendix   A.5 . Furthermore, an example of the generation for a cluster with the central topic  Continual Text Classification  is included in  Appendix   A.7 .",
            "In addition to GAT  (Velickovic et al.,  2017 ) , we also explored other GNNs as graph encoders, i.e., GCN  (Kipf & Welling,  2016 )  and Graph Transformer  (Shi et al.,  2020 ) . The comparison results of these models on clustering are shown in  Table   5 .",
            "Comparison.  As illustrated in  Fig.   4  and  Fig.   5 , both the human-designed taxonomy and the taxonomy generated by HiReview for Lifelong Learning of LLMs provide a clear and cohesive hierarchical structure. In contrast, the outline in  Fig.   3  covers plausible approaches and concepts related to lifelong learning and organizes these elements. The outline provides a broad structure covering everything from basics to future trends. For instance, it includes  Introduction  and  Future Directions and Emerging Trends , allowing for an overview of the literature review. The taxonomy clearly outlines specific applications like  Continual Relation Extraction , allowing for a more focused discussion on particular areas of lifelong learning. Therefore, use outline-then-generation for comprehensive, structured reviews that cover both theoretical and practical aspects, making it particularly effective for diverse audiences. In contrast, use taxonomy-then-generation for more focused, task-specific reviews, especially when the emphasis is on core concepts, and the audience is already familiar with the basics of a specific domain."
        ]
    },
    "global_footnotes": [
        "Specifically, SentenceBert",
        "is used to generate the text embeddings.",
        "Specifically, we use LLaMA-2-7b and gpt-4o-2024-05-13."
    ]
}