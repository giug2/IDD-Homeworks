{
    "PAPER'S NUMBER OF TABLES": 7,
    "S3.T1": {
        "caption": "Table 1. Statistics of two newly constructed benchmarks: FedFR-Small (FedFR-S) and FedFR-Large (FedFR-L). The benchmarks contain training data in (a) and evaluation data in (b). We simulate real-world scenarios using Caucasian identities for the source domain and African identities for the target domain. For evaluation, we use the Test set to evaluate face verification and construct queries and galleries to evaluate face identification.",
        "table": "<table id=\"S3.T1.st1.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.st1.2.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.st1.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" rowspan=\"2\"><span id=\"S3.T1.st1.2.1.1.1.1\" class=\"ltx_text\">Benchmark</span></th>\n<th id=\"S3.T1.st1.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" colspan=\"2\">Source Domain</th>\n<th id=\"S3.T1.st1.2.1.1.3\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th id=\"S3.T1.st1.2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" colspan=\"2\">Target Domain</th>\n</tr>\n<tr id=\"S3.T1.st1.2.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.st1.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># IDs</th>\n<th id=\"S3.T1.st1.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># Images</th>\n<th id=\"S3.T1.st1.2.2.2.3\" class=\"ltx_td ltx_th ltx_th_column\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th id=\"S3.T1.st1.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># IDs</th>\n<th id=\"S3.T1.st1.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># Images</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.st1.2.3.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.st1.2.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">FedFR-S</td>\n<td id=\"S3.T1.st1.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7,000</td>\n<td id=\"S3.T1.st1.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">326,484</td>\n<td id=\"S3.T1.st1.2.3.1.4\" class=\"ltx_td ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S3.T1.st1.2.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7,000</td>\n<td id=\"S3.T1.st1.2.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">324,376</td>\n</tr>\n<tr id=\"S3.T1.st1.2.4.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.st1.2.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">FedFR-L</td>\n<td id=\"S3.T1.st1.2.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">87,072</td>\n<td id=\"S3.T1.st1.2.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">4,434,177</td>\n<td id=\"S3.T1.st1.2.4.2.4\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S3.T1.st1.2.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7,000</td>\n<td id=\"S3.T1.st1.2.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">324,376</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We construct two benchmarks for federated face recognition since little work has been devoted to it, except mentioned in (Hu\net al., 2020). We design the source and target domains to contain datasets with different races — Caucasian in the source domain and African in the target domain, simulating models trained in one region and deployed into another. To better evaluate the effectiveness of algorithms, these two benchmarks vary the amount of training data in the source domain, representing different capabilities of the pre-trained models. The details of the datasets are shown in Table  1(a). These benchmarks also include evaluation datasets for each domain in Table 1(b).",
            "Evaluation We evaluate the verification and identification performance of face recognition models using data from Racial Faces in-the-Wild (RFW) dataset (Wang\net al., 2019), as shown in Table 1(b). We use around 3K Caucasian identities and around 3K African identities to evaluate the performance of the source and target domains, respectively. For face verification, we present the verification accuracy and true acceptance rate (TAR) at false acceptance rates (FAR) of 0.1, 0.01, and 0.001. For face identification, we report the rank-1 accuracy by matching a query to a gallery of images. We use the whole test set to evaluate face verification performance and construct queries and galleries to evaluate face identification performance. The details of the construction are described in the supplementary."
        ]
    },
    "S3.T1.st1": {
        "caption": "(a) Training data of the benchmarks",
        "table": "<table id=\"S3.T1.st1.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.st1.2.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.st1.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" rowspan=\"2\"><span id=\"S3.T1.st1.2.1.1.1.1\" class=\"ltx_text\">Benchmark</span></th>\n<th id=\"S3.T1.st1.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" colspan=\"2\">Source Domain</th>\n<th id=\"S3.T1.st1.2.1.1.3\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th id=\"S3.T1.st1.2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" colspan=\"2\">Target Domain</th>\n</tr>\n<tr id=\"S3.T1.st1.2.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.st1.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># IDs</th>\n<th id=\"S3.T1.st1.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># Images</th>\n<th id=\"S3.T1.st1.2.2.2.3\" class=\"ltx_td ltx_th ltx_th_column\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th id=\"S3.T1.st1.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># IDs</th>\n<th id=\"S3.T1.st1.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># Images</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.st1.2.3.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.st1.2.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">FedFR-S</td>\n<td id=\"S3.T1.st1.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7,000</td>\n<td id=\"S3.T1.st1.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">326,484</td>\n<td id=\"S3.T1.st1.2.3.1.4\" class=\"ltx_td ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S3.T1.st1.2.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7,000</td>\n<td id=\"S3.T1.st1.2.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">324,376</td>\n</tr>\n<tr id=\"S3.T1.st1.2.4.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.st1.2.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">FedFR-L</td>\n<td id=\"S3.T1.st1.2.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">87,072</td>\n<td id=\"S3.T1.st1.2.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">4,434,177</td>\n<td id=\"S3.T1.st1.2.4.2.4\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S3.T1.st1.2.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7,000</td>\n<td id=\"S3.T1.st1.2.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">324,376</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We construct two benchmarks for federated face recognition since little work has been devoted to it, except mentioned in (Hu\net al., 2020). We design the source and target domains to contain datasets with different races — Caucasian in the source domain and African in the target domain, simulating models trained in one region and deployed into another. To better evaluate the effectiveness of algorithms, these two benchmarks vary the amount of training data in the source domain, representing different capabilities of the pre-trained models. The details of the datasets are shown in Table  1(a). These benchmarks also include evaluation datasets for each domain in Table 1(b).",
            "Evaluation We evaluate the verification and identification performance of face recognition models using data from Racial Faces in-the-Wild (RFW) dataset (Wang\net al., 2019), as shown in Table 1(b). We use around 3K Caucasian identities and around 3K African identities to evaluate the performance of the source and target domains, respectively. For face verification, we present the verification accuracy and true acceptance rate (TAR) at false acceptance rates (FAR) of 0.1, 0.01, and 0.001. For face identification, we report the rank-1 accuracy by matching a query to a gallery of images. We use the whole test set to evaluate face verification performance and construct queries and galleries to evaluate face identification performance. The details of the construction are described in the supplementary.",
            "FedFR-S Comparisons Table 2 compares models trained using different methods on the FedFR-S benchmark. The performance discrepancy between African and Caucasian of the Source-Only model is ∼similar-to\\sim19% while the difference in the Merge model is no more than 3%, revealing the severe impact of the domain shift problem. FedFR tackles the problem, improving ∼similar-to\\sim12% on verification accuracy and ∼similar-to\\sim44% on rank-1 accuracy of the target domain (African).\nAlthough it does not outperform the upper bound (Merge), it is close to the Target-Only model and is superior to Fine-tune, DAN, and DANN models. Additionally, fine-tuning boosts the performance on African dataset, but it suffers from catastrophic forgetting (Kirkpatrick et al., 2017) as shown in Figure 6. With the progress of more iterations of training on the African dataset, the model gradually forgets the knowledge learned from the Caucasian dataset,\ncausing performance decreases on Caucasian evaluation. We run the experiments with K=4𝐾4K=4 and λ=0.002𝜆0.002\\lambda=0.002 for DCL. We provide more results of verification rate at FAR=0.1, 0.01, and 0.001 in the supplementary.",
            "FedFR-L Comparisons Table 3 reports the experiment results on the FedFR-L benchmark with verification accuracy, verification rate at FAR=0.1, 0.01, and 0.001, and identification at rank-1. The impact of the domain shift problem is still significant, which leads to a ∼similar-to\\sim6% performance gap on verification accuracy between these two domains in the baseline. What stands out in the table is the performance of FedFR, which outperforms all other models on the target domain (African), at the same time, maintains good performance on the source domain. It demonstrates the significance of our method. On the contrary, despite that DAN and DANN retain the performance on the Caucasian dataset, they hardly improve the performance on the African dataset.",
            "Impact of Clustering Algorithm The clustering algorithm for pseudo label generation (Section 3.3) has a large impact on the overall performance of FedFR. As shown in Table 4, our enhanced clustering algorithm C-FINCH achieves better performance (F-score) than the other method on both FedFR-S and FedFR-L benchmarks. It leads to better performance of FedFR on the African dataset. Specifically, on the FedFR-L benchmark, C-FINCH outperforms FINCH (Sarfraz\net al., 2019) by over 10%. These experiments are run with K=4𝐾4K=4. Comprehensive results of verification rate at FAR=0.1, 0.01, 0.001 are provided in the supplementary.",
            "Table 5 shows the performance comparison of these four methods. Generally, the performance on the target domain (African) improves with each added component and reaches the peak with all components. Although DCL does result in superior performance under TAR@FAR=0.01 and 0.001 on the FedFR-S benchmark, it leads to the best performance on other evaluations on FedFR-S and all evaluations on FedFR-L. These results align with our intuition of DCL. We design DCL to tackle the unbalanced data problem between two domains. Since both domains on the FedFR-S benchmark contain equal data volume, it is expected that the effect of DCL on FedFR-S is not very obvious. Most importantly, DCL achieves the best results on the FedFR-L where the source domain contains more than 10x data than the target domain. Due to space constrains, we provide ablation studies on standard face recognition datasets (LFW (Huang\net al., 2007) and IJB-A (Klare et al., 2015)) in the supplementary."
        ]
    },
    "S3.T1.st2": {
        "caption": "(b) Evaluation data",
        "table": "<table id=\"S3.T1.st2.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.st2.2.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.st2.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" rowspan=\"2\"><span id=\"S3.T1.st2.2.1.1.1.1\" class=\"ltx_text\">Dataset</span></th>\n<th id=\"S3.T1.st2.2.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" rowspan=\"2\"><span id=\"S3.T1.st2.2.1.1.2.1\" class=\"ltx_text\">Domain</span></th>\n<th id=\"S3.T1.st2.2.1.1.3\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th id=\"S3.T1.st2.2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" colspan=\"2\">Test</th>\n<th id=\"S3.T1.st2.2.1.1.5\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th id=\"S3.T1.st2.2.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" colspan=\"2\">Query</th>\n<th id=\"S3.T1.st2.2.1.1.7\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th id=\"S3.T1.st2.2.1.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" colspan=\"2\">Gallery</th>\n</tr>\n<tr id=\"S3.T1.st2.2.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.st2.2.2.2.1\" class=\"ltx_td\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S3.T1.st2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># IDs</td>\n<td id=\"S3.T1.st2.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># Images</td>\n<td id=\"S3.T1.st2.2.2.2.4\" class=\"ltx_td\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S3.T1.st2.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># IDs</td>\n<td id=\"S3.T1.st2.2.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># Images</td>\n<td id=\"S3.T1.st2.2.2.2.7\" class=\"ltx_td\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S3.T1.st2.2.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># IDs</td>\n<td id=\"S3.T1.st2.2.2.2.9\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"># Images</td>\n</tr>\n<tr id=\"S3.T1.st2.2.3.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.st2.2.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Caucasian</th>\n<th id=\"S3.T1.st2.2.3.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Source</th>\n<th id=\"S3.T1.st2.2.3.3.3\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th id=\"S3.T1.st2.2.3.3.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">2,959</th>\n<th id=\"S3.T1.st2.2.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">10,196</th>\n<th id=\"S3.T1.st2.2.3.3.6\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th id=\"S3.T1.st2.2.3.3.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">2,793</th>\n<th id=\"S3.T1.st2.2.3.3.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">2,793</th>\n<th id=\"S3.T1.st2.2.3.3.9\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></th>\n<th id=\"S3.T1.st2.2.3.3.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">2,958</th>\n<th id=\"S3.T1.st2.2.3.3.11\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">6,387</th>\n</tr>\n<tr id=\"S3.T1.st2.2.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.st2.2.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">African</td>\n<td id=\"S3.T1.st2.2.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Target</td>\n<td id=\"S3.T1.st2.2.4.4.3\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S3.T1.st2.2.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">2,995</td>\n<td id=\"S3.T1.st2.2.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">10,415</td>\n<td id=\"S3.T1.st2.2.4.4.6\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S3.T1.st2.2.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">2,865</td>\n<td id=\"S3.T1.st2.2.4.4.8\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">2,865</td>\n<td id=\"S3.T1.st2.2.4.4.9\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"></td>\n<td id=\"S3.T1.st2.2.4.4.10\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">2,995</td>\n<td id=\"S3.T1.st2.2.4.4.11\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">6,770</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We construct two benchmarks for federated face recognition since little work has been devoted to it, except mentioned in (Hu\net al., 2020). We design the source and target domains to contain datasets with different races — Caucasian in the source domain and African in the target domain, simulating models trained in one region and deployed into another. To better evaluate the effectiveness of algorithms, these two benchmarks vary the amount of training data in the source domain, representing different capabilities of the pre-trained models. The details of the datasets are shown in Table  1(a). These benchmarks also include evaluation datasets for each domain in Table 1(b).",
            "Evaluation We evaluate the verification and identification performance of face recognition models using data from Racial Faces in-the-Wild (RFW) dataset (Wang\net al., 2019), as shown in Table 1(b). We use around 3K Caucasian identities and around 3K African identities to evaluate the performance of the source and target domains, respectively. For face verification, we present the verification accuracy and true acceptance rate (TAR) at false acceptance rates (FAR) of 0.1, 0.01, and 0.001. For face identification, we report the rank-1 accuracy by matching a query to a gallery of images. We use the whole test set to evaluate face verification performance and construct queries and galleries to evaluate face identification performance. The details of the construction are described in the supplementary.",
            "FedFR-S Comparisons Table 2 compares models trained using different methods on the FedFR-S benchmark. The performance discrepancy between African and Caucasian of the Source-Only model is ∼similar-to\\sim19% while the difference in the Merge model is no more than 3%, revealing the severe impact of the domain shift problem. FedFR tackles the problem, improving ∼similar-to\\sim12% on verification accuracy and ∼similar-to\\sim44% on rank-1 accuracy of the target domain (African).\nAlthough it does not outperform the upper bound (Merge), it is close to the Target-Only model and is superior to Fine-tune, DAN, and DANN models. Additionally, fine-tuning boosts the performance on African dataset, but it suffers from catastrophic forgetting (Kirkpatrick et al., 2017) as shown in Figure 6. With the progress of more iterations of training on the African dataset, the model gradually forgets the knowledge learned from the Caucasian dataset,\ncausing performance decreases on Caucasian evaluation. We run the experiments with K=4𝐾4K=4 and λ=0.002𝜆0.002\\lambda=0.002 for DCL. We provide more results of verification rate at FAR=0.1, 0.01, and 0.001 in the supplementary.",
            "FedFR-L Comparisons Table 3 reports the experiment results on the FedFR-L benchmark with verification accuracy, verification rate at FAR=0.1, 0.01, and 0.001, and identification at rank-1. The impact of the domain shift problem is still significant, which leads to a ∼similar-to\\sim6% performance gap on verification accuracy between these two domains in the baseline. What stands out in the table is the performance of FedFR, which outperforms all other models on the target domain (African), at the same time, maintains good performance on the source domain. It demonstrates the significance of our method. On the contrary, despite that DAN and DANN retain the performance on the Caucasian dataset, they hardly improve the performance on the African dataset.",
            "Impact of Clustering Algorithm The clustering algorithm for pseudo label generation (Section 3.3) has a large impact on the overall performance of FedFR. As shown in Table 4, our enhanced clustering algorithm C-FINCH achieves better performance (F-score) than the other method on both FedFR-S and FedFR-L benchmarks. It leads to better performance of FedFR on the African dataset. Specifically, on the FedFR-L benchmark, C-FINCH outperforms FINCH (Sarfraz\net al., 2019) by over 10%. These experiments are run with K=4𝐾4K=4. Comprehensive results of verification rate at FAR=0.1, 0.01, 0.001 are provided in the supplementary.",
            "Table 5 shows the performance comparison of these four methods. Generally, the performance on the target domain (African) improves with each added component and reaches the peak with all components. Although DCL does result in superior performance under TAR@FAR=0.01 and 0.001 on the FedFR-S benchmark, it leads to the best performance on other evaluations on FedFR-S and all evaluations on FedFR-L. These results align with our intuition of DCL. We design DCL to tackle the unbalanced data problem between two domains. Since both domains on the FedFR-S benchmark contain equal data volume, it is expected that the effect of DCL on FedFR-S is not very obvious. Most importantly, DCL achieves the best results on the FedFR-L where the source domain contains more than 10x data than the target domain. Due to space constrains, we provide ablation studies on standard face recognition datasets (LFW (Huang\net al., 2007) and IJB-A (Klare et al., 2015)) in the supplementary."
        ]
    },
    "S3.T2": {
        "caption": "Table 2. Face verification (ver.) accuracy and identification (id.) at rank-1 on the FedFR-S benchmark. Although FedFR does not outperform supervised training containing target dataset (Target-Only and Merge), it effectively improves the performance on the target domain (African) and outperforms other methods, with setting K=4𝐾4K=4 and λ=0.002𝜆0.002\\lambda=0.002.",
        "table": "<table id=\"S3.T2.9\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.9.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.9.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T2.9.1.1.1.1\" class=\"ltx_text\">Model</span></th>\n<th id=\"S3.T2.9.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">African (%)</th>\n<th id=\"S3.T2.9.1.1.3\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\"></th>\n<th id=\"S3.T2.9.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">Caucasian (%)</th>\n</tr>\n<tr id=\"S3.T2.9.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.9.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Ver.</th>\n<th id=\"S3.T2.9.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Id.</th>\n<th id=\"S3.T2.9.2.2.3\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S3.T2.9.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Ver.</th>\n<th id=\"S3.T2.9.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Id.</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.9.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.9.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Source-Only</th>\n<td id=\"S3.T2.9.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">70.40</td>\n<td id=\"S3.T2.9.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">26.42</td>\n<td id=\"S3.T2.9.3.1.4\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S3.T2.9.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">89.10</td>\n<td id=\"S3.T2.9.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">71.79</td>\n</tr>\n<tr id=\"S3.T2.9.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.9.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Target-Only</th>\n<td id=\"S3.T2.9.4.2.2\" class=\"ltx_td ltx_align_center\">83.35</td>\n<td id=\"S3.T2.9.4.2.3\" class=\"ltx_td ltx_align_center\">73.54</td>\n<td id=\"S3.T2.9.4.2.4\" class=\"ltx_td\"></td>\n<td id=\"S3.T2.9.4.2.5\" class=\"ltx_td ltx_align_center\">86.23</td>\n<td id=\"S3.T2.9.4.2.6\" class=\"ltx_td ltx_align_center\">46.26</td>\n</tr>\n<tr id=\"S3.T2.9.5.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.9.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Merge</th>\n<td id=\"S3.T2.9.5.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.9.5.3.2.1\" class=\"ltx_text ltx_font_bold\">89.40</span></td>\n<td id=\"S3.T2.9.5.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.9.5.3.3.1\" class=\"ltx_text ltx_font_bold\">84.75</span></td>\n<td id=\"S3.T2.9.5.3.4\" class=\"ltx_td\"></td>\n<td id=\"S3.T2.9.5.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.9.5.3.5.1\" class=\"ltx_text ltx_font_bold\">92.75</span></td>\n<td id=\"S3.T2.9.5.3.6\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.9.5.3.6.1\" class=\"ltx_text ltx_font_bold\">85.43</span></td>\n</tr>\n<tr id=\"S3.T2.9.6.4\" class=\"ltx_tr\">\n<th id=\"S3.T2.9.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Fine-tune</th>\n<td id=\"S3.T2.9.6.4.2\" class=\"ltx_td ltx_align_center\">81.07</td>\n<td id=\"S3.T2.9.6.4.3\" class=\"ltx_td ltx_align_center\">64.08</td>\n<td id=\"S3.T2.9.6.4.4\" class=\"ltx_td\"></td>\n<td id=\"S3.T2.9.6.4.5\" class=\"ltx_td ltx_align_center\">85.42</td>\n<td id=\"S3.T2.9.6.4.6\" class=\"ltx_td ltx_align_center\">67.60</td>\n</tr>\n<tr id=\"S3.T2.9.7.5\" class=\"ltx_tr\">\n<th id=\"S3.T2.9.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DAN</th>\n<td id=\"S3.T2.9.7.5.2\" class=\"ltx_td ltx_align_center\">73.57</td>\n<td id=\"S3.T2.9.7.5.3\" class=\"ltx_td ltx_align_center\">31.62</td>\n<td id=\"S3.T2.9.7.5.4\" class=\"ltx_td\"></td>\n<td id=\"S3.T2.9.7.5.5\" class=\"ltx_td ltx_align_center\">85.53</td>\n<td id=\"S3.T2.9.7.5.6\" class=\"ltx_td ltx_align_center\">62.37</td>\n</tr>\n<tr id=\"S3.T2.9.8.6\" class=\"ltx_tr\">\n<th id=\"S3.T2.9.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DANN</th>\n<td id=\"S3.T2.9.8.6.2\" class=\"ltx_td ltx_align_center\">72.38</td>\n<td id=\"S3.T2.9.8.6.3\" class=\"ltx_td ltx_align_center\">31.06</td>\n<td id=\"S3.T2.9.8.6.4\" class=\"ltx_td\"></td>\n<td id=\"S3.T2.9.8.6.5\" class=\"ltx_td ltx_align_center\">89.15</td>\n<td id=\"S3.T2.9.8.6.6\" class=\"ltx_td ltx_align_center\">70.49</td>\n</tr>\n<tr id=\"S3.T2.9.9.7\" class=\"ltx_tr\">\n<th id=\"S3.T2.9.9.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\">FedFR (Ours)</th>\n<td id=\"S3.T2.9.9.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">82.50</td>\n<td id=\"S3.T2.9.9.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">70.47</td>\n<td id=\"S3.T2.9.9.7.4\" class=\"ltx_td ltx_border_bb ltx_border_t\"></td>\n<td id=\"S3.T2.9.9.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">87.62</td>\n<td id=\"S3.T2.9.9.7.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">77.01</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "FedFR-S Comparisons Table 2 compares models trained using different methods on the FedFR-S benchmark. The performance discrepancy between African and Caucasian of the Source-Only model is ∼similar-to\\sim19% while the difference in the Merge model is no more than 3%, revealing the severe impact of the domain shift problem. FedFR tackles the problem, improving ∼similar-to\\sim12% on verification accuracy and ∼similar-to\\sim44% on rank-1 accuracy of the target domain (African).\nAlthough it does not outperform the upper bound (Merge), it is close to the Target-Only model and is superior to Fine-tune, DAN, and DANN models. Additionally, fine-tuning boosts the performance on African dataset, but it suffers from catastrophic forgetting (Kirkpatrick et al., 2017) as shown in Figure 6. With the progress of more iterations of training on the African dataset, the model gradually forgets the knowledge learned from the Caucasian dataset,\ncausing performance decreases on Caucasian evaluation. We run the experiments with K=4𝐾4K=4 and λ=0.002𝜆0.002\\lambda=0.002 for DCL. We provide more results of verification rate at FAR=0.1, 0.01, and 0.001 in the supplementary."
        ]
    },
    "S3.T3": {
        "caption": "Table 3. Performance of face verification and identification (Id.) on the FedFR-L benchmark. For verification, we present accuracy and true acceptance rate (TAR) at different false acceptance rates (FAR) of 0.1, 0.01, and 0.001. FedFR significantly improves the performance on the target domain (African), even outperforming the Merge model. It almost maintains the performance on the source domain (Caucasian) at the same time, with setting K=1𝐾1K=1 and λ=0.01𝜆0.01\\lambda=0.01.",
        "table": "<table id=\"S3.T3.8\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T3.8.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.8.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"3\"><span id=\"S3.T3.8.1.1.1.1\" class=\"ltx_text\">Model</span></th>\n<th id=\"S3.T3.8.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"6\">African (%)</th>\n<th id=\"S3.T3.8.1.1.3\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\"></th>\n<th id=\"S3.T3.8.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"6\">Caucasian (%)</th>\n</tr>\n<tr id=\"S3.T3.8.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T3.8.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"4\">Verification</th>\n<th id=\"S3.T3.8.2.2.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\"></th>\n<th id=\"S3.T3.8.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Id.</th>\n<th id=\"S3.T3.8.2.2.4\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S3.T3.8.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"4\">Verification</th>\n<th id=\"S3.T3.8.2.2.6\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\"></th>\n<th id=\"S3.T3.8.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Id.</th>\n</tr>\n<tr id=\"S3.T3.8.3.3\" class=\"ltx_tr\">\n<th id=\"S3.T3.8.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Acc</th>\n<th id=\"S3.T3.8.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">0.1</th>\n<th id=\"S3.T3.8.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">0.01</th>\n<th id=\"S3.T3.8.3.3.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">0.001</th>\n<th id=\"S3.T3.8.3.3.5\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S3.T3.8.3.3.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Rank-1</th>\n<th id=\"S3.T3.8.3.3.7\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S3.T3.8.3.3.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Acc</th>\n<th id=\"S3.T3.8.3.3.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">0.1</th>\n<th id=\"S3.T3.8.3.3.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">0.01</th>\n<th id=\"S3.T3.8.3.3.11\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">0.001</th>\n<th id=\"S3.T3.8.3.3.12\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S3.T3.8.3.3.13\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Rank-1</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.8.4.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.8.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Source-Only</th>\n<td id=\"S3.T3.8.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">86.65</td>\n<td id=\"S3.T3.8.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">83.27</td>\n<td id=\"S3.T3.8.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">55.93</td>\n<td id=\"S3.T3.8.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">37.80</td>\n<td id=\"S3.T3.8.4.1.6\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S3.T3.8.4.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">82.13</td>\n<td id=\"S3.T3.8.4.1.8\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S3.T3.8.4.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">94.47</td>\n<td id=\"S3.T3.8.4.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\">95.67</td>\n<td id=\"S3.T3.8.4.1.11\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.8.4.1.11.1\" class=\"ltx_text ltx_font_bold\">87.53</span></td>\n<td id=\"S3.T3.8.4.1.12\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.8.4.1.12.1\" class=\"ltx_text ltx_font_bold\">76.67</span></td>\n<td id=\"S3.T3.8.4.1.13\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S3.T3.8.4.1.14\" class=\"ltx_td ltx_align_center ltx_border_t\">93.52</td>\n</tr>\n<tr id=\"S3.T3.8.5.2\" class=\"ltx_tr\">\n<th id=\"S3.T3.8.5.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Target-Only</th>\n<td id=\"S3.T3.8.5.2.2\" class=\"ltx_td ltx_align_center\">83.35</td>\n<td id=\"S3.T3.8.5.2.3\" class=\"ltx_td ltx_align_center\">75.6</td>\n<td id=\"S3.T3.8.5.2.4\" class=\"ltx_td ltx_align_center\">41.80</td>\n<td id=\"S3.T3.8.5.2.5\" class=\"ltx_td ltx_align_center\">22.00</td>\n<td id=\"S3.T3.8.5.2.6\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.5.2.7\" class=\"ltx_td ltx_align_center\">73.54</td>\n<td id=\"S3.T3.8.5.2.8\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.5.2.9\" class=\"ltx_td ltx_align_center\">86.23</td>\n<td id=\"S3.T3.8.5.2.10\" class=\"ltx_td ltx_align_center\">81.93</td>\n<td id=\"S3.T3.8.5.2.11\" class=\"ltx_td ltx_align_center\">54.83</td>\n<td id=\"S3.T3.8.5.2.12\" class=\"ltx_td ltx_align_center\">38.27</td>\n<td id=\"S3.T3.8.5.2.13\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.5.2.14\" class=\"ltx_td ltx_align_center\">46.26</td>\n</tr>\n<tr id=\"S3.T3.8.6.3\" class=\"ltx_tr\">\n<th id=\"S3.T3.8.6.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Merge</th>\n<td id=\"S3.T3.8.6.3.2\" class=\"ltx_td ltx_align_center\">88.60</td>\n<td id=\"S3.T3.8.6.3.3\" class=\"ltx_td ltx_align_center\">87.00</td>\n<td id=\"S3.T3.8.6.3.4\" class=\"ltx_td ltx_align_center\">66.90</td>\n<td id=\"S3.T3.8.6.3.5\" class=\"ltx_td ltx_align_center\">48.10</td>\n<td id=\"S3.T3.8.6.3.6\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.6.3.7\" class=\"ltx_td ltx_align_center\">89.04</td>\n<td id=\"S3.T3.8.6.3.8\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.6.3.9\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T3.8.6.3.9.1\" class=\"ltx_text ltx_font_bold\">94.78</span></td>\n<td id=\"S3.T3.8.6.3.10\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T3.8.6.3.10.1\" class=\"ltx_text ltx_font_bold\">96.60</span></td>\n<td id=\"S3.T3.8.6.3.11\" class=\"ltx_td ltx_align_center\">85.63</td>\n<td id=\"S3.T3.8.6.3.12\" class=\"ltx_td ltx_align_center\">74.43</td>\n<td id=\"S3.T3.8.6.3.13\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.6.3.14\" class=\"ltx_td ltx_align_center\">94.38</td>\n</tr>\n<tr id=\"S3.T3.8.7.4\" class=\"ltx_tr\">\n<th id=\"S3.T3.8.7.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Fine-tune</th>\n<td id=\"S3.T3.8.7.4.2\" class=\"ltx_td ltx_align_center\">88.72</td>\n<td id=\"S3.T3.8.7.4.3\" class=\"ltx_td ltx_align_center\">87.10</td>\n<td id=\"S3.T3.8.7.4.4\" class=\"ltx_td ltx_align_center\">62.23</td>\n<td id=\"S3.T3.8.7.4.5\" class=\"ltx_td ltx_align_center\">35.95</td>\n<td id=\"S3.T3.8.7.4.6\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.7.4.7\" class=\"ltx_td ltx_align_center\">84.05</td>\n<td id=\"S3.T3.8.7.4.8\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.7.4.9\" class=\"ltx_td ltx_align_center\">87.73</td>\n<td id=\"S3.T3.8.7.4.10\" class=\"ltx_td ltx_align_center\">85.87</td>\n<td id=\"S3.T3.8.7.4.11\" class=\"ltx_td ltx_align_center\">62.87</td>\n<td id=\"S3.T3.8.7.4.12\" class=\"ltx_td ltx_align_center\">39.77</td>\n<td id=\"S3.T3.8.7.4.13\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.7.4.14\" class=\"ltx_td ltx_align_center\">77.77</td>\n</tr>\n<tr id=\"S3.T3.8.8.5\" class=\"ltx_tr\">\n<th id=\"S3.T3.8.8.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DAN</th>\n<td id=\"S3.T3.8.8.5.2\" class=\"ltx_td ltx_align_center\">86.98</td>\n<td id=\"S3.T3.8.8.5.3\" class=\"ltx_td ltx_align_center\">83.87</td>\n<td id=\"S3.T3.8.8.5.4\" class=\"ltx_td ltx_align_center\">61.73</td>\n<td id=\"S3.T3.8.8.5.5\" class=\"ltx_td ltx_align_center\">41.43</td>\n<td id=\"S3.T3.8.8.5.6\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.8.5.7\" class=\"ltx_td ltx_align_center\">83.18</td>\n<td id=\"S3.T3.8.8.5.8\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.8.5.9\" class=\"ltx_td ltx_align_center\">94.07</td>\n<td id=\"S3.T3.8.8.5.10\" class=\"ltx_td ltx_align_center\">95.43</td>\n<td id=\"S3.T3.8.8.5.11\" class=\"ltx_td ltx_align_center\">85.20</td>\n<td id=\"S3.T3.8.8.5.12\" class=\"ltx_td ltx_align_center\">72.13</td>\n<td id=\"S3.T3.8.8.5.13\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.8.5.14\" class=\"ltx_td ltx_align_center\">93.30</td>\n</tr>\n<tr id=\"S3.T3.8.9.6\" class=\"ltx_tr\">\n<th id=\"S3.T3.8.9.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DANN</th>\n<td id=\"S3.T3.8.9.6.2\" class=\"ltx_td ltx_align_center\">86.77</td>\n<td id=\"S3.T3.8.9.6.3\" class=\"ltx_td ltx_align_center\">83.23</td>\n<td id=\"S3.T3.8.9.6.4\" class=\"ltx_td ltx_align_center\">60.80</td>\n<td id=\"S3.T3.8.9.6.5\" class=\"ltx_td ltx_align_center\">44.90</td>\n<td id=\"S3.T3.8.9.6.6\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.9.6.7\" class=\"ltx_td ltx_align_center\">82.23</td>\n<td id=\"S3.T3.8.9.6.8\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.9.6.9\" class=\"ltx_td ltx_align_center\">93.98</td>\n<td id=\"S3.T3.8.9.6.10\" class=\"ltx_td ltx_align_center\">96.03</td>\n<td id=\"S3.T3.8.9.6.11\" class=\"ltx_td ltx_align_center\">86.23</td>\n<td id=\"S3.T3.8.9.6.12\" class=\"ltx_td ltx_align_center\">73.97</td>\n<td id=\"S3.T3.8.9.6.13\" class=\"ltx_td\"></td>\n<td id=\"S3.T3.8.9.6.14\" class=\"ltx_td ltx_align_center\">93.59</td>\n</tr>\n<tr id=\"S3.T3.8.10.7\" class=\"ltx_tr\">\n<th id=\"S3.T3.8.10.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\">FedFR (Ours)</th>\n<td id=\"S3.T3.8.10.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T3.8.10.7.2.1\" class=\"ltx_text ltx_font_bold\">91.55</span></td>\n<td id=\"S3.T3.8.10.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T3.8.10.7.3.1\" class=\"ltx_text ltx_font_bold\">91.57</span></td>\n<td id=\"S3.T3.8.10.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T3.8.10.7.4.1\" class=\"ltx_text ltx_font_bold\">76.97</span></td>\n<td id=\"S3.T3.8.10.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T3.8.10.7.5.1\" class=\"ltx_text ltx_font_bold\">49.40</span></td>\n<td id=\"S3.T3.8.10.7.6\" class=\"ltx_td ltx_border_bb ltx_border_t\"></td>\n<td id=\"S3.T3.8.10.7.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T3.8.10.7.7.1\" class=\"ltx_text ltx_font_bold\">93.26</span></td>\n<td id=\"S3.T3.8.10.7.8\" class=\"ltx_td ltx_border_bb ltx_border_t\"></td>\n<td id=\"S3.T3.8.10.7.9\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">94.25</td>\n<td id=\"S3.T3.8.10.7.10\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">96.00</td>\n<td id=\"S3.T3.8.10.7.11\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">85.60</td>\n<td id=\"S3.T3.8.10.7.12\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">70.93</td>\n<td id=\"S3.T3.8.10.7.13\" class=\"ltx_td ltx_border_bb ltx_border_t\"></td>\n<td id=\"S3.T3.8.10.7.14\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T3.8.10.7.14.1\" class=\"ltx_text ltx_font_bold\">94.99</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "FedFR-L Comparisons Table 3 reports the experiment results on the FedFR-L benchmark with verification accuracy, verification rate at FAR=0.1, 0.01, and 0.001, and identification at rank-1. The impact of the domain shift problem is still significant, which leads to a ∼similar-to\\sim6% performance gap on verification accuracy between these two domains in the baseline. What stands out in the table is the performance of FedFR, which outperforms all other models on the target domain (African), at the same time, maintains good performance on the source domain. It demonstrates the significance of our method. On the contrary, despite that DAN and DANN retain the performance on the Caucasian dataset, they hardly improve the performance on the African dataset."
        ]
    },
    "S4.T4": {
        "caption": "Table 4. Performance comparison of different clustering algorithms. Our enhanced C-FINCH outperforms K-means and DBSCAN even without relying on prior knowledge of the dataset. It greatly outperforms FINCH on the FedFR-L benchmark.",
        "table": "<table id=\"S4.T4.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.4.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:5.5pt;padding-right:5.5pt;\" rowspan=\"2\"><span id=\"S4.T4.4.1.1.1.1\" class=\"ltx_text\">Benchmark</span></th>\n<th id=\"S4.T4.4.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:5.5pt;padding-right:5.5pt;\" rowspan=\"2\"><span id=\"S4.T4.4.1.1.2.1\" class=\"ltx_text\">Algorithm</span></th>\n<th id=\"S4.T4.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.5pt;padding-right:5.5pt;\" rowspan=\"2\"><span id=\"S4.T4.4.1.1.3.1\" class=\"ltx_text\">F-score (%)</span></th>\n<th id=\"S4.T4.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:5.5pt;padding-right:5.5pt;\" colspan=\"2\">African (%)</th>\n</tr>\n<tr id=\"S4.T4.4.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">Ver.</th>\n<th id=\"S4.T4.4.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">Id.</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.4.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\" rowspan=\"4\"><span id=\"S4.T4.4.3.1.1.1\" class=\"ltx_text\">FedFR-S</span></th>\n<th id=\"S4.T4.4.3.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">DBSCAN <cite class=\"ltx_cite ltx_citemacro_citep\">(Ester et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">1996</a>)</cite>\n</th>\n<td id=\"S4.T4.4.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">51.04</td>\n<td id=\"S4.T4.4.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">61.18</td>\n<td id=\"S4.T4.4.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">15.43</td>\n</tr>\n<tr id=\"S4.T4.4.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">K-means <cite class=\"ltx_cite ltx_citemacro_citep\">(MacQueen\net al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">1967</a>)</cite>\n</th>\n<td id=\"S4.T4.4.4.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">60.87</td>\n<td id=\"S4.T4.4.4.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">80.45</td>\n<td id=\"S4.T4.4.4.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">64.08</td>\n</tr>\n<tr id=\"S4.T4.4.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">FINCH <cite class=\"ltx_cite ltx_citemacro_citep\">(Sarfraz\net al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">2019</a>)</cite>\n</th>\n<td id=\"S4.T4.4.5.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">64.62</td>\n<td id=\"S4.T4.4.5.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">81.42</td>\n<td id=\"S4.T4.4.5.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">60.31</td>\n</tr>\n<tr id=\"S4.T4.4.6.4\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">C-FINCH</th>\n<td id=\"S4.T4.4.6.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span id=\"S4.T4.4.6.4.2.1\" class=\"ltx_text ltx_font_bold\">64.65</span></td>\n<td id=\"S4.T4.4.6.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span id=\"S4.T4.4.6.4.3.1\" class=\"ltx_text ltx_font_bold\">82.18</span></td>\n<td id=\"S4.T4.4.6.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span id=\"S4.T4.4.6.4.4.1\" class=\"ltx_text ltx_font_bold\">69.42</span></td>\n</tr>\n<tr id=\"S4.T4.4.7.5\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.7.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\" rowspan=\"4\"><span id=\"S4.T4.4.7.5.1.1\" class=\"ltx_text\">FedFR-L</span></th>\n<th id=\"S4.T4.4.7.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">DBSCAN <cite class=\"ltx_cite ltx_citemacro_citep\">(Ester et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">1996</a>)</cite>\n</th>\n<td id=\"S4.T4.4.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">84.42</td>\n<td id=\"S4.T4.4.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">86.75</td>\n<td id=\"S4.T4.4.7.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">88.73</td>\n</tr>\n<tr id=\"S4.T4.4.8.6\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">K-means <cite class=\"ltx_cite ltx_citemacro_citep\">(MacQueen\net al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">1967</a>)</cite>\n</th>\n<td id=\"S4.T4.4.8.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">87.17</td>\n<td id=\"S4.T4.4.8.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">89.99</td>\n<td id=\"S4.T4.4.8.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">87.96</td>\n</tr>\n<tr id=\"S4.T4.4.9.7\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.9.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">FINCH <cite class=\"ltx_cite ltx_citemacro_citep\">(Sarfraz\net al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">2019</a>)</cite>\n</th>\n<td id=\"S4.T4.4.9.7.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">70.08</td>\n<td id=\"S4.T4.4.9.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">87.58</td>\n<td id=\"S4.T4.4.9.7.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">81.61</td>\n</tr>\n<tr id=\"S4.T4.4.10.8\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.10.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">C-FINCH</th>\n<td id=\"S4.T4.4.10.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span id=\"S4.T4.4.10.8.2.1\" class=\"ltx_text ltx_font_bold\">91.54</span></td>\n<td id=\"S4.T4.4.10.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span id=\"S4.T4.4.10.8.3.1\" class=\"ltx_text ltx_font_bold\">90.43</span></td>\n<td id=\"S4.T4.4.10.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span id=\"S4.T4.4.10.8.4.1\" class=\"ltx_text ltx_font_bold\">91.24</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Impact of Clustering Algorithm The clustering algorithm for pseudo label generation (Section 3.3) has a large impact on the overall performance of FedFR. As shown in Table 4, our enhanced clustering algorithm C-FINCH achieves better performance (F-score) than the other method on both FedFR-S and FedFR-L benchmarks. It leads to better performance of FedFR on the African dataset. Specifically, on the FedFR-L benchmark, C-FINCH outperforms FINCH (Sarfraz\net al., 2019) by over 10%. These experiments are run with K=4𝐾4K=4. Comprehensive results of verification rate at FAR=0.1, 0.01, 0.001 are provided in the supplementary."
        ]
    },
    "S4.T5": {
        "caption": "Table 5. Ablation study of FedFR on the FedFR-S and FedFR-L benchmarks. Each added component improves the performance on the African dataset on the FedFR-L benchmark. The impact of domain constraint loss (DCL) on the FedFR-S is not as strong as on the FedFR-L because the data is balanced between domains on the FedFR-S benchmark.",
        "table": "<table id=\"S4.T5.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.4.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" rowspan=\"2\"><span id=\"S4.T5.4.1.1.1.1\" class=\"ltx_text\">Training Method</span></th>\n<th id=\"S4.T5.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" colspan=\"5\">African (%)</th>\n<td id=\"S4.T5.4.1.1.3\" class=\"ltx_td ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Acc</th>\n<th id=\"S4.T5.4.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">0.1</th>\n<th id=\"S4.T5.4.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">0.01</th>\n<th id=\"S4.T5.4.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">0.001</th>\n<th id=\"S4.T5.4.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Rank-1</th>\n<td id=\"S4.T5.4.2.2.6\" class=\"ltx_td\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.3.3.1.1\" class=\"ltx_text ltx_font_italic\">FedFR-S Benchmark</span></th>\n<th id=\"S4.T5.4.3.3.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></th>\n<th id=\"S4.T5.4.3.3.3\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></th>\n<th id=\"S4.T5.4.3.3.4\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></th>\n<th id=\"S4.T5.4.3.3.5\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></th>\n<th id=\"S4.T5.4.3.3.6\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></th>\n<td id=\"S4.T5.4.3.3.7\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Pre-training (P)</th>\n<td id=\"S4.T5.4.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">70.40</td>\n<td id=\"S4.T5.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">46.23</td>\n<td id=\"S4.T5.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">14.60</td>\n<td id=\"S4.T5.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">3.80</td>\n<td id=\"S4.T5.4.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">26.42</td>\n<td id=\"S4.T5.4.4.4.7\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">P + Clustering (C)</th>\n<td id=\"S4.T5.4.5.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">81.07</td>\n<td id=\"S4.T5.4.5.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">70.40</td>\n<td id=\"S4.T5.4.5.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">41.23</td>\n<td id=\"S4.T5.4.5.5.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.5.5.5.1\" class=\"ltx_text ltx_font_bold\">22.57</span></td>\n<td id=\"S4.T5.4.5.5.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">64.08</td>\n<td id=\"S4.T5.4.5.5.7\" class=\"ltx_td\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">P + C + FL</th>\n<td id=\"S4.T5.4.6.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">82.18</td>\n<td id=\"S4.T5.4.6.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">74.50</td>\n<td id=\"S4.T5.4.6.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.6.6.4.1\" class=\"ltx_text ltx_font_bold\">44.23</span></td>\n<td id=\"S4.T5.4.6.6.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">20.30</td>\n<td id=\"S4.T5.4.6.6.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">69.42</td>\n<td id=\"S4.T5.4.6.6.7\" class=\"ltx_td\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">P + C + FL + DCL</th>\n<td id=\"S4.T5.4.7.7.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.7.7.2.1\" class=\"ltx_text ltx_font_bold\">82.50</span></td>\n<td id=\"S4.T5.4.7.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.7.7.3.1\" class=\"ltx_text ltx_font_bold\">74.93</span></td>\n<td id=\"S4.T5.4.7.7.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">41.80</td>\n<td id=\"S4.T5.4.7.7.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">21.50</td>\n<td id=\"S4.T5.4.7.7.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.7.7.6.1\" class=\"ltx_text ltx_font_bold\">70.47</span></td>\n<td id=\"S4.T5.4.7.7.7\" class=\"ltx_td\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.8.8.1.1\" class=\"ltx_text ltx_font_italic\">FedFR-L Benchmark</span></th>\n<td id=\"S4.T5.4.8.8.2\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n<td id=\"S4.T5.4.8.8.3\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n<td id=\"S4.T5.4.8.8.4\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n<td id=\"S4.T5.4.8.8.5\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n<td id=\"S4.T5.4.8.8.6\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n<td id=\"S4.T5.4.8.8.7\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.9.9\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Pre-training (P)</th>\n<td id=\"S4.T5.4.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">86.65</td>\n<td id=\"S4.T5.4.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">83.27</td>\n<td id=\"S4.T5.4.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">55.93</td>\n<td id=\"S4.T5.4.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">37.80</td>\n<td id=\"S4.T5.4.9.9.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">82.13</td>\n<td id=\"S4.T5.4.9.9.7\" class=\"ltx_td ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.10.10\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">P + Clustering (C)</th>\n<td id=\"S4.T5.4.10.10.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">88.72</td>\n<td id=\"S4.T5.4.10.10.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">87.10</td>\n<td id=\"S4.T5.4.10.10.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">62.23</td>\n<td id=\"S4.T5.4.10.10.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">35.95</td>\n<td id=\"S4.T5.4.10.10.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">84.05</td>\n<td id=\"S4.T5.4.10.10.7\" class=\"ltx_td\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.11.11\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.11.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">P + C + FL</th>\n<td id=\"S4.T5.4.11.11.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">91.12</td>\n<td id=\"S4.T5.4.11.11.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">91.10</td>\n<td id=\"S4.T5.4.11.11.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">70.73</td>\n<td id=\"S4.T5.4.11.11.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">45.5</td>\n<td id=\"S4.T5.4.11.11.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">92.47</td>\n<td id=\"S4.T5.4.11.11.7\" class=\"ltx_td\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n<tr id=\"S4.T5.4.12.12\" class=\"ltx_tr\">\n<th id=\"S4.T5.4.12.12.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">P + C + FL + DCL</th>\n<td id=\"S4.T5.4.12.12.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.12.12.2.1\" class=\"ltx_text ltx_font_bold\">91.55</span></td>\n<td id=\"S4.T5.4.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.12.12.3.1\" class=\"ltx_text ltx_font_bold\">91.57</span></td>\n<td id=\"S4.T5.4.12.12.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.12.12.4.1\" class=\"ltx_text ltx_font_bold\">76.97</span></td>\n<td id=\"S4.T5.4.12.12.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.12.12.5.1\" class=\"ltx_text ltx_font_bold\">49.40</span></td>\n<td id=\"S4.T5.4.12.12.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"><span id=\"S4.T5.4.12.12.6.1\" class=\"ltx_text ltx_font_bold\">93.26</span></td>\n<td id=\"S4.T5.4.12.12.7\" class=\"ltx_td ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 5 shows the performance comparison of these four methods. Generally, the performance on the target domain (African) improves with each added component and reaches the peak with all components. Although DCL does result in superior performance under TAR@FAR=0.01 and 0.001 on the FedFR-S benchmark, it leads to the best performance on other evaluations on FedFR-S and all evaluations on FedFR-L. These results align with our intuition of DCL. We design DCL to tackle the unbalanced data problem between two domains. Since both domains on the FedFR-S benchmark contain equal data volume, it is expected that the effect of DCL on FedFR-S is not very obvious. Most importantly, DCL achieves the best results on the FedFR-L where the source domain contains more than 10x data than the target domain. Due to space constrains, we provide ablation studies on standard face recognition datasets (LFW (Huang\net al., 2007) and IJB-A (Klare et al., 2015)) in the supplementary."
        ]
    }
}