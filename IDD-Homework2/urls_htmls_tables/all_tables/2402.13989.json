{
    "PAPER'S NUMBER OF TABLES": 2,
    "S4.T1": {
        "caption": "Table 1: Dataset parameters and FL training parameters.",
        "table": "<table id=\"S4.T1.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.5.6.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.5.6.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S4.T1.5.6.1.1.1\" class=\"ltx_text ltx_font_bold\">Parameters</span></th>\n<td id=\"S4.T1.5.6.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S4.T1.5.6.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T1.5.6.1.2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.5.6.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Example 1</td>\n</tr>\n<tr id=\"S4.T1.5.6.1.2.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.5.6.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Linear regression</td>\n</tr>\n</table>\n</td>\n<td id=\"S4.T1.5.6.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<table id=\"S4.T1.5.6.1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T1.5.6.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.5.6.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Example 2</td>\n</tr>\n<tr id=\"S4.T1.5.6.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.5.6.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Image classification</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"S4.T1.5.7.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.5.7.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Training set size</th>\n<td id=\"S4.T1.5.7.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10000</td>\n<td id=\"S4.T1.5.7.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">10000</td>\n</tr>\n<tr id=\"S4.T1.5.8.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.5.8.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Test set size</th>\n<td id=\"S4.T1.5.8.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S4.T1.5.8.3.3\" class=\"ltx_td ltx_align_center\">1000</td>\n</tr>\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Data dimension</th>\n<td id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r\">1000</td>\n<td id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"28\\times 28\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mrow id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\"><mn id=\"S4.T1.1.1.1.m1.1.1.2\" xref=\"S4.T1.1.1.1.m1.1.1.2.cmml\">28</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S4.T1.1.1.1.m1.1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.1.cmml\">×</mo><mn id=\"S4.T1.1.1.1.m1.1.1.3\" xref=\"S4.T1.1.1.1.m1.1.1.3.cmml\">28</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><apply id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\"><times id=\"S4.T1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"S4.T1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.2\">28</cn><cn type=\"integer\" id=\"S4.T1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.3\">28</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">28\\times 28</annotation></semantics></math></td>\n</tr>\n<tr id=\"S4.T1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Communication rounds <math id=\"S4.T1.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S4.T1.2.2.1.m1.1a\"><mi id=\"S4.T1.2.2.1.m1.1.1\" xref=\"S4.T1.2.2.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.2.2.1.m1.1b\"><ci id=\"S4.T1.2.2.1.m1.1.1.cmml\" xref=\"S4.T1.2.2.1.m1.1.1\">𝐾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.2.2.1.m1.1c\">K</annotation></semantics></math>\n</th>\n<td id=\"S4.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">100</td>\n<td id=\"S4.T1.2.2.3\" class=\"ltx_td ltx_align_center\">200</td>\n</tr>\n<tr id=\"S4.T1.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Number of clients <math id=\"S4.T1.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"m\" display=\"inline\"><semantics id=\"S4.T1.3.3.1.m1.1a\"><mi id=\"S4.T1.3.3.1.m1.1.1\" xref=\"S4.T1.3.3.1.m1.1.1.cmml\">m</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.3.3.1.m1.1b\"><ci id=\"S4.T1.3.3.1.m1.1.1.cmml\" xref=\"S4.T1.3.3.1.m1.1.1\">𝑚</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.3.3.1.m1.1c\">m</annotation></semantics></math>\n</th>\n<td id=\"S4.T1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">100</td>\n<td id=\"S4.T1.3.3.3\" class=\"ltx_td ltx_align_center\">100</td>\n</tr>\n<tr id=\"S4.T1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Client subset size <math id=\"S4.T1.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"|\\mathcal{M}^{k}|\" display=\"inline\"><semantics id=\"S4.T1.4.4.1.m1.1a\"><mrow id=\"S4.T1.4.4.1.m1.1.1.1\" xref=\"S4.T1.4.4.1.m1.1.1.2.cmml\"><mo stretchy=\"false\" id=\"S4.T1.4.4.1.m1.1.1.1.2\" xref=\"S4.T1.4.4.1.m1.1.1.2.1.cmml\">|</mo><msup id=\"S4.T1.4.4.1.m1.1.1.1.1\" xref=\"S4.T1.4.4.1.m1.1.1.1.1.cmml\"><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.T1.4.4.1.m1.1.1.1.1.2\" xref=\"S4.T1.4.4.1.m1.1.1.1.1.2.cmml\">ℳ</mi><mi id=\"S4.T1.4.4.1.m1.1.1.1.1.3\" xref=\"S4.T1.4.4.1.m1.1.1.1.1.3.cmml\">k</mi></msup><mo stretchy=\"false\" id=\"S4.T1.4.4.1.m1.1.1.1.3\" xref=\"S4.T1.4.4.1.m1.1.1.2.1.cmml\">|</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.4.4.1.m1.1b\"><apply id=\"S4.T1.4.4.1.m1.1.1.2.cmml\" xref=\"S4.T1.4.4.1.m1.1.1.1\"><abs id=\"S4.T1.4.4.1.m1.1.1.2.1.cmml\" xref=\"S4.T1.4.4.1.m1.1.1.1.2\"></abs><apply id=\"S4.T1.4.4.1.m1.1.1.1.1.cmml\" xref=\"S4.T1.4.4.1.m1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T1.4.4.1.m1.1.1.1.1.1.cmml\" xref=\"S4.T1.4.4.1.m1.1.1.1.1\">superscript</csymbol><ci id=\"S4.T1.4.4.1.m1.1.1.1.1.2.cmml\" xref=\"S4.T1.4.4.1.m1.1.1.1.1.2\">ℳ</ci><ci id=\"S4.T1.4.4.1.m1.1.1.1.1.3.cmml\" xref=\"S4.T1.4.4.1.m1.1.1.1.1.3\">𝑘</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.4.4.1.m1.1c\">|\\mathcal{M}^{k}|</annotation></semantics></math>\n</th>\n<td id=\"S4.T1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">10</td>\n<td id=\"S4.T1.4.4.3\" class=\"ltx_td ltx_align_center\">10</td>\n</tr>\n<tr id=\"S4.T1.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\">Client learning rate <math id=\"S4.T1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\eta_{i}\" display=\"inline\"><semantics id=\"S4.T1.5.5.1.m1.1a\"><msub id=\"S4.T1.5.5.1.m1.1.1\" xref=\"S4.T1.5.5.1.m1.1.1.cmml\"><mi id=\"S4.T1.5.5.1.m1.1.1.2\" xref=\"S4.T1.5.5.1.m1.1.1.2.cmml\">η</mi><mi id=\"S4.T1.5.5.1.m1.1.1.3\" xref=\"S4.T1.5.5.1.m1.1.1.3.cmml\">i</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.5.5.1.m1.1b\"><apply id=\"S4.T1.5.5.1.m1.1.1.cmml\" xref=\"S4.T1.5.5.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T1.5.5.1.m1.1.1.1.cmml\" xref=\"S4.T1.5.5.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T1.5.5.1.m1.1.1.2.cmml\" xref=\"S4.T1.5.5.1.m1.1.1.2\">𝜂</ci><ci id=\"S4.T1.5.5.1.m1.1.1.3.cmml\" xref=\"S4.T1.5.5.1.m1.1.1.3\">𝑖</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.5.5.1.m1.1c\">\\eta_{i}</annotation></semantics></math>\n</th>\n<td id=\"S4.T1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">0.01</td>\n<td id=\"S4.T1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_b\">0.01</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In each communication round, the server uniformly samples 10% of the clients to perform the local training. During the local training, the selected clients use full-batch gradient descent with a learning rate of 0.01. For the vanilla FedADMM algorithm, unless otherwise indicated, the clients perform fixed ",
                "E",
                "=",
                "10",
                "𝐸",
                "10",
                "E=10",
                " steps of the full-batch gradient descent.\nFor FedADMM-In and FedADMM-InSa algorithms, the number of the full-batch gradient descent steps is controlled by the inexactness criterion, and we constrain the maximum number of gradient descent steps in each communication round to 10. For the inexactness criterion, we set ",
                "β",
                "~",
                "i",
                "subscript",
                "~",
                "𝛽",
                "𝑖",
                "\\tilde{\\beta}_{i}",
                " to the same value as ",
                "β",
                "i",
                "subscript",
                "𝛽",
                "𝑖",
                "{\\beta_{i}}",
                " and replace ",
                "u",
                "i",
                "k",
                "superscript",
                "subscript",
                "𝑢",
                "𝑖",
                "𝑘",
                "u_{i}^{k}",
                " with ",
                "z",
                "k",
                "superscript",
                "𝑧",
                "𝑘",
                "z^{k}",
                " for all the tests. We use the weight coefficient ",
                "α",
                "i",
                "=",
                "0.01",
                "subscript",
                "𝛼",
                "𝑖",
                "0.01",
                "\\alpha_{i}=0.01",
                " because the amount of data per client is the same in both examples. We choose ",
                "δ",
                "=",
                "0.01",
                "𝛿",
                "0.01",
                "\\delta=0.01",
                " for the server aggregation. Finally, important parameters used in the tests are summarized in ",
                "Table",
                " ",
                "1",
                "."
            ]
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Detailed comparison results of the tests presented in Figure 3. The results in the steps reduction column use the vanilla FedADMM (E=10𝐸10E=10) as the baseline.",
        "table": "<table id=\"S4.T2.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.5.4.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.5.4.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Algorithm</th>\n<th id=\"S4.T2.5.4.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Test accuracy</th>\n<th id=\"S4.T2.5.4.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Training loss</th>\n<th id=\"S4.T2.5.4.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Local update steps</th>\n<th id=\"S4.T2.5.4.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Steps reduction</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.3.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">FedADMM (<math id=\"S4.T2.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"E=2\" display=\"inline\"><semantics id=\"S4.T2.3.1.1.m1.1a\"><mrow id=\"S4.T2.3.1.1.m1.1.1\" xref=\"S4.T2.3.1.1.m1.1.1.cmml\"><mi id=\"S4.T2.3.1.1.m1.1.1.2\" xref=\"S4.T2.3.1.1.m1.1.1.2.cmml\">E</mi><mo id=\"S4.T2.3.1.1.m1.1.1.1\" xref=\"S4.T2.3.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.3.1.1.m1.1.1.3\" xref=\"S4.T2.3.1.1.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.1.1.m1.1b\"><apply id=\"S4.T2.3.1.1.m1.1.1.cmml\" xref=\"S4.T2.3.1.1.m1.1.1\"><eq id=\"S4.T2.3.1.1.m1.1.1.1.cmml\" xref=\"S4.T2.3.1.1.m1.1.1.1\"></eq><ci id=\"S4.T2.3.1.1.m1.1.1.2.cmml\" xref=\"S4.T2.3.1.1.m1.1.1.2\">𝐸</ci><cn type=\"integer\" id=\"S4.T2.3.1.1.m1.1.1.3.cmml\" xref=\"S4.T2.3.1.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.1.1.m1.1c\">E=2</annotation></semantics></math>)</td>\n<td id=\"S4.T2.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">81.6%</td>\n<td id=\"S4.T2.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.528</td>\n<td id=\"S4.T2.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4000</td>\n<td id=\"S4.T2.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S4.T2.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.2.1\" class=\"ltx_td ltx_align_center\">FedADMM (<math id=\"S4.T2.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"E=5\" display=\"inline\"><semantics id=\"S4.T2.4.2.1.m1.1a\"><mrow id=\"S4.T2.4.2.1.m1.1.1\" xref=\"S4.T2.4.2.1.m1.1.1.cmml\"><mi id=\"S4.T2.4.2.1.m1.1.1.2\" xref=\"S4.T2.4.2.1.m1.1.1.2.cmml\">E</mi><mo id=\"S4.T2.4.2.1.m1.1.1.1\" xref=\"S4.T2.4.2.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.4.2.1.m1.1.1.3\" xref=\"S4.T2.4.2.1.m1.1.1.3.cmml\">5</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.4.2.1.m1.1b\"><apply id=\"S4.T2.4.2.1.m1.1.1.cmml\" xref=\"S4.T2.4.2.1.m1.1.1\"><eq id=\"S4.T2.4.2.1.m1.1.1.1.cmml\" xref=\"S4.T2.4.2.1.m1.1.1.1\"></eq><ci id=\"S4.T2.4.2.1.m1.1.1.2.cmml\" xref=\"S4.T2.4.2.1.m1.1.1.2\">𝐸</ci><cn type=\"integer\" id=\"S4.T2.4.2.1.m1.1.1.3.cmml\" xref=\"S4.T2.4.2.1.m1.1.1.3\">5</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.4.2.1.m1.1c\">E=5</annotation></semantics></math>)</td>\n<td id=\"S4.T2.4.2.2\" class=\"ltx_td ltx_align_center\">71.9%</td>\n<td id=\"S4.T2.4.2.3\" class=\"ltx_td ltx_align_center\">0.762</td>\n<td id=\"S4.T2.4.2.4\" class=\"ltx_td ltx_align_center\">10000</td>\n<td id=\"S4.T2.4.2.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T2.5.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.3.1\" class=\"ltx_td ltx_align_center\">FedADMM (<math id=\"S4.T2.5.3.1.m1.1\" class=\"ltx_Math\" alttext=\"E=10\" display=\"inline\"><semantics id=\"S4.T2.5.3.1.m1.1a\"><mrow id=\"S4.T2.5.3.1.m1.1.1\" xref=\"S4.T2.5.3.1.m1.1.1.cmml\"><mi id=\"S4.T2.5.3.1.m1.1.1.2\" xref=\"S4.T2.5.3.1.m1.1.1.2.cmml\">E</mi><mo id=\"S4.T2.5.3.1.m1.1.1.1\" xref=\"S4.T2.5.3.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.5.3.1.m1.1.1.3\" xref=\"S4.T2.5.3.1.m1.1.1.3.cmml\">10</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.5.3.1.m1.1b\"><apply id=\"S4.T2.5.3.1.m1.1.1.cmml\" xref=\"S4.T2.5.3.1.m1.1.1\"><eq id=\"S4.T2.5.3.1.m1.1.1.1.cmml\" xref=\"S4.T2.5.3.1.m1.1.1.1\"></eq><ci id=\"S4.T2.5.3.1.m1.1.1.2.cmml\" xref=\"S4.T2.5.3.1.m1.1.1.2\">𝐸</ci><cn type=\"integer\" id=\"S4.T2.5.3.1.m1.1.1.3.cmml\" xref=\"S4.T2.5.3.1.m1.1.1.3\">10</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.5.3.1.m1.1c\">E=10</annotation></semantics></math>)</td>\n<td id=\"S4.T2.5.3.2\" class=\"ltx_td ltx_align_center\">62.6%</td>\n<td id=\"S4.T2.5.3.3\" class=\"ltx_td ltx_align_center\">0.955</td>\n<td id=\"S4.T2.5.3.4\" class=\"ltx_td ltx_align_center\">20000</td>\n<td id=\"S4.T2.5.3.5\" class=\"ltx_td ltx_align_center\">0.0%</td>\n</tr>\n<tr id=\"S4.T2.5.5.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.5.1.1\" class=\"ltx_td ltx_align_center\">FedADMM-In (ours)</td>\n<td id=\"S4.T2.5.5.1.2\" class=\"ltx_td ltx_align_center\">70.9%</td>\n<td id=\"S4.T2.5.5.1.3\" class=\"ltx_td ltx_align_center\">0.730</td>\n<td id=\"S4.T2.5.5.1.4\" class=\"ltx_td ltx_align_center\">10036</td>\n<td id=\"S4.T2.5.5.1.5\" class=\"ltx_td ltx_align_center\">49.8%</td>\n</tr>\n<tr id=\"S4.T2.5.6.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.6.2.1\" class=\"ltx_td ltx_align_center ltx_border_b\">FedADMM-InSa (ours)</td>\n<td id=\"S4.T2.5.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.5.6.2.2.1\" class=\"ltx_text ltx_font_bold\">87.8%</span></td>\n<td id=\"S4.T2.5.6.2.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.5.6.2.3.1\" class=\"ltx_text ltx_font_bold\">0.325</span></td>\n<td id=\"S4.T2.5.6.2.4\" class=\"ltx_td ltx_align_center ltx_border_b\">7139</td>\n<td id=\"S4.T2.5.6.2.5\" class=\"ltx_td ltx_align_center ltx_border_b\">64.3%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this subsection, we present the comparison results of our FedADMM-InSa (",
                "Algorithm",
                " ",
                "3",
                ") with the other two algorithms, namely our FedADMM-In (",
                "Algorithm",
                " ",
                "2",
                ") and the vanilla FedADMM (",
                "Algorithm",
                " ",
                "1",
                "). For FedADMM-InSa, we set the initial penalty parameter ",
                "β",
                "i",
                "0",
                "=",
                "2",
                "superscript",
                "subscript",
                "𝛽",
                "𝑖",
                "0",
                "2",
                "\\beta_{i}^{0}=2",
                " and update it by the scheme (",
                "3.15",
                ") with ",
                "μ",
                "=",
                "20",
                "𝜇",
                "20",
                "\\mu=20",
                " and ",
                "τ",
                "=",
                "2",
                "𝜏",
                "2",
                "\\tau=2",
                ". For both FedADMM-In and FedADMM, the penalty parameter ",
                "β",
                "i",
                "=",
                "2",
                "subscript",
                "𝛽",
                "𝑖",
                "2",
                "\\beta_{i}=2",
                " is fixed throughout the training. For the vanilla FedADMM, we test it with three different local full-batch gradient descent steps, i.e., ",
                "E",
                "=",
                "2",
                ",",
                "5",
                ",",
                "10",
                "𝐸",
                "2",
                "5",
                "10",
                "E=2,5,10",
                ". The results are plotted in ",
                "Figure",
                " ",
                "3",
                " and summarized in ",
                "Table",
                " ",
                "2",
                ".",
                "From ",
                "Figure",
                " ",
                "3",
                ", it is evident that our FedADMM-InSa algorithm, incorporating a self-adaptive penalty parameter (",
                "3.15",
                "), significantly outperforms the other two algorithms. As depicted in ",
                "Figure",
                " ",
                "3(a)",
                ", under the same number of communication rounds, FedADMM-InSa exhibits significantly higher prediction accuracy compared to the other two algorithms. In other words, FedADMM-InSa can achieve a given target accuracy with fewer communication rounds than the other two algorithms. This is also validated by the fastest decreasing training loss of FedADMM-InSa shown in ",
                "Figure",
                " ",
                "3(b)",
                ".",
                "Figure",
                " ",
                "3(d)",
                " illustrates that for a specific client (client 1), when using FedADMM-InSa, it performs less number of gradient descent steps compared with FedADMM-In and FedADMM (",
                "E",
                "=",
                "10",
                "𝐸",
                "10",
                "E=10",
                "), especially in the later communication rounds. This reduction in gradient descent steps is further quantified in ",
                "Table",
                " ",
                "2",
                ", where compared to the baseline FedADMM (",
                "E",
                "=",
                "10",
                "𝐸",
                "10",
                "E=10",
                ") algorithm, our proposed FedADMM-In and FedADMM-InSa algorithms reduce the number of gradient descent steps by 49.8% and 64.3%, respectively, leading to a substantial improvement in training efficiency. Although FedADMM (",
                "E",
                "=",
                "2",
                "𝐸",
                "2",
                "E=2",
                ") has the lowest total number of local gradient descent steps, the value of ",
                "E",
                "𝐸",
                "E",
                " has to be chosen empirically in advance. Without knowing the empirical information of the FL system, it is difficult to find an appropriate ",
                "E",
                "𝐸",
                "E",
                " in advance. Meanwhile, the decline in test accuracy from FedADMM (",
                "E",
                "=",
                "2",
                "𝐸",
                "2",
                "E=2",
                ") to FedADMM (",
                "E",
                "=",
                "10",
                "𝐸",
                "10",
                "E=10",
                ") is likely attributed to the pathological non-IID datasets, further emphasizing the challenge of empirically choosing an appropriate ",
                "E",
                "𝐸",
                "E",
                " in advance. Notably, our proposed FedADMM-InSa algorithm outperforms FedADMM (",
                "E",
                "=",
                "2",
                "𝐸",
                "2",
                "E=2",
                ") in terms of test accuracy, achieving a balance between improving training performance and reducing computational load.",
                "Finally, in ",
                "Figure",
                " ",
                "3(c)",
                ", the variation of the average penalty parameter across all clients is plotted. It can be observed that FedADMM-InSa dynamically adjusts the average penalty parameter from an initial value of two to around one. This demonstrates that FedADMM-InSa can adaptively correct the initially improperly chosen penalty parameters, highlighting the robustness of our proposed algorithm."
            ]
        ]
    }
}