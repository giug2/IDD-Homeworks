{
    "id_table_1": {
        "caption": "Table 1 :  Each value in the table is the difference between the utility of a baseline (deterministic) RAG model and the average utility of a fairer RAG model at a specific fairness interval. Nonnegative differences are highlighted. Full results are listed in Appendix  I .",
        "table": "S5.T1.2.1.1",
        "footnotes": [],
        "references": [
            "In recent years, the concept of fair ranking has emerged as a critical concern in modern information access systems  [ 11 ] . However, despite its significance, fair ranking has yet to be thoroughly examined in the context of retrieval-augmented generation (RAG)  [ 28 ] , a rapidly advancing trend in natural language processing (NLP) systems  [ 26 ] .  To understand why this is important, consider the RAG system in Figure  1 , where a user asks a question about running shoes. A classic retrieval system might return several documents containing information from various running shoe companies. If the RAG system only selects the top two documents, then information from the remaining two relevant companies will not be relayed to the predictive model and will likely be omitted from its answer. The fair ranking literature refers to this situation as unfair because some relevant companies (i.e., in documents at position 3 and 4) receive less or no exposure compared to equally relevant company in the top position  [ 11 ] .",
            "The following sections describe how we construct a test collection with utility labels ( 3.1 ),  how we stochastically sample multiple rankings ( 3.2 ), and how we evaluate the fairness and ranking quality of the sampled rankings ( 3.3.1 ) and measure the effectiveness of a RAG system given multiple rankings ( 3.3.2 ).",
            "In this paper, based on the empirical investigation done by  Raj and Ekstrand [ 38 ] , we use expected exposure disparity (EE-D) and expected exposure relevance (EE-R)  [ 9 ]  as   f subscript  f \\mu_{f} italic_ start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT  and   r subscript  r \\mu_{r} italic_ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , respectively ( 3.3.1 ).  For   u subscript  u \\mu_{u} italic_ start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT , we select the metric depending on the task, and we get the expectation of the utility of a RAG model which we call an expected utility (EU) ( 3.3.2 ).",
            "We choose the LaMP benchmark  [ 45 ]  for our dataset. It assesses the personalization capability of language models through retrieval-augmentation of users interaction history in a platform. LaMP includes various prediction tasks, such as classification, regression, and generation, and is well-suited for tasks where multiple items can be relevant/useful, unlike QA tasks with typically one or two provenance items. The retrieval items in LaMP have clear providers and consumers, aligning with our goal to ensure fairness for individual item providers. For example, in LaMP-1, retrieval items are academic papers, where exposure can increase citation counts for authors. In LaMP-4, retrieval items are news articles, where exposure can lead to monetary compensation for journalists.  Due to the absence of a test set, we constructed a test collection as described in  3.1 , using the first thousand entries of a user-based development set.  Then, we discarded entries that have only one useful item in the corpus, as it is unnecessary to concern item-fairness in that case. We release the test collection, and the dataset statistics can be found in the Appendix  J .",
            "However, a closer look at the local trend offers a significant insight:  RAG systems with fair ranking can often achieve higher system-effectiveness compared to models with deterministic rankers .  In Table  1 , we divided the fairness levels into five intervals based on the normalized EE-D. As shown in the table and Appendix  I , improving fairness to the level of  EE-D    [ 0.8 , 1.0 )   EE-D 0.8 1.0 \\overline{\\text{EE-D}}\\in[0.8,1.0) over  start_ARG EE-D end_ARG  [ 0.8 , 1.0 ) , and even  EE-D    [ 0.6 , 0.8 )   EE-D 0.6 0.8 \\overline{\\text{EE-D}}\\in[0.6,0.8) over  start_ARG EE-D end_ARG  [ 0.6 , 0.8 ) , can often enhance the utility of many RAG models across most LaMP tasks. For example, having  EE-D     EE-D \\overline{\\text{EE-D}} over  start_ARG EE-D end_ARG  in the range of [0.8, 1.0) outperforms the baseline for all models in LaMP-2 and for seven out of nine models in LaMP tasks 4, 5, and 6."
        ]
    },
    "id_table_2": {
        "caption": "Table 2 :  Notation.",
        "table": "S5.T1.3.1.1",
        "footnotes": [],
        "references": [
            "To address the issue of unfairness in the rankings passed to the generator, we can convert a deterministic retriever into a stochastic retriever, which has been shown to provide fair rankings in expectation  [ 9 ] .  By sampling a ranking from a distribution of rankings predicted to be relevant, we smooth the expected exposure of different relevant items to be similar and, therefore, fairer (Appendix  E ).  Because decisions are stochastic, the fairness and quality of stochastic retrieval is evaluated based on a sample of rankings. Similarly, since a sampled ranking is processed by a generator, we also compute the expected effectiveness by using sampled rankings.  The complete evaluation pipeline of a RAG system with a stochastic retriever is illustrated in Figure  2 .",
            "The following sections describe how we construct a test collection with utility labels ( 3.1 ),  how we stochastically sample multiple rankings ( 3.2 ), and how we evaluate the fairness and ranking quality of the sampled rankings ( 3.3.1 ) and measure the effectiveness of a RAG system given multiple rankings ( 3.3.2 ).",
            "In this paper, based on the empirical investigation done by  Raj and Ekstrand [ 38 ] , we use expected exposure disparity (EE-D) and expected exposure relevance (EE-R)  [ 9 ]  as   f subscript  f \\mu_{f} italic_ start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT  and   r subscript  r \\mu_{r} italic_ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , respectively ( 3.3.1 ).  For   u subscript  u \\mu_{u} italic_ start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT , we select the metric depending on the task, and we get the expectation of the utility of a RAG model which we call an expected utility (EU) ( 3.3.2 ).",
            "We repeat the experiments with four different temperature parameters   = 1 , 2 , 4 , 8  1 2 4 8 \\alpha=1,2,4,8 italic_ = 1 , 2 , 4 , 8 , which allows us to assess the utility of the RAG models with different levels of item-fairness.  From Figure  3 , we observe how effectively    \\alpha italic_ , described in the Equation  2 , controls the disparity of rankings.  For example, when    \\alpha italic_  is set to 4, we usually obtain a set of sampled rankings with  EE-D     EE-D \\overline{\\text{EE-D}} over  start_ARG EE-D end_ARG  mostly in the range of [0.5, 0.8], and when    \\alpha italic_  is set to 8, we often get a set of sampled rankings with  EE-D   = 1   EE-D 1 \\overline{\\text{EE-D}}=1 over  start_ARG EE-D end_ARG = 1 .  Refer to Appendix  D  to see the full description of the effect of    \\alpha italic_  on the other metrics."
        ]
    },
    "id_table_3": {
        "caption": "Table 3 :  Values on the left are the gradient of a linear line fit to the data points where x-axis is  EE-D     EE-D \\overline{\\text{EE-D}} over  start_ARG EE-D end_ARG  and y-axis is  EE-R     EE-R \\overline{\\text{EE-R}} over  start_ARG EE-R end_ARG . Higher the value, stronger the tradeoff between fairness and ranking quality. Values on the right are the DR-AUC on the disparity-ranking quality ( EE-D     EE-D \\overline{\\text{EE-D}} over  start_ARG EE-D end_ARG  Vs.  EE-R     EE-R \\overline{\\text{EE-R}} over  start_ARG EE-R end_ARG ) curve. Higher the value, stronger the ranking quality, given consistent tradeoff between fairness and relevance.  Oracle retriever is omitted here as  EE-R     EE-R \\overline{\\text{EE-R}} over  start_ARG EE-R end_ARG  of oracle is almost always 1.0.",
        "table": "A1.T2.44",
        "footnotes": [],
        "references": [
            "The following sections describe how we construct a test collection with utility labels ( 3.1 ),  how we stochastically sample multiple rankings ( 3.2 ), and how we evaluate the fairness and ranking quality of the sampled rankings ( 3.3.1 ) and measure the effectiveness of a RAG system given multiple rankings ( 3.3.2 ).",
            "As mentioned in Section  3 , because we are dealing with stochastic retrievers, we need to measure the  expected  behavior of the system.  Let  S  ( s , N , k ) S s N k \\mathcal{S}(\\mathbf{s},N,k) caligraphic_S ( bold_s , italic_N , italic_k )  be the stochastic sampler that samples a set of  N N N italic_N  rankings   = [  1 ,  2 ,  ,  N ]  subscript  1 subscript  2  subscript  N \\Sigma=[\\sigma_{1},\\sigma_{2},\\cdots,\\sigma_{N}] roman_ = [ italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ,  , italic_ start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ] , given the retrieval scores  s s \\mathbf{s} bold_s , where each ranking   i subscript  i \\sigma_{i} italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is truncated to the size of  k k k italic_k .  From each ranking, we can get an output  y ^ i = G  (  p  ( x ,  i ) ) subscript ^ y i G subscript italic- p x subscript  i \\hat{y}_{i}=\\mathcal{G}(\\phi_{p}(x,\\sigma_{i})) over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = caligraphic_G ( italic_ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_x , italic_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) .  With an arbitrary fairness metric   f  (  ) subscript  f  \\mu_{f}(\\Sigma) italic_ start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT ( roman_ )  and a ranking quality metric   r  (  ) subscript  r  \\mu_{r}(\\Sigma) italic_ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( roman_ )  that takes a set of rankings as an input, we can measure the degree of fairness and ranking quality of the sampled rankings.  Similarly, an arbitrary string utility metric   u  ( y , y ^ i ) subscript  u y subscript ^ y i \\mu_{u}(y,\\hat{y}_{i}) italic_ start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( italic_y , over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , such as ROUGE, can be used to assess an expected effectiveness of a RAG system by calculating the average of the  N N N italic_N  metric scores.",
            "In this paper, based on the empirical investigation done by  Raj and Ekstrand [ 38 ] , we use expected exposure disparity (EE-D) and expected exposure relevance (EE-R)  [ 9 ]  as   f subscript  f \\mu_{f} italic_ start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT  and   r subscript  r \\mu_{r} italic_ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , respectively ( 3.3.1 ).  For   u subscript  u \\mu_{u} italic_ start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT , we select the metric depending on the task, and we get the expectation of the utility of a RAG model which we call an expected utility (EU) ( 3.3.2 ).",
            "From Equation  3 , we decompose the metric into EE-D and EE-R. Since the bounds of these metrics depend on the number of useful items, normalization must be applied per query. Both metrics are min-max normalized based on their theoretical lower and upper bounds. We denote the normalized EE-D and EE-R as  EE-D   q subscript   EE-D q \\overline{\\text{EE-D}}_{q} over  start_ARG EE-D end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  and  EE-R   q subscript   EE-R q \\overline{\\text{EE-R}}_{q} over  start_ARG EE-R end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , respectively.",
            "We choose the LaMP benchmark  [ 45 ]  for our dataset. It assesses the personalization capability of language models through retrieval-augmentation of users interaction history in a platform. LaMP includes various prediction tasks, such as classification, regression, and generation, and is well-suited for tasks where multiple items can be relevant/useful, unlike QA tasks with typically one or two provenance items. The retrieval items in LaMP have clear providers and consumers, aligning with our goal to ensure fairness for individual item providers. For example, in LaMP-1, retrieval items are academic papers, where exposure can increase citation counts for authors. In LaMP-4, retrieval items are news articles, where exposure can lead to monetary compensation for journalists.  Due to the absence of a test set, we constructed a test collection as described in  3.1 , using the first thousand entries of a user-based development set.  Then, we discarded entries that have only one useful item in the corpus, as it is unnecessary to concern item-fairness in that case. We release the test collection, and the dataset statistics can be found in the Appendix  J .",
            "We repeat the experiments with four different temperature parameters   = 1 , 2 , 4 , 8  1 2 4 8 \\alpha=1,2,4,8 italic_ = 1 , 2 , 4 , 8 , which allows us to assess the utility of the RAG models with different levels of item-fairness.  From Figure  3 , we observe how effectively    \\alpha italic_ , described in the Equation  2 , controls the disparity of rankings.  For example, when    \\alpha italic_  is set to 4, we usually obtain a set of sampled rankings with  EE-D     EE-D \\overline{\\text{EE-D}} over  start_ARG EE-D end_ARG  mostly in the range of [0.5, 0.8], and when    \\alpha italic_  is set to 8, we often get a set of sampled rankings with  EE-D   = 1   EE-D 1 \\overline{\\text{EE-D}}=1 over  start_ARG EE-D end_ARG = 1 .  Refer to Appendix  D  to see the full description of the effect of    \\alpha italic_  on the other metrics."
        ]
    },
    "id_table_4": {
        "caption": "Table 4 :  Values on the left are the gradient of a linear line fit to the data points where x-axis is  EE-R     EE-R \\overline{\\text{EE-R}} over  start_ARG EE-R end_ARG  and y-axis is  EU     EU \\overline{\\text{EU}} over  start_ARG EU end_ARG . Higher the value, stronger the tradeoff between retrieval quality and generation quality. Values on the right are the RU-AUC on the ranking quality-utility ( EE-R     EE-R \\overline{\\text{EE-R}} over  start_ARG EE-R end_ARG Vs.  EU     EU \\overline{\\text{EU}} over  start_ARG EU end_ARG ) curve. Higher the value, stronger the general end-performance of a RAG model when every level of relevance is considered.  Oracle retriever is omitted here as  EE-R     EE-R \\overline{\\text{EE-R}} over  start_ARG EE-R end_ARG  of oracle is almost always 1.0.",
        "table": "A6.T3.12.1",
        "footnotes": [],
        "references": [
            "By gathering all four repeated runs of the experiments with different    \\alpha italic_  values, we can plot the trend of ranking quality ( EE-R     EE-R \\overline{\\text{EE-R}} over  start_ARG EE-R end_ARG ) against item fairness ( EE-D     EE-D \\overline{\\text{EE-D}} over  start_ARG EE-D end_ARG ), as shown in Figure  4 .",
            "As shown in previous studies  [ 50 ,  9 ] , there is a well-known tradeoff between fairness and ranking quality for human users. Similarly, we observe a general tradeoff for machine users. However, unlike past findings, this tradeoff is not always strict. For instance, in Figure  4 , both SPLADE and Contriever maintain consistently high ranking quality while being considerably fairer, and for BM25, ranking quality even improves as fairness increases, up to a certain point.",
            "To quantify the performance of fair rankers, we calculate the area under the disparity-ranking quality curve (Figure  4 ), with higher values indicating stronger ranking quality. We also measure the tradeoff by fitting a linear line to the experiment results, where a steeper slope reflects a stronger tradeoff between fairness and ranking quality. Based on these metrics, we observe that Contriever-based models exhibit the highest tradeoff, while BM25-based models show the lowest, despite their poor retrieval quality. Overall, SPLADE-based models achieve high retrieval quality while maintaining a relatively low tradeoff. For detailed plots and quantifications, refer to Appendix  F .",
            "Before examining the relationship between fairness and RAG utility, Figure  5(a)  shows an auxiliary result confirming a strong correlation between utility-based ranking quality and the effectiveness of RAG models. This is unsurprising, as item-worthiness judgments were based on the utility-gain provided by the generator. However, this correlation suggests that the tradeoff observed in the disparity-ranking quality curve (Figure  4 ) is likely to manifest similarly due to this strong relationship."
        ]
    },
    "id_table_5": {
        "caption": "Table 5 :  Values on the left are the gradient of a linear line fit to the data points where x-axis is  EE-D     EE-D \\overline{\\text{EE-D}} over  start_ARG EE-D end_ARG  and y-axis is  EU     EU \\overline{\\text{EU}} over  start_ARG EU end_ARG . Higher the value, stronger the tradeoff between item-fairness and generation quality. Values on the right are the DU-AUC on the disparity-utility ( EE-D     EE-D \\overline{\\text{EE-D}} over  start_ARG EE-D end_ARG  Vs.  EU     EU \\overline{\\text{EU}} over  start_ARG EU end_ARG ) curve. Higher the value, stronger the general end-performance of a RAG model when every level of fairness is considered.",
        "table": "A7.T4.12.1",
        "footnotes": [],
        "references": [
            "Before examining the relationship between fairness and RAG utility, Figure  5(a)  shows an auxiliary result confirming a strong correlation between utility-based ranking quality and the effectiveness of RAG models. This is unsurprising, as item-worthiness judgments were based on the utility-gain provided by the generator. However, this correlation suggests that the tradeoff observed in the disparity-ranking quality curve (Figure  4 ) is likely to manifest similarly due to this strong relationship.",
            "In fact, as observed from the disparity-utility curve (Figure  5(b) ), we see a global trend of a non-strict tradeoff (i.e., RAG models maintain high generation quality while being considerably fair, and often even achieve higher quality)."
        ]
    },
    "id_table_6": {
        "caption": "Table 6 :  LaMP-1",
        "table": "A8.T5.10.1",
        "footnotes": [],
        "references": [
            "With UM, the upper bound of EE-R can be calculated by equation  6 .   If  m  k m k m\\leq k italic_m  italic_k ,      2 2 superscript subscript delimited- superscript italic- 2 2 {\\left\\lVert\\mathbf{\\epsilon}^{*}\\right\\rVert}_{2}^{2}  italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT  becomes",
            "However, we can expect some edge cases.  For instance, in LaMP-1 (left column of the figure), difference in  EU     EU \\overline{\\text{EU}} over  start_ARG EU end_ARG  when   = 4  4 \\alpha=4 italic_ = 4  and   = 8  8 \\alpha=8 italic_ = 8  is not large, and we can see that even the lower quartile of the utility is increased when    \\alpha italic_  is set to 4 (Figure  6(c) ). This can possibly mean that in LaMP-1, the RAG model can maintain considerable utility when the disparity is roughly in the range of [0.6, 0.8].  Similar observation can be made for the LaMP-4 (right column of the figure), except that the  EE-R     EE-R \\overline{\\text{EE-R}} over  start_ARG EE-R end_ARG  is higher when   = 4  4 \\alpha=4 italic_ = 4  than when   = 8  8 \\alpha=8 italic_ = 8  (Figure  6(b) ). This indicates that the deterministic retriever does not always provide the maximum ranking quality, and the retriever can sometimes provide higher ranking quality by being more fair, ultimately maintaining considerable or higher utility (similar  EU     EU \\overline{\\text{EU}} over  start_ARG EU end_ARG  when    \\alpha italic_ =4 and when    \\alpha italic_ =8) at the same time."
        ]
    },
    "id_table_7": {
        "caption": "Table 7 :  LaMP-2",
        "table": "A9.T6.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_8": {
        "caption": "Table 8 :  LaMP-3",
        "table": "A9.T7.2.1",
        "footnotes": [],
        "references": [
            "The lower bound is achieved when   italic- \\mathbf{\\epsilon} italic_  becomes    superscript italic- \\mathbf{\\epsilon}^{-} italic_ start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT , which is an exposure vector of the worst case deterministic ranking    superscript  \\sigma^{-} italic_ start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT  (permutations that rank all non-relevant items above relevant items). Given the assumption made from equation  8  and,  C + superscript C \\textrm{C}^{+} C start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT  and  C  superscript C \\textrm{C}^{-} C start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT , which are set of indices of relevant and non-relevant items, respectively,"
        ]
    },
    "id_table_9": {
        "caption": "Table 9 :  LaMP-4",
        "table": "A9.T8.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_10": {
        "caption": "Table 10 :  LaMP-5",
        "table": "A9.T9.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_11": {
        "caption": "Table 11 :  LaMP-6",
        "table": "A9.T10.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_12": {
        "caption": "Table 12 :  LaMP-7",
        "table": "A9.T11.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_13": {
        "caption": "Table 13 :  LaMP data statistics for Flan-T5-Small after filtering for fairness evaluation.",
        "table": "A9.T12.2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_14": {
        "caption": "Table 14 :  LaMP data statistics for Flan-T5-Base after filtering for fairness evaluation.",
        "table": "A10.T13.2",
        "footnotes": [],
        "references": []
    },
    "id_table_15": {
        "caption": "Table 15 :  LaMP data statistics for Flan-T5-XXL after filtering for fairness evaluation.",
        "table": "A10.T14.2",
        "footnotes": [],
        "references": []
    },
    "id_table_16": {
        "caption": "",
        "table": "A10.T15.2",
        "footnotes": [],
        "references": []
    },
    "global_footnotes": [
        "Throughout this paper, we use utility and generation quality interchangeably to refer to the downstream effectiveness of RAG models, measured by arbitrary string utility metrics.",
        "We normalized the values to the range of [1, 2] instead of [0, 1]. The addition of 1 effectively serves the same purpose as adjusting a real-numbered",
        ". We chose this range to allow for an integer-valued",
        "."
    ]
}