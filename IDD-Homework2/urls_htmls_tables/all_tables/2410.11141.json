{
    "id_table_1": {
        "caption": "Table 1:  Sample prompt and response from the models",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": [
            "We propose a comprehensive framework to help models learn from structured data and hence minimize EU. In this section, we demonstrate how ontologies can be used to reduce EU and help achieve quicker learning. We also explore a novel approach using ontologies to aid RAGs and overcome hallucinations that are often faced by LLMs. Figure  1  shows the overall framework of our work.",
            "In this section, we first attempt to prove hypothesis  1  by making use of the Symptoms Ontology which contains 1019 classes surrounding symptoms from various systems and functions in the human body as the source ontology, and Clinical Signs and Symptoms Ontology is a collection of 303 classes surrounding various aspects of medical symptoms and signs of diseases as the target ontology. Ontology alignment is performed to obtain equivalence and subsumption mappings. These mappings are a result of the synonymous classification task which is done using a pre-trained version of a BERT-based model. These models are further used to perform sequential classification on the dataset. Using these subsumption mappings we implement the proposed method to infiltrate the prompt to overcome LLM hallucinations and to build on top of the existing RAG frameworks.",
            "To prove hypothesis  1  we first used the pre-trained version of BioClinical BERT to perform ontology matching which gives a resultant extremely fine-tuned version of BioClinical BERT that has now been trained on ontologies. This model is now used to perform sequential classification on the MedQuAD-MedicalQnA dataset  Ben Abacha and Demner-Fushman ( 2019 ) . The rate at which the model learns is significantly higher compared to the rate at which a normal BioClinical BERT learns. A similar experimentation was performed using the pre-trained version of bert-base-uncased-yelp-polarity which yielded similar results.",
            "Table  1  shows a qualitative comparison of the results obtained from the native GPT-3.5 turbo model and the GPT-3.5-turbo model with subsumption infiltration."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Contextual similarity scores",
        "table": "S4.T2.1",
        "footnotes": [],
        "references": [
            "The Figure  2  and Figure  3  represent the accuracies of extremely fine-tuned and native models versions of both BioClinical BERT and bert-base-uncased-yelp-polarity models. Analyzing the accuracy after every epoch, it can be inferred that the rate of learning of the model trained through ontology alignment is higher and similarly Figure  4  and Figure  5  show how quickly the model converges to an optimal state. This proves the hypothesis that training a model using structured data enhances the capabilities of the model making it learn at a higher rate.",
            "Table  2  shows how subsumptions help keep intact the context from the prompt, at the same time enhancing it and Table  3  shows how closer it is to the lines from the document itself. It is to be noted that cosine similarity and dot product are desired to be a higher value and intuitively, euclidean distance is to be a lesser value. Table  4  displays scores that prove how the model tackles hallucination when subsumptions are introduced to the prompt while also minimizing the effect of EU.  Note, in all three tables, cosine similarity is represented as a percentage."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Factual Accuracy scores",
        "table": "S4.T3.1",
        "footnotes": [],
        "references": [
            "The Figure  2  and Figure  3  represent the accuracies of extremely fine-tuned and native models versions of both BioClinical BERT and bert-base-uncased-yelp-polarity models. Analyzing the accuracy after every epoch, it can be inferred that the rate of learning of the model trained through ontology alignment is higher and similarly Figure  4  and Figure  5  show how quickly the model converges to an optimal state. This proves the hypothesis that training a model using structured data enhances the capabilities of the model making it learn at a higher rate.",
            "Table  2  shows how subsumptions help keep intact the context from the prompt, at the same time enhancing it and Table  3  shows how closer it is to the lines from the document itself. It is to be noted that cosine similarity and dot product are desired to be a higher value and intuitively, euclidean distance is to be a lesser value. Table  4  displays scores that prove how the model tackles hallucination when subsumptions are introduced to the prompt while also minimizing the effect of EU.  Note, in all three tables, cosine similarity is represented as a percentage."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Hallucination Index",
        "table": "S4.T4.1",
        "footnotes": [],
        "references": [
            "Our work uses an approach where we make use of subsumptions obtained through ontology mapping, to provide more contextual information to the prompt that is passed to the Language Model. One of the main issues with the current retrieval approaches using Retrieval-Augmented Generation is hallucination, where the model gives out irrelevant, incorrect, and unreal responses. By incorporating subsumptions in the prompt, we ensure hallucination is minimized and the response of the Language Model is more contextually and factually intact. Section  4  presents key insights from our experimentation with ontologies in the medical domain, demonstrating how our methodology could be used for quicker training and reducing hallucinations in LLMs.",
            "The Figure  2  and Figure  3  represent the accuracies of extremely fine-tuned and native models versions of both BioClinical BERT and bert-base-uncased-yelp-polarity models. Analyzing the accuracy after every epoch, it can be inferred that the rate of learning of the model trained through ontology alignment is higher and similarly Figure  4  and Figure  5  show how quickly the model converges to an optimal state. This proves the hypothesis that training a model using structured data enhances the capabilities of the model making it learn at a higher rate.",
            "Table  2  shows how subsumptions help keep intact the context from the prompt, at the same time enhancing it and Table  3  shows how closer it is to the lines from the document itself. It is to be noted that cosine similarity and dot product are desired to be a higher value and intuitively, euclidean distance is to be a lesser value. Table  4  displays scores that prove how the model tackles hallucination when subsumptions are introduced to the prompt while also minimizing the effect of EU.  Note, in all three tables, cosine similarity is represented as a percentage."
        ]
    },
    "global_footnotes": []
}