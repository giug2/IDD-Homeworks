{
    "S3.T1": {
        "caption": "Table 1: Homophility rate (HR) in different meta-path sub-graph of ACM dataset. ACC represents the node classification accuracy of 2-layer GCN with ReLU activation.",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Dataset</th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Meta-path</th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">HR(%)</th>\n<th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">ACC(%)</th>\n<th id=\"S3.T1.1.1.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_t\">Edges</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_border_t\"/>\n<td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">PAP</td>\n<td id=\"S3.T1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">81.45</td>\n<td id=\"S3.T1.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">87.33 ± 0.56</td>\n<td id=\"S3.T1.1.2.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\">29767</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.2.1\" class=\"ltx_td\"/>\n<td id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_left\">PSP</td>\n<td id=\"S3.T1.1.3.2.3\" class=\"ltx_td ltx_align_left\">64.03</td>\n<td id=\"S3.T1.1.3.2.4\" class=\"ltx_td ltx_align_left\">66.72 ± 0.49</td>\n<td id=\"S3.T1.1.3.2.5\" class=\"ltx_td ltx_nopad_r ltx_align_left\">2217089</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_center\">ACM</td>\n<td id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_left\">PTP</td>\n<td id=\"S3.T1.1.4.3.3\" class=\"ltx_td ltx_align_left\">33.38</td>\n<td id=\"S3.T1.1.4.3.4\" class=\"ltx_td ltx_align_left\">68.21 ± 0.14</td>\n<td id=\"S3.T1.1.4.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_left\">9150595</td>\n</tr>\n<tr id=\"S3.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.5.4.1\" class=\"ltx_td\"/>\n<td id=\"S3.T1.1.5.4.2\" class=\"ltx_td ltx_align_left\">PcPSP</td>\n<td id=\"S3.T1.1.5.4.3\" class=\"ltx_td ltx_align_left\">60.62</td>\n<td id=\"S3.T1.1.5.4.4\" class=\"ltx_td ltx_align_left\">68.21 ± 1.08</td>\n<td id=\"S3.T1.1.5.4.5\" class=\"ltx_td ltx_nopad_r ltx_align_left\">1933761</td>\n</tr>\n<tr id=\"S3.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.6.5.1\" class=\"ltx_td ltx_border_b\"/>\n<td id=\"S3.T1.1.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_b\">PrPSP</td>\n<td id=\"S3.T1.1.6.5.3\" class=\"ltx_td ltx_align_left ltx_border_b\">61.41</td>\n<td id=\"S3.T1.1.6.5.4\" class=\"ltx_td ltx_align_left ltx_border_b\">68.16 ± 1.28</td>\n<td id=\"S3.T1.1.6.5.5\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_b\">1440299</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "(1) Sensitivity to Meta-path Combinations.\nMeta-path combinations critically affect HGNN performance. Variations in these combinations impact the structural configuration of meta-path sub-graphs, significantly influencing model outcomes, as evidenced by the substantial standard deviation and min-max gap shown in Figure 1. In extreme cases, improper combinations can lead to model failure. This challenge is more acute in SSL models due to the lack of downstream task feedback. Even proven meta-paths can cause dramatic performance deterioration if combined inappropriately. The sensitivity of HGNNs to these combinations is partly due to their responsiveness to topological changes and is further compounded by the low homophily ratios in meta-path sub-graphs [13] (referenced in Table 1), which exacerbates the issue in denser sub-graph structures."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: The statistics of the datasets",
        "table": "<table id=\"S4.T2.8\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.8.9.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.8.9.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Dataset</th>\n<th id=\"S4.T2.8.9.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Nodes</th>\n<th id=\"S4.T2.8.9.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">NodeTypes</th>\n<th id=\"S4.T2.8.9.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Edges</th>\n<th id=\"S4.T2.8.9.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">EdgeTypes</th>\n<th id=\"S4.T2.8.9.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Target</th>\n<th id=\"S4.T2.8.9.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Classes</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">DBLP</td>\n<td id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"26\\,128\" display=\"inline\"><semantics id=\"S4.T2.1.1.1.m1.1a\"><mn id=\"S4.T2.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.m1.1.1.cmml\">26 128</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.m1.1b\"><cn type=\"integer\" id=\"S4.T2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1\">26128</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.m1.1c\">26\\,128</annotation></semantics></math></td>\n<td id=\"S4.T2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4</td>\n<td id=\"S4.T2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"239\\,566\" display=\"inline\"><semantics id=\"S4.T2.2.2.2.m1.1a\"><mn id=\"S4.T2.2.2.2.m1.1.1\" xref=\"S4.T2.2.2.2.m1.1.1.cmml\">239 566</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.m1.1b\"><cn type=\"integer\" id=\"S4.T2.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1\">239566</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.m1.1c\">239\\,566</annotation></semantics></math></td>\n<td id=\"S4.T2.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">6</td>\n<td id=\"S4.T2.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">author</td>\n<td id=\"S4.T2.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">4</td>\n</tr>\n<tr id=\"S4.T2.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.4.3\" class=\"ltx_td ltx_align_center\">IMDB</td>\n<td id=\"S4.T2.3.3.1\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T2.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"21\\,420\" display=\"inline\"><semantics id=\"S4.T2.3.3.1.m1.1a\"><mn id=\"S4.T2.3.3.1.m1.1.1\" xref=\"S4.T2.3.3.1.m1.1.1.cmml\">21 420</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.3.1.m1.1b\"><cn type=\"integer\" id=\"S4.T2.3.3.1.m1.1.1.cmml\" xref=\"S4.T2.3.3.1.m1.1.1\">21420</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.3.1.m1.1c\">21\\,420</annotation></semantics></math></td>\n<td id=\"S4.T2.4.4.4\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"S4.T2.4.4.2\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T2.4.4.2.m1.1\" class=\"ltx_Math\" alttext=\"86\\,642\" display=\"inline\"><semantics id=\"S4.T2.4.4.2.m1.1a\"><mn id=\"S4.T2.4.4.2.m1.1.1\" xref=\"S4.T2.4.4.2.m1.1.1.cmml\">86 642</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.4.4.2.m1.1b\"><cn type=\"integer\" id=\"S4.T2.4.4.2.m1.1.1.cmml\" xref=\"S4.T2.4.4.2.m1.1.1\">86642</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.4.4.2.m1.1c\">86\\,642</annotation></semantics></math></td>\n<td id=\"S4.T2.4.4.5\" class=\"ltx_td ltx_align_center\">6</td>\n<td id=\"S4.T2.4.4.6\" class=\"ltx_td ltx_align_center\">movie</td>\n<td id=\"S4.T2.4.4.7\" class=\"ltx_td ltx_align_center\">5</td>\n</tr>\n<tr id=\"S4.T2.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.6.6.3\" class=\"ltx_td ltx_align_center\">ACM</td>\n<td id=\"S4.T2.5.5.1\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T2.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"10\\,942\" display=\"inline\"><semantics id=\"S4.T2.5.5.1.m1.1a\"><mn id=\"S4.T2.5.5.1.m1.1.1\" xref=\"S4.T2.5.5.1.m1.1.1.cmml\">10 942</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.5.5.1.m1.1b\"><cn type=\"integer\" id=\"S4.T2.5.5.1.m1.1.1.cmml\" xref=\"S4.T2.5.5.1.m1.1.1\">10942</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.5.5.1.m1.1c\">10\\,942</annotation></semantics></math></td>\n<td id=\"S4.T2.6.6.4\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"S4.T2.6.6.2\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T2.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"547\\,872\" display=\"inline\"><semantics id=\"S4.T2.6.6.2.m1.1a\"><mn id=\"S4.T2.6.6.2.m1.1.1\" xref=\"S4.T2.6.6.2.m1.1.1.cmml\">547 872</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.6.6.2.m1.1b\"><cn type=\"integer\" id=\"S4.T2.6.6.2.m1.1.1.cmml\" xref=\"S4.T2.6.6.2.m1.1.1\">547872</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.6.6.2.m1.1c\">547\\,872</annotation></semantics></math></td>\n<td id=\"S4.T2.6.6.5\" class=\"ltx_td ltx_align_center\">8</td>\n<td id=\"S4.T2.6.6.6\" class=\"ltx_td ltx_align_center\">paper</td>\n<td id=\"S4.T2.6.6.7\" class=\"ltx_td ltx_align_center\">3</td>\n</tr>\n<tr id=\"S4.T2.8.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_b\">Freebase</td>\n<td id=\"S4.T2.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_b\"><math id=\"S4.T2.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"180\\,098\" display=\"inline\"><semantics id=\"S4.T2.7.7.1.m1.1a\"><mn id=\"S4.T2.7.7.1.m1.1.1\" xref=\"S4.T2.7.7.1.m1.1.1.cmml\">180 098</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.7.7.1.m1.1b\"><cn type=\"integer\" id=\"S4.T2.7.7.1.m1.1.1.cmml\" xref=\"S4.T2.7.7.1.m1.1.1\">180098</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.7.7.1.m1.1c\">180\\,098</annotation></semantics></math></td>\n<td id=\"S4.T2.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_b\">8</td>\n<td id=\"S4.T2.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><math id=\"S4.T2.8.8.2.m1.1\" class=\"ltx_Math\" alttext=\"1\\,057\\,688\" display=\"inline\"><semantics id=\"S4.T2.8.8.2.m1.1a\"><mn id=\"S4.T2.8.8.2.m1.1.1\" xref=\"S4.T2.8.8.2.m1.1.1.cmml\">1 057 688</mn><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.8.8.2.m1.1b\"><cn type=\"integer\" id=\"S4.T2.8.8.2.m1.1.1.cmml\" xref=\"S4.T2.8.8.2.m1.1.1\">1057688</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.8.8.2.m1.1c\">1\\,057\\,688</annotation></semantics></math></td>\n<td id=\"S4.T2.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_b\">36</td>\n<td id=\"S4.T2.8.8.6\" class=\"ltx_td ltx_align_center ltx_border_b\">book</td>\n<td id=\"S4.T2.8.8.7\" class=\"ltx_td ltx_align_center ltx_border_b\">7</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "In our study, we leveraged the HGB benchmark [31], which includes four diverse HIN datasets detailed in Table 2. The DBLP dataset [8] is sourced from the renowned DBLP bibliography website, focusing on a subset of computer science publications and featuring nodes such as authors, papers, terms, and venues. The ACM dataset [56] is also a citation network from the computer science domain. We utilized the Freebase knowledge graph [29], specifically a subgraph with around 1,000,000 edges across eight types of entities, in line with previous research methodologies [48]. Lastly, the IMDB dataset focuses on the IMDB movie database, particularly covering movie genres like Action, Comedy, Drama, Romance, and Thriller."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Quantitative results on node classification, detailing accuracy percentages and standard deviations. The second column specifies the training data available for each method, where X𝑋X, A𝐴A, P𝑃P, and Y𝑌Y correspond to node features, the adjacency matrix, optimal meta-path combination, and labels, respectively. The best and second best performance for unsupervised models is highlighted in boldface and underline. Instances where the computation surpassed the memory constraints of a 200GB CPU are marked as \"OOM\".",
        "table": null,
        "footnotes": [],
        "references": [
            "In node classification task, we leveraged learned node embeddings to train a linear classifier in a transductive setting, utilizing all available edges during training. The distribution of node labels was consistent across datasets: 24% for training, 6% for validation, and 70% for testing. Classification performance was evaluated using Macro-F1 and Micro-F1 metrics, with results reported for the test set based on optimal validation performance (Table 3). Among all baseline methods, we report the best performance with their corresponding optimal meta-path combinations For LAMP, we report the performance with combination involving all the meta-path to demonstrate the robustness. Notably, LAMP consistently surpassed other unsupervised methods and showed remarkable efficacy against supervised models, particularly in sparser datasets like IMDB and Freebase. Crucially, LAMP operates without relying on an optimal meta-path combination, setting it apart from other methodologies. We also examined LAMP’s sensitivity to meta-path combinations (Figure 1), demonstrating its superior stability and robustness, even in comparison to supervised approaches.",
            "Table 3 illustrates that both LAMPv​a​r​1subscriptLAMP𝑣𝑎𝑟1\\text{{LAMP}}_{var1} and LAMPv​a​r​2subscriptLAMP𝑣𝑎𝑟2\\text{{LAMP}}_{var2} suffer a considerable decline in performance. (1) Lacking the meta-path importance γ𝛾\\gamma, LAMPv​a​r​1subscriptLAMP𝑣𝑎𝑟1\\text{{LAMP}}_{var1} struggles to harness sufficient overall structural data. It primarily emphasizes local details based on node attributes. Similarly, without the guidance of meta-path importance γ𝛾\\gamma, LMA tends to prioritize lengthy meta-paths, and neglect potentially valuable shorter meta-paths. The resultant effect weakens LAMPv​a​r​1subscriptLAMP𝑣𝑎𝑟1\\text{{LAMP}}_{var1}’s capability to bridge local and high-order information. This underscores that the guidance from meta-path importance is crucial for the LAMP model. (2) For LAMPv​a​r​2subscriptLAMP𝑣𝑎𝑟2\\text{{LAMP}}_{var2} , employing separate HGNN encoders for the two views might have been effective in HeCo, but it does not work for LAMP. As shown in Table6, LAMPv​a​r​2subscriptLAMP𝑣𝑎𝑟2\\text{{LAMP}}_{var2} lags behind in performance across all datasets.Using disparate HGNN encoders inherently amplifies the differences in embedding produced by the two views, even when the target node attributes remain consistent across both views. This introduces a dilemma for LMA, making it challenging to determine which edges to prune, as the two views already appear distinct. This inconsistency can destabilize the model, increasing the risk of training collapse."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Quantitative results on Sensitivity of Meta-Paths",
        "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><span id=\"S5.T4.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Methods</span></th>\n<th id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><span id=\"S5.T4.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Standard Deviation(%)</span></th>\n<th id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T4.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Min-Max gap(%)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">DMGI</span></td>\n<td id=\"S5.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.46</span></td>\n<td id=\"S5.T4.1.2.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">25.26</span></td>\n</tr>\n<tr id=\"S5.T4.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">XGOAL</span></td>\n<td id=\"S5.T4.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">7.01</span></td>\n<td id=\"S5.T4.1.3.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T4.1.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">24.89</span></td>\n</tr>\n<tr id=\"S5.T4.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">HeCo</span></td>\n<td id=\"S5.T4.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.70</span></td>\n<td id=\"S5.T4.1.4.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T4.1.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">36.69</span></td>\n</tr>\n<tr id=\"S5.T4.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">HAN-1Layer</span></td>\n<td id=\"S5.T4.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.95</span></td>\n<td id=\"S5.T4.1.5.4.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T4.1.5.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.16</span></td>\n</tr>\n<tr id=\"S5.T4.1.6.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.6.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">HAN-2Layer</span></td>\n<td id=\"S5.T4.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.49</span></td>\n<td id=\"S5.T4.1.6.5.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T4.1.6.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">20.82</span></td>\n</tr>\n<tr id=\"S5.T4.1.7.6\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.7.6.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">LAMP</span></td>\n<td id=\"S5.T4.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.7.6.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">2.07</span></td>\n<td id=\"S5.T4.1.7.6.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T4.1.7.6.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">6.08</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "To examine the sensitivity of various meta-path combinations, we conducted experiments on the ACM dataset. Our focus was to observe the variations and the min-max gap in Micro-F1 scores across all possible meta-path combinations. We considered the following candidate meta-paths: \"PAP\", \"PSP\", \"PTP\", \"PPSP\", and \"-PPSP\", which collectively form 26 distinct meta-path combinations, as illustrated in Figure 3. It is important to note that methods like Mp2vec and DGI were excluded from these experiments, as they are incompatible with all meta-path combinations due to their inherent design limitations and their inability to achieve state-of-the-art (SOTA) performance. The results of our experiments are presented in Table 4. In these tests, LAMP demonstrated a significant outperformance over existing unsupervised methods and even surpassed some of the supervised learning methods in terms of Micro-F1 scores. Intriguingly, current state-of-the-art methods, including HeCo and Xgoal, exhibited substantial sensitivity to the choice of meta-path combinations. This finding underscores the importance of robust meta-path handling, especially in self-supervised learning contexts, and highlights the effectiveness of LAMP in addressing this challenge."
        ]
    },
    "S5.T5": {
        "caption": "Table 5: Quantitative results on node clustering.",
        "table": "<table id=\"S5.T5.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Datesets</span></th>\n<th id=\"S5.T5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T5.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">DBLP</span></th>\n<th id=\"S5.T5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T5.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">ACM</span></th>\n<th id=\"S5.T5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"2\"><span id=\"S5.T5.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Freebase</span></th>\n</tr>\n<tr id=\"S5.T5.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Metrics</span></th>\n<th id=\"S5.T5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T5.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">NMI</span></th>\n<th id=\"S5.T5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">ARI</span></th>\n<th id=\"S5.T5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T5.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">NMI</span></th>\n<th id=\"S5.T5.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">ARI</span></th>\n<th id=\"S5.T5.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T5.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">NMI</span></th>\n<th id=\"S5.T5.1.2.2.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T5.1.2.2.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">ARI</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.1.3.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Mp2vec</span></th>\n<td id=\"S5.T5.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.1.3.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">73.55</span></td>\n<td id=\"S5.T5.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.3.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">77.70</span></td>\n<td id=\"S5.T5.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.1.3.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">48.43</span></td>\n<td id=\"S5.T5.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.3.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">34.65</span></td>\n<td id=\"S5.T5.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.1.3.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.47</span></td>\n<td id=\"S5.T5.1.3.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span id=\"S5.T5.1.3.1.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.32</span></td>\n</tr>\n<tr id=\"S5.T5.1.4.2\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><span id=\"S5.T5.1.4.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">DGI</span></th>\n<td id=\"S5.T5.1.4.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.4.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">59.23</span></td>\n<td id=\"S5.T5.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T5.1.4.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">61.85</span></td>\n<td id=\"S5.T5.1.4.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.4.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">51.73</span></td>\n<td id=\"S5.T5.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T5.1.4.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">41.16</span></td>\n<td id=\"S5.T5.1.4.2.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.4.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.34</span></td>\n<td id=\"S5.T5.1.4.2.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T5.1.4.2.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.29</span></td>\n</tr>\n<tr id=\"S5.T5.1.5.3\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><span id=\"S5.T5.1.5.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">DMGI</span></th>\n<td id=\"S5.T5.1.5.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.5.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">70.06</span></td>\n<td id=\"S5.T5.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T5.1.5.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">75.46</span></td>\n<td id=\"S5.T5.1.5.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.5.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">51.66</span></td>\n<td id=\"S5.T5.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T5.1.5.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">46.64</span></td>\n<td id=\"S5.T5.1.5.3.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.5.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.98</span></td>\n<td id=\"S5.T5.1.5.3.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T5.1.5.3.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.91</span></td>\n</tr>\n<tr id=\"S5.T5.1.6.4\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><span id=\"S5.T5.1.6.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">X-GOAL</span></th>\n<td id=\"S5.T5.1.6.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.6.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">61.53</span></td>\n<td id=\"S5.T5.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T5.1.6.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">78.91</span></td>\n<td id=\"S5.T5.1.6.4.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.6.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">56.77</span></td>\n<td id=\"S5.T5.1.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T5.1.6.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">43.67</span></td>\n<td id=\"S5.T5.1.6.4.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.6.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.67</span></td>\n<td id=\"S5.T5.1.6.4.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T5.1.6.4.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.44</span></td>\n</tr>\n<tr id=\"S5.T5.1.7.5\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.7.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><span id=\"S5.T5.1.7.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">HeCo</span></th>\n<td id=\"S5.T5.1.7.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.7.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">74.51</span></td>\n<td id=\"S5.T5.1.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T5.1.7.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">80.17</span></td>\n<td id=\"S5.T5.1.7.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.7.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">56.87</span></td>\n<td id=\"S5.T5.1.7.5.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T5.1.7.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">56.94</span></td>\n<td id=\"S5.T5.1.7.5.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.1.7.5.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">20.38</span></td>\n<td id=\"S5.T5.1.7.5.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T5.1.7.5.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">20.98</span></td>\n</tr>\n<tr id=\"S5.T5.1.8.6\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.8.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.8.6.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">LAMP</span></th>\n<td id=\"S5.T5.1.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T5.1.8.6.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">77.13</span></td>\n<td id=\"S5.T5.1.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.8.6.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">82.73</span></td>\n<td id=\"S5.T5.1.8.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T5.1.8.6.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">58.45</span></td>\n<td id=\"S5.T5.1.8.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.8.6.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">59.12</span></td>\n<td id=\"S5.T5.1.8.6.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T5.1.8.6.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">23.44</span></td>\n<td id=\"S5.T5.1.8.6.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T5.1.8.6.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">24.38</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "In our experimental setup, we employ the K-means clustering algorithm for the learned node embedding. For performance evaluation, we utilize standard clustering metrics: normalized mutual information (NMI) and adjusted rand index (ARI). Recognizing the potential variability introduced by K-means due to its sensitivity to initialization, we execute the clustering process across ten independent runs and present the averaged outcomes in Table 5. Notably, the IMDB dataset is excluded from this evaluation, given its multi-dimensional label structure in HGB dataset. Furthermore, direct comparisons with supervised methodologies are omitted; these models have inherent access to label information during training and are optimized based on validation metrics. Empirical results underscore that LAMP consistently exhibits superior performance across datasets, reaffirming its effectiveness in the clustering context."
        ]
    },
    "S5.T6": {
        "caption": "Table 6: Quantitative results with two LAMP variants.",
        "table": null,
        "footnotes": [],
        "references": [
            "Table 3 illustrates that both LAMPv​a​r​1subscriptLAMP𝑣𝑎𝑟1\\text{{LAMP}}_{var1} and LAMPv​a​r​2subscriptLAMP𝑣𝑎𝑟2\\text{{LAMP}}_{var2} suffer a considerable decline in performance. (1) Lacking the meta-path importance γ𝛾\\gamma, LAMPv​a​r​1subscriptLAMP𝑣𝑎𝑟1\\text{{LAMP}}_{var1} struggles to harness sufficient overall structural data. It primarily emphasizes local details based on node attributes. Similarly, without the guidance of meta-path importance γ𝛾\\gamma, LMA tends to prioritize lengthy meta-paths, and neglect potentially valuable shorter meta-paths. The resultant effect weakens LAMPv​a​r​1subscriptLAMP𝑣𝑎𝑟1\\text{{LAMP}}_{var1}’s capability to bridge local and high-order information. This underscores that the guidance from meta-path importance is crucial for the LAMP model. (2) For LAMPv​a​r​2subscriptLAMP𝑣𝑎𝑟2\\text{{LAMP}}_{var2} , employing separate HGNN encoders for the two views might have been effective in HeCo, but it does not work for LAMP. As shown in Table6, LAMPv​a​r​2subscriptLAMP𝑣𝑎𝑟2\\text{{LAMP}}_{var2} lags behind in performance across all datasets.Using disparate HGNN encoders inherently amplifies the differences in embedding produced by the two views, even when the target node attributes remain consistent across both views. This introduces a dilemma for LMA, making it challenging to determine which edges to prune, as the two views already appear distinct. This inconsistency can destabilize the model, increasing the risk of training collapse."
        ]
    }
}