{
    "PAPER'S NUMBER OF TABLES": 1,
    "S2.T1": {
        "caption": "Table 1. Comparison of distance error between our agents (Agent 1-4) after round 3, all-knowing deep reinforcement learning agent (Agent X) after round 1, partially-knowing deep reinforcement learning agent (Agent Y) after round 1, and traditional lifelong deep reinforcement learning agent (Agent M) after round 8.",
        "table": "",
        "footnotes": "",
        "references": [
            "We conducted a deployment experiment based on 8 sub-task-environment pairs: Axial HGG t1ce, Sagittal HGG t1ce, Coronal HGG t1ce, Axial HGG flair, Sagittal LGG flair, Coronal LGG flair, Coronal LGG t2, Sagittal LGG t1. We sampled one image from each task to test the performance of our model and baseline models. Each round the four federated lifelong learning will receive a new task. They will begin the next round when there is also ERB to train from. Since the agents’ training speeds are very different, A1 and A2 will finish their tasks slower, allowing them to learn from more ERBs at once. As shown in Table 1, after three rounds of training, A2 was able to achieve a mean distance error of 7.81 on all 8 tasks, compared to the all-knowing agent’s 11.78 (p=0.22), but significantly lower compared to partially-knowing agent’s 54.58 (p¡0.001), and the traditional lifelong learning agent’s 15.17 (p=0.01) after eight rounds of training. Since this is a real-world experiment, other agents trained faster than A2, meaning that they did not have all the ERBs available to them when they started their last round of training, resulting in their performances being worse than A2. The possible reasons for Agent 1 to have lower performance than Agent X and Agent M can be because it did not have all ERBs or the training was stuck at a local minimum. This can be easily solved by sharing the model parameters of the latest agent. Note that the all-knowing agent and the partially-knowing agent only train for 1 round for this experiment because they have no lifelong learning capability."
        ]
    }
}