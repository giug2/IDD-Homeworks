{
    "id_table_1": {
        "caption": "Table 1:  Performance comparison (%) on  CMB-Exam ,  MMCU-Medical  and  CMB-Clin  datasets.",
        "table": "S5.T1.3.3",
        "footnotes": [],
        "references": [
            "In  TcRag , the Memory of LLMs is conceptualized as a White Box Turing Machine  (Turing  1936 ) , with the rigorous theoretical proof in  Appendix  8.1 .  Let  Tc = ( S , A , M ,  , s 0 , F ,  ) Tc S A M  subscript s 0 F  \\text{{Tc}}=(\\mathcal{S},\\mathcal{A},\\mathcal{M},\\delta,s_{0},\\mathcal{F},\\sigma) Tc = ( caligraphic_S , caligraphic_A , caligraphic_M , italic_ , italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , caligraphic_F , italic_ )  represent the stack memory of the LLMs, where:",
            "We define a stack-based memory system incorporating a system state variable and prove its equivalence to a universal Turing machine  T T T italic_T  through a series of formal definitions, lemmas, and a main theorem. The detailed proofs are provided in  Appendix  8.1 .  We prove this by showing that for any Turing machine  T T T italic_T , there exists  Tc  that can simulate  T T T italic_T .",
            "In this section, we present our innovative framework,  TcRag , as illustrated in Figure  1 . Traditional methods, such as those based on thought chain  (Yu et al.  2023 ; Li et al.  2023a ; Ma et al.  2023 ; Wei et al.  2023 )  and reasoning and acting approaches   (Yao et al.  2022a ; Shinn et al.  2024 ; Zhu et al.  2024 ) , often suffer from lack of state management, retrieval halting, accumulated erroneous knowledge, token inefficiency, and the issue of being lost in the middle. To address these challenges, we introduce a stack-based memory system that leverages  push  and  pop  actions for efficient memory management for  C1, C3 .  Additionally, to further improve the LLMs knowledge comprehension and adaptability, we incorporate an expert knowledge pre-training module based on the general LLM, which enhances the LLMs understanding and reasoning capabilities (as detailed in  Appendix  8.3 ) for  C2 . Next, in subsection  5.1 , we define the stack memory structure and the composite actions such as  Thought ,  Tool_Observation ,  Backtrack ,  Summary , and  Conclusion .  We then outline the stack statesinitiation, intermediate, and finaland provide specific state calculations in subsection  5.2 .  In  Appendix  8.4 , we describe the prompting strategy and the full algorithm employed in  TcRag .",
            "To answer RQ1, we conduct experiments and report results of the accuracy on the MMCU-Medical, CMB-Exam and CMB-Clin datasets with two LLMs in Table 1 . From the reported accuracy, we can find the following observations:",
            "We perform ablation studies to evaluate the impact of each component within  TcRag , as detailed in Table  1 , with three variants:  (1)  TcRag  without  Backtrack  action (denoted as  w/o Backtrack ),  (2)  TcRag  without  Summary  action (denoted as  w/o Summary ),  (3)  TcRag  without State Monitor, relying solely on the LLMs Final Answer action to determine termination, transforming into a black-box system (denoted as  w/o State Monitor ).  The results reveal that each component contributes positively to the overall performance of  TcRag . The exclusion of any component leads to a noticeable reduction in effectiveness. Particularly, the absence of the State Monitor results in significant performance degradation, highlighting the critical importance of the system state variable in monitoring the process, in line with  C1 , which is essential for preventing overconfidence and ensuring appropriate termination, thereby avoiding excessive or inadequate retrieval.  Moreover, the removal of the  Backtrack  and  Summary  actions underscores the necessity of effective memory management. These actions are crucial for mitigating irrelevant noise and maintaining an optimal system state, aligning with the challenges outlined in  C3 .",
            "Algorithm  1  describes the reasoning loop of  TcRag  for generating a final answer based on user query using a pre-trained Medical LLM. The process begins by initializing the stack memory and the initial state (Lines 1-2). The user query is then pushed into the stack memory (Line 3)."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Medical pre-train data statistics",
        "table": "S8.T2.1",
        "footnotes": [],
        "references": [
            "In this section, we present our innovative framework,  TcRag , as illustrated in Figure  1 . Traditional methods, such as those based on thought chain  (Yu et al.  2023 ; Li et al.  2023a ; Ma et al.  2023 ; Wei et al.  2023 )  and reasoning and acting approaches   (Yao et al.  2022a ; Shinn et al.  2024 ; Zhu et al.  2024 ) , often suffer from lack of state management, retrieval halting, accumulated erroneous knowledge, token inefficiency, and the issue of being lost in the middle. To address these challenges, we introduce a stack-based memory system that leverages  push  and  pop  actions for efficient memory management for  C1, C3 .  Additionally, to further improve the LLMs knowledge comprehension and adaptability, we incorporate an expert knowledge pre-training module based on the general LLM, which enhances the LLMs understanding and reasoning capabilities (as detailed in  Appendix  8.3 ) for  C2 . Next, in subsection  5.1 , we define the stack memory structure and the composite actions such as  Thought ,  Tool_Observation ,  Backtrack ,  Summary , and  Conclusion .  We then outline the stack statesinitiation, intermediate, and finaland provide specific state calculations in subsection  5.2 .  In  Appendix  8.4 , we describe the prompting strategy and the full algorithm employed in  TcRag .",
            "RQ1  (Section  6.2 ): Does  TcRag  outperform the SOTA RAG methods using the same database source?",
            "The results indicate that the ReACT-based approach struggles with accumulating irrelevant noise, leading to overconfidence and inaccurate conclusions, simply due to the unit conversion in Figure  2 .  In contrast,  TcRag  effectively manages its memory and utilizes  Summary  &  Backtrack  actions to prune incorrect retrievals, resulting in more concise and accurate conclusions, which underscores  TcRag s superiority in handling complex tasks (for  C3 ).  Furthermore, we found that the ReACT-based approach tends to prematurely settle on answers when the system state value is high, due to the lack of state management. On the other hand,  TcRag  dynamically monitors the RAG process, ensuring that the system state value meets the termination condition, which highlights the necessity of constructing a system state, in line with  C1 .",
            "These datasets span multiple specialties, giving the model a comprehensive understanding of medical knowledge. The total corpus size is 5647 MB, as shown in Table  2 ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Results for Structural and Partial Attacks",
        "table": "S8.T3.1.1",
        "footnotes": [],
        "references": [
            "We now prove that  Tc  can simulate each step of  T T T italic_T  as in Lemma  3 :",
            "Let  c 1 = ( s  t 1 , w 1  a 1  w 2 ) subscript c 1 s subscript t 1 subscript w 1 subscript a 1 subscript w 2 c_{1}=(st_{1},w_{1}a_{1}w_{2}) italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = ( italic_s italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT )  and  c 2 = ( s  t 2 , w 1   a 2  w 2  ) subscript c 2 s subscript t 2 superscript subscript w 1  subscript a 2 superscript subscript w 2  c_{2}=(st_{2},w_{1}^{\\prime}a_{2}w_{2}^{\\prime}) italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = ( italic_s italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT )  be configurations of  T T T italic_T  with  a t = { L , R } subscript a t L R a_{t}=\\{L,R\\} italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = { italic_L , italic_R } . We prove Lemma  3  by considering the two cases  p  u  s  h p u s h push italic_p italic_u italic_s italic_h  and  p  o  p p o p pop italic_p italic_o italic_p  corresponding to the possible directions of tape head movement in  T T T italic_T .",
            "In this section, we present our innovative framework,  TcRag , as illustrated in Figure  1 . Traditional methods, such as those based on thought chain  (Yu et al.  2023 ; Li et al.  2023a ; Ma et al.  2023 ; Wei et al.  2023 )  and reasoning and acting approaches   (Yao et al.  2022a ; Shinn et al.  2024 ; Zhu et al.  2024 ) , often suffer from lack of state management, retrieval halting, accumulated erroneous knowledge, token inefficiency, and the issue of being lost in the middle. To address these challenges, we introduce a stack-based memory system that leverages  push  and  pop  actions for efficient memory management for  C1, C3 .  Additionally, to further improve the LLMs knowledge comprehension and adaptability, we incorporate an expert knowledge pre-training module based on the general LLM, which enhances the LLMs understanding and reasoning capabilities (as detailed in  Appendix  8.3 ) for  C2 . Next, in subsection  5.1 , we define the stack memory structure and the composite actions such as  Thought ,  Tool_Observation ,  Backtrack ,  Summary , and  Conclusion .  We then outline the stack statesinitiation, intermediate, and finaland provide specific state calculations in subsection  5.2 .  In  Appendix  8.4 , we describe the prompting strategy and the full algorithm employed in  TcRag .",
            "RQ2  (Section  6.3 ): Is the stack framework we designed effective? What impact does each component have on the overall performance?",
            "To demonstrate the effectiveness of the system state variables, we also conducted experiments on  TcRag  via two LLMs on MMCU-Medical and CMB-Exam. As shown in Figure  3 , we found that as    \\sigma italic_  increases, the system state is imposed with small constraints, and the LLM becomes overconfident, reaching conclusions before fully analyzing and planning the necessary steps.  Conversely, when    \\sigma italic_  decreases, the state variable exerts a stronger influence on the output, making it harder to reach the termination state. Thus, the LLM becomes overly cautious, attempting multiple actions and slightly reducing effectiveness.  Overall, we can balance    \\sigma italic_  to ensure optimal performance and accuracy of  TcRag , aligning with the challenges outlined in  C1 .",
            "We now prove that  Tc  can simulate each step of  T T T italic_T  as in Lemma  3 :",
            "Let  c 1 = ( s  t 1 , w 1  a 1  w 2 ) subscript c 1 s subscript t 1 subscript w 1 subscript a 1 subscript w 2 c_{1}=(st_{1},w_{1}a_{1}w_{2}) italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = ( italic_s italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT )  and  c 2 = ( s  t 2 , w 1   a 2  w 2  ) subscript c 2 s subscript t 2 superscript subscript w 1  subscript a 2 superscript subscript w 2  c_{2}=(st_{2},w_{1}^{\\prime}a_{2}w_{2}^{\\prime}) italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = ( italic_s italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT )  be configurations of  T T T italic_T  with  a t = { L , R } subscript a t L R a_{t}=\\{L,R\\} italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = { italic_L , italic_R } . We prove Lemma  3  by considering the two cases  p  u  s  h p u s h push italic_p italic_u italic_s italic_h  and  p  o  p p o p pop italic_p italic_o italic_p  corresponding to the possible directions of tape head movement in  T T T italic_T ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Performance of Various Approaches on CMB Leaderboard",
        "table": "S8.T4.1.1",
        "footnotes": [],
        "references": [
            "In this section, we present our innovative framework,  TcRag , as illustrated in Figure  1 . Traditional methods, such as those based on thought chain  (Yu et al.  2023 ; Li et al.  2023a ; Ma et al.  2023 ; Wei et al.  2023 )  and reasoning and acting approaches   (Yao et al.  2022a ; Shinn et al.  2024 ; Zhu et al.  2024 ) , often suffer from lack of state management, retrieval halting, accumulated erroneous knowledge, token inefficiency, and the issue of being lost in the middle. To address these challenges, we introduce a stack-based memory system that leverages  push  and  pop  actions for efficient memory management for  C1, C3 .  Additionally, to further improve the LLMs knowledge comprehension and adaptability, we incorporate an expert knowledge pre-training module based on the general LLM, which enhances the LLMs understanding and reasoning capabilities (as detailed in  Appendix  8.3 ) for  C2 . Next, in subsection  5.1 , we define the stack memory structure and the composite actions such as  Thought ,  Tool_Observation ,  Backtrack ,  Summary , and  Conclusion .  We then outline the stack statesinitiation, intermediate, and finaland provide specific state calculations in subsection  5.2 .  In  Appendix  8.4 , we describe the prompting strategy and the full algorithm employed in  TcRag .",
            "As a consequence, as outlined in Definition 1, we leverage the stack  M M \\mathcal{M} caligraphic_M  to simulate the LLMs memory.  Based on the meta stack operations of push and pop in Section  4 , the following composite actions have been devised to enhance the reasoning and planning capabilities of LLMs:",
            "RQ3  (Section  6.4 , Appendix  8.6 ): Can  TcRag  really pop up erroneous execution memory and noise injection and achieve memory management?",
            "Here, we compared the specific testing results of our model on CMB with the publicly available rankings on CMB Leaderboard with open-source baselines in Table  4 ."
        ]
    },
    "global_footnotes": [
        "Corresponding authors.",
        "Junfeng Zhao is also at the Big Data Technology Research Center, Nanhu Laboratory, 314002, Jiaxing.",
        "https://cmedbenchmark.llmzoo.com/static/leaderboard.html",
        "https://cmekg.pcl.ac.cn/",
        "https://github.com/king-yyf/CMeKG_tools",
        "https://cpubmed.openi.org.cn/graph/wiki",
        "https://github.com/nuolade/disease-kb",
        "https://www.wikipedia.org/",
        "https://baike.baidu.com/",
        "https://www.yixue.com/",
        "https://www.modelscope.cn/models/damo/nlp_gte_sentence-embedding"
    ]
}