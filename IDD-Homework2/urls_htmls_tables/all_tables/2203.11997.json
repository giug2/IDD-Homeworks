{
    "PAPER'S NUMBER OF TABLES": 1,
    "S3.T1": {
        "caption": "Table 1: Relative benchmark results for the proposed method and baseline models.\nNote that we set “SSL w/o 𝒟c​l​i​e​n​tsubscript𝒟𝑐𝑙𝑖𝑒𝑛𝑡\\mathcal{D}_{client}” as the baseline\n(100%) to calculate the relative performance for other two methods\nin each column. FSSL is equivalent to the FSSL (4x) in Fig. 2. FSSL consistently outperforms SSL w/o 𝒟c​l​i​e​n​tsubscript𝒟𝑐𝑙𝑖𝑒𝑛𝑡\\mathcal{D}_{client} baseline on all data partitions. The improvement, however, is less compared to SSL w/ 𝒟c​l​i​e​n​tsubscript𝒟𝑐𝑙𝑖𝑒𝑛𝑡\\mathcal{D}_{client} when the 𝒟c​l​i​e​n​tsubscript𝒟𝑐𝑙𝑖𝑒𝑛𝑡\\mathcal{D}_{client} is directly used to train the classifier.\n",
        "table": "",
        "footnotes": "\n\n\n\n\n\nMethods\n𝒟𝒟\\mathcal{D}ℐℐ\\mathcal{I}\n\n𝒟𝒟\\mathcal{D}𝒰𝒰\\mathcal{U}\n𝒟𝒟\\mathcal{D}𝒯𝒯\\mathcal{T}\n\nAUC (%)\nPrecision (%) at recall r𝑟r\nAUC (%)\nPrecision (%) at recall r𝑟r\nAUC (%)\nPrecision (%) at recall r𝑟r\n\nr=0.7𝑟0.7r=0.7\nr=0.8𝑟0.8r=0.8\nr=0.9𝑟0.9r=0.9\nr=0.7𝑟0.7r=0.7\nr=0.8𝑟0.8r=0.8\nr=0.9𝑟0.9r=0.9\nr=0.7𝑟0.7r=0.7\nr=0.8𝑟0.8r=0.8\nr=0.9𝑟0.9r=0.9\n\nSSL w/o 𝒟c​l​i​e​n​tsubscript𝒟𝑐𝑙𝑖𝑒𝑛𝑡\\mathcal{D}_{client}\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n\nFSSL\n4.55↑↑\\uparrow\n7.41↑↑\\uparrow\n10.51↑↑\\uparrow\n18.56↑↑\\uparrow\n3.15↑↑\\uparrow\n2.94↑↑\\uparrow\n7.56↑↑\\uparrow\n20.30↑↑\\uparrow\n4.97↑↑\\uparrow\n5.72↑↑\\uparrow\n8.59↑↑\\uparrow\n18.80↑↑\\uparrow\n\nSSL w/ 𝒟c​l​i​e​n​tsubscript𝒟𝑐𝑙𝑖𝑒𝑛𝑡\\mathcal{D}_{client}\n13.17↑↑\\uparrow\n14.01↑↑\\uparrow\n21.60↑↑\\uparrow\n39.57↑↑\\uparrow\n16.96↑↑\\uparrow\n17.71↑↑\\uparrow\n22.75↑↑\\uparrow\n52.36↑↑\\uparrow\n14.87↑↑\\uparrow\n13.15↑↑\\uparrow\n23.39↑↑\\uparrow\n50.83↑↑\\uparrow\n\n\n",
        "references": [
            "The results of different models benchmarked on 𝒟ℐsubscript𝒟ℐ\\mathcal{D}_{\\mathcal{I}}, 𝒟𝒰subscript𝒟𝒰\\mathcal{D}_{\\mathcal{U}}, and 𝒟𝒯subscript𝒟𝒯\\mathcal{D}_{\\mathcal{T}} are shown in Table 1. The proposed\nmethod consistently outperforms the baseline model SSL w/o 𝒟c​l​i​e​n​tsubscript𝒟𝑐𝑙𝑖𝑒𝑛𝑡\\mathcal{D}_{client}\nin all benchmarks, whereas SSL w/ 𝒟c​l​i​e​n​tsubscript𝒟𝑐𝑙𝑖𝑒𝑛𝑡\\mathcal{D}_{client} yields the\nbest model performance among all three models.\nAlthough the improvement in the overall AUC brought by FL of representations\nis relatively small, the improvements at high recall regions (e.g., 0.6-0.9) are significant.\nSince high recall regions are of practical production interest, our results show\nclear evidence that fine-tuning acoustic event classification model\nin the post-deployment stage through continual learning of representations\nis feasible. The vastly superior performance from SSL w/ 𝒟c​l​i​e​n​tsubscript𝒟𝑐𝑙𝑖𝑒𝑛𝑡\\mathcal{D}_{client}\nthe model indicates that when well-annotated data is accessible to centralized\ncomputing resources, conventional supervised learning is still more\neffective in optimizing model weights with respect to fixed learning\ntargets. However, for particular use cases where sensitive data is\ninvolved and the learning algorithm is not allowed to directly interact\nwith large datasets on the cloud, centralized learning algorithms\nis consequently infeasible. In turn, federated learning may be one\nof the few solutions to the task."
        ]
    }
}