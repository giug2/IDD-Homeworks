{
    "S4.T1.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.1.1.1.1\">Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.2\">DSC (F1)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.3\">Precision</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.4\">Recall</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.1.2.1.1\">YoloS(avg)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.2\">0.83 &#177; 0.015</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.3\">0.84 &#177; 0.014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.4\">0.83 &#177; 0.016</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.3.2.1\">SAM (avg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.2\">0.86 &#177; 0.120</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.3\">0.87 &#177; 0.100</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.4\">0.85 &#177; 0.110</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.1.4.3.1\">H-vmunet (avg)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.4.3.2\">0.92 &#177; 0.062</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.4.3.3\">0.92 &#177; 0.061</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.4.3.4\">0.92 &#177; 0.064</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 1:  Comparison results on the prostate 2019 dataset ",
        "footnotes": [],
        "references": [
            "With TP, FP, TN, and FN indiciating true positives, false positives, true negatives, and false negatives, respectively.\nThese metrics highlight the challenge in differentiating between four classes in Gleason2019 and SICAPv2 dataset. It is worth mentioning that due to severe class imbalance in these datasets, we opt for a weighted average over class metrics to provide a more comprehensive measurement of overall performance. This approach ensures that the performance metrics reflect the proportion of each class in the dataset, rather than being skewed by the performance on less frequent Gleason patterns.\nWe compared the YoloS, SAM, and H-vmunet models on the Prostate2019 and SICAP-V2 datasets using Dice score, precision, and recall metrics, as presented in Tables 1 and 2. On the Prostate2019 dataset, H-vmunet outperformed the other models, achieving the a dice score of 0.92 (highest score) across all metrics, which highlights its effectiveness in segmenting Gleason images. This superior performance can be attributed to the advanced architecture of H-vmunet, which leverages vision mamba to better capture and differentiate complex tissue structures. Similarly, on the SICAP-V2 dataset, H-vmunet again achieved the best results (dice score of 0.68) compared to SAM and YoloS, demonstrating its robustness and generalization capability across different types of pathological images. The consistent high performance of H-vmunet suggests that its sophisticated model design, which includes enhanced feature extraction and segmentation strategies, is particularly well-suited for medical image analysis, making it more effective in handling the variability and complexity inherent in these datasets.\nThe H-vmunet showcases notable performance metrics, with Precision and Recall values both standing at 0.68 for the SICAP-V2 and 0.92. This uniformity in scores indicates a balanced approach in identifying true positives and minimizing false negatives, suggesting a well-rounded performance of the H-vmunet method in the evaluated dataset. Such consistency across these key metrics underscores the method’s reliability and effectiveness in classification tasks, offering promising insights for further application and refinement in related domains."
        ]
    },
    "S4.T2.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T2.1.1.1.1\">Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.2\">DSC (F1)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.3\">Precision</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.4\">Recall</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.2.1.1\">YoloS(avg)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.1.2\">0.65 &#177; 0.025</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.1.3\">0.64 &#177; 0.027</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.1.4\">0.65 &#177; 0.024</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.3.2.1\">SAM (avg)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.3.2.2\">0.66 &#177; 0.12</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.3.2.3\">0.67 &#177; 0.049</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.3.2.4\">0.66 &#177; 0.027</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.1.4.3.1\">H-vmunet (avg)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.4.3.2\">0.68 &#177; 0.034</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.4.3.3\">0.68 &#177; 0.047</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.4.3.4\">0.68 &#177; 0.031</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 2:  Comparison results on the SICAP-V2 dataset ",
        "footnotes": [],
        "references": [
            "With TP, FP, TN, and FN indiciating true positives, false positives, true negatives, and false negatives, respectively.\nThese metrics highlight the challenge in differentiating between four classes in Gleason2019 and SICAPv2 dataset. It is worth mentioning that due to severe class imbalance in these datasets, we opt for a weighted average over class metrics to provide a more comprehensive measurement of overall performance. This approach ensures that the performance metrics reflect the proportion of each class in the dataset, rather than being skewed by the performance on less frequent Gleason patterns.\nWe compared the YoloS, SAM, and H-vmunet models on the Prostate2019 and SICAP-V2 datasets using Dice score, precision, and recall metrics, as presented in Tables 1 and 2. On the Prostate2019 dataset, H-vmunet outperformed the other models, achieving the a dice score of 0.92 (highest score) across all metrics, which highlights its effectiveness in segmenting Gleason images. This superior performance can be attributed to the advanced architecture of H-vmunet, which leverages vision mamba to better capture and differentiate complex tissue structures. Similarly, on the SICAP-V2 dataset, H-vmunet again achieved the best results (dice score of 0.68) compared to SAM and YoloS, demonstrating its robustness and generalization capability across different types of pathological images. The consistent high performance of H-vmunet suggests that its sophisticated model design, which includes enhanced feature extraction and segmentation strategies, is particularly well-suited for medical image analysis, making it more effective in handling the variability and complexity inherent in these datasets.\nThe H-vmunet showcases notable performance metrics, with Precision and Recall values both standing at 0.68 for the SICAP-V2 and 0.92. This uniformity in scores indicates a balanced approach in identifying true positives and minimizing false negatives, suggesting a well-rounded performance of the H-vmunet method in the evaluated dataset. Such consistency across these key metrics underscores the method’s reliability and effectiveness in classification tasks, offering promising insights for further application and refinement in related domains."
        ]
    }
}