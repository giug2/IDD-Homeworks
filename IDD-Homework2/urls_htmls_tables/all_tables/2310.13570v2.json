{
    "S4.T1": {
        "caption": "Table 1: Comparison with other methods on the OK-VQA dataset: Our method with 9 question-informative captions achieves state-of-the-art performance.",
        "table": "<table id=\"S4.T1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Method</th>\n<th id=\"S4.T1.1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Knowledge Resources</th>\n<th id=\"S4.T1.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Acc (%)</th>\n</tr>\n<tr id=\"S4.T1.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">KRISP</th>\n<th id=\"S4.T1.1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Wikipedia+ConceptNet</th>\n<th id=\"S4.T1.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">38.35</th>\n</tr>\n<tr id=\"S4.T1.1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">MAVEx</th>\n<th id=\"S4.T1.1.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Wikipedia+ConceptNet+Google Images</th>\n<th id=\"S4.T1.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">39.4</th>\n</tr>\n<tr id=\"S4.T1.1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Unified-IO (2.8B)</th>\n<th id=\"S4.T1.1.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Multimodal Pretraining</th>\n<th id=\"S4.T1.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">54</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.1.5.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.5.1.1\" class=\"ltx_td ltx_align_center\">Flamingo (80B)</td>\n<td id=\"S4.T1.1.1.5.1.2\" class=\"ltx_td ltx_align_left\">Multimodal Pretraining</td>\n<td id=\"S4.T1.1.1.5.1.3\" class=\"ltx_td ltx_align_center\">57.8</td>\n</tr>\n<tr id=\"S4.T1.1.1.6.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.6.2.1\" class=\"ltx_td ltx_align_center\">PICa-Full</td>\n<td id=\"S4.T1.1.1.6.2.2\" class=\"ltx_td ltx_align_left\">Frozen GPT-3 (175B)</td>\n<td id=\"S4.T1.1.1.6.2.3\" class=\"ltx_td ltx_align_center\">48.0</td>\n</tr>\n<tr id=\"S4.T1.1.1.7.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.7.3.1\" class=\"ltx_td ltx_align_center\">KAT_base (single)</td>\n<td id=\"S4.T1.1.1.7.3.2\" class=\"ltx_td ltx_align_left\">Wikidata+Frozen GPT-3 (175B)</td>\n<td id=\"S4.T1.1.1.7.3.3\" class=\"ltx_td ltx_align_center\">50.58</td>\n</tr>\n<tr id=\"S4.T1.1.1.8.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.8.4.1\" class=\"ltx_td ltx_align_center\">KAT_large (single)</td>\n<td id=\"S4.T1.1.1.8.4.2\" class=\"ltx_td ltx_align_left\">Wikidata+Frozen GPT-3 (175B)</td>\n<td id=\"S4.T1.1.1.8.4.3\" class=\"ltx_td ltx_align_center\">53.09</td>\n</tr>\n<tr id=\"S4.T1.1.1.9.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.9.5.1\" class=\"ltx_td ltx_align_center\">KAT_large (ensemble)</td>\n<td id=\"S4.T1.1.1.9.5.2\" class=\"ltx_td ltx_align_left\">Wikidata+Frozen GPT-3 (175B)</td>\n<td id=\"S4.T1.1.1.9.5.3\" class=\"ltx_td ltx_align_center\">54.41</td>\n</tr>\n<tr id=\"S4.T1.1.1.10.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.10.6.1\" class=\"ltx_td ltx_align_center\">REVIVE_large (single)</td>\n<td id=\"S4.T1.1.1.10.6.2\" class=\"ltx_td ltx_align_left\">Wikidata+Frozen GPT-3 (175B)</td>\n<td id=\"S4.T1.1.1.10.6.3\" class=\"ltx_td ltx_align_center\">56.6</td>\n</tr>\n<tr id=\"S4.T1.1.1.11.7\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.11.7.1\" class=\"ltx_td ltx_align_center\">REVIVE_large (ensemble)</td>\n<td id=\"S4.T1.1.1.11.7.2\" class=\"ltx_td ltx_align_left\">Wikidata+Frozen GPT-3 (175B)</td>\n<td id=\"S4.T1.1.1.11.7.3\" class=\"ltx_td ltx_align_center\">58.0</td>\n</tr>\n<tr id=\"S4.T1.1.1.12.8\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.12.8.1\" class=\"ltx_td ltx_align_center\">Prophet</td>\n<td id=\"S4.T1.1.1.12.8.2\" class=\"ltx_td ltx_align_left\">Frozen GPT-3 (175B)</td>\n<td id=\"S4.T1.1.1.12.8.3\" class=\"ltx_td ltx_align_center\">61.1</td>\n</tr>\n<tr id=\"S4.T1.1.1.13.9\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.13.9.1\" class=\"ltx_td ltx_align_center\">Ours</td>\n<td id=\"S4.T1.1.1.13.9.2\" class=\"ltx_td ltx_align_left\">Frozen LLaMA (13B)</td>\n<td id=\"S4.T1.1.1.13.9.3\" class=\"ltx_td ltx_align_center\">58.69</td>\n</tr>\n<tr id=\"S4.T1.1.1.14.10\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.14.10.1\" class=\"ltx_td ltx_align_center\">Ours + MCAN</td>\n<td id=\"S4.T1.1.1.14.10.2\" class=\"ltx_td ltx_align_left\">Frozen LLaMA (13B)</td>\n<td id=\"S4.T1.1.1.14.10.3\" class=\"ltx_td ltx_align_center\">60.02</td>\n</tr>\n<tr id=\"S4.T1.1.1.15.11\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.15.11.1\" class=\"ltx_td ltx_align_center\">Ours</td>\n<td id=\"S4.T1.1.1.15.11.2\" class=\"ltx_td ltx_align_left\">Frozen LLaMA 2 (13B)</td>\n<td id=\"S4.T1.1.1.15.11.3\" class=\"ltx_td ltx_align_center\">59.07</td>\n</tr>\n<tr id=\"S4.T1.1.1.16.12\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.16.12.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.16.12.1.1\" class=\"ltx_text ltx_font_bold\">Ours + MCAN</span></td>\n<td id=\"S4.T1.1.1.16.12.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T1.1.1.16.12.2.1\" class=\"ltx_text ltx_font_bold\">Frozen LLaMA 2 (13B)</span></td>\n<td id=\"S4.T1.1.1.16.12.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.16.12.3.1\" class=\"ltx_text ltx_font_bold\">61.2</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Comparative results on OK-VQA: Table 1 summarizes the results of various methods on OK-VQA including our best method (last row) which uses 9 question-informative captions and 5 query ensembles. When using LLaMA our approach outperforms all methods and achieves comparable results with Prophet especially when using the same shot selection strategy based on MCAN Yu etÂ al. (2019). Moreover, it performs better than Unified-IO and the 80B Flamingo which have been pre-trained with multimodal objectives. When compared to methods that rely on GPT-3 for implicit knowledge extraction, our approach outperforms PICa-Full which only uses generic image captions by 12.02% while outperforming the SOTA supervised methods KAT and REVIVE by 5.61% and 2.02% respectively. Finally, when using LLaMA 2 and MCAN-based shot selection strategy, our method achieves state-of-the-art accuracy of 61.2%."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Comparison with other methods on the A-OK-VQA dataset: Our method with 9 question-informative captions achieves state-of-the-art performance at the direct answer (DA) setting. Note that our method does not support multiple-choice (MC).",
        "table": "<table id=\"S4.T2.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_center\">Method</td>\n<td id=\"S4.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_left\">DA</td>\n<td id=\"S4.T2.1.1.1.1.3\" class=\"ltx_td\"></td>\n<td id=\"S4.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_center\">MC</td>\n<td id=\"S4.T2.1.1.1.1.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.T2.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.2.2.1\" class=\"ltx_td\"></td>\n<td id=\"S4.T2.1.1.2.2.2\" class=\"ltx_td ltx_align_left\">Val</td>\n<td id=\"S4.T2.1.1.2.2.3\" class=\"ltx_td ltx_align_center\">Test</td>\n<td id=\"S4.T2.1.1.2.2.4\" class=\"ltx_td ltx_align_center\">Val</td>\n<td id=\"S4.T2.1.1.2.2.5\" class=\"ltx_td ltx_align_left\">Test</td>\n</tr>\n<tr id=\"S4.T2.1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.3.3.1\" class=\"ltx_td ltx_align_center\">ClipCap</td>\n<td id=\"S4.T2.1.1.3.3.2\" class=\"ltx_td ltx_align_left\">30.9</td>\n<td id=\"S4.T2.1.1.3.3.3\" class=\"ltx_td ltx_align_center\">25.9</td>\n<td id=\"S4.T2.1.1.3.3.4\" class=\"ltx_td ltx_align_center\">56.9</td>\n<td id=\"S4.T2.1.1.3.3.5\" class=\"ltx_td ltx_align_left\">51.4</td>\n</tr>\n<tr id=\"S4.T2.1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.4.4.1\" class=\"ltx_td ltx_align_center\">ViLBERT</td>\n<td id=\"S4.T2.1.1.4.4.2\" class=\"ltx_td ltx_align_left\">30.6</td>\n<td id=\"S4.T2.1.1.4.4.3\" class=\"ltx_td ltx_align_center\">25.9</td>\n<td id=\"S4.T2.1.1.4.4.4\" class=\"ltx_td ltx_align_center\">49.1</td>\n<td id=\"S4.T2.1.1.4.4.5\" class=\"ltx_td ltx_align_left\">41.5</td>\n</tr>\n<tr id=\"S4.T2.1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.5.5.1\" class=\"ltx_td ltx_align_center\">LXMERT</td>\n<td id=\"S4.T2.1.1.5.5.2\" class=\"ltx_td ltx_align_left\">30.7</td>\n<td id=\"S4.T2.1.1.5.5.3\" class=\"ltx_td ltx_align_center\">25.9</td>\n<td id=\"S4.T2.1.1.5.5.4\" class=\"ltx_td ltx_align_center\">51.4</td>\n<td id=\"S4.T2.1.1.5.5.5\" class=\"ltx_td ltx_align_left\">41.6</td>\n</tr>\n<tr id=\"S4.T2.1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.6.6.1\" class=\"ltx_td ltx_align_center\">KRISP</td>\n<td id=\"S4.T2.1.1.6.6.2\" class=\"ltx_td ltx_align_left\">33.7</td>\n<td id=\"S4.T2.1.1.6.6.3\" class=\"ltx_td ltx_align_center\">27.1</td>\n<td id=\"S4.T2.1.1.6.6.4\" class=\"ltx_td ltx_align_center\">51.9</td>\n<td id=\"S4.T2.1.1.6.6.5\" class=\"ltx_td ltx_align_left\">42.2</td>\n</tr>\n<tr id=\"S4.T2.1.1.7.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.7.7.1\" class=\"ltx_td ltx_align_center\">GPV-2</td>\n<td id=\"S4.T2.1.1.7.7.2\" class=\"ltx_td ltx_align_left\">48.6</td>\n<td id=\"S4.T2.1.1.7.7.3\" class=\"ltx_td ltx_align_center\">40.7</td>\n<td id=\"S4.T2.1.1.7.7.4\" class=\"ltx_td ltx_align_center\">60.3</td>\n<td id=\"S4.T2.1.1.7.7.5\" class=\"ltx_td ltx_align_left\">53.7</td>\n</tr>\n<tr id=\"S4.T2.1.1.8.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.8.8.1\" class=\"ltx_td ltx_align_center\">Unified-IO</td>\n<td id=\"S4.T2.1.1.8.8.2\" class=\"ltx_td ltx_align_left\">-</td>\n<td id=\"S4.T2.1.1.8.8.3\" class=\"ltx_td ltx_align_center\">45.2</td>\n<td id=\"S4.T2.1.1.8.8.4\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T2.1.1.8.8.5\" class=\"ltx_td ltx_align_left\">-</td>\n</tr>\n<tr id=\"S4.T2.1.1.9.9\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.9.9.1\" class=\"ltx_td ltx_align_center\">Prophet</td>\n<td id=\"S4.T2.1.1.9.9.2\" class=\"ltx_td ltx_align_left\">58.2</td>\n<td id=\"S4.T2.1.1.9.9.3\" class=\"ltx_td ltx_align_center\">55.7</td>\n<td id=\"S4.T2.1.1.9.9.4\" class=\"ltx_td ltx_align_center\">59.3</td>\n<td id=\"S4.T2.1.1.9.9.5\" class=\"ltx_td ltx_align_left\">57.3</td>\n</tr>\n<tr id=\"S4.T2.1.1.10.10\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.10.10.1\" class=\"ltx_td ltx_align_center\">OursÂ (LLaMA)</td>\n<td id=\"S4.T2.1.1.10.10.2\" class=\"ltx_td ltx_align_left\">54.4</td>\n<td id=\"S4.T2.1.1.10.10.3\" class=\"ltx_td ltx_align_center\">53.8</td>\n<td id=\"S4.T2.1.1.10.10.4\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T2.1.1.10.10.5\" class=\"ltx_td ltx_align_left\">-</td>\n</tr>\n<tr id=\"S4.T2.1.1.11.11\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.11.11.1\" class=\"ltx_td ltx_align_center\">Ours + MCAN (LLaMA)</td>\n<td id=\"S4.T2.1.1.11.11.2\" class=\"ltx_td ltx_align_left\">57.4</td>\n<td id=\"S4.T2.1.1.11.11.3\" class=\"ltx_td ltx_align_center\">55.0</td>\n<td id=\"S4.T2.1.1.11.11.4\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T2.1.1.11.11.5\" class=\"ltx_td ltx_align_left\">-</td>\n</tr>\n<tr id=\"S4.T2.1.1.12.12\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.12.12.1\" class=\"ltx_td ltx_align_center\">OursÂ (LLaMA 2)</td>\n<td id=\"S4.T2.1.1.12.12.2\" class=\"ltx_td ltx_align_left\">57.1</td>\n<td id=\"S4.T2.1.1.12.12.3\" class=\"ltx_td ltx_align_center\">55.4</td>\n<td id=\"S4.T2.1.1.12.12.4\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T2.1.1.12.12.5\" class=\"ltx_td ltx_align_left\">-</td>\n</tr>\n<tr id=\"S4.T2.1.1.13.13\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.13.13.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.1.13.13.1.1\" class=\"ltx_text ltx_font_bold\">Ours + MCAN (LLaMA 2)</span></td>\n<td id=\"S4.T2.1.1.13.13.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.1.13.13.2.1\" class=\"ltx_text ltx_font_bold\">58.6</span></td>\n<td id=\"S4.T2.1.1.13.13.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.1.13.13.3.1\" class=\"ltx_text ltx_font_bold\">57.5</span></td>\n<td id=\"S4.T2.1.1.13.13.4\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T2.1.1.13.13.5\" class=\"ltx_td ltx_align_left\">-</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Comparative results on A-OK-VQA: Table 2 summarizes the results of various methods on A-OK-VQA including our best method (last row) which uses 9 question-informative captions and 5 query ensembles. We compare our method to the strong baselines\nin Schwenk etÂ al. (2022) and the current state-of-the-art method Prophet Shao etÂ al. (2023). When employing LLaMA, our approach surpasses all other methods on the DA setting and achieves comparable results to Prophet, particularly when employing the same shot selection strategy based on MCAN. Finally, with LLaMA 2 and MCAN our method attains state-of-the-art performance on both the validation and test sets, achieving 58.6% and 57.5% accuracy respectively, demonstrating the effectiveness and robust generalization of our proposed method."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Generic vs. question-informative captions.",
        "table": "<table id=\"S5.T3.2.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.2.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.2.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\">Captions</th>\n<th id=\"S5.T3.2.2.2.4\" class=\"ltx_td ltx_nopad_r ltx_th ltx_th_column\"></th>\n<th id=\"S5.T3.2.2.2.5\" class=\"ltx_td ltx_nopad_r ltx_th ltx_th_column\"></th>\n<th id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\"><math id=\"S5.T3.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"n\" display=\"inline\"><semantics id=\"S5.T3.1.1.1.1.m1.1a\"><mi id=\"S5.T3.1.1.1.1.m1.1.1\" xref=\"S5.T3.1.1.1.1.m1.1.1.cmml\">n</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.1.1.1.1.m1.1b\"><ci id=\"S5.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T3.1.1.1.1.m1.1.1\">ð</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.1.1.1.1.m1.1c\">n</annotation></semantics></math></th>\n<th id=\"S5.T3.2.2.2.2\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\"><math id=\"S5.T3.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"k\" display=\"inline\"><semantics id=\"S5.T3.2.2.2.2.m1.1a\"><mi id=\"S5.T3.2.2.2.2.m1.1.1\" xref=\"S5.T3.2.2.2.2.m1.1.1.cmml\">k</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.2.2.2.2.m1.1b\"><ci id=\"S5.T3.2.2.2.2.m1.1.1.cmml\" xref=\"S5.T3.2.2.2.2.m1.1.1\">ð</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.2.2.2.2.m1.1c\">k</annotation></semantics></math></th>\n<th id=\"S5.T3.2.2.2.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\">Acc (%)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.2.2.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.2.2.3.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">Generic</td>\n<td id=\"S5.T3.2.2.3.1.2\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S5.T3.2.2.3.1.3\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S5.T3.2.2.3.1.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">14</td>\n<td id=\"S5.T3.2.2.3.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">5</td>\n<td id=\"S5.T3.2.2.3.1.6\" class=\"ltx_td ltx_nopad_r ltx_align_center\">43.35</td>\n</tr>\n<tr id=\"S5.T3.2.2.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.2.2.4.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Question-informative</td>\n<td id=\"S5.T3.2.2.4.2.2\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S5.T3.2.2.4.2.3\" class=\"ltx_td ltx_nopad_r\"></td>\n<td id=\"S5.T3.2.2.4.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">14</td>\n<td id=\"S5.T3.2.2.4.2.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">5</td>\n<td id=\"S5.T3.2.2.4.2.6\" class=\"ltx_td ltx_nopad_r ltx_align_center\">57.56</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Effect of question-informative captions:\nTable 3 shows the performance of our method when using generic captions vs question-informative captions for in-context learning which is the key component of our system. Following Yang etÂ al. (2022); Shao etÂ al. (2023) we leverage the OSCAR+ Zhang etÂ al. (2021) as the captioning model. The results suggest using question-informative captions results in huge accuracy boosts (43.35% vs 57.56%)."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Accuracy when using different shot selection strategies. Avg. question and image sim. strategy retrieves shots based on the average cosine similarity between the test sampleâs question and image, and the training examplesâ question and image. MCAN latent space strategy retrieves shots that are closer to the test sample in the trained MCANâs latent space.",
        "table": "<table id=\"S5.T4.3.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.3.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T4.3.3.3.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\">Shot Selection Strategy</th>\n<th id=\"S5.T4.3.3.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\">Captions</th>\n<th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\"><math id=\"S5.T4.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"m\" display=\"inline\"><semantics id=\"S5.T4.1.1.1.1.m1.1a\"><mi id=\"S5.T4.1.1.1.1.m1.1.1\" xref=\"S5.T4.1.1.1.1.m1.1.1.cmml\">m</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.1.1.1.1.m1.1b\"><ci id=\"S5.T4.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1\">ð</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.1.1.1.1.m1.1c\">m</annotation></semantics></math></th>\n<th id=\"S5.T4.2.2.2.2\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\"><math id=\"S5.T4.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"n\" display=\"inline\"><semantics id=\"S5.T4.2.2.2.2.m1.1a\"><mi id=\"S5.T4.2.2.2.2.m1.1.1\" xref=\"S5.T4.2.2.2.2.m1.1.1.cmml\">n</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.2.2.2.2.m1.1b\"><ci id=\"S5.T4.2.2.2.2.m1.1.1.cmml\" xref=\"S5.T4.2.2.2.2.m1.1.1\">ð</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.2.2.2.2.m1.1c\">n</annotation></semantics></math></th>\n<th id=\"S5.T4.3.3.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\"><math id=\"S5.T4.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"k\" display=\"inline\"><semantics id=\"S5.T4.3.3.3.3.m1.1a\"><mi id=\"S5.T4.3.3.3.3.m1.1.1\" xref=\"S5.T4.3.3.3.3.m1.1.1.cmml\">k</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.3.3.3.3.m1.1b\"><ci id=\"S5.T4.3.3.3.3.m1.1.1.cmml\" xref=\"S5.T4.3.3.3.3.m1.1.1\">ð</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.3.3.3.3.m1.1c\">k</annotation></semantics></math></th>\n<th id=\"S5.T4.3.3.3.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\">Acc (%)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.3.3.4.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.3.3.4.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">Random</td>\n<td id=\"S5.T4.3.3.4.1.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Question-informative</td>\n<td id=\"S5.T4.3.3.4.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">1</td>\n<td id=\"S5.T4.3.3.4.1.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">14</td>\n<td id=\"S5.T4.3.3.4.1.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">5</td>\n<td id=\"S5.T4.3.3.4.1.6\" class=\"ltx_td ltx_nopad_r ltx_align_center\">53.19</td>\n</tr>\n<tr id=\"S5.T4.3.3.5.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.3.3.5.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Avg. Question and Image Sim.</td>\n<td id=\"S5.T4.3.3.5.2.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Question-informative</td>\n<td id=\"S5.T4.3.3.5.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">1</td>\n<td id=\"S5.T4.3.3.5.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">14</td>\n<td id=\"S5.T4.3.3.5.2.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">5</td>\n<td id=\"S5.T4.3.3.5.2.6\" class=\"ltx_td ltx_nopad_r ltx_align_center\">56.50</td>\n</tr>\n<tr id=\"S5.T4.3.3.6.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.3.3.6.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">MCAN latent space</td>\n<td id=\"S5.T4.3.3.6.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Question-informative</td>\n<td id=\"S5.T4.3.3.6.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">1</td>\n<td id=\"S5.T4.3.3.6.3.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">14</td>\n<td id=\"S5.T4.3.3.6.3.5\" class=\"ltx_td ltx_nopad_r ltx_align_center\">5</td>\n<td id=\"S5.T4.3.3.6.3.6\" class=\"ltx_td ltx_nopad_r ltx_align_center\">57.56</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Effect of shot selection strategy:\nTableÂ 4 shows that selecting random shots during in-context learning hurts the accuracy, confirming the findings of Yang etÂ al. (2022). Retrieving shots based on the similarity between the test sample and the training examples yields a significant accuracy boost. Prophetâs shot selection strategy based on MCAN also seems to be effective but we note that it is based on pre-training a vanilla VQA model on a different\ndataset (VQA-v2)."
        ]
    },
    "S5.3": {
        "caption": "Figure 2: (a) Accuracy vs number of question informative captions used per shot during few shot in-context learning. (b) Accuracy vs number of prompts kðk used during in-context learning.",
        "table": "<table id=\"S5.2.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.2.2.2\" class=\"ltx_tr\">\n<th id=\"S5.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">\n<img src=\"/html/2310.13570/assets/images/ablate_no_of_captions.png\" id=\"S5.1.1.1.1.g1\" class=\"ltx_graphics ltx_img_landscape\" width=\"135\" height=\"102\" alt=\"[Uncaptioned image]\">\n</th>\n<td id=\"S5.2.2.2.2\" class=\"ltx_td ltx_align_center\"><img src=\"/html/2310.13570/assets/images/ablate_k_ensemble.png\" id=\"S5.2.2.2.2.g1\" class=\"ltx_graphics ltx_img_landscape\" width=\"135\" height=\"102\" alt=\"[Uncaptioned image]\"></td>\n</tr>\n<tr id=\"S5.2.2.3.1\" class=\"ltx_tr\">\n<th id=\"S5.2.2.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">(a)</th>\n<td id=\"S5.2.2.3.1.2\" class=\"ltx_td ltx_align_center\">(b)</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": []
    }
}