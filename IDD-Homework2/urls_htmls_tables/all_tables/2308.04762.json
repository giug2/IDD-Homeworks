{
    "PAPER'S NUMBER OF TABLES": 3,
    "S3.T1": {
        "caption": "TABLE I: Experimental setup",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Dataset</th>\n<td id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">MNIST</td>\n<td id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">CIFAR-10</td>\n<td id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">IMDb</td>\n</tr>\n<tr id=\"S3.T1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Number of nodes</th>\n<td id=\"S3.T1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">3, 5, 10</td>\n<td id=\"S3.T1.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">3, 5, 10</td>\n<td id=\"S3.T1.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">3, 5</td>\n</tr>\n<tr id=\"S3.T1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Model size</th>\n<td id=\"S3.T1.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1,199,882</td>\n<td id=\"S3.T1.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\">2,168,746</td>\n<td id=\"S3.T1.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\">328,386</td>\n</tr>\n<tr id=\"S3.T1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Input size</th>\n<td id=\"S3.T1.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_t\">784</td>\n<td id=\"S3.T1.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_t\">1024</td>\n<td id=\"S3.T1.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_t\">80</td>\n</tr>\n<tr id=\"S3.T1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Mini-batch size</th>\n<td id=\"S3.T1.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_t\">100</td>\n<td id=\"S3.T1.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_t\">100</td>\n<td id=\"S3.T1.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_t\">100</td>\n</tr>\n<tr id=\"S3.T1.1.6.6\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Learning-rate</th>\n<td id=\"S3.T1.1.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.005</td>\n<td id=\"S3.T1.1.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.005</td>\n<td id=\"S3.T1.1.6.6.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.05</td>\n</tr>\n<tr id=\"S3.T1.1.7.7\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Model transmission interval</th>\n<td id=\"S3.T1.1.7.7.2\" class=\"ltx_td ltx_align_left ltx_border_t\">6</td>\n<td id=\"S3.T1.1.7.7.3\" class=\"ltx_td ltx_align_left ltx_border_t\">1</td>\n<td id=\"S3.T1.1.7.7.4\" class=\"ltx_td ltx_align_left ltx_border_t\">1</td>\n</tr>\n<tr id=\"S3.T1.1.8.8\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\">Total iteration number</th>\n<td id=\"S3.T1.1.8.8.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">5,000</td>\n<td id=\"S3.T1.1.8.8.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">100,000</td>\n<td id=\"S3.T1.1.8.8.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">25,000</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We conducted experimental evaluations across two scenarios, both operating under a non-IID setting. For the initial scenario, we benchmarked Tram-FL (without the model routing algorithm) against two baseline methods, Gossip-SGD ",
                "[",
                "3",
                ", ",
                "4",
                ", ",
                "5",
                "]",
                " and PDMM-SGD ",
                "[",
                "7",
                "]",
                ". This comparison served to underscore the potential of Tram-FL to enhance model convergence, particularly in the context of non-IID data distributions.",
                "We employed two image classification tasks, namely MNIST",
                "[",
                "10",
                "]",
                " and CIFAR-10",
                "[",
                "11",
                "]",
                ", and a text classification task called IMDb",
                "[",
                "12",
                "]",
                ". The MNIST dataset contains ten classes of handwritten digits, while the CIFAR-10 dataset comprises color images of objects belonging to ten different classes. The IMDb dataset consists of movie reviews that are labeled either positive or negative. The sample sizes of the training and test sets are 60,000, 10,000, 50,000, 10,000, and 25,000, 25,000 for MNIST, CIFAR-10, and IMDb, respectively. The training samples were distributed to the nodes in the following way.",
                "MNIST, CIFAR-10",
                ": The data labels assigned to each node are distributed uniformly and without any overlapping. Specifically, when ",
                "V",
                "=",
                "3",
                "ùëâ",
                "3",
                "V=3",
                ", the labels are partitioned into three sets ",
                "{",
                "0",
                ",",
                "1",
                ",",
                "2",
                "}",
                "0",
                "1",
                "2",
                "\\{0,1,2\\}",
                ", ",
                "{",
                "3",
                ",",
                "4",
                ",",
                "5",
                "}",
                "3",
                "4",
                "5",
                "\\{3,4,5\\}",
                ", and ",
                "{",
                "6",
                ",",
                "7",
                ",",
                "8",
                ",",
                "9",
                "}",
                "6",
                "7",
                "8",
                "9",
                "\\{6,7,8,9\\}",
                ", and assigned to node 0, 1, and 2, respectively. In a similar fashion, when ",
                "V",
                "=",
                "5",
                "ùëâ",
                "5",
                "V=5",
                ", the labels are partitioned into five sets ",
                "{",
                "0",
                ",",
                "1",
                "}",
                "0",
                "1",
                "\\{0,1\\}",
                ", ",
                "{",
                "2",
                ",",
                "3",
                "}",
                "2",
                "3",
                "\\{2,3\\}",
                ", ",
                "{",
                "4",
                ",",
                "5",
                "}",
                "4",
                "5",
                "\\{4,5\\}",
                ", ",
                "{",
                "6",
                ",",
                "7",
                "}",
                "6",
                "7",
                "\\{6,7\\}",
                ", and ",
                "{",
                "8",
                ",",
                "9",
                "}",
                "8",
                "9",
                "\\{8,9\\}",
                ", while for ",
                "V",
                "=",
                "10",
                "ùëâ",
                "10",
                "V=10",
                ", they are partitioned into ten sets ",
                "{",
                "0",
                "}",
                "0",
                "\\{0\\}",
                ", ",
                "{",
                "1",
                "}",
                "1",
                "\\{1\\}",
                ", ",
                "{",
                "2",
                "}",
                "2",
                "\\{2\\}",
                ", ",
                "{",
                "3",
                "}",
                "3",
                "\\{3\\}",
                ", ",
                "{",
                "4",
                "}",
                "4",
                "\\{4\\}",
                ", ",
                "{",
                "5",
                "}",
                "5",
                "\\{5\\}",
                ", ",
                "{",
                "6",
                "}",
                "6",
                "\\{6\\}",
                ", ",
                "{",
                "7",
                "}",
                "7",
                "\\{7\\}",
                ", ",
                "{",
                "8",
                "}",
                "8",
                "\\{8\\}",
                ", and ",
                "{",
                "9",
                "}",
                "9",
                "\\{9\\}",
                ".\nEach node is assigned all the samples that have data labels distributed in that node. In MNIST, when ",
                "V",
                "=",
                "3",
                "ùëâ",
                "3",
                "V=3",
                ", ",
                "N",
                "1",
                "=",
                "18000",
                "subscript",
                "ùëÅ",
                "1",
                "18000",
                "N_{1}=18000",
                ", ",
                "N",
                "2",
                "=",
                "18000",
                "subscript",
                "ùëÅ",
                "2",
                "18000",
                "N_{2}=18000",
                ", ",
                "N",
                "3",
                "=",
                "24000",
                "subscript",
                "ùëÅ",
                "3",
                "24000",
                "N_{3}=24000",
                ". When ",
                "V",
                "=",
                "5",
                "ùëâ",
                "5",
                "V=5",
                ", ",
                "N",
                "=",
                "12000",
                "ùëÅ",
                "12000",
                "N=12000",
                " and when ",
                "V",
                "=",
                "10",
                "ùëâ",
                "10",
                "V=10",
                ", ",
                "N",
                "=",
                "6000",
                "ùëÅ",
                "6000",
                "N=6000",
                ". In CIFAR-10, when ",
                "V",
                "=",
                "3",
                "ùëâ",
                "3",
                "V=3",
                ", ",
                "N",
                "1",
                "=",
                "15000",
                "subscript",
                "ùëÅ",
                "1",
                "15000",
                "N_{1}=15000",
                ", ",
                "N",
                "‚Äã",
                "2",
                "=",
                "15000",
                "ùëÅ",
                "2",
                "15000",
                "N2=15000",
                ", ",
                "N",
                "‚Äã",
                "3",
                "=",
                "20000",
                "ùëÅ",
                "3",
                "20000",
                "N3=20000",
                ". When ",
                "V",
                "=",
                "5",
                "ùëâ",
                "5",
                "V=5",
                ", ",
                "N",
                "=",
                "10000",
                "ùëÅ",
                "10000",
                "N=10000",
                " and when ",
                "V",
                "=",
                "10",
                "ùëâ",
                "10",
                "V=10",
                ", ",
                "N",
                "=",
                "5000",
                "ùëÅ",
                "5000",
                "N=5000",
                ".",
                "IMDb",
                ": The training data is divided based on the exponential distribution and its corresponding cumulative distribution function. Specifically, when V=3, ",
                "L",
                "0",
                "subscript",
                "ùêø",
                "0",
                "L_{0}",
                ", ",
                "L",
                "1",
                "subscript",
                "ùêø",
                "1",
                "L_{1}",
                ", and ",
                "L",
                "2",
                "subscript",
                "ùêø",
                "2",
                "L_{2}",
                " were [10,125, 2,625], [2,000, 4,750], and [375, 5,125], respectively. Similarly, when V=5, ",
                "L",
                "0",
                "subscript",
                "ùêø",
                "0",
                "L_{0}",
                ", ",
                "L",
                "1",
                "subscript",
                "ùêø",
                "1",
                "L_{1}",
                ", ",
                "L",
                "2",
                "subscript",
                "ùêø",
                "2",
                "L_{2}",
                ", ",
                "L",
                "3",
                "subscript",
                "ùêø",
                "3",
                "L_{3}",
                ", and ",
                "L",
                "4",
                "subscript",
                "ùêø",
                "4",
                "L_{4}",
                " were [7,875, 1,125], [2,875, 2,375], [1,125, 2,875], [375, 3,000], and [250, 3,125], respectively.\n",
                "A DNN architecture for each task was as follows: The model for MNIST was a convolutional neural network (CNN) comprising two 3 √ó 3 convolutional layers with 32 and 64 output channels, respectively, which are activated by Rectified Linear Units (ReLU). Following the convolutional layers are 2 √ó 2 max pooling and a dropout rate of 0.5. Subsequently, the architecture incorporates two fully connected layers with 128 units activated by ReLU and 10 units with a dropout rate of 0.5 in between. The model for CIFAR-10 consists of four 3√ó3 convolutional layers with 32, 64, 64, and 64 channels, each activated with ReLU and group normalized. Further, the model includes 2√ó2 per 2-layer max pooling and a dropout rate of 0.25. Additionally, the architecture has two all-coupled layers with 512 units activated with ReLU and 10 units activated with softmax, with a dropout rate of 0.5 in between. For the IMDb, we used LSTM, a type of recurrent neural network (RNN) known for its ability to handle sequential data. Specifically, we used the same model architecture as the one used in the Keras tutorial",
                "[",
                "13",
                "]",
                " for the IMDb dataset. The model includes an embedding layer with 32 output dimensions for each word, an LSTM layer with 32 nodes, and a fully connected layer with two units activated with softmax. He‚Äôs method",
                "[",
                "14",
                "]",
                " was utilized to initialize w with a shared random seed for each node.",
                "We set the number of nodes to range from 3 to 10. We assumed full-mesh connectivity, wherein all nodes are adjacent to one another. Therefore, in both Gossip SGD and PDMM-SGD, each round involves an exchange of the model with all neighboring nodes. In contrast, for our proposed method, we structured the model to initiate from node 0 and then transmit sequentially to nodes 1, 2, 3, etc. After reaching the last node, the model is looped back to node 0, and this cycle is repeatedly performed.\nThe other hyperparameters are summarized in ",
                "TABLE¬†I",
                ".",
                "In the second scenario, we evaluated the effectiveness of the proposed model routing algorithm. We used the CIFAR-10 dataset while keeping all other settings the same except for data distribution. A mesh network with 5 nodes was emulated, and the data labels were randomly assigned to each node such that each node had between 2-5 labels. The samples were distributed to each node according to the label assignment. Each node is assigned all the samples that have data labels distributed in that node. Therefore, the number of samples increases in proportion to the number of assigned labels. We evaluated the convergence speed of the proposed dynamic routing and static routes for circulating models by assessing the number of required model transmissions to achieve a certain accuracy threshold. ",
                "TABLE¬†II",
                " presents the static routes. Routes 1 to 24 correspond to static model routing, constituting a total of 24 distinct routes that traverse all five nodes. We also used random routing as a baseline for the dynamic routing algorithm, in which the next node is selected randomly from among its neighbors."
            ]
        ]
    },
    "S3.T2": {
        "caption": "TABLE II: Comparison route",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\">Route¬†1</th>\n<th id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">0,1,2,3,4</th>\n<th id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Route¬†9</th>\n<th id=\"S3.T2.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">0,2,3,1,4</th>\n<th id=\"S3.T2.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Route¬†17</th>\n<th id=\"S3.T2.1.1.1.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">0,3,4,1,2</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Route¬†2</th>\n<th id=\"S3.T2.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0,1,2,4,3</th>\n<td id=\"S3.T2.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†10</td>\n<td id=\"S3.T2.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0,2,3,4,1</td>\n<td id=\"S3.T2.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†18</td>\n<td id=\"S3.T2.1.2.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\">0,3,4,2,1</td>\n</tr>\n<tr id=\"S3.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Route¬†3</th>\n<th id=\"S3.T2.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0,1,3,2,4</th>\n<td id=\"S3.T2.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†11</td>\n<td id=\"S3.T2.1.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0,2,4,1,3</td>\n<td id=\"S3.T2.1.3.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†19</td>\n<td id=\"S3.T2.1.3.2.6\" class=\"ltx_td ltx_align_left ltx_border_t\">0,4,1,2,3</td>\n</tr>\n<tr id=\"S3.T2.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Route¬†4</th>\n<th id=\"S3.T2.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0,1,3,4,2</th>\n<td id=\"S3.T2.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†12</td>\n<td id=\"S3.T2.1.4.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0,2,4,3,1</td>\n<td id=\"S3.T2.1.4.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†20</td>\n<td id=\"S3.T2.1.4.3.6\" class=\"ltx_td ltx_align_left ltx_border_t\">0,4,1,3,2</td>\n</tr>\n<tr id=\"S3.T2.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Route¬†5</th>\n<th id=\"S3.T2.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0,1,4,2,3</th>\n<td id=\"S3.T2.1.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†13</td>\n<td id=\"S3.T2.1.5.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0,3,1,2,4</td>\n<td id=\"S3.T2.1.5.4.5\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†21</td>\n<td id=\"S3.T2.1.5.4.6\" class=\"ltx_td ltx_align_left ltx_border_t\">0,4,2,1,3</td>\n</tr>\n<tr id=\"S3.T2.1.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Route¬†6</th>\n<th id=\"S3.T2.1.6.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0,1,4,3,2</th>\n<td id=\"S3.T2.1.6.5.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†14</td>\n<td id=\"S3.T2.1.6.5.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0,3,1,4,2</td>\n<td id=\"S3.T2.1.6.5.5\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†22</td>\n<td id=\"S3.T2.1.6.5.6\" class=\"ltx_td ltx_align_left ltx_border_t\">0,4,2,3,1</td>\n</tr>\n<tr id=\"S3.T2.1.7.6\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Route¬†7</th>\n<th id=\"S3.T2.1.7.6.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0,2,1,3,4</th>\n<td id=\"S3.T2.1.7.6.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†15</td>\n<td id=\"S3.T2.1.7.6.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0,3,2,1,4</td>\n<td id=\"S3.T2.1.7.6.5\" class=\"ltx_td ltx_align_left ltx_border_t\">Route¬†23</td>\n<td id=\"S3.T2.1.7.6.6\" class=\"ltx_td ltx_align_left ltx_border_t\">0,4,3,1,2</td>\n</tr>\n<tr id=\"S3.T2.1.8.7\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\">Route¬†8</th>\n<th id=\"S3.T2.1.8.7.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\">0,2,1,4,3</th>\n<td id=\"S3.T2.1.8.7.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">Route¬†16</td>\n<td id=\"S3.T2.1.8.7.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">0,3,2,4,1</td>\n<td id=\"S3.T2.1.8.7.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">Route¬†24</td>\n<td id=\"S3.T2.1.8.7.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">0,4,3,2,1</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We conducted experimental evaluations across two scenarios, both operating under a non-IID setting. For the initial scenario, we benchmarked Tram-FL (without the model routing algorithm) against two baseline methods, Gossip-SGD ",
                "[",
                "3",
                ", ",
                "4",
                ", ",
                "5",
                "]",
                " and PDMM-SGD ",
                "[",
                "7",
                "]",
                ". This comparison served to underscore the potential of Tram-FL to enhance model convergence, particularly in the context of non-IID data distributions.",
                "We employed two image classification tasks, namely MNIST",
                "[",
                "10",
                "]",
                " and CIFAR-10",
                "[",
                "11",
                "]",
                ", and a text classification task called IMDb",
                "[",
                "12",
                "]",
                ". The MNIST dataset contains ten classes of handwritten digits, while the CIFAR-10 dataset comprises color images of objects belonging to ten different classes. The IMDb dataset consists of movie reviews that are labeled either positive or negative. The sample sizes of the training and test sets are 60,000, 10,000, 50,000, 10,000, and 25,000, 25,000 for MNIST, CIFAR-10, and IMDb, respectively. The training samples were distributed to the nodes in the following way.",
                "MNIST, CIFAR-10",
                ": The data labels assigned to each node are distributed uniformly and without any overlapping. Specifically, when ",
                "V",
                "=",
                "3",
                "ùëâ",
                "3",
                "V=3",
                ", the labels are partitioned into three sets ",
                "{",
                "0",
                ",",
                "1",
                ",",
                "2",
                "}",
                "0",
                "1",
                "2",
                "\\{0,1,2\\}",
                ", ",
                "{",
                "3",
                ",",
                "4",
                ",",
                "5",
                "}",
                "3",
                "4",
                "5",
                "\\{3,4,5\\}",
                ", and ",
                "{",
                "6",
                ",",
                "7",
                ",",
                "8",
                ",",
                "9",
                "}",
                "6",
                "7",
                "8",
                "9",
                "\\{6,7,8,9\\}",
                ", and assigned to node 0, 1, and 2, respectively. In a similar fashion, when ",
                "V",
                "=",
                "5",
                "ùëâ",
                "5",
                "V=5",
                ", the labels are partitioned into five sets ",
                "{",
                "0",
                ",",
                "1",
                "}",
                "0",
                "1",
                "\\{0,1\\}",
                ", ",
                "{",
                "2",
                ",",
                "3",
                "}",
                "2",
                "3",
                "\\{2,3\\}",
                ", ",
                "{",
                "4",
                ",",
                "5",
                "}",
                "4",
                "5",
                "\\{4,5\\}",
                ", ",
                "{",
                "6",
                ",",
                "7",
                "}",
                "6",
                "7",
                "\\{6,7\\}",
                ", and ",
                "{",
                "8",
                ",",
                "9",
                "}",
                "8",
                "9",
                "\\{8,9\\}",
                ", while for ",
                "V",
                "=",
                "10",
                "ùëâ",
                "10",
                "V=10",
                ", they are partitioned into ten sets ",
                "{",
                "0",
                "}",
                "0",
                "\\{0\\}",
                ", ",
                "{",
                "1",
                "}",
                "1",
                "\\{1\\}",
                ", ",
                "{",
                "2",
                "}",
                "2",
                "\\{2\\}",
                ", ",
                "{",
                "3",
                "}",
                "3",
                "\\{3\\}",
                ", ",
                "{",
                "4",
                "}",
                "4",
                "\\{4\\}",
                ", ",
                "{",
                "5",
                "}",
                "5",
                "\\{5\\}",
                ", ",
                "{",
                "6",
                "}",
                "6",
                "\\{6\\}",
                ", ",
                "{",
                "7",
                "}",
                "7",
                "\\{7\\}",
                ", ",
                "{",
                "8",
                "}",
                "8",
                "\\{8\\}",
                ", and ",
                "{",
                "9",
                "}",
                "9",
                "\\{9\\}",
                ".\nEach node is assigned all the samples that have data labels distributed in that node. In MNIST, when ",
                "V",
                "=",
                "3",
                "ùëâ",
                "3",
                "V=3",
                ", ",
                "N",
                "1",
                "=",
                "18000",
                "subscript",
                "ùëÅ",
                "1",
                "18000",
                "N_{1}=18000",
                ", ",
                "N",
                "2",
                "=",
                "18000",
                "subscript",
                "ùëÅ",
                "2",
                "18000",
                "N_{2}=18000",
                ", ",
                "N",
                "3",
                "=",
                "24000",
                "subscript",
                "ùëÅ",
                "3",
                "24000",
                "N_{3}=24000",
                ". When ",
                "V",
                "=",
                "5",
                "ùëâ",
                "5",
                "V=5",
                ", ",
                "N",
                "=",
                "12000",
                "ùëÅ",
                "12000",
                "N=12000",
                " and when ",
                "V",
                "=",
                "10",
                "ùëâ",
                "10",
                "V=10",
                ", ",
                "N",
                "=",
                "6000",
                "ùëÅ",
                "6000",
                "N=6000",
                ". In CIFAR-10, when ",
                "V",
                "=",
                "3",
                "ùëâ",
                "3",
                "V=3",
                ", ",
                "N",
                "1",
                "=",
                "15000",
                "subscript",
                "ùëÅ",
                "1",
                "15000",
                "N_{1}=15000",
                ", ",
                "N",
                "‚Äã",
                "2",
                "=",
                "15000",
                "ùëÅ",
                "2",
                "15000",
                "N2=15000",
                ", ",
                "N",
                "‚Äã",
                "3",
                "=",
                "20000",
                "ùëÅ",
                "3",
                "20000",
                "N3=20000",
                ". When ",
                "V",
                "=",
                "5",
                "ùëâ",
                "5",
                "V=5",
                ", ",
                "N",
                "=",
                "10000",
                "ùëÅ",
                "10000",
                "N=10000",
                " and when ",
                "V",
                "=",
                "10",
                "ùëâ",
                "10",
                "V=10",
                ", ",
                "N",
                "=",
                "5000",
                "ùëÅ",
                "5000",
                "N=5000",
                ".",
                "IMDb",
                ": The training data is divided based on the exponential distribution and its corresponding cumulative distribution function. Specifically, when V=3, ",
                "L",
                "0",
                "subscript",
                "ùêø",
                "0",
                "L_{0}",
                ", ",
                "L",
                "1",
                "subscript",
                "ùêø",
                "1",
                "L_{1}",
                ", and ",
                "L",
                "2",
                "subscript",
                "ùêø",
                "2",
                "L_{2}",
                " were [10,125, 2,625], [2,000, 4,750], and [375, 5,125], respectively. Similarly, when V=5, ",
                "L",
                "0",
                "subscript",
                "ùêø",
                "0",
                "L_{0}",
                ", ",
                "L",
                "1",
                "subscript",
                "ùêø",
                "1",
                "L_{1}",
                ", ",
                "L",
                "2",
                "subscript",
                "ùêø",
                "2",
                "L_{2}",
                ", ",
                "L",
                "3",
                "subscript",
                "ùêø",
                "3",
                "L_{3}",
                ", and ",
                "L",
                "4",
                "subscript",
                "ùêø",
                "4",
                "L_{4}",
                " were [7,875, 1,125], [2,875, 2,375], [1,125, 2,875], [375, 3,000], and [250, 3,125], respectively.\n",
                "A DNN architecture for each task was as follows: The model for MNIST was a convolutional neural network (CNN) comprising two 3 √ó 3 convolutional layers with 32 and 64 output channels, respectively, which are activated by Rectified Linear Units (ReLU). Following the convolutional layers are 2 √ó 2 max pooling and a dropout rate of 0.5. Subsequently, the architecture incorporates two fully connected layers with 128 units activated by ReLU and 10 units with a dropout rate of 0.5 in between. The model for CIFAR-10 consists of four 3√ó3 convolutional layers with 32, 64, 64, and 64 channels, each activated with ReLU and group normalized. Further, the model includes 2√ó2 per 2-layer max pooling and a dropout rate of 0.25. Additionally, the architecture has two all-coupled layers with 512 units activated with ReLU and 10 units activated with softmax, with a dropout rate of 0.5 in between. For the IMDb, we used LSTM, a type of recurrent neural network (RNN) known for its ability to handle sequential data. Specifically, we used the same model architecture as the one used in the Keras tutorial",
                "[",
                "13",
                "]",
                " for the IMDb dataset. The model includes an embedding layer with 32 output dimensions for each word, an LSTM layer with 32 nodes, and a fully connected layer with two units activated with softmax. He‚Äôs method",
                "[",
                "14",
                "]",
                " was utilized to initialize w with a shared random seed for each node.",
                "We set the number of nodes to range from 3 to 10. We assumed full-mesh connectivity, wherein all nodes are adjacent to one another. Therefore, in both Gossip SGD and PDMM-SGD, each round involves an exchange of the model with all neighboring nodes. In contrast, for our proposed method, we structured the model to initiate from node 0 and then transmit sequentially to nodes 1, 2, 3, etc. After reaching the last node, the model is looped back to node 0, and this cycle is repeatedly performed.\nThe other hyperparameters are summarized in ",
                "TABLE¬†I",
                ".",
                "In the second scenario, we evaluated the effectiveness of the proposed model routing algorithm. We used the CIFAR-10 dataset while keeping all other settings the same except for data distribution. A mesh network with 5 nodes was emulated, and the data labels were randomly assigned to each node such that each node had between 2-5 labels. The samples were distributed to each node according to the label assignment. Each node is assigned all the samples that have data labels distributed in that node. Therefore, the number of samples increases in proportion to the number of assigned labels. We evaluated the convergence speed of the proposed dynamic routing and static routes for circulating models by assessing the number of required model transmissions to achieve a certain accuracy threshold. ",
                "TABLE¬†II",
                " presents the static routes. Routes 1 to 24 correspond to static model routing, constituting a total of 24 distinct routes that traverse all five nodes. We also used random routing as a baseline for the dynamic routing algorithm, in which the next node is selected randomly from among its neighbors."
            ]
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: Average number of model transmissions",
        "table": "<table id=\"S4.T3.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.5.6.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.6.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Proposed</th>\n<th id=\"S4.T3.5.6.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">Static routing</th>\n<th id=\"S4.T3.5.6.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Uniform random</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.5.7.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.7.1.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S4.T3.5.7.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Best</th>\n<th id=\"S4.T3.5.7.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Median</th>\n<th id=\"S4.T3.5.7.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Worst</th>\n<td id=\"S4.T3.5.7.1.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.T3.5.8.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.5.8.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">60778</th>\n<td id=\"S4.T3.5.8.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">64667</td>\n<td id=\"S4.T3.5.8.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">72722</td>\n<td id=\"S4.T3.5.8.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">80444</td>\n<td id=\"S4.T3.5.8.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">71611</td>\n</tr>\n<tr id=\"S4.T3.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">\n<math id=\"S4.T3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.m1.1a\"><mo id=\"S4.T3.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.m1.1.1.cmml\">¬±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T3.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.m1.1c\">\\pm</annotation></semantics></math>3119</th>\n<td id=\"S4.T3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<math id=\"S4.T3.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.T3.2.2.2.m1.1a\"><mo id=\"S4.T3.2.2.2.m1.1.1\" xref=\"S4.T3.2.2.2.m1.1.1.cmml\">¬±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T3.2.2.2.m1.1.1.cmml\" xref=\"S4.T3.2.2.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.2.m1.1c\">\\pm</annotation></semantics></math>4435</td>\n<td id=\"S4.T3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<math id=\"S4.T3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm 5\" display=\"inline\"><semantics id=\"S4.T3.3.3.3.m1.1a\"><mrow id=\"S4.T3.3.3.3.m1.1.1\" xref=\"S4.T3.3.3.3.m1.1.1.cmml\"><mo id=\"S4.T3.3.3.3.m1.1.1a\" xref=\"S4.T3.3.3.3.m1.1.1.cmml\">¬±</mo><mn id=\"S4.T3.3.3.3.m1.1.1.2\" xref=\"S4.T3.3.3.3.m1.1.1.2.cmml\">5</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.3.3.3.m1.1b\"><apply id=\"S4.T3.3.3.3.m1.1.1.cmml\" xref=\"S4.T3.3.3.3.m1.1.1\"><csymbol cd=\"latexml\" id=\"S4.T3.3.3.3.m1.1.1.1.cmml\" xref=\"S4.T3.3.3.3.m1.1.1\">plus-or-minus</csymbol><cn type=\"integer\" id=\"S4.T3.3.3.3.m1.1.1.2.cmml\" xref=\"S4.T3.3.3.3.m1.1.1.2\">5</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.3.3.3.m1.1c\">\\pm 5</annotation></semantics></math>135</td>\n<td id=\"S4.T3.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<math id=\"S4.T3.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.T3.4.4.4.m1.1a\"><mo id=\"S4.T3.4.4.4.m1.1.1\" xref=\"S4.T3.4.4.4.m1.1.1.cmml\">¬±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.4.4.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T3.4.4.4.m1.1.1.cmml\" xref=\"S4.T3.4.4.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.4.4.4.m1.1c\">\\pm</annotation></semantics></math>5535</td>\n<td id=\"S4.T3.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<math id=\"S4.T3.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.T3.5.5.5.m1.1a\"><mo id=\"S4.T3.5.5.5.m1.1.1\" xref=\"S4.T3.5.5.5.m1.1.1.cmml\">¬±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.5.5.5.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T3.5.5.5.m1.1.1.cmml\" xref=\"S4.T3.5.5.5.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.5.5.5.m1.1c\">\\pm</annotation></semantics></math>6293</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Scenario 1:",
                "\n",
                "Fig. 2",
                " shows the test accuracy against the total number of model transmissions in the network for the first scenario. As the total number of model transmissions between nodes increases, the models are updated and learning progresses, and as a result, the test accuracy increases in all the tasks.\nExperimental results for MNIST and CIFAR-10 are shown in ",
                "Fig. 2(a),(b)",
                ". Despite some comparative approaches being unable to obtain an accurate global model owing to unstable convergence resulting from variations in the number of nodes and data distribution, Tram-FL managed to obtain an accurate global model in all settings. In contrast, ",
                "Fig. 2(c)",
                " shows the experimental results for IMDb, where PDMM-SGD and Gossip-SGD failed to converge within the number of transmissions in this experiment, while the proposed method obtained an accurate global model.",
                "Scenario 2:",
                "\n",
                "Fig. 3",
                " presents a box plot displaying the total number of model transmissions required to attain a test accuracy of 78% ‚Äì a mark 2% lower than the one achieved by centralized learning for CIFAR-10 ‚Äì in Tram-FL, using each routing method. This data is drawn from a specific distribution and is based on 15 trials.\nCompared to static model routing, the proposed routing algorithm demonstrated an average reduction of 16.25% in model transmissions. Furthermore, when compared to the random routing, the proposed algorithm exhibited an average decrease of 20.22% in model transmissions.\n",
                "TABLE¬†III",
                " presents the mean and standard deviation of the total number of model transmissions required to achieve a test accuracy of 78%. We evaluated three routes for static routing: the best route, median route, and worst route, which were identified via a comprehensive search. Our proposed model routing algorithm achieved a test accuracy of 78% with the least total number of model transmissions. The efficiency realized through our proposed method can be attributed to its dynamic routing nature. While static routing entails the selection of each node in an orderly, evenly spaced manner, our method permits the consecutive or biased selection of the same node. This flexibility allows for a closer approximation of a uniform data distribution, a strategic approach absent in static routing schemes."
            ]
        ]
    }
}