{
    "PAPER'S NUMBER OF TABLES": 1,
    "S2.T1": {
        "caption": "Table 1: Client optimization parameters and transmission size comparison (∗ Referenced from [5], number of channels set to 1).",
        "table": "<table id=\"S2.T1.2.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S2.T1.2.2.2\" class=\"ltx_tr\">\n<th id=\"S2.T1.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S2.T1.2.2.2.3.1\" class=\"ltx_text ltx_font_bold\">Backbone</span></th>\n<th id=\"S2.T1.2.2.2.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\"><span id=\"S2.T1.2.2.2.4.1\" class=\"ltx_text ltx_font_bold\"># params</span></th>\n<th id=\"S2.T1.1.1.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S2.T1.1.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S2.T1.1.1.1.1.1.2\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.1.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_right\"><span id=\"S2.T1.1.1.1.1.1.2.1.1\" class=\"ltx_text ltx_font_bold\"># BN</span></td>\n</tr>\n<tr id=\"S2.T1.1.1.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S2.T1.1.1.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_right\"><span id=\"S2.T1.1.1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">params<sup id=\"S2.T1.1.1.1.1.1.1.1.1.1\" class=\"ltx_sup\"><span id=\"S2.T1.1.1.1.1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_medium\">∗</span></sup></span></td>\n</tr>\n</table>\n</th>\n<th id=\"S2.T1.2.2.2.5\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S2.T1.2.2.2.5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S2.T1.2.2.2.5.1.1\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.2.5.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_right\"><span id=\"S2.T1.2.2.2.5.1.1.1.1\" class=\"ltx_text ltx_font_bold\">BN</span></td>\n</tr>\n<tr id=\"S2.T1.2.2.2.5.1.2\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.2.5.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_right\"><span id=\"S2.T1.2.2.2.5.1.2.1.1\" class=\"ltx_text ltx_font_bold\">size (kB)</span></td>\n</tr>\n</table>\n</th>\n<th id=\"S2.T1.2.2.2.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S2.T1.2.2.2.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S2.T1.2.2.2.2.1.2\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.2.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_right\"><span id=\"S2.T1.2.2.2.2.1.2.1.1\" class=\"ltx_text ltx_font_bold\"># <span id=\"S2.T1.2.2.2.2.1.2.1.1.1\" class=\"ltx_text ltx_font_italic\">FedMixStyle</span></span></td>\n</tr>\n<tr id=\"S2.T1.2.2.2.2.1.1\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.2.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_right\"><span id=\"S2.T1.2.2.2.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">params<sup id=\"S2.T1.2.2.2.2.1.1.1.1.1\" class=\"ltx_sup\"><span id=\"S2.T1.2.2.2.2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_medium\">∗</span></sup></span></td>\n</tr>\n</table>\n</th>\n<th id=\"S2.T1.2.2.2.6\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S2.T1.2.2.2.6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S2.T1.2.2.2.6.1.1\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.2.6.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_right\"><span id=\"S2.T1.2.2.2.6.1.1.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">FedMixStyle</span></td>\n</tr>\n<tr id=\"S2.T1.2.2.2.6.1.2\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.2.6.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_right\"><span id=\"S2.T1.2.2.2.6.1.2.1.1\" class=\"ltx_text ltx_font_bold\">size (kB)</span></td>\n</tr>\n</table>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S2.T1.2.2.3.1\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">ResNet-18</td>\n<td id=\"S2.T1.2.2.3.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\">12 million</td>\n<td id=\"S2.T1.2.2.3.1.3\" class=\"ltx_td ltx_align_right ltx_border_t\">9,600</td>\n<td id=\"S2.T1.2.2.3.1.4\" class=\"ltx_td ltx_align_right ltx_border_t\">36</td>\n<td id=\"S2.T1.2.2.3.1.5\" class=\"ltx_td ltx_align_right ltx_border_t\">80</td>\n<td id=\"S2.T1.2.2.3.1.6\" class=\"ltx_td ltx_align_right ltx_border_t\">0.3</td>\n</tr>\n<tr id=\"S2.T1.2.2.4.2\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.4.2.1\" class=\"ltx_td ltx_align_left\">ResNet-50</td>\n<td id=\"S2.T1.2.2.4.2.2\" class=\"ltx_td ltx_align_right\">26 million</td>\n<td id=\"S2.T1.2.2.4.2.3\" class=\"ltx_td ltx_align_right\">53,120</td>\n<td id=\"S2.T1.2.2.4.2.4\" class=\"ltx_td ltx_align_right\">199</td>\n<td id=\"S2.T1.2.2.4.2.5\" class=\"ltx_td ltx_align_right\">212</td>\n<td id=\"S2.T1.2.2.4.2.6\" class=\"ltx_td ltx_align_right\">0.8</td>\n</tr>\n<tr id=\"S2.T1.2.2.5.3\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.5.3.1\" class=\"ltx_td ltx_align_left\">ResNet-101</td>\n<td id=\"S2.T1.2.2.5.3.2\" class=\"ltx_td ltx_align_right\">45 million</td>\n<td id=\"S2.T1.2.2.5.3.3\" class=\"ltx_td ltx_align_right\">105,344</td>\n<td id=\"S2.T1.2.2.5.3.4\" class=\"ltx_td ltx_align_right\">395</td>\n<td id=\"S2.T1.2.2.5.3.5\" class=\"ltx_td ltx_align_right\">416</td>\n<td id=\"S2.T1.2.2.5.3.6\" class=\"ltx_td ltx_align_right\">1.6</td>\n</tr>\n<tr id=\"S2.T1.2.2.6.4\" class=\"ltx_tr\">\n<td id=\"S2.T1.2.2.6.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">DenseNet-121</td>\n<td id=\"S2.T1.2.2.6.4.2\" class=\"ltx_td ltx_align_right ltx_border_bb\">29 million</td>\n<td id=\"S2.T1.2.2.6.4.3\" class=\"ltx_td ltx_align_right ltx_border_bb\">83,648</td>\n<td id=\"S2.T1.2.2.6.4.4\" class=\"ltx_td ltx_align_right ltx_border_bb\">314</td>\n<td id=\"S2.T1.2.2.6.4.5\" class=\"ltx_td ltx_align_right ltx_border_bb\">484</td>\n<td id=\"S2.T1.2.2.6.4.6\" class=\"ltx_td ltx_align_right ltx_border_bb\">1.8</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Following the conceptual overview\nof ",
                "FedMixStyle ",
                "in Fig. ",
                "2",
                ", the pre-training (",
                "1",
                ") objective for our server-side, supervised classification task is defined as",
                "where ",
                "ℒ",
                "C",
                "​",
                "E",
                "subscript",
                "ℒ",
                "𝐶",
                "𝐸",
                "\\mathcal{L}_{CE}",
                " denotes the cross entropy loss function and ",
                "y",
                "l",
                "subscript",
                "𝑦",
                "𝑙",
                "y_{l}",
                " the ground-truth label associated with ",
                "x",
                "l",
                "subscript",
                "𝑥",
                "𝑙",
                "x_{l}",
                " drawn from ",
                "D",
                "S",
                "subscript",
                "𝐷",
                "𝑆",
                "D_{S}",
                " with the intention to learn and refine discriminatory and transferable features for near domains.\nConsequently, the adapted parameters of the server model are used as deployment baseline for client devices joining FL (",
                "2",
                ") with ",
                "ϕ",
                "T",
                "i",
                "=",
                "ϕ",
                "S",
                "subscript",
                "italic-ϕ",
                "subscript",
                "𝑇",
                "𝑖",
                "subscript",
                "italic-ϕ",
                "𝑆",
                "\\phi_{T_{i}}=\\phi_{S}",
                " and ",
                "ν",
                "T",
                "i",
                "=",
                "ν",
                "S",
                "subscript",
                "𝜈",
                "subscript",
                "𝑇",
                "𝑖",
                "subscript",
                "𝜈",
                "𝑆",
                "\\nu_{T_{i}}=\\nu_{S}",
                ".\nThe client-side adaptation of the local model (",
                "3",
                ") concentrates on approximating the optimal target BN statistics ",
                "{",
                "μ",
                "T",
                "i",
                ",",
                "σ",
                "T",
                "i",
                "}",
                "subscript",
                "𝜇",
                "subscript",
                "𝑇",
                "𝑖",
                "subscript",
                "𝜎",
                "subscript",
                "𝑇",
                "𝑖",
                "\\{\\mu_{T_{i}},\\sigma_{T_{i}}\\}",
                " of the BN layers from the feature extractor according to ",
                "[",
                "5",
                "]",
                " while exploiting the BN statistics ",
                "{",
                "μ",
                "S",
                ",",
                "σ",
                "S",
                "}",
                "subscript",
                "𝜇",
                "𝑆",
                "subscript",
                "𝜎",
                "𝑆",
                "\\{\\mu_{S},\\sigma_{S}\\}",
                " from the pre-trained server model and subsequently fine-tuning the learnable ",
                "Linear Combination Coefficients for BN Statistics",
                " (similar to LCCS) and target classifier by cross-entropy loss minimization on ",
                "D",
                "T",
                "i",
                "subscript",
                "𝐷",
                "subscript",
                "𝑇",
                "𝑖",
                "D_{T_{i}}",
                ".\nIn the penultimate step, clients transmit their learnt parameter set back to the server for follow-up processing (",
                "4",
                "). Tab. ",
                "1",
                " compares typical BN methods to our approach. We show common backbone architectures and their estimated number of parameters to fine-tune as well as the expected data transmission size for one federated round, respectively.\nCompared to other BN-based techniques, ",
                "FedMixStyle ",
                "significantly reduces the number of client-adapted parameters.\nOur method also offers the advantage of reducing the transmission sizes for server-client communication, effectively countering FL constraints.",
                "For the sake of clarity, server-level aggregation (",
                "5",
                ") is carried out by applying FedAvg ",
                "[",
                "4",
                "]",
                ". Thus, the server-side objective function, aiming to optimize generalization capabilities of our global model by parameter averaging over all client instances, cumulates to",
                "where ",
                "m",
                "𝑚",
                "m",
                " denotes the number of clients, ",
                "I",
                "𝐼",
                "I",
                " is the total number of instances over all clients, ",
                "F",
                "𝐹",
                "F",
                " is the shared model, and ",
                "ℒ",
                "C",
                "​",
                "E",
                "subscript",
                "ℒ",
                "𝐶",
                "𝐸",
                "\\mathcal{L}_{CE}",
                " is the cross-entropy loss."
            ]
        ]
    }
}