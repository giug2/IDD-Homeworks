{
    "id_table_1": {
        "caption": "Table 1:  Evaluation of FID across generations for different generative models trained on various datasets, including colorized MNIST w/wo bias initialization, CIFAR-20/100, and Hard ImageNet. The  1 1 1 1 st generative model is trained on the original dataset without the inclusion of generative data.",
        "table": "S3.E1",
        "footnotes": [],
        "references": [
            "As models continue to evolve and become more sophisticated, the demand for large amounts of high-quality training data has escalated  (Alzubaidi et al.,  2023 ) . Traditionally, web data has been the primary resource for enhancing model performance  (Deng et al.,  2024 ) . However, as this source becomes fully exploited, researchers have begun to explore alternative methods. One promising approach is to leverage generative models to create synthetic data  (Fan et al.,  2024 ) , thereby fueling continuous training cycles, as shown in  fig.   1 . This innovative self-sustaining pipeline effectively mitigates the issue of data scarcity, allowing models to improve iteratively with the help of their own generated outputs  (Chen et al.,  2024 ; Lu et al.,  2024 ) . Despite the apparent advantages, this strategy introduces a crucial and complex debate:  Will the reliance on self-generated data eventually lead to model degradation ?",
            "Implementations . We set the number of generations to  10 10 10 10  or  4 4 4 4  in MNIST/CIFAR and Hard ImageNet, respectively. For training all models, we use the Adam optimizer, initializing the learning rate at  1  10  1 1 superscript 10 1 1\\times 10^{-1} 1  10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT , with training capped at  50 50 50 50  epochs. Early stopping is employed to ensure full convergence and to avoid overfitting. We provide the evaluation of different generators across generations based on the FID score in  table   1 . The classification model at the  0 0 -the generation is trained on the original dataset without any generated data. The queue has a maximum capacity of  3 3 3 3 . For all results, We run  3 3 3 3  times to reduce the experimental randomness.",
            "Summarization & Takeaways . As reported in  table   1 , the generative model can learn an approaching latent representation similar to that of the real samples on the colorized MNIST datasets, which is evident by the similar results on the FID evolution across generations. Thus, we can omit the impact of the quality of the generated data on the downstream models here. On the MNIST dataset, models can be consistently improved by augmenting the dataset with generated data across multiple generations. Notably, the inclusion of additional generated data does not significantly affect the models single-bias performance, even with a large number of generations. However, it can lead to substantial variations in subgroup performance, revealing the presence of the multi-bias problem. The impact of generated data across generations varies between different models but remains consistent within the same architecture over multiple generations. Comparing results from unbiased and biased initializations, we observe that the presence of bias in the original dataset does not cause the model to degrade rapidly. Both initialization types exhibit similar trends in single- and multi-bias performance. In other words, the presence of dataset bias does not significantly amplify model bias when the dataset is augmented with generated data across generations.",
            "Summarization & Takeaways . As shown in  table   1 , continuously training on the dataset augmented by generated data across multiple generations leads to a slight improvement in generative performance, as evidenced by the decreasing FID scores on the CIFAR-20/100 dataset. However, despite the improved generative model, classification models trained with successively augmented datasets still experience a decline in performance in both the original classification task and bias evaluations. When using pre-trained weights from the ImageNet dataset, the classification models show significant improvement compared to training from scratch. Nevertheless, it is evident that models with pre-trained weights are more susceptible to integration bias introduced by the augmented datasets evolved over generations, further exacerbating performance deterioration in bias evaluations."
        ]
    },
    "id_table_2": {
        "caption": "",
        "table": "S4.T1.3.1",
        "footnotes": [],
        "references": [
            "Among these metrics, MEO ( eq.   2 ), DI ( eq.   3 ), and MD ( eq.   4 ) assess single-bias evaluation, and subgroup performance evaluates ( eq.   5 ) the impact of multiple biases."
        ]
    }
}