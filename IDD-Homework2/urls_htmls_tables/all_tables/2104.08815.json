{
    "PAPER'S NUMBER OF TABLES": 3,
    "S3.T1": {
        "caption": "–¢–∞–±–ª–∏—Ü–∞ 1: \nStatistics of the selected datasets for our experiments. *37 is the size of the tag vocabulary.\n",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S3.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_tt\">Task</td>\n<td id=\"S3.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Txt.Cls.</td>\n<td id=\"S3.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Seq.Tag.</td>\n<td id=\"S3.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">QA</td>\n<td id=\"S3.T1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">Seq2Seq</td>\n</tr>\n<tr id=\"S3.T1.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\">Dataset</td>\n<td id=\"S3.T1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">20News</td>\n<td id=\"S3.T1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Onto.</td>\n<td id=\"S3.T1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">MRQA</td>\n<td id=\"S3.T1.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Giga.</td>\n</tr>\n<tr id=\"S3.T1.1.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\"># Training</td>\n<td id=\"S3.T1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">11.3k</td>\n<td id=\"S3.T1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">50k</td>\n<td id=\"S3.T1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">53.9k</td>\n<td id=\"S3.T1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">10k</td>\n</tr>\n<tr id=\"S3.T1.1.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_rr\"># Test</td>\n<td id=\"S3.T1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">7.5k</td>\n<td id=\"S3.T1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">5k</td>\n<td id=\"S3.T1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">3k</td>\n<td id=\"S3.T1.1.4.5\" class=\"ltx_td ltx_align_center\">2k</td>\n</tr>\n<tr id=\"S3.T1.1.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_rr\"># Labels</td>\n<td id=\"S3.T1.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">20</td>\n<td id=\"S3.T1.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">37*</td>\n<td id=\"S3.T1.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">N/A</td>\n<td id=\"S3.T1.1.5.5\" class=\"ltx_td ltx_align_center\">N/A</td>\n</tr>\n<tr id=\"S3.T1.1.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t\">Metrics</td>\n<td id=\"S3.T1.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">Acc.</td>\n<td id=\"S3.T1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">F-1</td>\n<td id=\"S3.T1.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">F-1</td>\n<td id=\"S3.T1.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">ROUGE</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We show the basic statistics of the above datasets in Table¬†1.\nNote that our FedNLP as a research platform supports a much wider range of specific tasks of each formulation, while we only introduce the ones used in our experiments here with typical settings.\nMoreover, our contribution is more of a general FL+NLP benchmarking platform instead of particular datasets and partitions.",
            "Although straightforward and effective, the above label-based Dirichlet allocation method has a major limitation ‚Äî it is only suitable for text classification tasks where the outputs can be modeled as category-based random variables.\nTo create synthetic partitions for other non-classification NLP tasks and model distribution shifts,\nwe thus propose a partition method based on feature clustering.\nSpecifically,\nwe use SentenceBERT¬†Reimers and Gurevych (2019) to encode each example to a dense vector by their text then we apply K-Means clustering to get the cluster label of each example; finally, we use these cluster labels (as if they were classification tasks) to follow the steps in modeling label distribution shift.\nThere are two obvious benefits of this clustering-based Dirichlet partition method:\n1) It enables us to easily synthesize the FL datasets for non-classification tasks (i.e., ST, QA, SS) as they do not have discrete labels as output space;\n2) The BERT-based clustering results naturally imply different sub-topics of a dataset, and thus feature shift can be seen as a shift of latent labels ‚Äî we can reuse the same method for the label-based Dirichlet partition method.",
            "We use DistilBERT and BART-base for most of our experiments,\nas the former is a distilled version of the BERT model and has a 7x speed improvement over BERT-base on mobile devices ‚Äî a common scenario for FL applications; the BART-base model is the most suitable option considering the trade-off between performance and computation cost.\nWe leave our implementation details and the selected hyper-parameters in the submitted supplementary materials.",
            "Our experiments cover both cross-device and cross-silo settings. As shown in Table 2, in the cross-device setting, we use uniform sampling to select 10 clients for each round when the client number in a dataset is very large (e.g., 100). For the cross-silo setting, each round will select the same number of clients (we use 6 for the QA task). The local epoch number is set to 1 for all experiments.\nTo make our results reproducible, we use wandb.ai to store all experiment logs and hyper-parameters as well as running scripts.",
            "We compare the three typical FL methods under the same setting (i.e., data partition, communication rounds, etc.) for each task formulation.\nAs shown in Table¬†2,\nwe report the results of FedAvg, FedProx, and FedOPT.\nWe can see that overall FedOPT performs better than the other two methods, with the only exception being in the seq2seq generation task.\nFedAvg and FedProx perform similarly with marginal differences, but FedAvg outperforms FedProx in sequence tagging.\nThese two exceptions are surprising findings, as many prior works in the FL community show that FedOPT is generally better than FedProx and FedAvg on vision tasks and datasets.",
            "We report our results in Table¬†3 and Figure¬†6.\nWe find that in centralized training, the largest performance gain happens when we unfreeze the last layer, while in FedOPT we have to unfreeze the last three layers to enjoy a comparable performance with the full model.\nThis suggests that reducing communication costs via freezing some layers of Transformer LMs is feasible, though one should be aware that the experience in centralized training may not generalize to the FL experiments."
        ]
    },
    "S3.T2": {
        "caption": "–¢–∞–±–ª–∏—Ü–∞ 2: The comparisons between different FL methods under the same setting on different NLP tasks. The number of workers per round are 10, expect for the MRQA task, which uses 6. ",
        "table": "<table id=\"S3.T2.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S3.T2.3.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.4.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.3.4.1.1\" class=\"ltx_text ltx_font_bold\">Task</span></td>\n<td id=\"S3.T2.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S3.T2.3.4.2.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></td>\n<td id=\"S3.T2.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.3.4.3.1\" class=\"ltx_text ltx_font_bold\">Partition</span></td>\n<td id=\"S3.T2.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S3.T2.3.4.4.1\" class=\"ltx_text ltx_font_bold\">Clients</span></td>\n<td id=\"S3.T2.3.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.3.4.5.1\" class=\"ltx_text ltx_font_typewriter\">FedAvg</span></td>\n<td id=\"S3.T2.3.4.6\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.3.4.6.1\" class=\"ltx_text ltx_font_typewriter\">FedProx</span></td>\n<td id=\"S3.T2.3.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S3.T2.3.4.7.1\" class=\"ltx_text ltx_font_typewriter\">FedOPT</span></td>\n<td id=\"S3.T2.3.4.8\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.3.4.8.1\" class=\"ltx_text ltx_font_bold\"># Rounds</span></td>\n</tr>\n<tr id=\"S3.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Text Classification</td>\n<td id=\"S3.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">20news</td>\n<td id=\"S3.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<math id=\"S3.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=\" display=\"inline\"><semantics id=\"S3.T2.1.1.1.m1.1a\"><mrow id=\"S3.T2.1.1.1.m1.1.1\" xref=\"S3.T2.1.1.1.m1.1.1.cmml\"><mi id=\"S3.T2.1.1.1.m1.1.1.2\" xref=\"S3.T2.1.1.1.m1.1.1.2.cmml\">Œ±</mi><mo id=\"S3.T2.1.1.1.m1.1.1.1\" xref=\"S3.T2.1.1.1.m1.1.1.1.cmml\">=</mo><mi id=\"S3.T2.1.1.1.m1.1.1.3\" xref=\"S3.T2.1.1.1.m1.1.1.3.cmml\"></mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.1.1.1.m1.1b\"><apply id=\"S3.T2.1.1.1.m1.1.1.cmml\" xref=\"S3.T2.1.1.1.m1.1.1\"><eq id=\"S3.T2.1.1.1.m1.1.1.1.cmml\" xref=\"S3.T2.1.1.1.m1.1.1.1\"></eq><ci id=\"S3.T2.1.1.1.m1.1.1.2.cmml\" xref=\"S3.T2.1.1.1.m1.1.1.2\">ùõº</ci><csymbol cd=\"latexml\" id=\"S3.T2.1.1.1.m1.1.1.3.cmml\" xref=\"S3.T2.1.1.1.m1.1.1.3\">absent</csymbol></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.1.1.1.m1.1c\">\\alpha=</annotation></semantics></math>1 (label shift)</td>\n<td id=\"S3.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100</td>\n<td id=\"S3.T2.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.5142</td>\n<td id=\"S3.T2.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.5143</td>\n<td id=\"S3.T2.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.5349</td>\n<td id=\"S3.T2.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">22</td>\n</tr>\n<tr id=\"S3.T2.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.2.2.2\" class=\"ltx_td ltx_align_center\">Sequence Tagging</td>\n<td id=\"S3.T2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">OntoNotes</td>\n<td id=\"S3.T2.2.2.1\" class=\"ltx_td ltx_align_center\">\n<math id=\"S3.T2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=\" display=\"inline\"><semantics id=\"S3.T2.2.2.1.m1.1a\"><mrow id=\"S3.T2.2.2.1.m1.1.1\" xref=\"S3.T2.2.2.1.m1.1.1.cmml\"><mi id=\"S3.T2.2.2.1.m1.1.1.2\" xref=\"S3.T2.2.2.1.m1.1.1.2.cmml\">Œ±</mi><mo id=\"S3.T2.2.2.1.m1.1.1.1\" xref=\"S3.T2.2.2.1.m1.1.1.1.cmml\">=</mo><mi id=\"S3.T2.2.2.1.m1.1.1.3\" xref=\"S3.T2.2.2.1.m1.1.1.3.cmml\"></mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.2.2.1.m1.1b\"><apply id=\"S3.T2.2.2.1.m1.1.1.cmml\" xref=\"S3.T2.2.2.1.m1.1.1\"><eq id=\"S3.T2.2.2.1.m1.1.1.1.cmml\" xref=\"S3.T2.2.2.1.m1.1.1.1\"></eq><ci id=\"S3.T2.2.2.1.m1.1.1.2.cmml\" xref=\"S3.T2.2.2.1.m1.1.1.2\">ùõº</ci><csymbol cd=\"latexml\" id=\"S3.T2.2.2.1.m1.1.1.3.cmml\" xref=\"S3.T2.2.2.1.m1.1.1.3\">absent</csymbol></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.2.2.1.m1.1c\">\\alpha=</annotation></semantics></math>0.1 (label shift)</td>\n<td id=\"S3.T2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">30</td>\n<td id=\"S3.T2.2.2.5\" class=\"ltx_td ltx_align_center\">0.7382</td>\n<td id=\"S3.T2.2.2.6\" class=\"ltx_td ltx_align_center\">0.6731</td>\n<td id=\"S3.T2.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0.7918</td>\n<td id=\"S3.T2.2.2.8\" class=\"ltx_td ltx_align_center\">17</td>\n</tr>\n<tr id=\"S3.T2.3.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.5.1\" class=\"ltx_td ltx_align_center\">Question Answering</td>\n<td id=\"S3.T2.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">MRQA</td>\n<td id=\"S3.T2.3.5.3\" class=\"ltx_td ltx_align_center\">natural factor</td>\n<td id=\"S3.T2.3.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">6</td>\n<td id=\"S3.T2.3.5.5\" class=\"ltx_td ltx_align_center\">0.2707</td>\n<td id=\"S3.T2.3.5.6\" class=\"ltx_td ltx_align_center\">0.2706</td>\n<td id=\"S3.T2.3.5.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0.3280</td>\n<td id=\"S3.T2.3.5.8\" class=\"ltx_td ltx_align_center\">13</td>\n</tr>\n<tr id=\"S3.T2.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">Seq2Seq Generation</td>\n<td id=\"S3.T2.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">Gigaword</td>\n<td id=\"S3.T2.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<math id=\"S3.T2.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=\" display=\"inline\"><semantics id=\"S3.T2.3.3.1.m1.1a\"><mrow id=\"S3.T2.3.3.1.m1.1.1\" xref=\"S3.T2.3.3.1.m1.1.1.cmml\"><mi id=\"S3.T2.3.3.1.m1.1.1.2\" xref=\"S3.T2.3.3.1.m1.1.1.2.cmml\">Œ±</mi><mo id=\"S3.T2.3.3.1.m1.1.1.1\" xref=\"S3.T2.3.3.1.m1.1.1.1.cmml\">=</mo><mi id=\"S3.T2.3.3.1.m1.1.1.3\" xref=\"S3.T2.3.3.1.m1.1.1.3.cmml\"></mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.3.3.1.m1.1b\"><apply id=\"S3.T2.3.3.1.m1.1.1.cmml\" xref=\"S3.T2.3.3.1.m1.1.1\"><eq id=\"S3.T2.3.3.1.m1.1.1.1.cmml\" xref=\"S3.T2.3.3.1.m1.1.1.1\"></eq><ci id=\"S3.T2.3.3.1.m1.1.1.2.cmml\" xref=\"S3.T2.3.3.1.m1.1.1.2\">ùõº</ci><csymbol cd=\"latexml\" id=\"S3.T2.3.3.1.m1.1.1.3.cmml\" xref=\"S3.T2.3.3.1.m1.1.1.3\">absent</csymbol></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.3.3.1.m1.1c\">\\alpha=</annotation></semantics></math>0.1 (feature shift)</td>\n<td id=\"S3.T2.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">100</td>\n<td id=\"S3.T2.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.3192</td>\n<td id=\"S3.T2.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.3169</td>\n<td id=\"S3.T2.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">0.3037</td>\n<td id=\"S3.T2.3.3.8\" class=\"ltx_td ltx_align_center ltx_border_bb\">13</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We show the basic statistics of the above datasets in Table¬†1.\nNote that our FedNLP as a research platform supports a much wider range of specific tasks of each formulation, while we only introduce the ones used in our experiments here with typical settings.\nMoreover, our contribution is more of a general FL+NLP benchmarking platform instead of particular datasets and partitions.",
            "Although straightforward and effective, the above label-based Dirichlet allocation method has a major limitation ‚Äî it is only suitable for text classification tasks where the outputs can be modeled as category-based random variables.\nTo create synthetic partitions for other non-classification NLP tasks and model distribution shifts,\nwe thus propose a partition method based on feature clustering.\nSpecifically,\nwe use SentenceBERT¬†Reimers and Gurevych (2019) to encode each example to a dense vector by their text then we apply K-Means clustering to get the cluster label of each example; finally, we use these cluster labels (as if they were classification tasks) to follow the steps in modeling label distribution shift.\nThere are two obvious benefits of this clustering-based Dirichlet partition method:\n1) It enables us to easily synthesize the FL datasets for non-classification tasks (i.e., ST, QA, SS) as they do not have discrete labels as output space;\n2) The BERT-based clustering results naturally imply different sub-topics of a dataset, and thus feature shift can be seen as a shift of latent labels ‚Äî we can reuse the same method for the label-based Dirichlet partition method.",
            "We use DistilBERT and BART-base for most of our experiments,\nas the former is a distilled version of the BERT model and has a 7x speed improvement over BERT-base on mobile devices ‚Äî a common scenario for FL applications; the BART-base model is the most suitable option considering the trade-off between performance and computation cost.\nWe leave our implementation details and the selected hyper-parameters in the submitted supplementary materials.",
            "Our experiments cover both cross-device and cross-silo settings. As shown in Table 2, in the cross-device setting, we use uniform sampling to select 10 clients for each round when the client number in a dataset is very large (e.g., 100). For the cross-silo setting, each round will select the same number of clients (we use 6 for the QA task). The local epoch number is set to 1 for all experiments.\nTo make our results reproducible, we use wandb.ai to store all experiment logs and hyper-parameters as well as running scripts.",
            "We compare the three typical FL methods under the same setting (i.e., data partition, communication rounds, etc.) for each task formulation.\nAs shown in Table¬†2,\nwe report the results of FedAvg, FedProx, and FedOPT.\nWe can see that overall FedOPT performs better than the other two methods, with the only exception being in the seq2seq generation task.\nFedAvg and FedProx perform similarly with marginal differences, but FedAvg outperforms FedProx in sequence tagging.\nThese two exceptions are surprising findings, as many prior works in the FL community show that FedOPT is generally better than FedProx and FedAvg on vision tasks and datasets.",
            "We report our results in Table¬†3 and Figure¬†6.\nWe find that in centralized training, the largest performance gain happens when we unfreeze the last layer, while in FedOPT we have to unfreeze the last three layers to enjoy a comparable performance with the full model.\nThis suggests that reducing communication costs via freezing some layers of Transformer LMs is feasible, though one should be aware that the experience in centralized training may not generalize to the FL experiments."
        ]
    },
    "S4.T3": {
        "caption": "–¢–∞–±–ª–∏—Ü–∞ 3: \nPerformance (Acc.%) on 20news (TC) when different parts of DistilBERT are frozen for centralized training and FedOpt (at 28-th round). Eùê∏E stands for the embedding layer and LisubscriptùêøùëñL_{i} means the iùëñi-th layer. The significant lower accuracy are underlined.\n",
        "table": "<table id=\"S4.T3.7\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T3.7.8\" class=\"ltx_tr\">\n<td id=\"S4.T3.7.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Frozen Layers</td>\n<td id=\"S4.T3.7.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"># Tunable Paras.</td>\n<td id=\"S4.T3.7.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Cent.</td>\n<td id=\"S4.T3.7.8.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedOpt.</td>\n</tr>\n<tr id=\"S4.T3.7.9\" class=\"ltx_tr\">\n<td id=\"S4.T3.7.9.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T3.7.9.1.1\" class=\"ltx_text ltx_font_typewriter\">None</span></td>\n<td id=\"S4.T3.7.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">67.0M</td>\n<td id=\"S4.T3.7.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\">86.86</td>\n<td id=\"S4.T3.7.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">55.11</td>\n</tr>\n<tr id=\"S4.T3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><math id=\"S4.T3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"E\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.m1.1a\"><mi id=\"S4.T3.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.m1.1.1.cmml\">E</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.m1.1b\"><ci id=\"S4.T3.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.m1.1.1\">ùê∏</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.m1.1c\">E</annotation></semantics></math></td>\n<td id=\"S4.T3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r\">43.1M</td>\n<td id=\"S4.T3.1.1.3\" class=\"ltx_td ltx_align_center\">86.19</td>\n<td id=\"S4.T3.1.1.4\" class=\"ltx_td ltx_align_center\">54.86</td>\n</tr>\n<tr id=\"S4.T3.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><math id=\"S4.T3.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"E+L_{0}\" display=\"inline\"><semantics id=\"S4.T3.2.2.1.m1.1a\"><mrow id=\"S4.T3.2.2.1.m1.1.1\" xref=\"S4.T3.2.2.1.m1.1.1.cmml\"><mi id=\"S4.T3.2.2.1.m1.1.1.2\" xref=\"S4.T3.2.2.1.m1.1.1.2.cmml\">E</mi><mo id=\"S4.T3.2.2.1.m1.1.1.1\" xref=\"S4.T3.2.2.1.m1.1.1.1.cmml\">+</mo><msub id=\"S4.T3.2.2.1.m1.1.1.3\" xref=\"S4.T3.2.2.1.m1.1.1.3.cmml\"><mi id=\"S4.T3.2.2.1.m1.1.1.3.2\" xref=\"S4.T3.2.2.1.m1.1.1.3.2.cmml\">L</mi><mn id=\"S4.T3.2.2.1.m1.1.1.3.3\" xref=\"S4.T3.2.2.1.m1.1.1.3.3.cmml\">0</mn></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.1.m1.1b\"><apply id=\"S4.T3.2.2.1.m1.1.1.cmml\" xref=\"S4.T3.2.2.1.m1.1.1\"><plus id=\"S4.T3.2.2.1.m1.1.1.1.cmml\" xref=\"S4.T3.2.2.1.m1.1.1.1\"></plus><ci id=\"S4.T3.2.2.1.m1.1.1.2.cmml\" xref=\"S4.T3.2.2.1.m1.1.1.2\">ùê∏</ci><apply id=\"S4.T3.2.2.1.m1.1.1.3.cmml\" xref=\"S4.T3.2.2.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T3.2.2.1.m1.1.1.3.1.cmml\" xref=\"S4.T3.2.2.1.m1.1.1.3\">subscript</csymbol><ci id=\"S4.T3.2.2.1.m1.1.1.3.2.cmml\" xref=\"S4.T3.2.2.1.m1.1.1.3.2\">ùêø</ci><cn type=\"integer\" id=\"S4.T3.2.2.1.m1.1.1.3.3.cmml\" xref=\"S4.T3.2.2.1.m1.1.1.3.3\">0</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.1.m1.1c\">E+L_{0}</annotation></semantics></math></td>\n<td id=\"S4.T3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">36.0M</td>\n<td id=\"S4.T3.2.2.3\" class=\"ltx_td ltx_align_center\">86.54</td>\n<td id=\"S4.T3.2.2.4\" class=\"ltx_td ltx_align_center\">52.91</td>\n</tr>\n<tr id=\"S4.T3.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><math id=\"S4.T3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"E+L_{0\\rightarrow 1}\" display=\"inline\"><semantics id=\"S4.T3.3.3.1.m1.1a\"><mrow id=\"S4.T3.3.3.1.m1.1.1\" xref=\"S4.T3.3.3.1.m1.1.1.cmml\"><mi id=\"S4.T3.3.3.1.m1.1.1.2\" xref=\"S4.T3.3.3.1.m1.1.1.2.cmml\">E</mi><mo id=\"S4.T3.3.3.1.m1.1.1.1\" xref=\"S4.T3.3.3.1.m1.1.1.1.cmml\">+</mo><msub id=\"S4.T3.3.3.1.m1.1.1.3\" xref=\"S4.T3.3.3.1.m1.1.1.3.cmml\"><mi id=\"S4.T3.3.3.1.m1.1.1.3.2\" xref=\"S4.T3.3.3.1.m1.1.1.3.2.cmml\">L</mi><mrow id=\"S4.T3.3.3.1.m1.1.1.3.3\" xref=\"S4.T3.3.3.1.m1.1.1.3.3.cmml\"><mn id=\"S4.T3.3.3.1.m1.1.1.3.3.2\" xref=\"S4.T3.3.3.1.m1.1.1.3.3.2.cmml\">0</mn><mo stretchy=\"false\" id=\"S4.T3.3.3.1.m1.1.1.3.3.1\" xref=\"S4.T3.3.3.1.m1.1.1.3.3.1.cmml\">‚Üí</mo><mn id=\"S4.T3.3.3.1.m1.1.1.3.3.3\" xref=\"S4.T3.3.3.1.m1.1.1.3.3.3.cmml\">1</mn></mrow></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.3.3.1.m1.1b\"><apply id=\"S4.T3.3.3.1.m1.1.1.cmml\" xref=\"S4.T3.3.3.1.m1.1.1\"><plus id=\"S4.T3.3.3.1.m1.1.1.1.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.1\"></plus><ci id=\"S4.T3.3.3.1.m1.1.1.2.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.2\">ùê∏</ci><apply id=\"S4.T3.3.3.1.m1.1.1.3.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T3.3.3.1.m1.1.1.3.1.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.3\">subscript</csymbol><ci id=\"S4.T3.3.3.1.m1.1.1.3.2.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.3.2\">ùêø</ci><apply id=\"S4.T3.3.3.1.m1.1.1.3.3.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.3.3\"><ci id=\"S4.T3.3.3.1.m1.1.1.3.3.1.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.3.3.1\">‚Üí</ci><cn type=\"integer\" id=\"S4.T3.3.3.1.m1.1.1.3.3.2.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.3.3.2\">0</cn><cn type=\"integer\" id=\"S4.T3.3.3.1.m1.1.1.3.3.3.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.3.3.3\">1</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.3.3.1.m1.1c\">E+L_{0\\rightarrow 1}</annotation></semantics></math></td>\n<td id=\"S4.T3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">29.0M</td>\n<td id=\"S4.T3.3.3.3\" class=\"ltx_td ltx_align_center\">86.52</td>\n<td id=\"S4.T3.3.3.4\" class=\"ltx_td ltx_align_center\">53.92</td>\n</tr>\n<tr id=\"S4.T3.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><math id=\"S4.T3.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"E+L_{0\\rightarrow 2}\" display=\"inline\"><semantics id=\"S4.T3.4.4.1.m1.1a\"><mrow id=\"S4.T3.4.4.1.m1.1.1\" xref=\"S4.T3.4.4.1.m1.1.1.cmml\"><mi id=\"S4.T3.4.4.1.m1.1.1.2\" xref=\"S4.T3.4.4.1.m1.1.1.2.cmml\">E</mi><mo id=\"S4.T3.4.4.1.m1.1.1.1\" xref=\"S4.T3.4.4.1.m1.1.1.1.cmml\">+</mo><msub id=\"S4.T3.4.4.1.m1.1.1.3\" xref=\"S4.T3.4.4.1.m1.1.1.3.cmml\"><mi id=\"S4.T3.4.4.1.m1.1.1.3.2\" xref=\"S4.T3.4.4.1.m1.1.1.3.2.cmml\">L</mi><mrow id=\"S4.T3.4.4.1.m1.1.1.3.3\" xref=\"S4.T3.4.4.1.m1.1.1.3.3.cmml\"><mn id=\"S4.T3.4.4.1.m1.1.1.3.3.2\" xref=\"S4.T3.4.4.1.m1.1.1.3.3.2.cmml\">0</mn><mo stretchy=\"false\" id=\"S4.T3.4.4.1.m1.1.1.3.3.1\" xref=\"S4.T3.4.4.1.m1.1.1.3.3.1.cmml\">‚Üí</mo><mn id=\"S4.T3.4.4.1.m1.1.1.3.3.3\" xref=\"S4.T3.4.4.1.m1.1.1.3.3.3.cmml\">2</mn></mrow></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.4.4.1.m1.1b\"><apply id=\"S4.T3.4.4.1.m1.1.1.cmml\" xref=\"S4.T3.4.4.1.m1.1.1\"><plus id=\"S4.T3.4.4.1.m1.1.1.1.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.1\"></plus><ci id=\"S4.T3.4.4.1.m1.1.1.2.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.2\">ùê∏</ci><apply id=\"S4.T3.4.4.1.m1.1.1.3.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T3.4.4.1.m1.1.1.3.1.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.3\">subscript</csymbol><ci id=\"S4.T3.4.4.1.m1.1.1.3.2.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.3.2\">ùêø</ci><apply id=\"S4.T3.4.4.1.m1.1.1.3.3.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.3.3\"><ci id=\"S4.T3.4.4.1.m1.1.1.3.3.1.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.3.3.1\">‚Üí</ci><cn type=\"integer\" id=\"S4.T3.4.4.1.m1.1.1.3.3.2.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.3.3.2\">0</cn><cn type=\"integer\" id=\"S4.T3.4.4.1.m1.1.1.3.3.3.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.3.3.3\">2</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.4.4.1.m1.1c\">E+L_{0\\rightarrow 2}</annotation></semantics></math></td>\n<td id=\"S4.T3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">21.9M</td>\n<td id=\"S4.T3.4.4.3\" class=\"ltx_td ltx_align_center\">85.71</td>\n<td id=\"S4.T3.4.4.4\" class=\"ltx_td ltx_align_center\">52.01</td>\n</tr>\n<tr id=\"S4.T3.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><math id=\"S4.T3.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"E+L_{0\\rightarrow 3}\" display=\"inline\"><semantics id=\"S4.T3.5.5.1.m1.1a\"><mrow id=\"S4.T3.5.5.1.m1.1.1\" xref=\"S4.T3.5.5.1.m1.1.1.cmml\"><mi id=\"S4.T3.5.5.1.m1.1.1.2\" xref=\"S4.T3.5.5.1.m1.1.1.2.cmml\">E</mi><mo id=\"S4.T3.5.5.1.m1.1.1.1\" xref=\"S4.T3.5.5.1.m1.1.1.1.cmml\">+</mo><msub id=\"S4.T3.5.5.1.m1.1.1.3\" xref=\"S4.T3.5.5.1.m1.1.1.3.cmml\"><mi id=\"S4.T3.5.5.1.m1.1.1.3.2\" xref=\"S4.T3.5.5.1.m1.1.1.3.2.cmml\">L</mi><mrow id=\"S4.T3.5.5.1.m1.1.1.3.3\" xref=\"S4.T3.5.5.1.m1.1.1.3.3.cmml\"><mn id=\"S4.T3.5.5.1.m1.1.1.3.3.2\" xref=\"S4.T3.5.5.1.m1.1.1.3.3.2.cmml\">0</mn><mo stretchy=\"false\" id=\"S4.T3.5.5.1.m1.1.1.3.3.1\" xref=\"S4.T3.5.5.1.m1.1.1.3.3.1.cmml\">‚Üí</mo><mn id=\"S4.T3.5.5.1.m1.1.1.3.3.3\" xref=\"S4.T3.5.5.1.m1.1.1.3.3.3.cmml\">3</mn></mrow></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.5.5.1.m1.1b\"><apply id=\"S4.T3.5.5.1.m1.1.1.cmml\" xref=\"S4.T3.5.5.1.m1.1.1\"><plus id=\"S4.T3.5.5.1.m1.1.1.1.cmml\" xref=\"S4.T3.5.5.1.m1.1.1.1\"></plus><ci id=\"S4.T3.5.5.1.m1.1.1.2.cmml\" xref=\"S4.T3.5.5.1.m1.1.1.2\">ùê∏</ci><apply id=\"S4.T3.5.5.1.m1.1.1.3.cmml\" xref=\"S4.T3.5.5.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T3.5.5.1.m1.1.1.3.1.cmml\" xref=\"S4.T3.5.5.1.m1.1.1.3\">subscript</csymbol><ci id=\"S4.T3.5.5.1.m1.1.1.3.2.cmml\" xref=\"S4.T3.5.5.1.m1.1.1.3.2\">ùêø</ci><apply id=\"S4.T3.5.5.1.m1.1.1.3.3.cmml\" xref=\"S4.T3.5.5.1.m1.1.1.3.3\"><ci id=\"S4.T3.5.5.1.m1.1.1.3.3.1.cmml\" xref=\"S4.T3.5.5.1.m1.1.1.3.3.1\">‚Üí</ci><cn type=\"integer\" id=\"S4.T3.5.5.1.m1.1.1.3.3.2.cmml\" xref=\"S4.T3.5.5.1.m1.1.1.3.3.2\">0</cn><cn type=\"integer\" id=\"S4.T3.5.5.1.m1.1.1.3.3.3.cmml\" xref=\"S4.T3.5.5.1.m1.1.1.3.3.3\">3</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.5.5.1.m1.1c\">E+L_{0\\rightarrow 3}</annotation></semantics></math></td>\n<td id=\"S4.T3.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">14.8M</td>\n<td id=\"S4.T3.5.5.3\" class=\"ltx_td ltx_align_center\">85.47</td>\n<td id=\"S4.T3.5.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.5.5.4.1\" class=\"ltx_text ltx_font_italic ltx_framed ltx_framed_underline\">30.68</span></td>\n</tr>\n<tr id=\"S4.T3.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><math id=\"S4.T3.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"E+L_{0\\rightarrow 4}\" display=\"inline\"><semantics id=\"S4.T3.6.6.1.m1.1a\"><mrow id=\"S4.T3.6.6.1.m1.1.1\" xref=\"S4.T3.6.6.1.m1.1.1.cmml\"><mi id=\"S4.T3.6.6.1.m1.1.1.2\" xref=\"S4.T3.6.6.1.m1.1.1.2.cmml\">E</mi><mo id=\"S4.T3.6.6.1.m1.1.1.1\" xref=\"S4.T3.6.6.1.m1.1.1.1.cmml\">+</mo><msub id=\"S4.T3.6.6.1.m1.1.1.3\" xref=\"S4.T3.6.6.1.m1.1.1.3.cmml\"><mi id=\"S4.T3.6.6.1.m1.1.1.3.2\" xref=\"S4.T3.6.6.1.m1.1.1.3.2.cmml\">L</mi><mrow id=\"S4.T3.6.6.1.m1.1.1.3.3\" xref=\"S4.T3.6.6.1.m1.1.1.3.3.cmml\"><mn id=\"S4.T3.6.6.1.m1.1.1.3.3.2\" xref=\"S4.T3.6.6.1.m1.1.1.3.3.2.cmml\">0</mn><mo stretchy=\"false\" id=\"S4.T3.6.6.1.m1.1.1.3.3.1\" xref=\"S4.T3.6.6.1.m1.1.1.3.3.1.cmml\">‚Üí</mo><mn id=\"S4.T3.6.6.1.m1.1.1.3.3.3\" xref=\"S4.T3.6.6.1.m1.1.1.3.3.3.cmml\">4</mn></mrow></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.6.6.1.m1.1b\"><apply id=\"S4.T3.6.6.1.m1.1.1.cmml\" xref=\"S4.T3.6.6.1.m1.1.1\"><plus id=\"S4.T3.6.6.1.m1.1.1.1.cmml\" xref=\"S4.T3.6.6.1.m1.1.1.1\"></plus><ci id=\"S4.T3.6.6.1.m1.1.1.2.cmml\" xref=\"S4.T3.6.6.1.m1.1.1.2\">ùê∏</ci><apply id=\"S4.T3.6.6.1.m1.1.1.3.cmml\" xref=\"S4.T3.6.6.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T3.6.6.1.m1.1.1.3.1.cmml\" xref=\"S4.T3.6.6.1.m1.1.1.3\">subscript</csymbol><ci id=\"S4.T3.6.6.1.m1.1.1.3.2.cmml\" xref=\"S4.T3.6.6.1.m1.1.1.3.2\">ùêø</ci><apply id=\"S4.T3.6.6.1.m1.1.1.3.3.cmml\" xref=\"S4.T3.6.6.1.m1.1.1.3.3\"><ci id=\"S4.T3.6.6.1.m1.1.1.3.3.1.cmml\" xref=\"S4.T3.6.6.1.m1.1.1.3.3.1\">‚Üí</ci><cn type=\"integer\" id=\"S4.T3.6.6.1.m1.1.1.3.3.2.cmml\" xref=\"S4.T3.6.6.1.m1.1.1.3.3.2\">0</cn><cn type=\"integer\" id=\"S4.T3.6.6.1.m1.1.1.3.3.3.cmml\" xref=\"S4.T3.6.6.1.m1.1.1.3.3.3\">4</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.6.6.1.m1.1c\">E+L_{0\\rightarrow 4}</annotation></semantics></math></td>\n<td id=\"S4.T3.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">7.7M</td>\n<td id=\"S4.T3.6.6.3\" class=\"ltx_td ltx_align_center\">82.76</td>\n<td id=\"S4.T3.6.6.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.6.6.4.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">16.63</span></td>\n</tr>\n<tr id=\"S4.T3.7.7\" class=\"ltx_tr\">\n<td id=\"S4.T3.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><math id=\"S4.T3.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"E+L_{0\\rightarrow 5}\" display=\"inline\"><semantics id=\"S4.T3.7.7.1.m1.1a\"><mrow id=\"S4.T3.7.7.1.m1.1.1\" xref=\"S4.T3.7.7.1.m1.1.1.cmml\"><mi id=\"S4.T3.7.7.1.m1.1.1.2\" xref=\"S4.T3.7.7.1.m1.1.1.2.cmml\">E</mi><mo id=\"S4.T3.7.7.1.m1.1.1.1\" xref=\"S4.T3.7.7.1.m1.1.1.1.cmml\">+</mo><msub id=\"S4.T3.7.7.1.m1.1.1.3\" xref=\"S4.T3.7.7.1.m1.1.1.3.cmml\"><mi id=\"S4.T3.7.7.1.m1.1.1.3.2\" xref=\"S4.T3.7.7.1.m1.1.1.3.2.cmml\">L</mi><mrow id=\"S4.T3.7.7.1.m1.1.1.3.3\" xref=\"S4.T3.7.7.1.m1.1.1.3.3.cmml\"><mn id=\"S4.T3.7.7.1.m1.1.1.3.3.2\" xref=\"S4.T3.7.7.1.m1.1.1.3.3.2.cmml\">0</mn><mo stretchy=\"false\" id=\"S4.T3.7.7.1.m1.1.1.3.3.1\" xref=\"S4.T3.7.7.1.m1.1.1.3.3.1.cmml\">‚Üí</mo><mn id=\"S4.T3.7.7.1.m1.1.1.3.3.3\" xref=\"S4.T3.7.7.1.m1.1.1.3.3.3.cmml\">5</mn></mrow></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.7.7.1.m1.1b\"><apply id=\"S4.T3.7.7.1.m1.1.1.cmml\" xref=\"S4.T3.7.7.1.m1.1.1\"><plus id=\"S4.T3.7.7.1.m1.1.1.1.cmml\" xref=\"S4.T3.7.7.1.m1.1.1.1\"></plus><ci id=\"S4.T3.7.7.1.m1.1.1.2.cmml\" xref=\"S4.T3.7.7.1.m1.1.1.2\">ùê∏</ci><apply id=\"S4.T3.7.7.1.m1.1.1.3.cmml\" xref=\"S4.T3.7.7.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T3.7.7.1.m1.1.1.3.1.cmml\" xref=\"S4.T3.7.7.1.m1.1.1.3\">subscript</csymbol><ci id=\"S4.T3.7.7.1.m1.1.1.3.2.cmml\" xref=\"S4.T3.7.7.1.m1.1.1.3.2\">ùêø</ci><apply id=\"S4.T3.7.7.1.m1.1.1.3.3.cmml\" xref=\"S4.T3.7.7.1.m1.1.1.3.3\"><ci id=\"S4.T3.7.7.1.m1.1.1.3.3.1.cmml\" xref=\"S4.T3.7.7.1.m1.1.1.3.3.1\">‚Üí</ci><cn type=\"integer\" id=\"S4.T3.7.7.1.m1.1.1.3.3.2.cmml\" xref=\"S4.T3.7.7.1.m1.1.1.3.3.2\">0</cn><cn type=\"integer\" id=\"S4.T3.7.7.1.m1.1.1.3.3.3.cmml\" xref=\"S4.T3.7.7.1.m1.1.1.3.3.3\">5</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.7.7.1.m1.1c\">E+L_{0\\rightarrow 5}</annotation></semantics></math></td>\n<td id=\"S4.T3.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">0.6M</td>\n<td id=\"S4.T3.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.7.7.3.1\" class=\"ltx_text ltx_font_italic ltx_framed ltx_framed_underline\">63.83</span></td>\n<td id=\"S4.T3.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.7.7.4.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">12.97</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We show the basic statistics of the above datasets in Table¬†1.\nNote that our FedNLP as a research platform supports a much wider range of specific tasks of each formulation, while we only introduce the ones used in our experiments here with typical settings.\nMoreover, our contribution is more of a general FL+NLP benchmarking platform instead of particular datasets and partitions.",
            "Although straightforward and effective, the above label-based Dirichlet allocation method has a major limitation ‚Äî it is only suitable for text classification tasks where the outputs can be modeled as category-based random variables.\nTo create synthetic partitions for other non-classification NLP tasks and model distribution shifts,\nwe thus propose a partition method based on feature clustering.\nSpecifically,\nwe use SentenceBERT¬†Reimers and Gurevych (2019) to encode each example to a dense vector by their text then we apply K-Means clustering to get the cluster label of each example; finally, we use these cluster labels (as if they were classification tasks) to follow the steps in modeling label distribution shift.\nThere are two obvious benefits of this clustering-based Dirichlet partition method:\n1) It enables us to easily synthesize the FL datasets for non-classification tasks (i.e., ST, QA, SS) as they do not have discrete labels as output space;\n2) The BERT-based clustering results naturally imply different sub-topics of a dataset, and thus feature shift can be seen as a shift of latent labels ‚Äî we can reuse the same method for the label-based Dirichlet partition method.",
            "We use DistilBERT and BART-base for most of our experiments,\nas the former is a distilled version of the BERT model and has a 7x speed improvement over BERT-base on mobile devices ‚Äî a common scenario for FL applications; the BART-base model is the most suitable option considering the trade-off between performance and computation cost.\nWe leave our implementation details and the selected hyper-parameters in the submitted supplementary materials.",
            "Our experiments cover both cross-device and cross-silo settings. As shown in Table 2, in the cross-device setting, we use uniform sampling to select 10 clients for each round when the client number in a dataset is very large (e.g., 100). For the cross-silo setting, each round will select the same number of clients (we use 6 for the QA task). The local epoch number is set to 1 for all experiments.\nTo make our results reproducible, we use wandb.ai to store all experiment logs and hyper-parameters as well as running scripts.",
            "We compare the three typical FL methods under the same setting (i.e., data partition, communication rounds, etc.) for each task formulation.\nAs shown in Table¬†2,\nwe report the results of FedAvg, FedProx, and FedOPT.\nWe can see that overall FedOPT performs better than the other two methods, with the only exception being in the seq2seq generation task.\nFedAvg and FedProx perform similarly with marginal differences, but FedAvg outperforms FedProx in sequence tagging.\nThese two exceptions are surprising findings, as many prior works in the FL community show that FedOPT is generally better than FedProx and FedAvg on vision tasks and datasets.",
            "We report our results in Table¬†3 and Figure¬†6.\nWe find that in centralized training, the largest performance gain happens when we unfreeze the last layer, while in FedOPT we have to unfreeze the last three layers to enjoy a comparable performance with the full model.\nThis suggests that reducing communication costs via freezing some layers of Transformer LMs is feasible, though one should be aware that the experience in centralized training may not generalize to the FL experiments."
        ]
    }
}