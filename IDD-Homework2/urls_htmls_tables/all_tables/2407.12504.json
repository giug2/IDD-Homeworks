{
    "A1.T5": {
        "caption": "Table 5: Prompt template for zero-shot Case2Code\u00a0evaluation. We inject {prompt} and {func_name} for each test sample for evaluation.",
        "table": "<table id=\"A1.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T5.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"A1.T5.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Prompt Template for Zero-shot Case2Code&#160;Evaluation.</span></td>\n</tr>\n<tr id=\"A1.T5.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">\n<span id=\"A1.T5.1.2.1.1\" class=\"ltx_inline-block ltx_minipage ltx_align_middle\" style=\"width:346.9pt;\"><span id=\"A1.T5.1.2.1.1.1\" class=\"ltx_ERROR undefined\">{spverbatim}</span>\n<span id=\"A1.T5.1.2.1.1.2\" class=\"ltx_p\">prompt</span>\n<span id=\"A1.T5.1.2.1.1.3\" class=\"ltx_p\">Please write the correct names of arguments. As the function you implement will be called by: func_name(**input_dict). Keep the original type. No need to convert the output to string.</span>\n</span>\n</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "The prompt template for evaluating zero-shot Case2Code\u00a0performance of various LLMs is listed in Table\u00a05."
        ]
    },
    "A1.T6": {
        "caption": "Table 6: Prompt for LLM input generator, we replace {code} with programs collected in for Case2Code.",
        "table": "<table id=\"A1.T6.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T6.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"A1.T6.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Prompt for LLM Input Generator</span></td>\n</tr>\n<tr id=\"A1.T6.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">\n<span id=\"A1.T6.1.2.1.1\" class=\"ltx_inline-block ltx_minipage ltx_align_middle\" style=\"width:346.9pt;\"><span id=\"A1.T6.1.2.1.1.1\" class=\"ltx_ERROR undefined\">{spverbatim}</span>\n<span id=\"A1.T6.1.2.1.1.2\" class=\"ltx_p\">Given the function, first analyze the types of the function arguments, then write 10 different example inputs for the function, each example should be a dict with function arguments&#8217; names and their values.\nOutput format:\n&#8220;&#8216;python\nexamples = [\ndict(argname=argvalue),\n&#8230;.\n]\n&#8220;&#8216;</span>\n<span id=\"A1.T6.1.2.1.1.3\" class=\"ltx_p\">Function:\n&#8220;&#8216;python\ndef test_func(a: int, b: str) -&gt; str:\nreturn str(a) + b\n&#8220;&#8216;\nExamples:\n&#8220;&#8216;python\nexamples = [\ndict(a=1, b=&#8217;a&#8217;),\ndict(a=2, b=&#8217;b&#8217;),\ndict(a=3, b=&#8217;c&#8217;),\ndict(a=4, b=&#8217;d&#8217;),\ndict(a=5, b=&#8217;e&#8217;),\ndict(a=6, b=&#8217;f&#8217;),\ndict(a=7, b=&#8217;g&#8217;),\ndict(a=8, b=&#8217;h&#8217;),\ndict(a=9, b=&#8217;i&#8217;),\ndict(a=10, b=&#8217;j&#8217;),\n]\n&#8220;&#8216;</span>\n<span id=\"A1.T6.1.2.1.1.4\" class=\"ltx_p\">Function:\n&#8220;&#8216;python\ncode\n&#8220;&#8216;\nExamples:</span>\n</span>\n</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "Once we collect large-scale functions, the next step is to obtain the corresponding input-output pairs for each function to construct the Case2Code\u00a0data. It is infeasible to write test cases for each function manually. So, we utilize LLMs to generate suitable input examples for these functions. We prompt LLMs to write some example input arguments for each function based on the corresponding function implementation. Detailed prompt is listed in Table\u00a06 in the appendix.",
            "We show the prompt for using LLMs as input generators for synthesizing Case2Code\u00a0data in Table\u00a06."
        ]
    },
    "A1.T7": {
        "caption": "Table 7: Case2Code\u00a0data examples.",
        "table": "<table id=\"A1.T7.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T7.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"A1.T7.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Case2Code&#160;Examples</span></td>\n</tr>\n<tr id=\"A1.T7.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<span id=\"A1.T7.1.2.1.1\" class=\"ltx_inline-block ltx_minipage ltx_align_middle\" style=\"width:346.9pt;\"><span id=\"A1.T7.1.2.1.1.1\" class=\"ltx_ERROR undefined\">{spverbatim}</span>\n<span id=\"A1.T7.1.2.1.1.2\" class=\"ltx_p\">Input: dict(s=\"abcba\", center=2), Output: \"(5, 0, 4)\"\nInput: dict(s=\"abcdefg\", center=3), Output: \"(1, 3, 3)\"\nInput: dict(s=\"aba\", center=1), Output: \"(3, 0, 2)\"\nInput: dict(s=\"racecar\", center=3), Output: \"(7, 0, 6)\"\nInput: dict(s=\"madam\", center=2), Output: \"(5, 0, 4)\"\nInput: dict(s=\"abcabcabc\", center=4), Output: \"(1, 4, 4)\"\nInput: dict(s=\"xyzyx\", center=2), Output: \"(5, 0, 4)\"\nInput: dict(s=\"hello\", center=2), Output: \"(1, 2, 2)\"\nInput: dict(s=\"ab\", center=0), Output: \"(1, 0, 0)\"\nInput: dict(s=\"a\", center=0), Output: \"(1, 0, 0)\"</span>\n<span id=\"A1.T7.1.2.1.1.3\" class=\"ltx_p\">Write a function that generates the output from the input.\nFunction: greatest_palindrome_size_odd</span>\n</span>\n</td>\n</tr>\n<tr id=\"A1.T7.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.3.1\" class=\"ltx_td ltx_align_left\">\n<span id=\"A1.T7.1.3.1.1\" class=\"ltx_inline-block ltx_minipage ltx_align_middle\" style=\"width:346.9pt;\"><span id=\"A1.T7.1.3.1.1.1\" class=\"ltx_ERROR undefined\">{spverbatim}</span>\n<span id=\"A1.T7.1.3.1.1.2\" class=\"ltx_p\">The function is:</span>\n<span id=\"A1.T7.1.3.1.1.3\" class=\"ltx_p\">&#8220;&#8216;python\ndef greatest_palindrome_size_odd(s, center):\nright = center + 1\nleft = center - 1\nsize = 1\noptimum_right = optimum_left = center\nwhile left &gt;= 0 and right &lt; len(s):\nif s[left] == s[right]:\nsize += 2\noptimum_left = left\noptimum_right = right\nright += 1\nleft -= 1\nelse:\nbreak\nreturn size, optimum_left, optimum_right</span>\n<span id=\"A1.T7.1.3.1.1.4\" class=\"ltx_p\">&#8220;&#8216;</span>\n</span>\n</td>\n</tr>\n<tr id=\"A1.T7.1.4\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">\n<span id=\"A1.T7.1.4.1.1\" class=\"ltx_inline-block ltx_minipage ltx_align_middle\" style=\"width:346.9pt;\"><span id=\"A1.T7.1.4.1.1.1\" class=\"ltx_ERROR undefined\">{spverbatim}</span>\n<span id=\"A1.T7.1.4.1.1.2\" class=\"ltx_p\">Arguments and results:\nInput: dict(seq=\"ATCG\", complementarity=&#8217;A&#8217;: &#8217;U&#8217;, &#8217;T&#8217;: &#8217;A&#8217;, &#8217;C&#8217;: &#8217;G&#8217;, &#8217;G&#8217;: &#8217;C&#8217;), Output: \"&#8217;CGAU&#8217;\"\nInput: \"ATCG\", &#8217;A&#8217;: &#8217;T&#8217;, &#8217;T&#8217;: &#8217;A&#8217;, &#8217;C&#8217;: &#8217;G&#8217;, &#8217;G&#8217;: &#8217;C&#8217;, Output: \"&#8217;CGAT&#8217;\"\nInput: seq:\"ACGT\", complementarity:&#8217;A&#8217;: &#8217;U&#8217;, &#8217;T&#8217;: &#8217;A&#8217;, &#8217;C&#8217;: &#8217;G&#8217;, &#8217;G&#8217;: &#8217;C&#8217;, Output: \"&#8217;ACGU&#8217;\"\nInput: \"ACGT\", &#8217;A&#8217;: &#8217;T&#8217;, &#8217;T&#8217;: &#8217;A&#8217;, &#8217;C&#8217;: &#8217;G&#8217;, &#8217;G&#8217;: &#8217;C&#8217;, Output: \"&#8217;ACGT&#8217;\"</span>\n<span id=\"A1.T7.1.4.1.1.3\" class=\"ltx_p\">Please write a function to process the input arguments and produce the specified outputs.</span>\n<span id=\"A1.T7.1.4.1.1.4\" class=\"ltx_p\">Start with the function:\nreverse_complement</span>\n<span id=\"A1.T7.1.4.1.1.5\" class=\"ltx_p\">The function is:</span>\n<span id=\"A1.T7.1.4.1.1.6\" class=\"ltx_p\">&#8220;&#8216;python\ndef reverse_complement(seq, complementarity):\nbases = list(seq)\nbases = [complementarity[base] for base in bases]\nreversed_complement = &#8221;.join(bases)\nreturn reversed_complement[::-1]</span>\n<span id=\"A1.T7.1.4.1.1.7\" class=\"ltx_p\">&#8220;&#8216;</span>\n</span>\n</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "The final step is to convert the obtained functions and their corresponding input-output pairs into Case2Code\u00a0style data. Formally, for a given function \ud835\udcab\ud835\udcab\\mathcal{P} and its n\ud835\udc5bn test cases \ud835\udcae\ud835\udcab={(x1,y1),(x2,y2),\u2026,(xn,yn)}subscript\ud835\udcae\ud835\udcabsubscript\ud835\udc651subscript\ud835\udc661subscript\ud835\udc652subscript\ud835\udc662\u2026subscript\ud835\udc65\ud835\udc5bsubscript\ud835\udc66\ud835\udc5b\\mathcal{S_{P}}=\\{(x_{1},y_{1}),(x_{2},y_{2}),...,(x_{n},y_{n})\\}, we randomly sample m\ud835\udc5am examples (m<=n\ud835\udc5a\ud835\udc5bm<=n) as the observed set \ud835\udcae\ud835\udcab\u2032subscriptsuperscript\ud835\udcae\u2032\ud835\udcab\\mathcal{S^{\\prime}_{P}}. We generate the prompted data that facilitate the LLM to conduct inductive reasoning on the observed examples \ud835\udcae\ud835\udcab\u2032subscriptsuperscript\ud835\udcae\u2032\ud835\udcab\\mathcal{S^{\\prime}_{P}} to reconstruct the given function \ud835\udcab\ud835\udcab\\mathcal{P}. Converted training examples are shown in Table\u00a07 in the appendix.",
            "We randomly sample some Case2Code\u00a0 data to demonstrate in Table\u00a07."
        ]
    },
    "S4.T1": {
        "caption": "Table 1: Results of Code Benchmarks and zero-shot Case2Code\u00a0performance of various representative LLMs.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Size</span></td>\n<td id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">HumanEval</span></td>\n<td id=\"S4.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">\n<span id=\"S4.T1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">HumanEval</span>+</td>\n<td id=\"S4.T1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">MBPP</span></td>\n<td id=\"S4.T1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">\n<span id=\"S4.T1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">MBPP</span>+</td>\n<td id=\"S4.T1.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.1.1.7.1\" class=\"ltx_text ltx_font_bold\">Case2Code</span></td>\n</tr>\n<tr id=\"S4.T1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">GPT-4</td>\n<td id=\"S4.T1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S4.T1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">90.2</td>\n<td id=\"S4.T1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.6</td>\n<td id=\"S4.T1.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">85.7</td>\n<td id=\"S4.T1.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">73.3</td>\n<td id=\"S4.T1.1.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">43.6</td>\n</tr>\n<tr id=\"S4.T1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.3.1\" class=\"ltx_td ltx_align_left\">GPT-3.5</td>\n<td id=\"S4.T1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S4.T1.1.3.3\" class=\"ltx_td ltx_align_center\">76.8</td>\n<td id=\"S4.T1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">70.7</td>\n<td id=\"S4.T1.1.3.5\" class=\"ltx_td ltx_align_center\">82.5</td>\n<td id=\"S4.T1.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r\">69.7</td>\n<td id=\"S4.T1.1.3.7\" class=\"ltx_td ltx_align_center\">34.2</td>\n</tr>\n<tr id=\"S4.T1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"4\"><span id=\"S4.T1.1.4.1.1\" class=\"ltx_text\">LLaMA2-Chat</span></td>\n<td id=\"S4.T1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7B</td>\n<td id=\"S4.T1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">14.0</td>\n<td id=\"S4.T1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">11.6</td>\n<td id=\"S4.T1.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">26.8</td>\n<td id=\"S4.T1.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">20.3</td>\n<td id=\"S4.T1.1.4.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.2</td>\n</tr>\n<tr id=\"S4.T1.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">13B</td>\n<td id=\"S4.T1.1.5.2\" class=\"ltx_td ltx_align_center\">23.1</td>\n<td id=\"S4.T1.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">19.5</td>\n<td id=\"S4.T1.1.5.4\" class=\"ltx_td ltx_align_center\">37.0</td>\n<td id=\"S4.T1.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r\">27.6</td>\n<td id=\"S4.T1.1.5.6\" class=\"ltx_td ltx_align_center\">8.2</td>\n</tr>\n<tr id=\"S4.T1.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">34B</td>\n<td id=\"S4.T1.1.6.2\" class=\"ltx_td ltx_align_center\">22.6</td>\n<td id=\"S4.T1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S4.T1.1.6.4\" class=\"ltx_td ltx_align_center\">33.0</td>\n<td id=\"S4.T1.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S4.T1.1.6.6\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T1.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">70B</td>\n<td id=\"S4.T1.1.7.2\" class=\"ltx_td ltx_align_center\">36.6</td>\n<td id=\"S4.T1.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">28.7</td>\n<td id=\"S4.T1.1.7.4\" class=\"ltx_td ltx_align_center\">46.3</td>\n<td id=\"S4.T1.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_r\">35.1</td>\n<td id=\"S4.T1.1.7.6\" class=\"ltx_td ltx_align_center\">7.8</td>\n</tr>\n<tr id=\"S4.T1.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.8.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"3\"><span id=\"S4.T1.1.8.1.1\" class=\"ltx_text\">CodeLLaMA-Instruct</span></td>\n<td id=\"S4.T1.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7B</td>\n<td id=\"S4.T1.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">37.8</td>\n<td id=\"S4.T1.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">35.4</td>\n<td id=\"S4.T1.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\">59.5</td>\n<td id=\"S4.T1.1.8.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">46.8</td>\n<td id=\"S4.T1.1.8.7\" class=\"ltx_td ltx_align_center ltx_border_t\">14.2</td>\n</tr>\n<tr id=\"S4.T1.1.9\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">13B</td>\n<td id=\"S4.T1.1.9.2\" class=\"ltx_td ltx_align_center\">42.7</td>\n<td id=\"S4.T1.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\">38.4</td>\n<td id=\"S4.T1.1.9.4\" class=\"ltx_td ltx_align_center\">63.5</td>\n<td id=\"S4.T1.1.9.5\" class=\"ltx_td ltx_align_center ltx_border_r\">52.6</td>\n<td id=\"S4.T1.1.9.6\" class=\"ltx_td ltx_align_center\">19.0</td>\n</tr>\n<tr id=\"S4.T1.1.10\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_r\">34B</td>\n<td id=\"S4.T1.1.10.2\" class=\"ltx_td ltx_align_center\">51.8</td>\n<td id=\"S4.T1.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">43.9</td>\n<td id=\"S4.T1.1.10.4\" class=\"ltx_td ltx_align_center\">69.3</td>\n<td id=\"S4.T1.1.10.5\" class=\"ltx_td ltx_align_center ltx_border_r\">56.3</td>\n<td id=\"S4.T1.1.10.6\" class=\"ltx_td ltx_align_center\">22.6</td>\n</tr>\n<tr id=\"S4.T1.1.11\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.11.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" rowspan=\"2\"><span id=\"S4.T1.1.11.1.1\" class=\"ltx_text\">LLaMA3-Instruct</span></td>\n<td id=\"S4.T1.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">8B</td>\n<td id=\"S4.T1.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_t\">61.6</td>\n<td id=\"S4.T1.1.11.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">56.7</td>\n<td id=\"S4.T1.1.11.5\" class=\"ltx_td ltx_align_center ltx_border_t\">70.1</td>\n<td id=\"S4.T1.1.11.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">59.3</td>\n<td id=\"S4.T1.1.11.7\" class=\"ltx_td ltx_align_center ltx_border_t\">10.4</td>\n</tr>\n<tr id=\"S4.T1.1.12\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.12.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">70B</td>\n<td id=\"S4.T1.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">77.4</td>\n<td id=\"S4.T1.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">72.0</td>\n<td id=\"S4.T1.1.12.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">82.3</td>\n<td id=\"S4.T1.1.12.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">69</td>\n<td id=\"S4.T1.1.12.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">22.6</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "As shown in Table\u00a01, we report the zero-shot Case2Code\u00a0performance of different representative LLMs and their programming performance. We can find that the zero-shot Case2Code\u00a0performance of representative models is strongly related to their corresponding program synthesis performance. Models with higher program synthesis scores tend to achieve higher Case2Code\u00a0performance. And larger models often outperform small models. This indicates that Case2Code\u00a0can become a good benchmark to reflect the code reasoning performance of different LLMs. However, the zero-shot Case2Code\u00a0scores of LLMs have a large gap compared with their coding accuracy, which demonstrates that existing LLMs are better at some types of reasoning (e.g. writing programs based on instructions) than others (e.g. inductive programs by their behaviors). This can be explained as the LLMs are trained with massive program generation data but fewer samples similar to Case2Code\u00a0that need inductive reasoning. Similar to the Reverse Curse\u00a0Berglund et\u00a0al. (2023), models trained with deductive reasoning data struggle to transfer to inductive reasoning tasks.",
            "First, we find that LLMs that are directly trained on the Case2Code\u00a0reasoning samples can effectively learn coding based on cases. As shown in Table\u00a02, by direct fine-tuning, Internlm2-7B and LLaMA3-8B can significantly outperform the few-shot prompting baselines by up to 18.9%, achieve up to 44.5% and 42.0% accuracy on Case2Code\u00a0evaluation set, respectively, which even outperforms the more powerful LLMs like LLaMA3-70B, GPT-3.5, and comparable with GPT-4 (results in Table\u00a01). Moreover, models trained with Case2Code\u00a0reasoning also improve their program synthesis performance on benchmarks like HumanEval and MBPP. This indicates that the Case2Code\u00a0reasoning is general and challenging. Training on Case2Code\u00a0samples not only boosts the inductive reasoning performance in distribution but enhances the code understanding and code generation abilities of LLMs. As the Case2Code\u00a0samples can be synthetic at scale, we believe that synthesizing large-scale and high-quality inductive reasoning data is a promising path to consistently improve LLMs without exhausting data."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Results of models trained with Case2Code\u00a0synthetic dataset and the corresponding generalization performance. Case2Code\u00a0performance are evaluated with zero-shot prompting, except results with \u2020, which are evaluated with four-shot prompting.",
        "table": "<table id=\"S4.T2.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T2.3.3.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.4.1\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S4.T2.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T2.3.3.4.2.1\" class=\"ltx_text\">\n<span id=\"S4.T2.3.3.4.2.1.1\" class=\"ltx_inline-block ltx_parbox ltx_align_middle\" style=\"width:42.7pt;\">\n<span id=\"S4.T2.3.3.4.2.1.1.1\" class=\"ltx_p\"><span id=\"S4.T2.3.3.4.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Train w/ \n<br class=\"ltx_break\">Ours</span></span>\n</span></span></td>\n<td id=\"S4.T2.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T2.3.3.4.3.1\" class=\"ltx_text ltx_font_bold\">HumanEval</span></td>\n<td id=\"S4.T2.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T2.3.3.4.4.1\" class=\"ltx_text\"><span id=\"S4.T2.3.3.4.4.1.1\" class=\"ltx_text ltx_font_bold\">HumanEval</span>+</span></td>\n<td id=\"S4.T2.3.3.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T2.3.3.4.5.1\" class=\"ltx_text ltx_font_bold\">MBPP</span></td>\n<td id=\"S4.T2.3.3.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T2.3.3.4.6.1\" class=\"ltx_text\"><span id=\"S4.T2.3.3.4.6.1.1\" class=\"ltx_text ltx_font_bold\">MBPP</span>+</span></td>\n<td id=\"S4.T2.3.3.4.7\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T2.3.3.4.7.1\" class=\"ltx_text ltx_font_bold\">Case2Code</span></td>\n</tr>\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">InternLM2-7B-Base</td>\n<td id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#10007;</td>\n<td id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">31.1</td>\n<td id=\"S4.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">21.3</td>\n<td id=\"S4.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">51.4</td>\n<td id=\"S4.T2.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">40.3</td>\n<td id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">27.2<sup id=\"S4.T2.1.1.1.1.1\" class=\"ltx_sup\"><span id=\"S4.T2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">&#8224;</span></sup>\n</td>\n</tr>\n<tr id=\"S4.T2.3.3.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.5.1\" class=\"ltx_td ltx_align_left\">w/ Direct Fine-tuning</td>\n<td id=\"S4.T2.3.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>\n<td id=\"S4.T2.3.3.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.3.5.3.1\" class=\"ltx_text ltx_font_bold\">44.5</span></td>\n<td id=\"S4.T2.3.3.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">34.8</td>\n<td id=\"S4.T2.3.3.5.5\" class=\"ltx_td ltx_align_center\">56.0</td>\n<td id=\"S4.T2.3.3.5.6\" class=\"ltx_td ltx_align_center ltx_border_r\">40.4</td>\n<td id=\"S4.T2.3.3.5.7\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.3.5.7.1\" class=\"ltx_text ltx_font_bold\">44.4</span></td>\n</tr>\n<tr id=\"S4.T2.3.3.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.6.1\" class=\"ltx_td ltx_align_left\">w/ Mixed Pre-training</td>\n<td id=\"S4.T2.3.3.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>\n<td id=\"S4.T2.3.3.6.3\" class=\"ltx_td ltx_align_center\">43.9</td>\n<td id=\"S4.T2.3.3.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.3.3.6.4.1\" class=\"ltx_text ltx_font_bold\">40.9</span></td>\n<td id=\"S4.T2.3.3.6.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.3.6.5.1\" class=\"ltx_text ltx_font_bold\">58.4</span></td>\n<td id=\"S4.T2.3.3.6.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.3.3.6.6.1\" class=\"ltx_text ltx_font_bold\">42.6</span></td>\n<td id=\"S4.T2.3.3.6.7\" class=\"ltx_td ltx_align_center\">41.4</td>\n</tr>\n<tr id=\"S4.T2.2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">InternLM2-7B</td>\n<td id=\"S4.T2.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#10007;</td>\n<td id=\"S4.T2.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">39.0</td>\n<td id=\"S4.T2.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.4</td>\n<td id=\"S4.T2.2.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">56.8</td>\n<td id=\"S4.T2.2.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.2.2.2.7.1\" class=\"ltx_text ltx_font_bold\">54.1</span></td>\n<td id=\"S4.T2.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">25.6<sup id=\"S4.T2.2.2.2.1.1\" class=\"ltx_sup\"><span id=\"S4.T2.2.2.2.1.1.1\" class=\"ltx_text ltx_font_italic\">&#8224;</span></sup>\n</td>\n</tr>\n<tr id=\"S4.T2.3.3.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.7.1\" class=\"ltx_td ltx_align_left\">w/ Direct Fine-tuning</td>\n<td id=\"S4.T2.3.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>\n<td id=\"S4.T2.3.3.7.3\" class=\"ltx_td ltx_align_center\">43.3</td>\n<td id=\"S4.T2.3.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_r\">40.9</td>\n<td id=\"S4.T2.3.3.7.5\" class=\"ltx_td ltx_align_center\">54.5</td>\n<td id=\"S4.T2.3.3.7.6\" class=\"ltx_td ltx_align_center ltx_border_r\">40.6</td>\n<td id=\"S4.T2.3.3.7.7\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.3.7.7.1\" class=\"ltx_text ltx_font_bold\">44.5</span></td>\n</tr>\n<tr id=\"S4.T2.3.3.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.8.1\" class=\"ltx_td ltx_align_left\">w/ Mixed Pre-training</td>\n<td id=\"S4.T2.3.3.8.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>\n<td id=\"S4.T2.3.3.8.3\" class=\"ltx_td ltx_align_center\">47.6</td>\n<td id=\"S4.T2.3.3.8.4\" class=\"ltx_td ltx_align_center ltx_border_r\">37.2</td>\n<td id=\"S4.T2.3.3.8.5\" class=\"ltx_td ltx_align_center\">58.4</td>\n<td id=\"S4.T2.3.3.8.6\" class=\"ltx_td ltx_align_center ltx_border_r\">45.6</td>\n<td id=\"S4.T2.3.3.8.7\" class=\"ltx_td ltx_align_center\">42.4</td>\n</tr>\n<tr id=\"S4.T2.3.3.9\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.9.1\" class=\"ltx_td ltx_align_left\">w/ Insturction-tuning</td>\n<td id=\"S4.T2.3.3.9.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10007;</td>\n<td id=\"S4.T2.3.3.9.3\" class=\"ltx_td ltx_align_center\">49.4</td>\n<td id=\"S4.T2.3.3.9.4\" class=\"ltx_td ltx_align_center ltx_border_r\">43.9</td>\n<td id=\"S4.T2.3.3.9.5\" class=\"ltx_td ltx_align_center\">58.0</td>\n<td id=\"S4.T2.3.3.9.6\" class=\"ltx_td ltx_align_center ltx_border_r\">50.4</td>\n<td id=\"S4.T2.3.3.9.7\" class=\"ltx_td ltx_align_center\">6.2</td>\n</tr>\n<tr id=\"S4.T2.3.3.10\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.10.1\" class=\"ltx_td ltx_align_left\">w/ Mixed Instruction-tuning</td>\n<td id=\"S4.T2.3.3.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>\n<td id=\"S4.T2.3.3.10.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.3.10.3.1\" class=\"ltx_text ltx_font_bold\">64.6</span></td>\n<td id=\"S4.T2.3.3.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.3.3.10.4.1\" class=\"ltx_text ltx_font_bold\">56.7</span></td>\n<td id=\"S4.T2.3.3.10.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.3.10.5.1\" class=\"ltx_text ltx_font_bold\">63.4</span></td>\n<td id=\"S4.T2.3.3.10.6\" class=\"ltx_td ltx_align_center ltx_border_r\">52.4</td>\n<td id=\"S4.T2.3.3.10.7\" class=\"ltx_td ltx_align_center\">44.0</td>\n</tr>\n<tr id=\"S4.T2.3.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">LLaMA3-8B</td>\n<td id=\"S4.T2.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#10007;</td>\n<td id=\"S4.T2.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">35.4</td>\n<td id=\"S4.T2.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">20.1</td>\n<td id=\"S4.T2.3.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">59.1</td>\n<td id=\"S4.T2.3.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">45.1</td>\n<td id=\"S4.T2.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">29.2<sup id=\"S4.T2.3.3.3.1.1\" class=\"ltx_sup\"><span id=\"S4.T2.3.3.3.1.1.1\" class=\"ltx_text ltx_font_italic\">&#8224;</span></sup>\n</td>\n</tr>\n<tr id=\"S4.T2.3.3.11\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.11.1\" class=\"ltx_td ltx_align_left\">w/ Direct Fine-tuning</td>\n<td id=\"S4.T2.3.3.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>\n<td id=\"S4.T2.3.3.11.3\" class=\"ltx_td ltx_align_center\">43.2</td>\n<td id=\"S4.T2.3.3.11.4\" class=\"ltx_td ltx_align_center ltx_border_r\">39.0</td>\n<td id=\"S4.T2.3.3.11.5\" class=\"ltx_td ltx_align_center\">50.6</td>\n<td id=\"S4.T2.3.3.11.6\" class=\"ltx_td ltx_align_center ltx_border_r\">35.1</td>\n<td id=\"S4.T2.3.3.11.7\" class=\"ltx_td ltx_align_center\">44.8</td>\n</tr>\n<tr id=\"S4.T2.3.3.12\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.12.1\" class=\"ltx_td ltx_align_left\">w/ Mixed Pre-training</td>\n<td id=\"S4.T2.3.3.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>\n<td id=\"S4.T2.3.3.12.3\" class=\"ltx_td ltx_align_center\">47.6</td>\n<td id=\"S4.T2.3.3.12.4\" class=\"ltx_td ltx_align_center ltx_border_r\">40.9</td>\n<td id=\"S4.T2.3.3.12.5\" class=\"ltx_td ltx_align_center\">55.6</td>\n<td id=\"S4.T2.3.3.12.6\" class=\"ltx_td ltx_align_center ltx_border_r\">41.1</td>\n<td id=\"S4.T2.3.3.12.7\" class=\"ltx_td ltx_align_center\">42.6</td>\n</tr>\n<tr id=\"S4.T2.3.3.13\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.13.1\" class=\"ltx_td ltx_align_left\">w/ Insturction-tuning</td>\n<td id=\"S4.T2.3.3.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10007;</td>\n<td id=\"S4.T2.3.3.13.3\" class=\"ltx_td ltx_align_center\">49.8</td>\n<td id=\"S4.T2.3.3.13.4\" class=\"ltx_td ltx_align_center ltx_border_r\">45.7</td>\n<td id=\"S4.T2.3.3.13.5\" class=\"ltx_td ltx_align_center\">57.6</td>\n<td id=\"S4.T2.3.3.13.6\" class=\"ltx_td ltx_align_center ltx_border_r\">47.9</td>\n<td id=\"S4.T2.3.3.13.7\" class=\"ltx_td ltx_align_center\">8.6</td>\n</tr>\n<tr id=\"S4.T2.3.3.14\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.14.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">w/ Mixed Instruction-tuning</td>\n<td id=\"S4.T2.3.3.14.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">&#10003;</td>\n<td id=\"S4.T2.3.3.14.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.3.3.14.3.1\" class=\"ltx_text ltx_font_bold\">64.8</span></td>\n<td id=\"S4.T2.3.3.14.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.3.3.14.4.1\" class=\"ltx_text ltx_font_bold\">57.9</span></td>\n<td id=\"S4.T2.3.3.14.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.3.3.14.5.1\" class=\"ltx_text ltx_font_bold\">71.2</span></td>\n<td id=\"S4.T2.3.3.14.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.3.3.14.6.1\" class=\"ltx_text ltx_font_bold\">53.1</span></td>\n<td id=\"S4.T2.3.3.14.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.3.3.14.7.1\" class=\"ltx_text ltx_font_bold\">45.0</span></td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "First, we find that LLMs that are directly trained on the Case2Code\u00a0reasoning samples can effectively learn coding based on cases. As shown in Table\u00a02, by direct fine-tuning, Internlm2-7B and LLaMA3-8B can significantly outperform the few-shot prompting baselines by up to 18.9%, achieve up to 44.5% and 42.0% accuracy on Case2Code\u00a0evaluation set, respectively, which even outperforms the more powerful LLMs like LLaMA3-70B, GPT-3.5, and comparable with GPT-4 (results in Table\u00a01). Moreover, models trained with Case2Code\u00a0reasoning also improve their program synthesis performance on benchmarks like HumanEval and MBPP. This indicates that the Case2Code\u00a0reasoning is general and challenging. Training on Case2Code\u00a0samples not only boosts the inductive reasoning performance in distribution but enhances the code understanding and code generation abilities of LLMs. As the Case2Code\u00a0samples can be synthetic at scale, we believe that synthesizing large-scale and high-quality inductive reasoning data is a promising path to consistently improve LLMs without exhausting data.",
            "As shown in Table\u00a02, when incorporated into the pre-training stage, the Case2Code\u00a0training data helps the model to connect the execution states with the function implementation, which further facilitates the program synthesis performance of these LLMs. Compared with directly fine-tuned on Case2Code\u00a0dataset, training these samples with pre-training texts enables the generalization of inductive reasoning of code states learned by the Case2Code\u00a0task.",
            "When trained with instruction-following datasets, the Case2Code\u00a0data also improves the performance of the programming with instruction tasks, as reported in Table\u00a02. We evaluate the SFT models with the zero-shot instructed version of programming synthesis tasks, HumanEval, and MBPP. We find that incorporating Case2Code\u00a0data boosts the performance of various LLMs on code generation tasks. Compared to the corresponding SFT baselines, InternLM2-7B improves on HumanEval from 49.4% to 64.6%, with more than 10% improvements. LLaMA3-8B achieves 64.6%, 57.9%, and 71.2% on HumanEval, HumanEval+, and MBPP, respectively, with significant improvements compared to the SFT version. These results demonstrate the effectiveness of learning on Case2Code\u00a0and the necessity of incorporating inductive reasoning data into LLM training."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Efficiency of using different LLM Writers for Input Generation. \u201cTP\u201d refers to the size of the tensor parallel for inference. \u201cTGS\u201d refers to the inference throughput (tokens/s) of each LLM instance. \u201cCosts\u201d refers to the relative compute costs of different LLM generators. Due to the large TP and low throughput, the large LMs can be more costly than the small LMs when inferencing on the same number of GPUs. In our data synthetic process, using LLaMA3-70B costs about 9\u00d7\\times compute resources compared to small models like InternLM2-7B. Due to the high costs of LLaMA3-70B, we only sub-sample the raw data to run the data synthesis. The total costs are still 4.5\u00d7\\times compared to InternLM2-7B.",
        "table": "<table id=\"S4.T3.2.2\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T3.2.2.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.3.1\" class=\"ltx_td ltx_border_r ltx_border_tt\"></td>\n<td id=\"S4.T3.2.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">TP</td>\n<td id=\"S4.T3.2.2.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">TGS</td>\n<td id=\"S4.T3.2.2.3.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">Costs</td>\n<td id=\"S4.T3.2.2.3.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"># Samples</td>\n</tr>\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">InternLM2-7B</td>\n<td id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"S4.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1600 tokens/s</td>\n<td id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">1<math id=\"S4.T3.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\times\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.1.m1.1a\"><mo id=\"S4.T3.1.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.1.m1.1.1.cmml\">&#215;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.1.m1.1b\"><times id=\"S4.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.1.m1.1c\">\\times</annotation></semantics></math>\n</td>\n<td id=\"S4.T3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">1.3M</td>\n</tr>\n<tr id=\"S4.T3.2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">LLaMA3-70B</td>\n<td id=\"S4.T3.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">4</td>\n<td id=\"S4.T3.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">720 tokens/s</td>\n<td id=\"S4.T3.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">4.5<math id=\"S4.T3.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\times\" display=\"inline\"><semantics id=\"S4.T3.2.2.2.1.m1.1a\"><mo id=\"S4.T3.2.2.2.1.m1.1.1\" xref=\"S4.T3.2.2.2.1.m1.1.1.cmml\">&#215;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.2.1.m1.1b\"><times id=\"S4.T3.2.2.2.1.m1.1.1.cmml\" xref=\"S4.T3.2.2.2.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.2.1.m1.1c\">\\times</annotation></semantics></math>\n</td>\n<td id=\"S4.T3.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">700K</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "During the synthesis of Case2Code\u00a0data, a critical step is prompting the LLM to write several input examples for each program. These inputs are then executed with the corresponding programs one by one to obtain the program outputs, thus we can utilize these important contexts to construct Case2Code\u00a0training data. To explore whether the reasoning ability of the LLM writer affects the synthetic data quality, we replace the LLM generator from Interlm2-7B to LLaMA3-70B, and rerun the data synthesis pipeline to obtain a new version of Case2Code\u00a0training data. Due to the high costs of LLaMA3-70B, we only generate half the size of our original synthetic data. Detailed generation costs are reported in Table\u00a03. We train Interlm2-7B with this version of Case2Code\u00a0dataset under the instruction-tuning setup to evaluate the data quality. As shown in Figure\u00a04, compared with the InternLM2-7B generator, large LMs like LLaMA3-70B can write high-quality input samples that help trained LLMs to achieve comparable code reasoning capability with fewer training data. It indicates that the input generation step can affect the overall synthetic data quality, suggesting data collectors choose a strong LLM to be the input writer if compute resources are sufficient. However, we note that LLaMA3-70B contains too many parameters that are 4.5\u00d74.5\\times more costly than InternLM2-7B. By generating inputs with InternLM2-7B, our Case2Code\u00a0data synthesis framework maintains generation efficiency and data quality. It also demonstrates the possibility of self-improving for LLMs on their code reasoning capabilities."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Code results with different scales of models, after supervised fine-tuning on the instruction-following dataset mixed with Case2Code\u00a0synthetic data.",
        "table": "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T4.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.1.1\" class=\"ltx_td ltx_border_r ltx_border_tt\"></td>\n<td id=\"S4.T4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">HumanEval</td>\n<td id=\"S4.T4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">HumanEval+</td>\n<td id=\"S4.T4.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">MBPP</td>\n<td id=\"S4.T4.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MBPP+</td>\n<td id=\"S4.T4.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">Case2Code</td>\n</tr>\n<tr id=\"S4.T4.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">InternLM2-1.8B</td>\n<td id=\"S4.T4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">32.3</td>\n<td id=\"S4.T4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">29.9</td>\n<td id=\"S4.T4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">43.6</td>\n<td id=\"S4.T4.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">24.3</td>\n<td id=\"S4.T4.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">27.8</td>\n</tr>\n<tr id=\"S4.T4.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\">InternLM2-7B</td>\n<td id=\"S4.T4.1.3.2\" class=\"ltx_td ltx_align_center\">64.6</td>\n<td id=\"S4.T4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">56.7</td>\n<td id=\"S4.T4.1.3.4\" class=\"ltx_td ltx_align_center\">63.4</td>\n<td id=\"S4.T4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">52.4</td>\n<td id=\"S4.T4.1.3.6\" class=\"ltx_td ltx_align_center\">42.2</td>\n</tr>\n<tr id=\"S4.T4.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">InternLM2-20B</td>\n<td id=\"S4.T4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.1.4.2.1\" class=\"ltx_text ltx_font_bold\">73.1</span></td>\n<td id=\"S4.T4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T4.1.4.3.1\" class=\"ltx_text ltx_font_bold\">65.2</span></td>\n<td id=\"S4.T4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.1.4.4.1\" class=\"ltx_text ltx_font_bold\">77.4</span></td>\n<td id=\"S4.T4.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T4.1.4.5.1\" class=\"ltx_text ltx_font_bold\">55.4</span></td>\n<td id=\"S4.T4.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.1.4.6.1\" class=\"ltx_text ltx_font_bold\">46.0</span></td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "We want to explore whether the Case2Code\u00a0data synthesized using a small model can still improve a large model, and how the model scale affects the learning process. Therefore, we use Case2Code\u00a0data generated with InternLM2-7B to train models in the InternLM2 series to investigate these questions. The training is taken under the setting of data mixing with SFT dataset\u00a0Luo et\u00a0al. (2023) and the results are shown in Table\u00a04. Our synthetic data consistently enhances the code reasoning performance of various sizes of LLMs, even though one of the student models is almost three times larger than the model used for data synthesis. These results demonstrate the possibilities of weak-to-strong supervision in code-related tasks at scale."
        ]
    }
}