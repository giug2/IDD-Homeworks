{
    "A1.T11": {
        "caption": "Table 11: Pretrained ResNet18 teacher evaluated on synthetic dataset with different scaling factors s\ud835\udc60s and sampling steps T\ud835\udc47T. When classifier-free guidance is used\u00a0(i.e., s>1\ud835\udc601s>1), these results are significantly higher than the accuracy of 69.75% on the real ImageNet validation set. When s\ud835\udc60s=1, we can observe that the accuracy of the pre-trained teacher is only around 50%. This implies that the teacher is unable to provide accurate soft labels for distillation.",
        "table": "<table id=\"A1.T11.2.2.2\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T11.2.2.2.2\" class=\"ltx_tr\">\n<td id=\"A1.T11.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"A1.T11.1.1.1.1.1.1\" class=\"ltx_text\"><span id=\"A1.T11.1.1.1.1.1.1.2\" class=\"ltx_text\"></span> <span id=\"A1.T11.1.1.1.1.1.1.1\" class=\"ltx_text\">\n<span id=\"A1.T11.1.1.1.1.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"A1.T11.1.1.1.1.1.1.1.1.2\" class=\"ltx_tr\">\n<span id=\"A1.T11.1.1.1.1.1.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Sampling</span></span>\n<span id=\"A1.T11.1.1.1.1.1.1.1.1.1\" class=\"ltx_tr\">\n<span id=\"A1.T11.1.1.1.1.1.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Factor <math id=\"A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"s\" display=\"inline\"><semantics id=\"A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1a\"><mi id=\"A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1.1\" xref=\"A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml\">s</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1b\"><ci id=\"A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1.1\">&#119904;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T11.1.1.1.1.1.1.1.1.1.1.m1.1c\">s</annotation></semantics></math></span></span>\n</span></span> <span id=\"A1.T11.1.1.1.1.1.1.3\" class=\"ltx_text\"></span></span></td>\n<td id=\"A1.T11.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"5\">Sampling Step <math id=\"A1.T11.2.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"T\" display=\"inline\"><semantics id=\"A1.T11.2.2.2.2.2.m1.1a\"><mi id=\"A1.T11.2.2.2.2.2.m1.1.1\" xref=\"A1.T11.2.2.2.2.2.m1.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T11.2.2.2.2.2.m1.1b\"><ci id=\"A1.T11.2.2.2.2.2.m1.1.1.cmml\" xref=\"A1.T11.2.2.2.2.2.m1.1.1\">&#119879;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T11.2.2.2.2.2.m1.1c\">T</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"A1.T11.2.2.2.3\" class=\"ltx_tr\">\n<td id=\"A1.T11.2.2.2.3.1\" class=\"ltx_td ltx_align_center\">50</td>\n<td id=\"A1.T11.2.2.2.3.2\" class=\"ltx_td ltx_align_center\">100</td>\n<td id=\"A1.T11.2.2.2.3.3\" class=\"ltx_td ltx_align_center\">150</td>\n<td id=\"A1.T11.2.2.2.3.4\" class=\"ltx_td ltx_align_center\">200</td>\n<td id=\"A1.T11.2.2.2.3.5\" class=\"ltx_td ltx_align_center\">250</td>\n</tr>\n<tr id=\"A1.T11.2.2.2.4\" class=\"ltx_tr\">\n<td id=\"A1.T11.2.2.2.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td id=\"A1.T11.2.2.2.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">44.68</td>\n<td id=\"A1.T11.2.2.2.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">48.62</td>\n<td id=\"A1.T11.2.2.2.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">50.53</td>\n<td id=\"A1.T11.2.2.2.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">50.40</td>\n<td id=\"A1.T11.2.2.2.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\">50.83</td>\n</tr>\n<tr id=\"A1.T11.2.2.2.5\" class=\"ltx_tr\">\n<td id=\"A1.T11.2.2.2.5.1\" class=\"ltx_td ltx_align_center\">2</td>\n<td id=\"A1.T11.2.2.2.5.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#ECECEC;\"><span id=\"A1.T11.2.2.2.5.2.1\" class=\"ltx_text\" style=\"background-color:#ECECEC;\">80.31</span></td>\n<td id=\"A1.T11.2.2.2.5.3\" class=\"ltx_td ltx_align_center\" style=\"background-color:#ECECEC;\"><span id=\"A1.T11.2.2.2.5.3.1\" class=\"ltx_text\" style=\"background-color:#ECECEC;\">81.45</span></td>\n<td id=\"A1.T11.2.2.2.5.4\" class=\"ltx_td ltx_align_center\" style=\"background-color:#ECECEC;\"><span id=\"A1.T11.2.2.2.5.4.1\" class=\"ltx_text\" style=\"background-color:#ECECEC;\">81.72</span></td>\n<td id=\"A1.T11.2.2.2.5.5\" class=\"ltx_td ltx_align_center\" style=\"background-color:#ECECEC;\"><span id=\"A1.T11.2.2.2.5.5.1\" class=\"ltx_text\" style=\"background-color:#ECECEC;\">82.07</span></td>\n<td id=\"A1.T11.2.2.2.5.6\" class=\"ltx_td ltx_align_center\" style=\"background-color:#ECECEC;\"><span id=\"A1.T11.2.2.2.5.6.1\" class=\"ltx_text\" style=\"background-color:#ECECEC;\">81.90</span></td>\n</tr>\n<tr id=\"A1.T11.2.2.2.6\" class=\"ltx_tr\">\n<td id=\"A1.T11.2.2.2.6.1\" class=\"ltx_td ltx_align_center\">3</td>\n<td id=\"A1.T11.2.2.2.6.2\" class=\"ltx_td ltx_align_center\">87.56</td>\n<td id=\"A1.T11.2.2.2.6.3\" class=\"ltx_td ltx_align_center\">87.73</td>\n<td id=\"A1.T11.2.2.2.6.4\" class=\"ltx_td ltx_align_center\">87.46</td>\n<td id=\"A1.T11.2.2.2.6.5\" class=\"ltx_td ltx_align_center\">87.53</td>\n<td id=\"A1.T11.2.2.2.6.6\" class=\"ltx_td ltx_align_center\">87.53</td>\n</tr>\n<tr id=\"A1.T11.2.2.2.7\" class=\"ltx_tr\">\n<td id=\"A1.T11.2.2.2.7.1\" class=\"ltx_td ltx_align_center ltx_border_b\">4</td>\n<td id=\"A1.T11.2.2.2.7.2\" class=\"ltx_td ltx_align_center ltx_border_b\">88.96</td>\n<td id=\"A1.T11.2.2.2.7.3\" class=\"ltx_td ltx_align_center ltx_border_b\">89.00</td>\n<td id=\"A1.T11.2.2.2.7.4\" class=\"ltx_td ltx_align_center ltx_border_b\">88.72</td>\n<td id=\"A1.T11.2.2.2.7.5\" class=\"ltx_td ltx_align_center ltx_border_b\">88.76</td>\n<td id=\"A1.T11.2.2.2.7.6\" class=\"ltx_td ltx_align_center ltx_border_b\">88.71</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "When using DiT to generate images, due to the classifier-free guidance mechanism, the generated images will have a distinct appearance that aligns with the specific class. This allows the classifier to classify these generated images more easily than real images, resulting in higher class confidence, as shown in Table\u00a011.\nHowever, this high confidence in the synthesized images can also result in a sharp output distribution, making it challenging for knowledge distillation to effectively transfer knowledge of class similarity. A smooth target distribution would be more effective for knowledge transfer."
        ]
    },
    "A1.T12": {
        "caption": "Table 12: The variance\u00a0(10\u22124superscript10410^{-4}) of the probability distribution output by the pretrained teacher model on the synthetic dataset. The sampling step is fixed to 100. Smaller variances represent smoother probability distributions.",
        "table": "<table id=\"A1.T12.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A1.T12.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T12.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Variance&#160;(<math id=\"A1.T12.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"10^{-4}\" display=\"inline\"><semantics id=\"A1.T12.1.1.1.1.1.m1.1a\"><msup id=\"A1.T12.1.1.1.1.1.m1.1.1\" xref=\"A1.T12.1.1.1.1.1.m1.1.1.cmml\"><mn id=\"A1.T12.1.1.1.1.1.m1.1.1.2\" xref=\"A1.T12.1.1.1.1.1.m1.1.1.2.cmml\">10</mn><mrow id=\"A1.T12.1.1.1.1.1.m1.1.1.3\" xref=\"A1.T12.1.1.1.1.1.m1.1.1.3.cmml\"><mo id=\"A1.T12.1.1.1.1.1.m1.1.1.3a\" xref=\"A1.T12.1.1.1.1.1.m1.1.1.3.cmml\">&#8722;</mo><mn id=\"A1.T12.1.1.1.1.1.m1.1.1.3.2\" xref=\"A1.T12.1.1.1.1.1.m1.1.1.3.2.cmml\">4</mn></mrow></msup><annotation-xml encoding=\"MathML-Content\" id=\"A1.T12.1.1.1.1.1.m1.1b\"><apply id=\"A1.T12.1.1.1.1.1.m1.1.1.cmml\" xref=\"A1.T12.1.1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A1.T12.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"A1.T12.1.1.1.1.1.m1.1.1\">superscript</csymbol><cn type=\"integer\" id=\"A1.T12.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"A1.T12.1.1.1.1.1.m1.1.1.2\">10</cn><apply id=\"A1.T12.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"A1.T12.1.1.1.1.1.m1.1.1.3\"><minus id=\"A1.T12.1.1.1.1.1.m1.1.1.3.1.cmml\" xref=\"A1.T12.1.1.1.1.1.m1.1.1.3\"></minus><cn type=\"integer\" id=\"A1.T12.1.1.1.1.1.m1.1.1.3.2.cmml\" xref=\"A1.T12.1.1.1.1.1.m1.1.1.3.2\">4</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T12.1.1.1.1.1.m1.1c\">10^{-4}</annotation></semantics></math>)</td>\n<td id=\"A1.T12.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">s=2</td>\n<td id=\"A1.T12.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">s=3</td>\n<td id=\"A1.T12.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">s=4</td>\n</tr>\n<tr id=\"A1.T12.1.1.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T12.1.1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">ResNet18</td>\n<td id=\"A1.T12.1.1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#ECECEC;\"><span id=\"A1.T12.1.1.1.2.2.1\" class=\"ltx_text\" style=\"background-color:#ECECEC;\">6.80</span></td>\n<td id=\"A1.T12.1.1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">7.57</td>\n<td id=\"A1.T12.1.1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">7.72</td>\n</tr>\n<tr id=\"A1.T12.1.1.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T12.1.1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_b\">ResNet34</td>\n<td id=\"A1.T12.1.1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"background-color:#ECECEC;\"><span id=\"A1.T12.1.1.1.3.2.1\" class=\"ltx_text\" style=\"background-color:#ECECEC;\">7.25</span></td>\n<td id=\"A1.T12.1.1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_b\">7.95</td>\n<td id=\"A1.T12.1.1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_b\">8.10</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "Both our second and third findings in Section\u00a01 are attempts to reduce the sharpness of the distribution and create a smooth learning target for distillation.\n(1) The goal of creating low-fidelity samples is to increase the classification difficulty of the classifier and decrease its tendency to become overconfident in predicting a certain class.\nAs shown in Table\u00a012, by gradually reducing the scaling factor s\ud835\udc60s, the variance is gradually reduced, which means that the distribution generated by the teacher becomes smoother. The best performance is achieved when we set s\ud835\udc60s=2, which corresponds to the lowest scaling factor in the table.\n(2) Weak classifiers are less discriminative compared to strong classifiers and tend to produce smoother outputs. In Table\u00a012, we compare the output variance of pretrained ResNet18 and ResNet34 teachers on the synthetic dataset. Our results indicate that for different scaling factors s\ud835\udc60s, ResNet18 consistently achieves a lower variance than ResNet34. This shows that ResNet18 can produce smoother output for distillation."
        ]
    },
    "S3.T1": {
        "caption": "Table 1: Comparison of three state-of-the-art diffusion models on ImageNet-1K using their default hyper-parameters to generate synthetic images. \"#Syn Images\" represents the total number of synthetic images. We use the pre-trained ResNet18 as the teacher to train the vanilla ResNet18 student model.",
        "table": "<table id=\"S3.T1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Method</td>\n<td id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">#Syn Images</td>\n<td id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Epoch</td>\n<td id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Acc&#160;(%)</td>\n</tr>\n<tr id=\"S3.T1.1.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">GLIDE&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib40\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">nichol2021glide</span> </a></cite>\n</td>\n<td id=\"S3.T1.1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">200K</td>\n<td id=\"S3.T1.1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">100</td>\n<td id=\"S3.T1.1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">44.58</td>\n</tr>\n<tr id=\"S3.T1.1.1.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.3.1\" class=\"ltx_td ltx_align_left\">SD&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib50\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">rombach2022high</span> </a></cite>\n</td>\n<td id=\"S3.T1.1.1.3.2\" class=\"ltx_td ltx_align_center\">200K</td>\n<td id=\"S3.T1.1.1.3.3\" class=\"ltx_td ltx_align_center\">100</td>\n<td id=\"S3.T1.1.1.3.4\" class=\"ltx_td ltx_align_center\">39.95</td>\n</tr>\n<tr id=\"S3.T1.1.1.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_b\">DiT&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib46\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">peebles2022scalable</span> </a></cite>\n</td>\n<td id=\"S3.T1.1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_b\">200K</td>\n<td id=\"S3.T1.1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_b\">100</td>\n<td id=\"S3.T1.1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_b\">54.64</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "where \u03f5\u03b8\u200b(xt|c)subscriptitalic-\u03f5\ud835\udf03conditionalsubscript\ud835\udc65\ud835\udc61\ud835\udc50\\epsilon_{\\theta}(x_{t}|c) is the sampled noise predicted at timestep t\ud835\udc61t with condition c\ud835\udc50c, and \u03f5\u03b8\u200b(xt|\u2205)subscriptitalic-\u03f5\ud835\udf03conditionalsubscript\ud835\udc65\ud835\udc61\\epsilon_{\\theta}(x_{t}|\\emptyset) is the unconditional predicted noise.\nHere, the hyperparameter s\u22651\ud835\udc601s\\geq 1 is used to adjust the scale of the guidance, with s\ud835\udc60s=1 indicating that no classifier-free guidance is employed. Additionally, \u2205\\emptyset represents a trainable \"null\" condition.\nBased on the performance comparison between DiT, Glide, and SD in Table\u00a01, we default to use DiT as our synthetic data generator for knowledge distillation in this study. Data generation and student training details are presented in the supplementary material."
        ]
    },
    "S4.T10": {
        "caption": "Table 10: Accuracy comparison of hard and soft labels. Soft labels work better than hard labels and both.",
        "table": "<table id=\"S4.T10.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T10.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T10.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T10.1.1.1.1.1\" class=\"ltx_text\">Hard Label</span></td>\n<td id=\"S4.T10.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T10.1.1.1.2.1\" class=\"ltx_text\">Soft Label</span></td>\n<td id=\"S4.T10.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">T: ResNet18</td>\n<td id=\"S4.T10.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">T: ResNet34</td>\n<td id=\"S4.T10.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">T: VGG16</td>\n</tr>\n<tr id=\"S4.T10.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T10.1.1.2.1\" class=\"ltx_td ltx_align_center\">S: ResNet18</td>\n<td id=\"S4.T10.1.1.2.2\" class=\"ltx_td ltx_align_center\">S: ResNet18</td>\n<td id=\"S4.T10.1.1.2.3\" class=\"ltx_td ltx_align_center\">S: VGG11</td>\n</tr>\n<tr id=\"S4.T10.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T10.1.1.3.1\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S4.T10.1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">&#10003;</td>\n<td id=\"S4.T10.1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T10.1.1.3.3.1\" class=\"ltx_text ltx_font_bold\">57.22</span></td>\n<td id=\"S4.T10.1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T10.1.1.3.4.1\" class=\"ltx_text ltx_font_bold\">54.17</span></td>\n<td id=\"S4.T10.1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T10.1.1.3.5.1\" class=\"ltx_text ltx_font_bold\">51.81</span></td>\n</tr>\n<tr id=\"S4.T10.1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T10.1.1.4.1\" class=\"ltx_td ltx_align_center\">&#10003;</td>\n<td id=\"S4.T10.1.1.4.2\" class=\"ltx_td\"></td>\n<td id=\"S4.T10.1.1.4.3\" class=\"ltx_td ltx_align_center\">42.40</td>\n<td id=\"S4.T10.1.1.4.4\" class=\"ltx_td ltx_align_center\">42.58</td>\n<td id=\"S4.T10.1.1.4.5\" class=\"ltx_td ltx_align_center\">41.10</td>\n</tr>\n<tr id=\"S4.T10.1.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T10.1.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_b\">&#10003;</td>\n<td id=\"S4.T10.1.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_b\">&#10003;</td>\n<td id=\"S4.T10.1.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_b\">56.08</td>\n<td id=\"S4.T10.1.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_b\">53.61</td>\n<td id=\"S4.T10.1.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_b\">50.32</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "Training with hard labels.\nThe DiT model uses class labels as input to generate images, making it possible to use these labels as hard labels to supervise the model\u2019s training. In order to investigate the potential benefits of hard label supervision for synthetic datasets, we conduct experiments as presented in Table\u00a010.\nThe experiments involved training the student model with soft labels only, hard labels only, and a combination of hard and soft labels.\nFor the joint hard label and soft label training, we follow the traditional distillation methods\u00a0hinton2015distilling ; zhang2018deep ; zhao2022decoupled  to weights the two losses at a 1:1 ratio.\nThe results indicate that utilizing hard labels during training actually leads to worse performance compared to using only soft labels. This finding confirms the existence of a domain shift between the synthetic and real datasets, as mentioned in\u00a0he2022synthetic . However, by using the distillation method, the impact of the domain shift is largely reduced."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Student accuracy on CIFAR-100 validation set. ",
        "table": "<table id=\"S4.T2.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text\">Method</span></td>\n<td id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T2.1.1.1.2.1\" class=\"ltx_text\">Syn Method</span></td>\n<td id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">T:ResNet34</td>\n<td id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">T:VGG11</td>\n<td id=\"S4.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">T:WRN40-2</td>\n<td id=\"S4.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">T:WRN40-2</td>\n<td id=\"S4.T2.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">T:WRN40-2</td>\n</tr>\n<tr id=\"S4.T2.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.2.1\" class=\"ltx_td ltx_align_center\">S:ResNet18</td>\n<td id=\"S4.T2.1.1.2.2\" class=\"ltx_td ltx_align_center\">S:ResNet18</td>\n<td id=\"S4.T2.1.1.2.3\" class=\"ltx_td ltx_align_center\">S:WRN16-1</td>\n<td id=\"S4.T2.1.1.2.4\" class=\"ltx_td ltx_align_center\">S:WRN40-1</td>\n<td id=\"S4.T2.1.1.2.5\" class=\"ltx_td ltx_align_center\">S:WRN16-2</td>\n</tr>\n<tr id=\"S4.T2.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Teacher</td>\n<td id=\"S4.T2.1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n<td id=\"S4.T2.1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">78.05</td>\n<td id=\"S4.T2.1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">71.32</td>\n<td id=\"S4.T2.1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">75.83</td>\n<td id=\"S4.T2.1.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">75.83</td>\n<td id=\"S4.T2.1.1.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\">75.83</td>\n</tr>\n<tr id=\"S4.T2.1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.4.1\" class=\"ltx_td ltx_align_center\">Student</td>\n<td id=\"S4.T2.1.1.4.2\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T2.1.1.4.3\" class=\"ltx_td ltx_align_center\">77.10</td>\n<td id=\"S4.T2.1.1.4.4\" class=\"ltx_td ltx_align_center\">77.10</td>\n<td id=\"S4.T2.1.1.4.5\" class=\"ltx_td ltx_align_center\">65.31</td>\n<td id=\"S4.T2.1.1.4.6\" class=\"ltx_td ltx_align_center\">72.19</td>\n<td id=\"S4.T2.1.1.4.7\" class=\"ltx_td ltx_align_center\">73.56</td>\n</tr>\n<tr id=\"S4.T2.1.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.5.1\" class=\"ltx_td ltx_align_center\">KD</td>\n<td id=\"S4.T2.1.1.5.2\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T2.1.1.5.3\" class=\"ltx_td ltx_align_center\">77.87</td>\n<td id=\"S4.T2.1.1.5.4\" class=\"ltx_td ltx_align_center\">75.07</td>\n<td id=\"S4.T2.1.1.5.5\" class=\"ltx_td ltx_align_center\">64.06</td>\n<td id=\"S4.T2.1.1.5.6\" class=\"ltx_td ltx_align_center\">68.58</td>\n<td id=\"S4.T2.1.1.5.7\" class=\"ltx_td ltx_align_center\">70.79</td>\n</tr>\n<tr id=\"S4.T2.1.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_t\">DeepInv&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib63\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">yin2020dreaming</span> </a></cite>\n</td>\n<td id=\"S4.T2.1.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Inversion</td>\n<td id=\"S4.T2.1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">61.32</td>\n<td id=\"S4.T2.1.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\">54.13</td>\n<td id=\"S4.T2.1.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\">53.77</td>\n<td id=\"S4.T2.1.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_t\">61.33</td>\n<td id=\"S4.T2.1.1.6.7\" class=\"ltx_td ltx_align_center ltx_border_t\">61.34</td>\n</tr>\n<tr id=\"S4.T2.1.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.7.1\" class=\"ltx_td ltx_align_center\">DAFL&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib8\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">chen2019data</span> </a></cite>\n</td>\n<td id=\"S4.T2.1.1.7.2\" class=\"ltx_td ltx_align_center\">Inversion</td>\n<td id=\"S4.T2.1.1.7.3\" class=\"ltx_td ltx_align_center\">74.47</td>\n<td id=\"S4.T2.1.1.7.4\" class=\"ltx_td ltx_align_center\">54.16</td>\n<td id=\"S4.T2.1.1.7.5\" class=\"ltx_td ltx_align_center\">20.88</td>\n<td id=\"S4.T2.1.1.7.6\" class=\"ltx_td ltx_align_center\">42.83</td>\n<td id=\"S4.T2.1.1.7.7\" class=\"ltx_td ltx_align_center\">43.70</td>\n</tr>\n<tr id=\"S4.T2.1.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.8.1\" class=\"ltx_td ltx_align_center\">DFQ&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">choi2020data</span> </a></cite>\n</td>\n<td id=\"S4.T2.1.1.8.2\" class=\"ltx_td ltx_align_center\">Inversion</td>\n<td id=\"S4.T2.1.1.8.3\" class=\"ltx_td ltx_align_center\">77.01</td>\n<td id=\"S4.T2.1.1.8.4\" class=\"ltx_td ltx_align_center\">66.21</td>\n<td id=\"S4.T2.1.1.8.5\" class=\"ltx_td ltx_align_center\">51.27</td>\n<td id=\"S4.T2.1.1.8.6\" class=\"ltx_td ltx_align_center\">54.43</td>\n<td id=\"S4.T2.1.1.8.7\" class=\"ltx_td ltx_align_center\">64.79</td>\n</tr>\n<tr id=\"S4.T2.1.1.9\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.9.1\" class=\"ltx_td ltx_align_center\">FastDFKD&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">fang2022up</span> </a></cite>\n</td>\n<td id=\"S4.T2.1.1.9.2\" class=\"ltx_td ltx_align_center\">Inversion</td>\n<td id=\"S4.T2.1.1.9.3\" class=\"ltx_td ltx_align_center\">74.34</td>\n<td id=\"S4.T2.1.1.9.4\" class=\"ltx_td ltx_align_center\">67.44</td>\n<td id=\"S4.T2.1.1.9.5\" class=\"ltx_td ltx_align_center\">54.02</td>\n<td id=\"S4.T2.1.1.9.6\" class=\"ltx_td ltx_align_center\">63.91</td>\n<td id=\"S4.T2.1.1.9.7\" class=\"ltx_td ltx_align_center\">65.12</td>\n</tr>\n<tr id=\"S4.T2.1.1.10\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_t\">One-Image&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">asano2023the</span> </a></cite>\n</td>\n<td id=\"S4.T2.1.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Augmentation</td>\n<td id=\"S4.T2.1.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_t\">74.56</td>\n<td id=\"S4.T2.1.1.10.4\" class=\"ltx_td ltx_align_center ltx_border_t\">68.51</td>\n<td id=\"S4.T2.1.1.10.5\" class=\"ltx_td ltx_align_center ltx_border_t\">34.62</td>\n<td id=\"S4.T2.1.1.10.6\" class=\"ltx_td ltx_align_center ltx_border_t\">52.39</td>\n<td id=\"S4.T2.1.1.10.7\" class=\"ltx_td ltx_align_center ltx_border_t\">54.71</td>\n</tr>\n<tr id=\"S4.T2.1.1.11\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.11.1\" class=\"ltx_td ltx_align_center ltx_border_b\">DM-KD&#160;(Ours)</td>\n<td id=\"S4.T2.1.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_b\">Diffusion</td>\n<td id=\"S4.T2.1.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.1.1.11.3.1\" class=\"ltx_text ltx_font_bold\">76.58</span></td>\n<td id=\"S4.T2.1.1.11.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.1.1.11.4.1\" class=\"ltx_text ltx_font_bold\">70.83</span></td>\n<td id=\"S4.T2.1.1.11.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.1.1.11.5.1\" class=\"ltx_text ltx_font_bold\">56.29</span></td>\n<td id=\"S4.T2.1.1.11.6\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.1.1.11.6.1\" class=\"ltx_text ltx_font_bold\">65.01</span></td>\n<td id=\"S4.T2.1.1.11.7\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.1.1.11.7.1\" class=\"ltx_text ltx_font_bold\">66.89</span></td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "Data-free Distillation.\nExisting data-free distillation methods are all based on the white-box teacher model for distillation. These methods primarily utilize information within the white-box teacher model, such as layer statistics, to generate samples and construct training sets that approximate the original data for distillation.\nPrevious methods have three limitations. Firstly, it requires careful of design of the generative method, which is complex and time-consuming. Secondly, it becomes ineffective when the white-box teacher model is not available and only predictions through APIs are provided. Thirdly, current methods face difficulties in scaling with larger data volumes due to the limited diversity of synthetic data\u00a0luo2020large ; choi2020data ; fang2021contrastive .\nOur method effectively solves the above problems. By adopting the publicly available advanced diffusion model, samples can also be generated when the teacher is a black-box model. At the same time, the large-scale diffusion model can easily generate a large number of diverse high-resolution samples for distillation.\nIn Tables\u00a02 and\u00a03, we compare our method with mainstream data-free methods, and our method shows very competitive performance when trained on the same amount of synthetic data. By simply introducing more synthetic training samples, our method significantly improves the performance of data-free distillation by a large margin, as shown in Table\u00a03.",
            "One Image Distillation.\nOne-Image-Distill\u00a0asano2023the  first performs multiple random crops on a large image\u00a0(i.e., 2560\u00d71920256019202560\\times 1920), and then applies data augmentation techniques to the cropped images to create a synthetic image set. The synthetic dataset contains approximately 50K images for CIFAR-100 and 1.28M images for ImageNet-1K.\nIt\u2019s critical to carefully select the source image for One-Image-Distill since sparse images will perform much worse than dense images as mentioned in the original paper. However, our method doesn\u2019t require such detailed selection operations. We can directly generate images through the diffusion model given the target label space.\nAs shown in Table\u00a02 and Table\u00a03, our method shows better performance for the same or larger data volume.\nNote that the results in Table\u00a02 were not reported in the original paper, so we adopt the \"Animals\" image and reimplement the method based on the official code111https://github.com/yukimasano/single-img-extrapolating.",
            "Extension to other datasets.\nOur synthetic dataset is generated based on the 1K classes of ImageNet-1K. To verify the generalizability of our method, we extended it to other datasets, including CIFAR-100\u00a0krizhevsky2009learning , ImageNet-100\u00a0deng2009imagenet , and Flowers-102\u00a0nilsback2006visual . Specifically, the teacher pre-trains on the specified real dataset and then performs knowledge distillation based on our synthetic dataset. The results are reported in Tables\u00a02 and\u00a04, and the excellent performance on these three datasets indicates our method demonstrates good generalization to other datasets. Notably, it is surprising to find that our method achieved a great distillation performance on the fine-grained Flowers-102 dataset, even though the synthetic dataset categories do not intersect with the Flowers-102 dataset categories.\nThere are two possible reasons for such a good generalization. First, the 1K classes of the synthetic data contain most of the common classes, enabling students to learn robust general features during training. Second, in knowledge distillation, the influence of data domain shift on students can be effectively weakened by the supervision of the pretrained teacher model."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Student accuracy on ImageNet-1K validation set.\n",
        "table": "<table id=\"S4.T3.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T3.1.1.1.1.1\" class=\"ltx_text\">Method</span></td>\n<td id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T3.1.1.1.2.1\" class=\"ltx_text\">Syn Method</span></td>\n<td id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T3.1.1.1.3.1\" class=\"ltx_text\">Data Amount</span></td>\n<td id=\"S4.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T3.1.1.1.4.1\" class=\"ltx_text\">Epoch</span></td>\n<td id=\"S4.T3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">T: ResNet50/18</td>\n<td id=\"S4.T3.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">T: ResNet50/18</td>\n</tr>\n<tr id=\"S4.T3.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.2.1\" class=\"ltx_td ltx_align_center\">S: ResNet50</td>\n<td id=\"S4.T3.1.1.2.2\" class=\"ltx_td ltx_align_center\">S: ResNet18</td>\n</tr>\n<tr id=\"S4.T3.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Places365+KD</td>\n<td id=\"S4.T3.1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n<td id=\"S4.T3.1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1.8M</td>\n<td id=\"S4.T3.1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">200</td>\n<td id=\"S4.T3.1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">55.74</td>\n<td id=\"S4.T3.1.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">45.53</td>\n</tr>\n<tr id=\"S4.T3.1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.4.1\" class=\"ltx_td ltx_align_center\">BigGAN&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">brock2018large</span> </a></cite>\n</td>\n<td id=\"S4.T3.1.1.4.2\" class=\"ltx_td ltx_align_center\">GAN</td>\n<td id=\"S4.T3.1.1.4.3\" class=\"ltx_td ltx_align_center\">215K</td>\n<td id=\"S4.T3.1.1.4.4\" class=\"ltx_td ltx_align_center\">90</td>\n<td id=\"S4.T3.1.1.4.5\" class=\"ltx_td ltx_align_center\">64.00</td>\n<td id=\"S4.T3.1.1.4.6\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T3.1.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.5.1\" class=\"ltx_td ltx_align_center\">DeepInv&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib63\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">yin2020dreaming</span> </a></cite>\n</td>\n<td id=\"S4.T3.1.1.5.2\" class=\"ltx_td ltx_align_center\">Inversion</td>\n<td id=\"S4.T3.1.1.5.3\" class=\"ltx_td ltx_align_center\">140K</td>\n<td id=\"S4.T3.1.1.5.4\" class=\"ltx_td ltx_align_center\">90</td>\n<td id=\"S4.T3.1.1.5.5\" class=\"ltx_td ltx_align_center\">68.00</td>\n<td id=\"S4.T3.1.1.5.6\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T3.1.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.6.1\" class=\"ltx_td ltx_align_center\">FastDFKD&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">fang2022up</span> </a></cite>\n</td>\n<td id=\"S4.T3.1.1.6.2\" class=\"ltx_td ltx_align_center\">Inversion</td>\n<td id=\"S4.T3.1.1.6.3\" class=\"ltx_td ltx_align_center\">140K</td>\n<td id=\"S4.T3.1.1.6.4\" class=\"ltx_td ltx_align_center\">200</td>\n<td id=\"S4.T3.1.1.6.5\" class=\"ltx_td ltx_align_center\">68.61</td>\n<td id=\"S4.T3.1.1.6.6\" class=\"ltx_td ltx_align_center\">53.45</td>\n</tr>\n<tr id=\"S4.T3.1.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_t\">One-Image&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">asano2023the</span> </a></cite>\n</td>\n<td id=\"S4.T3.1.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Augmentation</td>\n<td id=\"S4.T3.1.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1.28M</td>\n<td id=\"S4.T3.1.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">200</td>\n<td id=\"S4.T3.1.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">66.20</td>\n<td id=\"S4.T3.1.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S4.T3.1.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" rowspan=\"3\"><span id=\"S4.T3.1.1.8.1.1\" class=\"ltx_text\">DM-KD&#160;(Ours)</span></td>\n<td id=\"S4.T3.1.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" rowspan=\"3\"><span id=\"S4.T3.1.1.8.2.1\" class=\"ltx_text\">Diffusion</span></td>\n<td id=\"S4.T3.1.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">140K</td>\n<td id=\"S4.T3.1.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">200</td>\n<td id=\"S4.T3.1.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\">66.74</td>\n<td id=\"S4.T3.1.1.8.6\" class=\"ltx_td ltx_align_center ltx_border_t\">60.10</td>\n</tr>\n<tr id=\"S4.T3.1.1.9\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.9.1\" class=\"ltx_td ltx_align_center\">200K</td>\n<td id=\"S4.T3.1.1.9.2\" class=\"ltx_td ltx_align_center\">200</td>\n<td id=\"S4.T3.1.1.9.3\" class=\"ltx_td ltx_align_center\">68.63</td>\n<td id=\"S4.T3.1.1.9.4\" class=\"ltx_td ltx_align_center\">61.61</td>\n</tr>\n<tr id=\"S4.T3.1.1.10\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_b\">1.28M</td>\n<td id=\"S4.T3.1.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_b\">200</td>\n<td id=\"S4.T3.1.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T3.1.1.10.3.1\" class=\"ltx_text ltx_font_bold\">72.43</span></td>\n<td id=\"S4.T3.1.1.10.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T3.1.1.10.4.1\" class=\"ltx_text ltx_font_bold\">68.25</span></td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "Data-free Distillation.\nExisting data-free distillation methods are all based on the white-box teacher model for distillation. These methods primarily utilize information within the white-box teacher model, such as layer statistics, to generate samples and construct training sets that approximate the original data for distillation.\nPrevious methods have three limitations. Firstly, it requires careful of design of the generative method, which is complex and time-consuming. Secondly, it becomes ineffective when the white-box teacher model is not available and only predictions through APIs are provided. Thirdly, current methods face difficulties in scaling with larger data volumes due to the limited diversity of synthetic data\u00a0luo2020large ; choi2020data ; fang2021contrastive .\nOur method effectively solves the above problems. By adopting the publicly available advanced diffusion model, samples can also be generated when the teacher is a black-box model. At the same time, the large-scale diffusion model can easily generate a large number of diverse high-resolution samples for distillation.\nIn Tables\u00a02 and\u00a03, we compare our method with mainstream data-free methods, and our method shows very competitive performance when trained on the same amount of synthetic data. By simply introducing more synthetic training samples, our method significantly improves the performance of data-free distillation by a large margin, as shown in Table\u00a03.",
            "One Image Distillation.\nOne-Image-Distill\u00a0asano2023the  first performs multiple random crops on a large image\u00a0(i.e., 2560\u00d71920256019202560\\times 1920), and then applies data augmentation techniques to the cropped images to create a synthetic image set. The synthetic dataset contains approximately 50K images for CIFAR-100 and 1.28M images for ImageNet-1K.\nIt\u2019s critical to carefully select the source image for One-Image-Distill since sparse images will perform much worse than dense images as mentioned in the original paper. However, our method doesn\u2019t require such detailed selection operations. We can directly generate images through the diffusion model given the target label space.\nAs shown in Table\u00a02 and Table\u00a03, our method shows better performance for the same or larger data volume.\nNote that the results in Table\u00a02 were not reported in the original paper, so we adopt the \"Animals\" image and reimplement the method based on the official code111https://github.com/yukimasano/single-img-extrapolating.",
            "ImageNet-1K. We have two training schedules in this paper. The first is the classic distillation training strategy, which is to train 100 epochs and divide the learning rate by 10 in the 30th, 60th, and 90th epochs. We use this as the default training strategy unless otherwise stated. In Table\u00a03, we adopted the second training strategy, which is the same as that of FastDFKD\u00a0fang2022up . This involves training for 200 epochs, with the learning rate divided by 10 at the 120th, 150th, and 180th epochs.\nSpecifically, we choose the teacher model with the same structure as the student for distillation in Table\u00a03. In the 5th column, we use ResNet50 as the teacher to train the student ResNet50, while in the 6th column, we use ResNet18 as the teacher to train the student ResNet18.\nFor data augmentation, following the setting of One-Image\u00a0asano2023the , we adopt the CutMix method during training."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Student accuracy on ImageNet-100, and Flowers-102 datasets. Our DM-KD demonstrates good generalization to other datasets. Notably, even when there is no intersection of categories between the synthetic dataset and the Flowers-102 dataset, our method still achieves high performance.",
        "table": "<table id=\"S4.T4.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T4.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T4.1.1.1.1.1\" class=\"ltx_text\">Datasets</span></td>\n<td id=\"S4.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Categories</td>\n<td id=\"S4.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Teacher</td>\n<td id=\"S4.T4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">One-Image&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">asano2023the</span> </a></cite>\n</td>\n<td id=\"S4.T4.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Ours</td>\n</tr>\n<tr id=\"S4.T4.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.1.2.1\" class=\"ltx_td ltx_align_center\">(#Classes)</td>\n<td id=\"S4.T4.1.1.2.2\" class=\"ltx_td ltx_align_center\">ResNet18</td>\n<td id=\"S4.T4.1.1.2.3\" class=\"ltx_td ltx_align_center\">ResNet50</td>\n<td id=\"S4.T4.1.1.2.4\" class=\"ltx_td ltx_align_center\">ResNet50</td>\n</tr>\n<tr id=\"S4.T4.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">ImageNet-100&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">deng2009imagenet</span> </a></cite>\n</td>\n<td id=\"S4.T4.1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Objects&#160;(100)</td>\n<td id=\"S4.T4.1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">89.6</td>\n<td id=\"S4.T4.1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">84.4</td>\n<td id=\"S4.T4.1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.1.3.5.1\" class=\"ltx_text ltx_font_bold\">85.9</span></td>\n</tr>\n<tr id=\"S4.T4.1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">Flowers-102&#160;<cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib42\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text\" style=\"font-size:90%;\">nilsback2006visual</span> </a></cite>\n</td>\n<td id=\"S4.T4.1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">Flower types&#160;(102)</td>\n<td id=\"S4.T4.1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">87.9</td>\n<td id=\"S4.T4.1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">81.5</td>\n<td id=\"S4.T4.1.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T4.1.1.4.5.1\" class=\"ltx_text ltx_font_bold\">85.4</span></td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "Extension to other datasets.\nOur synthetic dataset is generated based on the 1K classes of ImageNet-1K. To verify the generalizability of our method, we extended it to other datasets, including CIFAR-100\u00a0krizhevsky2009learning , ImageNet-100\u00a0deng2009imagenet , and Flowers-102\u00a0nilsback2006visual . Specifically, the teacher pre-trains on the specified real dataset and then performs knowledge distillation based on our synthetic dataset. The results are reported in Tables\u00a02 and\u00a04, and the excellent performance on these three datasets indicates our method demonstrates good generalization to other datasets. Notably, it is surprising to find that our method achieved a great distillation performance on the fine-grained Flowers-102 dataset, even though the synthetic dataset categories do not intersect with the Flowers-102 dataset categories.\nThere are two possible reasons for such a good generalization. First, the 1K classes of the synthetic data contain most of the common classes, enabling students to learn robust general features during training. Second, in knowledge distillation, the influence of data domain shift on students can be effectively weakened by the supervision of the pretrained teacher model."
        ]
    },
    "S4.T7": {
        "caption": "Table 7: Distillation performance for different teacher-student pairs under low- and high-fidelity synthetic images. The low-fidelity images are more effective for various teacher-student pairs. ",
        "table": "<table id=\"S4.T7.4.4.4\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T7.4.4.4.5\" class=\"ltx_tr\">\n<td id=\"S4.T7.4.4.4.5.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Teacher</td>\n<td id=\"S4.T7.4.4.4.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">ResNet18</td>\n<td id=\"S4.T7.4.4.4.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">ResNet34</td>\n<td id=\"S4.T7.4.4.4.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">VGG16</td>\n<td id=\"S4.T7.4.4.4.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">ResNet50</td>\n<td id=\"S4.T7.4.4.4.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\">ShuffleV2</td>\n</tr>\n<tr id=\"S4.T7.4.4.4.6\" class=\"ltx_tr\">\n<td id=\"S4.T7.4.4.4.6.1\" class=\"ltx_td ltx_align_center\">Acc.&#160;(%)</td>\n<td id=\"S4.T7.4.4.4.6.2\" class=\"ltx_td ltx_align_center\">69.75</td>\n<td id=\"S4.T7.4.4.4.6.3\" class=\"ltx_td ltx_align_center\">73.31</td>\n<td id=\"S4.T7.4.4.4.6.4\" class=\"ltx_td ltx_align_center\">73.36</td>\n<td id=\"S4.T7.4.4.4.6.5\" class=\"ltx_td ltx_align_center\">76.13</td>\n<td id=\"S4.T7.4.4.4.6.6\" class=\"ltx_td ltx_align_center\">69.36</td>\n</tr>\n<tr id=\"S4.T7.4.4.4.7\" class=\"ltx_tr\">\n<td id=\"S4.T7.4.4.4.7.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Student</td>\n<td id=\"S4.T7.4.4.4.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">ResNet18</td>\n<td id=\"S4.T7.4.4.4.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">ResNet18</td>\n<td id=\"S4.T7.4.4.4.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">VGG11</td>\n<td id=\"S4.T7.4.4.4.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">ResNet34</td>\n<td id=\"S4.T7.4.4.4.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\">ResNet50</td>\n</tr>\n<tr id=\"S4.T7.2.2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T7.2.2.2.2.2\" class=\"ltx_td ltx_align_center\">Low Fidelity&#160;(<math id=\"S4.T7.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"s\" display=\"inline\"><semantics id=\"S4.T7.1.1.1.1.1.m1.1a\"><mi id=\"S4.T7.1.1.1.1.1.m1.1.1\" xref=\"S4.T7.1.1.1.1.1.m1.1.1.cmml\">s</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.1.1.1.1.1.m1.1b\"><ci id=\"S4.T7.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T7.1.1.1.1.1.m1.1.1\">&#119904;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T7.1.1.1.1.1.m1.1c\">s</annotation></semantics></math>=2, <math id=\"S4.T7.2.2.2.2.2.m2.1\" class=\"ltx_Math\" alttext=\"T\" display=\"inline\"><semantics id=\"S4.T7.2.2.2.2.2.m2.1a\"><mi id=\"S4.T7.2.2.2.2.2.m2.1.1\" xref=\"S4.T7.2.2.2.2.2.m2.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.2.2.2.2.2.m2.1b\"><ci id=\"S4.T7.2.2.2.2.2.m2.1.1.cmml\" xref=\"S4.T7.2.2.2.2.2.m2.1.1\">&#119879;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T7.2.2.2.2.2.m2.1c\">T</annotation></semantics></math>=100, reward=-0.292)</td>\n<td id=\"S4.T7.2.2.2.2.3\" class=\"ltx_td ltx_align_center\">57.22</td>\n<td id=\"S4.T7.2.2.2.2.4\" class=\"ltx_td ltx_align_center\">54.17</td>\n<td id=\"S4.T7.2.2.2.2.5\" class=\"ltx_td ltx_align_center\">51.81</td>\n<td id=\"S4.T7.2.2.2.2.6\" class=\"ltx_td ltx_align_center\">57.78</td>\n<td id=\"S4.T7.2.2.2.2.7\" class=\"ltx_td ltx_align_center\">63.66</td>\n</tr>\n<tr id=\"S4.T7.4.4.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T7.4.4.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b\">High Fidelity&#160;(<math id=\"S4.T7.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"s\" display=\"inline\"><semantics id=\"S4.T7.3.3.3.3.1.m1.1a\"><mi id=\"S4.T7.3.3.3.3.1.m1.1.1\" xref=\"S4.T7.3.3.3.3.1.m1.1.1.cmml\">s</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.3.3.3.3.1.m1.1b\"><ci id=\"S4.T7.3.3.3.3.1.m1.1.1.cmml\" xref=\"S4.T7.3.3.3.3.1.m1.1.1\">&#119904;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T7.3.3.3.3.1.m1.1c\">s</annotation></semantics></math>=4, <math id=\"S4.T7.4.4.4.4.2.m2.1\" class=\"ltx_Math\" alttext=\"T\" display=\"inline\"><semantics id=\"S4.T7.4.4.4.4.2.m2.1a\"><mi id=\"S4.T7.4.4.4.4.2.m2.1.1\" xref=\"S4.T7.4.4.4.4.2.m2.1.1.cmml\">T</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T7.4.4.4.4.2.m2.1b\"><ci id=\"S4.T7.4.4.4.4.2.m2.1.1.cmml\" xref=\"S4.T7.4.4.4.4.2.m2.1.1\">&#119879;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T7.4.4.4.4.2.m2.1c\">T</annotation></semantics></math>=250, reward=-0.003)</td>\n<td id=\"S4.T7.4.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b\">56.19</td>\n<td id=\"S4.T7.4.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b\">49.73</td>\n<td id=\"S4.T7.4.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b\">47.51</td>\n<td id=\"S4.T7.4.4.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_b\">52.24</td>\n<td id=\"S4.T7.4.4.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_b\">56.20</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "Results.\nFor image classification tasks, it is commonly believed that classification models will demonstrate better generalization ability on real data when high-fidelity, photo-realistic synthesized images are utilized as the training dataset.\nExisting data-free distillation methods\u00a0chen2019data ; yin2020dreaming  follow a similar idea by synthesizing realistic datasets for distillation.\nHowever, we find that the distillation performance of images synthesized with default parameters is suboptimal.\nTo assess the distillation performance achieved with different synthetic datasets, we report the student accuracy in Table \u00a04.3 and Table\u00a07, which correspond to the datasets in Table\u00a04.3.\nOur study shows that high-fidelity images, as indicated by a high ImageReward\u00a0xu2023imagereward  score, generated with default parameters, exhibit weaker distillation performance than low-fidelity ones. By progressively decreasing the values of both the scaling factor s\ud835\udc60s and sampling step T\ud835\udc47T, a better distillation performance can be achieved. These findings suggest that low-fidelity images are more effective as learning materials for students during the distillation process.\nIn addition, when setting s\ud835\udc60s=1, which means that there is no classifier-free guidance in the image generation process, a significant drop in student performance is observed. This suggests that poor fidelity generated images may hinder the student model\u2019s ability to learn effectively in logit representation.\nOur experiments show that setting s\ud835\udc60s=2 and using a sampling step of 100 can generate images with relatively low fidelity, which results in the best performance for ImageNet-1K knowledge distillation (see in Table\u00a04.3 and Table\u00a07)."
        ]
    },
    "S4.T8": {
        "caption": "Table 8: Knowledge distillation with large teacher-student capacity gaps. A relatively weak teacher with a small teacher-student gap generally leads to better performance.",
        "table": "<table id=\"S4.T8.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T8.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Teacher</td>\n<td id=\"S4.T8.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">SNV2-0.5</td>\n<td id=\"S4.T8.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Res18</td>\n<td id=\"S4.T8.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Res34</td>\n<td id=\"S4.T8.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">SNV2-0.5</td>\n<td id=\"S4.T8.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">Res18</td>\n<td id=\"S4.T8.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Res34</td>\n<td id=\"S4.T8.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">SNV2-0.5</td>\n<td id=\"S4.T8.1.1.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">Res18</td>\n</tr>\n<tr id=\"S4.T8.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.1.2.1\" class=\"ltx_td ltx_align_center\">Acc.&#160;(%)</td>\n<td id=\"S4.T8.1.1.2.2\" class=\"ltx_td ltx_align_center\">60.55</td>\n<td id=\"S4.T8.1.1.2.3\" class=\"ltx_td ltx_align_center\">69.75</td>\n<td id=\"S4.T8.1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">73.31</td>\n<td id=\"S4.T8.1.1.2.5\" class=\"ltx_td ltx_align_center\">60.55</td>\n<td id=\"S4.T8.1.1.2.6\" class=\"ltx_td ltx_align_center\">69.75</td>\n<td id=\"S4.T8.1.1.2.7\" class=\"ltx_td ltx_align_center ltx_border_r\">73.31</td>\n<td id=\"S4.T8.1.1.2.8\" class=\"ltx_td ltx_align_center\">60.55</td>\n<td id=\"S4.T8.1.1.2.9\" class=\"ltx_td ltx_align_center\">69.75</td>\n</tr>\n<tr id=\"S4.T8.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Student</td>\n<td id=\"S4.T8.1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Res18</td>\n<td id=\"S4.T8.1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Res18</td>\n<td id=\"S4.T8.1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Res18</td>\n<td id=\"S4.T8.1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Res34</td>\n<td id=\"S4.T8.1.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">Res34</td>\n<td id=\"S4.T8.1.1.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Res34</td>\n<td id=\"S4.T8.1.1.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">Res50</td>\n<td id=\"S4.T8.1.1.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\">Res50</td>\n</tr>\n<tr id=\"S4.T8.1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_b\">SynKD</td>\n<td id=\"S4.T8.1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_b\">54.03</td>\n<td id=\"S4.T8.1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_b\">57.22</td>\n<td id=\"S4.T8.1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">54.17</td>\n<td id=\"S4.T8.1.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_b\">56.83</td>\n<td id=\"S4.T8.1.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_b\">61.11</td>\n<td id=\"S4.T8.1.1.4.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">60.19</td>\n<td id=\"S4.T8.1.1.4.8\" class=\"ltx_td ltx_align_center ltx_border_b\">58.11</td>\n<td id=\"S4.T8.1.1.4.9\" class=\"ltx_td ltx_align_center ltx_border_b\">62.74</td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "Should teachers be as weak as possible?\nTo answer this question, we conduct a series of experiments using three groups of teacher-student pairs with large capacity gaps, as shown in Table.\u00a08.\nWe choose SNV2-0.5 as the teacher to test the effect that the teacher is obviously weaker than the student.\nOur results show that when the teacher-student gap is large, it does not necessarily lead to better performance. In fact, our experiments suggest that using a relatively weak teacher model may be a better choice for optimizing knowledge transfer."
        ]
    },
    "S4.T9": {
        "caption": "Table 9: Data diversity. Generating more data samples increases the diversity of the synthetic dataset, leading to better distillation performance.",
        "table": "<table id=\"S4.T9.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T9.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">#Syn Images</td>\n<td id=\"S4.T9.1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">50K</td>\n<td id=\"S4.T9.1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">100K</td>\n<td id=\"S4.T9.1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">200K</td>\n<td id=\"S4.T9.1.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">400K</td>\n</tr>\n<tr id=\"S4.T9.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.1.3.1\" class=\"ltx_td ltx_align_center\">Train Epoch</td>\n<td id=\"S4.T9.1.1.3.2\" class=\"ltx_td ltx_align_center\">400</td>\n<td id=\"S4.T9.1.1.3.3\" class=\"ltx_td ltx_align_center\">200</td>\n<td id=\"S4.T9.1.1.3.4\" class=\"ltx_td ltx_align_center\">100</td>\n<td id=\"S4.T9.1.1.3.5\" class=\"ltx_td ltx_align_center\">50</td>\n</tr>\n<tr id=\"S4.T9.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">ResNet18<math id=\"S4.T9.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T9.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T9.1.1.1.1.m1.1.1\" xref=\"S4.T9.1.1.1.1.m1.1.1.cmml\">&#8594;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.1.1.1.1.m1.1b\"><ci id=\"S4.T9.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T9.1.1.1.1.m1.1.1\">&#8594;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.1.1.1.1.m1.1c\">\\rightarrow</annotation></semantics></math>ResNet18</td>\n<td id=\"S4.T9.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">54.84</td>\n<td id=\"S4.T9.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">55.00</td>\n<td id=\"S4.T9.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">57.22</td>\n<td id=\"S4.T9.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T9.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">57.69</span></td>\n</tr>\n</table>\n",
        "footnotes": [],
        "references": [
            "Data diversity.\nIn this experiment, we aim to validate whether generating more samples brings greater diversity to the dataset and thus leads to better distillation performance. To achieve this, we fix the number of total training iterations (i.e., Data Amount\u00d7\\timesTrain Epochs) and scale the training schedule based on the data volume. Our results, presented in Table\u00a09, demonstrate that generating more data increases the diversity in the synthetic dataset, resulting in improved performance."
        ]
    }
}