{
    "S4.T1": {
        "caption": "Table 1: Accuracy comparisons over the GQA dataset. ‘-’ and ’‘††{\\dagger}’ denote the numbers are not available and our implementation, respectively. b​a​l𝑏𝑎𝑙{bal} denotes the model trained on the balanced split.",
        "table": "<table id=\"S4.T1.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T1.2.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.3.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T1.2.3.1.1\" class=\"ltx_text\">Method</span></td>\n<td id=\"S4.T1.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T1.2.3.2.1\" class=\"ltx_text\">Pre-trained</span></td>\n<td id=\"S4.T1.2.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\">Accuracy (%)</td>\n</tr>\n<tr id=\"S4.T1.2.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.4.1\" class=\"ltx_td ltx_align_center\">Test-dev</td>\n<td id=\"S4.T1.2.4.2\" class=\"ltx_td ltx_align_center\">Test-std</td>\n</tr>\n<tr id=\"S4.T1.2.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">MMN [<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib3\" title=\"\" class=\"ltx_ref\">2021</a></cite>]</td>\n<td id=\"S4.T1.2.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T1.2.5.2.1\" class=\"ltx_text\">✗</span></td>\n<td id=\"S4.T1.2.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n<td id=\"S4.T1.2.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">60.83</td>\n</tr>\n<tr id=\"S4.T1.2.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.6.1\" class=\"ltx_td ltx_align_left\">NSM [<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">2019b</a></cite>]</td>\n<td id=\"S4.T1.2.6.2\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T1.2.6.3\" class=\"ltx_td ltx_align_center\">63.17</td>\n</tr>\n<tr id=\"S4.T1.2.7\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">LXMERT [<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib21\" title=\"\" class=\"ltx_ref\">2019</a></cite>]</td>\n<td id=\"S4.T1.2.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"7\"><span id=\"S4.T1.2.7.2.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S4.T1.2.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">60.00</td>\n<td id=\"S4.T1.2.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">60.33</td>\n</tr>\n<tr id=\"S4.T1.2.8\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.8.1\" class=\"ltx_td ltx_align_left\">VILLA [<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">2020</a></cite>]</td>\n<td id=\"S4.T1.2.8.2\" class=\"ltx_td ltx_align_center\">60.98</td>\n<td id=\"S4.T1.2.8.3\" class=\"ltx_td ltx_align_center\">61.12</td>\n</tr>\n<tr id=\"S4.T1.2.9\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.9.1\" class=\"ltx_td ltx_align_left\">OSCAR [<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2020</a></cite>]</td>\n<td id=\"S4.T1.2.9.2\" class=\"ltx_td ltx_align_center\">61.58</td>\n<td id=\"S4.T1.2.9.3\" class=\"ltx_td ltx_align_center\">61.62</td>\n</tr>\n<tr id=\"S4.T1.2.10\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.10.1\" class=\"ltx_td ltx_align_left\">VL-T5 [<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">2021</a></cite>]</td>\n<td id=\"S4.T1.2.10.2\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T1.2.10.3\" class=\"ltx_td ltx_align_center\">60.80</td>\n</tr>\n<tr id=\"S4.T1.2.11\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.11.1\" class=\"ltx_td ltx_align_left\">MDETR [<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">2021</a></cite>]</td>\n<td id=\"S4.T1.2.11.2\" class=\"ltx_td ltx_align_center\">62.95</td>\n<td id=\"S4.T1.2.11.3\" class=\"ltx_td ltx_align_center\">62.45</td>\n</tr>\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_left\">VinVL<math id=\"S4.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"{}_{bal}^{{\\dagger}}\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mmultiscripts id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T1.1.1.1.m1.1.1.2.2\" xref=\"S4.T1.1.1.1.m1.1.1.2.2.cmml\"></mi><mprescripts id=\"S4.T1.1.1.1.m1.1.1a\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\"></mprescripts><mrow id=\"S4.T1.1.1.1.m1.1.1b\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\"></mrow><mo id=\"S4.T1.1.1.1.m1.1.1.3\" xref=\"S4.T1.1.1.1.m1.1.1.3.cmml\">†</mo><mrow id=\"S4.T1.1.1.1.m1.1.1.2.3\" xref=\"S4.T1.1.1.1.m1.1.1.2.3.cmml\"><mi id=\"S4.T1.1.1.1.m1.1.1.2.3.2\" xref=\"S4.T1.1.1.1.m1.1.1.2.3.2.cmml\">b</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T1.1.1.1.m1.1.1.2.3.1\" xref=\"S4.T1.1.1.1.m1.1.1.2.3.1.cmml\">​</mo><mi id=\"S4.T1.1.1.1.m1.1.1.2.3.3\" xref=\"S4.T1.1.1.1.m1.1.1.2.3.3.cmml\">a</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T1.1.1.1.m1.1.1.2.3.1a\" xref=\"S4.T1.1.1.1.m1.1.1.2.3.1.cmml\">​</mo><mi id=\"S4.T1.1.1.1.m1.1.1.2.3.4\" xref=\"S4.T1.1.1.1.m1.1.1.2.3.4.cmml\">l</mi></mrow><mrow id=\"S4.T1.1.1.1.m1.1.1c\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\"></mrow></mmultiscripts><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><apply id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">superscript</csymbol><apply id=\"S4.T1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T1.1.1.1.m1.1.1.2.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">subscript</csymbol><csymbol cd=\"latexml\" id=\"S4.T1.1.1.1.m1.1.1.2.2.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.2.2\">absent</csymbol><apply id=\"S4.T1.1.1.1.m1.1.1.2.3.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.2.3\"><times id=\"S4.T1.1.1.1.m1.1.1.2.3.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.2.3.1\"></times><ci id=\"S4.T1.1.1.1.m1.1.1.2.3.2.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.2.3.2\">𝑏</ci><ci id=\"S4.T1.1.1.1.m1.1.1.2.3.3.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.2.3.3\">𝑎</ci><ci id=\"S4.T1.1.1.1.m1.1.1.2.3.4.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.2.3.4\">𝑙</ci></apply></apply><ci id=\"S4.T1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T1.1.1.1.m1.1.1.3\">†</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">{}_{bal}^{{\\dagger}}</annotation></semantics></math> [<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">2021</a></cite>]</td>\n<td id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_center\">60.76</td>\n<td id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_center\">60.89</td>\n</tr>\n<tr id=\"S4.T1.2.12\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.12.1\" class=\"ltx_td ltx_align_left\">VinVL [<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">2021</a></cite>]</td>\n<td id=\"S4.T1.2.12.2\" class=\"ltx_td ltx_align_center\">65.05</td>\n<td id=\"S4.T1.2.12.3\" class=\"ltx_td ltx_align_center\">64.65</td>\n</tr>\n<tr id=\"S4.T1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">DPT<sub id=\"S4.T1.2.2.1.1\" class=\"ltx_sub\"><span id=\"S4.T1.2.2.1.1.1\" class=\"ltx_text ltx_font_italic\">bal</span></sub>\n</td>\n<td id=\"S4.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"2\"><span id=\"S4.T1.2.2.2.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S4.T1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">63.55</td>\n<td id=\"S4.T1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">63.57</td>\n</tr>\n<tr id=\"S4.T1.2.13\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.13.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">DPT</td>\n<td id=\"S4.T1.2.13.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.2.13.2.1\" class=\"ltx_text ltx_font_bold\">65.20</span></td>\n<td id=\"S4.T1.2.13.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.2.13.3.1\" class=\"ltx_text ltx_font_bold\">64.92</span></td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "For online evaluation of GQA dataset, we compare our method with the state-of-the-art models, including non-pretrained models i.e., MMN Chen et al. (2021), NSM Hudson and\nManning (2019b), and pre-trained VL models i.e., LXMERT Tan and Bansal (2019), VILLA Gan et al. (2020), OSCAR Li et al. (2020), VinVL Zhang et al. (2021), MDETR Kamath et al. (2021), VL-T5 Cho et al. (2021). The results are reported in Table 1. When only exploiting balanced split for training, our method achieves 63.55% and 63.57% overall accuracy on test-dev and test-std, respectively, outperforming the state-of-the-art non-pretrained/pre-trained models. Specifically, our method (DPTbal) surpasses the fine-tuned counterpart (VinVLbal) by a significant margin of 2.68% on test-std. When using all split to bootstrap our model similar to Chen et al. (2021); Zhang et al. (2021), our method (DPT) still ranks the top regarding overall accuracy, and outperforms the counterpart (VinVL) by 0.27% on test-std. Among the compared models, MMN and NSM also achieve competitive results even if no pre-training is performed, which is thanks to the usage of deliberately generated scene graphs or supervision of execution programs.",
            "To perform predictions on the test split of GQA or VQA v2.0 datasets, the fine-tuned T5 model is exploited to convert questions into declarative sentences. In Table 10, we visualize several declarative sentences from GQA dataset, which are generated by the fine-tuned T5 model. It can be observed that [MASK] token is placed at the proper position that can prompt the model to predict the answer. However, we find that some generated sentences may not contain complete semantic information of the question. For example, the sample-3 refers to vehicle in front of the flag, while only vehicle is generated in the declarative sentence. This may cause ambiguity in visual reasoning. Therefore, we preserve the original question in the textual input of VL models, maximally reserving the semantics of questions.",
            "Table 11 shows several declarative sentences generated from VQA v2.0 dataset. Since the questions in VQA v2.0 are raised manually, there exists various question types, which requires broader capabilities beyond the image understanding. As Table 11 shows, T5 model is able to generalize to VQA v2.0 dataset, and generate appropriate declarative sentences for most cases. For example, the question pattern in sample-1 (i.e., what … say?) has not appeared in GQA dataset, but the T5 model still produces the proper declarative sentence. However, there also exist several question types that are difficult to convert, e.g., why, how, etc. For example, the sample-2 asks the reason about the sailboats have their sails lowered, but the [MASK] token in the declarative sentence is unable to prompt the answer. This limitation can explain the differences of the absolute accuracy improvement on GQA and VQA v2.0 datasets shown in Table 2."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Effectiveness validation of declarative sentences for prompt tuning on GQA and VQA v2.0 datasets. Output and Task denote the outputs for prediction and the adapted tasks for fine-tuning, respectively. [C] and [M] are abbreviated as [CLS] and [MASK].",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T2.1.1.1.1\" class=\"ltx_text\">Prompt</span></td>\n<td id=\"S4.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T2.1.1.2.1\" class=\"ltx_text\">Output</span></td>\n<td id=\"S4.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T2.1.1.3.1\" class=\"ltx_text\">Task</span></td>\n<td id=\"S4.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\">Accuracy (%)</td>\n</tr>\n<tr id=\"S4.T2.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.2.1\" class=\"ltx_td ltx_align_center\">GQA</td>\n<td id=\"S4.T2.1.2.2\" class=\"ltx_td ltx_align_center\">VQA v2</td>\n</tr>\n<tr id=\"S4.T2.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Baseline</td>\n<td id=\"S4.T2.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">[C]</td>\n<td id=\"S4.T2.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Baseline</td>\n<td id=\"S4.T2.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">60.26</td>\n<td id=\"S4.T2.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">74.05</td>\n</tr>\n<tr id=\"S4.T2.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.4.1\" class=\"ltx_td ltx_align_left\">Mask</td>\n<td id=\"S4.T2.1.4.2\" class=\"ltx_td ltx_align_center\">[C]&amp;[M]</td>\n<td id=\"S4.T2.1.4.3\" class=\"ltx_td ltx_align_center\">MLM</td>\n<td id=\"S4.T2.1.4.4\" class=\"ltx_td ltx_align_center\">60.88</td>\n<td id=\"S4.T2.1.4.5\" class=\"ltx_td ltx_align_center\">74.30</td>\n</tr>\n<tr id=\"S4.T2.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.5.1\" class=\"ltx_td ltx_align_left\">Dynamic</td>\n<td id=\"S4.T2.1.5.2\" class=\"ltx_td ltx_align_center\">[C]&amp;[M]</td>\n<td id=\"S4.T2.1.5.3\" class=\"ltx_td ltx_align_center\">MLM</td>\n<td id=\"S4.T2.1.5.4\" class=\"ltx_td ltx_align_center\">62.09</td>\n<td id=\"S4.T2.1.5.5\" class=\"ltx_td ltx_align_center\">74.39</td>\n</tr>\n<tr id=\"S4.T2.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.6.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" rowspan=\"3\"><span id=\"S4.T2.1.6.1.1\" class=\"ltx_text\">Declaration</span></td>\n<td id=\"S4.T2.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">[M]</td>\n<td id=\"S4.T2.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">MLM</td>\n<td id=\"S4.T2.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\">60.03</td>\n<td id=\"S4.T2.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\">73.90</td>\n</tr>\n<tr id=\"S4.T2.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.7.1\" class=\"ltx_td ltx_align_center\">[C]&amp;[M]</td>\n<td id=\"S4.T2.1.7.2\" class=\"ltx_td ltx_align_center\">MLM</td>\n<td id=\"S4.T2.1.7.3\" class=\"ltx_td ltx_align_center\">62.71</td>\n<td id=\"S4.T2.1.7.4\" class=\"ltx_td ltx_align_center\">74.39</td>\n</tr>\n<tr id=\"S4.T2.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">[C]&amp;[M]</td>\n<td id=\"S4.T2.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">MLM&amp;ITM</td>\n<td id=\"S4.T2.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.8.3.1\" class=\"ltx_text ltx_font_bold\">63.13</span></td>\n<td id=\"S4.T2.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.1.8.4.1\" class=\"ltx_text ltx_font_bold\">74.50</span></td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "Different prompts. To illustrate the effectiveness of declarative sentences for prompt tuning, several prompt variants are proposed for comparison in Table 2, defined as follows:",
            "where ‘[V1]’-‘[V16]’ denote the learnable tokens which are jointly trained during fine-tuning. As Table 2 shows, on GQA dataset, our proposed declaration-based prompt is more effective than manually designed templates (i.e., Mask and Dynamic). For example, DPT with MLM task (row 5) surpasses the Mask and Dynamic with 1.83% and 0.62%, respectively. Equipped with both MLM and ITM tasks, our full model (row 6) surpasses Baseline by 2.87%. To measure the confidence of the results, we have performed additional 3 runs for our best-performing model on GQA and VQA v2.0 datasets, getting standard deviations of 0.10% and 0.06%, respectively.",
            "Generalizability over different datasets. Table 2 shows the ablation results on VQA v2.0 with respect to different prompts. Consistent with the results on GQA, our proposed DPT surpasses the fine-tuning using fixed templates, i.e., Mask or Dynamic. Specifically, our model with DPT outperforms Baseline by 0.45%. The difference in accuracy gain between GQA and VQA (2.87% vs. 0.45%) is mainly due to the question complexity and the quality of the generated declaration sentences (refer to Appendix for details).",
            "Table 11 shows several declarative sentences generated from VQA v2.0 dataset. Since the questions in VQA v2.0 are raised manually, there exists various question types, which requires broader capabilities beyond the image understanding. As Table 11 shows, T5 model is able to generalize to VQA v2.0 dataset, and generate appropriate declarative sentences for most cases. For example, the question pattern in sample-1 (i.e., what … say?) has not appeared in GQA dataset, but the T5 model still produces the proper declarative sentence. However, there also exist several question types that are difficult to convert, e.g., why, how, etc. For example, the sample-2 asks the reason about the sailboats have their sails lowered, but the [MASK] token in the declarative sentence is unable to prompt the answer. This limitation can explain the differences of the absolute accuracy improvement on GQA and VQA v2.0 datasets shown in Table 2."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Effectiveness validation of DPT over different pre-trained VL models on VQA v2.0 datasets. Δ(%)\\Delta(\\%) denotes the absolute accuracy improvement margin compared with baseline.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\">Model</td>\n<td id=\"S4.T3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Task</td>\n<td id=\"S4.T3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">Accuracy (%)</td>\n<td id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<math id=\"S4.T3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\Delta\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S4.T3.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.m1.1.1.cmml\">Δ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.m1.1b\"><ci id=\"S4.T3.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.m1.1.1\">Δ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.m1.1c\">\\Delta</annotation></semantics></math> (%)</td>\n</tr>\n<tr id=\"S4.T3.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"3\"><span id=\"S4.T3.1.2.1.1\" class=\"ltx_text\">VinVL[<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">2021</a></cite>]</span></td>\n<td id=\"S4.T3.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Baseline</td>\n<td id=\"S4.T3.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">74.05</td>\n<td id=\"S4.T3.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.00</td>\n</tr>\n<tr id=\"S4.T3.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.3.1\" class=\"ltx_td ltx_align_center\">MLM</td>\n<td id=\"S4.T3.1.3.2\" class=\"ltx_td ltx_align_center\">74.39</td>\n<td id=\"S4.T3.1.3.3\" class=\"ltx_td ltx_align_center\">0.34</td>\n</tr>\n<tr id=\"S4.T3.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.4.1\" class=\"ltx_td ltx_align_center\">MLM&amp;ITM</td>\n<td id=\"S4.T3.1.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.4.2.1\" class=\"ltx_text ltx_font_bold\">74.50</span></td>\n<td id=\"S4.T3.1.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.4.3.1\" class=\"ltx_text ltx_font_bold\">0.45</span></td>\n</tr>\n<tr id=\"S4.T3.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"3\"><span id=\"S4.T3.1.5.1.1\" class=\"ltx_text\">ViLT[<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">2021</a></cite>]</span></td>\n<td id=\"S4.T3.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Baseline</td>\n<td id=\"S4.T3.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">70.71</td>\n<td id=\"S4.T3.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.00</td>\n</tr>\n<tr id=\"S4.T3.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.6.1\" class=\"ltx_td ltx_align_center\">MLM</td>\n<td id=\"S4.T3.1.6.2\" class=\"ltx_td ltx_align_center\">71.01</td>\n<td id=\"S4.T3.1.6.3\" class=\"ltx_td ltx_align_center\">0.30</td>\n</tr>\n<tr id=\"S4.T3.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.7.1\" class=\"ltx_td ltx_align_center\">MLM&amp;ITM</td>\n<td id=\"S4.T3.1.7.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.7.2.1\" class=\"ltx_text ltx_font_bold\">71.17</span></td>\n<td id=\"S4.T3.1.7.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.7.3.1\" class=\"ltx_text ltx_font_bold\">0.46</span></td>\n</tr>\n<tr id=\"S4.T3.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.8.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" rowspan=\"3\"><span id=\"S4.T3.1.8.1.1\" class=\"ltx_text\">UNITER[<cite class=\"ltx_cite ltx_citemacro_citeyear\"><a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\">2020</a></cite>]</span></td>\n<td id=\"S4.T3.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Baseline</td>\n<td id=\"S4.T3.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">67.72</td>\n<td id=\"S4.T3.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.00</td>\n</tr>\n<tr id=\"S4.T3.1.9\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.9.1\" class=\"ltx_td ltx_align_center\">MLM</td>\n<td id=\"S4.T3.1.9.2\" class=\"ltx_td ltx_align_center\">68.69</td>\n<td id=\"S4.T3.1.9.3\" class=\"ltx_td ltx_align_center\">0.97</td>\n</tr>\n<tr id=\"S4.T3.1.10\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">MLM&amp;ITM</td>\n<td id=\"S4.T3.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.1.10.2.1\" class=\"ltx_text ltx_font_bold\">68.73</span></td>\n<td id=\"S4.T3.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.1.10.3.1\" class=\"ltx_text ltx_font_bold\">1.01</span></td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "Generalizability over different VL models. To illustrate the generalizability of our proposed method over different pre-trained VL models, we apply our DPT to the recently proposed VL models that have been pre-trained via MLM and ITM tasks, e.g., UNITER Chen et al. (2020) and ViLT Kim et al. (2021). As shown in Table 3, for all the three baselines, equipped with our DPT method, a consistent performance improvement (0.64% on average) can be observed. For example, ViLT+DPT and UNITER+DPT achieve absolute performance gains of 0.46% and 1.01% compared with the fine-tuning counterparts, respectively."
        ]
    },
    "A1.T4": {
        "caption": "Table 4: Statistics of samples in VQA-v2 dataset",
        "table": "<table id=\"A1.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T4.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T4.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Split</td>\n<td id=\"A1.T4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">#Images</td>\n<td id=\"A1.T4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">#Questions</td>\n<td id=\"A1.T4.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">#Answers</td>\n</tr>\n<tr id=\"A1.T4.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Train</td>\n<td id=\"A1.T4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">82,783</td>\n<td id=\"A1.T4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">443,757</td>\n<td id=\"A1.T4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4,437,570</td>\n</tr>\n<tr id=\"A1.T4.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T4.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">Val</td>\n<td id=\"A1.T4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">40,504</td>\n<td id=\"A1.T4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">214,354</td>\n<td id=\"A1.T4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">2,143,540</td>\n</tr>\n<tr id=\"A1.T4.1.4\" class=\"ltx_tr\">\n<td id=\"A1.T4.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">Test</td>\n<td id=\"A1.T4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">81,434</td>\n<td id=\"A1.T4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">447,793</td>\n<td id=\"A1.T4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n</tr>\n<tr id=\"A1.T4.1.5\" class=\"ltx_tr\">\n<td id=\"A1.T4.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">All</td>\n<td id=\"A1.T4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">204,721</td>\n<td id=\"A1.T4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1,105,904</td>\n<td id=\"A1.T4.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">-</td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "VQA v2.0. VQA v2.0 Agrawal et al. (2015) is the most commonly used VQA benchmark. It contains real images and annotated question-answer pairs. Each image has an average of 5 questions. Each question has 10 answers annotated by different annotators, and the most frequent answer is regarded as the ground-truth answer. The dataset is split into train, val, and test sets, statistically detailed in Table 4. The evaluation metric (i.e., accuracy) on this dataset is robust to inter-human variability, calculated as follows:"
        ]
    },
    "A1.T5": {
        "caption": "Table 5: Statistics of balance-split in GQA dataset",
        "table": "<table id=\"A1.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T5.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Split</td>\n<td id=\"A1.T5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">#Images</td>\n<td id=\"A1.T5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">#Questions</td>\n<td id=\"A1.T5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">#Vocab</td>\n</tr>\n<tr id=\"A1.T5.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Train</td>\n<td id=\"A1.T5.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">72,140</td>\n<td id=\"A1.T5.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">943,000</td>\n<td id=\"A1.T5.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"A1.T5.1.2.4.1\" class=\"ltx_text\">3,097</span></td>\n</tr>\n<tr id=\"A1.T5.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">Val</td>\n<td id=\"A1.T5.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">10,234</td>\n<td id=\"A1.T5.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">132,062</td>\n</tr>\n<tr id=\"A1.T5.1.4\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">Test-dev</td>\n<td id=\"A1.T5.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">398</td>\n<td id=\"A1.T5.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">12,578</td>\n</tr>\n<tr id=\"A1.T5.1.5\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">Test</td>\n<td id=\"A1.T5.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">2,987</td>\n<td id=\"A1.T5.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">95,336</td>\n</tr>\n<tr id=\"A1.T5.1.6\" class=\"ltx_tr\">\n<td id=\"A1.T5.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">All</td>\n<td id=\"A1.T5.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">85,759</td>\n<td id=\"A1.T5.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1,182,976</td>\n<td id=\"A1.T5.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">3,097</td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "GQA. GQA Hudson and Manning (2019a) is a VQA dataset that characterizes in compositional question answering and visual reasoning about real-world images. With the help of the scene graph annotations from Visual Genome Krishna et al. (2016), GQA is able to maximally mitigate the language priors that exist widely in previous VQA datasets. Additionally, the questions are generated via the engine that operates over 524 patterns, spanning 117 question groups. Therefore, it requires more complicated reasoning skills to answer the questions. GQA consists of two splits, i.e., all split that contains 22M QA pairs, and balanced split that consists of 1.7M QA pairs with resampled question-answer distribution. The dataset is split into 70% train, 10% validation, 10% test and 10% challenge. The statistics of balanced split are detailed in Table 5."
        ]
    },
    "A1.T6": {
        "caption": "Table 6: An annotation example of GQA dataset. Only part of the annotations is listed for illustration.",
        "table": "<table id=\"A1.T6.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T6.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_tt\">questionId</td>\n<td id=\"A1.T6.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">201640614</td>\n</tr>\n<tr id=\"A1.T6.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\">question</td>\n<td id=\"A1.T6.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Who is wearing the dress?</td>\n</tr>\n<tr id=\"A1.T6.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l\">answer</td>\n<td id=\"A1.T6.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">woman</td>\n</tr>\n<tr id=\"A1.T6.1.4\" class=\"ltx_tr\">\n<td id=\"A1.T6.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_l\">fullAnswer</td>\n<td id=\"A1.T6.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">The woman is wearing a dress.</td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "Declaration dataset. As introduced in Section 4.1, the declaration dataset is generated from the annotations from GQA dataset. Specifically, each annotation in GQA training set contains three keys, i.e., question, answer, and fullAnswer, illustrated in Table 6."
        ]
    },
    "A1.T7": {
        "caption": "Table 7: An example of question and the corresponding declaration.",
        "table": "<table id=\"A1.T7.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T7.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_tt\">questionId</td>\n<td id=\"A1.T7.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">201640614</td>\n</tr>\n<tr id=\"A1.T7.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\">question</td>\n<td id=\"A1.T7.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Who is wearing the dress?</td>\n</tr>\n<tr id=\"A1.T7.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T7.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_l\">declaration</td>\n<td id=\"A1.T7.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">The [MASK] is wearing a dress.</td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "It can be observed that ‘answer’ is usually a word or phrase while the ‘fullAnswer’ is a complete declarative sentence. According to statistics, we find that most short ‘answer’s are included in the ‘fullAnswer’s, which inspires us that instead of choosing one from a candidate answer set, we can extract a word/phrase as the answer from the complete declarative sentence in the form of cloze-filling. Formally, we replace the short ‘answer’ included in the ‘fullAnswer’ with a [MASK] token, resulting in a declarative sentence that can be used for answer clozing, illustrated in Table 7."
        ]
    },
    "A1.T8": {
        "caption": "Table 8: Five samples from the declaration dataset. Q and D indicate question and declaration, respectively.",
        "table": "<table id=\"A1.T8.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T8.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_tt\"><span id=\"A1.T8.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Type</span></td>\n<td id=\"A1.T8.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"A1.T8.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Content</span></td>\n</tr>\n<tr id=\"A1.T8.1.2\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\">Q</td>\n<td id=\"A1.T8.1.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Are there any black gloves or hats?</td>\n</tr>\n<tr id=\"A1.T8.1.3\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l\">D</td>\n<td id=\"A1.T8.1.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\">[MASK]</td>\n</tr>\n<tr id=\"A1.T8.1.4\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\">Q</td>\n<td id=\"A1.T8.1.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">What is the vehicle that is to the right of the man?</td>\n</tr>\n<tr id=\"A1.T8.1.5\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_l\">D</td>\n<td id=\"A1.T8.1.5.2\" class=\"ltx_td ltx_align_left ltx_border_r\">the vehicle is a [MASK].</td>\n</tr>\n<tr id=\"A1.T8.1.6\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\">Q</td>\n<td id=\"A1.T8.1.6.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">On which side of the image is the woman?</td>\n</tr>\n<tr id=\"A1.T8.1.7\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_l\">D</td>\n<td id=\"A1.T8.1.7.2\" class=\"ltx_td ltx_align_left ltx_border_r\">the woman is on the [MASK] of the image.</td>\n</tr>\n<tr id=\"A1.T8.1.8\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\">Q</td>\n<td id=\"A1.T8.1.8.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Who is swinging the bat?</td>\n</tr>\n<tr id=\"A1.T8.1.9\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_l\">D</td>\n<td id=\"A1.T8.1.9.2\" class=\"ltx_td ltx_align_left ltx_border_r\">the [MASK] is swinging the bat.</td>\n</tr>\n<tr id=\"A1.T8.1.10\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\">Q</td>\n<td id=\"A1.T8.1.10.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">What color are the gloves?</td>\n</tr>\n<tr id=\"A1.T8.1.11\" class=\"ltx_tr\">\n<td id=\"A1.T8.1.11.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_l\">D</td>\n<td id=\"A1.T8.1.11.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">the gloves are [MASK].</td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "In this way, we are able to convert the questions into declaration format from the all split of GQA dataset, resulting in 726k and 181k question-declaration pairs for training and validation, respectively. Several examples from our proposed declaration dataset are shown in Table 8."
        ]
    },
    "A3.T9": {
        "caption": "Table 9: Ablation experiments on the GQA balanced dataset. K𝐾K stands for the number of candidate answers chosen for image-text matching.",
        "table": "<table id=\"A3.T9.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A3.T9.3.1\" class=\"ltx_tr\">\n<td id=\"A3.T9.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">K</td>\n<td id=\"A3.T9.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Accuracy (%)</td>\n</tr>\n<tr id=\"A3.T9.3.2\" class=\"ltx_tr\">\n<td id=\"A3.T9.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">0</td>\n<td id=\"A3.T9.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">62.79</td>\n</tr>\n<tr id=\"A3.T9.3.3\" class=\"ltx_tr\">\n<td id=\"A3.T9.3.3.1\" class=\"ltx_td ltx_align_center\">1</td>\n<td id=\"A3.T9.3.3.2\" class=\"ltx_td ltx_align_center\">62.79</td>\n</tr>\n<tr id=\"A3.T9.3.4\" class=\"ltx_tr\">\n<td id=\"A3.T9.3.4.1\" class=\"ltx_td ltx_align_center\">2</td>\n<td id=\"A3.T9.3.4.2\" class=\"ltx_td ltx_align_center\">62.90</td>\n</tr>\n<tr id=\"A3.T9.3.5\" class=\"ltx_tr\">\n<td id=\"A3.T9.3.5.1\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"A3.T9.3.5.2\" class=\"ltx_td ltx_align_center\">63.06</td>\n</tr>\n<tr id=\"A3.T9.3.6\" class=\"ltx_tr\">\n<td id=\"A3.T9.3.6.1\" class=\"ltx_td ltx_align_center\">8</td>\n<td id=\"A3.T9.3.6.2\" class=\"ltx_td ltx_align_center\"><span id=\"A3.T9.3.6.2.1\" class=\"ltx_text ltx_font_bold\">63.13</span></td>\n</tr>\n<tr id=\"A3.T9.3.7\" class=\"ltx_tr\">\n<td id=\"A3.T9.3.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">16</td>\n<td id=\"A3.T9.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">63.12</td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "Table 9 shows the ablation results over the number of candidate answers for image-text matching. It can be observed that the best performance 63.13% is achieved when K=8𝐾8K=8. Additionally, computational complexity will increase dramatically when K𝐾K grows larger, while the accuracy does not change much. Therefore, we set K=8𝐾8K=8 throughout the experiments."
        ]
    },
    "A4.T10": {
        "caption": "Table 10: Examples from the declaration generation on GQA test split. Q and D denote the question and generated declarative sentence by T5 model, respectively.",
        "table": "<table id=\"A4.T10.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A4.T10.1.1\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_tt\"><span id=\"A4.T10.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Id</span></td>\n<td id=\"A4.T10.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"A4.T10.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Type</span></td>\n<td id=\"A4.T10.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"A4.T10.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Content</span></td>\n</tr>\n<tr id=\"A4.T10.1.2\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"A4.T10.1.2.1.1\" class=\"ltx_text\">0</span></td>\n<td id=\"A4.T10.1.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Q</td>\n<td id=\"A4.T10.1.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Which color is the shirt?</td>\n</tr>\n<tr id=\"A4.T10.1.3\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.3.1\" class=\"ltx_td ltx_align_left\">D</td>\n<td id=\"A4.T10.1.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\">the shirt is [MASK].</td>\n</tr>\n<tr id=\"A4.T10.1.4\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"A4.T10.1.4.1.1\" class=\"ltx_text\">1</span></td>\n<td id=\"A4.T10.1.4.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Q</td>\n<td id=\"A4.T10.1.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">What is beneath the microwave?</td>\n</tr>\n<tr id=\"A4.T10.1.5\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.5.1\" class=\"ltx_td ltx_align_left\">D</td>\n<td id=\"A4.T10.1.5.2\" class=\"ltx_td ltx_align_left ltx_border_r\">the [MASK] is beneath the microwave.</td>\n</tr>\n<tr id=\"A4.T10.1.6\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"A4.T10.1.6.1.1\" class=\"ltx_text\">2</span></td>\n<td id=\"A4.T10.1.6.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Q</td>\n<td id=\"A4.T10.1.6.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Is this a bed or a cabinet?</td>\n</tr>\n<tr id=\"A4.T10.1.7\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.7.1\" class=\"ltx_td ltx_align_left\">D</td>\n<td id=\"A4.T10.1.7.2\" class=\"ltx_td ltx_align_left ltx_border_r\">this is a [MASK].</td>\n</tr>\n<tr id=\"A4.T10.1.8\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"A4.T10.1.8.1.1\" class=\"ltx_text\">3</span></td>\n<td id=\"A4.T10.1.8.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Q</td>\n<td id=\"A4.T10.1.8.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Which kind of vehicle is in front of the flag?</td>\n</tr>\n<tr id=\"A4.T10.1.9\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.9.1\" class=\"ltx_td ltx_align_left\">D</td>\n<td id=\"A4.T10.1.9.2\" class=\"ltx_td ltx_align_left ltx_border_r\">the vehicle is a [MASK].</td>\n</tr>\n<tr id=\"A4.T10.1.10\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"A4.T10.1.10.1.1\" class=\"ltx_text\">4</span></td>\n<td id=\"A4.T10.1.10.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Q</td>\n<td id=\"A4.T10.1.10.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Are there rivers or oceans that are not calm?</td>\n</tr>\n<tr id=\"A4.T10.1.11\" class=\"ltx_tr\">\n<td id=\"A4.T10.1.11.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">D</td>\n<td id=\"A4.T10.1.11.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">[MASK].</td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "To perform predictions on the test split of GQA or VQA v2.0 datasets, the fine-tuned T5 model is exploited to convert questions into declarative sentences. In Table 10, we visualize several declarative sentences from GQA dataset, which are generated by the fine-tuned T5 model. It can be observed that [MASK] token is placed at the proper position that can prompt the model to predict the answer. However, we find that some generated sentences may not contain complete semantic information of the question. For example, the sample-3 refers to vehicle in front of the flag, while only vehicle is generated in the declarative sentence. This may cause ambiguity in visual reasoning. Therefore, we preserve the original question in the textual input of VL models, maximally reserving the semantics of questions."
        ]
    },
    "A4.T11": {
        "caption": "Table 11: Examples from the declaration generation on VQA v2.0 dataset. Q and D denote the question and generated declarative sentences by T5 model, respectively.",
        "table": "<table id=\"A4.T11.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A4.T11.1.1\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_tt\"><span id=\"A4.T11.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Id</span></td>\n<td id=\"A4.T11.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"A4.T11.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Type</span></td>\n<td id=\"A4.T11.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"A4.T11.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Content</span></td>\n</tr>\n<tr id=\"A4.T11.1.2\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"A4.T11.1.2.1.1\" class=\"ltx_text\">0</span></td>\n<td id=\"A4.T11.1.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Q</td>\n<td id=\"A4.T11.1.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">What is the man doing?</td>\n</tr>\n<tr id=\"A4.T11.1.3\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.3.1\" class=\"ltx_td ltx_align_left\">D</td>\n<td id=\"A4.T11.1.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\">the man is [MASK].</td>\n</tr>\n<tr id=\"A4.T11.1.4\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"A4.T11.1.4.1.1\" class=\"ltx_text\">1</span></td>\n<td id=\"A4.T11.1.4.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Q</td>\n<td id=\"A4.T11.1.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">What does the sign say?</td>\n</tr>\n<tr id=\"A4.T11.1.5\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.5.1\" class=\"ltx_td ltx_align_left\">D</td>\n<td id=\"A4.T11.1.5.2\" class=\"ltx_td ltx_align_left ltx_border_r\">the sign says the [MASK].</td>\n</tr>\n<tr id=\"A4.T11.1.6\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"A4.T11.1.6.1.1\" class=\"ltx_text\">2</span></td>\n<td id=\"A4.T11.1.6.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Q</td>\n<td id=\"A4.T11.1.6.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Why do the sailboats have their sails lowered?</td>\n</tr>\n<tr id=\"A4.T11.1.7\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.7.1\" class=\"ltx_td ltx_align_left\">D</td>\n<td id=\"A4.T11.1.7.2\" class=\"ltx_td ltx_align_left ltx_border_r\">the sailboats have [MASK] lowered.</td>\n</tr>\n<tr id=\"A4.T11.1.8\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"A4.T11.1.8.1.1\" class=\"ltx_text\">3</span></td>\n<td id=\"A4.T11.1.8.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Q</td>\n<td id=\"A4.T11.1.8.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Could this roof be tiled?</td>\n</tr>\n<tr id=\"A4.T11.1.9\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.9.1\" class=\"ltx_td ltx_align_left\">D</td>\n<td id=\"A4.T11.1.9.2\" class=\"ltx_td ltx_align_left ltx_border_r\">[MASK]</td>\n</tr>\n<tr id=\"A4.T11.1.10\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_l ltx_border_t\" rowspan=\"2\"><span id=\"A4.T11.1.10.1.1\" class=\"ltx_text\">4</span></td>\n<td id=\"A4.T11.1.10.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Q</td>\n<td id=\"A4.T11.1.10.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">What pattern is the person’s shirt?</td>\n</tr>\n<tr id=\"A4.T11.1.11\" class=\"ltx_tr\">\n<td id=\"A4.T11.1.11.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">D</td>\n<td id=\"A4.T11.1.11.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">the shirt is [MASK].</td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "Table 11 shows several declarative sentences generated from VQA v2.0 dataset. Since the questions in VQA v2.0 are raised manually, there exists various question types, which requires broader capabilities beyond the image understanding. As Table 11 shows, T5 model is able to generalize to VQA v2.0 dataset, and generate appropriate declarative sentences for most cases. For example, the question pattern in sample-1 (i.e., what … say?) has not appeared in GQA dataset, but the T5 model still produces the proper declarative sentence. However, there also exist several question types that are difficult to convert, e.g., why, how, etc. For example, the sample-2 asks the reason about the sailboats have their sails lowered, but the [MASK] token in the declarative sentence is unable to prompt the answer. This limitation can explain the differences of the absolute accuracy improvement on GQA and VQA v2.0 datasets shown in Table 2."
        ]
    }
}