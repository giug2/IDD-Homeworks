{
    "PAPER'S NUMBER OF TABLES": 9,
    "S4.SS1.SSS0.Px6.98": {
        "caption": "Table 1: Defenses against GS attack on MNIST and CIFAR10. Values are averaged. For DP-Gaussian, we follow the implementation in studies (Sun et al. 2021; Gao et al. 2021).",
        "table": "<table id=\"S4.F1.7\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_bottom\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.F1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.F1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Defense</th>\n<th id=\"S4.F1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">PSNR<math id=\"S4.F1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.F1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.F1.1.1.1.m1.1.1\" xref=\"S4.F1.1.1.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.1.1.1.m1.1b\"><ci id=\"S4.F1.1.1.1.m1.1.1.cmml\" xref=\"S4.F1.1.1.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S4.F1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">SSIM<math id=\"S4.F1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.F1.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.F1.2.2.2.m1.1.1\" xref=\"S4.F1.2.2.2.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.2.2.2.m1.1b\"><ci id=\"S4.F1.2.2.2.m1.1.1.cmml\" xref=\"S4.F1.2.2.2.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.2.2.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.F1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.F1.4.4.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">None</th>\n<td id=\"S4.F1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">59.22<math id=\"S4.F1.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.F1.3.3.1.m1.1a\"><mo id=\"S4.F1.3.3.1.m1.1.1\" xref=\"S4.F1.3.3.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.F1.3.3.1.m1.1.1.cmml\" xref=\"S4.F1.3.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.3.3.1.m1.1c\">\\pm</annotation></semantics></math>2.71</td>\n<td id=\"S4.F1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1.00<math id=\"S4.F1.4.4.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.F1.4.4.2.m1.1a\"><mo id=\"S4.F1.4.4.2.m1.1.1\" xref=\"S4.F1.4.4.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.4.4.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.F1.4.4.2.m1.1.1.cmml\" xref=\"S4.F1.4.4.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.4.4.2.m1.1c\">\\pm</annotation></semantics></math>4.77</td>\n</tr>\n<tr id=\"S4.F1.7.7\" class=\"ltx_tr\">\n<th id=\"S4.F1.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S4.F1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\text{DCS}^{2}\" display=\"inline\"><semantics id=\"S4.F1.5.5.1.m1.1a\"><msup id=\"S4.F1.5.5.1.m1.1.1\" xref=\"S4.F1.5.5.1.m1.1.1.cmml\"><mtext id=\"S4.F1.5.5.1.m1.1.1.2\" xref=\"S4.F1.5.5.1.m1.1.1.2a.cmml\">DCS</mtext><mn id=\"S4.F1.5.5.1.m1.1.1.3\" xref=\"S4.F1.5.5.1.m1.1.1.3.cmml\">2</mn></msup><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.5.5.1.m1.1b\"><apply id=\"S4.F1.5.5.1.m1.1.1.cmml\" xref=\"S4.F1.5.5.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.F1.5.5.1.m1.1.1.1.cmml\" xref=\"S4.F1.5.5.1.m1.1.1\">superscript</csymbol><ci id=\"S4.F1.5.5.1.m1.1.1.2a.cmml\" xref=\"S4.F1.5.5.1.m1.1.1.2\"><mtext id=\"S4.F1.5.5.1.m1.1.1.2.cmml\" xref=\"S4.F1.5.5.1.m1.1.1.2\">DCS</mtext></ci><cn type=\"integer\" id=\"S4.F1.5.5.1.m1.1.1.3.cmml\" xref=\"S4.F1.5.5.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.5.5.1.m1.1c\">\\text{DCS}^{2}</annotation></semantics></math></th>\n<td id=\"S4.F1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">7.87<math id=\"S4.F1.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.F1.6.6.2.m1.1a\"><mo id=\"S4.F1.6.6.2.m1.1.1\" xref=\"S4.F1.6.6.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.6.6.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.F1.6.6.2.m1.1.1.cmml\" xref=\"S4.F1.6.6.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.6.6.2.m1.1c\">\\pm</annotation></semantics></math>2.44</td>\n<td id=\"S4.F1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.18<math id=\"S4.F1.7.7.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.F1.7.7.3.m1.1a\"><mo id=\"S4.F1.7.7.3.m1.1.1\" xref=\"S4.F1.7.7.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.7.7.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.F1.7.7.3.m1.1.1.cmml\" xref=\"S4.F1.7.7.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.7.7.3.m1.1c\">\\pm</annotation></semantics></math>0.09</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "\n\n\n\n\n\n\nMNIST\n\nCIFAR10\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nNone\n59.20±plus-or-minus\\pm2.71\n1.00±plus-or-minus\\pm4.87\n86.98±plus-or-minus\\pm0.00\n87.16±plus-or-minus\\pm0.01\n\n20.41±plus-or-minus\\pm3.15\n0.73±plus-or-minus\\pm0.09\n90.35±plus-or-minus\\pm0.04\n80.41±plus-or-minus\\pm0.01\n\n\\cdashline2-10\n\nDP-Gaussian\n35.38±plus-or-minus\\pm2.44\n0.83±plus-or-minus\\pm0.07\n85.94±plus-or-minus\\pm0.00\n86.91±plus-or-minus\\pm0.01\n\n12.34±plus-or-minus\\pm1.34\n0.28±plus-or-minus\\pm0.06\n77.19±plus-or-minus\\pm0.18\n79.65±plus-or-minus\\pm0.04\n\nPrune\n14.13±plus-or-minus\\pm2.29\n0.37±plus-or-minus\\pm0.06\n85.94±plus-or-minus\\pm0.00\n86.91±plus-or-minus\\pm0.00\n\n11.26±plus-or-minus\\pm1.75\n0.22±plus-or-minus\\pm0.06\n77.80±plus-or-minus\\pm0.32\n79.51±plus-or-minus\\pm0.08\n\nSoteria\n9.67±plus-or-minus\\pm1.09\n0.30±plus-or-minus\\pm0.07\n86.98±plus-or-minus\\pm0.00\n86.94±plus-or-minus\\pm0.00\n\n11.48±plus-or-minus\\pm1.42\n0.29±plus-or-minus\\pm0.06\n84.70±plus-or-minus\\pm0.32\n79.76±plus-or-minus\\pm0.04\n\nDCS2superscriptDCS2\\text{DCS}^{2} (Ours)\n7.84±plus-or-minus\\pm2.56\n0.17±plus-or-minus\\pm0.09\n86.98±plus-or-minus\\pm0.00\n86.98±plus-or-minus\\pm0.01\n\n8.04±plus-or-minus\\pm1.10\n0.15±plus-or-minus\\pm0.05\n80.39±plus-or-minus\\pm0.07\n79.79±plus-or-minus\\pm0.03\n\n\n\n\n\n\n\n\n\nCelebA\n\nTinyImageNet\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\nSSIM↓↓\\downarrow\nLPIPS↑↑\\uparrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nNone\n19.92±plus-or-minus\\pm2.18\n0.75±plus-or-minus\\pm0.07\n100.0±plus-or-minus\\pm0.00\n93.79±plus-or-minus\\pm0.07\n\n1.00±plus-or-minus\\pm0.00\n0.00±plus-or-minus\\pm0.00\n73.94±plus-or-minus\\pm1.21\n66.41±plus-or-minus\\pm0.02\n\n\\cdashline2-10\n\nDP-Gaussian\n13.95±plus-or-minus\\pm1.52\n0.44±plus-or-minus\\pm0.08\n90.51±plus-or-minus\\pm0.47\n93.19±plus-or-minus\\pm0.04\n\n1.00±plus-or-minus\\pm0.00\n0.00±plus-or-minus\\pm0.00\n53.28±plus-or-minus\\pm0.78\n65.65±plus-or-minus\\pm0.07\n\nPrune\n9.57±plus-or-minus\\pm2.66\n0.24±plus-or-minus\\pm0.12\n91.41±plus-or-minus\\pm1.10\n93.25±plus-or-minus\\pm0.06\n\n0.91±plus-or-minus\\pm0.12\n0.16±plus-or-minus\\pm0.20\n52.77±plus-or-minus\\pm0.07\n65.73±plus-or-minus\\pm0.20\n\nSoteria\n8.89±plus-or-minus\\pm2.63\n0.24±plus-or-minus\\pm0.11\n100.0±plus-or-minus\\pm0.00\n93.86±plus-or-minus\\pm0.01\n\n1.00±plus-or-minus\\pm0.00\n0.00±plus-or-minus\\pm0.00\n41.84±plus-or-minus\\pm1.14\n52.06±plus-or-minus\\pm1.47\n\nDCS2superscriptDCS2\\text{DCS}^{2} (Ours)\n8.24±plus-or-minus\\pm2.71\n0.17±plus-or-minus\\pm0.12\n100.0±plus-or-minus\\pm0.00\n94.31±plus-or-minus\\pm0.01\n\n0.79±plus-or-minus\\pm0.22\n0.22±plus-or-minus\\pm0.23\n59.88±plus-or-minus\\pm0.71\n65.68±plus-or-minus\\pm0.05\n\n\n\n\n\n\n\n\nλgsubscript𝜆𝑔\\lambda_{g}\nSSIM↓↓\\downarrow\nLPIPS↑↑\\uparrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\n0.5\n0.80±plus-or-minus\\pm0.20\n0.22±plus-or-minus\\pm0.21\n60.33±plus-or-minus\\pm0.71\n65.76±plus-or-minus\\pm0.04\n\n0.7\n0.79±plus-or-minus\\pm0.22\n0.22±plus-or-minus\\pm0.23\n59.88±plus-or-minus\\pm0.71\n65.68±plus-or-minus\\pm0.05\n\n1.0\n0.78±plus-or-minus\\pm0.22\n0.23±plus-or-minus\\pm0.23\n58.54±plus-or-minus\\pm0.46\n65.24±plus-or-minus\\pm0.21\n\n\nWe consider 100% of the training data in the target client as sensitive samples.\nThe optimal conditions for an adversary to invert gradients are a batch size of one, a low image resolution, and an untrained target network.We first evaluate defenses against the GS attack on the MNIST and CIFAR10 datasets using models with randomly initialized weights.\nResults on Sec. 4.1 indicate that, compared with existing defenses, our proposed approach provides a better defense against the GS attack.\nSpecifically, on MNIST, the defense baselines reduce the PSNR from 59.20 to ∼10similar-toabsent10\\sim 10, while our defense can reduce the PSNR to around 8. On CIFAR10, our method reduces the SSIM to 0.17 when other defenses only reduce it to around 0.3.\nIn terms of the FL performance, as shown in Sec. 4.1, our proposed defense method DCS2superscriptDCS2\\text{DCS}^{2} largely retains the performance compared with other defenses.\nSpecifically, on MNIST, when most defense baseline drops the performance by about 1% on the sensitive data, our defense maintains the performance.Further, we compare different defenses for more complex datasets, with larger capacity networks, on CelebA and TinyImageNet, to defend against stronger attacks.\nWe use randomly initialized weights and use the attribute gender as the target label in CelebA to perform binary classification. A pre-trained ResNet18 was applied for TinyImageNet.\nAs shown in Table 4.1, our defense provides the best protection while competitively maintaining the original FL performance.\nSpecifically, on CelebA, defending against the GGL attack, our method provides the best protection, and the FL performance is even improved while defenses DP-Gaussian and Prune drop by around 0.5% on the test set.\nOn TinyImageNet, when defending against the Imprint attack, the defense Soteria cannot know where the adversary would insert the imprint module, so it cannot withstand the Imprint attack.\nWhile most defenses cannot provide protection, our defense method increases the LPIPS from 0.00 to 0.22.Fig. 2 shows the example of reconstructions from different attacks with defenses on different datasets.\nThe attacks could still recover some parts of the sensitive data with other defenses, while they fail with our proposed defense method.\nThe training process on various datasets with different defenses is illustrated in Fig. 4. Training with these defenses typically results in convergence. However, in the case of Soteria on TinyImageNet, approximately 90% of the representations are perturbed, resulting in a convergence failure.Tab. 3 presents the results for DCS2superscriptDCS2\\text{DCS}^{2} on TinyImageNet under varying values of λgsubscript𝜆𝑔\\lambda_{g}.\nAs λgsubscript𝜆𝑔\\lambda_{g} increases, the protection for sensitive data improves. However, this leads to a reduction in the performance of the FL system.[table]Defend against adaptive attacks.We compared the proposed defense method DCS2superscriptDCS2\\text{DCS}^{2} against two SOTA attacks: Imprint and GGL. Imprint modifies the architecture, and GGL uses a GAN to learn prior knowledge from public datasets.\nAs per  Gao et al. (2021), both these attacks are adaptive since the adversary “starts the reconstruction from an image with certain semantic information”\nor “designs attack techniques instead of optimizing the distance between the real and dummy gradients”.\nResults in Secs. 4.1 and 4.1 indicate that our defense provides the best protection with minimal drop in accuracy.\nFor example, on TinyImageNet, our defense reduces the SSIM score from 1.0 to 0.79. In comparison, the defense Prune decreases it to approximately 0.9 and other defenses prove inadequate against this attack. The accuracy of the FL system using our defense on the sensitive data decreases by about 14%, whereas other defenses drop exceeding 20%.Further, we design another strong attack where the adversary has strong prior knowledge and initializes the GS attack with the average image for each class.\nResults are shown in Fig. 1, our proposed method can still provide good protection against such an attack with prior knowledge about the sensitive data.\nFig. 1 shows an example of the reconstructions from this attack. The GS attack would initialize the dummy input with the AvgImg (average image) shown in Fig. 1. The average image already explicitly includes information about the sensitive data, while our defense method could still protect the data against this adaptive attack.\n\n\n\n\n\nMNIST\nNoise\nMixUP\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\n✓\n✗\n✓\n7.97±plus-or-minus\\pm2.48\n0.18±plus-or-minus\\pm0.08\n86.56±plus-or-minus\\pm0.57\n86.99±plus-or-minus\\pm0.01\n\n✓\n✗\n✗\n7.84±plus-or-minus\\pm2.56\n0.17±plus-or-minus\\pm0.09\n86.98±plus-or-minus\\pm0.00\n86.98±plus-or-minus\\pm0.01\n\n✗\n✓\n✓\n7.69±plus-or-minus\\pm2.38\n0.18±plus-or-minus\\pm0.08\n86.98±plus-or-minus\\pm0.00\n86.99±plus-or-minus\\pm0.00\n\n✗\n✓\n✗\n7.40±plus-or-minus\\pm2.22\n0.16±plus-or-minus\\pm0.08\n85.94±plus-or-minus\\pm0.00\n86.94±plus-or-minus\\pm0.00\n\n\n[table]Start points from CIFAR10 for CelebA.We further evaluate our defense by choosing different initial starting points to craft the concealed samples.\nTab. 4 show the performance with different start points. ‘MixUP’ means that 𝒙~csubscript~𝒙𝑐\\tilde{{\\bm{x}}}_{c} is initialized with 0.7​𝒙0+0.3​𝒙s0.7subscript𝒙00.3subscript𝒙𝑠0.7{\\bm{x}}_{0}+0.3{\\bm{x}}_{s}.\nFig. 3 show the results when the start points are from CIFAR10, which has different distribution than the target task dataset CelebA.\nAs shown in Tabs. 4 and 3, even starting from random noise and different domains, our defense method could still provide protection and retain the model’s performance.\n\n\n\n\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nPrune\n14.13±plus-or-minus\\pm2.29\n0.37±plus-or-minus\\pm0.06\n85.94±plus-or-minus\\pm0.00\n86.91±plus-or-minus\\pm0.00\n\nDCS2superscriptDCS2\\text{DCS}^{2}\n7.84±plus-or-minus\\pm2.56\n0.17±plus-or-minus\\pm0.09\n86.98±plus-or-minus\\pm0.00\n86.98±plus-or-minus\\pm0.01\n\nPrune&DCS2superscriptDCS2\\&\\text{DCS}^{2}\n6.08±plus-or-minus\\pm1.60\n0.12±plus-or-minus\\pm0.06\n86.15±plus-or-minus\\pm0.47\n86.92±plus-or-minus\\pm0.01\n\n\nAn illustration of combining DCS2superscriptDCS2\\text{DCS}^{2} with the defense ‘Prune’ is presented in Tab. 5. In this scenario, the enhancement of protection for private training data is notable. While the performance experiences a slight decrease compared to the standalone proposed defense method, it still surpasses the performance of the defense ‘Prune’ alone.While our empirical evaluations show that our proposed defense is effective in enhancing privacy and retaining FL performance, it requires additional computation to craft concealed samples (refer to the supplementary material for details on compute complexity).\nFuture directions to improve concealed samples-based defense include finding the best starting points and reducing the time to craft the concealed samples. We hope our defense can provide a new perspective for defending against model inversion attacks in FL.In this work, we proposed an effective defense algorithm against model inversion attacks in FL. Our approach crafts concealed samples that imitate the sensitive data, but can obfuscate their gradients, thus making it challenging for an adversary to reconstruct sensitive data from the shared gradients.\nTo enhance the privacy of the sensitive data, the concealed samples are adaptively learned to be visually very dissimilar to the sensitive samples, while their gradients are aligned with the original samples to avoid FL performance drop. Our evaluations on four benchmark datasets showed that, compared with other defenses, our approach offers the best protection against model inversion attacks while simultaneously retaining or even improving the FL performance.Mehrtash Harandi gratefully acknowledges the support from the Australian Research Council (ARC), project DP230101176.Let’s consider a model with d𝑑d parameters, and we’ll denote the time complexity for forward propagation as h​(d)ℎ𝑑h(d). As per the Baur-Strassen theorem (Griewank and Walther 2008), the time complexity of a single step in backpropagation will be at most 5​h​(d)5ℎ𝑑5h(d).\nOur approach introduces an additional time complexity of 6​f​(d)6𝑓𝑑6f(d) due to the incorporation of concealed samples.\nAssuming that 𝒙∈ℝn𝒙superscriptℝ𝑛{\\bm{x}}\\in\\mathbb{R}^{n} and f​(𝒙)∈ℝm𝑓𝒙superscriptℝ𝑚f({\\bm{x}})\\in\\mathbb{R}^{m}, we can express the overall computational cost of the objective function in Sec. 3.3 as 𝒪​(d2+n2+m2)𝒪superscript𝑑2superscript𝑛2superscript𝑚2{\\mathcal{O}}(d^{2}+n^{2}+m^{2}).\nIf the perturbed gradient with concealed samples behaves dissimilar to that of the original gradient, then the computational cost of the gradient projection is around 𝒪​(d3)𝒪superscript𝑑3{\\mathcal{O}}(d^{3}).\nOn TinyImageNet, we observed that one round of updates with our method on an NVIDIA RTX A100 GPU takes approximately 172 seconds. In comparison, an update without any defenses requires around 102 seconds.Details of the models used in this study are shown in Tab. 6. The activation layers of the model for the MNIST dataset are Sigmoid, and for CIFAR10 and CelebA, TinyImageNet datasets are ReLU.\n\n\n\n\n\nMNIST\nCIFAR10/CelebA\nTinyImageNet\n\n\n\n5×5555\\times 5 Conv, 12\n5×5555\\times 5 Conv, 32\n7×7777\\times 7 Conv, 64\n\n5×5555\\times 5 Conv, 12\n{5×5​ Conv, 64}×2matrix55 Conv, 642\\begin{Bmatrix}5\\times 5\\text{ Conv, 64}\\end{Bmatrix}\\times 2\n3×3333\\times 3 MaxPool\n\n5×5555\\times 5 Conv, 12\n{5×5​ Conv, 128}×3matrix55 Conv, 1283\\begin{Bmatrix}5\\times 5\\text{ Conv, 128}\\end{Bmatrix}\\times 3\n{3×3​ Conv, 643×3​ Conv, 64}×2matrix33 Conv, 6433 Conv, 642\\begin{Bmatrix}3\\times 3\\text{ Conv, 64}\\\\\n3\\times 3\\text{ Conv, 64}\\end{Bmatrix}\\times 2\n\n5×5555\\times 5 Conv, 12\n3×3333\\times 3 MaxPool\n{3×3​ Conv, 1283×3​ Conv, 128}×2matrix33 Conv, 12833 Conv, 1282\\begin{Bmatrix}3\\times 3\\text{ Conv, 128}\\\\\n3\\times 3\\text{ Conv, 128}\\end{Bmatrix}\\times 2\n\nFC-10\n{5×5​ Conv, 128}×3matrix55 Conv, 1283\\begin{Bmatrix}5\\times 5\\text{ Conv, 128}\\end{Bmatrix}\\times 3\n{3×3​ Conv, 2563×3​ Conv, 256}×2matrix33 Conv, 25633 Conv, 2562\\begin{Bmatrix}3\\times 3\\text{ Conv, 256}\\\\\n3\\times 3\\text{ Conv, 256}\\end{Bmatrix}\\times 2\n\n\n3×3333\\times 3 MaxPool\n{3×3​ Conv, 5123×3​ Conv, 512}×2matrix33 Conv, 51233 Conv, 5122\\begin{Bmatrix}3\\times 3\\text{ Conv, 512}\\\\\n3\\times 3\\text{ Conv, 512}\\end{Bmatrix}\\times 2\n\n\nFC-10 (CIFAR10) / FC-2 (CelebA)\n7×7777\\times 7 AveragePool\n\n\n\nFC-200\n\n\nWe build on the repository using the official implementation of the GS, GGL, and Imprint attack methods.\nFor the defenses Soteria, Prune, and DP-Gaussian, we build on the repository from the study (Sun et al. 2021).\nFor the defense ATS, we build upon the repository from the study (Balunović et al. 2022).\nFor training, we apply SGD optimizer and set the learning rate for updating the local models η=0.01𝜂0.01\\eta=0.01 with exponential decay.\nThe pruning rate from the defense Prune is 0.9 for CIFAR10 and 0.7 for others.\nThe variance of noise distribution from the defense DP-Gaussian is 0.01 for MNIST, 0.5 for TinyImageNet, and 0.001 for others.\nThe pruning rate from the defense Soteria is 0.2 for MNIST, 0.5 for CIFAR10, 0.7 for CelebA, and 0.9 for TinyImageNet.\nOur method set ϵ=0.01italic-ϵ0.01\\epsilon=0.01, λg=0.7subscript𝜆𝑔0.7\\lambda_{g}=0.7, and the number of iteration as 1000 for all datasets, λx=0.01subscript𝜆𝑥0.01\\lambda_{x}=0.01 and λz=0.01subscript𝜆𝑧0.01\\lambda_{z}=0.01 for MNIST and CIFAR10, λx=0.01subscript𝜆𝑥0.01\\lambda_{x}=0.01 and λz=0.1subscript𝜆𝑧0.1\\lambda_{z}=0.1 for CelebA, λx=0.001subscript𝜆𝑥0.001\\lambda_{x}=0.001 and λz=0.01subscript𝜆𝑧0.01\\lambda_{z}=0.01 for TinyImageNet.\nThe weights of penalty terms in Eq. (9) are chosen to balance them or kept fixed across all experiments (e.g., ϵ=0.01italic-ϵ0.01\\epsilon=0.01 for all experiments.)\nIn our experiments, we opt for the entirety of the training data in the target client to be sensitive and generate one synthetic sample per sensitive datum (ratio 1:1).\nSSIM is 0.92 with an accuracy of 87% and 0.86 with an accuracy of 86.91% for ratios 10:1 and 5:1, respectively.\nWhile the protection becomes better, the model’s performance will drop.Consider a sensitive data point 𝒙ssubscript𝒙𝑠{\\bm{x}}_{s} (see Fig. 5 for an illustration), we aim to craft the concealed sample 𝒙~csubscript~𝒙𝑐\\tilde{{\\bm{x}}}_{c} which makes ∇𝜽ℒ​(f𝜽​(𝒙~c),𝒚~c)subscript∇𝜽ℒsubscript𝑓𝜽subscript~𝒙𝑐subscript~𝒚𝑐\\nabla_{{\\bm{\\theta}}}\\mathcal{L}(f_{{\\bm{\\theta}}}(\\tilde{{\\bm{x}}}_{c}),\\tilde{{\\bm{y}}}_{c}) approaching ∇𝜽ℒ​(f𝜽​(𝒙s),𝒚s)subscript∇𝜽ℒsubscript𝑓𝜽subscript𝒙𝑠subscript𝒚𝑠\\nabla_{{\\bm{\\theta}}}\\mathcal{L}(f_{{\\bm{\\theta}}}({\\bm{x}}_{s}),{\\bm{y}}_{s}).\nThis strategy obfuscates the sensitive samples, as the reconstruction by the adversary through the gradient will contain information from the concealed sample, which we aim to be visually different from the sensitive data.\n\n\n\n\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nATS\n19.68±plus-or-minus\\pm4.60\n0.59±plus-or-minus\\pm0.14\n67.99±plus-or-minus\\pm0.57\n75.70±plus-or-minus\\pm0.02\n\nDCS2superscriptDCS2\\text{DCS}^{2} (Ours)\n8.04±plus-or-minus\\pm1.10\n0.15±plus-or-minus\\pm0.05\n80.39±plus-or-minus\\pm0.07\n79.79±plus-or-minus\\pm0.03\n\n\n\n\n\n\n\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nNone\n57.50±plus-or-minus\\pm1.95\n1.00±plus-or-minus\\pm0.00\n89.84±plus-or-minus\\pm0.00\n76.60±plus-or-minus\\pm0.00\n\nDP-Gaussian\n34.73±plus-or-minus\\pm0.79\n0.83±plus-or-minus\\pm0.04\n83.59±plus-or-minus\\pm0.00\n75.75±plus-or-minus\\pm0.01\n\nPrune\n14.49±plus-or-minus\\pm1.81\n0.39±plus-or-minus\\pm0.05\n83.59±plus-or-minus\\pm0.00\n75.75±plus-or-minus\\pm0.00\n\nSoteria\n7.28±plus-or-minus\\pm0.60\n0.23±plus-or-minus\\pm0.04\n85.42±plus-or-minus\\pm0.00\n75.92±plus-or-minus\\pm0.01\n\nDCS2superscriptDCS2\\text{DCS}^{2} (Ours)\n7.27±plus-or-minus\\pm1.77\n0.16±plus-or-minus\\pm0.06\n89.32±plus-or-minus\\pm0.00\n75.19±plus-or-minus\\pm0.02\n\n\nWe evaluated the Imprint attack with the recently introduced dataset FACET (Gustafson et al. 2023) (Fig. 8 (a)). With our defense applied, the attack failed to perfectly reconstruct the data. The accuracy of the model on the test set w/o and w/ our defense is around 77.21% and 76.62%, respectively.Note that neither optimization-based attacks nor model modification attacks can precisely separate the gradient for individual data points.\nIn Fig. 8 (b), for instance, there are four ‘6’ within the batch; the gradients w.r.t. these images cannot be fully separated, and the GS attack fails to reconstruct the third image.\nBesides, similar to any defense mechanism, it is possible to identify the concealed samples.\nFor example, an adversary could potentially modify the model to reconstruct the concealed samples and use a filtering mechanism to identify them.\nOur model might become vulnerable if the adversary has extensive knowledge about the data and model as exemplified by the GGL attack (use partial training data to learn prior knowledge), or has the ability to modify model architecture as in the Imprint attack. Fig.2 and Fig. 8 (a) provide examples of GGL and Imprint attacks, where the attack managed to reconstruct facial outlines and vague information. It is important to note that model modification methods are generally identifiable and can be countered by vigilant clients.",
        "references": [
            [
                "We apply FedAvg ",
                "(McMahan et al. ",
                "2017a",
                ")",
                " during training to report our results.\nWe set the local epoch ",
                "E",
                "𝐸",
                "E",
                " as 1 (easier for attacks) and batch size ",
                "B",
                "𝐵",
                "B",
                " as 64.\nWe have 10 clients in total; each client only has 200 samples on MNIST, 2000 samples on CIFAR10, 500 samples on CelebA, and 2000 samples on TinyImageNet."
            ]
        ]
    },
    "S4.SS1.SSS0.Px6.98.98": {
        "caption": "Table 2: Defenses against GGL attack on CelebA and Imprint attack on TinyImageNet. Values are averaged.",
        "table": "<table id=\"S4.F1.7\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_bottom\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.F1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.F1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Defense</th>\n<th id=\"S4.F1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">PSNR<math id=\"S4.F1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.F1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.F1.1.1.1.m1.1.1\" xref=\"S4.F1.1.1.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.1.1.1.m1.1b\"><ci id=\"S4.F1.1.1.1.m1.1.1.cmml\" xref=\"S4.F1.1.1.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S4.F1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">SSIM<math id=\"S4.F1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.F1.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.F1.2.2.2.m1.1.1\" xref=\"S4.F1.2.2.2.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.2.2.2.m1.1b\"><ci id=\"S4.F1.2.2.2.m1.1.1.cmml\" xref=\"S4.F1.2.2.2.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.2.2.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.F1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.F1.4.4.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">None</th>\n<td id=\"S4.F1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">59.22<math id=\"S4.F1.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.F1.3.3.1.m1.1a\"><mo id=\"S4.F1.3.3.1.m1.1.1\" xref=\"S4.F1.3.3.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.F1.3.3.1.m1.1.1.cmml\" xref=\"S4.F1.3.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.3.3.1.m1.1c\">\\pm</annotation></semantics></math>2.71</td>\n<td id=\"S4.F1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1.00<math id=\"S4.F1.4.4.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.F1.4.4.2.m1.1a\"><mo id=\"S4.F1.4.4.2.m1.1.1\" xref=\"S4.F1.4.4.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.4.4.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.F1.4.4.2.m1.1.1.cmml\" xref=\"S4.F1.4.4.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.4.4.2.m1.1c\">\\pm</annotation></semantics></math>4.77</td>\n</tr>\n<tr id=\"S4.F1.7.7\" class=\"ltx_tr\">\n<th id=\"S4.F1.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S4.F1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\text{DCS}^{2}\" display=\"inline\"><semantics id=\"S4.F1.5.5.1.m1.1a\"><msup id=\"S4.F1.5.5.1.m1.1.1\" xref=\"S4.F1.5.5.1.m1.1.1.cmml\"><mtext id=\"S4.F1.5.5.1.m1.1.1.2\" xref=\"S4.F1.5.5.1.m1.1.1.2a.cmml\">DCS</mtext><mn id=\"S4.F1.5.5.1.m1.1.1.3\" xref=\"S4.F1.5.5.1.m1.1.1.3.cmml\">2</mn></msup><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.5.5.1.m1.1b\"><apply id=\"S4.F1.5.5.1.m1.1.1.cmml\" xref=\"S4.F1.5.5.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.F1.5.5.1.m1.1.1.1.cmml\" xref=\"S4.F1.5.5.1.m1.1.1\">superscript</csymbol><ci id=\"S4.F1.5.5.1.m1.1.1.2a.cmml\" xref=\"S4.F1.5.5.1.m1.1.1.2\"><mtext id=\"S4.F1.5.5.1.m1.1.1.2.cmml\" xref=\"S4.F1.5.5.1.m1.1.1.2\">DCS</mtext></ci><cn type=\"integer\" id=\"S4.F1.5.5.1.m1.1.1.3.cmml\" xref=\"S4.F1.5.5.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.5.5.1.m1.1c\">\\text{DCS}^{2}</annotation></semantics></math></th>\n<td id=\"S4.F1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">7.87<math id=\"S4.F1.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.F1.6.6.2.m1.1a\"><mo id=\"S4.F1.6.6.2.m1.1.1\" xref=\"S4.F1.6.6.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.6.6.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.F1.6.6.2.m1.1.1.cmml\" xref=\"S4.F1.6.6.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.6.6.2.m1.1c\">\\pm</annotation></semantics></math>2.44</td>\n<td id=\"S4.F1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.18<math id=\"S4.F1.7.7.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.F1.7.7.3.m1.1a\"><mo id=\"S4.F1.7.7.3.m1.1.1\" xref=\"S4.F1.7.7.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.F1.7.7.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.F1.7.7.3.m1.1.1.cmml\" xref=\"S4.F1.7.7.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.F1.7.7.3.m1.1c\">\\pm</annotation></semantics></math>0.09</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "\n\n\n\n\n\n\nCelebA\n\nTinyImageNet\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\nSSIM↓↓\\downarrow\nLPIPS↑↑\\uparrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nNone\n19.92±plus-or-minus\\pm2.18\n0.75±plus-or-minus\\pm0.07\n100.0±plus-or-minus\\pm0.00\n93.79±plus-or-minus\\pm0.07\n\n1.00±plus-or-minus\\pm0.00\n0.00±plus-or-minus\\pm0.00\n73.94±plus-or-minus\\pm1.21\n66.41±plus-or-minus\\pm0.02\n\n\\cdashline2-10\n\nDP-Gaussian\n13.95±plus-or-minus\\pm1.52\n0.44±plus-or-minus\\pm0.08\n90.51±plus-or-minus\\pm0.47\n93.19±plus-or-minus\\pm0.04\n\n1.00±plus-or-minus\\pm0.00\n0.00±plus-or-minus\\pm0.00\n53.28±plus-or-minus\\pm0.78\n65.65±plus-or-minus\\pm0.07\n\nPrune\n9.57±plus-or-minus\\pm2.66\n0.24±plus-or-minus\\pm0.12\n91.41±plus-or-minus\\pm1.10\n93.25±plus-or-minus\\pm0.06\n\n0.91±plus-or-minus\\pm0.12\n0.16±plus-or-minus\\pm0.20\n52.77±plus-or-minus\\pm0.07\n65.73±plus-or-minus\\pm0.20\n\nSoteria\n8.89±plus-or-minus\\pm2.63\n0.24±plus-or-minus\\pm0.11\n100.0±plus-or-minus\\pm0.00\n93.86±plus-or-minus\\pm0.01\n\n1.00±plus-or-minus\\pm0.00\n0.00±plus-or-minus\\pm0.00\n41.84±plus-or-minus\\pm1.14\n52.06±plus-or-minus\\pm1.47\n\nDCS2superscriptDCS2\\text{DCS}^{2} (Ours)\n8.24±plus-or-minus\\pm2.71\n0.17±plus-or-minus\\pm0.12\n100.0±plus-or-minus\\pm0.00\n94.31±plus-or-minus\\pm0.01\n\n0.79±plus-or-minus\\pm0.22\n0.22±plus-or-minus\\pm0.23\n59.88±plus-or-minus\\pm0.71\n65.68±plus-or-minus\\pm0.05\n\n\n\n\n\n\n\n\nλgsubscript𝜆𝑔\\lambda_{g}\nSSIM↓↓\\downarrow\nLPIPS↑↑\\uparrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\n0.5\n0.80±plus-or-minus\\pm0.20\n0.22±plus-or-minus\\pm0.21\n60.33±plus-or-minus\\pm0.71\n65.76±plus-or-minus\\pm0.04\n\n0.7\n0.79±plus-or-minus\\pm0.22\n0.22±plus-or-minus\\pm0.23\n59.88±plus-or-minus\\pm0.71\n65.68±plus-or-minus\\pm0.05\n\n1.0\n0.78±plus-or-minus\\pm0.22\n0.23±plus-or-minus\\pm0.23\n58.54±plus-or-minus\\pm0.46\n65.24±plus-or-minus\\pm0.21\n\n\nWe consider 100% of the training data in the target client as sensitive samples.\nThe optimal conditions for an adversary to invert gradients are a batch size of one, a low image resolution, and an untrained target network.We first evaluate defenses against the GS attack on the MNIST and CIFAR10 datasets using models with randomly initialized weights.\nResults on Sec. 4.1 indicate that, compared with existing defenses, our proposed approach provides a better defense against the GS attack.\nSpecifically, on MNIST, the defense baselines reduce the PSNR from 59.20 to ∼10similar-toabsent10\\sim 10, while our defense can reduce the PSNR to around 8. On CIFAR10, our method reduces the SSIM to 0.17 when other defenses only reduce it to around 0.3.\nIn terms of the FL performance, as shown in Sec. 4.1, our proposed defense method DCS2superscriptDCS2\\text{DCS}^{2} largely retains the performance compared with other defenses.\nSpecifically, on MNIST, when most defense baseline drops the performance by about 1% on the sensitive data, our defense maintains the performance.Further, we compare different defenses for more complex datasets, with larger capacity networks, on CelebA and TinyImageNet, to defend against stronger attacks.\nWe use randomly initialized weights and use the attribute gender as the target label in CelebA to perform binary classification. A pre-trained ResNet18 was applied for TinyImageNet.\nAs shown in Table 4.1, our defense provides the best protection while competitively maintaining the original FL performance.\nSpecifically, on CelebA, defending against the GGL attack, our method provides the best protection, and the FL performance is even improved while defenses DP-Gaussian and Prune drop by around 0.5% on the test set.\nOn TinyImageNet, when defending against the Imprint attack, the defense Soteria cannot know where the adversary would insert the imprint module, so it cannot withstand the Imprint attack.\nWhile most defenses cannot provide protection, our defense method increases the LPIPS from 0.00 to 0.22.Fig. 2 shows the example of reconstructions from different attacks with defenses on different datasets.\nThe attacks could still recover some parts of the sensitive data with other defenses, while they fail with our proposed defense method.\nThe training process on various datasets with different defenses is illustrated in Fig. 4. Training with these defenses typically results in convergence. However, in the case of Soteria on TinyImageNet, approximately 90% of the representations are perturbed, resulting in a convergence failure.Tab. 3 presents the results for DCS2superscriptDCS2\\text{DCS}^{2} on TinyImageNet under varying values of λgsubscript𝜆𝑔\\lambda_{g}.\nAs λgsubscript𝜆𝑔\\lambda_{g} increases, the protection for sensitive data improves. However, this leads to a reduction in the performance of the FL system.[table]Defend against adaptive attacks.We compared the proposed defense method DCS2superscriptDCS2\\text{DCS}^{2} against two SOTA attacks: Imprint and GGL. Imprint modifies the architecture, and GGL uses a GAN to learn prior knowledge from public datasets.\nAs per  Gao et al. (2021), both these attacks are adaptive since the adversary “starts the reconstruction from an image with certain semantic information”\nor “designs attack techniques instead of optimizing the distance between the real and dummy gradients”.\nResults in Secs. 4.1 and 4.1 indicate that our defense provides the best protection with minimal drop in accuracy.\nFor example, on TinyImageNet, our defense reduces the SSIM score from 1.0 to 0.79. In comparison, the defense Prune decreases it to approximately 0.9 and other defenses prove inadequate against this attack. The accuracy of the FL system using our defense on the sensitive data decreases by about 14%, whereas other defenses drop exceeding 20%.Further, we design another strong attack where the adversary has strong prior knowledge and initializes the GS attack with the average image for each class.\nResults are shown in Fig. 1, our proposed method can still provide good protection against such an attack with prior knowledge about the sensitive data.\nFig. 1 shows an example of the reconstructions from this attack. The GS attack would initialize the dummy input with the AvgImg (average image) shown in Fig. 1. The average image already explicitly includes information about the sensitive data, while our defense method could still protect the data against this adaptive attack.\n\n\n\n\n\nMNIST\nNoise\nMixUP\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\n✓\n✗\n✓\n7.97±plus-or-minus\\pm2.48\n0.18±plus-or-minus\\pm0.08\n86.56±plus-or-minus\\pm0.57\n86.99±plus-or-minus\\pm0.01\n\n✓\n✗\n✗\n7.84±plus-or-minus\\pm2.56\n0.17±plus-or-minus\\pm0.09\n86.98±plus-or-minus\\pm0.00\n86.98±plus-or-minus\\pm0.01\n\n✗\n✓\n✓\n7.69±plus-or-minus\\pm2.38\n0.18±plus-or-minus\\pm0.08\n86.98±plus-or-minus\\pm0.00\n86.99±plus-or-minus\\pm0.00\n\n✗\n✓\n✗\n7.40±plus-or-minus\\pm2.22\n0.16±plus-or-minus\\pm0.08\n85.94±plus-or-minus\\pm0.00\n86.94±plus-or-minus\\pm0.00\n\n\n[table]Start points from CIFAR10 for CelebA.We further evaluate our defense by choosing different initial starting points to craft the concealed samples.\nTab. 4 show the performance with different start points. ‘MixUP’ means that 𝒙~csubscript~𝒙𝑐\\tilde{{\\bm{x}}}_{c} is initialized with 0.7​𝒙0+0.3​𝒙s0.7subscript𝒙00.3subscript𝒙𝑠0.7{\\bm{x}}_{0}+0.3{\\bm{x}}_{s}.\nFig. 3 show the results when the start points are from CIFAR10, which has different distribution than the target task dataset CelebA.\nAs shown in Tabs. 4 and 3, even starting from random noise and different domains, our defense method could still provide protection and retain the model’s performance.\n\n\n\n\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nPrune\n14.13±plus-or-minus\\pm2.29\n0.37±plus-or-minus\\pm0.06\n85.94±plus-or-minus\\pm0.00\n86.91±plus-or-minus\\pm0.00\n\nDCS2superscriptDCS2\\text{DCS}^{2}\n7.84±plus-or-minus\\pm2.56\n0.17±plus-or-minus\\pm0.09\n86.98±plus-or-minus\\pm0.00\n86.98±plus-or-minus\\pm0.01\n\nPrune&DCS2superscriptDCS2\\&\\text{DCS}^{2}\n6.08±plus-or-minus\\pm1.60\n0.12±plus-or-minus\\pm0.06\n86.15±plus-or-minus\\pm0.47\n86.92±plus-or-minus\\pm0.01\n\n\nAn illustration of combining DCS2superscriptDCS2\\text{DCS}^{2} with the defense ‘Prune’ is presented in Tab. 5. In this scenario, the enhancement of protection for private training data is notable. While the performance experiences a slight decrease compared to the standalone proposed defense method, it still surpasses the performance of the defense ‘Prune’ alone.While our empirical evaluations show that our proposed defense is effective in enhancing privacy and retaining FL performance, it requires additional computation to craft concealed samples (refer to the supplementary material for details on compute complexity).\nFuture directions to improve concealed samples-based defense include finding the best starting points and reducing the time to craft the concealed samples. We hope our defense can provide a new perspective for defending against model inversion attacks in FL.In this work, we proposed an effective defense algorithm against model inversion attacks in FL. Our approach crafts concealed samples that imitate the sensitive data, but can obfuscate their gradients, thus making it challenging for an adversary to reconstruct sensitive data from the shared gradients.\nTo enhance the privacy of the sensitive data, the concealed samples are adaptively learned to be visually very dissimilar to the sensitive samples, while their gradients are aligned with the original samples to avoid FL performance drop. Our evaluations on four benchmark datasets showed that, compared with other defenses, our approach offers the best protection against model inversion attacks while simultaneously retaining or even improving the FL performance.Mehrtash Harandi gratefully acknowledges the support from the Australian Research Council (ARC), project DP230101176.Let’s consider a model with d𝑑d parameters, and we’ll denote the time complexity for forward propagation as h​(d)ℎ𝑑h(d). As per the Baur-Strassen theorem (Griewank and Walther 2008), the time complexity of a single step in backpropagation will be at most 5​h​(d)5ℎ𝑑5h(d).\nOur approach introduces an additional time complexity of 6​f​(d)6𝑓𝑑6f(d) due to the incorporation of concealed samples.\nAssuming that 𝒙∈ℝn𝒙superscriptℝ𝑛{\\bm{x}}\\in\\mathbb{R}^{n} and f​(𝒙)∈ℝm𝑓𝒙superscriptℝ𝑚f({\\bm{x}})\\in\\mathbb{R}^{m}, we can express the overall computational cost of the objective function in Sec. 3.3 as 𝒪​(d2+n2+m2)𝒪superscript𝑑2superscript𝑛2superscript𝑚2{\\mathcal{O}}(d^{2}+n^{2}+m^{2}).\nIf the perturbed gradient with concealed samples behaves dissimilar to that of the original gradient, then the computational cost of the gradient projection is around 𝒪​(d3)𝒪superscript𝑑3{\\mathcal{O}}(d^{3}).\nOn TinyImageNet, we observed that one round of updates with our method on an NVIDIA RTX A100 GPU takes approximately 172 seconds. In comparison, an update without any defenses requires around 102 seconds.Details of the models used in this study are shown in Tab. 6. The activation layers of the model for the MNIST dataset are Sigmoid, and for CIFAR10 and CelebA, TinyImageNet datasets are ReLU.\n\n\n\n\n\nMNIST\nCIFAR10/CelebA\nTinyImageNet\n\n\n\n5×5555\\times 5 Conv, 12\n5×5555\\times 5 Conv, 32\n7×7777\\times 7 Conv, 64\n\n5×5555\\times 5 Conv, 12\n{5×5​ Conv, 64}×2matrix55 Conv, 642\\begin{Bmatrix}5\\times 5\\text{ Conv, 64}\\end{Bmatrix}\\times 2\n3×3333\\times 3 MaxPool\n\n5×5555\\times 5 Conv, 12\n{5×5​ Conv, 128}×3matrix55 Conv, 1283\\begin{Bmatrix}5\\times 5\\text{ Conv, 128}\\end{Bmatrix}\\times 3\n{3×3​ Conv, 643×3​ Conv, 64}×2matrix33 Conv, 6433 Conv, 642\\begin{Bmatrix}3\\times 3\\text{ Conv, 64}\\\\\n3\\times 3\\text{ Conv, 64}\\end{Bmatrix}\\times 2\n\n5×5555\\times 5 Conv, 12\n3×3333\\times 3 MaxPool\n{3×3​ Conv, 1283×3​ Conv, 128}×2matrix33 Conv, 12833 Conv, 1282\\begin{Bmatrix}3\\times 3\\text{ Conv, 128}\\\\\n3\\times 3\\text{ Conv, 128}\\end{Bmatrix}\\times 2\n\nFC-10\n{5×5​ Conv, 128}×3matrix55 Conv, 1283\\begin{Bmatrix}5\\times 5\\text{ Conv, 128}\\end{Bmatrix}\\times 3\n{3×3​ Conv, 2563×3​ Conv, 256}×2matrix33 Conv, 25633 Conv, 2562\\begin{Bmatrix}3\\times 3\\text{ Conv, 256}\\\\\n3\\times 3\\text{ Conv, 256}\\end{Bmatrix}\\times 2\n\n\n3×3333\\times 3 MaxPool\n{3×3​ Conv, 5123×3​ Conv, 512}×2matrix33 Conv, 51233 Conv, 5122\\begin{Bmatrix}3\\times 3\\text{ Conv, 512}\\\\\n3\\times 3\\text{ Conv, 512}\\end{Bmatrix}\\times 2\n\n\nFC-10 (CIFAR10) / FC-2 (CelebA)\n7×7777\\times 7 AveragePool\n\n\n\nFC-200\n\n\nWe build on the repository using the official implementation of the GS, GGL, and Imprint attack methods.\nFor the defenses Soteria, Prune, and DP-Gaussian, we build on the repository from the study (Sun et al. 2021).\nFor the defense ATS, we build upon the repository from the study (Balunović et al. 2022).\nFor training, we apply SGD optimizer and set the learning rate for updating the local models η=0.01𝜂0.01\\eta=0.01 with exponential decay.\nThe pruning rate from the defense Prune is 0.9 for CIFAR10 and 0.7 for others.\nThe variance of noise distribution from the defense DP-Gaussian is 0.01 for MNIST, 0.5 for TinyImageNet, and 0.001 for others.\nThe pruning rate from the defense Soteria is 0.2 for MNIST, 0.5 for CIFAR10, 0.7 for CelebA, and 0.9 for TinyImageNet.\nOur method set ϵ=0.01italic-ϵ0.01\\epsilon=0.01, λg=0.7subscript𝜆𝑔0.7\\lambda_{g}=0.7, and the number of iteration as 1000 for all datasets, λx=0.01subscript𝜆𝑥0.01\\lambda_{x}=0.01 and λz=0.01subscript𝜆𝑧0.01\\lambda_{z}=0.01 for MNIST and CIFAR10, λx=0.01subscript𝜆𝑥0.01\\lambda_{x}=0.01 and λz=0.1subscript𝜆𝑧0.1\\lambda_{z}=0.1 for CelebA, λx=0.001subscript𝜆𝑥0.001\\lambda_{x}=0.001 and λz=0.01subscript𝜆𝑧0.01\\lambda_{z}=0.01 for TinyImageNet.\nThe weights of penalty terms in Eq. (9) are chosen to balance them or kept fixed across all experiments (e.g., ϵ=0.01italic-ϵ0.01\\epsilon=0.01 for all experiments.)\nIn our experiments, we opt for the entirety of the training data in the target client to be sensitive and generate one synthetic sample per sensitive datum (ratio 1:1).\nSSIM is 0.92 with an accuracy of 87% and 0.86 with an accuracy of 86.91% for ratios 10:1 and 5:1, respectively.\nWhile the protection becomes better, the model’s performance will drop.Consider a sensitive data point 𝒙ssubscript𝒙𝑠{\\bm{x}}_{s} (see Fig. 5 for an illustration), we aim to craft the concealed sample 𝒙~csubscript~𝒙𝑐\\tilde{{\\bm{x}}}_{c} which makes ∇𝜽ℒ​(f𝜽​(𝒙~c),𝒚~c)subscript∇𝜽ℒsubscript𝑓𝜽subscript~𝒙𝑐subscript~𝒚𝑐\\nabla_{{\\bm{\\theta}}}\\mathcal{L}(f_{{\\bm{\\theta}}}(\\tilde{{\\bm{x}}}_{c}),\\tilde{{\\bm{y}}}_{c}) approaching ∇𝜽ℒ​(f𝜽​(𝒙s),𝒚s)subscript∇𝜽ℒsubscript𝑓𝜽subscript𝒙𝑠subscript𝒚𝑠\\nabla_{{\\bm{\\theta}}}\\mathcal{L}(f_{{\\bm{\\theta}}}({\\bm{x}}_{s}),{\\bm{y}}_{s}).\nThis strategy obfuscates the sensitive samples, as the reconstruction by the adversary through the gradient will contain information from the concealed sample, which we aim to be visually different from the sensitive data.\n\n\n\n\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nATS\n19.68±plus-or-minus\\pm4.60\n0.59±plus-or-minus\\pm0.14\n67.99±plus-or-minus\\pm0.57\n75.70±plus-or-minus\\pm0.02\n\nDCS2superscriptDCS2\\text{DCS}^{2} (Ours)\n8.04±plus-or-minus\\pm1.10\n0.15±plus-or-minus\\pm0.05\n80.39±plus-or-minus\\pm0.07\n79.79±plus-or-minus\\pm0.03\n\n\n\n\n\n\n\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nNone\n57.50±plus-or-minus\\pm1.95\n1.00±plus-or-minus\\pm0.00\n89.84±plus-or-minus\\pm0.00\n76.60±plus-or-minus\\pm0.00\n\nDP-Gaussian\n34.73±plus-or-minus\\pm0.79\n0.83±plus-or-minus\\pm0.04\n83.59±plus-or-minus\\pm0.00\n75.75±plus-or-minus\\pm0.01\n\nPrune\n14.49±plus-or-minus\\pm1.81\n0.39±plus-or-minus\\pm0.05\n83.59±plus-or-minus\\pm0.00\n75.75±plus-or-minus\\pm0.00\n\nSoteria\n7.28±plus-or-minus\\pm0.60\n0.23±plus-or-minus\\pm0.04\n85.42±plus-or-minus\\pm0.00\n75.92±plus-or-minus\\pm0.01\n\nDCS2superscriptDCS2\\text{DCS}^{2} (Ours)\n7.27±plus-or-minus\\pm1.77\n0.16±plus-or-minus\\pm0.06\n89.32±plus-or-minus\\pm0.00\n75.19±plus-or-minus\\pm0.02\n\n\nWe evaluated the Imprint attack with the recently introduced dataset FACET (Gustafson et al. 2023) (Fig. 8 (a)). With our defense applied, the attack failed to perfectly reconstruct the data. The accuracy of the model on the test set w/o and w/ our defense is around 77.21% and 76.62%, respectively.Note that neither optimization-based attacks nor model modification attacks can precisely separate the gradient for individual data points.\nIn Fig. 8 (b), for instance, there are four ‘6’ within the batch; the gradients w.r.t. these images cannot be fully separated, and the GS attack fails to reconstruct the third image.\nBesides, similar to any defense mechanism, it is possible to identify the concealed samples.\nFor example, an adversary could potentially modify the model to reconstruct the concealed samples and use a filtering mechanism to identify them.\nOur model might become vulnerable if the adversary has extensive knowledge about the data and model as exemplified by the GGL attack (use partial training data to learn prior knowledge), or has the ability to modify model architecture as in the Imprint attack. Fig.2 and Fig. 8 (a) provide examples of GGL and Imprint attacks, where the attack managed to reconstruct facial outlines and vague information. It is important to note that model modification methods are generally identifiable and can be countered by vigilant clients.",
        "references": [
            []
        ]
    },
    "S4.T3": {
        "caption": "Table 3: DCS2superscriptDCS2\\text{DCS}^{2} with different λgsubscript𝜆𝑔\\lambda_{g} on TinyImageNet.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nλgsubscript𝜆𝑔\\lambda_{g}\nSSIM↓↓\\downarrow\nLPIPS↑↑\\uparrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\n0.5\n0.80±plus-or-minus\\pm0.20\n0.22±plus-or-minus\\pm0.21\n60.33±plus-or-minus\\pm0.71\n65.76±plus-or-minus\\pm0.04\n\n0.7\n0.79±plus-or-minus\\pm0.22\n0.22±plus-or-minus\\pm0.23\n59.88±plus-or-minus\\pm0.71\n65.68±plus-or-minus\\pm0.05\n\n1.0\n0.78±plus-or-minus\\pm0.22\n0.23±plus-or-minus\\pm0.23\n58.54±plus-or-minus\\pm0.46\n65.24±plus-or-minus\\pm0.21\n\n\n",
        "references": [
            []
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Different start points on MNIST.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nMNIST\nNoise\nMixUP\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\n✓\n✗\n✓\n7.97±plus-or-minus\\pm2.48\n0.18±plus-or-minus\\pm0.08\n86.56±plus-or-minus\\pm0.57\n86.99±plus-or-minus\\pm0.01\n\n✓\n✗\n✗\n7.84±plus-or-minus\\pm2.56\n0.17±plus-or-minus\\pm0.09\n86.98±plus-or-minus\\pm0.00\n86.98±plus-or-minus\\pm0.01\n\n✗\n✓\n✓\n7.69±plus-or-minus\\pm2.38\n0.18±plus-or-minus\\pm0.08\n86.98±plus-or-minus\\pm0.00\n86.99±plus-or-minus\\pm0.00\n\n✗\n✓\n✗\n7.40±plus-or-minus\\pm2.22\n0.16±plus-or-minus\\pm0.08\n85.94±plus-or-minus\\pm0.00\n86.94±plus-or-minus\\pm0.00\n\n\n",
        "references": [
            "Further, we compare different defenses for more complex datasets, with larger capacity networks, on CelebA and TinyImageNet, to defend against stronger attacks.\nWe use randomly initialized weights and use the attribute gender as the target label in CelebA to perform binary classification. A pre-trained ResNet18 was applied for TinyImageNet.\nAs shown in Table 4.1, our defense provides the best protection while competitively maintaining the original FL performance.\nSpecifically, on CelebA, defending against the GGL attack, our method provides the best protection, and the FL performance is even improved while defenses DP-Gaussian and Prune drop by around 0.5% on the test set.\nOn TinyImageNet, when defending against the Imprint attack, the defense Soteria cannot know where the adversary would insert the imprint module, so it cannot withstand the Imprint attack.\nWhile most defenses cannot provide protection, our defense method increases the LPIPS from 0.00 to 0.22."
        ]
    },
    "S4.T5": {
        "caption": "Table 5: Combination of defenses.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nPrune\n14.13±plus-or-minus\\pm2.29\n0.37±plus-or-minus\\pm0.06\n85.94±plus-or-minus\\pm0.00\n86.91±plus-or-minus\\pm0.00\n\nDCS2superscriptDCS2\\text{DCS}^{2}\n7.84±plus-or-minus\\pm2.56\n0.17±plus-or-minus\\pm0.09\n86.98±plus-or-minus\\pm0.00\n86.98±plus-or-minus\\pm0.01\n\nPrune&DCS2superscriptDCS2\\&\\text{DCS}^{2}\n6.08±plus-or-minus\\pm1.60\n0.12±plus-or-minus\\pm0.06\n86.15±plus-or-minus\\pm0.47\n86.92±plus-or-minus\\pm0.01\n\n\n",
        "references": [
            [
                "An illustration of combining ",
                "DCS",
                "2",
                "superscript",
                "DCS",
                "2",
                "\\text{DCS}^{2}",
                " with the defense ‘Prune’ is presented in ",
                "Tab.",
                " ",
                "5",
                ". In this scenario, the enhancement of protection for private training data is notable. While the performance experiences a slight decrease compared to the standalone proposed defense method, it still surpasses the performance of the defense ‘Prune’ alone."
            ]
        ]
    },
    "S8.T6": {
        "caption": "Table 6: Model architectures for different datasets.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nMNIST\nCIFAR10/CelebA\nTinyImageNet\n\n\n\n5×5555\\times 5 Conv, 12\n5×5555\\times 5 Conv, 32\n7×7777\\times 7 Conv, 64\n\n5×5555\\times 5 Conv, 12\n{5×5​ Conv, 64}×2matrix55 Conv, 642\\begin{Bmatrix}5\\times 5\\text{ Conv, 64}\\end{Bmatrix}\\times 2\n3×3333\\times 3 MaxPool\n\n5×5555\\times 5 Conv, 12\n{5×5​ Conv, 128}×3matrix55 Conv, 1283\\begin{Bmatrix}5\\times 5\\text{ Conv, 128}\\end{Bmatrix}\\times 3\n{3×3​ Conv, 643×3​ Conv, 64}×2matrix33 Conv, 6433 Conv, 642\\begin{Bmatrix}3\\times 3\\text{ Conv, 64}\\\\\n3\\times 3\\text{ Conv, 64}\\end{Bmatrix}\\times 2\n\n5×5555\\times 5 Conv, 12\n3×3333\\times 3 MaxPool\n{3×3​ Conv, 1283×3​ Conv, 128}×2matrix33 Conv, 12833 Conv, 1282\\begin{Bmatrix}3\\times 3\\text{ Conv, 128}\\\\\n3\\times 3\\text{ Conv, 128}\\end{Bmatrix}\\times 2\n\nFC-10\n{5×5​ Conv, 128}×3matrix55 Conv, 1283\\begin{Bmatrix}5\\times 5\\text{ Conv, 128}\\end{Bmatrix}\\times 3\n{3×3​ Conv, 2563×3​ Conv, 256}×2matrix33 Conv, 25633 Conv, 2562\\begin{Bmatrix}3\\times 3\\text{ Conv, 256}\\\\\n3\\times 3\\text{ Conv, 256}\\end{Bmatrix}\\times 2\n\n\n3×3333\\times 3 MaxPool\n{3×3​ Conv, 5123×3​ Conv, 512}×2matrix33 Conv, 51233 Conv, 5122\\begin{Bmatrix}3\\times 3\\text{ Conv, 512}\\\\\n3\\times 3\\text{ Conv, 512}\\end{Bmatrix}\\times 2\n\n\nFC-10 (CIFAR10) / FC-2 (CelebA)\n7×7777\\times 7 AveragePool\n\n\n\nFC-200\n\n\n",
        "references": [
            [
                "Details of the models used in this study are shown in ",
                "Tab.",
                " ",
                "6",
                ". The activation layers of the model for the MNIST dataset are Sigmoid, and for CIFAR10 and CelebA, TinyImageNet datasets are ReLU."
            ]
        ]
    },
    "S8.T7": {
        "caption": "Table 7: Defenses against GS attack on CIFAR10. ATS applies data augmentations and here it needs to run for extra 50 rounds to converge.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nATS\n19.68±plus-or-minus\\pm4.60\n0.59±plus-or-minus\\pm0.14\n67.99±plus-or-minus\\pm0.57\n75.70±plus-or-minus\\pm0.02\n\nDCS2superscriptDCS2\\text{DCS}^{2} (Ours)\n8.04±plus-or-minus\\pm1.10\n0.15±plus-or-minus\\pm0.05\n80.39±plus-or-minus\\pm0.07\n79.79±plus-or-minus\\pm0.03\n\n\n",
        "references": [
            [
                "We evaluated the Imprint attack with the recently introduced dataset FACET ",
                "(Gustafson et al. ",
                "2023",
                ")",
                " (",
                "Fig.",
                " ",
                "8",
                " (a)). With our defense applied, the attack failed to perfectly reconstruct the data. The accuracy of the model on the test set ",
                "w/o",
                " and ",
                "w/",
                " our defense is around 77.21% and 76.62%, respectively.",
                "Note that neither optimization-based attacks nor model modification attacks can precisely separate the gradient for individual data points.\nIn ",
                "Fig.",
                " ",
                "8",
                " (b), for instance, there are four ‘6’ within the batch; the gradients w.r.t.",
                " these images cannot be fully separated, and the GS attack fails to reconstruct the third image.\nBesides, similar to any defense mechanism, it is possible to identify the concealed samples.\nFor example, an adversary could potentially modify the model to reconstruct the concealed samples and use a filtering mechanism to identify them.\nOur model might become vulnerable if the adversary has extensive knowledge about the data and model as exemplified by the GGL attack (use partial training data to learn prior knowledge), or has the ability to modify model architecture as in the Imprint attack. Fig.2 and ",
                "Fig.",
                " ",
                "8",
                " (a) provide examples of GGL and Imprint attacks, where the attack managed to reconstruct facial outlines and vague information. It is important to note that model modification methods are generally identifiable and can be countered by vigilant clients."
            ]
        ]
    },
    "S8.T8": {
        "caption": "Table 8: Against GS attack on MNIST on Non-IID setting. Non-IID data indeed presents additional challenges to training.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nDefense\nPSNR↓↓\\downarrow\nSSIM↓↓\\downarrow\nAcc↑↑\\uparrow (Sensitive Data)\nAcc↑↑\\uparrow (Test set)\n\n\n\nNone\n57.50±plus-or-minus\\pm1.95\n1.00±plus-or-minus\\pm0.00\n89.84±plus-or-minus\\pm0.00\n76.60±plus-or-minus\\pm0.00\n\nDP-Gaussian\n34.73±plus-or-minus\\pm0.79\n0.83±plus-or-minus\\pm0.04\n83.59±plus-or-minus\\pm0.00\n75.75±plus-or-minus\\pm0.01\n\nPrune\n14.49±plus-or-minus\\pm1.81\n0.39±plus-or-minus\\pm0.05\n83.59±plus-or-minus\\pm0.00\n75.75±plus-or-minus\\pm0.00\n\nSoteria\n7.28±plus-or-minus\\pm0.60\n0.23±plus-or-minus\\pm0.04\n85.42±plus-or-minus\\pm0.00\n75.92±plus-or-minus\\pm0.01\n\nDCS2superscriptDCS2\\text{DCS}^{2} (Ours)\n7.27±plus-or-minus\\pm1.77\n0.16±plus-or-minus\\pm0.06\n89.32±plus-or-minus\\pm0.00\n75.19±plus-or-minus\\pm0.02\n\n\n",
        "references": [
            [
                "We evaluated the Imprint attack with the recently introduced dataset FACET ",
                "(Gustafson et al. ",
                "2023",
                ")",
                " (",
                "Fig.",
                " ",
                "8",
                " (a)). With our defense applied, the attack failed to perfectly reconstruct the data. The accuracy of the model on the test set ",
                "w/o",
                " and ",
                "w/",
                " our defense is around 77.21% and 76.62%, respectively.",
                "Note that neither optimization-based attacks nor model modification attacks can precisely separate the gradient for individual data points.\nIn ",
                "Fig.",
                " ",
                "8",
                " (b), for instance, there are four ‘6’ within the batch; the gradients w.r.t.",
                " these images cannot be fully separated, and the GS attack fails to reconstruct the third image.\nBesides, similar to any defense mechanism, it is possible to identify the concealed samples.\nFor example, an adversary could potentially modify the model to reconstruct the concealed samples and use a filtering mechanism to identify them.\nOur model might become vulnerable if the adversary has extensive knowledge about the data and model as exemplified by the GGL attack (use partial training data to learn prior knowledge), or has the ability to modify model architecture as in the Imprint attack. Fig.2 and ",
                "Fig.",
                " ",
                "8",
                " (a) provide examples of GGL and Imprint attacks, where the attack managed to reconstruct facial outlines and vague information. It is important to note that model modification methods are generally identifiable and can be countered by vigilant clients."
            ]
        ]
    },
    "S8.T9": {
        "caption": "Table 9: Defend against adaptive attacks on MNIST.",
        "table": "<table id=\"S8.T9.13\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S8.T9.1.1\" class=\"ltx_tr\">\n<th id=\"S8.T9.1.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></th>\n<th id=\"S8.T9.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">None</th>\n<th id=\"S8.T9.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">DP-Gaussian</th>\n<th id=\"S8.T9.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Prune</th>\n<th id=\"S8.T9.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Soteria</th>\n<th id=\"S8.T9.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S8.T9.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\text{DCS}^{2}\" display=\"inline\"><semantics id=\"S8.T9.1.1.1.m1.1a\"><msup id=\"S8.T9.1.1.1.m1.1.1\" xref=\"S8.T9.1.1.1.m1.1.1.cmml\"><mtext id=\"S8.T9.1.1.1.m1.1.1.2\" xref=\"S8.T9.1.1.1.m1.1.1.2a.cmml\">DCS</mtext><mn id=\"S8.T9.1.1.1.m1.1.1.3\" xref=\"S8.T9.1.1.1.m1.1.1.3.cmml\">2</mn></msup><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.1.1.1.m1.1b\"><apply id=\"S8.T9.1.1.1.m1.1.1.cmml\" xref=\"S8.T9.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S8.T9.1.1.1.m1.1.1.1.cmml\" xref=\"S8.T9.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"S8.T9.1.1.1.m1.1.1.2a.cmml\" xref=\"S8.T9.1.1.1.m1.1.1.2\"><mtext id=\"S8.T9.1.1.1.m1.1.1.2.cmml\" xref=\"S8.T9.1.1.1.m1.1.1.2\">DCS</mtext></ci><cn type=\"integer\" id=\"S8.T9.1.1.1.m1.1.1.3.cmml\" xref=\"S8.T9.1.1.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.1.1.1.m1.1c\">\\text{DCS}^{2}</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S8.T9.7.7\" class=\"ltx_tr\">\n<th id=\"S8.T9.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">PSNR<math id=\"S8.T9.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S8.T9.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S8.T9.2.2.1.m1.1.1\" xref=\"S8.T9.2.2.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.2.2.1.m1.1b\"><ci id=\"S8.T9.2.2.1.m1.1.1.cmml\" xref=\"S8.T9.2.2.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.2.2.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<td id=\"S8.T9.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">59.22<math id=\"S8.T9.3.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S8.T9.3.3.2.m1.1a\"><mo id=\"S8.T9.3.3.2.m1.1.1\" xref=\"S8.T9.3.3.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.3.3.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S8.T9.3.3.2.m1.1.1.cmml\" xref=\"S8.T9.3.3.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.3.3.2.m1.1c\">\\pm</annotation></semantics></math>2.71</td>\n<td id=\"S8.T9.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">35.28<math id=\"S8.T9.4.4.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S8.T9.4.4.3.m1.1a\"><mo id=\"S8.T9.4.4.3.m1.1.1\" xref=\"S8.T9.4.4.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.4.4.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S8.T9.4.4.3.m1.1.1.cmml\" xref=\"S8.T9.4.4.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.4.4.3.m1.1c\">\\pm</annotation></semantics></math>2.50</td>\n<td id=\"S8.T9.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">14.23<math id=\"S8.T9.5.5.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S8.T9.5.5.4.m1.1a\"><mo id=\"S8.T9.5.5.4.m1.1.1\" xref=\"S8.T9.5.5.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.5.5.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S8.T9.5.5.4.m1.1.1.cmml\" xref=\"S8.T9.5.5.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.5.5.4.m1.1c\">\\pm</annotation></semantics></math>2.23</td>\n<td id=\"S8.T9.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">9.94<math id=\"S8.T9.6.6.5.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S8.T9.6.6.5.m1.1a\"><mo id=\"S8.T9.6.6.5.m1.1.1\" xref=\"S8.T9.6.6.5.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.6.6.5.m1.1b\"><csymbol cd=\"latexml\" id=\"S8.T9.6.6.5.m1.1.1.cmml\" xref=\"S8.T9.6.6.5.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.6.6.5.m1.1c\">\\pm</annotation></semantics></math>1.10</td>\n<td id=\"S8.T9.7.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S8.T9.7.7.6.1\" class=\"ltx_text ltx_font_bold\">7.87<math id=\"S8.T9.7.7.6.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S8.T9.7.7.6.1.m1.1a\"><mo id=\"S8.T9.7.7.6.1.m1.1.1\" xref=\"S8.T9.7.7.6.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.7.7.6.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S8.T9.7.7.6.1.m1.1.1.cmml\" xref=\"S8.T9.7.7.6.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.7.7.6.1.m1.1c\">\\pm</annotation></semantics></math>2.44</span></td>\n</tr>\n<tr id=\"S8.T9.13.13\" class=\"ltx_tr\">\n<th id=\"S8.T9.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">SSIM<math id=\"S8.T9.8.8.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S8.T9.8.8.1.m1.1a\"><mo stretchy=\"false\" id=\"S8.T9.8.8.1.m1.1.1\" xref=\"S8.T9.8.8.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.8.8.1.m1.1b\"><ci id=\"S8.T9.8.8.1.m1.1.1.cmml\" xref=\"S8.T9.8.8.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.8.8.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<td id=\"S8.T9.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1.00<math id=\"S8.T9.9.9.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S8.T9.9.9.2.m1.1a\"><mo id=\"S8.T9.9.9.2.m1.1.1\" xref=\"S8.T9.9.9.2.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.9.9.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S8.T9.9.9.2.m1.1.1.cmml\" xref=\"S8.T9.9.9.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.9.9.2.m1.1c\">\\pm</annotation></semantics></math>4.77</td>\n<td id=\"S8.T9.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.82<math id=\"S8.T9.10.10.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S8.T9.10.10.3.m1.1a\"><mo id=\"S8.T9.10.10.3.m1.1.1\" xref=\"S8.T9.10.10.3.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.10.10.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S8.T9.10.10.3.m1.1.1.cmml\" xref=\"S8.T9.10.10.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.10.10.3.m1.1c\">\\pm</annotation></semantics></math>0.07</td>\n<td id=\"S8.T9.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.37<math id=\"S8.T9.11.11.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S8.T9.11.11.4.m1.1a\"><mo id=\"S8.T9.11.11.4.m1.1.1\" xref=\"S8.T9.11.11.4.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.11.11.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S8.T9.11.11.4.m1.1.1.cmml\" xref=\"S8.T9.11.11.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.11.11.4.m1.1c\">\\pm</annotation></semantics></math>0.06</td>\n<td id=\"S8.T9.12.12.5\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">0.31<math id=\"S8.T9.12.12.5.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S8.T9.12.12.5.m1.1a\"><mo id=\"S8.T9.12.12.5.m1.1.1\" xref=\"S8.T9.12.12.5.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.12.12.5.m1.1b\"><csymbol cd=\"latexml\" id=\"S8.T9.12.12.5.m1.1.1.cmml\" xref=\"S8.T9.12.12.5.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.12.12.5.m1.1c\">\\pm</annotation></semantics></math>0.07</td>\n<td id=\"S8.T9.13.13.6\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span id=\"S8.T9.13.13.6.1\" class=\"ltx_text ltx_font_bold\">0.18<math id=\"S8.T9.13.13.6.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S8.T9.13.13.6.1.m1.1a\"><mo id=\"S8.T9.13.13.6.1.m1.1.1\" xref=\"S8.T9.13.13.6.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S8.T9.13.13.6.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S8.T9.13.13.6.1.m1.1.1.cmml\" xref=\"S8.T9.13.13.6.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S8.T9.13.13.6.1.m1.1c\">\\pm</annotation></semantics></math>0.09</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We evaluated the Imprint attack with the recently introduced dataset FACET ",
                "(Gustafson et al. ",
                "2023",
                ")",
                " (",
                "Fig.",
                " ",
                "8",
                " (a)). With our defense applied, the attack failed to perfectly reconstruct the data. The accuracy of the model on the test set ",
                "w/o",
                " and ",
                "w/",
                " our defense is around 77.21% and 76.62%, respectively.",
                "Note that neither optimization-based attacks nor model modification attacks can precisely separate the gradient for individual data points.\nIn ",
                "Fig.",
                " ",
                "8",
                " (b), for instance, there are four ‘6’ within the batch; the gradients w.r.t.",
                " these images cannot be fully separated, and the GS attack fails to reconstruct the third image.\nBesides, similar to any defense mechanism, it is possible to identify the concealed samples.\nFor example, an adversary could potentially modify the model to reconstruct the concealed samples and use a filtering mechanism to identify them.\nOur model might become vulnerable if the adversary has extensive knowledge about the data and model as exemplified by the GGL attack (use partial training data to learn prior knowledge), or has the ability to modify model architecture as in the Imprint attack. Fig.2 and ",
                "Fig.",
                " ",
                "8",
                " (a) provide examples of GGL and Imprint attacks, where the attack managed to reconstruct facial outlines and vague information. It is important to note that model modification methods are generally identifiable and can be countered by vigilant clients."
            ]
        ]
    }
}