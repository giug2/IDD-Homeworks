{
    "PAPER'S NUMBER OF TABLES": 5,
    "S1.T1": {
        "caption": "Table 1: Summary of the State of the Art Federated Learning Methods",
        "table": "<table id=\"S1.T1.1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S1.T1.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S1.T1.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Paper</span></th>\n<td id=\"S1.T1.1.1.2.1.2\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Client</span></td>\n<td id=\"S1.T1.1.1.2.1.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.2.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Aggregation</span></td>\n<td id=\"S1.T1.1.1.2.1.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Loss</span></td>\n<td id=\"S1.T1.1.1.2.1.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.2.1.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Information</span></td>\n<td id=\"S1.T1.1.1.2.1.6\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.2.1.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Model</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S1.T1.1.1.3.2.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">[Year]</span></th>\n<td id=\"S1.T1.1.1.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.3.2.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Selection</span></td>\n<td id=\"S1.T1.1.1.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">function</span></td>\n<td id=\"S1.T1.1.1.3.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">function</span></td>\n<td id=\"S1.T1.1.1.3.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.3.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Exchanged</span></td>\n<td id=\"S1.T1.1.1.3.2.6\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S1.T1.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">\n<span id=\"S1.T1.1.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedAvg </span><cite class=\"ltx_cite ltx_citemacro_cite\">McMahan <span class=\"ltx_text ltx_font_italic\">et al.</span> <span id=\"S1.T1.1.1.4.3.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(</span><a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2016</a><span id=\"S1.T1.1.1.4.3.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td id=\"S1.T1.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S1.T1.1.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Random</span></td>\n<td id=\"S1.T1.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S1.T1.1.1.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Avg</span></td>\n<td id=\"S1.T1.1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S1.T1.1.1.4.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S1.T1.1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S1.T1.1.1.4.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></td>\n<td id=\"S1.T1.1.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S1.T1.1.1.4.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">\n<span id=\"S1.T1.1.1.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedProx </span><cite class=\"ltx_cite ltx_citemacro_cite\">Sahu <span class=\"ltx_text ltx_font_italic\">et al.</span> <span id=\"S1.T1.1.1.5.4.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(</span><a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">2018</a><span id=\"S1.T1.1.1.5.4.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td id=\"S1.T1.1.1.5.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Random</span></td>\n<td id=\"S1.T1.1.1.5.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.5.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Avg</span></td>\n<td id=\"S1.T1.1.1.5.4.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.5.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Custom</span></td>\n<td id=\"S1.T1.1.1.5.4.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.5.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></td>\n<td id=\"S1.T1.1.1.5.4.6\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.5.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">Zhao <span class=\"ltx_text ltx_font_italic\">et al.</span> <span id=\"S1.T1.1.1.6.5.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(</span><a href=\"#bib.bib16\" title=\"\" class=\"ltx_ref\">2018</a><span id=\"S1.T1.1.1.6.5.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite></th>\n<td id=\"S1.T1.1.1.6.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Random</span></td>\n<td id=\"S1.T1.1.1.6.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.6.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Avg</span></td>\n<td id=\"S1.T1.1.1.6.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.6.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S1.T1.1.1.6.5.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.6.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model+Data(S2C)</span></td>\n<td id=\"S1.T1.1.1.6.5.6\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.6.5.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">Anil <span class=\"ltx_text ltx_font_italic\">et al.</span> <span id=\"S1.T1.1.1.7.6.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(</span><a href=\"#bib.bib1\" title=\"\" class=\"ltx_ref\">2018</a><span id=\"S1.T1.1.1.7.6.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite></th>\n<td id=\"S1.T1.1.1.7.6.2\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.7.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Random</span></td>\n<td id=\"S1.T1.1.1.7.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.7.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S1.T1.1.1.7.6.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.7.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Distillation</span></td>\n<td id=\"S1.T1.1.1.7.6.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.7.6.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></td>\n<td id=\"S1.T1.1.1.7.6.6\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.7.6.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">Jeong <span class=\"ltx_text ltx_font_italic\">et al.</span> <span id=\"S1.T1.1.1.1.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(</span><a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">2018</a><span id=\"S1.T1.1.1.1.2.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite></th>\n<td id=\"S1.T1.1.1.1.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">All</span></td>\n<td id=\"S1.T1.1.1.1.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Avg</span></td>\n<td id=\"S1.T1.1.1.1.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Distillation</span></td>\n<td id=\"S1.T1.1.1.1.1\" class=\"ltx_td ltx_align_center\">\n<span id=\"S1.T1.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Each class 1 vector</span><math id=\"S1.T1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\star\" display=\"inline\"><semantics id=\"S1.T1.1.1.1.1.m1.1a\"><mo mathsize=\"90%\" id=\"S1.T1.1.1.1.1.m1.1.1\" xref=\"S1.T1.1.1.1.1.m1.1.1.cmml\">⋆</mo><annotation-xml encoding=\"MathML-Content\" id=\"S1.T1.1.1.1.1.m1.1b\"><ci id=\"S1.T1.1.1.1.1.m1.1.1.cmml\" xref=\"S1.T1.1.1.1.1.m1.1.1\">⋆</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T1.1.1.1.1.m1.1c\">\\star</annotation></semantics></math>\n</td>\n<td id=\"S1.T1.1.1.1.6\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.8.7\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">\n<span id=\"S1.T1.1.1.8.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Agnos </span><cite class=\"ltx_cite ltx_citemacro_cite\">Mohri <span class=\"ltx_text ltx_font_italic\">et al.</span> <span id=\"S1.T1.1.1.8.7.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(</span><a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">2019</a><span id=\"S1.T1.1.1.8.7.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td id=\"S1.T1.1.1.8.7.2\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.8.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S1.T1.1.1.8.7.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.8.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Avg</span></td>\n<td id=\"S1.T1.1.1.8.7.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.8.7.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Custom</span></td>\n<td id=\"S1.T1.1.1.8.7.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.8.7.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Distribution Update</span></td>\n<td id=\"S1.T1.1.1.8.7.6\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.8.7.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.9.8\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">\n<span id=\"S1.T1.1.1.9.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">LG </span><cite class=\"ltx_cite ltx_citemacro_cite\">Liang <span class=\"ltx_text ltx_font_italic\">et al.</span> <span id=\"S1.T1.1.1.9.8.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(</span><a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">2019</a><span id=\"S1.T1.1.1.9.8.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td id=\"S1.T1.1.1.9.8.2\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.9.8.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Random</span></td>\n<td id=\"S1.T1.1.1.9.8.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.9.8.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Avg</span></td>\n<td id=\"S1.T1.1.1.9.8.4\" class=\"ltx_td ltx_align_center\">\n<span id=\"S1.T1.1.1.9.8.4.1\" class=\"ltx_inline-block\">\n<span id=\"S1.T1.1.1.9.8.4.1.1\" class=\"ltx_p\"><span id=\"S1.T1.1.1.9.8.4.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Softmax+</span></span>\n<span id=\"S1.T1.1.1.9.8.4.1.2\" class=\"ltx_p\"><span id=\"S1.T1.1.1.9.8.4.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">feature learning</span></span>\n</span>\n</td>\n<td id=\"S1.T1.1.1.9.8.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.9.8.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">partial model</span></td>\n<td id=\"S1.T1.1.1.9.8.6\" class=\"ltx_td ltx_align_center\">\n<span id=\"S1.T1.1.1.9.8.6.1\" class=\"ltx_inline-block\">\n<span id=\"S1.T1.1.1.9.8.6.1.1\" class=\"ltx_p\"><span id=\"S1.T1.1.1.9.8.6.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Feature Extractor +</span></span>\n<span id=\"S1.T1.1.1.9.8.6.1.2\" class=\"ltx_p\"><span id=\"S1.T1.1.1.9.8.6.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Class Predictor</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S1.T1.1.1.10.9\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">Sattler <span class=\"ltx_text ltx_font_italic\">et al.</span> <span id=\"S1.T1.1.1.10.9.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(</span><a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2019</a><span id=\"S1.T1.1.1.10.9.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite></th>\n<td id=\"S1.T1.1.1.10.9.2\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.10.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Clustering</span></td>\n<td id=\"S1.T1.1.1.10.9.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.10.9.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Avg</span></td>\n<td id=\"S1.T1.1.1.10.9.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.10.9.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S1.T1.1.1.10.9.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.10.9.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></td>\n<td id=\"S1.T1.1.1.10.9.6\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.10.9.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.11.10\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.11.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">\n<span id=\"S1.T1.1.1.11.10.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">q-FFL</span><cite class=\"ltx_cite ltx_citemacro_cite\">Li <span class=\"ltx_text ltx_font_italic\">et al.</span> <span id=\"S1.T1.1.1.11.10.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(</span><a href=\"#bib.bib8\" title=\"\" class=\"ltx_ref\">2019</a><span id=\"S1.T1.1.1.11.10.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td id=\"S1.T1.1.1.11.10.2\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.11.10.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Random</span></td>\n<td id=\"S1.T1.1.1.11.10.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.11.10.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Reweight Avg</span></td>\n<td id=\"S1.T1.1.1.11.10.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.11.10.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S1.T1.1.1.11.10.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.11.10.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model+qValue</span></td>\n<td id=\"S1.T1.1.1.11.10.6\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.11.10.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.12.11\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.12.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">Izbicki and Shelton <span id=\"S1.T1.1.1.12.11.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(</span><a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">2019</a><span id=\"S1.T1.1.1.12.11.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite></th>\n<td id=\"S1.T1.1.1.12.11.2\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.12.11.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S1.T1.1.1.12.11.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.12.11.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Reweight Avg</span></td>\n<td id=\"S1.T1.1.1.12.11.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.12.11.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S1.T1.1.1.12.11.5\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.12.11.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></td>\n<td id=\"S1.T1.1.1.12.11.6\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.1.1.12.11.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr id=\"S1.T1.1.1.13.12\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.13.12.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><em id=\"S1.T1.1.1.13.12.1.1\" class=\"ltx_emph ltx_font_italic\" style=\"font-size:90%;\">this paper</em></th>\n<td id=\"S1.T1.1.1.13.12.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><em id=\"S1.T1.1.1.13.12.2.1\" class=\"ltx_emph ltx_font_italic\" style=\"font-size:90%;\">Random</em></td>\n<td id=\"S1.T1.1.1.13.12.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><em id=\"S1.T1.1.1.13.12.3.1\" class=\"ltx_emph ltx_font_italic\" style=\"font-size:90%;\">Avg</em></td>\n<td id=\"S1.T1.1.1.13.12.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S1.T1.1.1.13.12.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S1.T1.1.1.13.12.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><em id=\"S1.T1.1.1.13.12.5.1\" class=\"ltx_emph ltx_font_italic\" style=\"font-size:90%;\">generic parameters</em></td>\n<td id=\"S1.T1.1.1.13.12.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><em id=\"S1.T1.1.1.13.12.6.1\" class=\"ltx_emph ltx_font_italic\" style=\"font-size:90%;\">generic + specific</em></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Machine learning and particularly Neural Network (NN) models are now tremendously popular to solve computer vision, natural language processing and networking problems. Proper ",
                "model training in centralized settings",
                " is not without challenges. On the one hand, centralized training raises data sharing concerns, both in terms of transfer volumes and data privacy – which in European countries is very critical due to the recent stringent regulation on private data protection (GDPR).\nOn the other hand, model training on individual datasets helps solving data sharing concerns, yet generates portability/generalization issues.\nTo circumvent the above concerns, ",
                "McMahan ",
                "et al.",
                " (",
                "2016",
                ")",
                " introduced the notion of ",
                "Federated Learning (FL)",
                ", that has a number of appealing properties. First and foremost, FL allows for collaboratively training the model, without having to share the data. Second, sharing models allow additionally to save significant data transfer volume, yielding beneficial cost reduction in cloud-based models (as charging also depends on data transfer). Third, distributed training also reinforces the generalization capabilities of the model.",
                "However, FL is not without downsides.\nFirst and foremost, even (0) sharing models can be a sensitive issue, either due to the presence of multiple stackholders, or due to stringent regulation. Additionally, in practical deployment scenarios data exhibit properties such as (1) Class imbalance, (2) Disjoint class distribution and (3) Signal multi-modality within each class across datasets,\nwhich lead to model divergence and could limit the practical relevance of FL models.\nTo make FL viable in presence of (0) model sharing constraints, while at the same time handling the above (1)-(3) data characteristics, we propose in this paper a novel method where clients are not only able to benefit from model sharing, but also and especially retain the ability to ",
                "keep secret",
                " and ",
                "specialize",
                " part of their model, to respectively handle problems (0) and (1)-(3).\nWe argue this can be achieved by ",
                "divide et impera",
                ": in a nutshell, in the NN architecture we isolate a common generic parameters from the client-specific parameters, and treat them differently in the distributed training process.\nIn particular, we propose that each client keeps a private and independent classifier, while sharing the common feature extraction process by averaging the generic parameters: so doing, clients benefit by the global learning process, whilst being able to keep their own (private) differences at the same time.",
                "We perform a thorough performance evaluation of our proposed Heterogeneous Data Aware Federated Learning (HDAFL) approach, contrasting it with the classic benchmark in the state of the art, namely ",
                "McMahan ",
                "et al.",
                " (",
                "2016",
                ")",
                ". We leverage different datasets, including the classic FEMNIST dataset, which exhibits characteristics (1)-(2), as well as very large proprietary dataset for TCP/IP traffic classification which which exhibits characteristics (1)-(3). Results show that HDAFL improves the local and global system accuracy, even slightly reducing the volume of information exchanged, which makes FL of practical relevance in real-world situations.",
                "In the rest of this paper, we overview the related work (Sec 2), and contextualize our applications and dataset (Sec 3). We next outline our method (Sec 4), contrast its performance with the state of the art (Sec 5) and summarize our findings (Sec 6)."
            ]
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Datasets at a glance.",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Application</span></th>\n<td id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S3.T2.1.1.1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T2.1.1.1.2.1.1\" class=\"ltx_p\"><span id=\"S3.T2.1.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Image</span></span>\n<span id=\"S3.T2.1.1.1.2.1.2\" class=\"ltx_p\"><span id=\"S3.T2.1.1.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">recognition</span></span>\n</span>\n</td>\n<td id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center\">\n<span id=\"S3.T2.1.1.1.3.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T2.1.1.1.3.1.1\" class=\"ltx_p\"><span id=\"S3.T2.1.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Traffic</span></span>\n<span id=\"S3.T2.1.1.1.3.1.2\" class=\"ltx_p\"><span id=\"S3.T2.1.1.1.3.1.2.1\" class=\"ltx_text ltx_font_bold\">classification</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Dataset</th>\n<td id=\"S3.T2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">FEMNIST</td>\n<td id=\"S3.T2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Huawei</td>\n</tr>\n<tr id=\"S3.T2.1.3.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Availability</th>\n<td id=\"S3.T2.1.3.3.2\" class=\"ltx_td ltx_align_center\">Public</td>\n<td id=\"S3.T2.1.3.3.3\" class=\"ltx_td ltx_align_center\">Proprietary</td>\n</tr>\n<tr id=\"S3.T2.1.4.4\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Samples</th>\n<td id=\"S3.T2.1.4.4.2\" class=\"ltx_td ltx_align_center\">805k</td>\n<td id=\"S3.T2.1.4.4.3\" class=\"ltx_td ltx_align_center\">1.9M</td>\n</tr>\n<tr id=\"S3.T2.1.5.5\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Sources</th>\n<td id=\"S3.T2.1.5.5.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S3.T2.1.5.5.2.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T2.1.5.5.2.1.1\" class=\"ltx_p\">3.5k</span>\n<span id=\"S3.T2.1.5.5.2.1.2\" class=\"ltx_p\">writers</span>\n</span>\n</td>\n<td id=\"S3.T2.1.5.5.3\" class=\"ltx_td ltx_align_center\">\n<span id=\"S3.T2.1.5.5.3.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T2.1.5.5.3.1.1\" class=\"ltx_p\">2</span>\n<span id=\"S3.T2.1.5.5.3.1.2\" class=\"ltx_p\">networks</span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T2.1.6.6\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">Classes</th>\n<td id=\"S3.T2.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_b\">62</td>\n<td id=\"S3.T2.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_b\">35</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We leverage a large proprietary dataset, collected at two different clients representative of Home and Enterprise business respectively, for the purpose of network traffic classification, which is a key function of network traffic management.\nClass labels represent fine-grained Internet applications, while input signal are timeseries of the size of the first 10 packets, which are known to have a high discriminative power for the classification task by  ",
                "Crotti ",
                "et al.",
                " (",
                "2007",
                ")",
                " and be amenable to real-time inference by ",
                "Santiago ",
                "et al.",
                " (",
                "2012",
                ")",
                ", and are well suited as input of a 1D-CNN architecture. This dataset represent a different operational point as it has more than twice of the samples and about half of the classes than FEMNIST.",
                "Network traffic comes from two different environment: namely home users’ households vs enterprise business, that can be considered as clients in the FL terminology. This client mixture explains non i.i.d properties of the data: the top plot of Fig.",
                "1",
                " depicts 10 samples showing that, as expected, some applications are prevalent in the enterprise environment (such as Skype for business, ExpressVPN, NetBIOS, etc.) while others are exclusively present in the home environment (such as SopCast) so that class labels are even ",
                "disjoint",
                " in the two networks.",
                "Further, from Fig.",
                "1",
                "-(bottom) notice that applications present in both datasets (DouYouTV in the example) can further exhibit signal multi-modality, as clearly shown in the heatmap of the signal component (y-axis, color encodes the size and direction of the first 10 packets from bottom to top) for different traffic samples (x-axis) in the Home vs Enterprise clients.\nMulti-modality is related to the physics of the underlying network and its interaction with specific applications: e.g., for some applications, different environments tied to specific network technologies (e.g., access type, encapsulations) and configuration (e.g., firewalls, NATs) trigger different behavioral modes, which yield to specific and non portable signatures.\nWhile this is perfectly normal and not done on purpose (e.g., to try to “evade” traffic classification), the resulting effect on training can be seen as adversarial with respect to what discussed in ",
                "Sattler ",
                "et al.",
                " (",
                "2019",
                "); Zhao ",
                "et al.",
                " (",
                "2018",
                ")",
                ", and need to be dealt with."
            ]
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Accuracy results on FEMNIST dataset at 400 rounds of communications for the three experimental settings.",
        "table": "<table id=\"S5.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.1.1\" class=\"ltx_tr\" style=\"background-color:#E6E6E6;\">\n<th id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" colspan=\"2\"><span id=\"S5.T3.1.1.1.1.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Experimental</span></th>\n<td id=\"S5.T3.1.1.1.2\" class=\"ltx_td ltx_align_center\" colspan=\"3\"><span id=\"S5.T3.1.1.1.2.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Client selected</span></td>\n</tr>\n<tr id=\"S5.T3.1.2.2\" class=\"ltx_tr\" style=\"background-color:#E6E6E6;\">\n<th id=\"S5.T3.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T3.1.2.2.1.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Settings</span></th>\n<th id=\"S5.T3.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S5.T3.1.2.2.2.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Method</span></th>\n<td id=\"S5.T3.1.2.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.2.2.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">10</span></td>\n<td id=\"S5.T3.1.2.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.2.2.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">20</span></td>\n<td id=\"S5.T3.1.2.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.2.2.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">50</span></td>\n</tr>\n<tr id=\"S5.T3.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">i.i.d</th>\n<th id=\"S5.T3.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">HDAFL</th>\n<td id=\"S5.T3.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">74.90</td>\n<td id=\"S5.T3.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">75.37</td>\n<td id=\"S5.T3.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">75.89</td>\n</tr>\n<tr id=\"S5.T3.1.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.4.4.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S5.T3.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">FedAvg</th>\n<td id=\"S5.T3.1.4.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.4.4.3.1\" class=\"ltx_text ltx_font_bold\">78.26</span></td>\n<td id=\"S5.T3.1.4.4.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.4.4.4.1\" class=\"ltx_text ltx_font_bold\">79.00</span></td>\n<td id=\"S5.T3.1.4.4.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.4.4.5.1\" class=\"ltx_text ltx_font_bold\">79.03</span></td>\n</tr>\n<tr id=\"S5.T3.1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">non-i.i.d</th>\n<th id=\"S5.T3.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">HDAFL</th>\n<td id=\"S5.T3.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.5.5.3.1\" class=\"ltx_text ltx_font_bold\">79.61</span></td>\n<td id=\"S5.T3.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.5.5.4.1\" class=\"ltx_text ltx_font_bold\">79.97</span></td>\n<td id=\"S5.T3.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.5.5.5.1\" class=\"ltx_text ltx_font_bold\">80.47</span></td>\n</tr>\n<tr id=\"S5.T3.1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.6.6.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S5.T3.1.6.6.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">FedAvg</th>\n<td id=\"S5.T3.1.6.6.3\" class=\"ltx_td ltx_align_center\">78.00</td>\n<td id=\"S5.T3.1.6.6.4\" class=\"ltx_td ltx_align_center\">78.88</td>\n<td id=\"S5.T3.1.6.6.5\" class=\"ltx_td ltx_align_center\">79.06</td>\n</tr>\n<tr id=\"S5.T3.1.7.7\" class=\"ltx_tr\" style=\"background-color:#E6E6E6;\">\n<th id=\"S5.T3.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S5.T3.1.7.7.1.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Settings</span></th>\n<th id=\"S5.T3.1.7.7.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S5.T3.1.7.7.2.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Method</span></th>\n<td id=\"S5.T3.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.7.7.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">10</span></td>\n<td id=\"S5.T3.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.7.7.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">20</span></td>\n<td id=\"S5.T3.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.7.7.5.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">31</span></td>\n</tr>\n<tr id=\"S5.T3.1.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Disjoint</th>\n<th id=\"S5.T3.1.8.8.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">HDAFL</th>\n<td id=\"S5.T3.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.8.8.3.1\" class=\"ltx_text ltx_font_bold\">97.53</span></td>\n<td id=\"S5.T3.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.8.8.4.1\" class=\"ltx_text ltx_font_bold\">97.80</span></td>\n<td id=\"S5.T3.1.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.8.8.5.1\" class=\"ltx_text ltx_font_bold\">97.78</span></td>\n</tr>\n<tr id=\"S5.T3.1.9.9\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.9.9.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_b\"></th>\n<th id=\"S5.T3.1.9.9.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">FedAvg</th>\n<td id=\"S5.T3.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_b\">17.44</td>\n<td id=\"S5.T3.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_b\">18.99</td>\n<td id=\"S5.T3.1.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_b\">19.51</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Tab. ",
                "3",
                " summarizes the results for the three sampling strategies. In the i.i.d case, FedAvg by ",
                "McMahan ",
                "et al.",
                " (",
                "2016",
                ")",
                " gives better results than our approach.\nIn a centralized learning, having the whole dataset instead of a sub-part will improve the accuracy.\nAs the local data distribution is the same on each client, what would be beneficial in a centralized scheme is also beneficial on each client. Intuitively, sharing the whole model allows to somehow exploit the whole dataset, and therefore includes more variability during the training that increases the model representation capabilities.\nIn our approach, even if the feature extraction also benefit from seeing the whole dataset, the specific layers relies on a smaller amount of data, leading to an accuracy decrease.",
                "In the non-i.i.d case, the results are reversed, our approach gives better results than the FedAvg. In HDAFL, the client specific layer allows to capture more the client data distribution than the FedAvg approach. As non-i.i.d. data is prevalent in the real-world over i.i.d. data, we also expect gains over FedAvg to be consistent in practice.",
                "The disjoint experiment is an extreme case, that illustrates a limitation of the FedAvg approach, and project the potential benefit of our proposal.\nTo understand why this happens, consider that ",
                "Zhao ",
                "et al.",
                " (",
                "2018",
                ")",
                " show that this disjoint case correspond to the maximum probability distance, thus maximum weights divergence. Consider further that in the disjoint settings, each client has two classes. For example, averaging the classification layer over 10 clients leads to add 9 times a non relevant weight (in the sense the class has not been seen during the training) and 1 time a relevant weight for triggering the neurons corresponding to each class. Our approach do not suffer from this problem, since it keeps the classification layer specific to each client.",
                "One potential downside of HDAFL is that last layer specificity might leads to some over adaptation. However, we point out this may happen in cases where most classes are disjoint, which is an extreme case considered here only to show the potential gain of the method even where the benefit from joint learning is marginal. At the same time, we expect real world cases to exhibit mixture of non-i.i.d. and occasional disjoint classes: in these cases, sharing generic model parameters is beneficial and client over adaptation less likely since several clients have their own data for the very same classes."
            ]
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Communication cost to attain 78% accuracy (non-i.i.d)",
        "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\" style=\"background-color:#E6E6E6;\">\n<th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\">\n<span id=\"S5.T4.1.1.1.1.1\" class=\"ltx_inline-block\" style=\"background-color:#E6E6E6;\">\n<span id=\"S5.T4.1.1.1.1.1.1\" class=\"ltx_p\">Clients</span>\n<span id=\"S5.T4.1.1.1.1.1.2\" class=\"ltx_p\">selected</span>\n</span>\n</th>\n<th id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T4.1.1.1.2.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Method</span></th>\n<th id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">\n<span id=\"S5.T4.1.1.1.3.1\" class=\"ltx_inline-block\" style=\"background-color:#E6E6E6;\">\n<span id=\"S5.T4.1.1.1.3.1.1\" class=\"ltx_p\">Rounds</span>\n<span id=\"S5.T4.1.1.1.3.1.2\" class=\"ltx_p\">number</span>\n</span>\n</th>\n<th id=\"S5.T4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">\n<span id=\"S5.T4.1.1.1.4.1\" class=\"ltx_inline-block\" style=\"background-color:#E6E6E6;\">\n<span id=\"S5.T4.1.1.1.4.1.1\" class=\"ltx_p\">Communication</span>\n<span id=\"S5.T4.1.1.1.4.1.2\" class=\"ltx_p\">Cost (MB)</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">10</th>\n<td id=\"S5.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">HDAFL</td>\n<td id=\"S5.T4.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.2.1.3.1\" class=\"ltx_text ltx_font_bold\">139</span></td>\n<td id=\"S5.T4.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">86.8</span></td>\n</tr>\n<tr id=\"S5.T4.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">20</th>\n<td id=\"S5.T4.1.3.2.2\" class=\"ltx_td ltx_align_center\">HDAFL</td>\n<td id=\"S5.T4.1.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\">110</span></td>\n<td id=\"S5.T4.1.3.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">137.5</span></td>\n</tr>\n<tr id=\"S5.T4.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">50</th>\n<td id=\"S5.T4.1.4.3.2\" class=\"ltx_td ltx_align_center\">HDAFL</td>\n<td id=\"S5.T4.1.4.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.1.4.3.3.1\" class=\"ltx_text ltx_font_bold\">83</span></td>\n<td id=\"S5.T4.1.4.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">259.3</span></td>\n</tr>\n<tr id=\"S5.T4.1.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">10</th>\n<td id=\"S5.T4.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">FedAvg</td>\n<td id=\"S5.T4.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">259</td>\n<td id=\"S5.T4.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">171.7</td>\n</tr>\n<tr id=\"S5.T4.1.6.5\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">20</th>\n<td id=\"S5.T4.1.6.5.2\" class=\"ltx_td ltx_align_center\">FedAvg</td>\n<td id=\"S5.T4.1.6.5.3\" class=\"ltx_td ltx_align_center\">157</td>\n<td id=\"S5.T4.1.6.5.4\" class=\"ltx_td ltx_align_center\">208.2</td>\n</tr>\n<tr id=\"S5.T4.1.7.6\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">50</th>\n<td id=\"S5.T4.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_b\">FedAvg</td>\n<td id=\"S5.T4.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_b\">115</td>\n<td id=\"S5.T4.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_b\">381.2</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Communication cost is an important metric for federated learning. Two factors concur in reducing communication complexity: the rate of convergence at a target accuracy,\nwhich determines the number of rounds, and the amount of model parameters transferred at each round.\nWe show in Fig. ",
                "3",
                " the convergence analysis of the accuracy over the number of rounds communications for the non-i.i.d sampling.\nOur method converge more quickly than the FedAvg and achieves a higher accuracy. Generally speaking, curves are smoother when more clients participate in learning. This smoothness can also be attained by our method with less clients: sharing only the generic parameters decreases the weights divergence, which in turns increases the model stability, explaining the smoothness. Reduced weight divergence leads to faster convergence and smaller communication costs.",
                "Tab. ",
                "4",
                " report the communication cost needed to attain a target of 78% average accuracy",
                "1",
                "1",
                "1",
                "To allow a full comparison, target is selected as the minimum over non-i.i.d settings (FedAvg ",
                "C",
                "=",
                "10",
                "𝐶",
                "10",
                "C=10",
                " in Tab.",
                "3",
                ")",
                ". The minimum communication cost of HDAFL is 86.8 Mbyte, two times lower than FedAvg. If training duration is a priority factor, we can let 50 clients participate in each round, so that learning lasts only 83 rounds, which is 1.3",
                "×",
                "\\times",
                " faster than FedAvg and requires a 1.5",
                "×",
                "\\times",
                " smaller volume of exchanges. We stress that these already quite sizeable gains are obtained in the non-i.i.d case, and can be expected to grow when the imbalance grows, as testified by the performance gap in the extreme disjoint case."
            ]
        ]
    },
    "S5.T5": {
        "caption": "Table 5: Comparison table for the TCP/IP traffic classification. Performance loss (accuracy) and gain (communication) are relative to those of a centralized trained model.",
        "table": "<table id=\"S5.T5.6.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T5.6.6.7.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.6.6.7.1.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S5.T5.6.6.7.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row\"></th>\n<th id=\"S5.T5.6.6.7.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><span id=\"S5.T5.6.6.7.1.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Accuracy</span></th>\n<th id=\"S5.T5.6.6.7.1.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><span id=\"S5.T5.6.6.7.1.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Communication</span></th>\n</tr>\n<tr id=\"S5.T5.6.6.8.2\" class=\"ltx_tr\" style=\"background-color:#E6E6E6;\">\n<th id=\"S5.T5.6.6.8.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\"><span id=\"S5.T5.6.6.8.2.1.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Method</span></th>\n<th id=\"S5.T5.6.6.8.2.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row\"><span id=\"S5.T5.6.6.8.2.2.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">Rounds</span></th>\n<th id=\"S5.T5.6.6.8.2.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><span id=\"S5.T5.6.6.8.2.3.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">loss</span></th>\n<th id=\"S5.T5.6.6.8.2.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\"><span id=\"S5.T5.6.6.8.2.4.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">gain</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.1.1.2\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\"></th>\n<th id=\"S5.T5.1.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t\">4</th>\n<td id=\"S5.T5.1.1.1.4\" class=\"ltx_td ltx_align_right ltx_border_t\">-2.0%</td>\n<td id=\"S5.T5.1.1.1.1\" class=\"ltx_td ltx_align_right ltx_border_t\">28.9<math id=\"S5.T5.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\times\" display=\"inline\"><semantics id=\"S5.T5.1.1.1.1.m1.1a\"><mo id=\"S5.T5.1.1.1.1.m1.1.1\" xref=\"S5.T5.1.1.1.1.m1.1.1.cmml\">×</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.1.1.1.1.m1.1b\"><times id=\"S5.T5.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T5.1.1.1.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.1.1.1.1.m1.1c\">\\times</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S5.T5.2.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T5.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">FedAvg</th>\n<th id=\"S5.T5.2.2.2.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">8</th>\n<td id=\"S5.T5.2.2.2.4\" class=\"ltx_td ltx_align_right\">-1.6%</td>\n<td id=\"S5.T5.2.2.2.1\" class=\"ltx_td ltx_align_right\">14.5<math id=\"S5.T5.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\times\" display=\"inline\"><semantics id=\"S5.T5.2.2.2.1.m1.1a\"><mo id=\"S5.T5.2.2.2.1.m1.1.1\" xref=\"S5.T5.2.2.2.1.m1.1.1.cmml\">×</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.2.2.2.1.m1.1b\"><times id=\"S5.T5.2.2.2.1.m1.1.1.cmml\" xref=\"S5.T5.2.2.2.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.2.2.2.1.m1.1c\">\\times</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S5.T5.3.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T5.3.3.3.2\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S5.T5.3.3.3.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">20</th>\n<td id=\"S5.T5.3.3.3.4\" class=\"ltx_td ltx_align_right\">-1.7%</td>\n<td id=\"S5.T5.3.3.3.1\" class=\"ltx_td ltx_align_right\">5.8<math id=\"S5.T5.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\times\" display=\"inline\"><semantics id=\"S5.T5.3.3.3.1.m1.1a\"><mo id=\"S5.T5.3.3.3.1.m1.1.1\" xref=\"S5.T5.3.3.3.1.m1.1.1.cmml\">×</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.3.3.3.1.m1.1b\"><times id=\"S5.T5.3.3.3.1.m1.1.1.cmml\" xref=\"S5.T5.3.3.3.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.3.3.3.1.m1.1c\">\\times</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S5.T5.4.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T5.4.4.4.2\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\"></th>\n<th id=\"S5.T5.4.4.4.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t\">4</th>\n<td id=\"S5.T5.4.4.4.4\" class=\"ltx_td ltx_align_right ltx_border_t\"><span id=\"S5.T5.4.4.4.4.1\" class=\"ltx_text ltx_font_bold\">-1.2%</span></td>\n<td id=\"S5.T5.4.4.4.1\" class=\"ltx_td ltx_align_right ltx_border_t\"><span id=\"S5.T5.4.4.4.1.1\" class=\"ltx_text ltx_font_bold\">32.9<math id=\"S5.T5.4.4.4.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\times\" display=\"inline\"><semantics id=\"S5.T5.4.4.4.1.1.m1.1a\"><mo id=\"S5.T5.4.4.4.1.1.m1.1.1\" xref=\"S5.T5.4.4.4.1.1.m1.1.1.cmml\">×</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.4.4.4.1.1.m1.1b\"><times id=\"S5.T5.4.4.4.1.1.m1.1.1.cmml\" xref=\"S5.T5.4.4.4.1.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.4.4.4.1.1.m1.1c\">\\times</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S5.T5.5.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T5.5.5.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">HDAFL</th>\n<th id=\"S5.T5.5.5.5.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row\">8</th>\n<td id=\"S5.T5.5.5.5.4\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T5.5.5.5.4.1\" class=\"ltx_text ltx_font_bold\">-0.4%</span></td>\n<td id=\"S5.T5.5.5.5.1\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T5.5.5.5.1.1\" class=\"ltx_text ltx_font_bold\">16.5<math id=\"S5.T5.5.5.5.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\times\" display=\"inline\"><semantics id=\"S5.T5.5.5.5.1.1.m1.1a\"><mo id=\"S5.T5.5.5.5.1.1.m1.1.1\" xref=\"S5.T5.5.5.5.1.1.m1.1.1.cmml\">×</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.5.5.5.1.1.m1.1b\"><times id=\"S5.T5.5.5.5.1.1.m1.1.1.cmml\" xref=\"S5.T5.5.5.5.1.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.5.5.5.1.1.m1.1c\">\\times</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S5.T5.6.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T5.6.6.6.2\" class=\"ltx_td ltx_th ltx_th_row ltx_border_b\"></th>\n<th id=\"S5.T5.6.6.6.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_b\">20</th>\n<td id=\"S5.T5.6.6.6.4\" class=\"ltx_td ltx_align_right ltx_border_b\"><span id=\"S5.T5.6.6.6.4.1\" class=\"ltx_text ltx_font_bold\">-0.5%</span></td>\n<td id=\"S5.T5.6.6.6.1\" class=\"ltx_td ltx_align_right ltx_border_b\"><span id=\"S5.T5.6.6.6.1.1\" class=\"ltx_text ltx_font_bold\">6.6<math id=\"S5.T5.6.6.6.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\times\" display=\"inline\"><semantics id=\"S5.T5.6.6.6.1.1.m1.1a\"><mo id=\"S5.T5.6.6.6.1.1.m1.1.1\" xref=\"S5.T5.6.6.6.1.1.m1.1.1.cmml\">×</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.6.6.6.1.1.m1.1b\"><times id=\"S5.T5.6.6.6.1.1.m1.1.1.cmml\" xref=\"S5.T5.6.6.6.1.1.m1.1.1\"></times></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.6.6.6.1.1.m1.1c\">\\times</annotation></semantics></math></span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We note that in the TCP/IP Traffic classification use case, FedAvg could be hardly used in practice due to the privacy constraint that HDAFL solves. Still, it makes sense to contrast the performance of both algorithms.\nThe algorithmic targets are to contain the model accuracy loss due to distributed training to less than 1% (hard constraint) with an at least 10-fold reduction\nin the communication cost with respect to the case where all data is sent in a\nspace efficient and compressed format to a central location for training (soft constraint).",
                "As our focus is on the ability of FL algorithms to distributed the training process, we report results relative to the centralized model. As shown in Tab.",
                "5",
                ", our method always achieves less accuracy drop compared with the FedAvg",
                "McMahan ",
                "et al.",
                " (",
                "2016",
                ")",
                ". In particular, accuracy reduction in HDAFL approaches the 1% target already after 4 rounds, with a 33-fold reduction of the communication cost. At 8 rounds, the accuracy reduction is half of the target, for a 16-fold communication cost. In contrast, FedAvg is not able to achieve the accuracy target, and this irrespective of the number of rounds. Finally, it is once more worth stressing the slight but noticeable communication cost reduction of HDAFL over FedAvg, which stems from the confidentiality of the last layers."
            ]
        ]
    }
}