{
    "PAPER'S NUMBER OF TABLES": 4,
    "S3.SS2.SSS0.Px3.20": {
        "caption": "Table 1: Gram matrix of three-input parties.",
        "table": "<table id=\"S4.Ex1\" class=\"ltx_equation ltx_eqn_table\">\n\n<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_eqn_cell ltx_align_center\"><math id=\"S4.Ex1.m1.97\" class=\"ltx_math_unparsed\" alttext=\"\\begin{split}A^{\\prime}B^{\\prime T}&amp;=AL_{A}(NN^{T})^{\\frac{1}{2}}(BL_{B}(NN^{T})^{\\frac{1}{2}})^{T},\\\\\n&amp;=AL_{A}(NN^{T})^{\\frac{1}{2}}(NN^{T})^{\\frac{1}{2}}L_{B}^{T}B^{T},\\\\\n&amp;=AL_{A}(NN^{T})L_{B}^{T}B^{T},\\\\\n&amp;=A(L_{A}N)(L_{B}N)^{T}B^{T},\\\\\n&amp;=AB^{T}=(BA^{T})^{T}.\\end{split}\" display=\"block\"><semantics id=\"S4.Ex1.m1.97a\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\" id=\"S4.Ex1.m1.97.97.5\"><mtr id=\"S4.Ex1.m1.97.97.5a\"><mtd class=\"ltx_align_right\" columnalign=\"right\" id=\"S4.Ex1.m1.97.97.5b\"><mrow id=\"S4.Ex1.m1.4.4.4.4.4\"><msup id=\"S4.Ex1.m1.4.4.4.4.4.6\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.1.1.1.1.1.1\">A</mi><mo mathsize=\"90%\" id=\"S4.Ex1.m1.2.2.2.2.2.2.1\">â€²</mo></msup><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.4.4.4.4.4.5\">â€‹</mo><msup id=\"S4.Ex1.m1.4.4.4.4.4.7\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.3.3.3.3.3.3\">B</mi><mrow id=\"S4.Ex1.m1.4.4.4.4.4.4.1.2\"><mo mathsize=\"142%\" id=\"S4.Ex1.m1.4.4.4.4.4.4.1.2.1\">â€²</mo><mo lspace=\"0em\" id=\"S4.Ex1.m1.4.4.4.4.4.4.1.2.2\">â£</mo><mi mathsize=\"90%\" id=\"S4.Ex1.m1.4.4.4.4.4.4.1.1\">T</mi></mrow></msup></mrow></mtd><mtd class=\"ltx_align_left\" columnalign=\"left\" id=\"S4.Ex1.m1.97.97.5c\"><mrow id=\"S4.Ex1.m1.93.93.1.93.28.24.24\"><mrow id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1\"><mi id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.3\"></mi><mo mathsize=\"90%\" id=\"S4.Ex1.m1.5.5.5.5.1.1\">=</mo><mrow id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.6.6.6.6.2.2\">A</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.3\">â€‹</mo><msub id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.4\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.7.7.7.7.3.3\">L</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.8.8.8.8.4.4.1\">A</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.3a\">â€‹</mo><msup id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.1.1\"><mrow id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.1.1.1.1\"><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.9.9.9.9.5.5\">(</mo><mrow id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.1.1.1.1.1\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.10.10.10.10.6.6\">N</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.1.1.1.1.1.1\">â€‹</mo><msup id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.1.1.1.1.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.11.11.11.11.7.7\">N</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.12.12.12.12.8.8.1\">T</mi></msup></mrow><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.13.13.13.13.9.9\">)</mo></mrow><mfrac id=\"S4.Ex1.m1.14.14.14.14.10.10.1\"><mn mathsize=\"90%\" id=\"S4.Ex1.m1.14.14.14.14.10.10.1.2\">1</mn><mn mathsize=\"90%\" id=\"S4.Ex1.m1.14.14.14.14.10.10.1.3\">2</mn></mfrac></msup><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.3b\">â€‹</mo><msup id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2\"><mrow id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2.1.1\"><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.15.15.15.15.11.11\">(</mo><mrow id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2.1.1.1\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.16.16.16.16.12.12\">B</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2.1.1.1.2\">â€‹</mo><msub id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2.1.1.1.3\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.17.17.17.17.13.13\">L</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.18.18.18.18.14.14.1\">B</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2.1.1.1.2a\">â€‹</mo><msup id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2.1.1.1.1\"><mrow id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2.1.1.1.1.1.1\"><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.19.19.19.19.15.15\">(</mo><mrow id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2.1.1.1.1.1.1.1\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.20.20.20.20.16.16\">N</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2.1.1.1.1.1.1.1.1\">â€‹</mo><msup id=\"S4.Ex1.m1.93.93.1.93.28.24.24.1.2.2.1.1.1.1.1.1.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.21.21.21.21.17.17\">N</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.22.22.22.22.18.18.1\">T</mi></msup></mrow><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.23.23.23.23.19.19\">)</mo></mrow><mfrac id=\"S4.Ex1.m1.24.24.24.24.20.20.1\"><mn mathsize=\"90%\" id=\"S4.Ex1.m1.24.24.24.24.20.20.1.2\">1</mn><mn mathsize=\"90%\" id=\"S4.Ex1.m1.24.24.24.24.20.20.1.3\">2</mn></mfrac></msup></mrow><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.25.25.25.25.21.21\">)</mo></mrow><mi mathsize=\"90%\" id=\"S4.Ex1.m1.26.26.26.26.22.22.1\">T</mi></msup></mrow></mrow><mo mathsize=\"90%\" id=\"S4.Ex1.m1.27.27.27.27.23.23\">,</mo></mrow></mtd></mtr><mtr id=\"S4.Ex1.m1.97.97.5d\"><mtd id=\"S4.Ex1.m1.97.97.5e\"></mtd><mtd class=\"ltx_align_left\" columnalign=\"left\" id=\"S4.Ex1.m1.97.97.5f\"><mrow id=\"S4.Ex1.m1.94.94.2.94.23.23.23\"><mrow id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1\"><mi id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.3\"></mi><mo mathsize=\"90%\" id=\"S4.Ex1.m1.28.28.28.1.1.1\">=</mo><mrow id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.29.29.29.2.2.2\">A</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.3\">â€‹</mo><msub id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.4\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.30.30.30.3.3.3\">L</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.31.31.31.4.4.4.1\">A</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.3a\">â€‹</mo><msup id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.1.1\"><mrow id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.1.1.1.1\"><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.32.32.32.5.5.5\">(</mo><mrow id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.1.1.1.1.1\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.33.33.33.6.6.6\">N</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.1.1.1.1.1.1\">â€‹</mo><msup id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.1.1.1.1.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.34.34.34.7.7.7\">N</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.35.35.35.8.8.8.1\">T</mi></msup></mrow><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.36.36.36.9.9.9\">)</mo></mrow><mfrac id=\"S4.Ex1.m1.37.37.37.10.10.10.1\"><mn mathsize=\"90%\" id=\"S4.Ex1.m1.37.37.37.10.10.10.1.2\">1</mn><mn mathsize=\"90%\" id=\"S4.Ex1.m1.37.37.37.10.10.10.1.3\">2</mn></mfrac></msup><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.3b\">â€‹</mo><msup id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.2\"><mrow id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.2.1.1\"><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.38.38.38.11.11.11\">(</mo><mrow id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.2.1.1.1\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.39.39.39.12.12.12\">N</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.2.1.1.1.1\">â€‹</mo><msup id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.2.1.1.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.40.40.40.13.13.13\">N</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.41.41.41.14.14.14.1\">T</mi></msup></mrow><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.42.42.42.15.15.15\">)</mo></mrow><mfrac id=\"S4.Ex1.m1.43.43.43.16.16.16.1\"><mn mathsize=\"90%\" id=\"S4.Ex1.m1.43.43.43.16.16.16.1.2\">1</mn><mn mathsize=\"90%\" id=\"S4.Ex1.m1.43.43.43.16.16.16.1.3\">2</mn></mfrac></msup><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.3c\">â€‹</mo><msubsup id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.5\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.44.44.44.17.17.17\">L</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.45.45.45.18.18.18.1\">B</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.46.46.46.19.19.19.1\">T</mi></msubsup><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.3d\">â€‹</mo><msup id=\"S4.Ex1.m1.94.94.2.94.23.23.23.1.2.6\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.47.47.47.20.20.20\">B</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.48.48.48.21.21.21.1\">T</mi></msup></mrow></mrow><mo mathsize=\"90%\" id=\"S4.Ex1.m1.49.49.49.22.22.22\">,</mo></mrow></mtd></mtr><mtr id=\"S4.Ex1.m1.97.97.5g\"><mtd id=\"S4.Ex1.m1.97.97.5h\"></mtd><mtd class=\"ltx_align_left\" columnalign=\"left\" id=\"S4.Ex1.m1.97.97.5i\"><mrow id=\"S4.Ex1.m1.95.95.3.95.16.16.16\"><mrow id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1\"><mi id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.2\"></mi><mo mathsize=\"90%\" id=\"S4.Ex1.m1.50.50.50.1.1.1\">=</mo><mrow id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.51.51.51.2.2.2\">A</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.2\">â€‹</mo><msub id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.3\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.52.52.52.3.3.3\">L</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.53.53.53.4.4.4.1\">A</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.2a\">â€‹</mo><mrow id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.1.1\"><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.54.54.54.5.5.5\">(</mo><mrow id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.1.1.1\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.55.55.55.6.6.6\">N</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.1.1.1.1\">â€‹</mo><msup id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.1.1.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.56.56.56.7.7.7\">N</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.57.57.57.8.8.8.1\">T</mi></msup></mrow><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.58.58.58.9.9.9\">)</mo></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.2b\">â€‹</mo><msubsup id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.4\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.59.59.59.10.10.10\">L</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.60.60.60.11.11.11.1\">B</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.61.61.61.12.12.12.1\">T</mi></msubsup><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.2c\">â€‹</mo><msup id=\"S4.Ex1.m1.95.95.3.95.16.16.16.1.1.5\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.62.62.62.13.13.13\">B</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.63.63.63.14.14.14.1\">T</mi></msup></mrow></mrow><mo mathsize=\"90%\" id=\"S4.Ex1.m1.64.64.64.15.15.15\">,</mo></mrow></mtd></mtr><mtr id=\"S4.Ex1.m1.97.97.5j\"><mtd id=\"S4.Ex1.m1.97.97.5k\"></mtd><mtd class=\"ltx_align_left\" columnalign=\"left\" id=\"S4.Ex1.m1.97.97.5l\"><mrow id=\"S4.Ex1.m1.96.96.4.96.17.17.17\"><mrow id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1\"><mi id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.3\"></mi><mo mathsize=\"90%\" id=\"S4.Ex1.m1.65.65.65.1.1.1\">=</mo><mrow id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.66.66.66.2.2.2\">A</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.2.3\">â€‹</mo><mrow id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.1.1.1\"><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.67.67.67.3.3.3\">(</mo><mrow id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.1.1.1.1\"><msub id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.1.1.1.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.68.68.68.4.4.4\">L</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.69.69.69.5.5.5.1\">A</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.1.1.1.1.1\">â€‹</mo><mi mathsize=\"90%\" id=\"S4.Ex1.m1.70.70.70.6.6.6\">N</mi></mrow><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.71.71.71.7.7.7\">)</mo></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.2.3a\">â€‹</mo><msup id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.2.2\"><mrow id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.2.2.1.1\"><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.72.72.72.8.8.8\">(</mo><mrow id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.2.2.1.1.1\"><msub id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.2.2.1.1.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.73.73.73.9.9.9\">L</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.74.74.74.10.10.10.1\">B</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.2.2.1.1.1.1\">â€‹</mo><mi mathsize=\"90%\" id=\"S4.Ex1.m1.75.75.75.11.11.11\">N</mi></mrow><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.76.76.76.12.12.12\">)</mo></mrow><mi mathsize=\"90%\" id=\"S4.Ex1.m1.77.77.77.13.13.13.1\">T</mi></msup><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.2.3b\">â€‹</mo><msup id=\"S4.Ex1.m1.96.96.4.96.17.17.17.1.2.4\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.78.78.78.14.14.14\">B</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.79.79.79.15.15.15.1\">T</mi></msup></mrow></mrow><mo mathsize=\"90%\" id=\"S4.Ex1.m1.80.80.80.16.16.16\">,</mo></mrow></mtd></mtr><mtr id=\"S4.Ex1.m1.97.97.5m\"><mtd id=\"S4.Ex1.m1.97.97.5n\"></mtd><mtd class=\"ltx_align_left\" columnalign=\"left\" id=\"S4.Ex1.m1.97.97.5o\"><mrow id=\"S4.Ex1.m1.97.97.5.97.13.13.13\"><mrow id=\"S4.Ex1.m1.97.97.5.97.13.13.13.1\"><mi id=\"S4.Ex1.m1.97.97.5.97.13.13.13.1.3\"></mi><mo mathsize=\"90%\" id=\"S4.Ex1.m1.81.81.81.1.1.1\">=</mo><mrow id=\"S4.Ex1.m1.97.97.5.97.13.13.13.1.4\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.82.82.82.2.2.2\">A</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.97.97.5.97.13.13.13.1.4.1\">â€‹</mo><msup id=\"S4.Ex1.m1.97.97.5.97.13.13.13.1.4.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.83.83.83.3.3.3\">B</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.84.84.84.4.4.4.1\">T</mi></msup></mrow><mo mathsize=\"90%\" id=\"S4.Ex1.m1.85.85.85.5.5.5\">=</mo><msup id=\"S4.Ex1.m1.97.97.5.97.13.13.13.1.1\"><mrow id=\"S4.Ex1.m1.97.97.5.97.13.13.13.1.1.1.1\"><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.86.86.86.6.6.6\">(</mo><mrow id=\"S4.Ex1.m1.97.97.5.97.13.13.13.1.1.1.1.1\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.87.87.87.7.7.7\">B</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.97.97.5.97.13.13.13.1.1.1.1.1.1\">â€‹</mo><msup id=\"S4.Ex1.m1.97.97.5.97.13.13.13.1.1.1.1.1.2\"><mi mathsize=\"90%\" id=\"S4.Ex1.m1.88.88.88.8.8.8\">A</mi><mi mathsize=\"90%\" id=\"S4.Ex1.m1.89.89.89.9.9.9.1\">T</mi></msup></mrow><mo maxsize=\"90%\" minsize=\"90%\" id=\"S4.Ex1.m1.90.90.90.10.10.10\">)</mo></mrow><mi mathsize=\"90%\" id=\"S4.Ex1.m1.91.91.91.11.11.11.1\">T</mi></msup></mrow><mo lspace=\"0em\" mathsize=\"90%\" id=\"S4.Ex1.m1.92.92.92.12.12.12\">.</mo></mrow></mtd></mtr></mtable><annotation encoding=\"application/x-tex\" id=\"S4.Ex1.m1.97b\">\\begin{split}A^{\\prime}B^{\\prime T}&amp;=AL_{A}(NN^{T})^{\\frac{1}{2}}(BL_{B}(NN^{T})^{\\frac{1}{2}})^{T},\\\\\n&amp;=AL_{A}(NN^{T})^{\\frac{1}{2}}(NN^{T})^{\\frac{1}{2}}L_{B}^{T}B^{T},\\\\\n&amp;=AL_{A}(NN^{T})L_{B}^{T}B^{T},\\\\\n&amp;=A(L_{A}N)(L_{B}N)^{T}B^{T},\\\\\n&amp;=AB^{T}=(BA^{T})^{T}.\\end{split}</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n</tr></tbody>\n</table>\n\n",
        "footnotes": "cell-space-limits = 1mm\n{NiceTabular}*5c[name=MyTbl5]Input Parties  A  B  C  X\nA  Aâ€‹ATğ´superscriptğ´ğ‘‡AA^{T}  Aâ€‹BTğ´superscriptğµğ‘‡AB^{T}  Aâ€‹CTğ´superscriptğ¶ğ‘‡AC^{T}  Aâ€‹XTğ´superscriptğ‘‹ğ‘‡AX^{T} \nB  Bâ€‹ATğµsuperscriptğ´ğ‘‡BA^{T}  Bâ€‹BTğµsuperscriptğµğ‘‡BB^{T}  Bâ€‹CTğµsuperscriptğ¶ğ‘‡BC^{T}  Bâ€‹XTğµsuperscriptğ‘‹ğ‘‡BX^{T} \nC  Câ€‹ATğ¶superscriptğ´ğ‘‡CA^{T}  Câ€‹BTğ¶superscriptğµğ‘‡CB^{T}  Câ€‹CTğ¶superscriptğ¶ğ‘‡CC^{T}  Câ€‹XTğ¶superscriptğ‘‹ğ‘‡CX^{T} \nX  Xâ€‹ATğ‘‹superscriptğ´ğ‘‡XA^{T}  Xâ€‹BTğ‘‹superscriptğµğ‘‡XB^{T}  Xâ€‹CTğ‘‹superscriptğ¶ğ‘‡XC^{T}  Xâ€‹XTğ‘‹superscriptğ‘‹ğ‘‡XX^{T} \nWe consider the semi-honest (or honest-but-curious) adversary model.\nIn a multi-party scenario, a semi-honest adversaryÂ (Evans etÂ al., , 2018) corrupts an arbitrary subset of the parties involved. The corrupted parties follow the multi-party protocol as specified, i.e., the output of the protocol is correct. The corrupted parties try to learn private data from the messages they receive from uncorrupted parties. At the end of the protocol, the corrupted parties are allowed to share their information.FLAKE consists of a function party and a number of input parties. From Requirement Privacy follows that FLAKE needs to ensure two privacy properties: (i) the data of uncorrupted input parties must kept private from any corrupted input party or the function party, and (ii) a corrupted function party must not be able to learn the number of features.If the function party and all input parties operate honestly, privacy properties (i) and (ii) are ensured. If all input parties have been corrupted by a semi-honest adversary, privacy cannot ensured.\nBetween these extreme cases, we distinguish three cases for further analyses:A subset of the input parties is corrupted by a semi-honest adversary.The function party is corrupted by a semi-honest adversary.The function and a subset of input parties are corrupted by a semi-honest adversary.Recall that we do not consider extreme scenarios. In particular, we exclude data distributions where the number of features or the training data of one or more input parties can be guessed, and protocols with only one input party. However, to make the guessing harder, the input parties generate a unique matrix Lğ¿L in each iteration. Therefore, the function party can not determine if an input party updates their data in a subsequent iteration. Also, all-zero rows are not allowed; though these are usually discarded as part of preprocessing anyway.Before we begin analysing the privacy of the protocol, we shall establish its correctness, which is unaffected by the existence of a semi-honest adversary.Without loss of generality, we assume there are two input parties Alice and Bob with individual left inverses LAsubscriptğ¿ğ´L_{A} and LBsubscriptğ¿ğµL_{B} of a common mask matrix Nğ‘N, whose outputs are Aâ€²=Aâ€‹LAâ€‹(Nâ€‹NT)12superscriptğ´â€²ğ´subscriptğ¿ğ´superscriptğ‘superscriptğ‘ğ‘‡12A^{\\prime}=AL_{A}(NN^{T})^{\\frac{1}{2}} and Bâ€²=Bâ€‹LBâ€‹(Nâ€‹NT)12superscriptğµâ€²ğµsubscriptğ¿ğµsuperscriptğ‘superscriptğ‘ğ‘‡12B^{\\prime}=BL_{B}(NN^{T})^{\\frac{1}{2}}. Then, the correctness of the protocol follows as below.Analogously, correctness follows for Aâ€‹ATğ´superscriptğ´ğ‘‡AA^{T} and Bâ€‹BTğµsuperscriptğµğ‘‡BB^{T}.\nâˆWe analyze Case (1) first. Since the input parties know the number of features, we only have to prove PropertyÂ (ii), i.e.,\na corrupted function party cannot learn the number of features.FLAKE is secure against a semi-honest adversary who corrupts a subset of the input parties.Let SUsubscriptğ‘†ğ‘ˆS_{U} be the set of all input parties involved in the computation. While executing FLAKE protocol, an input party PâˆˆSUğ‘ƒsubscriptğ‘†ğ‘ˆP\\in S_{U} has access only to the common mask N, the common seed used to generate N and the left inverse LPsubscriptğ¿ğ‘ƒL_{P} of N generated by P. At any point in FLAKE protocol, the input party P gets neither the masked data of other input parties nor the computed Gram matrix using the masked data of all input parties. Thus, A semi-honest adversary corrupting a subset of input parties SCâŠ‚SUsubscriptğ‘†ğ¶subscriptğ‘†ğ‘ˆS_{C}\\subset S_{U} cannot learn the data of non-corrupted input parties SHâŠ‚SUsubscriptğ‘†ğ»subscriptğ‘†ğ‘ˆS_{H}\\subset S_{U} where SCâˆ©SH=âˆ…subscriptğ‘†ğ¶subscriptğ‘†ğ»S_{C}\\cap S_{H}=\\emptyset.FLAKE is, therefore, secure against the semi-honest adversary corrupting a subset of input parties. Because a semi-honest adversary follows the protocol, the data provided by the corrupted input parties do not affect the result of the computation. âˆRegarding Case (2), we need to prove that FLAKE does not allow a semi-honest function party to learn (i) input data nor (ii) the number of features.FLAKE is secure against a semi-honest adversary who corrupts the function party.A semi-honest function party is only the receiver of the masked data from the input parties, and follows the protocol as intended. Without loss of generality, let there be two input parties Alice and Bob with input data Aâˆˆâ„nAÃ—fğ´superscriptâ„subscriptğ‘›ğ´ğ‘“A\\in\\mathbb{R}^{n_{A}\\times f} and Bâˆˆâ„nBÃ—fğµsuperscriptâ„subscriptğ‘›ğµğ‘“B\\in\\mathbb{R}^{n_{B}\\times f}, respectively, where nxsubscriptğ‘›ğ‘¥n_{x} is the number of samples in the corresponding party and fğ‘“f is the number of features. The semi-honest function party receives the masked input matrices of them, which are Aâ€²=Aâ€‹LAâ€‹(Nâ€‹NT)12âˆˆâ„nAÃ—ksuperscriptğ´â€²ğ´subscriptğ¿ğ´superscriptğ‘superscriptğ‘ğ‘‡12superscriptâ„subscriptğ‘›ğ´ğ‘˜A^{\\prime}=AL_{A}(NN^{T})^{\\frac{1}{2}}\\in\\mathbb{R}^{n_{A}\\times k} and Bâ€²=Bâ€‹LBâ€‹(Nâ€‹NT)12âˆˆâ„nBÃ—ksuperscriptğµâ€²ğµsubscriptğ¿ğµsuperscriptğ‘superscriptğ‘ğ‘‡12superscriptâ„subscriptğ‘›ğµğ‘˜B^{\\prime}=BL_{B}(NN^{T})^{\\frac{1}{2}}\\in\\mathbb{R}^{n_{B}\\times k} where k>fğ‘˜ğ‘“k>f. Then, it computes Aâ€²â€‹Bâ€²â£T=Aâ€‹BTâˆˆâ„nAÃ—nBsuperscriptğ´â€²superscriptğµâ€²ğ‘‡ğ´superscriptğµğ‘‡superscriptâ„subscriptğ‘›ğ´subscriptğ‘›ğµA^{\\prime}B^{\\prime T}=AB^{T}\\in\\mathbb{R}^{n_{A}\\times n_{B}}, Aâ€²â€‹Aâ€²â£T=Aâ€‹ATâˆˆâ„nAÃ—nAsuperscriptğ´â€²superscriptğ´â€²ğ‘‡ğ´superscriptğ´ğ‘‡superscriptâ„subscriptğ‘›ğ´subscriptğ‘›ğ´A^{\\prime}A^{\\prime T}=AA^{T}\\in\\mathbb{R}^{n_{A}\\times n_{A}} and Bâ€²â€‹Bâ€²â£T=Bâ€‹BTâˆˆâ„nBÃ—nBsuperscriptğµâ€²superscriptğµâ€²ğ‘‡ğµsuperscriptğµğ‘‡superscriptâ„subscriptğ‘›ğµsubscriptğ‘›ğµB^{\\prime}B^{\\prime T}=BB^{T}\\in\\mathbb{R}^{n_{B}\\times n_{B}}. The data that the function party has access to then includesAâ€²superscriptğ´â€²A^{\\prime} and analogously, Bâ€²superscriptğµâ€²B^{\\prime}.Aâ€‹BT=(Bâ€‹AT)Tğ´superscriptğµğ‘‡superscriptğµsuperscriptğ´ğ‘‡ğ‘‡AB^{T}=(BA^{T})^{T}, Aâ€‹ATğ´superscriptğ´ğ‘‡AA^{T} and analogously Bâ€‹BTğµsuperscriptğµğ‘‡BB^{T}.Regarding (a)ğ‘(a), it is trivial that Aâ€²superscriptğ´â€²A^{\\prime} does not reveal the number of features of Ağ´A. We now show that Aâ€²superscriptğ´â€²A^{\\prime} is not produced by a unique matrix Ağ´A. Given an orthogonal matrix Oâˆˆâ„fÃ—fğ‘‚superscriptâ„ğ‘“ğ‘“O\\in\\mathbb{R}^{f\\times f} with f>1ğ‘“1f>1, for A~=Aâ€‹O~ğ´ğ´ğ‘‚\\tilde{A}=AO and LA~=OTâ€‹LAsubscriptğ¿~ğ´superscriptğ‘‚ğ‘‡subscriptğ¿ğ´L_{\\tilde{A}}=O^{T}L_{A}, we have Aâ€²=A~(LA~(NNT)12A^{\\prime}=\\tilde{A}(L_{\\tilde{A}}(NN^{T})^{\\frac{1}{2}}. Further, since we require that not all entries of any one sample is full of zeroes, the function party cannot deduce anything about Ağ´A from Aâ€²superscriptğ´â€²A^{\\prime}.\n\nÂ \nRegarding (b)ğ‘(b), the matrices that produce these Gram matrices are not unique, since for any orthogonal matrix Oâˆˆâ„fÃ—fğ‘‚superscriptâ„ğ‘“ğ‘“O\\in\\mathbb{R}^{f\\times f} where f>1ğ‘“1f>1, labeling A~=Aâ€‹O~ğ´ğ´ğ‘‚\\tilde{A}=AO and B~=Bâ€‹O~ğµğµğ‘‚\\tilde{B}=BO, we haveIn consequence, the function party only learns the singular values and singular vectors of the matrices, i.e., it can find Uğ‘ˆU and Sğ‘†S from the singular value decomposition A=Uâ€‹Sâ€‹VTğ´ğ‘ˆğ‘†superscriptğ‘‰ğ‘‡A=USV^{T} by eigen-decomposing Aâ€‹ATğ´superscriptğ´ğ‘‡AA^{T}. However, these values are insufficient to solve for Ağ´A since we can generate countless number of different orthogonal matrices (Aguilera and PÃ©rez-Aguila, , 2004). The function party learns neither (i) input data nor (ii) the number of features.Although the function party obtains the Gram matrix, it cannot deduce the samples used to compute this Gram matrix, which was shown by (Ãœnal etÂ al., , 2021). Details can be found in the supplementary material.âˆCase (3) means that not only the function party, but also a subset of the input parties has been corrupted by a semi-honest adversary. In this case, since the adversary knows Nğ‘N, the privacy of the data of the other parties is compromised since for data from a non-corrupt party Charlie of the form Câ€²=Câ€‹LCâ€‹(Nâ€‹NT)12superscriptğ¶â€²ğ¶subscriptğ¿ğ¶superscriptğ‘superscriptğ‘ğ‘‡12C^{\\prime}=CL_{C}(NN^{T})^{\\frac{1}{2}}, the adversary can obtain Cğ¶C by multiplying the data with (Nâ€‹NT)12â€‹LTsuperscriptğ‘superscriptğ‘ğ‘‡12superscriptğ¿ğ‘‡(NN^{T})^{\\frac{1}{2}}L^{T}.In this section, we evaluate the performance of FLAKE and provide a run-time analysis.We experiment with three clinical data sets which contain medical records and, thus, have strong privacy concerns (Wolberg etÂ al., , 1992; Ãœnal etÂ al., , 2019; Center for Machine Learning and Intelligent Systems,\n, 2023). All of them are suitable for classification tasks. For the run-time analysis, we experimented with a synthetic data set with {500,1000,2000,4000,8000}5001000200040008000\\{500,1000,2000,4000,8000\\} data points (dp) for each input party.\nDetails about their statistics can be found in the supplementary material.Before starting with the run-time experiments, we want to compare FLAKE to other methods for randomization-based kernel computation for horizontally shared data. For this purpose, we implemented a 5-fold cross validation with FLAKE, ESCAPED (Ãœnal etÂ al., , 2021), PPSVM (Yu etÂ al., , 2006), RSVM (Lin etÂ al., , 2015) and a naive SVM classifier in Python. Our experiments show that FLAKE, ESCAPED and the naive classifier produces the same results as they are exact solutions. Because of the introduced stochasticity, RSVM and PPSVM have a performance almost as good as the naive classifier, but they are not exact. Furthermore, the overhead associated with the various methods was measured for a single node and 1000 data points. The overhead for all methods was found to be extremely low, to the point of being negligible. Therefore, the subsequent experiments will primarily focus on scaling up the number of data points and input parties for FLAKE and ESCAPED, the two exact methods. For further details see the supplementary material.We implemented FLAKE for a scenario with three input parties and one function party.\nTo mimick the network communication between input parties and function party, we have implemented each party as an isolated process that communicates with others via TCP connections. Our four data sets are divided into three disjoint partitions. Each partition is assigned an input party. Each input party then masks its data according to the FLAKE protocol, and splits the masked data into chunks.\nAfter that, each input party compresses the chunks by zlibâ€™s Deflate-algorithm, and forwards the compressed chunks to the function party. The function party deflates the chunks, computes the Gram matrix and a polynomial kernel.\nFinally, a SVM is trained with a 5-fold cross-validation. A grid search optimizes the corresponding hyperparameters Câˆˆ{2âˆ’4,â€¦,210}ğ¶superscript24â€¦superscript210C\\in\\{2^{-4},...,2^{10}\\} (misclassification penalty) and pâˆˆ{1,â€¦,5}ğ‘1â€¦5p\\in\\{1,...,5\\} (degree).All experiments were executed on a host with an AMD 7713 with 2.0GHZ and 512 GB of memory, which is a typical stand-alone server configuration for a small datacenter. We have used a single-threaded implementation. We repeated each experiment 10 times.We want to confirm that training time, masking time, communication time, gram-computation time and update time do not limit the applicability of FLAKE.\nAs known from literature, SVMs typically do not scale readily to very large data sets. In a centralized scenario, it is the training time for the SVM that limits the size of the input data.\nWe declare success, if we can show that the run-times of the stages of FLAKE in a federated scenario are negligible, compared to the stages required for the federated training of a SVM without masking.\nThe training takes place at the function party.\nFigure 1(c) shows the training time for varying numbers of dp in our synthetic data set. As expected, the longest takes the training of the data set with 8000 dp with 516.62 (Â±plus-or-minus\\pm 2.45) on average. Recall that 8000 dp means that each of our three input parties sends a masked data set of this size to the function party.To find out how much masking burdens the input parties, we ran a series of experiments, again with the synthetic data set. We varied the number of dp and measured the time for masking. Figure 1(a) reports the masking time measured for one input party. Even with 8000 dp per input party, the execution takes less than 0,00300030,003 (Â±plus-or-minus\\pm 0.0001) seconds on average. This masking time is negligible, compared to the time to train the SVM model, and does not restrict the applicability of FLAKE.Because our implementation runs on a data-center host, we estimate the communication time needed to send masked data from the input parties to the function party. The communication timeÂ Tğ‘‡T can be estimated as shown in EquationÂ 1:Our largest data set consists of 8000 points, which adds up to a Datasize of 1.31 MB for each input party. A typical VPN has a Bandwidth of 1.25MBps, with an average Latency of 0.1s and a Packetloss of 2% (Ookla, , 2022). For this set of parameters, the estimated the communication time is 1.05 seconds. Without Latency and Packetloss, it is 1.048 seconds. Recall that our experiments are executed on a single data-center host, i.e., the actual data transfer takes place as inter-process communication in the main memory of the host and virtually requires no time.We also measured the time the function party needs to compute the Gram matrix from the masked data from the input parties. FigureÂ 1(b) shows that the computation time increases slightly more than linearly with the size of the data set, with no outliers. For 8000 dp, it took 0.99 (Â±plus-or-minus\\pm 0.0083) seconds on average to compute the Gram matrix. Again, 8000 dp means the function party receives 3x8000 masked data sets from our three input parties. In summary, we have confirmed that the Gram-computation time does not contribute much to the total computation time.Having shown that the time required to mask the data, send them to the function party, and compute the Gram matrix is several orders of magnitude below the time to train the model, we now consider updating the model.\nTo mimick a typical Federated Learning use case, where the training data increases due to dynamic data collection after the initial training, the data sets were updated with additional data in multiple training iterations.In particular, we performed multiple training iterations starting with a synthetic data set with 1000 dp for each input party. Figure 3 reports the run-times for masking the data and computing the Gram matrix for a three party scenario. We compared four training iterations of FLAKE and ESCAPED (Ãœnal etÂ al., , 2021), where 1000 dp are added in each iteration. The experiment is measured in the same way as for the other diagrams. The figure confirms that FLAKE outperforms ESCAPED. In particular, masking with ESCAPED takes much more time. We conclude that updating the training data in FLAKE is an inexpensive operation and, thus, can be successfully applied in a FL setting.Many privacy-preserving machine learning methods ensure privacy by adding stochasticity, which decreases the result quality (privacy âˆ¼similar-to\\sim utility trade-off) (Chen and Liu, , 2005; Chen etÂ al., , 2007; Lin etÂ al., , 2015; Lin, , 2013). In contrast, the function party in FLAKE obtains an exact Gram matrix (Requirement Accuracy), that can be used to compute any desired kernel matrix and later train any kernel-based machine learning algorithm, as if it was centralized data.\nESCAPED, which provides an accurate solution as well, requires more communication between the parties, which results in longer execution times (Ãœnal etÂ al., , 2021). As shown in section 5, FLAKE is more efficient due to less communication rounds. Also, FLAKE allows input parties to update the Gram matrix with new samples independently of the previous samples. In ESCAPED, updating the Gram matrix with new samples is not supported. Instead, the Gram matrix must be recomputed using all the samples that the input parties have. After all, FLAKE has various advantages over preceding work using the randomized masking approach.Federated learning is an essential aspect of distributed machine learning, particularly when data privacy is a primary concern. However, when implementing both Federated Learning and privacy-preserving methods, the quality of model training can suffer as a result. In this work, we have proposed FLAKE, a Federated Learning Approach for KErnel methods, as a solution to that challenge. Our approach allows for the efficient and private computation of the Gram matrix from data that is distributed on multiple sources, enabling the training of kernel-based machine learning algorithms without any trade-offs in utility.\nInitially, four requirements were formulated, of which we have shown that FLAKE satisfies them: Privacy, Accuracy, Updatability and Efficiency. We showed, that FLAKE is both correct and private with regard to the considered threat models. We conducted various experiments on benchmark data sets to show FLAKE meets the accuracy and correctness of centralized models. Besides conducting experiments on well-known data sets, we also replicated the experiments of (Ãœnal etÂ al., , 2019) on HIV V3 Loop Sequence data. While other privacy-preserving techniques can be computationally expensive, FLAKE is quite efficient. An analysis of FLAKE and comparable approaches shows, that FLAKE is not as computationally expensive. In order to expand the capabilities of the framework, additional common machine learning operations could be incorporated as future developments. Also, the masking and processing of vertically shared data could be included in FLAKE.We believe that FLAKE has the potential to improve healthcare outcomes and reduce costs while addressing the privacy concerns associated with machine learning on clinical data. We also think that it may find many use cases in other application domains that handle sensitive, distributed data.The following proof is based on a proof by Ãœnal etÂ al.,  (2019).FLAKE provides security against a malicious function party A, assuming A is either semi-honest or malicious and does not collude with any input parties. In this scenario, A is unable to deduce the data of the input parties from the Gram matrix GğºG that is generated as a result.Although the number of features are hidden by FLAKE, we assume now the full Gram matrix G=Dâ€‹DTğºğ·superscriptğ·ğ‘‡G=DD^{T} with the data of the input parties D=[A,B,C]ğ·ğ´ğµğ¶D=[A,B,C] and the number of features are known to the function party. We show, that an attacker could not obtain any data since it there are multiple matrices that result in the Gram matrix.Assume that there is a rotation matrix Râˆˆâ„NÃ—Nğ‘…superscriptâ„ğ‘ğ‘R\\in\\mathbb{R}^{N\\times N} where N=2â€‹(na+nb+nc)ğ‘2subscriptğ‘›ğ‘subscriptğ‘›ğ‘subscriptğ‘›ğ‘N=2(n_{a}+n_{b}+n_{c}) with nxsubscriptğ‘›ğ‘¥n_{x} is the number of samples in the corresponding party. Then, there is a matrix Eğ¸E which can be computed by E=Râˆ’1â€‹Dğ¸superscriptğ‘…1ğ·E=R^{-1}D. From that, we can say that D=Râ€‹Eğ·ğ‘…ğ¸D=RE. Then, due to the rotation property of Râˆ’1=RTsuperscriptğ‘…1superscriptğ‘…ğ‘‡R^{-1}=R^{T}, the the following holds:âˆSince Aguilera and PÃ©rez-Aguila,  (2004) showed, that countless rotation matrices can be generated, we cannot obtain a unique matrix resulting in Gram matrix GğºG: For every new rotation matrix Î¸âˆˆâ„NÃ—Nğœƒsuperscriptâ„ğ‘ğ‘\\theta\\in\\mathbb{R}^{N\\times N}, there exists a new matrix Î²=Î¸âˆ’1â€‹Dğ›½superscriptğœƒ1ğ·\\beta=\\theta^{-1}D satisfying G=Î²Tâ€‹Î²ğºsuperscriptğ›½ğ‘‡ğ›½G=\\beta^{T}\\beta. Thus, A is unable to deduce the input partiesâ€™ data D=(A,B,C)ğ·ğ´ğµğ¶D=(A,B,C) from G=DDâ€‹Tğºsuperscriptğ·ğ·ğ‘‡G=D^{D}T.All methods employed a polynomial kernel and identical hyperparameter settings. For this implementation, Sequential Minimal Optimization (libsvm) provided by scikit-learn was used Zeng etÂ al.,  (2008). Since the Pima Indian diabetes data set, HIV and Breast Cancer data set have an unbalanced distribution of classes, we have applied Macro Averaging. Correspondingly, for the balanced synthetic data set, Micro Averaging.",
        "references": [
            [
                "To integrate new data without having to rebuild the model from scratch (Requirement ",
                "Updatability",
                "), FLAKE provides a protocol for inference and updating the Gram matrix.\nWe can distinguish two cases: First, one of the input parties may have received new input data. Second, a new input party shall be integrated into the computation.\nFor simplicity, we again explain our protocol with three parties Alice, Bob and Charlie with their respective data sets ",
                "A",
                ",",
                "B",
                ",",
                "C",
                "ğ´",
                "ğµ",
                "ğ¶",
                "A,B,C",
                ".",
                "Assume ",
                "C",
                "ğ¶",
                "C",
                " has new data ",
                "X",
                "ğ‘‹",
                "X",
                " which must be integrated into the Gram matrix shown in TableÂ ",
                "3.2",
                ". ",
                "X",
                "ğ‘‹",
                "X",
                " is the data set to be used for updating the model. To extend the gram matrix with the new values from ",
                "C",
                "ğ¶",
                "C",
                ", the function party only needs to have the entries in the dashed rectangles. The party ",
                "C",
                "ğ¶",
                "C",
                " uses the aforementioned masking and sending approaches for this purpose.\nNow assume that a new input party needs to be added. In this case, the function party must calculate the values in the continuous rectangles in TableÂ ",
                "3.2",
                ". The remaining new entries can be computed locally by ",
                "C",
                "ğ¶",
                "C",
                ". In both cases, updating the Gram matrix means that the function party has to calculate only a small set of new values. The vast majority of values need to be calculated just once, and a large share of the calculation effort remains at the input parties.\nNote that ",
                "X",
                "ğ‘‹",
                "X",
                " can be also a test data set.",
                "When a party wants to leave the consortium the function party deletes all random components coming from this party and gram matrix entries that are calculated using these random components. This is important for compliance with legal regulations such as General Data Protection Regulation (GDPR) ",
                "(",
                "European Parliament and Council of the European Union, ",
                ", ",
                "2016",
                ")",
                ". It can be seen as an application of machine unlearning. In current FL methods, it is unclear and difficult how to eliminate a partyâ€™s contribution to the collaboratively trained ML model."
            ]
        ]
    },
    "S7.T2": {
        "caption": "Table 2: statistics of data sets used in the experiment section",
        "table": "<table id=\"S7.T2.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S7.T2.4.1.1\" class=\"ltx_tr\">\n<td id=\"S7.T2.4.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S7.T2.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S7.T2.4.1.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Naive</span></th>\n<th id=\"S7.T2.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S7.T2.4.1.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">FLAKE</span></th>\n</tr>\n<tr id=\"S7.T2.4.2.2\" class=\"ltx_tr\">\n<th id=\"S7.T2.4.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span id=\"S7.T2.4.2.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Data set</span></th>\n<th id=\"S7.T2.4.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S7.T2.4.2.2.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Number of data points</span></th>\n<th id=\"S7.T2.4.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S7.T2.4.2.2.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Number of Features</span></th>\n<th id=\"S7.T2.4.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S7.T2.4.2.2.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">binary/multi - label</span></th>\n<th id=\"S7.T2.4.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S7.T2.4.2.2.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">distribution</span></th>\n</tr>\n<tr id=\"S7.T2.4.3.3\" class=\"ltx_tr\">\n<td id=\"S7.T2.4.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S7.T2.4.3.3.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Diabetes</span></td>\n<td id=\"S7.T2.4.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S7.T2.4.3.3.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">768</span></td>\n<td id=\"S7.T2.4.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S7.T2.4.3.3.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">8</span></td>\n<td id=\"S7.T2.4.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S7.T2.4.3.3.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">binary</span></td>\n<td id=\"S7.T2.4.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S7.T2.4.3.3.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">in-balanced</span></td>\n</tr>\n<tr id=\"S7.T2.4.4.4\" class=\"ltx_tr\">\n<td id=\"S7.T2.4.4.4.1\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T2.4.4.4.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Cancer</span></td>\n<td id=\"S7.T2.4.4.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T2.4.4.4.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">569</span></td>\n<td id=\"S7.T2.4.4.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T2.4.4.4.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">10</span></td>\n<td id=\"S7.T2.4.4.4.4\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T2.4.4.4.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">binary</span></td>\n<td id=\"S7.T2.4.4.4.5\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T2.4.4.4.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">in-balanced</span></td>\n</tr>\n<tr id=\"S7.T2.4.5.5\" class=\"ltx_tr\">\n<td id=\"S7.T2.4.5.5.1\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T2.4.5.5.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">HIV</span></td>\n<td id=\"S7.T2.4.5.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T2.4.5.5.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">766</span></td>\n<td id=\"S7.T2.4.5.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T2.4.5.5.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">924</span></td>\n<td id=\"S7.T2.4.5.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T2.4.5.5.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">binary</span></td>\n<td id=\"S7.T2.4.5.5.5\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T2.4.5.5.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">in-balanced</span></td>\n</tr>\n<tr id=\"S7.T2.4.6.6\" class=\"ltx_tr\">\n<td id=\"S7.T2.4.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S7.T2.4.6.6.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Synthetic</span></td>\n<td id=\"S7.T2.4.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S7.T2.4.6.6.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">500-8000</span></td>\n<td id=\"S7.T2.4.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S7.T2.4.6.6.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">20</span></td>\n<td id=\"S7.T2.4.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S7.T2.4.6.6.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">multi class</span></td>\n<td id=\"S7.T2.4.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S7.T2.4.6.6.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">balanced</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "All methods employed a polynomial kernel and identical hyperparameter settings. For this implementation, Sequential Minimal Optimization (libsvm) provided by scikit-learn was used ",
                "Zeng etÂ al., ",
                " ",
                "(",
                "2008",
                ")",
                ". Since the Pima Indian diabetes data set, HIV and Breast Cancer data set have an unbalanced distribution of classes, we have applied Macro Averaging. Correspondingly, for the balanced synthetic data set, Micro Averaging."
            ]
        ]
    },
    "S7.T3": {
        "caption": "Table 3: ROC AUC with standard deviation for Naive SVM, FLAKE, ESCAPED, RSVM, PPSVM on various data sets.",
        "table": "<table id=\"S7.T3.20.20\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S7.T3.20.20.21.1\" class=\"ltx_tr\">\n<th id=\"S7.T3.20.20.21.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<th id=\"S7.T3.20.20.21.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S7.T3.20.20.21.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Naive</span></th>\n<th id=\"S7.T3.20.20.21.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S7.T3.20.20.21.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">FLAKE</span></th>\n<th id=\"S7.T3.20.20.21.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S7.T3.20.20.21.1.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">ESCAPED</span></th>\n<th id=\"S7.T3.20.20.21.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S7.T3.20.20.21.1.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">RSVM</span></th>\n<th id=\"S7.T3.20.20.21.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S7.T3.20.20.21.1.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">PPSVM</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S7.T3.5.5.5\" class=\"ltx_tr\">\n<th id=\"S7.T3.5.5.5.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S7.T3.5.5.5.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Diabetes</span></th>\n<td id=\"S7.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<span id=\"S7.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.97</span><math id=\"S7.T3.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.1.1.1.1.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.1.1.1.1.m1.1.1\" xref=\"S7.T3.1.1.1.1.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S7.T3.1.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.1.1.1.1.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.1.1.1.1.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.04</span>\n</td>\n<td id=\"S7.T3.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<span id=\"S7.T3.2.2.2.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.97</span><math id=\"S7.T3.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.2.2.2.2.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.2.2.2.2.m1.1.1\" xref=\"S7.T3.2.2.2.2.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.2.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.2.2.2.2.m1.1.1.cmml\" xref=\"S7.T3.2.2.2.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.2.2.2.2.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.2.2.2.2.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.04</span>\n</td>\n<td id=\"S7.T3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<span id=\"S7.T3.3.3.3.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.97</span><math id=\"S7.T3.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.3.3.3.3.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.3.3.3.3.m1.1.1\" xref=\"S7.T3.3.3.3.3.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.3.3.3.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.3.3.3.3.m1.1.1.cmml\" xref=\"S7.T3.3.3.3.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.3.3.3.3.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.3.3.3.3.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.04</span>\n</td>\n<td id=\"S7.T3.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<span id=\"S7.T3.4.4.4.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.95</span><math id=\"S7.T3.4.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.4.4.4.4.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.4.4.4.4.m1.1.1\" xref=\"S7.T3.4.4.4.4.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.4.4.4.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.4.4.4.4.m1.1.1.cmml\" xref=\"S7.T3.4.4.4.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.4.4.4.4.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.4.4.4.4.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.02</span>\n</td>\n<td id=\"S7.T3.5.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<span id=\"S7.T3.5.5.5.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.94</span><math id=\"S7.T3.5.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.5.5.5.5.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.5.5.5.5.m1.1.1\" xref=\"S7.T3.5.5.5.5.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.5.5.5.5.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.5.5.5.5.m1.1.1.cmml\" xref=\"S7.T3.5.5.5.5.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.5.5.5.5.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.5.5.5.5.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.04</span>\n</td>\n</tr>\n<tr id=\"S7.T3.10.10.10\" class=\"ltx_tr\">\n<th id=\"S7.T3.10.10.10.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S7.T3.10.10.10.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Cancer</span></th>\n<td id=\"S7.T3.6.6.6.1\" class=\"ltx_td ltx_align_center\">\n<span id=\"S7.T3.6.6.6.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.97 </span><math id=\"S7.T3.6.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.6.6.6.1.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.6.6.6.1.m1.1.1\" xref=\"S7.T3.6.6.6.1.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.6.6.6.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.6.6.6.1.m1.1.1.cmml\" xref=\"S7.T3.6.6.6.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.6.6.6.1.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.6.6.6.1.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.03</span>\n</td>\n<td id=\"S7.T3.7.7.7.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S7.T3.7.7.7.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.97 </span><math id=\"S7.T3.7.7.7.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.7.7.7.2.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.7.7.7.2.m1.1.1\" xref=\"S7.T3.7.7.7.2.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.7.7.7.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.7.7.7.2.m1.1.1.cmml\" xref=\"S7.T3.7.7.7.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.7.7.7.2.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.7.7.7.2.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.03</span>\n</td>\n<td id=\"S7.T3.8.8.8.3\" class=\"ltx_td ltx_align_center\">\n<span id=\"S7.T3.8.8.8.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.97 </span><math id=\"S7.T3.8.8.8.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.8.8.8.3.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.8.8.8.3.m1.1.1\" xref=\"S7.T3.8.8.8.3.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.8.8.8.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.8.8.8.3.m1.1.1.cmml\" xref=\"S7.T3.8.8.8.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.8.8.8.3.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.8.8.8.3.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.03</span>\n</td>\n<td id=\"S7.T3.9.9.9.4\" class=\"ltx_td ltx_align_center\">\n<span id=\"S7.T3.9.9.9.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.96 </span><math id=\"S7.T3.9.9.9.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.9.9.9.4.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.9.9.9.4.m1.1.1\" xref=\"S7.T3.9.9.9.4.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.9.9.9.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.9.9.9.4.m1.1.1.cmml\" xref=\"S7.T3.9.9.9.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.9.9.9.4.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.9.9.9.4.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.02</span>\n</td>\n<td id=\"S7.T3.10.10.10.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S7.T3.10.10.10.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.97 </span><math id=\"S7.T3.10.10.10.5.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.10.10.10.5.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.10.10.10.5.m1.1.1\" xref=\"S7.T3.10.10.10.5.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.10.10.10.5.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.10.10.10.5.m1.1.1.cmml\" xref=\"S7.T3.10.10.10.5.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.10.10.10.5.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.10.10.10.5.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.04</span>\n</td>\n</tr>\n<tr id=\"S7.T3.15.15.15\" class=\"ltx_tr\">\n<th id=\"S7.T3.15.15.15.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S7.T3.15.15.15.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">HIV</span></th>\n<td id=\"S7.T3.11.11.11.1\" class=\"ltx_td ltx_align_center\">\n<span id=\"S7.T3.11.11.11.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.78</span><math id=\"S7.T3.11.11.11.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.11.11.11.1.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.11.11.11.1.m1.1.1\" xref=\"S7.T3.11.11.11.1.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.11.11.11.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.11.11.11.1.m1.1.1.cmml\" xref=\"S7.T3.11.11.11.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.11.11.11.1.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.11.11.11.1.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.03</span>\n</td>\n<td id=\"S7.T3.12.12.12.2\" class=\"ltx_td ltx_align_center\">\n<span id=\"S7.T3.12.12.12.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.78</span><math id=\"S7.T3.12.12.12.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.12.12.12.2.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.12.12.12.2.m1.1.1\" xref=\"S7.T3.12.12.12.2.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.12.12.12.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.12.12.12.2.m1.1.1.cmml\" xref=\"S7.T3.12.12.12.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.12.12.12.2.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.12.12.12.2.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.03</span>\n</td>\n<td id=\"S7.T3.13.13.13.3\" class=\"ltx_td ltx_align_center\">\n<span id=\"S7.T3.13.13.13.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.78</span><math id=\"S7.T3.13.13.13.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.13.13.13.3.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.13.13.13.3.m1.1.1\" xref=\"S7.T3.13.13.13.3.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.13.13.13.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.13.13.13.3.m1.1.1.cmml\" xref=\"S7.T3.13.13.13.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.13.13.13.3.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.13.13.13.3.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.03</span>\n</td>\n<td id=\"S7.T3.14.14.14.4\" class=\"ltx_td ltx_align_center\">\n<span id=\"S7.T3.14.14.14.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.65</span><math id=\"S7.T3.14.14.14.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.14.14.14.4.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.14.14.14.4.m1.1.1\" xref=\"S7.T3.14.14.14.4.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.14.14.14.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.14.14.14.4.m1.1.1.cmml\" xref=\"S7.T3.14.14.14.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.14.14.14.4.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.14.14.14.4.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.17</span>\n</td>\n<td id=\"S7.T3.15.15.15.5\" class=\"ltx_td ltx_align_center\">\n<span id=\"S7.T3.15.15.15.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.64</span><math id=\"S7.T3.15.15.15.5.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.15.15.15.5.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.15.15.15.5.m1.1.1\" xref=\"S7.T3.15.15.15.5.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.15.15.15.5.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.15.15.15.5.m1.1.1.cmml\" xref=\"S7.T3.15.15.15.5.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.15.15.15.5.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.15.15.15.5.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.10</span>\n</td>\n</tr>\n<tr id=\"S7.T3.20.20.20\" class=\"ltx_tr\">\n<th id=\"S7.T3.20.20.20.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S7.T3.20.20.20.6.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Synthetic</span></th>\n<td id=\"S7.T3.16.16.16.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<span id=\"S7.T3.16.16.16.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.97</span><math id=\"S7.T3.16.16.16.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.16.16.16.1.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.16.16.16.1.m1.1.1\" xref=\"S7.T3.16.16.16.1.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.16.16.16.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.16.16.16.1.m1.1.1.cmml\" xref=\"S7.T3.16.16.16.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.16.16.16.1.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.16.16.16.1.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.01</span>\n</td>\n<td id=\"S7.T3.17.17.17.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<span id=\"S7.T3.17.17.17.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.97</span><math id=\"S7.T3.17.17.17.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.17.17.17.2.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.17.17.17.2.m1.1.1\" xref=\"S7.T3.17.17.17.2.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.17.17.17.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.17.17.17.2.m1.1.1.cmml\" xref=\"S7.T3.17.17.17.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.17.17.17.2.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.17.17.17.2.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.01</span>\n</td>\n<td id=\"S7.T3.18.18.18.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<span id=\"S7.T3.18.18.18.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.97</span><math id=\"S7.T3.18.18.18.3.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.18.18.18.3.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.18.18.18.3.m1.1.1\" xref=\"S7.T3.18.18.18.3.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.18.18.18.3.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.18.18.18.3.m1.1.1.cmml\" xref=\"S7.T3.18.18.18.3.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.18.18.18.3.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.18.18.18.3.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.01</span>\n</td>\n<td id=\"S7.T3.19.19.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<span id=\"S7.T3.19.19.19.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.83</span><math id=\"S7.T3.19.19.19.4.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.19.19.19.4.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.19.19.19.4.m1.1.1\" xref=\"S7.T3.19.19.19.4.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.19.19.19.4.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.19.19.19.4.m1.1.1.cmml\" xref=\"S7.T3.19.19.19.4.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.19.19.19.4.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.19.19.19.4.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.04</span>\n</td>\n<td id=\"S7.T3.20.20.20.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<span id=\"S7.T3.20.20.20.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.95</span><math id=\"S7.T3.20.20.20.5.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S7.T3.20.20.20.5.m1.1a\"><mo mathsize=\"70%\" id=\"S7.T3.20.20.20.5.m1.1.1\" xref=\"S7.T3.20.20.20.5.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S7.T3.20.20.20.5.m1.1b\"><csymbol cd=\"latexml\" id=\"S7.T3.20.20.20.5.m1.1.1.cmml\" xref=\"S7.T3.20.20.20.5.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T3.20.20.20.5.m1.1c\">\\pm</annotation></semantics></math><span id=\"S7.T3.20.20.20.5.2\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\"> 0.01</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Assume Cğ¶C has new data Xğ‘‹X which must be integrated into the Gram matrix shown in TableÂ 3.2. Xğ‘‹X is the data set to be used for updating the model. To extend the gram matrix with the new values from Cğ¶C, the function party only needs to have the entries in the dashed rectangles. The party Cğ¶C uses the aforementioned masking and sending approaches for this purpose.\nNow assume that a new input party needs to be added. In this case, the function party must calculate the values in the continuous rectangles in TableÂ 3.2. The remaining new entries can be computed locally by Cğ¶C. In both cases, updating the Gram matrix means that the function party has to calculate only a small set of new values. The vast majority of values need to be calculated just once, and a large share of the calculation effort remains at the input parties.\nNote that Xğ‘‹X can be also a test data set."
        ]
    },
    "S7.T4": {
        "caption": "Table 4: Overhead (Masking time + Gram time) for FLAKE, ESCAPED, RSVM, PPSVM for three input parties with 1000 dp each.",
        "table": "<table id=\"S7.T4.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S7.T4.4.1.1\" class=\"ltx_tr\">\n<th id=\"S7.T4.4.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<th id=\"S7.T4.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S7.T4.4.1.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">FLAKE</span></th>\n<th id=\"S7.T4.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S7.T4.4.1.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">ESCAPED</span></th>\n<th id=\"S7.T4.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S7.T4.4.1.1.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">RSVM</span></th>\n<th id=\"S7.T4.4.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S7.T4.4.1.1.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">PPSVM</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S7.T4.4.2.1\" class=\"ltx_tr\">\n<th id=\"S7.T4.4.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S7.T4.4.2.1.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Masking time for one IP</span></th>\n<td id=\"S7.T4.4.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S7.T4.4.2.1.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.00146</span></td>\n<td id=\"S7.T4.4.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S7.T4.4.2.1.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">1.23610</span></td>\n<td id=\"S7.T4.4.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S7.T4.4.2.1.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.00201</span></td>\n<td id=\"S7.T4.4.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S7.T4.4.2.1.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.02257</span></td>\n</tr>\n<tr id=\"S7.T4.4.3.2\" class=\"ltx_tr\">\n<th id=\"S7.T4.4.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span id=\"S7.T4.4.3.2.1.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">Time to compute Gram</span></th>\n<td id=\"S7.T4.4.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S7.T4.4.3.2.2.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.02071</span></td>\n<td id=\"S7.T4.4.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S7.T4.4.3.2.3.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.03156</span></td>\n<td id=\"S7.T4.4.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S7.T4.4.3.2.4.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.00530</span></td>\n<td id=\"S7.T4.4.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S7.T4.4.3.2.5.1\" class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:70%;\">0.01121</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "All methods employed a polynomial kernel and identical hyperparameter settings. For this implementation, Sequential Minimal Optimization (libsvm) provided by scikit-learn was used ",
                "Zeng etÂ al., ",
                " ",
                "(",
                "2008",
                ")",
                ". Since the Pima Indian diabetes data set, HIV and Breast Cancer data set have an unbalanced distribution of classes, we have applied Macro Averaging. Correspondingly, for the balanced synthetic data set, Micro Averaging."
            ]
        ]
    }
}