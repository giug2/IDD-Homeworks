{
    "PAPER'S NUMBER OF TABLES": 2,
    "S5.T1": {
        "caption": "Table 1: Comparison of different methods for 50, 100, and 500 clients splits of CIFAR-100. Top-1 accuracy.",
        "table": "<table id=\"S5.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.3.4.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.3.4.1.1.1\" class=\"ltx_text\">Method</span></th>\n<th id=\"S5.T1.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"3\"><span id=\"S5.T1.3.4.1.2.1\" class=\"ltx_text ltx_font_bold\">Top-1 Accuracy (%)</span></th>\n</tr>\n<tr id=\"S5.T1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><math id=\"S5.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"50\" display=\"inline\"><semantics id=\"S5.T1.1.1.1.m1.1a\"><mn id=\"S5.T1.1.1.1.m1.1.1\" xref=\"S5.T1.1.1.1.m1.1.1.cmml\">50</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.1.1.1.m1.1b\"><cn type=\"integer\" id=\"S5.T1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.1.1.1.m1.1.1\">50</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.1.1.1.m1.1c\">50</annotation></semantics></math></th>\n<th id=\"S5.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><math id=\"S5.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"100\" display=\"inline\"><semantics id=\"S5.T1.2.2.2.m1.1a\"><mn id=\"S5.T1.2.2.2.m1.1.1\" xref=\"S5.T1.2.2.2.m1.1.1.cmml\">100</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.2.2.2.m1.1b\"><cn type=\"integer\" id=\"S5.T1.2.2.2.m1.1.1.cmml\" xref=\"S5.T1.2.2.2.m1.1.1\">100</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.2.2.2.m1.1c\">100</annotation></semantics></math></th>\n<th id=\"S5.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><math id=\"S5.T1.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"500\" display=\"inline\"><semantics id=\"S5.T1.3.3.3.m1.1a\"><mn id=\"S5.T1.3.3.3.m1.1.1\" xref=\"S5.T1.3.3.3.m1.1.1.cmml\">500</mn><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.3.3.3.m1.1b\"><cn type=\"integer\" id=\"S5.T1.3.3.3.m1.1.1.cmml\" xref=\"S5.T1.3.3.3.m1.1.1\">500</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.3.3.3.m1.1c\">500</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.3.5.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedAvg <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib20\" title=\"\" class=\"ltx_ref\">20</a>]</cite>\n</th>\n<td id=\"S5.T1.3.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">2.86</td>\n<td id=\"S5.T1.3.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">2.01</td>\n<td id=\"S5.T1.3.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">2.63</td>\n</tr>\n<tr id=\"S5.T1.3.6.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.6.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">PASS<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib37\" title=\"\" class=\"ltx_ref\">37</a>]</cite> + FedAvg <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib20\" title=\"\" class=\"ltx_ref\">20</a>]</cite>\n</th>\n<td id=\"S5.T1.3.6.2.2\" class=\"ltx_td ltx_align_center\">29.08</td>\n<td id=\"S5.T1.3.6.2.3\" class=\"ltx_td ltx_align_center\">22.97</td>\n<td id=\"S5.T1.3.6.2.4\" class=\"ltx_td ltx_align_center\">13.39</td>\n</tr>\n<tr id=\"S5.T1.3.7.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.3.7.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\"><span id=\"S5.T1.3.7.3.1.1\" class=\"ltx_text ltx_font_bold\">Ours (FedSpace)</span></th>\n<td id=\"S5.T1.3.7.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T1.3.7.3.2.1\" class=\"ltx_text ltx_font_bold\">37.18</span></td>\n<td id=\"S5.T1.3.7.3.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T1.3.7.3.3.1\" class=\"ltx_text ltx_font_bold\">29.99</span></td>\n<td id=\"S5.T1.3.7.3.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T1.3.7.3.4.1\" class=\"ltx_text ltx_font_bold\">28.42</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In Table 1, we report the\nTop-1 accuracy, for each federated split (50, 100, and 500 clients), and compare the performance with FedAvg [20] and PASS[37] adapted to FL.\nWe notice that in this highly challenging scenario, FedAvg [20] is not a feasible solution and provides very poor performances between 2%percent22\\% and 3%percent33\\% (even by adding the fractal pre-training stage of Section 4.1 results do not improve). The main reason is the catastrophic forgetting, here experienced both\nin a continual learning and in a federated learning way.\nAt each communication round, due to client drift and misaligned learning of new classes across the selected clients, the global model loses knowledge of the previously learned classes.\nMoreover, when a set of classes is no more experienced by clients selected in future rounds, those are forgotten as well known in continual learning."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Ablation of our method on CIFAR-100 for 50, 100 and 500 clients.\nTop-1 accuracy.\nProto aggr. refers to the prototype aggregation (Eq.¬†6), Pre-train is the server fractal pre-training (Sec¬†4.1), Repr. Loss is the representation loss (Eq.¬†9) and Server Aggr. corresponds to the modified aggregation (Eq.¬†10) instead of FedAvg.",
        "table": "",
        "footnotes": "\n\n\n\nProto\nPre-\nRepr.\nServer\nAccuracy (%)\n\nAggr.\ntrain\nLoss\nAggr.\n50\n100\n500\n\n\n\n‚úì\n\n\n\n28.76\n29.58\n23.45\n\n\n‚úì\n‚úì\n‚úì\n30.82\n25.89\n23.45\n\n‚úì\n\n‚úì\n‚úì\n35.72\n25.89\n19.01\n\n‚úì\n‚úì\n\n‚úì\n35.96\n26.84\n27.05\n\n‚úì\n‚úì\n‚úì\n\n35.60\n31.90\n17.46\n\n‚úì\n‚úì\n‚úì\n‚úì\n37.18\n29.99\n28.42\n\n",
        "references": [
            "In order to validate the performance and robustness of the proposed method, we perform an extensive ablation on all the three settings.\nIn Table 2, we report the Top-1 accuracy, computed on all classes Cùê∂C after 500050005000 rounds, while in Fig.¬†4 we show the classification accuracy while the training goes on, i.e., at the end of every communication round, for 50 and 500 clients.\nThe Figure reports the accuracy during training for the competitors, our method, and its reduced versions obtained by removing each component singularly.",
            "Interestingly, when the number of total clients is low, during the first rounds keeping the prototypes local (i.e., not aggregating them) leads to\nhigher performances, however, after a certain amount of rounds, aggregating prototypes starts to be beneficial and gives a similar improvement in every setting, with an increase of 6%percent66\\%, 4%percent44\\% and 5%percent55\\% for 505050, 100100100 and 500500500 clients, respectively (second row of Table 2). Even if it is less evident, this is true also for the representation loss, with an increase of 1%percent11\\%, 3%percent33\\% and 1%percent11\\% (fourth row of Table 2)."
        ]
    }
}