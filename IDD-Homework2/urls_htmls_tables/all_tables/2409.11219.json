{
    "id_table_1": {
        "caption": "Table 1 :  Class forgetting results on CIFAR-10 and STL-10.  SFD refers to the DDPM model trained with Score Forgetting Distillation, while SFD-CFG refers to the SFD model trained with classifier-free guidance (as discussed in  Section   3.2 ). UAs that exceed the testing recall rate of the forgetting class (96.60% for CIFAR-10 and 98.15% for STL-10) are highlighted in  yellow .",
        "table": "A4.EGx1",
        "footnotes": [
            ""
        ],
        "references": [
            "Diffusion models, also known as score-based generative models  ( Sohl-Dickstein et al. ,  2015 ;  Song and Ermon ,  2019 ;  Ho et al. ,  2020 ;  Dhariwal and Nichol ,  2021 ;  Karras et al. ,  2022 ) , have emerged as the leading choice for generative modeling of high-dimensional data. These models are widely celebrated for their ability to produce high-quality, diverse, and photorealistic images  ( Nichol et al. ,  2022 ;  Ramesh et al. ,  2022 ;  Saharia et al. ,  2022 ;  Rombach et al. ,  2022 ;  Podell et al. ,  2024 ;  Zheng et al. ,  2024 ) . However, their capacity to memorize and reproduce specific images and concepts from training datasets raises significant privacy and safety concerns. Moreover, they are susceptible to poisoning attacks, enabling the generation of targeted images with embedded triggers, posing substantial security risks  ( Rando et al. ,  2022 ;  Chen et al. ,  2023b ) .",
            "To address these challenges, we introduce  Score Forgetting Distillation  (SFD), a novel framework designed to efficiently mitigate the influence of specific characteristics in data points on pre-trained diffusion models. This framework is a key part of the broader domain of Machine Unlearning (MU), which has evolved significantly to address core issues in trustworthy machine learning  ( Lowd and Meek ,  2005 ;  Narayanan and Shmatikov ,  2008 ;  Abadi et al. ,  2016 ) . Originating from compliance needs with data protection regulations such as the right to be forgotten  ( Hoofnagle et al. ,  2019 ) , MU has broadened its scope to include applications in diffusion modeling across various domains like computer vision and content generation  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Additionally, MU aims to promote model fairness  ( Oesterling et al. ,  2024 ) , refine pre-training methodologies  ( Jain et al. ,  2023 ;  Jia et al. ,  2023 ) , and reduce the generation of inappropriate content  ( Gandikota et al. ,  2023 ) . The development of SFD is aligned with these objectives, providing a strategic approach to mitigate the potential risks and reduce the high generation costs associated with diffusion models, thereby advancing the field of trustworthy machine learning.",
            "MU methods are generally categorized into two types: exact MU and approximate MU. Exact MU entails creating a model that behaves as if sensitive data had never been part of the training set  ( Cao and Yang ,  2015 ;  Bourtoule et al. ,  2021 ) . This process requires the unlearned model to be identical in distribution to a model retrained without the sensitive data, both in terms of model weights and output behavior. In contrast, approximate MU does not seek an exact match between the unlearned model and a retrained model. Instead, it aims to approximate how closely the output distributions of the two models align after the unlearning process. A prominent strategy in approximate MU utilizes the principles of differential privacy  ( Dwork ,  2006 ) . For instance,  Guo et al.  ( 2019 )  introduced a certified removal technique that prevents adversaries from extracting information about removed training data, offering a theoretical guarantee of data privacy. However, these approaches typically necessitate retraining the model from scratch, which can be computationally intensive and require access to the original training dataset. Efficient and stable unlearning has become crucial in MU. Techniques like the influence functions  ( Warnecke et al. ,  2021 ;  Izzo et al. ,  2021 ) , selective forgetting  ( Golatkar et al. ,  2020 ) , weight-based pruning  ( Liu et al. ,  2024 ) , and gradient-based saliency  ( Fan et al. ,  2024 )  have been explored, though they often suffer from performance degradation or restrictive assumptions  ( Becker and Liebig ,  2022 ) . These methods are primarily applied to MU for image classification tasks and do not adequately address the rapid forgetting and unlearning required for data generation tasks.",
            "Before diving into the specific MU problem, we will first establish the essential concepts and notations in diffusion modeling: A diffusion model corrupts its data  x  p data  ( x  c ) similar-to x subscript p data conditional x c x\\sim p_{\\text{data}}(x\\mid c) italic_x  italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_x  italic_c )  during the forward diffusion process at time  t t t italic_t  as  z t = a t  x +  t   t subscript z t subscript a t x subscript  t subscript italic- t z_{t}=a_{t}x+\\sigma_{t}\\epsilon_{t} italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x + italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , where   t  N  ( 0 , 1 ) similar-to subscript italic- t N 0 1 \\epsilon_{t}\\sim\\mathcal{N}(0,1) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  caligraphic_N ( 0 , 1 ) ,  c c c italic_c  represents the given condition such as a label or text, and  a t subscript a t a_{t} italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and   t subscript  t \\sigma_{t} italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  are diffusion scheduling parameters. The goal of pretraining a diffusion model is to obtain an optimal score estimator  s   ( z t , c , t ) subscript s italic- subscript z t c t s_{\\phi}(z_{t},c,t) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  such that  s   ( z t , c , t ) =  z t ln  p data  ( z t | c ) subscript s italic- subscript z t c t subscript  subscript z t subscript p data conditional subscript z t c s_{\\phi}(z_{t},c,t)=\\nabla_{z_{t}}\\ln p_{\\text{data}}(z_{t}\\,|\\,c) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) =  start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c ) . Let  x   ( z t , c , t ) subscript x italic- subscript z t c t x_{\\phi}(z_{t},c,t) italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  be the optimal conditional mean estimator such that for  x   ( z t , c , t ) = E  [ x | z t , c , t ] subscript x italic- subscript z t c t E delimited-[] conditional x subscript z t c t x_{\\phi}(z_{t},c,t)=\\mathbb{E}[x\\,|\\,z_{t},c,t] italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) = blackboard_E [ italic_x | italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ] . Applying Tweedies formula  ( Robbins ,  1992 ;  Efron ,  2011 )  in the context of diffusion modeling  ( Luo ,  2022 ;  Chung et al. ,  2023 ;  Zhou et al. ,  2024b ) , the optimal score and conditional mean estimators,  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and  x  subscript x italic- x_{\\phi} italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT , for the training data are related as follows:",
            "With this optimal score estimator, we can construct a corresponding reverse diffusion process, enabling us to approximately sample from the data distribution through numerical discretization along the time horizon  ( Anderson ,  1982 ;  Song et al. ,  2020 ) .",
            "A distilled one-step diffusion model is a one-step generator capable of producing samples from the generative distribution of a pretrained model in a single step. The generation process for this one-step generator is defined as  g   ( n , c ) subscript g  n c g_{\\theta}(n,c) italic_g start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_n , italic_c ) , where  n  N  ( 0 , I ) similar-to n N 0 I n\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I}) italic_n  caligraphic_N ( bold_0 , bold_I ) . Denote the generative distribution of  x x x italic_x  given class  c c c italic_c  as  D  , c subscript D  c \\mathcal{D}_{\\theta,c} caligraphic_D start_POSTSUBSCRIPT italic_ , italic_c end_POSTSUBSCRIPT , and the optimal score estimator corresponding to the one-step generator  g  subscript g  g_{\\theta} italic_g start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  as  s    (  )  ( z t , c , t ) subscript s superscript   subscript z t c t s_{\\psi^{*}(\\theta)}(z_{t},c,t) italic_s start_POSTSUBSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ ) end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) . The same as how  x  subscript x italic- x_{\\phi} italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  is related in Eq.  1 , we have",
            "In the problem setting of concept forgetting in text-to-image diffusion models, our goal is to unlearn the concepts associated with specific keywords, such as Brad Pitt, by substituting them with more generic terms like a middle aged man, as illustrated in Figure  1 . This process aims to minimize any negative impact on the generation quality of other concepts, thereby maintaining the overall integrity and diversity of the images generated under text guidance.",
            "In the problem of class unlearning, as described in Section  2.1 , our goal is to align the conditional distributions of both the forgetting class and the remaining classes with those that would exist if the model had been retrained without the data from the forgetting class. By adapting the concept of data-free score distillation to the MU challenge, we aim to achieve this alignment using our proposed data-free MU process, SFD. Our method eliminates the need for access to the original training data and accelerates synthetic data sampling, effectively enabling the forgetting of a specific class while preserving the original generative capabilities for the other classes.",
            "where   t > 0 subscript  t 0 \\gamma_{t}>0 italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT > 0  is a re-weighting function. In practice, the lack of the access to   x ln  p   ( z t | c ) subscript  x subscript p  conditional subscript z t c \\nabla_{x}\\ln p_{\\theta}(z_{t}\\,|\\,c)  start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c )  makes Eq.  4  intractable. However, we can alternatively optimize a denoising SM loss  ( Vincent ,  2011 )  as",
            "This formulation corresponds to a bi-level optimization problem  ( Ye et al. ,  1997 ;  Hong et al. ,  2023 ;  Shen et al. ,  2023 ) , subject to an additional forgetting-based constraint. Solving this problem directly is challenging, so we initially relax the constraint specified by  L sfd subscript L sfd \\mathcal{L}_{\\text{sfd}} caligraphic_L start_POSTSUBSCRIPT sfd end_POSTSUBSCRIPT  in the above equation by integrating it into the distillation objective as an additional MU regularization term:",
            "where    \\lambda italic_  and    \\mu italic_  are tunable constants that serve as control knobs to balance the distillation of the remaining classes and the unlearning of the target class. Furthermore, we implement an alternating update strategy between    \\theta italic_  and    \\psi italic_ . This approach mitigates the need to obtain the optimal score estimator     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ )  for each    \\theta italic_ , simplifying the computational process. We outline a practical implementation of this strategy in  Algorithm   1 . Specifically, generalizing the derivation in  Zhou et al.  ( 2024b ) , we have the following Lemma, whose proof is provided in  Appendix   D :",
            "To quantitatively assess the effectiveness of class forgetting, we primarily focus on the success rate of forgetting the target class, and the generative capability on classes to retain. Specifically, we measure the success rate of forgetting by unlearning accuracy (UA) employing an external classifier trained on the original training set, which is essentially the mis-classification rate of the classifier on the generated samples from the target class. We measure image generation quality using Frechet Inception Distance (FID)  ( Heusel et al. ,  2017 )  and sample diversity using Inception Score (IS)  ( Salimans et al. ,  2016 ) . Additionally, we report Precision and Recall  ( Kynkaanniemi et al. ,  2019 ) , and number of function evaluations (NFEs) for sampling. Following  Fan et al.  ( 2024 ) , we compute and report generation quality metrics using generated samples, with the full training set from the remaining classes serving as the reference. For concept forgetting tasks including celebrity forgetting and nudity forgetting, we also provide quantitative evaluations as well as qualitative comparison. Specifically, we evaluate celebrity forgetting using a off-the-shelf celebrity face detector, while we assess the MU performance of our nudity forgetting model on the I2P benchmark ( https://github.com/ml-research/i2p ). Please refer to  Section   B.2  for more details of the evaluation metrics.",
            "We provide both qualitative and quantitative results of celebrity forgetting tasks on two selected celebrities,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , Brad Pitt and Angelina Jolie, where the concepts to forget are bard pitt and angelina jolie, respectively, and the corresponding concepts to override are a middle aged man and a middle aged woman, respectively. As is shown in  Figure   1  and  Table   2 , we showcase the effectiveness of SFD for forgetting certain concepts in text-to-image diffusion models, such as removing the generative capability of celebrities.",
            "Classifier-free guidance (CFG), first proposed by  Ho and Salimans  ( 2021 ) , is a commonly-used strategy for conditional sampling. While typically adopted during inference to enhance class fidelity, it has also been shown to be useful for the training of score-based distillation  ( Yin et al. ,  2024 ;  Zhou et al. ,  2024a ) . We compare our models trained with and without CFG in  Table   4 . In our experiments on STL-10, we found that including classifier-free guidance during training improved the performance in terms of both FID and UA. However, we did not observe such improvements on the CIFAR-10 dataset; on the contrary, we noticed a degradation in the evaluation metrics. We speculate that the influence of CFG may be tied to the inter-class differences: when training data contain classes sharing similar features, such as automobile and truck in CIFAR-10, training with CFG may not be as beneficial as it is when the training dataset consists of more distinct classes.",
            "The study of MU can be traced back to classical machine learning models in response to data protection regulations such as the right to be forgotten  [ Cao and Yang ,  2015 ,  Hoofnagle et al. ,  2019 ,  Bourtoule et al. ,  2021 ,  Nguyen et al. ,  2022 ] . Due to its capability of assessing data influence on model performance, the landscape of MU has expanded to encompass diverse domains, such as image classification  [ Ginart et al. ,  2019 ,  Golatkar et al. ,  2020 ,  Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] , text-to-image generation  [ Gandikota et al. ,  2023 ,  Zhang et al. ,  2023a ,  Kumari et al. ,  2023 ,  Fan et al. ,  2024 ] , federated learning  [ Halimi et al. ,  2022 ,  Che et al. ,  2023 ] , and graph neural networks  [ Chen et al. ,  2022 ,  Chien et al. ,  2022 ,  Wu et al. ,  2023 ] . In the literature, exact unlearning, which involves retraining the model from scratch after removing specific training data points, is often considered the gold standard. However, this approach comes with significant computational demands and requires access to the entire training set  [ Thudi et al. ,  2022 ] . To address these challenges, many research efforts have shifted towards the development of scalable and effective approximate unlearning methods  [ Liu et al. ,  2024 ,  Chen et al. ,  2023a ] . In addition, probabilistic methods with certain provable removal guarantees have been explored, often leveraging the concept of differential privacy  [ Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] . Focusing on MU in diffusion-based image generation, this paper introduces a general data-free approach for rapid forgetting and one-step sampling in diffusion models, eliminating the need to access any real data.",
            "In examining the challenges and strategies associated with diffusion models and MU, several key issues and methodologies have been identified. Diffusion models, particularly when trained on data from open collections, face risks of contamination or manipulation, which could lead to the generation of inappropriate or offensive content  [ Chen et al. ,  2023b ,  Schramowski et al. ,  2023 ] . Strategies to mitigate these include data censoring and safety guidance to steer models away from undesirable outputs  [ Nichol et al. ,  2021 ] , and introducing subtle perturbations to protect artistic styles  [ Shan et al. ,  2023 ] . Despite these measures, challenges remain in fully preventing diffusion models from generating harmful content or being susceptible to targeted poison attacks  [ Rando et al. ,  2022 ] . Furthermore, the evaluation of MU presents unique difficulties, especially as conventional retraining benchmarks are often impractical. Empirical metrics for assessing MU include unlearning accuracy, the utility of the model post-unlearning, and the use of classifiers to gauge the integrity of generated outputs  [ Jang et al. ,  2022 ] . Unlike existing methods, our approach efficiently suppresses the generation of harmful content using a one-step diffusion generator that overrides unsafe concepts with MU-regularized score-based distillation.",
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper.",
            "Classic score-matching-based diffusion models  [ Sohl-Dickstein et al. ,  2015 ,  Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  have become increasingly influential in developing generative models with high extensibility and sample quality  [ Dhariwal and Nichol ,  2021 ,  Karras et al. ,  2022 ,  Ramesh et al. ,  2022 ] . However, standard Gaussian diffusion models, along with other non-Gaussian variants  [ Hoogeboom et al. ,  2021 ,  Austin et al. ,  2021 ,  Chen and Zhou ,  2023 ,  Zhou et al. ,  2023 ] , suffer from relatively slow sampling compared to traditional one-step generative models, such as GANs and VAEs. Inspired by the success of applying diffusion processes to the training of generative models,  Xiao et al.   [ 2021 ]  and  Wang et al.   [ 2022 ]  were among the first to promote faster generation by leveraging both adversarial training techniques and diffusion-based data augmentation. However, these approaches inevitably reintroduce potential issues like training instability and mode collapse. Closely related to the original score matching,  Salimans and Ho   [ 2022 ]  proposed progressively halving the steps needed in the reverse generation process. Similarly,  Song et al.   [ 2023 ]  presented the consistency model as a method for distilling the reverse ODE sampling process. Along this direction, much effort has been made by others  [ Xu et al. ,  2023 ,  Yin et al. ,  2024 ,  Luo et al. ,  2023 ,  Zhou et al. ,  2024b ]  to improve both sample quality and diversity.",
            "When applying MU to classification tasks, effectiveness-oriented metrics include unlearning accuracy, which evaluates how accurately the model performs on the forget set after unlearning  [ Golatkar et al. ,  2020 ] . Utility-oriented metrics include remaining accuracy, which measures the updated models performance on the retain set post-unlearning  [ Song and Mittal ,  2021 ] , and testing accuracy, which assesses the models generalization capability after unlearning. For generation tasks, accuracy-based metrics use a post-generation classifier to evaluate the generated content  [ Zhang et al. ,  2023b ] , while quality metrics assess the overall utility of the generated outputs  [ Gandikota et al. ,  2023 ] . A significant limitation of these metrics, particularly in measuring unlearning effectiveness, is their heavy dependence on the specific unlearning tasks  [ Fan et al. ,  2024 ] . To address this, we train an external classifier to evaluate  unlearning accuracy  (UA), ensuring that the generated images do not belong to the forgetting class or concept. Additionally, we use FID to evaluate the quality of image generations for non-forgetting classes or prompts.",
            "For the class forgetting tasks, we utilize CIFAR-10  [ Krizhevsky ,  2009 ]  at a resolution of  32  32 32 32 32\\times 32 32  32  and STL-10  [ Coates et al. ,  2011 ]  at  64  64 64 64 64\\times 64 64  64  resolution. The CIFAR-10 dataset consists of 60,000 32  \\times  32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. The dataset consists of 50,000 training images and 10,000 test images. It is organized into five training batches and one test batch, each containing 10,000 images. The test batch includes precisely 1,000 randomly-selected images from each class. The training batches, which hold the remaining images in random order, may have varying numbers of images from each class. The STL-10 dataset is another natural image dataset with 10 classes, each of which has 500 training data and 800 testing data. The image data has a higher resolution of 96  \\times  96 in pixels and RGB color channels compared with CIFAR-10. The images were acquired from labeled examples on ImageNet  [ Deng et al. ,  2009 ] . During training time, the image data from STL-10 are resized to 64  \\times  64. Due to the limited number of the original training data, both training and testing data were used in the experiments, making up 13,000 training images in total.",
            "For class forgetting tasks, we employed an external classifier to obtain unlearning accuracy (UA), ensuring that the generated images are not associated with the class or concept designated for forgetting. The UA is essentially the mis-classification rate of the classifier on the generated samples from the target class. A classifier with high test accuracy and low UA typically indicates effective forgetting, ensuring that the generated images are unlikely to belong to the target class or concept. For the external classifier, we fine-tuned ResNet-34  [ He et al. ,  2016 ]  for 10 epochs on both CIFAR-10 and STL-10 datasets using transfer learning, which is originally pretrained on ImageNet  [ Deng et al. ,  2009 ] . We adapted the original 1000-way classification model by replacing the last fully-connected layer with a customized fully-connected layer with 10 output dimension. The resulting classifiers achieved training and testing accuracies of 99.96% and 95.03% on CIFAR-10, and 100.00% and 96.20% on STL-10, respectively.",
            "We implemented our techniques in a newly developed codebase, loosely based on the original implementations by  [ Karras et al. ,  2022 ,  Fan et al. ,  2024 ,  Zhou et al. ,  2024a ] . The pseudo-code is described in  Algorithm   1 . We performed extensive evaluation to verify that our implementation produced exactly the same results as previous work, including samplers, pre-trained models, network architectures, training configurations, and evaluation. We ran all experiments using PyTorch with 4 NVIDIA RTX A5000 GPUs."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Quantitative results of celebrity forgetting of two celebrities,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , Brad Pitt and Angelina Jolie.  Bold values indicate the best score in each column, while underlined values represent the second-best.",
        "table": "A4.EGx2",
        "footnotes": [],
        "references": [
            "Diffusion models, also known as score-based generative models  ( Sohl-Dickstein et al. ,  2015 ;  Song and Ermon ,  2019 ;  Ho et al. ,  2020 ;  Dhariwal and Nichol ,  2021 ;  Karras et al. ,  2022 ) , have emerged as the leading choice for generative modeling of high-dimensional data. These models are widely celebrated for their ability to produce high-quality, diverse, and photorealistic images  ( Nichol et al. ,  2022 ;  Ramesh et al. ,  2022 ;  Saharia et al. ,  2022 ;  Rombach et al. ,  2022 ;  Podell et al. ,  2024 ;  Zheng et al. ,  2024 ) . However, their capacity to memorize and reproduce specific images and concepts from training datasets raises significant privacy and safety concerns. Moreover, they are susceptible to poisoning attacks, enabling the generation of targeted images with embedded triggers, posing substantial security risks  ( Rando et al. ,  2022 ;  Chen et al. ,  2023b ) .",
            "To address these challenges, we introduce  Score Forgetting Distillation  (SFD), a novel framework designed to efficiently mitigate the influence of specific characteristics in data points on pre-trained diffusion models. This framework is a key part of the broader domain of Machine Unlearning (MU), which has evolved significantly to address core issues in trustworthy machine learning  ( Lowd and Meek ,  2005 ;  Narayanan and Shmatikov ,  2008 ;  Abadi et al. ,  2016 ) . Originating from compliance needs with data protection regulations such as the right to be forgotten  ( Hoofnagle et al. ,  2019 ) , MU has broadened its scope to include applications in diffusion modeling across various domains like computer vision and content generation  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Additionally, MU aims to promote model fairness  ( Oesterling et al. ,  2024 ) , refine pre-training methodologies  ( Jain et al. ,  2023 ;  Jia et al. ,  2023 ) , and reduce the generation of inappropriate content  ( Gandikota et al. ,  2023 ) . The development of SFD is aligned with these objectives, providing a strategic approach to mitigate the potential risks and reduce the high generation costs associated with diffusion models, thereby advancing the field of trustworthy machine learning.",
            "MU methods are generally categorized into two types: exact MU and approximate MU. Exact MU entails creating a model that behaves as if sensitive data had never been part of the training set  ( Cao and Yang ,  2015 ;  Bourtoule et al. ,  2021 ) . This process requires the unlearned model to be identical in distribution to a model retrained without the sensitive data, both in terms of model weights and output behavior. In contrast, approximate MU does not seek an exact match between the unlearned model and a retrained model. Instead, it aims to approximate how closely the output distributions of the two models align after the unlearning process. A prominent strategy in approximate MU utilizes the principles of differential privacy  ( Dwork ,  2006 ) . For instance,  Guo et al.  ( 2019 )  introduced a certified removal technique that prevents adversaries from extracting information about removed training data, offering a theoretical guarantee of data privacy. However, these approaches typically necessitate retraining the model from scratch, which can be computationally intensive and require access to the original training dataset. Efficient and stable unlearning has become crucial in MU. Techniques like the influence functions  ( Warnecke et al. ,  2021 ;  Izzo et al. ,  2021 ) , selective forgetting  ( Golatkar et al. ,  2020 ) , weight-based pruning  ( Liu et al. ,  2024 ) , and gradient-based saliency  ( Fan et al. ,  2024 )  have been explored, though they often suffer from performance degradation or restrictive assumptions  ( Becker and Liebig ,  2022 ) . These methods are primarily applied to MU for image classification tasks and do not adequately address the rapid forgetting and unlearning required for data generation tasks.",
            "Given the prominence of diffusion models, there is a growing need to develop MU techniques that specifically cater to these models, ensuring efficient unlearning while maintaining generation capabilities  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Our SFD framework efficiently distills the knowledge from a pre-trained diffusion model by optimizing two learnable modulesa generator network and a score networkguided by the frozen pre-trained model itself. The score network is trained to optimize the score associated with the generator by minimizing a score distillation loss, which aims to match the conditional scores of the class to forget and the classes to remember with those of the pre-trained model. The generator network learns to produce examples that are indistinguishable by the pre-trained score network and fake score network in terms of score predictions, utilizing a model-based cross-class score distillation loss.",
            "Diffusion models are celebrated for their superior performance in generating high-quality and diverse samples. However, their robust capabilities also introduce challenges, particularly the risk of misuse in generating inappropriate content. This concern highlights the ethical implications and potential negative impacts of their application. Additionally, these models have a significant drawback: slow sampling speeds. This inefficiency becomes particularly problematic in downstream tasks that require finetuning on synthetic data generated by these models. When access to real data is not feasible, the task of preparing a sufficiently large synthetic dataset can already become computationally prohibitive  ( Yin et al. ,  2024 ) . This issue is especially acute in the context of MU and image generation, where access to real data often raises privacy concerns, making reliance on synthetic data crucial. Consequently, the slow sampling rate of diffusion models presents a critical bottleneck, necessitating improvements to enable effective data-free MU operations.",
            "In this section, we introduce SFD, a principled and data-free approach designed to address the MU problem while simultaneously achieving fast sampling for diffusion models. Building on recent advancements in data-free diffusion distillation for one-step generation  ( Luo et al. ,  2023 ;  Zhou et al. ,  2024b ) , we conceptualize MU in diffusion models as a problem of MU-regularized score distillation.",
            "Before diving into the specific MU problem, we will first establish the essential concepts and notations in diffusion modeling: A diffusion model corrupts its data  x  p data  ( x  c ) similar-to x subscript p data conditional x c x\\sim p_{\\text{data}}(x\\mid c) italic_x  italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_x  italic_c )  during the forward diffusion process at time  t t t italic_t  as  z t = a t  x +  t   t subscript z t subscript a t x subscript  t subscript italic- t z_{t}=a_{t}x+\\sigma_{t}\\epsilon_{t} italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x + italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , where   t  N  ( 0 , 1 ) similar-to subscript italic- t N 0 1 \\epsilon_{t}\\sim\\mathcal{N}(0,1) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  caligraphic_N ( 0 , 1 ) ,  c c c italic_c  represents the given condition such as a label or text, and  a t subscript a t a_{t} italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and   t subscript  t \\sigma_{t} italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  are diffusion scheduling parameters. The goal of pretraining a diffusion model is to obtain an optimal score estimator  s   ( z t , c , t ) subscript s italic- subscript z t c t s_{\\phi}(z_{t},c,t) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  such that  s   ( z t , c , t ) =  z t ln  p data  ( z t | c ) subscript s italic- subscript z t c t subscript  subscript z t subscript p data conditional subscript z t c s_{\\phi}(z_{t},c,t)=\\nabla_{z_{t}}\\ln p_{\\text{data}}(z_{t}\\,|\\,c) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) =  start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c ) . Let  x   ( z t , c , t ) subscript x italic- subscript z t c t x_{\\phi}(z_{t},c,t) italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  be the optimal conditional mean estimator such that for  x   ( z t , c , t ) = E  [ x | z t , c , t ] subscript x italic- subscript z t c t E delimited-[] conditional x subscript z t c t x_{\\phi}(z_{t},c,t)=\\mathbb{E}[x\\,|\\,z_{t},c,t] italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) = blackboard_E [ italic_x | italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ] . Applying Tweedies formula  ( Robbins ,  1992 ;  Efron ,  2011 )  in the context of diffusion modeling  ( Luo ,  2022 ;  Chung et al. ,  2023 ;  Zhou et al. ,  2024b ) , the optimal score and conditional mean estimators,  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and  x  subscript x italic- x_{\\phi} italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT , for the training data are related as follows:",
            "With this optimal score estimator, we can construct a corresponding reverse diffusion process, enabling us to approximately sample from the data distribution through numerical discretization along the time horizon  ( Anderson ,  1982 ;  Song et al. ,  2020 ) .",
            "In the problem of class unlearning, as described in Section  2.1 , our goal is to align the conditional distributions of both the forgetting class and the remaining classes with those that would exist if the model had been retrained without the data from the forgetting class. By adapting the concept of data-free score distillation to the MU challenge, we aim to achieve this alignment using our proposed data-free MU process, SFD. Our method eliminates the need for access to the original training data and accelerates synthetic data sampling, effectively enabling the forgetting of a specific class while preserving the original generative capabilities for the other classes.",
            "where   t > 0 subscript  t 0 \\gamma_{t}>0 italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT > 0  is a re-weighting function. In practice, the lack of the access to   x ln  p   ( z t | c ) subscript  x subscript p  conditional subscript z t c \\nabla_{x}\\ln p_{\\theta}(z_{t}\\,|\\,c)  start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c )  makes Eq.  4  intractable. However, we can alternatively optimize a denoising SM loss  ( Vincent ,  2011 )  as",
            "This formulation corresponds to a bi-level optimization problem  ( Ye et al. ,  1997 ;  Hong et al. ,  2023 ;  Shen et al. ,  2023 ) , subject to an additional forgetting-based constraint. Solving this problem directly is challenging, so we initially relax the constraint specified by  L sfd subscript L sfd \\mathcal{L}_{\\text{sfd}} caligraphic_L start_POSTSUBSCRIPT sfd end_POSTSUBSCRIPT  in the above equation by integrating it into the distillation objective as an additional MU regularization term:",
            "where    \\lambda italic_  and    \\mu italic_  are tunable constants that serve as control knobs to balance the distillation of the remaining classes and the unlearning of the target class. Furthermore, we implement an alternating update strategy between    \\theta italic_  and    \\psi italic_ . This approach mitigates the need to obtain the optimal score estimator     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ )  for each    \\theta italic_ , simplifying the computational process. We outline a practical implementation of this strategy in  Algorithm   1 . Specifically, generalizing the derivation in  Zhou et al.  ( 2024b ) , we have the following Lemma, whose proof is provided in  Appendix   D :",
            "A biased loss for    \\theta italic_  can be derived by replacing     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ )  in either Eq.  3  or Eq.  8  with its SGD-based approximation    \\psi italic_ , and disregarding the dependency of    superscript  \\psi^{*} italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  on    \\theta italic_  when computing the gradient of    \\theta italic_ . Empirical experiments by  Zhou et al.  ( 2024b )  suggest that in the context of diffusion distillation without involving unlearning, Eq.  8  can be effective independently, while Eq.  3  may not perform as expected. This observation leads to a practical approach that involves subtracting Eq.  3  from Eq.  8 . This strategy aims to sidestep detrimental biased gradient directions and potentially compensate for the overlooked gradient dependency of     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ ) . We implement this approach in practice under the framework of SFD, defining the loss used in practice as follows:",
            "where    0  0 \\alpha\\geq 0 italic_  0  is some constant that typically set as 1 or 1.2,  z t = a t  x +  t   t , x  D  , c 2 ,  t  N  ( 0 , I ) , t  Unif  [ t min , t max ] formulae-sequence subscript z t subscript a t x subscript  t subscript italic- t formulae-sequence similar-to x subscript D  subscript c 2 formulae-sequence similar-to subscript italic- t N 0 I similar-to t Unif subscript t min subscript t max z_{t}=a_{t}x+\\sigma_{t}{\\epsilon}_{t},~{}x\\sim\\mathcal{D}_{\\theta,c_{2}},~{}{% \\epsilon}_{t}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I}),~{}t\\sim\\text{Unif}[t_{% \\text{min}},t_{\\text{max}}] italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x + italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_x  caligraphic_D start_POSTSUBSCRIPT italic_ , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  caligraphic_N ( bold_0 , bold_I ) , italic_t  Unif [ italic_t start_POSTSUBSCRIPT min end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT max end_POSTSUBSCRIPT ] . In this paper, we follow  Yin et al.  ( 2024 )  and  Zhou et al.  ( 2024b )  to set   t =  t 4 a t 2  C  x   ( z t , t , c )  x  1 , sg subscript  t superscript subscript  t 4 superscript subscript a t 2 C subscript norm subscript x italic- subscript z t t c x 1 sg \\omega_{t}=\\frac{\\sigma_{t}^{4}}{a_{t}^{2}}\\frac{C}{\\|x_{\\phi}(z_{t},t,c)-x\\|_% {1,\\text{sg}}} italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = divide start_ARG italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_ARG start_ARG italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG divide start_ARG italic_C end_ARG start_ARG  italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , italic_c ) - italic_x  start_POSTSUBSCRIPT 1 , sg end_POSTSUBSCRIPT end_ARG , where  C C C italic_C  is the data dimension and sg stands for stop gradient.",
            "We explore class forgetting in class-conditional image generation tasks using DDPM  ( Ho et al. ,  2020 ) , and investigate concept forgetting in text-to-image generation tasks using Stable Diffusion  ( Rombach et al. ,  2022 ) . Class forgetting aims to prevent class-conditional diffusion models from generating images of a specified class, while concept forgetting seeks to remove the models ability to generate images containing specific concepts, such as celebrities or inappropriate content. Class-conditional and text-to-image sampling are achieved by inputting class labels and text prompts into the respective diffusion models, with fidelity further enhanced by classifier-free guidance introduced in  Ho and Salimans  ( 2022 ) . Specifically, we approach unlearning by overriding a class or concept with another that is safe to retain. The class forgetting experiments were conducted on class-conditional diffusion models pre-trained on CIFAR-10 and STL-10, while the concept forgetting experiments were conducted on Stable Diffusion, including forgetting celebrities, specifically American actor Brad Pitt and actress Angelina Jolie, and forgetting a general NSFW (not safe for work) concept,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , nudity. For DDPM baselines, we used the default 1000-step DDPM samplers to obtain FIDs for samples from the remaining classes, while for SD baselines, we used DDIM samplers with 50 steps. In contrast, our method requires only a single step for generation, making it 1,000 times faster than the DDPM baselines and 50 times faster in latent sampling than the SD baselines.",
            "To quantitatively assess the effectiveness of class forgetting, we primarily focus on the success rate of forgetting the target class, and the generative capability on classes to retain. Specifically, we measure the success rate of forgetting by unlearning accuracy (UA) employing an external classifier trained on the original training set, which is essentially the mis-classification rate of the classifier on the generated samples from the target class. We measure image generation quality using Frechet Inception Distance (FID)  ( Heusel et al. ,  2017 )  and sample diversity using Inception Score (IS)  ( Salimans et al. ,  2016 ) . Additionally, we report Precision and Recall  ( Kynkaanniemi et al. ,  2019 ) , and number of function evaluations (NFEs) for sampling. Following  Fan et al.  ( 2024 ) , we compute and report generation quality metrics using generated samples, with the full training set from the remaining classes serving as the reference. For concept forgetting tasks including celebrity forgetting and nudity forgetting, we also provide quantitative evaluations as well as qualitative comparison. Specifically, we evaluate celebrity forgetting using a off-the-shelf celebrity face detector, while we assess the MU performance of our nudity forgetting model on the I2P benchmark ( https://github.com/ml-research/i2p ). Please refer to  Section   B.2  for more details of the evaluation metrics.",
            "Our main implementation of class forgetting experiments is based on DDPM  ( Ho et al. ,  2020 ) , where we utilize the codebase developed by  Fan et al.  ( 2024 ) . Additionally, we implement our method using EDM  ( Karras et al. ,  2022 )  framework and the official codebase ( https://github.com/NVlabs/edm ). For concept forgetting experiments, we implement our method for SD models based on the implementation of  Zhou et al.  ( 2024a ) . We adopt the same model configuration for both the generator  g  subscript g  g_{\\theta} italic_g start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and its score estimation network  s  subscript s  s_{\\psi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and initialize the model weights according to the pre-trained score network  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT . This type of initialization prepares a good starting point for SFD.",
            "We provide both qualitative and quantitative results of celebrity forgetting tasks on two selected celebrities,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , Brad Pitt and Angelina Jolie, where the concepts to forget are bard pitt and angelina jolie, respectively, and the corresponding concepts to override are a middle aged man and a middle aged woman, respectively. As is shown in  Figure   1  and  Table   2 , we showcase the effectiveness of SFD for forgetting certain concepts in text-to-image diffusion models, such as removing the generative capability of celebrities.",
            "EDM  ( Karras et al. ,  2022 )  is a state-of-the-art diffusion model with enhanced capability for generating high-quality images. To evaluate our methods generalizability across different model architectures, we additionally conduct experiment using the EDM architecture. We adapted the codebase used by SiD  ( Zhou et al. ,  2024b )  and fine-tuned the pre-trained class-conditional CIFAR-10 EDM-VP model.  Figure   5  shows that the FID results of our method can be further improve when based on a more powerful pre-trained model.",
            "Classifier-free guidance (CFG), first proposed by  Ho and Salimans  ( 2021 ) , is a commonly-used strategy for conditional sampling. While typically adopted during inference to enhance class fidelity, it has also been shown to be useful for the training of score-based distillation  ( Yin et al. ,  2024 ;  Zhou et al. ,  2024a ) . We compare our models trained with and without CFG in  Table   4 . In our experiments on STL-10, we found that including classifier-free guidance during training improved the performance in terms of both FID and UA. However, we did not observe such improvements on the CIFAR-10 dataset; on the contrary, we noticed a degradation in the evaluation metrics. We speculate that the influence of CFG may be tied to the inter-class differences: when training data contain classes sharing similar features, such as automobile and truck in CIFAR-10, training with CFG may not be as beneficial as it is when the training dataset consists of more distinct classes.",
            "The study of MU can be traced back to classical machine learning models in response to data protection regulations such as the right to be forgotten  [ Cao and Yang ,  2015 ,  Hoofnagle et al. ,  2019 ,  Bourtoule et al. ,  2021 ,  Nguyen et al. ,  2022 ] . Due to its capability of assessing data influence on model performance, the landscape of MU has expanded to encompass diverse domains, such as image classification  [ Ginart et al. ,  2019 ,  Golatkar et al. ,  2020 ,  Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] , text-to-image generation  [ Gandikota et al. ,  2023 ,  Zhang et al. ,  2023a ,  Kumari et al. ,  2023 ,  Fan et al. ,  2024 ] , federated learning  [ Halimi et al. ,  2022 ,  Che et al. ,  2023 ] , and graph neural networks  [ Chen et al. ,  2022 ,  Chien et al. ,  2022 ,  Wu et al. ,  2023 ] . In the literature, exact unlearning, which involves retraining the model from scratch after removing specific training data points, is often considered the gold standard. However, this approach comes with significant computational demands and requires access to the entire training set  [ Thudi et al. ,  2022 ] . To address these challenges, many research efforts have shifted towards the development of scalable and effective approximate unlearning methods  [ Liu et al. ,  2024 ,  Chen et al. ,  2023a ] . In addition, probabilistic methods with certain provable removal guarantees have been explored, often leveraging the concept of differential privacy  [ Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] . Focusing on MU in diffusion-based image generation, this paper introduces a general data-free approach for rapid forgetting and one-step sampling in diffusion models, eliminating the need to access any real data.",
            "In examining the challenges and strategies associated with diffusion models and MU, several key issues and methodologies have been identified. Diffusion models, particularly when trained on data from open collections, face risks of contamination or manipulation, which could lead to the generation of inappropriate or offensive content  [ Chen et al. ,  2023b ,  Schramowski et al. ,  2023 ] . Strategies to mitigate these include data censoring and safety guidance to steer models away from undesirable outputs  [ Nichol et al. ,  2021 ] , and introducing subtle perturbations to protect artistic styles  [ Shan et al. ,  2023 ] . Despite these measures, challenges remain in fully preventing diffusion models from generating harmful content or being susceptible to targeted poison attacks  [ Rando et al. ,  2022 ] . Furthermore, the evaluation of MU presents unique difficulties, especially as conventional retraining benchmarks are often impractical. Empirical metrics for assessing MU include unlearning accuracy, the utility of the model post-unlearning, and the use of classifiers to gauge the integrity of generated outputs  [ Jang et al. ,  2022 ] . Unlike existing methods, our approach efficiently suppresses the generation of harmful content using a one-step diffusion generator that overrides unsafe concepts with MU-regularized score-based distillation.",
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper.",
            "Classic score-matching-based diffusion models  [ Sohl-Dickstein et al. ,  2015 ,  Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  have become increasingly influential in developing generative models with high extensibility and sample quality  [ Dhariwal and Nichol ,  2021 ,  Karras et al. ,  2022 ,  Ramesh et al. ,  2022 ] . However, standard Gaussian diffusion models, along with other non-Gaussian variants  [ Hoogeboom et al. ,  2021 ,  Austin et al. ,  2021 ,  Chen and Zhou ,  2023 ,  Zhou et al. ,  2023 ] , suffer from relatively slow sampling compared to traditional one-step generative models, such as GANs and VAEs. Inspired by the success of applying diffusion processes to the training of generative models,  Xiao et al.   [ 2021 ]  and  Wang et al.   [ 2022 ]  were among the first to promote faster generation by leveraging both adversarial training techniques and diffusion-based data augmentation. However, these approaches inevitably reintroduce potential issues like training instability and mode collapse. Closely related to the original score matching,  Salimans and Ho   [ 2022 ]  proposed progressively halving the steps needed in the reverse generation process. Similarly,  Song et al.   [ 2023 ]  presented the consistency model as a method for distilling the reverse ODE sampling process. Along this direction, much effort has been made by others  [ Xu et al. ,  2023 ,  Yin et al. ,  2024 ,  Luo et al. ,  2023 ,  Zhou et al. ,  2024b ]  to improve both sample quality and diversity.",
            "To address the slow sampling speed associated with traditional diffusion models, score distillation methods have been developed to harness pretrained score functions. These methods approximate data scores, facilitating model distribution matching under noisy conditions to align with the noisy data distribution governed by the pretrained denoising score matching function. These methods, as explored in several recent works  [ Poole et al. ,  2023 ,  Wang et al. ,  2023 ,  Luo et al. ,  2023 ,  Nguyen and Tran ,  2023 ,  Yin et al. ,  2024 ] , primarily utilize the KL divergence, whose gradients can be analytically computed using both the pretrained and estimated score functions. Importantly, these KL-based methods do not require access to real data, as the KL divergence is defined with respect to the model distribution. While these approaches have successfully approximated the data distribution in a data-free manner, they often suffer from performance degradation when compared to the original, pretrained teacher diffusion model. Consequently, additional loss terms that require access to the original training data or data synthesized with the pretrained diffusion models are often necessary to mitigate this performance degradation. However, employing these terms voids the data-free feature of the process.",
            "When applying MU to classification tasks, effectiveness-oriented metrics include unlearning accuracy, which evaluates how accurately the model performs on the forget set after unlearning  [ Golatkar et al. ,  2020 ] . Utility-oriented metrics include remaining accuracy, which measures the updated models performance on the retain set post-unlearning  [ Song and Mittal ,  2021 ] , and testing accuracy, which assesses the models generalization capability after unlearning. For generation tasks, accuracy-based metrics use a post-generation classifier to evaluate the generated content  [ Zhang et al. ,  2023b ] , while quality metrics assess the overall utility of the generated outputs  [ Gandikota et al. ,  2023 ] . A significant limitation of these metrics, particularly in measuring unlearning effectiveness, is their heavy dependence on the specific unlearning tasks  [ Fan et al. ,  2024 ] . To address this, we train an external classifier to evaluate  unlearning accuracy  (UA), ensuring that the generated images do not belong to the forgetting class or concept. Additionally, we use FID to evaluate the quality of image generations for non-forgetting classes or prompts.",
            "For the class forgetting tasks, we utilize CIFAR-10  [ Krizhevsky ,  2009 ]  at a resolution of  32  32 32 32 32\\times 32 32  32  and STL-10  [ Coates et al. ,  2011 ]  at  64  64 64 64 64\\times 64 64  64  resolution. The CIFAR-10 dataset consists of 60,000 32  \\times  32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. The dataset consists of 50,000 training images and 10,000 test images. It is organized into five training batches and one test batch, each containing 10,000 images. The test batch includes precisely 1,000 randomly-selected images from each class. The training batches, which hold the remaining images in random order, may have varying numbers of images from each class. The STL-10 dataset is another natural image dataset with 10 classes, each of which has 500 training data and 800 testing data. The image data has a higher resolution of 96  \\times  96 in pixels and RGB color channels compared with CIFAR-10. The images were acquired from labeled examples on ImageNet  [ Deng et al. ,  2009 ] . During training time, the image data from STL-10 are resized to 64  \\times  64. Due to the limited number of the original training data, both training and testing data were used in the experiments, making up 13,000 training images in total.",
            "For class forgetting tasks, we employed an external classifier to obtain unlearning accuracy (UA), ensuring that the generated images are not associated with the class or concept designated for forgetting. The UA is essentially the mis-classification rate of the classifier on the generated samples from the target class. A classifier with high test accuracy and low UA typically indicates effective forgetting, ensuring that the generated images are unlikely to belong to the target class or concept. For the external classifier, we fine-tuned ResNet-34  [ He et al. ,  2016 ]  for 10 epochs on both CIFAR-10 and STL-10 datasets using transfer learning, which is originally pretrained on ImageNet  [ Deng et al. ,  2009 ] . We adapted the original 1000-way classification model by replacing the last fully-connected layer with a customized fully-connected layer with 10 output dimension. The resulting classifiers achieved training and testing accuracies of 99.96% and 95.03% on CIFAR-10, and 100.00% and 96.20% on STL-10, respectively.",
            "We followed the Inappropriate Image Prompts (I2P) benchmark introduced by  Schramowski et al.   [ 2023 ]  to assess the risk of generating NSFW images in text-to-image diffusion models. The I2P dataset consists of 4,703 text prompts covering a wide range of NSFW concepts, including nudity. For each prompt, we generated 10 images and applied both the NudeNet and Q16 detectors to identify inappropriate content. We report the sample-level inappropriate probability (referred to as Inapprop. Prob.) and the prompt-level inappropriate rate (referred to as Max. Exp. Inapprop.).",
            "We implemented our techniques in a newly developed codebase, loosely based on the original implementations by  [ Karras et al. ,  2022 ,  Fan et al. ,  2024 ,  Zhou et al. ,  2024a ] . The pseudo-code is described in  Algorithm   1 . We performed extensive evaluation to verify that our implementation produced exactly the same results as previous work, including samplers, pre-trained models, network architectures, training configurations, and evaluation. We ran all experiments using PyTorch with 4 NVIDIA RTX A5000 GPUs."
        ]
    },
    "id_table_3": {
        "caption": "Table 3 :  Quantitative results of nudity forgetting.  Bold values indicate the best score in each column, while underlined values represent the second-best.",
        "table": "A4.EGx3",
        "footnotes": [],
        "references": [
            "Diffusion models, also known as score-based generative models  ( Sohl-Dickstein et al. ,  2015 ;  Song and Ermon ,  2019 ;  Ho et al. ,  2020 ;  Dhariwal and Nichol ,  2021 ;  Karras et al. ,  2022 ) , have emerged as the leading choice for generative modeling of high-dimensional data. These models are widely celebrated for their ability to produce high-quality, diverse, and photorealistic images  ( Nichol et al. ,  2022 ;  Ramesh et al. ,  2022 ;  Saharia et al. ,  2022 ;  Rombach et al. ,  2022 ;  Podell et al. ,  2024 ;  Zheng et al. ,  2024 ) . However, their capacity to memorize and reproduce specific images and concepts from training datasets raises significant privacy and safety concerns. Moreover, they are susceptible to poisoning attacks, enabling the generation of targeted images with embedded triggers, posing substantial security risks  ( Rando et al. ,  2022 ;  Chen et al. ,  2023b ) .",
            "To address these challenges, we introduce  Score Forgetting Distillation  (SFD), a novel framework designed to efficiently mitigate the influence of specific characteristics in data points on pre-trained diffusion models. This framework is a key part of the broader domain of Machine Unlearning (MU), which has evolved significantly to address core issues in trustworthy machine learning  ( Lowd and Meek ,  2005 ;  Narayanan and Shmatikov ,  2008 ;  Abadi et al. ,  2016 ) . Originating from compliance needs with data protection regulations such as the right to be forgotten  ( Hoofnagle et al. ,  2019 ) , MU has broadened its scope to include applications in diffusion modeling across various domains like computer vision and content generation  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Additionally, MU aims to promote model fairness  ( Oesterling et al. ,  2024 ) , refine pre-training methodologies  ( Jain et al. ,  2023 ;  Jia et al. ,  2023 ) , and reduce the generation of inappropriate content  ( Gandikota et al. ,  2023 ) . The development of SFD is aligned with these objectives, providing a strategic approach to mitigate the potential risks and reduce the high generation costs associated with diffusion models, thereby advancing the field of trustworthy machine learning.",
            "Given the prominence of diffusion models, there is a growing need to develop MU techniques that specifically cater to these models, ensuring efficient unlearning while maintaining generation capabilities  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Our SFD framework efficiently distills the knowledge from a pre-trained diffusion model by optimizing two learnable modulesa generator network and a score networkguided by the frozen pre-trained model itself. The score network is trained to optimize the score associated with the generator by minimizing a score distillation loss, which aims to match the conditional scores of the class to forget and the classes to remember with those of the pre-trained model. The generator network learns to produce examples that are indistinguishable by the pre-trained score network and fake score network in terms of score predictions, utilizing a model-based cross-class score distillation loss.",
            "In this section, we introduce SFD, a principled and data-free approach designed to address the MU problem while simultaneously achieving fast sampling for diffusion models. Building on recent advancements in data-free diffusion distillation for one-step generation  ( Luo et al. ,  2023 ;  Zhou et al. ,  2024b ) , we conceptualize MU in diffusion models as a problem of MU-regularized score distillation.",
            "Before diving into the specific MU problem, we will first establish the essential concepts and notations in diffusion modeling: A diffusion model corrupts its data  x  p data  ( x  c ) similar-to x subscript p data conditional x c x\\sim p_{\\text{data}}(x\\mid c) italic_x  italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_x  italic_c )  during the forward diffusion process at time  t t t italic_t  as  z t = a t  x +  t   t subscript z t subscript a t x subscript  t subscript italic- t z_{t}=a_{t}x+\\sigma_{t}\\epsilon_{t} italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x + italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , where   t  N  ( 0 , 1 ) similar-to subscript italic- t N 0 1 \\epsilon_{t}\\sim\\mathcal{N}(0,1) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  caligraphic_N ( 0 , 1 ) ,  c c c italic_c  represents the given condition such as a label or text, and  a t subscript a t a_{t} italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and   t subscript  t \\sigma_{t} italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  are diffusion scheduling parameters. The goal of pretraining a diffusion model is to obtain an optimal score estimator  s   ( z t , c , t ) subscript s italic- subscript z t c t s_{\\phi}(z_{t},c,t) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  such that  s   ( z t , c , t ) =  z t ln  p data  ( z t | c ) subscript s italic- subscript z t c t subscript  subscript z t subscript p data conditional subscript z t c s_{\\phi}(z_{t},c,t)=\\nabla_{z_{t}}\\ln p_{\\text{data}}(z_{t}\\,|\\,c) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) =  start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c ) . Let  x   ( z t , c , t ) subscript x italic- subscript z t c t x_{\\phi}(z_{t},c,t) italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  be the optimal conditional mean estimator such that for  x   ( z t , c , t ) = E  [ x | z t , c , t ] subscript x italic- subscript z t c t E delimited-[] conditional x subscript z t c t x_{\\phi}(z_{t},c,t)=\\mathbb{E}[x\\,|\\,z_{t},c,t] italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) = blackboard_E [ italic_x | italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ] . Applying Tweedies formula  ( Robbins ,  1992 ;  Efron ,  2011 )  in the context of diffusion modeling  ( Luo ,  2022 ;  Chung et al. ,  2023 ;  Zhou et al. ,  2024b ) , the optimal score and conditional mean estimators,  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and  x  subscript x italic- x_{\\phi} italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT , for the training data are related as follows:",
            "which admits the same optimal solution as Eq.  4  and provides an estimation of the score of the generator  g  subscript g  g_{\\theta} italic_g start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  at different noise levels. This setup allows us to tailor the SFD loss in Eq.  3  specifically for different class dynamics. When  c 1 = c 2 = c subscript c 1 subscript c 2 c c_{1}=c_{2}=c italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_c , the SFD loss facilitates class-specific score distillation, optimizing the score to closely model that of the generator within the same class. Conversely, setting  c 1 = c 2 subscript c 1 subscript c 2 c_{1}\\neq c_{2} italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  configures the SFD loss for score overriding, replacing the score  s    (  ) subscript s superscript   s_{\\psi^{*}(\\theta)} italic_s start_POSTSUBSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ ) end_POSTSUBSCRIPT  for class  c 2 subscript c 2 c_{2} italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  with the score  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  for class  c 1 subscript c 1 c_{1} italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT . This approach effectively addresses the dual objectives of class forgetting and targeted score modification, introducing two distinct losses to manage these scenarios:",
            "This formulation corresponds to a bi-level optimization problem  ( Ye et al. ,  1997 ;  Hong et al. ,  2023 ;  Shen et al. ,  2023 ) , subject to an additional forgetting-based constraint. Solving this problem directly is challenging, so we initially relax the constraint specified by  L sfd subscript L sfd \\mathcal{L}_{\\text{sfd}} caligraphic_L start_POSTSUBSCRIPT sfd end_POSTSUBSCRIPT  in the above equation by integrating it into the distillation objective as an additional MU regularization term:",
            "The Score Forgetting Distillation (SFD) loss in Eq.  3  can be equivalently expressed as",
            "A biased loss for    \\theta italic_  can be derived by replacing     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ )  in either Eq.  3  or Eq.  8  with its SGD-based approximation    \\psi italic_ , and disregarding the dependency of    superscript  \\psi^{*} italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  on    \\theta italic_  when computing the gradient of    \\theta italic_ . Empirical experiments by  Zhou et al.  ( 2024b )  suggest that in the context of diffusion distillation without involving unlearning, Eq.  8  can be effective independently, while Eq.  3  may not perform as expected. This observation leads to a practical approach that involves subtracting Eq.  3  from Eq.  8 . This strategy aims to sidestep detrimental biased gradient directions and potentially compensate for the overlooked gradient dependency of     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ ) . We implement this approach in practice under the framework of SFD, defining the loss used in practice as follows:",
            "From the empirical results, the proposed method, SFD, can effectively unlearn unwanted content ( e . g . formulae-sequence e g e.g. italic_e . italic_g . , a class of objects) and converge rapidly towards the level of generation quality of the pre-trained model. Additionally, the models fine-tuned by SFD inherently enables one step generation.  Figure   3  shows that the remaining classes were in fact intact during the MU-regularized distillation, the generation quality of class 1 to 9 were consistently improving as the number of generator-synthesized images, which were used by SFD for distillation and MU, went up. The FID between generated samples and training dataset decreased nearly exponentially fast as is captured by  Figure   5 . The forgetting class, on the other hand, was initialized to output airplanes and gradually forced to match the assigned class,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the class of automobile. The forgetting effect noticeably took place between 10k and 20k training steps. From  Figure   5 , we observe a steady increase of unlearning accuracy, reflecting the extent to which the generated Class 0 samples can no longer be correctly identified by the pre-trained image classifier.",
            "In addition to the celebrity forgetting experiments, we conducted experiments on a broader concept forgetting task, namely, forgetting nudity as a concept. We note that nudity is a broader concept than individuals ( e . g . , formulae-sequence e g e.g., italic_e . italic_g . ,  celebrities) and forgetting nudity in general is much more challenging. Therefore, we adopted a slightly different strategy for this task to enhance the forgetting performance. In particular, we first created a list of 12 common human subjects (see  Table   5 ) that can be potentially misused for generating nudity-related contents and randomly paired them with one of NSFW keywords (see  Table   6 ) as prompts to forget. We further leveraged the negative prompting technique to match these prompts with their corresponding prompts to override. Specifically, we take the original text prompt as the conditional text input while using the concatenated NSFW keywords instead of an empty string as the unconditional text input. We notice this approach also has a concept forgetting effect on the original score distillation method, which is denoted as SiD-LSG-Neg. We report key MU performance metrics in  Table   3 . Sample images by baselines and SFD are displayed in  Figure   6 .",
            "The study of MU can be traced back to classical machine learning models in response to data protection regulations such as the right to be forgotten  [ Cao and Yang ,  2015 ,  Hoofnagle et al. ,  2019 ,  Bourtoule et al. ,  2021 ,  Nguyen et al. ,  2022 ] . Due to its capability of assessing data influence on model performance, the landscape of MU has expanded to encompass diverse domains, such as image classification  [ Ginart et al. ,  2019 ,  Golatkar et al. ,  2020 ,  Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] , text-to-image generation  [ Gandikota et al. ,  2023 ,  Zhang et al. ,  2023a ,  Kumari et al. ,  2023 ,  Fan et al. ,  2024 ] , federated learning  [ Halimi et al. ,  2022 ,  Che et al. ,  2023 ] , and graph neural networks  [ Chen et al. ,  2022 ,  Chien et al. ,  2022 ,  Wu et al. ,  2023 ] . In the literature, exact unlearning, which involves retraining the model from scratch after removing specific training data points, is often considered the gold standard. However, this approach comes with significant computational demands and requires access to the entire training set  [ Thudi et al. ,  2022 ] . To address these challenges, many research efforts have shifted towards the development of scalable and effective approximate unlearning methods  [ Liu et al. ,  2024 ,  Chen et al. ,  2023a ] . In addition, probabilistic methods with certain provable removal guarantees have been explored, often leveraging the concept of differential privacy  [ Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] . Focusing on MU in diffusion-based image generation, this paper introduces a general data-free approach for rapid forgetting and one-step sampling in diffusion models, eliminating the need to access any real data.",
            "In examining the challenges and strategies associated with diffusion models and MU, several key issues and methodologies have been identified. Diffusion models, particularly when trained on data from open collections, face risks of contamination or manipulation, which could lead to the generation of inappropriate or offensive content  [ Chen et al. ,  2023b ,  Schramowski et al. ,  2023 ] . Strategies to mitigate these include data censoring and safety guidance to steer models away from undesirable outputs  [ Nichol et al. ,  2021 ] , and introducing subtle perturbations to protect artistic styles  [ Shan et al. ,  2023 ] . Despite these measures, challenges remain in fully preventing diffusion models from generating harmful content or being susceptible to targeted poison attacks  [ Rando et al. ,  2022 ] . Furthermore, the evaluation of MU presents unique difficulties, especially as conventional retraining benchmarks are often impractical. Empirical metrics for assessing MU include unlearning accuracy, the utility of the model post-unlearning, and the use of classifiers to gauge the integrity of generated outputs  [ Jang et al. ,  2022 ] . Unlike existing methods, our approach efficiently suppresses the generation of harmful content using a one-step diffusion generator that overrides unsafe concepts with MU-regularized score-based distillation.",
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper.",
            "Classic score-matching-based diffusion models  [ Sohl-Dickstein et al. ,  2015 ,  Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  have become increasingly influential in developing generative models with high extensibility and sample quality  [ Dhariwal and Nichol ,  2021 ,  Karras et al. ,  2022 ,  Ramesh et al. ,  2022 ] . However, standard Gaussian diffusion models, along with other non-Gaussian variants  [ Hoogeboom et al. ,  2021 ,  Austin et al. ,  2021 ,  Chen and Zhou ,  2023 ,  Zhou et al. ,  2023 ] , suffer from relatively slow sampling compared to traditional one-step generative models, such as GANs and VAEs. Inspired by the success of applying diffusion processes to the training of generative models,  Xiao et al.   [ 2021 ]  and  Wang et al.   [ 2022 ]  were among the first to promote faster generation by leveraging both adversarial training techniques and diffusion-based data augmentation. However, these approaches inevitably reintroduce potential issues like training instability and mode collapse. Closely related to the original score matching,  Salimans and Ho   [ 2022 ]  proposed progressively halving the steps needed in the reverse generation process. Similarly,  Song et al.   [ 2023 ]  presented the consistency model as a method for distilling the reverse ODE sampling process. Along this direction, much effort has been made by others  [ Xu et al. ,  2023 ,  Yin et al. ,  2024 ,  Luo et al. ,  2023 ,  Zhou et al. ,  2024b ]  to improve both sample quality and diversity.",
            "To address the slow sampling speed associated with traditional diffusion models, score distillation methods have been developed to harness pretrained score functions. These methods approximate data scores, facilitating model distribution matching under noisy conditions to align with the noisy data distribution governed by the pretrained denoising score matching function. These methods, as explored in several recent works  [ Poole et al. ,  2023 ,  Wang et al. ,  2023 ,  Luo et al. ,  2023 ,  Nguyen and Tran ,  2023 ,  Yin et al. ,  2024 ] , primarily utilize the KL divergence, whose gradients can be analytically computed using both the pretrained and estimated score functions. Importantly, these KL-based methods do not require access to real data, as the KL divergence is defined with respect to the model distribution. While these approaches have successfully approximated the data distribution in a data-free manner, they often suffer from performance degradation when compared to the original, pretrained teacher diffusion model. Consequently, additional loss terms that require access to the original training data or data synthesized with the pretrained diffusion models are often necessary to mitigate this performance degradation. However, employing these terms voids the data-free feature of the process.",
            "When applying MU to classification tasks, effectiveness-oriented metrics include unlearning accuracy, which evaluates how accurately the model performs on the forget set after unlearning  [ Golatkar et al. ,  2020 ] . Utility-oriented metrics include remaining accuracy, which measures the updated models performance on the retain set post-unlearning  [ Song and Mittal ,  2021 ] , and testing accuracy, which assesses the models generalization capability after unlearning. For generation tasks, accuracy-based metrics use a post-generation classifier to evaluate the generated content  [ Zhang et al. ,  2023b ] , while quality metrics assess the overall utility of the generated outputs  [ Gandikota et al. ,  2023 ] . A significant limitation of these metrics, particularly in measuring unlearning effectiveness, is their heavy dependence on the specific unlearning tasks  [ Fan et al. ,  2024 ] . To address this, we train an external classifier to evaluate  unlearning accuracy  (UA), ensuring that the generated images do not belong to the forgetting class or concept. Additionally, we use FID to evaluate the quality of image generations for non-forgetting classes or prompts.",
            "We followed the Inappropriate Image Prompts (I2P) benchmark introduced by  Schramowski et al.   [ 2023 ]  to assess the risk of generating NSFW images in text-to-image diffusion models. The I2P dataset consists of 4,703 text prompts covering a wide range of NSFW concepts, including nudity. For each prompt, we generated 10 images and applied both the NudeNet and Q16 detectors to identify inappropriate content. We report the sample-level inappropriate probability (referred to as Inapprop. Prob.) and the prompt-level inappropriate rate (referred to as Max. Exp. Inapprop.)."
        ]
    },
    "id_table_4": {
        "caption": "Table 4 :  Ablation study on classifier-free guidance during training and on the CIFAR-10 and STL-10 datasets.  The percentages in  green  and  red  are the relative performance boost and degradation respectively when the model is trained without classifier-free guidance.",
        "table": "A4.EGx4",
        "footnotes": [],
        "references": [
            "Diffusion models, also known as score-based generative models  ( Sohl-Dickstein et al. ,  2015 ;  Song and Ermon ,  2019 ;  Ho et al. ,  2020 ;  Dhariwal and Nichol ,  2021 ;  Karras et al. ,  2022 ) , have emerged as the leading choice for generative modeling of high-dimensional data. These models are widely celebrated for their ability to produce high-quality, diverse, and photorealistic images  ( Nichol et al. ,  2022 ;  Ramesh et al. ,  2022 ;  Saharia et al. ,  2022 ;  Rombach et al. ,  2022 ;  Podell et al. ,  2024 ;  Zheng et al. ,  2024 ) . However, their capacity to memorize and reproduce specific images and concepts from training datasets raises significant privacy and safety concerns. Moreover, they are susceptible to poisoning attacks, enabling the generation of targeted images with embedded triggers, posing substantial security risks  ( Rando et al. ,  2022 ;  Chen et al. ,  2023b ) .",
            "To address these challenges, we introduce  Score Forgetting Distillation  (SFD), a novel framework designed to efficiently mitigate the influence of specific characteristics in data points on pre-trained diffusion models. This framework is a key part of the broader domain of Machine Unlearning (MU), which has evolved significantly to address core issues in trustworthy machine learning  ( Lowd and Meek ,  2005 ;  Narayanan and Shmatikov ,  2008 ;  Abadi et al. ,  2016 ) . Originating from compliance needs with data protection regulations such as the right to be forgotten  ( Hoofnagle et al. ,  2019 ) , MU has broadened its scope to include applications in diffusion modeling across various domains like computer vision and content generation  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Additionally, MU aims to promote model fairness  ( Oesterling et al. ,  2024 ) , refine pre-training methodologies  ( Jain et al. ,  2023 ;  Jia et al. ,  2023 ) , and reduce the generation of inappropriate content  ( Gandikota et al. ,  2023 ) . The development of SFD is aligned with these objectives, providing a strategic approach to mitigate the potential risks and reduce the high generation costs associated with diffusion models, thereby advancing the field of trustworthy machine learning.",
            "MU methods are generally categorized into two types: exact MU and approximate MU. Exact MU entails creating a model that behaves as if sensitive data had never been part of the training set  ( Cao and Yang ,  2015 ;  Bourtoule et al. ,  2021 ) . This process requires the unlearned model to be identical in distribution to a model retrained without the sensitive data, both in terms of model weights and output behavior. In contrast, approximate MU does not seek an exact match between the unlearned model and a retrained model. Instead, it aims to approximate how closely the output distributions of the two models align after the unlearning process. A prominent strategy in approximate MU utilizes the principles of differential privacy  ( Dwork ,  2006 ) . For instance,  Guo et al.  ( 2019 )  introduced a certified removal technique that prevents adversaries from extracting information about removed training data, offering a theoretical guarantee of data privacy. However, these approaches typically necessitate retraining the model from scratch, which can be computationally intensive and require access to the original training dataset. Efficient and stable unlearning has become crucial in MU. Techniques like the influence functions  ( Warnecke et al. ,  2021 ;  Izzo et al. ,  2021 ) , selective forgetting  ( Golatkar et al. ,  2020 ) , weight-based pruning  ( Liu et al. ,  2024 ) , and gradient-based saliency  ( Fan et al. ,  2024 )  have been explored, though they often suffer from performance degradation or restrictive assumptions  ( Becker and Liebig ,  2022 ) . These methods are primarily applied to MU for image classification tasks and do not adequately address the rapid forgetting and unlearning required for data generation tasks.",
            "Given the prominence of diffusion models, there is a growing need to develop MU techniques that specifically cater to these models, ensuring efficient unlearning while maintaining generation capabilities  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Our SFD framework efficiently distills the knowledge from a pre-trained diffusion model by optimizing two learnable modulesa generator network and a score networkguided by the frozen pre-trained model itself. The score network is trained to optimize the score associated with the generator by minimizing a score distillation loss, which aims to match the conditional scores of the class to forget and the classes to remember with those of the pre-trained model. The generator network learns to produce examples that are indistinguishable by the pre-trained score network and fake score network in terms of score predictions, utilizing a model-based cross-class score distillation loss.",
            "Diffusion models are celebrated for their superior performance in generating high-quality and diverse samples. However, their robust capabilities also introduce challenges, particularly the risk of misuse in generating inappropriate content. This concern highlights the ethical implications and potential negative impacts of their application. Additionally, these models have a significant drawback: slow sampling speeds. This inefficiency becomes particularly problematic in downstream tasks that require finetuning on synthetic data generated by these models. When access to real data is not feasible, the task of preparing a sufficiently large synthetic dataset can already become computationally prohibitive  ( Yin et al. ,  2024 ) . This issue is especially acute in the context of MU and image generation, where access to real data often raises privacy concerns, making reliance on synthetic data crucial. Consequently, the slow sampling rate of diffusion models presents a critical bottleneck, necessitating improvements to enable effective data-free MU operations.",
            "In this section, we introduce SFD, a principled and data-free approach designed to address the MU problem while simultaneously achieving fast sampling for diffusion models. Building on recent advancements in data-free diffusion distillation for one-step generation  ( Luo et al. ,  2023 ;  Zhou et al. ,  2024b ) , we conceptualize MU in diffusion models as a problem of MU-regularized score distillation.",
            "Before diving into the specific MU problem, we will first establish the essential concepts and notations in diffusion modeling: A diffusion model corrupts its data  x  p data  ( x  c ) similar-to x subscript p data conditional x c x\\sim p_{\\text{data}}(x\\mid c) italic_x  italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_x  italic_c )  during the forward diffusion process at time  t t t italic_t  as  z t = a t  x +  t   t subscript z t subscript a t x subscript  t subscript italic- t z_{t}=a_{t}x+\\sigma_{t}\\epsilon_{t} italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x + italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , where   t  N  ( 0 , 1 ) similar-to subscript italic- t N 0 1 \\epsilon_{t}\\sim\\mathcal{N}(0,1) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  caligraphic_N ( 0 , 1 ) ,  c c c italic_c  represents the given condition such as a label or text, and  a t subscript a t a_{t} italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and   t subscript  t \\sigma_{t} italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  are diffusion scheduling parameters. The goal of pretraining a diffusion model is to obtain an optimal score estimator  s   ( z t , c , t ) subscript s italic- subscript z t c t s_{\\phi}(z_{t},c,t) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  such that  s   ( z t , c , t ) =  z t ln  p data  ( z t | c ) subscript s italic- subscript z t c t subscript  subscript z t subscript p data conditional subscript z t c s_{\\phi}(z_{t},c,t)=\\nabla_{z_{t}}\\ln p_{\\text{data}}(z_{t}\\,|\\,c) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) =  start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c ) . Let  x   ( z t , c , t ) subscript x italic- subscript z t c t x_{\\phi}(z_{t},c,t) italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  be the optimal conditional mean estimator such that for  x   ( z t , c , t ) = E  [ x | z t , c , t ] subscript x italic- subscript z t c t E delimited-[] conditional x subscript z t c t x_{\\phi}(z_{t},c,t)=\\mathbb{E}[x\\,|\\,z_{t},c,t] italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) = blackboard_E [ italic_x | italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ] . Applying Tweedies formula  ( Robbins ,  1992 ;  Efron ,  2011 )  in the context of diffusion modeling  ( Luo ,  2022 ;  Chung et al. ,  2023 ;  Zhou et al. ,  2024b ) , the optimal score and conditional mean estimators,  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and  x  subscript x italic- x_{\\phi} italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT , for the training data are related as follows:",
            "where   t > 0 subscript  t 0 \\gamma_{t}>0 italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT > 0  is a re-weighting function. In practice, the lack of the access to   x ln  p   ( z t | c ) subscript  x subscript p  conditional subscript z t c \\nabla_{x}\\ln p_{\\theta}(z_{t}\\,|\\,c)  start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c )  makes Eq.  4  intractable. However, we can alternatively optimize a denoising SM loss  ( Vincent ,  2011 )  as",
            "which admits the same optimal solution as Eq.  4  and provides an estimation of the score of the generator  g  subscript g  g_{\\theta} italic_g start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  at different noise levels. This setup allows us to tailor the SFD loss in Eq.  3  specifically for different class dynamics. When  c 1 = c 2 = c subscript c 1 subscript c 2 c c_{1}=c_{2}=c italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_c , the SFD loss facilitates class-specific score distillation, optimizing the score to closely model that of the generator within the same class. Conversely, setting  c 1 = c 2 subscript c 1 subscript c 2 c_{1}\\neq c_{2} italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  configures the SFD loss for score overriding, replacing the score  s    (  ) subscript s superscript   s_{\\psi^{*}(\\theta)} italic_s start_POSTSUBSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ ) end_POSTSUBSCRIPT  for class  c 2 subscript c 2 c_{2} italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  with the score  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  for class  c 1 subscript c 1 c_{1} italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT . This approach effectively addresses the dual objectives of class forgetting and targeted score modification, introducing two distinct losses to manage these scenarios:",
            "where    \\lambda italic_  and    \\mu italic_  are tunable constants that serve as control knobs to balance the distillation of the remaining classes and the unlearning of the target class. Furthermore, we implement an alternating update strategy between    \\theta italic_  and    \\psi italic_ . This approach mitigates the need to obtain the optimal score estimator     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ )  for each    \\theta italic_ , simplifying the computational process. We outline a practical implementation of this strategy in  Algorithm   1 . Specifically, generalizing the derivation in  Zhou et al.  ( 2024b ) , we have the following Lemma, whose proof is provided in  Appendix   D :",
            "A biased loss for    \\theta italic_  can be derived by replacing     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ )  in either Eq.  3  or Eq.  8  with its SGD-based approximation    \\psi italic_ , and disregarding the dependency of    superscript  \\psi^{*} italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  on    \\theta italic_  when computing the gradient of    \\theta italic_ . Empirical experiments by  Zhou et al.  ( 2024b )  suggest that in the context of diffusion distillation without involving unlearning, Eq.  8  can be effective independently, while Eq.  3  may not perform as expected. This observation leads to a practical approach that involves subtracting Eq.  3  from Eq.  8 . This strategy aims to sidestep detrimental biased gradient directions and potentially compensate for the overlooked gradient dependency of     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ ) . We implement this approach in practice under the framework of SFD, defining the loss used in practice as follows:",
            "where    0  0 \\alpha\\geq 0 italic_  0  is some constant that typically set as 1 or 1.2,  z t = a t  x +  t   t , x  D  , c 2 ,  t  N  ( 0 , I ) , t  Unif  [ t min , t max ] formulae-sequence subscript z t subscript a t x subscript  t subscript italic- t formulae-sequence similar-to x subscript D  subscript c 2 formulae-sequence similar-to subscript italic- t N 0 I similar-to t Unif subscript t min subscript t max z_{t}=a_{t}x+\\sigma_{t}{\\epsilon}_{t},~{}x\\sim\\mathcal{D}_{\\theta,c_{2}},~{}{% \\epsilon}_{t}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I}),~{}t\\sim\\text{Unif}[t_{% \\text{min}},t_{\\text{max}}] italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x + italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_x  caligraphic_D start_POSTSUBSCRIPT italic_ , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  caligraphic_N ( bold_0 , bold_I ) , italic_t  Unif [ italic_t start_POSTSUBSCRIPT min end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT max end_POSTSUBSCRIPT ] . In this paper, we follow  Yin et al.  ( 2024 )  and  Zhou et al.  ( 2024b )  to set   t =  t 4 a t 2  C  x   ( z t , t , c )  x  1 , sg subscript  t superscript subscript  t 4 superscript subscript a t 2 C subscript norm subscript x italic- subscript z t t c x 1 sg \\omega_{t}=\\frac{\\sigma_{t}^{4}}{a_{t}^{2}}\\frac{C}{\\|x_{\\phi}(z_{t},t,c)-x\\|_% {1,\\text{sg}}} italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = divide start_ARG italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_ARG start_ARG italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG divide start_ARG italic_C end_ARG start_ARG  italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , italic_c ) - italic_x  start_POSTSUBSCRIPT 1 , sg end_POSTSUBSCRIPT end_ARG , where  C C C italic_C  is the data dimension and sg stands for stop gradient.",
            "To quantitatively assess the effectiveness of class forgetting, we primarily focus on the success rate of forgetting the target class, and the generative capability on classes to retain. Specifically, we measure the success rate of forgetting by unlearning accuracy (UA) employing an external classifier trained on the original training set, which is essentially the mis-classification rate of the classifier on the generated samples from the target class. We measure image generation quality using Frechet Inception Distance (FID)  ( Heusel et al. ,  2017 )  and sample diversity using Inception Score (IS)  ( Salimans et al. ,  2016 ) . Additionally, we report Precision and Recall  ( Kynkaanniemi et al. ,  2019 ) , and number of function evaluations (NFEs) for sampling. Following  Fan et al.  ( 2024 ) , we compute and report generation quality metrics using generated samples, with the full training set from the remaining classes serving as the reference. For concept forgetting tasks including celebrity forgetting and nudity forgetting, we also provide quantitative evaluations as well as qualitative comparison. Specifically, we evaluate celebrity forgetting using a off-the-shelf celebrity face detector, while we assess the MU performance of our nudity forgetting model on the I2P benchmark ( https://github.com/ml-research/i2p ). Please refer to  Section   B.2  for more details of the evaluation metrics.",
            "Our main implementation of class forgetting experiments is based on DDPM  ( Ho et al. ,  2020 ) , where we utilize the codebase developed by  Fan et al.  ( 2024 ) . Additionally, we implement our method using EDM  ( Karras et al. ,  2022 )  framework and the official codebase ( https://github.com/NVlabs/edm ). For concept forgetting experiments, we implement our method for SD models based on the implementation of  Zhou et al.  ( 2024a ) . We adopt the same model configuration for both the generator  g  subscript g  g_{\\theta} italic_g start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and its score estimation network  s  subscript s  s_{\\psi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and initialize the model weights according to the pre-trained score network  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT . This type of initialization prepares a good starting point for SFD.",
            "EDM  ( Karras et al. ,  2022 )  is a state-of-the-art diffusion model with enhanced capability for generating high-quality images. To evaluate our methods generalizability across different model architectures, we additionally conduct experiment using the EDM architecture. We adapted the codebase used by SiD  ( Zhou et al. ,  2024b )  and fine-tuned the pre-trained class-conditional CIFAR-10 EDM-VP model.  Figure   5  shows that the FID results of our method can be further improve when based on a more powerful pre-trained model.",
            "Classifier-free guidance (CFG), first proposed by  Ho and Salimans  ( 2021 ) , is a commonly-used strategy for conditional sampling. While typically adopted during inference to enhance class fidelity, it has also been shown to be useful for the training of score-based distillation  ( Yin et al. ,  2024 ;  Zhou et al. ,  2024a ) . We compare our models trained with and without CFG in  Table   4 . In our experiments on STL-10, we found that including classifier-free guidance during training improved the performance in terms of both FID and UA. However, we did not observe such improvements on the CIFAR-10 dataset; on the contrary, we noticed a degradation in the evaluation metrics. We speculate that the influence of CFG may be tied to the inter-class differences: when training data contain classes sharing similar features, such as automobile and truck in CIFAR-10, training with CFG may not be as beneficial as it is when the training dataset consists of more distinct classes.",
            "The study of MU can be traced back to classical machine learning models in response to data protection regulations such as the right to be forgotten  [ Cao and Yang ,  2015 ,  Hoofnagle et al. ,  2019 ,  Bourtoule et al. ,  2021 ,  Nguyen et al. ,  2022 ] . Due to its capability of assessing data influence on model performance, the landscape of MU has expanded to encompass diverse domains, such as image classification  [ Ginart et al. ,  2019 ,  Golatkar et al. ,  2020 ,  Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] , text-to-image generation  [ Gandikota et al. ,  2023 ,  Zhang et al. ,  2023a ,  Kumari et al. ,  2023 ,  Fan et al. ,  2024 ] , federated learning  [ Halimi et al. ,  2022 ,  Che et al. ,  2023 ] , and graph neural networks  [ Chen et al. ,  2022 ,  Chien et al. ,  2022 ,  Wu et al. ,  2023 ] . In the literature, exact unlearning, which involves retraining the model from scratch after removing specific training data points, is often considered the gold standard. However, this approach comes with significant computational demands and requires access to the entire training set  [ Thudi et al. ,  2022 ] . To address these challenges, many research efforts have shifted towards the development of scalable and effective approximate unlearning methods  [ Liu et al. ,  2024 ,  Chen et al. ,  2023a ] . In addition, probabilistic methods with certain provable removal guarantees have been explored, often leveraging the concept of differential privacy  [ Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] . Focusing on MU in diffusion-based image generation, this paper introduces a general data-free approach for rapid forgetting and one-step sampling in diffusion models, eliminating the need to access any real data.",
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper.",
            "Classic score-matching-based diffusion models  [ Sohl-Dickstein et al. ,  2015 ,  Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  have become increasingly influential in developing generative models with high extensibility and sample quality  [ Dhariwal and Nichol ,  2021 ,  Karras et al. ,  2022 ,  Ramesh et al. ,  2022 ] . However, standard Gaussian diffusion models, along with other non-Gaussian variants  [ Hoogeboom et al. ,  2021 ,  Austin et al. ,  2021 ,  Chen and Zhou ,  2023 ,  Zhou et al. ,  2023 ] , suffer from relatively slow sampling compared to traditional one-step generative models, such as GANs and VAEs. Inspired by the success of applying diffusion processes to the training of generative models,  Xiao et al.   [ 2021 ]  and  Wang et al.   [ 2022 ]  were among the first to promote faster generation by leveraging both adversarial training techniques and diffusion-based data augmentation. However, these approaches inevitably reintroduce potential issues like training instability and mode collapse. Closely related to the original score matching,  Salimans and Ho   [ 2022 ]  proposed progressively halving the steps needed in the reverse generation process. Similarly,  Song et al.   [ 2023 ]  presented the consistency model as a method for distilling the reverse ODE sampling process. Along this direction, much effort has been made by others  [ Xu et al. ,  2023 ,  Yin et al. ,  2024 ,  Luo et al. ,  2023 ,  Zhou et al. ,  2024b ]  to improve both sample quality and diversity.",
            "To address the slow sampling speed associated with traditional diffusion models, score distillation methods have been developed to harness pretrained score functions. These methods approximate data scores, facilitating model distribution matching under noisy conditions to align with the noisy data distribution governed by the pretrained denoising score matching function. These methods, as explored in several recent works  [ Poole et al. ,  2023 ,  Wang et al. ,  2023 ,  Luo et al. ,  2023 ,  Nguyen and Tran ,  2023 ,  Yin et al. ,  2024 ] , primarily utilize the KL divergence, whose gradients can be analytically computed using both the pretrained and estimated score functions. Importantly, these KL-based methods do not require access to real data, as the KL divergence is defined with respect to the model distribution. While these approaches have successfully approximated the data distribution in a data-free manner, they often suffer from performance degradation when compared to the original, pretrained teacher diffusion model. Consequently, additional loss terms that require access to the original training data or data synthesized with the pretrained diffusion models are often necessary to mitigate this performance degradation. However, employing these terms voids the data-free feature of the process.",
            "When applying MU to classification tasks, effectiveness-oriented metrics include unlearning accuracy, which evaluates how accurately the model performs on the forget set after unlearning  [ Golatkar et al. ,  2020 ] . Utility-oriented metrics include remaining accuracy, which measures the updated models performance on the retain set post-unlearning  [ Song and Mittal ,  2021 ] , and testing accuracy, which assesses the models generalization capability after unlearning. For generation tasks, accuracy-based metrics use a post-generation classifier to evaluate the generated content  [ Zhang et al. ,  2023b ] , while quality metrics assess the overall utility of the generated outputs  [ Gandikota et al. ,  2023 ] . A significant limitation of these metrics, particularly in measuring unlearning effectiveness, is their heavy dependence on the specific unlearning tasks  [ Fan et al. ,  2024 ] . To address this, we train an external classifier to evaluate  unlearning accuracy  (UA), ensuring that the generated images do not belong to the forgetting class or concept. Additionally, we use FID to evaluate the quality of image generations for non-forgetting classes or prompts.",
            "We implemented our techniques in a newly developed codebase, loosely based on the original implementations by  [ Karras et al. ,  2022 ,  Fan et al. ,  2024 ,  Zhou et al. ,  2024a ] . The pseudo-code is described in  Algorithm   1 . We performed extensive evaluation to verify that our implementation produced exactly the same results as previous work, including samplers, pre-trained models, network architectures, training configurations, and evaluation. We ran all experiments using PyTorch with 4 NVIDIA RTX A5000 GPUs."
        ]
    },
    "id_table_5": {
        "caption": "(a)   CIFAR-10",
        "table": "A4.EGx5",
        "footnotes": [],
        "references": [
            "Diffusion models, also known as score-based generative models  ( Sohl-Dickstein et al. ,  2015 ;  Song and Ermon ,  2019 ;  Ho et al. ,  2020 ;  Dhariwal and Nichol ,  2021 ;  Karras et al. ,  2022 ) , have emerged as the leading choice for generative modeling of high-dimensional data. These models are widely celebrated for their ability to produce high-quality, diverse, and photorealistic images  ( Nichol et al. ,  2022 ;  Ramesh et al. ,  2022 ;  Saharia et al. ,  2022 ;  Rombach et al. ,  2022 ;  Podell et al. ,  2024 ;  Zheng et al. ,  2024 ) . However, their capacity to memorize and reproduce specific images and concepts from training datasets raises significant privacy and safety concerns. Moreover, they are susceptible to poisoning attacks, enabling the generation of targeted images with embedded triggers, posing substantial security risks  ( Rando et al. ,  2022 ;  Chen et al. ,  2023b ) .",
            "To address these challenges, we introduce  Score Forgetting Distillation  (SFD), a novel framework designed to efficiently mitigate the influence of specific characteristics in data points on pre-trained diffusion models. This framework is a key part of the broader domain of Machine Unlearning (MU), which has evolved significantly to address core issues in trustworthy machine learning  ( Lowd and Meek ,  2005 ;  Narayanan and Shmatikov ,  2008 ;  Abadi et al. ,  2016 ) . Originating from compliance needs with data protection regulations such as the right to be forgotten  ( Hoofnagle et al. ,  2019 ) , MU has broadened its scope to include applications in diffusion modeling across various domains like computer vision and content generation  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Additionally, MU aims to promote model fairness  ( Oesterling et al. ,  2024 ) , refine pre-training methodologies  ( Jain et al. ,  2023 ;  Jia et al. ,  2023 ) , and reduce the generation of inappropriate content  ( Gandikota et al. ,  2023 ) . The development of SFD is aligned with these objectives, providing a strategic approach to mitigate the potential risks and reduce the high generation costs associated with diffusion models, thereby advancing the field of trustworthy machine learning.",
            "MU methods are generally categorized into two types: exact MU and approximate MU. Exact MU entails creating a model that behaves as if sensitive data had never been part of the training set  ( Cao and Yang ,  2015 ;  Bourtoule et al. ,  2021 ) . This process requires the unlearned model to be identical in distribution to a model retrained without the sensitive data, both in terms of model weights and output behavior. In contrast, approximate MU does not seek an exact match between the unlearned model and a retrained model. Instead, it aims to approximate how closely the output distributions of the two models align after the unlearning process. A prominent strategy in approximate MU utilizes the principles of differential privacy  ( Dwork ,  2006 ) . For instance,  Guo et al.  ( 2019 )  introduced a certified removal technique that prevents adversaries from extracting information about removed training data, offering a theoretical guarantee of data privacy. However, these approaches typically necessitate retraining the model from scratch, which can be computationally intensive and require access to the original training dataset. Efficient and stable unlearning has become crucial in MU. Techniques like the influence functions  ( Warnecke et al. ,  2021 ;  Izzo et al. ,  2021 ) , selective forgetting  ( Golatkar et al. ,  2020 ) , weight-based pruning  ( Liu et al. ,  2024 ) , and gradient-based saliency  ( Fan et al. ,  2024 )  have been explored, though they often suffer from performance degradation or restrictive assumptions  ( Becker and Liebig ,  2022 ) . These methods are primarily applied to MU for image classification tasks and do not adequately address the rapid forgetting and unlearning required for data generation tasks.",
            "From the empirical results, the proposed method, SFD, can effectively unlearn unwanted content ( e . g . formulae-sequence e g e.g. italic_e . italic_g . , a class of objects) and converge rapidly towards the level of generation quality of the pre-trained model. Additionally, the models fine-tuned by SFD inherently enables one step generation.  Figure   3  shows that the remaining classes were in fact intact during the MU-regularized distillation, the generation quality of class 1 to 9 were consistently improving as the number of generator-synthesized images, which were used by SFD for distillation and MU, went up. The FID between generated samples and training dataset decreased nearly exponentially fast as is captured by  Figure   5 . The forgetting class, on the other hand, was initialized to output airplanes and gradually forced to match the assigned class,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the class of automobile. The forgetting effect noticeably took place between 10k and 20k training steps. From  Figure   5 , we observe a steady increase of unlearning accuracy, reflecting the extent to which the generated Class 0 samples can no longer be correctly identified by the pre-trained image classifier.",
            "In addition to the celebrity forgetting experiments, we conducted experiments on a broader concept forgetting task, namely, forgetting nudity as a concept. We note that nudity is a broader concept than individuals ( e . g . , formulae-sequence e g e.g., italic_e . italic_g . ,  celebrities) and forgetting nudity in general is much more challenging. Therefore, we adopted a slightly different strategy for this task to enhance the forgetting performance. In particular, we first created a list of 12 common human subjects (see  Table   5 ) that can be potentially misused for generating nudity-related contents and randomly paired them with one of NSFW keywords (see  Table   6 ) as prompts to forget. We further leveraged the negative prompting technique to match these prompts with their corresponding prompts to override. Specifically, we take the original text prompt as the conditional text input while using the concatenated NSFW keywords instead of an empty string as the unconditional text input. We notice this approach also has a concept forgetting effect on the original score distillation method, which is denoted as SiD-LSG-Neg. We report key MU performance metrics in  Table   3 . Sample images by baselines and SFD are displayed in  Figure   6 .",
            "EDM  ( Karras et al. ,  2022 )  is a state-of-the-art diffusion model with enhanced capability for generating high-quality images. To evaluate our methods generalizability across different model architectures, we additionally conduct experiment using the EDM architecture. We adapted the codebase used by SiD  ( Zhou et al. ,  2024b )  and fine-tuned the pre-trained class-conditional CIFAR-10 EDM-VP model.  Figure   5  shows that the FID results of our method can be further improve when based on a more powerful pre-trained model.",
            "The study of MU can be traced back to classical machine learning models in response to data protection regulations such as the right to be forgotten  [ Cao and Yang ,  2015 ,  Hoofnagle et al. ,  2019 ,  Bourtoule et al. ,  2021 ,  Nguyen et al. ,  2022 ] . Due to its capability of assessing data influence on model performance, the landscape of MU has expanded to encompass diverse domains, such as image classification  [ Ginart et al. ,  2019 ,  Golatkar et al. ,  2020 ,  Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] , text-to-image generation  [ Gandikota et al. ,  2023 ,  Zhang et al. ,  2023a ,  Kumari et al. ,  2023 ,  Fan et al. ,  2024 ] , federated learning  [ Halimi et al. ,  2022 ,  Che et al. ,  2023 ] , and graph neural networks  [ Chen et al. ,  2022 ,  Chien et al. ,  2022 ,  Wu et al. ,  2023 ] . In the literature, exact unlearning, which involves retraining the model from scratch after removing specific training data points, is often considered the gold standard. However, this approach comes with significant computational demands and requires access to the entire training set  [ Thudi et al. ,  2022 ] . To address these challenges, many research efforts have shifted towards the development of scalable and effective approximate unlearning methods  [ Liu et al. ,  2024 ,  Chen et al. ,  2023a ] . In addition, probabilistic methods with certain provable removal guarantees have been explored, often leveraging the concept of differential privacy  [ Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] . Focusing on MU in diffusion-based image generation, this paper introduces a general data-free approach for rapid forgetting and one-step sampling in diffusion models, eliminating the need to access any real data.",
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper.",
            "Classic score-matching-based diffusion models  [ Sohl-Dickstein et al. ,  2015 ,  Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  have become increasingly influential in developing generative models with high extensibility and sample quality  [ Dhariwal and Nichol ,  2021 ,  Karras et al. ,  2022 ,  Ramesh et al. ,  2022 ] . However, standard Gaussian diffusion models, along with other non-Gaussian variants  [ Hoogeboom et al. ,  2021 ,  Austin et al. ,  2021 ,  Chen and Zhou ,  2023 ,  Zhou et al. ,  2023 ] , suffer from relatively slow sampling compared to traditional one-step generative models, such as GANs and VAEs. Inspired by the success of applying diffusion processes to the training of generative models,  Xiao et al.   [ 2021 ]  and  Wang et al.   [ 2022 ]  were among the first to promote faster generation by leveraging both adversarial training techniques and diffusion-based data augmentation. However, these approaches inevitably reintroduce potential issues like training instability and mode collapse. Closely related to the original score matching,  Salimans and Ho   [ 2022 ]  proposed progressively halving the steps needed in the reverse generation process. Similarly,  Song et al.   [ 2023 ]  presented the consistency model as a method for distilling the reverse ODE sampling process. Along this direction, much effort has been made by others  [ Xu et al. ,  2023 ,  Yin et al. ,  2024 ,  Luo et al. ,  2023 ,  Zhou et al. ,  2024b ]  to improve both sample quality and diversity.",
            "We provide details of nudity forgetting experiments.  Table   5  lists 12 common human subjects by category that were used for fine-tuning our model, while  Table   6  lists 27 NSFW keywords, which often carry sexual connotations and suggest nudity. For the forgetting text prompts, we randomly combined one of the human subject with one NSFW keyword in two forms: <NSFW keyword> <human subject> and <human subject>, <NSFW keyword>, which correspond to a negative prompt composed of the comma-separated 27 NSFW keywords."
        ]
    },
    "id_table_6": {
        "caption": "(b)   STL-10",
        "table": "A4.EGx6",
        "footnotes": [],
        "references": [
            "To address these challenges, we introduce  Score Forgetting Distillation  (SFD), a novel framework designed to efficiently mitigate the influence of specific characteristics in data points on pre-trained diffusion models. This framework is a key part of the broader domain of Machine Unlearning (MU), which has evolved significantly to address core issues in trustworthy machine learning  ( Lowd and Meek ,  2005 ;  Narayanan and Shmatikov ,  2008 ;  Abadi et al. ,  2016 ) . Originating from compliance needs with data protection regulations such as the right to be forgotten  ( Hoofnagle et al. ,  2019 ) , MU has broadened its scope to include applications in diffusion modeling across various domains like computer vision and content generation  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Additionally, MU aims to promote model fairness  ( Oesterling et al. ,  2024 ) , refine pre-training methodologies  ( Jain et al. ,  2023 ;  Jia et al. ,  2023 ) , and reduce the generation of inappropriate content  ( Gandikota et al. ,  2023 ) . The development of SFD is aligned with these objectives, providing a strategic approach to mitigate the potential risks and reduce the high generation costs associated with diffusion models, thereby advancing the field of trustworthy machine learning.",
            "MU methods are generally categorized into two types: exact MU and approximate MU. Exact MU entails creating a model that behaves as if sensitive data had never been part of the training set  ( Cao and Yang ,  2015 ;  Bourtoule et al. ,  2021 ) . This process requires the unlearned model to be identical in distribution to a model retrained without the sensitive data, both in terms of model weights and output behavior. In contrast, approximate MU does not seek an exact match between the unlearned model and a retrained model. Instead, it aims to approximate how closely the output distributions of the two models align after the unlearning process. A prominent strategy in approximate MU utilizes the principles of differential privacy  ( Dwork ,  2006 ) . For instance,  Guo et al.  ( 2019 )  introduced a certified removal technique that prevents adversaries from extracting information about removed training data, offering a theoretical guarantee of data privacy. However, these approaches typically necessitate retraining the model from scratch, which can be computationally intensive and require access to the original training dataset. Efficient and stable unlearning has become crucial in MU. Techniques like the influence functions  ( Warnecke et al. ,  2021 ;  Izzo et al. ,  2021 ) , selective forgetting  ( Golatkar et al. ,  2020 ) , weight-based pruning  ( Liu et al. ,  2024 ) , and gradient-based saliency  ( Fan et al. ,  2024 )  have been explored, though they often suffer from performance degradation or restrictive assumptions  ( Becker and Liebig ,  2022 ) . These methods are primarily applied to MU for image classification tasks and do not adequately address the rapid forgetting and unlearning required for data generation tasks.",
            "Similar to Eqs.  6  and  7 , we have the following:",
            "To quantitatively assess the effectiveness of class forgetting, we primarily focus on the success rate of forgetting the target class, and the generative capability on classes to retain. Specifically, we measure the success rate of forgetting by unlearning accuracy (UA) employing an external classifier trained on the original training set, which is essentially the mis-classification rate of the classifier on the generated samples from the target class. We measure image generation quality using Frechet Inception Distance (FID)  ( Heusel et al. ,  2017 )  and sample diversity using Inception Score (IS)  ( Salimans et al. ,  2016 ) . Additionally, we report Precision and Recall  ( Kynkaanniemi et al. ,  2019 ) , and number of function evaluations (NFEs) for sampling. Following  Fan et al.  ( 2024 ) , we compute and report generation quality metrics using generated samples, with the full training set from the remaining classes serving as the reference. For concept forgetting tasks including celebrity forgetting and nudity forgetting, we also provide quantitative evaluations as well as qualitative comparison. Specifically, we evaluate celebrity forgetting using a off-the-shelf celebrity face detector, while we assess the MU performance of our nudity forgetting model on the I2P benchmark ( https://github.com/ml-research/i2p ). Please refer to  Section   B.2  for more details of the evaluation metrics.",
            "In addition to the celebrity forgetting experiments, we conducted experiments on a broader concept forgetting task, namely, forgetting nudity as a concept. We note that nudity is a broader concept than individuals ( e . g . , formulae-sequence e g e.g., italic_e . italic_g . ,  celebrities) and forgetting nudity in general is much more challenging. Therefore, we adopted a slightly different strategy for this task to enhance the forgetting performance. In particular, we first created a list of 12 common human subjects (see  Table   5 ) that can be potentially misused for generating nudity-related contents and randomly paired them with one of NSFW keywords (see  Table   6 ) as prompts to forget. We further leveraged the negative prompting technique to match these prompts with their corresponding prompts to override. Specifically, we take the original text prompt as the conditional text input while using the concatenated NSFW keywords instead of an empty string as the unconditional text input. We notice this approach also has a concept forgetting effect on the original score distillation method, which is denoted as SiD-LSG-Neg. We report key MU performance metrics in  Table   3 . Sample images by baselines and SFD are displayed in  Figure   6 .",
            "For class forgetting tasks, we employed an external classifier to obtain unlearning accuracy (UA), ensuring that the generated images are not associated with the class or concept designated for forgetting. The UA is essentially the mis-classification rate of the classifier on the generated samples from the target class. A classifier with high test accuracy and low UA typically indicates effective forgetting, ensuring that the generated images are unlikely to belong to the target class or concept. For the external classifier, we fine-tuned ResNet-34  [ He et al. ,  2016 ]  for 10 epochs on both CIFAR-10 and STL-10 datasets using transfer learning, which is originally pretrained on ImageNet  [ Deng et al. ,  2009 ] . We adapted the original 1000-way classification model by replacing the last fully-connected layer with a customized fully-connected layer with 10 output dimension. The resulting classifiers achieved training and testing accuracies of 99.96% and 95.03% on CIFAR-10, and 100.00% and 96.20% on STL-10, respectively.",
            "We provide details of nudity forgetting experiments.  Table   5  lists 12 common human subjects by category that were used for fine-tuning our model, while  Table   6  lists 27 NSFW keywords, which often carry sexual connotations and suggest nudity. For the forgetting text prompts, we randomly combined one of the human subject with one NSFW keyword in two forms: <NSFW keyword> <human subject> and <human subject>, <NSFW keyword>, which correspond to a negative prompt composed of the comma-separated 27 NSFW keywords."
        ]
    },
    "id_table_7": {
        "caption": "Table 5:  List of 12 subjects potentially prone to abuse",
        "table": "A4.EGx7",
        "footnotes": [],
        "references": [
            "This formulation corresponds to a bi-level optimization problem  ( Ye et al. ,  1997 ;  Hong et al. ,  2023 ;  Shen et al. ,  2023 ) , subject to an additional forgetting-based constraint. Solving this problem directly is challenging, so we initially relax the constraint specified by  L sfd subscript L sfd \\mathcal{L}_{\\text{sfd}} caligraphic_L start_POSTSUBSCRIPT sfd end_POSTSUBSCRIPT  in the above equation by integrating it into the distillation objective as an additional MU regularization term:",
            "Similar to Eqs.  6  and  7 , we have the following:",
            "To quantitatively assess the effectiveness of class forgetting, we primarily focus on the success rate of forgetting the target class, and the generative capability on classes to retain. Specifically, we measure the success rate of forgetting by unlearning accuracy (UA) employing an external classifier trained on the original training set, which is essentially the mis-classification rate of the classifier on the generated samples from the target class. We measure image generation quality using Frechet Inception Distance (FID)  ( Heusel et al. ,  2017 )  and sample diversity using Inception Score (IS)  ( Salimans et al. ,  2016 ) . Additionally, we report Precision and Recall  ( Kynkaanniemi et al. ,  2019 ) , and number of function evaluations (NFEs) for sampling. Following  Fan et al.  ( 2024 ) , we compute and report generation quality metrics using generated samples, with the full training set from the remaining classes serving as the reference. For concept forgetting tasks including celebrity forgetting and nudity forgetting, we also provide quantitative evaluations as well as qualitative comparison. Specifically, we evaluate celebrity forgetting using a off-the-shelf celebrity face detector, while we assess the MU performance of our nudity forgetting model on the I2P benchmark ( https://github.com/ml-research/i2p ). Please refer to  Section   B.2  for more details of the evaluation metrics.",
            "On CIFAR-10, we observed that the SFD-Two Stage model (or Two Stage, for short), which involves first distilling the pre-trained diffusion model with 50,000 steps and then fine-tuning it using the SFD loss for the same number of steps, exhibited faster forgetting. In  Figure   7 , we report two performance metrics, FID and UA, during the unlearning stage, compared with the results from SFD. The results indicate that SFD consistently outperforms the two-stage approach in both metrics given sufficient training. Although the two-stage approach started with a lower FID than SFD, its performance fluctuated and declined over time. The UA initially increased rapidly, peaked, and then slightly decreased at the end. The gain in UA during the unlearning stage came at the cost of FID. In contrast, SFD effectively coordinated machine unlearning and distillation to forget specific classes while retaining the original generative capability for the remaining classes, thereby improving both FID and UA throughout finetuning and achieving better final results. Nonetheless, the two-stage approach remains practical, especially when forgetting requirements vary over time or when there is an urgent need, as it appears more flexible and efficient under such conditions.",
            "We plot two main evaluation metrics for class forgetting experiments on CIFAR-10 for comparing SFD with SFD-Two Stage in  Figure   7 .",
            "We also provide additional nudity detection results by NudeNet detector in  Table   7 . Upon reviewing the unsafe images flagged by NudeNet, we identified several false positives (see  Figure   8  for examples) that were unrelated to the classification results, such as cases where no exposed anus was present in images generated by SFD."
        ]
    },
    "id_table_8": {
        "caption": "Table 6:  List of nudity-related NSFW keywords used for negative prompts",
        "table": "A4.EGx8",
        "footnotes": [],
        "references": [
            "To address these challenges, we introduce  Score Forgetting Distillation  (SFD), a novel framework designed to efficiently mitigate the influence of specific characteristics in data points on pre-trained diffusion models. This framework is a key part of the broader domain of Machine Unlearning (MU), which has evolved significantly to address core issues in trustworthy machine learning  ( Lowd and Meek ,  2005 ;  Narayanan and Shmatikov ,  2008 ;  Abadi et al. ,  2016 ) . Originating from compliance needs with data protection regulations such as the right to be forgotten  ( Hoofnagle et al. ,  2019 ) , MU has broadened its scope to include applications in diffusion modeling across various domains like computer vision and content generation  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Additionally, MU aims to promote model fairness  ( Oesterling et al. ,  2024 ) , refine pre-training methodologies  ( Jain et al. ,  2023 ;  Jia et al. ,  2023 ) , and reduce the generation of inappropriate content  ( Gandikota et al. ,  2023 ) . The development of SFD is aligned with these objectives, providing a strategic approach to mitigate the potential risks and reduce the high generation costs associated with diffusion models, thereby advancing the field of trustworthy machine learning.",
            "With this optimal score estimator, we can construct a corresponding reverse diffusion process, enabling us to approximately sample from the data distribution through numerical discretization along the time horizon  ( Anderson ,  1982 ;  Song et al. ,  2020 ) .",
            "A biased loss for    \\theta italic_  can be derived by replacing     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ )  in either Eq.  3  or Eq.  8  with its SGD-based approximation    \\psi italic_ , and disregarding the dependency of    superscript  \\psi^{*} italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  on    \\theta italic_  when computing the gradient of    \\theta italic_ . Empirical experiments by  Zhou et al.  ( 2024b )  suggest that in the context of diffusion distillation without involving unlearning, Eq.  8  can be effective independently, while Eq.  3  may not perform as expected. This observation leads to a practical approach that involves subtracting Eq.  3  from Eq.  8 . This strategy aims to sidestep detrimental biased gradient directions and potentially compensate for the overlooked gradient dependency of     (  ) superscript   \\psi^{*}(\\theta) italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( italic_ ) . We implement this approach in practice under the framework of SFD, defining the loss used in practice as follows:",
            "In addition to initializing both the generator and the fake score network with the pre-trained score network, we also experimented on a different initialization,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , initializing the generator with a pre-distilled generator model weights. Considering the nature of first distilling then forgetting, we named this variant SFD-Two Stage. For this variant specifically, we disabled exponential moving average (EMA) and adopted a more aggressive regularization with    =   =   =   = 1.0 subscript   subscript   subscript   subscript   1.0 \\lambda_{\\psi}=\\mu_{\\psi}=\\lambda_{\\theta}=\\mu_{\\theta}=1.0 italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT = 1.0 . The rationale behind this configuration was that the first stage distillation would have prepared a solid foundation for the second stage forgetting, which enables fast forgetting by increasing the weight of forgetting loss and by further prioritizing it in the second stage. We use Adam optimizer with   1 = 0 subscript  1 0 \\beta_{1}=0 italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0  and   2 = 0.999 subscript  2 0.999 \\beta_{2}=0.999 italic_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.999  for all the experiments. The base learning rate for both DDPM and EDM models is set to  10  5 superscript 10 5 10^{-5} 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT , except that we slightly increase the learning rate for  s  subscript s  s_{\\psi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  when distilling DDPM models. More details on the hyperparameter settings for the experiments can be found in  Table   8 .",
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper.",
            "We also provide additional nudity detection results by NudeNet detector in  Table   7 . Upon reviewing the unsafe images flagged by NudeNet, we identified several false positives (see  Figure   8  for examples) that were unrelated to the classification results, such as cases where no exposed anus was present in images generated by SFD.",
            "We list all the detailed hyparameter settings for training our DDPM, EDM, SD models in  Table   8 ."
        ]
    },
    "id_table_9": {
        "caption": "Table 7 :  Count of exposed body parts detected using the NudeNet classifier on the I2P benchmark dataset (4703 images).",
        "table": "A4.EGx9",
        "footnotes": [],
        "references": [
            "Diffusion models, also known as score-based generative models  ( Sohl-Dickstein et al. ,  2015 ;  Song and Ermon ,  2019 ;  Ho et al. ,  2020 ;  Dhariwal and Nichol ,  2021 ;  Karras et al. ,  2022 ) , have emerged as the leading choice for generative modeling of high-dimensional data. These models are widely celebrated for their ability to produce high-quality, diverse, and photorealistic images  ( Nichol et al. ,  2022 ;  Ramesh et al. ,  2022 ;  Saharia et al. ,  2022 ;  Rombach et al. ,  2022 ;  Podell et al. ,  2024 ;  Zheng et al. ,  2024 ) . However, their capacity to memorize and reproduce specific images and concepts from training datasets raises significant privacy and safety concerns. Moreover, they are susceptible to poisoning attacks, enabling the generation of targeted images with embedded triggers, posing substantial security risks  ( Rando et al. ,  2022 ;  Chen et al. ,  2023b ) .",
            "To address these challenges, we introduce  Score Forgetting Distillation  (SFD), a novel framework designed to efficiently mitigate the influence of specific characteristics in data points on pre-trained diffusion models. This framework is a key part of the broader domain of Machine Unlearning (MU), which has evolved significantly to address core issues in trustworthy machine learning  ( Lowd and Meek ,  2005 ;  Narayanan and Shmatikov ,  2008 ;  Abadi et al. ,  2016 ) . Originating from compliance needs with data protection regulations such as the right to be forgotten  ( Hoofnagle et al. ,  2019 ) , MU has broadened its scope to include applications in diffusion modeling across various domains like computer vision and content generation  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Additionally, MU aims to promote model fairness  ( Oesterling et al. ,  2024 ) , refine pre-training methodologies  ( Jain et al. ,  2023 ;  Jia et al. ,  2023 ) , and reduce the generation of inappropriate content  ( Gandikota et al. ,  2023 ) . The development of SFD is aligned with these objectives, providing a strategic approach to mitigate the potential risks and reduce the high generation costs associated with diffusion models, thereby advancing the field of trustworthy machine learning.",
            "MU methods are generally categorized into two types: exact MU and approximate MU. Exact MU entails creating a model that behaves as if sensitive data had never been part of the training set  ( Cao and Yang ,  2015 ;  Bourtoule et al. ,  2021 ) . This process requires the unlearned model to be identical in distribution to a model retrained without the sensitive data, both in terms of model weights and output behavior. In contrast, approximate MU does not seek an exact match between the unlearned model and a retrained model. Instead, it aims to approximate how closely the output distributions of the two models align after the unlearning process. A prominent strategy in approximate MU utilizes the principles of differential privacy  ( Dwork ,  2006 ) . For instance,  Guo et al.  ( 2019 )  introduced a certified removal technique that prevents adversaries from extracting information about removed training data, offering a theoretical guarantee of data privacy. However, these approaches typically necessitate retraining the model from scratch, which can be computationally intensive and require access to the original training dataset. Efficient and stable unlearning has become crucial in MU. Techniques like the influence functions  ( Warnecke et al. ,  2021 ;  Izzo et al. ,  2021 ) , selective forgetting  ( Golatkar et al. ,  2020 ) , weight-based pruning  ( Liu et al. ,  2024 ) , and gradient-based saliency  ( Fan et al. ,  2024 )  have been explored, though they often suffer from performance degradation or restrictive assumptions  ( Becker and Liebig ,  2022 ) . These methods are primarily applied to MU for image classification tasks and do not adequately address the rapid forgetting and unlearning required for data generation tasks.",
            "Before diving into the specific MU problem, we will first establish the essential concepts and notations in diffusion modeling: A diffusion model corrupts its data  x  p data  ( x  c ) similar-to x subscript p data conditional x c x\\sim p_{\\text{data}}(x\\mid c) italic_x  italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_x  italic_c )  during the forward diffusion process at time  t t t italic_t  as  z t = a t  x +  t   t subscript z t subscript a t x subscript  t subscript italic- t z_{t}=a_{t}x+\\sigma_{t}\\epsilon_{t} italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x + italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , where   t  N  ( 0 , 1 ) similar-to subscript italic- t N 0 1 \\epsilon_{t}\\sim\\mathcal{N}(0,1) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  caligraphic_N ( 0 , 1 ) ,  c c c italic_c  represents the given condition such as a label or text, and  a t subscript a t a_{t} italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and   t subscript  t \\sigma_{t} italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  are diffusion scheduling parameters. The goal of pretraining a diffusion model is to obtain an optimal score estimator  s   ( z t , c , t ) subscript s italic- subscript z t c t s_{\\phi}(z_{t},c,t) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  such that  s   ( z t , c , t ) =  z t ln  p data  ( z t | c ) subscript s italic- subscript z t c t subscript  subscript z t subscript p data conditional subscript z t c s_{\\phi}(z_{t},c,t)=\\nabla_{z_{t}}\\ln p_{\\text{data}}(z_{t}\\,|\\,c) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) =  start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c ) . Let  x   ( z t , c , t ) subscript x italic- subscript z t c t x_{\\phi}(z_{t},c,t) italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  be the optimal conditional mean estimator such that for  x   ( z t , c , t ) = E  [ x | z t , c , t ] subscript x italic- subscript z t c t E delimited-[] conditional x subscript z t c t x_{\\phi}(z_{t},c,t)=\\mathbb{E}[x\\,|\\,z_{t},c,t] italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) = blackboard_E [ italic_x | italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ] . Applying Tweedies formula  ( Robbins ,  1992 ;  Efron ,  2011 )  in the context of diffusion modeling  ( Luo ,  2022 ;  Chung et al. ,  2023 ;  Zhou et al. ,  2024b ) , the optimal score and conditional mean estimators,  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and  x  subscript x italic- x_{\\phi} italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT , for the training data are related as follows:",
            "With this optimal score estimator, we can construct a corresponding reverse diffusion process, enabling us to approximately sample from the data distribution through numerical discretization along the time horizon  ( Anderson ,  1982 ;  Song et al. ,  2020 ) .",
            "This formulation corresponds to a bi-level optimization problem  ( Ye et al. ,  1997 ;  Hong et al. ,  2023 ;  Shen et al. ,  2023 ) , subject to an additional forgetting-based constraint. Solving this problem directly is challenging, so we initially relax the constraint specified by  L sfd subscript L sfd \\mathcal{L}_{\\text{sfd}} caligraphic_L start_POSTSUBSCRIPT sfd end_POSTSUBSCRIPT  in the above equation by integrating it into the distillation objective as an additional MU regularization term:",
            "To quantitatively assess the effectiveness of class forgetting, we primarily focus on the success rate of forgetting the target class, and the generative capability on classes to retain. Specifically, we measure the success rate of forgetting by unlearning accuracy (UA) employing an external classifier trained on the original training set, which is essentially the mis-classification rate of the classifier on the generated samples from the target class. We measure image generation quality using Frechet Inception Distance (FID)  ( Heusel et al. ,  2017 )  and sample diversity using Inception Score (IS)  ( Salimans et al. ,  2016 ) . Additionally, we report Precision and Recall  ( Kynkaanniemi et al. ,  2019 ) , and number of function evaluations (NFEs) for sampling. Following  Fan et al.  ( 2024 ) , we compute and report generation quality metrics using generated samples, with the full training set from the remaining classes serving as the reference. For concept forgetting tasks including celebrity forgetting and nudity forgetting, we also provide quantitative evaluations as well as qualitative comparison. Specifically, we evaluate celebrity forgetting using a off-the-shelf celebrity face detector, while we assess the MU performance of our nudity forgetting model on the I2P benchmark ( https://github.com/ml-research/i2p ). Please refer to  Section   B.2  for more details of the evaluation metrics.",
            "The study of MU can be traced back to classical machine learning models in response to data protection regulations such as the right to be forgotten  [ Cao and Yang ,  2015 ,  Hoofnagle et al. ,  2019 ,  Bourtoule et al. ,  2021 ,  Nguyen et al. ,  2022 ] . Due to its capability of assessing data influence on model performance, the landscape of MU has expanded to encompass diverse domains, such as image classification  [ Ginart et al. ,  2019 ,  Golatkar et al. ,  2020 ,  Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] , text-to-image generation  [ Gandikota et al. ,  2023 ,  Zhang et al. ,  2023a ,  Kumari et al. ,  2023 ,  Fan et al. ,  2024 ] , federated learning  [ Halimi et al. ,  2022 ,  Che et al. ,  2023 ] , and graph neural networks  [ Chen et al. ,  2022 ,  Chien et al. ,  2022 ,  Wu et al. ,  2023 ] . In the literature, exact unlearning, which involves retraining the model from scratch after removing specific training data points, is often considered the gold standard. However, this approach comes with significant computational demands and requires access to the entire training set  [ Thudi et al. ,  2022 ] . To address these challenges, many research efforts have shifted towards the development of scalable and effective approximate unlearning methods  [ Liu et al. ,  2024 ,  Chen et al. ,  2023a ] . In addition, probabilistic methods with certain provable removal guarantees have been explored, often leveraging the concept of differential privacy  [ Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] . Focusing on MU in diffusion-based image generation, this paper introduces a general data-free approach for rapid forgetting and one-step sampling in diffusion models, eliminating the need to access any real data.",
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper.",
            "Classic score-matching-based diffusion models  [ Sohl-Dickstein et al. ,  2015 ,  Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  have become increasingly influential in developing generative models with high extensibility and sample quality  [ Dhariwal and Nichol ,  2021 ,  Karras et al. ,  2022 ,  Ramesh et al. ,  2022 ] . However, standard Gaussian diffusion models, along with other non-Gaussian variants  [ Hoogeboom et al. ,  2021 ,  Austin et al. ,  2021 ,  Chen and Zhou ,  2023 ,  Zhou et al. ,  2023 ] , suffer from relatively slow sampling compared to traditional one-step generative models, such as GANs and VAEs. Inspired by the success of applying diffusion processes to the training of generative models,  Xiao et al.   [ 2021 ]  and  Wang et al.   [ 2022 ]  were among the first to promote faster generation by leveraging both adversarial training techniques and diffusion-based data augmentation. However, these approaches inevitably reintroduce potential issues like training instability and mode collapse. Closely related to the original score matching,  Salimans and Ho   [ 2022 ]  proposed progressively halving the steps needed in the reverse generation process. Similarly,  Song et al.   [ 2023 ]  presented the consistency model as a method for distilling the reverse ODE sampling process. Along this direction, much effort has been made by others  [ Xu et al. ,  2023 ,  Yin et al. ,  2024 ,  Luo et al. ,  2023 ,  Zhou et al. ,  2024b ]  to improve both sample quality and diversity.",
            "For the class forgetting tasks, we utilize CIFAR-10  [ Krizhevsky ,  2009 ]  at a resolution of  32  32 32 32 32\\times 32 32  32  and STL-10  [ Coates et al. ,  2011 ]  at  64  64 64 64 64\\times 64 64  64  resolution. The CIFAR-10 dataset consists of 60,000 32  \\times  32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. The dataset consists of 50,000 training images and 10,000 test images. It is organized into five training batches and one test batch, each containing 10,000 images. The test batch includes precisely 1,000 randomly-selected images from each class. The training batches, which hold the remaining images in random order, may have varying numbers of images from each class. The STL-10 dataset is another natural image dataset with 10 classes, each of which has 500 training data and 800 testing data. The image data has a higher resolution of 96  \\times  96 in pixels and RGB color channels compared with CIFAR-10. The images were acquired from labeled examples on ImageNet  [ Deng et al. ,  2009 ] . During training time, the image data from STL-10 are resized to 64  \\times  64. Due to the limited number of the original training data, both training and testing data were used in the experiments, making up 13,000 training images in total.",
            "For class forgetting tasks, we employed an external classifier to obtain unlearning accuracy (UA), ensuring that the generated images are not associated with the class or concept designated for forgetting. The UA is essentially the mis-classification rate of the classifier on the generated samples from the target class. A classifier with high test accuracy and low UA typically indicates effective forgetting, ensuring that the generated images are unlikely to belong to the target class or concept. For the external classifier, we fine-tuned ResNet-34  [ He et al. ,  2016 ]  for 10 epochs on both CIFAR-10 and STL-10 datasets using transfer learning, which is originally pretrained on ImageNet  [ Deng et al. ,  2009 ] . We adapted the original 1000-way classification model by replacing the last fully-connected layer with a customized fully-connected layer with 10 output dimension. The resulting classifiers achieved training and testing accuracies of 99.96% and 95.03% on CIFAR-10, and 100.00% and 96.20% on STL-10, respectively."
        ]
    },
    "id_table_10": {
        "caption": "Table 8:  Detailed unlearned and distilled diffusion hyperparameter setting in for both DDPM, EDM, and SD model architectures",
        "table": "A4.EGx10",
        "footnotes": [],
        "references": []
    },
    "id_table_11": {
        "caption": "",
        "table": "S2.T1.6",
        "footnotes": [
            "",
            "",
            "",
            "",
            ""
        ],
        "references": [
            "Before diving into the specific MU problem, we will first establish the essential concepts and notations in diffusion modeling: A diffusion model corrupts its data  x  p data  ( x  c ) similar-to x subscript p data conditional x c x\\sim p_{\\text{data}}(x\\mid c) italic_x  italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_x  italic_c )  during the forward diffusion process at time  t t t italic_t  as  z t = a t  x +  t   t subscript z t subscript a t x subscript  t subscript italic- t z_{t}=a_{t}x+\\sigma_{t}\\epsilon_{t} italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x + italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , where   t  N  ( 0 , 1 ) similar-to subscript italic- t N 0 1 \\epsilon_{t}\\sim\\mathcal{N}(0,1) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  caligraphic_N ( 0 , 1 ) ,  c c c italic_c  represents the given condition such as a label or text, and  a t subscript a t a_{t} italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and   t subscript  t \\sigma_{t} italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  are diffusion scheduling parameters. The goal of pretraining a diffusion model is to obtain an optimal score estimator  s   ( z t , c , t ) subscript s italic- subscript z t c t s_{\\phi}(z_{t},c,t) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  such that  s   ( z t , c , t ) =  z t ln  p data  ( z t | c ) subscript s italic- subscript z t c t subscript  subscript z t subscript p data conditional subscript z t c s_{\\phi}(z_{t},c,t)=\\nabla_{z_{t}}\\ln p_{\\text{data}}(z_{t}\\,|\\,c) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) =  start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c ) . Let  x   ( z t , c , t ) subscript x italic- subscript z t c t x_{\\phi}(z_{t},c,t) italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  be the optimal conditional mean estimator such that for  x   ( z t , c , t ) = E  [ x | z t , c , t ] subscript x italic- subscript z t c t E delimited-[] conditional x subscript z t c t x_{\\phi}(z_{t},c,t)=\\mathbb{E}[x\\,|\\,z_{t},c,t] italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) = blackboard_E [ italic_x | italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ] . Applying Tweedies formula  ( Robbins ,  1992 ;  Efron ,  2011 )  in the context of diffusion modeling  ( Luo ,  2022 ;  Chung et al. ,  2023 ;  Zhou et al. ,  2024b ) , the optimal score and conditional mean estimators,  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and  x  subscript x italic- x_{\\phi} italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT , for the training data are related as follows:",
            "where   t > 0 subscript  t 0 \\gamma_{t}>0 italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT > 0  is a re-weighting function. In practice, the lack of the access to   x ln  p   ( z t | c ) subscript  x subscript p  conditional subscript z t c \\nabla_{x}\\ln p_{\\theta}(z_{t}\\,|\\,c)  start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c )  makes Eq.  4  intractable. However, we can alternatively optimize a denoising SM loss  ( Vincent ,  2011 )  as",
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper.",
            "For the class forgetting tasks, we utilize CIFAR-10  [ Krizhevsky ,  2009 ]  at a resolution of  32  32 32 32 32\\times 32 32  32  and STL-10  [ Coates et al. ,  2011 ]  at  64  64 64 64 64\\times 64 64  64  resolution. The CIFAR-10 dataset consists of 60,000 32  \\times  32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. The dataset consists of 50,000 training images and 10,000 test images. It is organized into five training batches and one test batch, each containing 10,000 images. The test batch includes precisely 1,000 randomly-selected images from each class. The training batches, which hold the remaining images in random order, may have varying numbers of images from each class. The STL-10 dataset is another natural image dataset with 10 classes, each of which has 500 training data and 800 testing data. The image data has a higher resolution of 96  \\times  96 in pixels and RGB color channels compared with CIFAR-10. The images were acquired from labeled examples on ImageNet  [ Deng et al. ,  2009 ] . During training time, the image data from STL-10 are resized to 64  \\times  64. Due to the limited number of the original training data, both training and testing data were used in the experiments, making up 13,000 training images in total."
        ]
    },
    "id_table_12": {
        "caption": "",
        "table": "S3.T2.6",
        "footnotes": [
            "",
            "",
            "",
            ""
        ],
        "references": []
    },
    "id_table_13": {
        "caption": "",
        "table": "S3.T3.2.2",
        "footnotes": [
            "",
            "",
            "",
            ""
        ],
        "references": [
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper."
        ]
    },
    "id_table_14": {
        "caption": "",
        "table": "S3.T4.st1.2.2",
        "footnotes": [],
        "references": [
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper."
        ]
    },
    "id_table_15": {
        "caption": "",
        "table": "S3.T4.st2.2.2",
        "footnotes": [],
        "references": [
            "Diffusion models, also known as score-based generative models  ( Sohl-Dickstein et al. ,  2015 ;  Song and Ermon ,  2019 ;  Ho et al. ,  2020 ;  Dhariwal and Nichol ,  2021 ;  Karras et al. ,  2022 ) , have emerged as the leading choice for generative modeling of high-dimensional data. These models are widely celebrated for their ability to produce high-quality, diverse, and photorealistic images  ( Nichol et al. ,  2022 ;  Ramesh et al. ,  2022 ;  Saharia et al. ,  2022 ;  Rombach et al. ,  2022 ;  Podell et al. ,  2024 ;  Zheng et al. ,  2024 ) . However, their capacity to memorize and reproduce specific images and concepts from training datasets raises significant privacy and safety concerns. Moreover, they are susceptible to poisoning attacks, enabling the generation of targeted images with embedded triggers, posing substantial security risks  ( Rando et al. ,  2022 ;  Chen et al. ,  2023b ) .",
            "MU methods are generally categorized into two types: exact MU and approximate MU. Exact MU entails creating a model that behaves as if sensitive data had never been part of the training set  ( Cao and Yang ,  2015 ;  Bourtoule et al. ,  2021 ) . This process requires the unlearned model to be identical in distribution to a model retrained without the sensitive data, both in terms of model weights and output behavior. In contrast, approximate MU does not seek an exact match between the unlearned model and a retrained model. Instead, it aims to approximate how closely the output distributions of the two models align after the unlearning process. A prominent strategy in approximate MU utilizes the principles of differential privacy  ( Dwork ,  2006 ) . For instance,  Guo et al.  ( 2019 )  introduced a certified removal technique that prevents adversaries from extracting information about removed training data, offering a theoretical guarantee of data privacy. However, these approaches typically necessitate retraining the model from scratch, which can be computationally intensive and require access to the original training dataset. Efficient and stable unlearning has become crucial in MU. Techniques like the influence functions  ( Warnecke et al. ,  2021 ;  Izzo et al. ,  2021 ) , selective forgetting  ( Golatkar et al. ,  2020 ) , weight-based pruning  ( Liu et al. ,  2024 ) , and gradient-based saliency  ( Fan et al. ,  2024 )  have been explored, though they often suffer from performance degradation or restrictive assumptions  ( Becker and Liebig ,  2022 ) . These methods are primarily applied to MU for image classification tasks and do not adequately address the rapid forgetting and unlearning required for data generation tasks.",
            "The study of MU can be traced back to classical machine learning models in response to data protection regulations such as the right to be forgotten  [ Cao and Yang ,  2015 ,  Hoofnagle et al. ,  2019 ,  Bourtoule et al. ,  2021 ,  Nguyen et al. ,  2022 ] . Due to its capability of assessing data influence on model performance, the landscape of MU has expanded to encompass diverse domains, such as image classification  [ Ginart et al. ,  2019 ,  Golatkar et al. ,  2020 ,  Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] , text-to-image generation  [ Gandikota et al. ,  2023 ,  Zhang et al. ,  2023a ,  Kumari et al. ,  2023 ,  Fan et al. ,  2024 ] , federated learning  [ Halimi et al. ,  2022 ,  Che et al. ,  2023 ] , and graph neural networks  [ Chen et al. ,  2022 ,  Chien et al. ,  2022 ,  Wu et al. ,  2023 ] . In the literature, exact unlearning, which involves retraining the model from scratch after removing specific training data points, is often considered the gold standard. However, this approach comes with significant computational demands and requires access to the entire training set  [ Thudi et al. ,  2022 ] . To address these challenges, many research efforts have shifted towards the development of scalable and effective approximate unlearning methods  [ Liu et al. ,  2024 ,  Chen et al. ,  2023a ] . In addition, probabilistic methods with certain provable removal guarantees have been explored, often leveraging the concept of differential privacy  [ Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] . Focusing on MU in diffusion-based image generation, this paper introduces a general data-free approach for rapid forgetting and one-step sampling in diffusion models, eliminating the need to access any real data.",
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper.",
            "Classic score-matching-based diffusion models  [ Sohl-Dickstein et al. ,  2015 ,  Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  have become increasingly influential in developing generative models with high extensibility and sample quality  [ Dhariwal and Nichol ,  2021 ,  Karras et al. ,  2022 ,  Ramesh et al. ,  2022 ] . However, standard Gaussian diffusion models, along with other non-Gaussian variants  [ Hoogeboom et al. ,  2021 ,  Austin et al. ,  2021 ,  Chen and Zhou ,  2023 ,  Zhou et al. ,  2023 ] , suffer from relatively slow sampling compared to traditional one-step generative models, such as GANs and VAEs. Inspired by the success of applying diffusion processes to the training of generative models,  Xiao et al.   [ 2021 ]  and  Wang et al.   [ 2022 ]  were among the first to promote faster generation by leveraging both adversarial training techniques and diffusion-based data augmentation. However, these approaches inevitably reintroduce potential issues like training instability and mode collapse. Closely related to the original score matching,  Salimans and Ho   [ 2022 ]  proposed progressively halving the steps needed in the reverse generation process. Similarly,  Song et al.   [ 2023 ]  presented the consistency model as a method for distilling the reverse ODE sampling process. Along this direction, much effort has been made by others  [ Xu et al. ,  2023 ,  Yin et al. ,  2024 ,  Luo et al. ,  2023 ,  Zhou et al. ,  2024b ]  to improve both sample quality and diversity."
        ]
    },
    "id_table_16": {
        "caption": "",
        "table": "A2.T6.4",
        "footnotes": [],
        "references": [
            "To address these challenges, we introduce  Score Forgetting Distillation  (SFD), a novel framework designed to efficiently mitigate the influence of specific characteristics in data points on pre-trained diffusion models. This framework is a key part of the broader domain of Machine Unlearning (MU), which has evolved significantly to address core issues in trustworthy machine learning  ( Lowd and Meek ,  2005 ;  Narayanan and Shmatikov ,  2008 ;  Abadi et al. ,  2016 ) . Originating from compliance needs with data protection regulations such as the right to be forgotten  ( Hoofnagle et al. ,  2019 ) , MU has broadened its scope to include applications in diffusion modeling across various domains like computer vision and content generation  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Additionally, MU aims to promote model fairness  ( Oesterling et al. ,  2024 ) , refine pre-training methodologies  ( Jain et al. ,  2023 ;  Jia et al. ,  2023 ) , and reduce the generation of inappropriate content  ( Gandikota et al. ,  2023 ) . The development of SFD is aligned with these objectives, providing a strategic approach to mitigate the potential risks and reduce the high generation costs associated with diffusion models, thereby advancing the field of trustworthy machine learning.",
            "To quantitatively assess the effectiveness of class forgetting, we primarily focus on the success rate of forgetting the target class, and the generative capability on classes to retain. Specifically, we measure the success rate of forgetting by unlearning accuracy (UA) employing an external classifier trained on the original training set, which is essentially the mis-classification rate of the classifier on the generated samples from the target class. We measure image generation quality using Frechet Inception Distance (FID)  ( Heusel et al. ,  2017 )  and sample diversity using Inception Score (IS)  ( Salimans et al. ,  2016 ) . Additionally, we report Precision and Recall  ( Kynkaanniemi et al. ,  2019 ) , and number of function evaluations (NFEs) for sampling. Following  Fan et al.  ( 2024 ) , we compute and report generation quality metrics using generated samples, with the full training set from the remaining classes serving as the reference. For concept forgetting tasks including celebrity forgetting and nudity forgetting, we also provide quantitative evaluations as well as qualitative comparison. Specifically, we evaluate celebrity forgetting using a off-the-shelf celebrity face detector, while we assess the MU performance of our nudity forgetting model on the I2P benchmark ( https://github.com/ml-research/i2p ). Please refer to  Section   B.2  for more details of the evaluation metrics.",
            "For class forgetting tasks, we employed an external classifier to obtain unlearning accuracy (UA), ensuring that the generated images are not associated with the class or concept designated for forgetting. The UA is essentially the mis-classification rate of the classifier on the generated samples from the target class. A classifier with high test accuracy and low UA typically indicates effective forgetting, ensuring that the generated images are unlikely to belong to the target class or concept. For the external classifier, we fine-tuned ResNet-34  [ He et al. ,  2016 ]  for 10 epochs on both CIFAR-10 and STL-10 datasets using transfer learning, which is originally pretrained on ImageNet  [ Deng et al. ,  2009 ] . We adapted the original 1000-way classification model by replacing the last fully-connected layer with a customized fully-connected layer with 10 output dimension. The resulting classifiers achieved training and testing accuracies of 99.96% and 95.03% on CIFAR-10, and 100.00% and 96.20% on STL-10, respectively."
        ]
    },
    "id_table_17": {
        "caption": "",
        "table": "A2.T7.6",
        "footnotes": [],
        "references": [
            "To quantitatively assess the effectiveness of class forgetting, we primarily focus on the success rate of forgetting the target class, and the generative capability on classes to retain. Specifically, we measure the success rate of forgetting by unlearning accuracy (UA) employing an external classifier trained on the original training set, which is essentially the mis-classification rate of the classifier on the generated samples from the target class. We measure image generation quality using Frechet Inception Distance (FID)  ( Heusel et al. ,  2017 )  and sample diversity using Inception Score (IS)  ( Salimans et al. ,  2016 ) . Additionally, we report Precision and Recall  ( Kynkaanniemi et al. ,  2019 ) , and number of function evaluations (NFEs) for sampling. Following  Fan et al.  ( 2024 ) , we compute and report generation quality metrics using generated samples, with the full training set from the remaining classes serving as the reference. For concept forgetting tasks including celebrity forgetting and nudity forgetting, we also provide quantitative evaluations as well as qualitative comparison. Specifically, we evaluate celebrity forgetting using a off-the-shelf celebrity face detector, while we assess the MU performance of our nudity forgetting model on the I2P benchmark ( https://github.com/ml-research/i2p ). Please refer to  Section   B.2  for more details of the evaluation metrics."
        ]
    },
    "id_table_18": {
        "caption": "",
        "table": "A2.T8.30",
        "footnotes": [
            "",
            "",
            "",
            ""
        ],
        "references": [
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper."
        ]
    },
    "id_table_19": {
        "caption": "",
        "table": "A4.EGx11",
        "footnotes": [],
        "references": [
            "Diffusion models, also known as score-based generative models  ( Sohl-Dickstein et al. ,  2015 ;  Song and Ermon ,  2019 ;  Ho et al. ,  2020 ;  Dhariwal and Nichol ,  2021 ;  Karras et al. ,  2022 ) , have emerged as the leading choice for generative modeling of high-dimensional data. These models are widely celebrated for their ability to produce high-quality, diverse, and photorealistic images  ( Nichol et al. ,  2022 ;  Ramesh et al. ,  2022 ;  Saharia et al. ,  2022 ;  Rombach et al. ,  2022 ;  Podell et al. ,  2024 ;  Zheng et al. ,  2024 ) . However, their capacity to memorize and reproduce specific images and concepts from training datasets raises significant privacy and safety concerns. Moreover, they are susceptible to poisoning attacks, enabling the generation of targeted images with embedded triggers, posing substantial security risks  ( Rando et al. ,  2022 ;  Chen et al. ,  2023b ) .",
            "To address these challenges, we introduce  Score Forgetting Distillation  (SFD), a novel framework designed to efficiently mitigate the influence of specific characteristics in data points on pre-trained diffusion models. This framework is a key part of the broader domain of Machine Unlearning (MU), which has evolved significantly to address core issues in trustworthy machine learning  ( Lowd and Meek ,  2005 ;  Narayanan and Shmatikov ,  2008 ;  Abadi et al. ,  2016 ) . Originating from compliance needs with data protection regulations such as the right to be forgotten  ( Hoofnagle et al. ,  2019 ) , MU has broadened its scope to include applications in diffusion modeling across various domains like computer vision and content generation  ( Gandikota et al. ,  2023 ;  Fan et al. ,  2024 ;  Heng and Soh ,  2024 ) . Additionally, MU aims to promote model fairness  ( Oesterling et al. ,  2024 ) , refine pre-training methodologies  ( Jain et al. ,  2023 ;  Jia et al. ,  2023 ) , and reduce the generation of inappropriate content  ( Gandikota et al. ,  2023 ) . The development of SFD is aligned with these objectives, providing a strategic approach to mitigate the potential risks and reduce the high generation costs associated with diffusion models, thereby advancing the field of trustworthy machine learning.",
            "MU methods are generally categorized into two types: exact MU and approximate MU. Exact MU entails creating a model that behaves as if sensitive data had never been part of the training set  ( Cao and Yang ,  2015 ;  Bourtoule et al. ,  2021 ) . This process requires the unlearned model to be identical in distribution to a model retrained without the sensitive data, both in terms of model weights and output behavior. In contrast, approximate MU does not seek an exact match between the unlearned model and a retrained model. Instead, it aims to approximate how closely the output distributions of the two models align after the unlearning process. A prominent strategy in approximate MU utilizes the principles of differential privacy  ( Dwork ,  2006 ) . For instance,  Guo et al.  ( 2019 )  introduced a certified removal technique that prevents adversaries from extracting information about removed training data, offering a theoretical guarantee of data privacy. However, these approaches typically necessitate retraining the model from scratch, which can be computationally intensive and require access to the original training dataset. Efficient and stable unlearning has become crucial in MU. Techniques like the influence functions  ( Warnecke et al. ,  2021 ;  Izzo et al. ,  2021 ) , selective forgetting  ( Golatkar et al. ,  2020 ) , weight-based pruning  ( Liu et al. ,  2024 ) , and gradient-based saliency  ( Fan et al. ,  2024 )  have been explored, though they often suffer from performance degradation or restrictive assumptions  ( Becker and Liebig ,  2022 ) . These methods are primarily applied to MU for image classification tasks and do not adequately address the rapid forgetting and unlearning required for data generation tasks.",
            "Before diving into the specific MU problem, we will first establish the essential concepts and notations in diffusion modeling: A diffusion model corrupts its data  x  p data  ( x  c ) similar-to x subscript p data conditional x c x\\sim p_{\\text{data}}(x\\mid c) italic_x  italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_x  italic_c )  during the forward diffusion process at time  t t t italic_t  as  z t = a t  x +  t   t subscript z t subscript a t x subscript  t subscript italic- t z_{t}=a_{t}x+\\sigma_{t}\\epsilon_{t} italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x + italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , where   t  N  ( 0 , 1 ) similar-to subscript italic- t N 0 1 \\epsilon_{t}\\sim\\mathcal{N}(0,1) italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  caligraphic_N ( 0 , 1 ) ,  c c c italic_c  represents the given condition such as a label or text, and  a t subscript a t a_{t} italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and   t subscript  t \\sigma_{t} italic_ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  are diffusion scheduling parameters. The goal of pretraining a diffusion model is to obtain an optimal score estimator  s   ( z t , c , t ) subscript s italic- subscript z t c t s_{\\phi}(z_{t},c,t) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  such that  s   ( z t , c , t ) =  z t ln  p data  ( z t | c ) subscript s italic- subscript z t c t subscript  subscript z t subscript p data conditional subscript z t c s_{\\phi}(z_{t},c,t)=\\nabla_{z_{t}}\\ln p_{\\text{data}}(z_{t}\\,|\\,c) italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) =  start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_ln italic_p start_POSTSUBSCRIPT data end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c ) . Let  x   ( z t , c , t ) subscript x italic- subscript z t c t x_{\\phi}(z_{t},c,t) italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t )  be the optimal conditional mean estimator such that for  x   ( z t , c , t ) = E  [ x | z t , c , t ] subscript x italic- subscript z t c t E delimited-[] conditional x subscript z t c t x_{\\phi}(z_{t},c,t)=\\mathbb{E}[x\\,|\\,z_{t},c,t] italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ) = blackboard_E [ italic_x | italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c , italic_t ] . Applying Tweedies formula  ( Robbins ,  1992 ;  Efron ,  2011 )  in the context of diffusion modeling  ( Luo ,  2022 ;  Chung et al. ,  2023 ;  Zhou et al. ,  2024b ) , the optimal score and conditional mean estimators,  s  subscript s italic- s_{\\phi} italic_s start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  and  x  subscript x italic- x_{\\phi} italic_x start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT , for the training data are related as follows:",
            "With this optimal score estimator, we can construct a corresponding reverse diffusion process, enabling us to approximately sample from the data distribution through numerical discretization along the time horizon  ( Anderson ,  1982 ;  Song et al. ,  2020 ) .",
            "This formulation corresponds to a bi-level optimization problem  ( Ye et al. ,  1997 ;  Hong et al. ,  2023 ;  Shen et al. ,  2023 ) , subject to an additional forgetting-based constraint. Solving this problem directly is challenging, so we initially relax the constraint specified by  L sfd subscript L sfd \\mathcal{L}_{\\text{sfd}} caligraphic_L start_POSTSUBSCRIPT sfd end_POSTSUBSCRIPT  in the above equation by integrating it into the distillation objective as an additional MU regularization term:",
            "To quantitatively assess the effectiveness of class forgetting, we primarily focus on the success rate of forgetting the target class, and the generative capability on classes to retain. Specifically, we measure the success rate of forgetting by unlearning accuracy (UA) employing an external classifier trained on the original training set, which is essentially the mis-classification rate of the classifier on the generated samples from the target class. We measure image generation quality using Frechet Inception Distance (FID)  ( Heusel et al. ,  2017 )  and sample diversity using Inception Score (IS)  ( Salimans et al. ,  2016 ) . Additionally, we report Precision and Recall  ( Kynkaanniemi et al. ,  2019 ) , and number of function evaluations (NFEs) for sampling. Following  Fan et al.  ( 2024 ) , we compute and report generation quality metrics using generated samples, with the full training set from the remaining classes serving as the reference. For concept forgetting tasks including celebrity forgetting and nudity forgetting, we also provide quantitative evaluations as well as qualitative comparison. Specifically, we evaluate celebrity forgetting using a off-the-shelf celebrity face detector, while we assess the MU performance of our nudity forgetting model on the I2P benchmark ( https://github.com/ml-research/i2p ). Please refer to  Section   B.2  for more details of the evaluation metrics.",
            "The study of MU can be traced back to classical machine learning models in response to data protection regulations such as the right to be forgotten  [ Cao and Yang ,  2015 ,  Hoofnagle et al. ,  2019 ,  Bourtoule et al. ,  2021 ,  Nguyen et al. ,  2022 ] . Due to its capability of assessing data influence on model performance, the landscape of MU has expanded to encompass diverse domains, such as image classification  [ Ginart et al. ,  2019 ,  Golatkar et al. ,  2020 ,  Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] , text-to-image generation  [ Gandikota et al. ,  2023 ,  Zhang et al. ,  2023a ,  Kumari et al. ,  2023 ,  Fan et al. ,  2024 ] , federated learning  [ Halimi et al. ,  2022 ,  Che et al. ,  2023 ] , and graph neural networks  [ Chen et al. ,  2022 ,  Chien et al. ,  2022 ,  Wu et al. ,  2023 ] . In the literature, exact unlearning, which involves retraining the model from scratch after removing specific training data points, is often considered the gold standard. However, this approach comes with significant computational demands and requires access to the entire training set  [ Thudi et al. ,  2022 ] . To address these challenges, many research efforts have shifted towards the development of scalable and effective approximate unlearning methods  [ Liu et al. ,  2024 ,  Chen et al. ,  2023a ] . In addition, probabilistic methods with certain provable removal guarantees have been explored, often leveraging the concept of differential privacy  [ Neel et al. ,  2021 ,  Sekhari et al. ,  2021 ] . Focusing on MU in diffusion-based image generation, this paper introduces a general data-free approach for rapid forgetting and one-step sampling in diffusion models, eliminating the need to access any real data.",
            "Generative modeling is a pivotal area in statistics and machine learning. Prior to the development of diffusion models and their associated denoising score matching (SM) techniques, effectively matching distributions in high-dimensional spacesparticularly those with intractable probability density functionsposed a significant challenge. Traditionally, deep generative models aimed to minimize discrepancies between data and model probability distributions using various distribution-matching related loss functions. These included Kullback-Leibler (KL) divergence  [ Kingma and Welling ,  2013 ,  Yin and Zhou ,  2018 ] , Jensen-Shannon (JS) divergence  [ Goodfellow et al. ,  2014 ] , and transport cost  [ Tanwisuth et al. ,  2021 ,  Zheng and Zhou ,  2021 ,  Zhang et al. ,  2021 ,  Tanwisuth et al. ,  2023 ] . While VAEs and GANs developed under this framework have significantly advanced the field of generative modeling, they have exhibited limited capabilities in faithfully regenerating the original data. More recent methods have utilized data-based Fisher divergence  [ Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  to compare noise-corrupted data with noise-corrupted model distributions. While directly minimizing Fisher divergence,  i . e . formulae-sequence i e i.e. italic_i . italic_e . , the explicit SM loss, is intractable, diffusion models have effectively transformed the problem into minimizing a data-based denoising SM loss  [ Vincent ,  2011 ,  Sohl-Dickstein et al. ,  2015 ] . This transformation has allowed diffusion models to demonstrate exceptional capabilities in generating high-dimensional data that closely resemble the original distribution. However, the iterative denoising-based sampling inherent in these models is not only slow but also complicates efforts to further optimize the data generation process for downstream tasks. This issue becomes particularly challenging for tasks such as MU, which require the model to selectively forget specific concepts we are targeting in this paper.",
            "Classic score-matching-based diffusion models  [ Sohl-Dickstein et al. ,  2015 ,  Song and Ermon ,  2019 ,  Ho et al. ,  2020 ,  Song et al. ,  2020 ]  have become increasingly influential in developing generative models with high extensibility and sample quality  [ Dhariwal and Nichol ,  2021 ,  Karras et al. ,  2022 ,  Ramesh et al. ,  2022 ] . However, standard Gaussian diffusion models, along with other non-Gaussian variants  [ Hoogeboom et al. ,  2021 ,  Austin et al. ,  2021 ,  Chen and Zhou ,  2023 ,  Zhou et al. ,  2023 ] , suffer from relatively slow sampling compared to traditional one-step generative models, such as GANs and VAEs. Inspired by the success of applying diffusion processes to the training of generative models,  Xiao et al.   [ 2021 ]  and  Wang et al.   [ 2022 ]  were among the first to promote faster generation by leveraging both adversarial training techniques and diffusion-based data augmentation. However, these approaches inevitably reintroduce potential issues like training instability and mode collapse. Closely related to the original score matching,  Salimans and Ho   [ 2022 ]  proposed progressively halving the steps needed in the reverse generation process. Similarly,  Song et al.   [ 2023 ]  presented the consistency model as a method for distilling the reverse ODE sampling process. Along this direction, much effort has been made by others  [ Xu et al. ,  2023 ,  Yin et al. ,  2024 ,  Luo et al. ,  2023 ,  Zhou et al. ,  2024b ]  to improve both sample quality and diversity."
        ]
    }
}