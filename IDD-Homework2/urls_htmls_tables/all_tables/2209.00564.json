{
    "PAPER'S NUMBER OF TABLES": 2,
    "S3.T1": {
        "caption": "Table 1: The simulation results of a binary classification in terms of accuracy.",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Methods</th>\n<td id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">SGD</td>\n<td id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Adagrad</td>\n<td id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Adam</td>\n<td id=\"S3.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">FQNGD</td>\n</tr>\n<tr id=\"S3.T1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Acc.</th>\n<td id=\"S3.T1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">98.48</td>\n<td id=\"S3.T1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">98.81</td>\n<td id=\"S3.T1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">98.87</td>\n<td id=\"S3.T1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">99.32</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To demonstrate the FQNGD algorithm for QFL, we perform the binary and ternary classification tasks on the standard MNIST dataset ",
                "[",
                "31",
                "]",
                ", specifically digits ",
                "{",
                "2",
                ",",
                "5",
                "}",
                "2",
                "5",
                "\\{2,5\\}",
                " for the binary task and ",
                "{",
                "1",
                ",",
                "3",
                ",",
                "7",
                "}",
                "1",
                "3",
                "7",
                "\\{1,3,7\\}",
                " for the ternary one. There are a total of ",
                "11379",
                "11379",
                "11379",
                " training data and ",
                "1924",
                "1924",
                "1924",
                " test data for the binary classification, and ",
                "19138",
                "19138",
                "19138",
                " training data and ",
                "3173",
                "3173",
                "3173",
                " test data are assigned for the ternary classification. As for the setup of QFL in our experiments, the QFL system consists of ",
                "6",
                "6",
                "6",
                " identically local VQC participants, each of which owns the same amount of training data. The test data are stored in the global part and are used to evaluate the classification performance.",
                "The experiments compare our proposed FQNGD algorithm with the other three optimizers: the naive SGD optimizer, the Adagrad optimizer ",
                "[",
                "32",
                "]",
                " and the Adam optimizer ",
                "[",
                "33",
                "]",
                ". The Adagrad optimizer is a gradient descent optimizer with a past-gradient-dependent learning rate in each dimension. The Adam optimizer refers to the gradient descent method with an adaptive learning rate as well as adaptive first and second moments.",
                "As shown in Figure ",
                "5",
                ", our simulation results suggest that our proposed FQNGD method is capable of achieving the fastest convergence rate compared with other optimization approaches. It means that the FQNGD method can lower the communication cost and also maintain the baseline performance of both binary and ternary classification on the MNIST dataset. Moreover, we evaluate the QFL performance in terms of classification accuracy. The FQNGD method outperforms the other counterparts with the highest accuracy values. In particular, the FQNGD is designed for the VQC model and can attain better empirical results than the Adam and Adagrad methods with adaptive learning rates over epochs."
            ]
        ]
    },
    "S3.T2": {
        "caption": "Table 2: The simulation results of a ternary classification in terms of accuracy.",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Methods</th>\n<td id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">SGD</td>\n<td id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Adagrad</td>\n<td id=\"S3.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Adam</td>\n<td id=\"S3.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">FQNGD</td>\n</tr>\n<tr id=\"S3.T2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">Acc.</th>\n<td id=\"S3.T2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">97.86</td>\n<td id=\"S3.T2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">98.63</td>\n<td id=\"S3.T2.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">98.71</td>\n<td id=\"S3.T2.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:1.5pt;padding-bottom:1.5pt;\">99.12</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To demonstrate the FQNGD algorithm for QFL, we perform the binary and ternary classification tasks on the standard MNIST dataset ",
                "[",
                "31",
                "]",
                ", specifically digits ",
                "{",
                "2",
                ",",
                "5",
                "}",
                "2",
                "5",
                "\\{2,5\\}",
                " for the binary task and ",
                "{",
                "1",
                ",",
                "3",
                ",",
                "7",
                "}",
                "1",
                "3",
                "7",
                "\\{1,3,7\\}",
                " for the ternary one. There are a total of ",
                "11379",
                "11379",
                "11379",
                " training data and ",
                "1924",
                "1924",
                "1924",
                " test data for the binary classification, and ",
                "19138",
                "19138",
                "19138",
                " training data and ",
                "3173",
                "3173",
                "3173",
                " test data are assigned for the ternary classification. As for the setup of QFL in our experiments, the QFL system consists of ",
                "6",
                "6",
                "6",
                " identically local VQC participants, each of which owns the same amount of training data. The test data are stored in the global part and are used to evaluate the classification performance.",
                "The experiments compare our proposed FQNGD algorithm with the other three optimizers: the naive SGD optimizer, the Adagrad optimizer ",
                "[",
                "32",
                "]",
                " and the Adam optimizer ",
                "[",
                "33",
                "]",
                ". The Adagrad optimizer is a gradient descent optimizer with a past-gradient-dependent learning rate in each dimension. The Adam optimizer refers to the gradient descent method with an adaptive learning rate as well as adaptive first and second moments.",
                "As shown in Figure ",
                "5",
                ", our simulation results suggest that our proposed FQNGD method is capable of achieving the fastest convergence rate compared with other optimization approaches. It means that the FQNGD method can lower the communication cost and also maintain the baseline performance of both binary and ternary classification on the MNIST dataset. Moreover, we evaluate the QFL performance in terms of classification accuracy. The FQNGD method outperforms the other counterparts with the highest accuracy values. In particular, the FQNGD is designed for the VQC model and can attain better empirical results than the Adam and Adagrad methods with adaptive learning rates over epochs."
            ]
        ]
    }
}