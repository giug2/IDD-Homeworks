{
    "PAPER'S NUMBER OF TABLES": 3,
    "S3.T1": {
        "caption": "Table 1: Experimental results on CIFAR-100 with different pre-training strategies. For image classification, we report standard Top-1 accuracy (%). ",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\" style=\"background-color:#FFFFFF;\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Downstream</span></th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:2.5pt;padding-right:2.5pt;\" colspan=\"4\"><span id=\"S3.T1.1.1.1.2.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Linear</span></th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:2.5pt;padding-right:2.5pt;\" colspan=\"4\"><span id=\"S3.T1.1.1.1.3.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Finetune</span></th>\n</tr>\n<tr id=\"S3.T1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Representation From</th>\n<th id=\"S3.T1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Layer 1</th>\n<th id=\"S3.T1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Layer 3</th>\n<th id=\"S3.T1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Layer 6</th>\n<th id=\"S3.T1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Layer 12</th>\n<th id=\"S3.T1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Layer 1</th>\n<th id=\"S3.T1.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Layer 3</th>\n<th id=\"S3.T1.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Layer 6</th>\n<th id=\"S3.T1.1.2.2.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Layer 12</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.3.1\" class=\"ltx_tr\" style=\"background-color:#FFFFFF;\">\n<td id=\"S3.T1.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span id=\"S3.T1.1.3.1.1.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Pre-training Method</span></td>\n<td id=\"S3.T1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\" colspan=\"8\"><span id=\"S3.T1.1.3.1.2.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Federated Layer-wise Learning</span></td>\n</tr>\n<tr id=\"S3.T1.1.4.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Accuracy</td>\n<td id=\"S3.T1.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">25.3</td>\n<td id=\"S3.T1.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">28.3</td>\n<td id=\"S3.T1.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">29.2</td>\n<td id=\"S3.T1.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">29.8</td>\n<td id=\"S3.T1.1.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">30.1</td>\n<td id=\"S3.T1.1.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">35.6</td>\n<td id=\"S3.T1.1.4.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">37.2</td>\n<td id=\"S3.T1.1.4.2.9\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">37.8</td>\n</tr>\n<tr id=\"S3.T1.1.5.3\" class=\"ltx_tr\" style=\"background-color:#FFFFFF;\">\n<td id=\"S3.T1.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span id=\"S3.T1.1.5.3.1.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Pre-training Method</span></td>\n<td id=\"S3.T1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\" colspan=\"8\"><span id=\"S3.T1.1.5.3.2.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Federated End-to-end Learning</span></td>\n</tr>\n<tr id=\"S3.T1.1.6.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Accuracy</td>\n<td id=\"S3.T1.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">18.0</td>\n<td id=\"S3.T1.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">23.9</td>\n<td id=\"S3.T1.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">27.8</td>\n<td id=\"S3.T1.1.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">30.3</td>\n<td id=\"S3.T1.1.6.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">25.4</td>\n<td id=\"S3.T1.1.6.4.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">32.2</td>\n<td id=\"S3.T1.1.6.4.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">35.7</td>\n<td id=\"S3.T1.1.6.4.9\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">38.6</td>\n</tr>\n<tr id=\"S3.T1.1.7.5\" class=\"ltx_tr\" style=\"background-color:#FFFFFF;\">\n<td id=\"S3.T1.1.7.5.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span id=\"S3.T1.1.7.5.1.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Pre-training Method</span></td>\n<td id=\"S3.T1.1.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\" colspan=\"8\"><span id=\"S3.T1.1.7.5.2.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Training from scratch (Without Pre-training)</span></td>\n</tr>\n<tr id=\"S3.T1.1.8.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.8.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Accuracy</td>\n<td id=\"S3.T1.1.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">9.2</td>\n<td id=\"S3.T1.1.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">10.0</td>\n<td id=\"S3.T1.1.8.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">10.5</td>\n<td id=\"S3.T1.1.8.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">11.3</td>\n<td id=\"S3.T1.1.8.6.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">18.7</td>\n<td id=\"S3.T1.1.8.6.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">24.2</td>\n<td id=\"S3.T1.1.8.6.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">27.6</td>\n<td id=\"S3.T1.1.8.6.9\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">29.2</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Here we compare our approach with federated end-to-end learning on standard benchmarks. Results with different setups on CIFAR-100 are shown in Table 1. We can make the following observations: (i) Both models pre-trained by Federated Layer-wise Learning and federated end-to-end learning can significantly outperform the model without pre-training, indicating the effectiveness of self-supervised representation learning in federated settings.\n(ii) While the Federated Layer-wise Learning approach is an approximation of federated end-to-end learning, it can achieve performance on par with the end-to-end method in downstream evaluation tasks. In particular, the performance gap is less than 1% when using the representation from the last layer (layer 12) of the network. (iii) we found that intermediate representations from the Federated Layer-wise Learning model performed better than those from the federated end-to-end learning model in certain downstream tasks. For example, in a linear downstream task using the representation from layer 3, the Federated Layer-wise Learning model achieved 28.3% accuracy, while the federated end-to-end learning model achieved 23.9%. This trend was also observed in other downstream tasks using different intermediate representations. This superior performance of intermediate representations is due to the contrastive loss being applied to all layers during the layer-wise pre-training process. These results suggest that models trained using the proposed method can easily compose sub-models of varying complexities."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Accuracy of depth dropout with Federated Layer-wise Learning, under finetuning downstream evaluation. The budget specifies the max number of layers involved in training. ",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\" style=\"background-color:#FFFFFF;\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Model Size</span></th>\n<th id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.1.1.2.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">6 layers</span></th>\n<th id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<table id=\"S3.T2.1.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\" style=\"background-color:#FFFFFF;\">\n<tr id=\"S3.T2.1.1.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">6 layers</td>\n</tr>\n<tr id=\"S3.T2.1.1.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">(Budget: 3 layers)</td>\n</tr>\n</table>\n</th>\n<th id=\"S3.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.1.1.4.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">3 layers</span></th>\n<th id=\"S3.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.1.1.5.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">12 layers</span></th>\n<th id=\"S3.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<table id=\"S3.T2.1.1.1.6.1\" class=\"ltx_tabular ltx_align_middle\" style=\"background-color:#FFFFFF;\">\n<tr id=\"S3.T2.1.1.1.6.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.1.6.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">12 layers</td>\n</tr>\n<tr id=\"S3.T2.1.1.1.6.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.1.6.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">(Budget: 6 layers)</td>\n</tr>\n</table>\n</th>\n<th id=\"S3.T2.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.1.1.7.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">6 layers</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.2.1\" class=\"ltx_tr\" style=\"background-color:#FFFFFF;\">\n<td id=\"S3.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.2.1.1.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Accuracy</span></td>\n<td id=\"S3.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.2.1.2.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">37.2</span></td>\n<td id=\"S3.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.2.1.3.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">37.0</span></td>\n<td id=\"S3.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.2.1.4.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">32.8</span></td>\n<td id=\"S3.T2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.2.1.5.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">37.8</span></td>\n<td id=\"S3.T2.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.2.1.6.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">37.6</span></td>\n<td id=\"S3.T2.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T2.1.2.1.7.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">37.2</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Here we compare our approach with federated end-to-end learning on standard benchmarks. Results with different setups on CIFAR-100 are shown in Table ",
                "1",
                ". We can make the following observations: (i) Both models pre-trained by Federated Layer-wise Learning and federated end-to-end learning can significantly outperform the model without pre-training, indicating the effectiveness of self-supervised representation learning in federated settings.\n(ii) While the Federated Layer-wise Learning approach is an approximation of federated end-to-end learning, it can achieve performance on par with the end-to-end method in downstream evaluation tasks. In particular, the performance gap is less than 1% when using the representation from the last layer (layer 12) of the network. (iii) we found that intermediate representations from the Federated Layer-wise Learning model performed better than those from the federated end-to-end learning model in certain downstream tasks. For example, in a linear downstream task using the representation from layer 3, the Federated Layer-wise Learning model achieved 28.3% accuracy, while the federated end-to-end learning model achieved 23.9%. This trend was also observed in other downstream tasks using different intermediate representations. This superior performance of intermediate representations is due to the contrastive loss being applied to all layers during the layer-wise pre-training process. These results suggest that models trained using the proposed method can easily compose sub-models of varying complexities.",
                "We conducted additional experiments to further investigate the effect of model size (number of layers) and number of training rounds per layer on the performance of Federated Layer-wise and end-to-end learning. The results of these experiments are shown in Figure ",
                "2",
                "(a). Increasing the number of layers generally led to improved performance for both learning approaches. We also found that the difference in performance between the two approaches was minimal when the number of training rounds per layer was small (4k) but became more pronounced when the number of training rounds per layer was increased (12k). Based on these results, it appears that layer-wise learning may require slightly more training rounds per layer to reach the same performance as end-to-end learning. This may be due to the fact that layer-wise learning is an approximation of end-to-end learning. However, the performance gap between the two approaches is generally less than 1%.",
                "The Effectiveness of Depth Dropout.",
                " We evaluate Depth Dropout with Federated Layer-wise Learning. We conducted two sets of experiments: applying Depth Dropout to a 6-layer model and a 12-layer model, with a fixed dropout rate of 50% (meaning half of the fixed layers were dropped). The results, shown in ",
                "Tables",
                " ",
                "2",
                " and ",
                "3",
                ", demonstrate that Depth Dropout does not significantly impact model performance. For example, the 6-layer model with Depth Dropout achieved 37.0% accuracy after finetuning, while the 6-layer model trained with only Layer-wise Learning achieved 37.2% accuracy. We observed similar results for the 12-layer model with Depth Dropout, which achieved 37.6% accuracy after finetuning, compared to 37.8% for the model trained with normal Layer-wise Learning. Additionally, Depth Dropout significantly reduced resource usage. It is worth noting that the resource usage of the 12-layer model with a budget of 6 layers was equivalent to the resource usage of a 6-layer model without Depth Dropout. As shown in Fig. ",
                "2",
                ", depth dropout reduced the upper bounds of resource usage in all three categories, especially communication cost. The original upper bound for Layer-wise training was 54%, but it was reduced to 29% when the dropout rate was set to 50%."
            ]
        ]
    },
    "S3.T3": {
        "caption": "Table 3: Accuracy of depth dropout with Federated Layer-wise Learning, under linear downstream evaluation. The budget specifies the max number of layers involved in training. ",
        "table": "<table id=\"S3.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T3.1.1.1\" class=\"ltx_tr\" style=\"background-color:#FFFFFF;\">\n<th id=\"S3.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.1.1.1.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Model Size</span></th>\n<th id=\"S3.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.1.1.2.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">6 layers</span></th>\n<th id=\"S3.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<table id=\"S3.T3.1.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\" style=\"background-color:#FFFFFF;\">\n<tr id=\"S3.T3.1.1.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">6 layers</td>\n</tr>\n<tr id=\"S3.T3.1.1.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">(Budget: 3 layers)</td>\n</tr>\n</table>\n</th>\n<th id=\"S3.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.1.1.4.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">3 layers</span></th>\n<th id=\"S3.T3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.1.1.5.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">12 layers</span></th>\n<th id=\"S3.T3.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<table id=\"S3.T3.1.1.1.6.1\" class=\"ltx_tabular ltx_align_middle\" style=\"background-color:#FFFFFF;\">\n<tr id=\"S3.T3.1.1.1.6.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.1.6.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">12 layers</td>\n</tr>\n<tr id=\"S3.T3.1.1.1.6.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.1.6.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">(Budget: 6 layers)</td>\n</tr>\n</table>\n</th>\n<th id=\"S3.T3.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.1.1.7.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">6 layers</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.1.2.1\" class=\"ltx_tr\" style=\"background-color:#FFFFFF;\">\n<td id=\"S3.T3.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.2.1.1.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">Accuracy</span></td>\n<td id=\"S3.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.2.1.2.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">29.2</span></td>\n<td id=\"S3.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.2.1.3.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">29.1</span></td>\n<td id=\"S3.T3.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.2.1.4.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">28.3</span></td>\n<td id=\"S3.T3.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.2.1.5.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">29.8</span></td>\n<td id=\"S3.T3.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.2.1.6.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">29.7</span></td>\n<td id=\"S3.T3.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S3.T3.1.2.1.7.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">29.2</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Here we compare our approach with federated end-to-end learning on standard benchmarks. Results with different setups on CIFAR-100 are shown in Table ",
                "1",
                ". We can make the following observations: (i) Both models pre-trained by Federated Layer-wise Learning and federated end-to-end learning can significantly outperform the model without pre-training, indicating the effectiveness of self-supervised representation learning in federated settings.\n(ii) While the Federated Layer-wise Learning approach is an approximation of federated end-to-end learning, it can achieve performance on par with the end-to-end method in downstream evaluation tasks. In particular, the performance gap is less than 1% when using the representation from the last layer (layer 12) of the network. (iii) we found that intermediate representations from the Federated Layer-wise Learning model performed better than those from the federated end-to-end learning model in certain downstream tasks. For example, in a linear downstream task using the representation from layer 3, the Federated Layer-wise Learning model achieved 28.3% accuracy, while the federated end-to-end learning model achieved 23.9%. This trend was also observed in other downstream tasks using different intermediate representations. This superior performance of intermediate representations is due to the contrastive loss being applied to all layers during the layer-wise pre-training process. These results suggest that models trained using the proposed method can easily compose sub-models of varying complexities.",
                "We conducted additional experiments to further investigate the effect of model size (number of layers) and number of training rounds per layer on the performance of Federated Layer-wise and end-to-end learning. The results of these experiments are shown in Figure ",
                "2",
                "(a). Increasing the number of layers generally led to improved performance for both learning approaches. We also found that the difference in performance between the two approaches was minimal when the number of training rounds per layer was small (4k) but became more pronounced when the number of training rounds per layer was increased (12k). Based on these results, it appears that layer-wise learning may require slightly more training rounds per layer to reach the same performance as end-to-end learning. This may be due to the fact that layer-wise learning is an approximation of end-to-end learning. However, the performance gap between the two approaches is generally less than 1%.",
                "The Effectiveness of Depth Dropout.",
                " We evaluate Depth Dropout with Federated Layer-wise Learning. We conducted two sets of experiments: applying Depth Dropout to a 6-layer model and a 12-layer model, with a fixed dropout rate of 50% (meaning half of the fixed layers were dropped). The results, shown in ",
                "Tables",
                " ",
                "2",
                " and ",
                "3",
                ", demonstrate that Depth Dropout does not significantly impact model performance. For example, the 6-layer model with Depth Dropout achieved 37.0% accuracy after finetuning, while the 6-layer model trained with only Layer-wise Learning achieved 37.2% accuracy. We observed similar results for the 12-layer model with Depth Dropout, which achieved 37.6% accuracy after finetuning, compared to 37.8% for the model trained with normal Layer-wise Learning. Additionally, Depth Dropout significantly reduced resource usage. It is worth noting that the resource usage of the 12-layer model with a budget of 6 layers was equivalent to the resource usage of a 6-layer model without Depth Dropout. As shown in Fig. ",
                "2",
                ", depth dropout reduced the upper bounds of resource usage in all three categories, especially communication cost. The original upper bound for Layer-wise training was 54%, but it was reduced to 29% when the dropout rate was set to 50%."
            ]
        ]
    }
}