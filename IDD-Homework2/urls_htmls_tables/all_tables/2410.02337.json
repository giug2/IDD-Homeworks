{
    "S2.T1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S2.T1.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.1.1\">Category</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.2.1\">Attribute</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_tt\" id=\"S2.T1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.1.1.3.1\">Description</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.2.2\">\n<td class=\"ltx_td ltx_border_t\" id=\"S2.T1.1.2.2.1\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.2.2.2\">Patient number</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S2.T1.1.2.2.3\">59</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.3.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.3.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.3.3.1.1\">Study Information</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.3.3.2\">Weight (kg)</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T1.1.3.3.3\">70.6 &#177; 8.4</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.4.4\">\n<td class=\"ltx_td\" id=\"S2.T1.1.4.4.1\"/>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.4.4.2\">Patient Position</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T1.1.4.4.3\">Head First Prone (HFP)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.5.5\">\n<td class=\"ltx_td\" id=\"S2.T1.1.5.5.1\"/>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.5.5.2\">Number of Images per Patient</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T1.1.5.5.3\">6 (1 pre-contrast, 5 post-contrast)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.6.6\">\n<td class=\"ltx_td ltx_border_t\" id=\"S2.T1.1.6.6.1\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.6.6.2\">Scanner Model</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S2.T1.1.6.6.3\">Philips Intera MRI Scanner</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.7.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.7.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.7.7.1.1\">Scanner Properties</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.7.7.2\">Magnetic Field Strength (T)</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T1.1.7.7.3\">1.5</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.8.8\">\n<td class=\"ltx_td\" id=\"S2.T1.1.8.8.1\"/>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.8.8.2\">Coil Technology</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T1.1.8.8.3\">SENSE Technology</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.9.9\">\n<td class=\"ltx_td ltx_border_t\" id=\"S2.T1.1.9.9.1\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.9.9.2\">Image Dimensions</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S2.T1.1.9.9.3\">(352,352,150), (352,352,140), (352,352,120)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.10.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.10.10.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.10.10.1.1\">Image characteristics</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.10.10.2\">Pixel Spacing (mm)</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T1.1.10.10.3\">0.9659 x 0.9659</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.11.11\">\n<td class=\"ltx_td\" id=\"S2.T1.1.11.11.1\"/>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.11.11.2\">Slice Thickness (mm)</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T1.1.11.11.3\">2</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.12.12\">\n<td class=\"ltx_td\" id=\"S2.T1.1.12.12.1\"/>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.12.12.2\">Field of View (FOV) (mm)</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T1.1.12.12.3\">400</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.13.13\">\n<td class=\"ltx_td ltx_border_t\" id=\"S2.T1.1.13.13.1\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.1.13.13.2\">MRI Sequence</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S2.T1.1.13.13.3\">T1 weighted fast spoiled gradient echo (FSPGR)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.14.14\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.14.14.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.1.14.14.1.1\">Imaging Features</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.14.14.2\">Repetition Time (TR)</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T1.1.14.14.3\">6.91</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.15.15\">\n<td class=\"ltx_td\" id=\"S2.T1.1.15.15.1\"/>\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.1.15.15.2\">Echo Time (TE)</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T1.1.15.15.3\">3.39</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.1.16.16\">\n<td class=\"ltx_td ltx_border_bb\" id=\"S2.T1.1.16.16.1\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S2.T1.1.16.16.2\">Flip Angle</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\" id=\"S2.T1.1.16.16.3\">12</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 1:  Detailed Specifications and Imaging Features of MRI Scans",
        "footnotes": [],
        "references": [
            "The dataset utilized in this study consists of DCE-MRI scans obtained from 59 patients at Stavanger University Hospital in 2008. The DCE sequence comprises one pre- and five post-contrast image series with a temporal resolution of 63 seconds. Table 1 provides a detailed description of the dataset and screening parameters."
        ]
    },
    "S2.T2.1": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S2.T2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S2.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S2.T2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.1.1.1.1.1\">Architecture name</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S2.T2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.1.1.1.2.1\">Layers</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S2.T2.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.1.1.1.3.1\">Learning Parameters</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S2.T2.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.1.1.1.4.1\">Special Features</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S2.T2.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S2.T2.1.2.1.1\">UNet</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S2.T2.1.2.1.2\">141</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S2.T2.1.2.1.3\">31,112,641</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"S2.T2.1.2.1.4\">Simple skip connection</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S2.T2.1.3.2.1\">UNet++</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T2.1.3.2.2\">240</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T2.1.3.2.3\">9,119,044</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T2.1.3.2.4\">Dense skip connection</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S2.T2.1.4.3.1\">DenseNet</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T2.1.4.3.2\">1216</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T2.1.4.3.3\">70,536,843</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T2.1.4.3.4\">Reusing Feature-maps in subsequent blocks</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S2.T2.1.5.4.1\">FCNResNet50</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T2.1.5.4.2\">157</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T2.1.5.4.3\">32,943,617</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T2.1.5.4.4\">Strong feature extractor alongside FCN header</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S2.T2.1.6.5.1\">FCNResNet101</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T2.1.6.5.2\">293</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T2.1.6.5.3\">51,935,745</td>\n<td class=\"ltx_td ltx_nopad_r\" id=\"S2.T2.1.6.5.4\"/>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S2.T2.1.7.6.1\">DeepLabv3ResNet50</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T2.1.7.6.2\">184</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S2.T2.1.7.6.3\">39,630,593</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S2.T2.1.7.6.4\">Atrous Spatial Pyramid Pooling (ASPP)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\" id=\"S2.T2.1.8.7.1\">DeepLabv3ResNet101</th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S2.T2.1.8.7.2\">320</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S2.T2.1.8.7.3\">58,622,721</td>\n<td class=\"ltx_td ltx_nopad_r ltx_border_b\" id=\"S2.T2.1.8.7.4\"/>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 2:  Model specification and features",
        "footnotes": [],
        "references": [
            "UNet, introduced by Ronneberger et al. in 2015 [19], is one of the most popular segmentation methods. It consists of contraction and expansion pathways connected by skip connections. These skip connections help the model retain important features that might otherwise be forgotten during the training process.\nUNet++ is an improved version of UNet, designed to achieve superior results. In UNet++, the skip connections were redesigned to reduce the loss of important features between the contraction and expansion pathways, enhancing the overall performance of the model [20].\nDenseNet, another architecture utilized in this study, has demonstrated promise in propagating features throughout the model. In DenseNet, every layer is connected to other layers, thereby enhancing feature propagation across the entire network and improving the model’s ability to learn complex patterns [21]. Given that DenseNet is primarily used for classification tasks, we employed its feature extraction part along with a decoder, excluding skip connections, to examine the impact of their absence in a deeper model.\nNext network is FCNResNet comprising a ResNet as the feature extractor and an FCN header [22] for upsampling or decoding. ResNet’s structure, which includes residual blocks, has proven effective [23], while the FCN header connects to each feature level, serving as a skip connection.\nLast architecture, DeepLabv3 is renowned for its Atrous Spatial Pyramid Pooling (ASPP) block [24]. Following the ResNet feature extractor, ASPP is applied and subsequently added to the decoder part of the architecture for upsampling.\nTable 2 provides practical information about the networks, including learning parameters, the number of layers, and their distinctive features. This comparative analysis offers valuable insights into the strengths and applications of each model in medical image segmentation tasks."
        ]
    },
    "S3.T3.16": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S3.T3.16\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T3.16.15.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T3.16.15.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.16.15.1.1.1\">Models</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.16.15.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.16.15.1.2.1\">Dice Training Loss</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.16.15.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.16.15.1.3.1\">Dice Validation Loss</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T3.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T3.4.2.3\">UNet</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.3.1.1\">0.0146 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.3.1.1.m1.1\"><semantics id=\"S3.T3.3.1.1.m1.1a\"><mo id=\"S3.T3.3.1.1.m1.1.1\" xref=\"S3.T3.3.1.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.3.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.3.1.1.m1.1.1.cmml\" xref=\"S3.T3.3.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.3.1.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.3.1.1.m1.1d\">&#177;</annotation></semantics></math> 0.0024</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.4.2.2\">0.0448 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.4.2.2.m1.1\"><semantics id=\"S3.T3.4.2.2.m1.1a\"><mo id=\"S3.T3.4.2.2.m1.1.1\" xref=\"S3.T3.4.2.2.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.4.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.4.2.2.m1.1.1.cmml\" xref=\"S3.T3.4.2.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.4.2.2.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.4.2.2.m1.1d\">&#177;</annotation></semantics></math> 0.0077</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.6.4.3\">UNet++</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.5.3.1\">0.0112 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.5.3.1.m1.1\"><semantics id=\"S3.T3.5.3.1.m1.1a\"><mo id=\"S3.T3.5.3.1.m1.1.1\" xref=\"S3.T3.5.3.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.5.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.5.3.1.m1.1.1.cmml\" xref=\"S3.T3.5.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.5.3.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.5.3.1.m1.1d\">&#177;</annotation></semantics></math> 0.0022</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.6.4.2\">0.0466 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.6.4.2.m1.1\"><semantics id=\"S3.T3.6.4.2.m1.1a\"><mo id=\"S3.T3.6.4.2.m1.1.1\" xref=\"S3.T3.6.4.2.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.6.4.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.6.4.2.m1.1.1.cmml\" xref=\"S3.T3.6.4.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.6.4.2.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.6.4.2.m1.1d\">&#177;</annotation></semantics></math> 0.0167</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.8.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.8.6.3\">DenseNet</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.7.5.1\">0.0163 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.7.5.1.m1.1\"><semantics id=\"S3.T3.7.5.1.m1.1a\"><mo id=\"S3.T3.7.5.1.m1.1.1\" xref=\"S3.T3.7.5.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.7.5.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.7.5.1.m1.1.1.cmml\" xref=\"S3.T3.7.5.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.7.5.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.7.5.1.m1.1d\">&#177;</annotation></semantics></math> 0.0038</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.8.6.2\">0.0525 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.8.6.2.m1.1\"><semantics id=\"S3.T3.8.6.2.m1.1a\"><mo id=\"S3.T3.8.6.2.m1.1.1\" xref=\"S3.T3.8.6.2.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.8.6.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.8.6.2.m1.1.1.cmml\" xref=\"S3.T3.8.6.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.8.6.2.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.8.6.2.m1.1d\">&#177;</annotation></semantics></math> 0.0082</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.10.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.10.8.3\">FCNResNet50</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.9.7.1\">0.0126 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.9.7.1.m1.1\"><semantics id=\"S3.T3.9.7.1.m1.1a\"><mo id=\"S3.T3.9.7.1.m1.1.1\" xref=\"S3.T3.9.7.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.9.7.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.9.7.1.m1.1.1.cmml\" xref=\"S3.T3.9.7.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.9.7.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.9.7.1.m1.1d\">&#177;</annotation></semantics></math> 0.0028</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.10.8.2\">0.0474 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.10.8.2.m1.1\"><semantics id=\"S3.T3.10.8.2.m1.1a\"><mo id=\"S3.T3.10.8.2.m1.1.1\" xref=\"S3.T3.10.8.2.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.10.8.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.10.8.2.m1.1.1.cmml\" xref=\"S3.T3.10.8.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.10.8.2.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.10.8.2.m1.1d\">&#177;</annotation></semantics></math> 0.0100</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.12.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.12.10.3\">FCNResNet101</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.11.9.1\">0.0134 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.11.9.1.m1.1\"><semantics id=\"S3.T3.11.9.1.m1.1a\"><mo id=\"S3.T3.11.9.1.m1.1.1\" xref=\"S3.T3.11.9.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.11.9.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.11.9.1.m1.1.1.cmml\" xref=\"S3.T3.11.9.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.11.9.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.11.9.1.m1.1d\">&#177;</annotation></semantics></math> 0.0043</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.12.10.2\">0.0497 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.12.10.2.m1.1\"><semantics id=\"S3.T3.12.10.2.m1.1a\"><mo id=\"S3.T3.12.10.2.m1.1.1\" xref=\"S3.T3.12.10.2.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.12.10.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.12.10.2.m1.1.1.cmml\" xref=\"S3.T3.12.10.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.12.10.2.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.12.10.2.m1.1d\">&#177;</annotation></semantics></math> 0.0067</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.14.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T3.14.12.3\">DeepLabv3ResNet50</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.13.11.1\">0.0140 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.13.11.1.m1.1\"><semantics id=\"S3.T3.13.11.1.m1.1a\"><mo id=\"S3.T3.13.11.1.m1.1.1\" xref=\"S3.T3.13.11.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.13.11.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.13.11.1.m1.1.1.cmml\" xref=\"S3.T3.13.11.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.13.11.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.13.11.1.m1.1d\">&#177;</annotation></semantics></math> 0.0036</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.14.12.2\">0.0469 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.14.12.2.m1.1\"><semantics id=\"S3.T3.14.12.2.m1.1a\"><mo id=\"S3.T3.14.12.2.m1.1.1\" xref=\"S3.T3.14.12.2.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.14.12.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.14.12.2.m1.1.1.cmml\" xref=\"S3.T3.14.12.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.14.12.2.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.14.12.2.m1.1d\">&#177;</annotation></semantics></math> 0.0085</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.16.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T3.16.14.3\">DeepLabv3ResNet101</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T3.15.13.1\">0.0131 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.15.13.1.m1.1\"><semantics id=\"S3.T3.15.13.1.m1.1a\"><mo id=\"S3.T3.15.13.1.m1.1.1\" xref=\"S3.T3.15.13.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.15.13.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.15.13.1.m1.1.1.cmml\" xref=\"S3.T3.15.13.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.15.13.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.15.13.1.m1.1d\">&#177;</annotation></semantics></math> 0.0018</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T3.16.14.2\">0.0462 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.16.14.2.m1.1\"><semantics id=\"S3.T3.16.14.2.m1.1a\"><mo id=\"S3.T3.16.14.2.m1.1.1\" xref=\"S3.T3.16.14.2.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.16.14.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T3.16.14.2.m1.1.1.cmml\" xref=\"S3.T3.16.14.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.16.14.2.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T3.16.14.2.m1.1d\">&#177;</annotation></semantics></math> 0.0034</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 3:  Training and validation Dice loss for various DL models for  k 𝑘 k italic_k -fold cross-validation.",
        "footnotes": [],
        "references": [
            "Table 3 displays Dice training and validation losses across different deep learning architectures at their best epochs. UNet++ achieves the lowest training loss of 0.0112 ± 0.0022, while FCN with ResNet50 also performs well with a Dice training loss of 0.0126 ± 0.0028. On the other hand, UNet architecture stands out for its superior validation results, indicating strong generalization to unseen data essential for real-world applications with validation loss of 0.0448 ± 0.0077. Following closely, UNet++ demonstrates competitive validation performance with losses of 0.0466 ± 0.0167, emphasizing its balanced model performance and generalizability.\nIn contrast, DenseNet exhibits some of the poorest performance metrics, both in terms of training and validation loss, despite its deeper architecture. On the other hand, DeepLabv3 with a ResNet101 backbone achieves superior validation loss, second only to UNet.",
            "As outlined in Table 3, UNet exhibited a higher Dice loss function during training compared to UNet++. This may be attributed to UNet’s simpler architecture, which could enable more effective generalization during validation. Conversely, UNet++ introduces added complexity through its nested and dense skip connections, which may contribute to slower convergence, as shown in Table 4, or difficulties in optimizing all parameters effectively. This increased complexity may also render the model more susceptible to overfitting, as indicated by the higher variance in validation loss. The comparison between FCN with ResNet50 and ResNet101 underscores the impact of deeper networks. ResNet101, being a deeper model than ResNet50, generally allows for the learning of more complex features. However, the slightly higher training Dice loss in ResNet101 suggests that, while it has the potential to learn more detailed representations, the benefits may diminish, particularly if the dataset is insufficiently large to fully exploit the deeper network’s capacity. Similarly, DeepLabv3 with ResNet50 and ResNet101 shows relatively close performance. The architecture of DeepLabv3, which incorporates atrous convolutions and multi-scale context aggregation, is intended to enhance feature extraction for semantic segmentation. The minor variation in Dice loss suggests that, although ResNet101 offers more layers and potentially improved feature extraction, the advantages are not significantly superior to those of ResNet50. This may indicate that the additional layers in ResNet101 are not fully utilized, or that the model’s complexity poses challenges in training without overfitting. DenseNet demonstrates the highest Dice loss among the models. Although DenseNet’s architecture employs a dense connectivity pattern that encourages feature reuse and facilitates gradient flow during backpropagation, it lacks skip connections between the feature extractor and the expansion part of the network. Consequently, the poorest results can be attributed to this absence of skip connections."
        ]
    },
    "S3.T4.7": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S3.T4.7\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T4.7.8.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T4.7.8.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.7.8.1.1.1\">Models</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T4.7.8.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.7.8.1.2.1\">Training time per fold (min)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T4.7.8.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.7.8.1.3.1\">Inference time per slice (msec)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T4.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S3.T4.1.1.2\">UNet</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T4.1.1.1\">136 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T4.1.1.1.m1.1\"><semantics id=\"S3.T4.1.1.1.m1.1a\"><mo id=\"S3.T4.1.1.1.m1.1.1\" xref=\"S3.T4.1.1.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T4.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T4.1.1.1.m1.1.1.cmml\" xref=\"S3.T4.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T4.1.1.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T4.1.1.1.m1.1d\">&#177;</annotation></semantics></math> 22</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T4.1.1.3\">126</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T4.2.2.2\">UNet++</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.2.2.1\">199 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T4.2.2.1.m1.1\"><semantics id=\"S3.T4.2.2.1.m1.1a\"><mo id=\"S3.T4.2.2.1.m1.1.1\" xref=\"S3.T4.2.2.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T4.2.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T4.2.2.1.m1.1.1.cmml\" xref=\"S3.T4.2.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T4.2.2.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T4.2.2.1.m1.1d\">&#177;</annotation></semantics></math> 21</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.2.2.3\">152</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T4.3.3.2\">DenseNet</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.3.3.1\">185 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T4.3.3.1.m1.1\"><semantics id=\"S3.T4.3.3.1.m1.1a\"><mo id=\"S3.T4.3.3.1.m1.1.1\" xref=\"S3.T4.3.3.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T4.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T4.3.3.1.m1.1.1.cmml\" xref=\"S3.T4.3.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T4.3.3.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T4.3.3.1.m1.1d\">&#177;</annotation></semantics></math> 56</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.3.3.3\">696</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T4.4.4.2\">FCNResNet50</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.4.4.1\">87 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T4.4.4.1.m1.1\"><semantics id=\"S3.T4.4.4.1.m1.1a\"><mo id=\"S3.T4.4.4.1.m1.1.1\" xref=\"S3.T4.4.4.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T4.4.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T4.4.4.1.m1.1.1.cmml\" xref=\"S3.T4.4.4.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T4.4.4.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T4.4.4.1.m1.1d\">&#177;</annotation></semantics></math> 18</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.4.4.3\">140</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T4.5.5.2\">FCNResNet101</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.5.5.1\">149 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T4.5.5.1.m1.1\"><semantics id=\"S3.T4.5.5.1.m1.1a\"><mo id=\"S3.T4.5.5.1.m1.1.1\" xref=\"S3.T4.5.5.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T4.5.5.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T4.5.5.1.m1.1.1.cmml\" xref=\"S3.T4.5.5.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T4.5.5.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T4.5.5.1.m1.1d\">&#177;</annotation></semantics></math> 35</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.5.5.3\">266</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T4.6.6.2\">DeepLabv3ResNet50</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.6.6.1\">104 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T4.6.6.1.m1.1\"><semantics id=\"S3.T4.6.6.1.m1.1a\"><mo id=\"S3.T4.6.6.1.m1.1.1\" xref=\"S3.T4.6.6.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T4.6.6.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T4.6.6.1.m1.1.1.cmml\" xref=\"S3.T4.6.6.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T4.6.6.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T4.6.6.1.m1.1d\">&#177;</annotation></semantics></math> 22</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T4.6.6.3\">161</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T4.7.7.2\">DeepLabv3ResNet101</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T4.7.7.1\">178 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T4.7.7.1.m1.1\"><semantics id=\"S3.T4.7.7.1.m1.1a\"><mo id=\"S3.T4.7.7.1.m1.1.1\" xref=\"S3.T4.7.7.1.m1.1.1.cmml\">&#177;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T4.7.7.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S3.T4.7.7.1.m1.1.1.cmml\" xref=\"S3.T4.7.7.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T4.7.7.1.m1.1c\">\\pm</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.T4.7.7.1.m1.1d\">&#177;</annotation></semantics></math> 37</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T4.7.7.3\">294</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 4:  Training and inference times across different models.",
        "footnotes": [],
        "references": [
            "Training and inference time are critical considerations in efficiency and cost of the modelling. Table 4 Demonstrates training time results of 10-fold, with mean and standard deviation, alongside average inference time in the test set for diverse architectures. As presented in the table, FCN with ResNet50 shows the shortest training time at 87 ± 18 minutes, while DenseNet exhibits the longest at 185 ± 56 minutes. In terms of inference time per slice, UNet performs the best with 126 milliseconds, whereas DenseNet requires significantly more time at 696 milliseconds, highlighting varying computational efficiencies across these models. Despite possessing fewer trained parameters, UNet++ required more time, 199 ± 21, to train each fold. On the other hand, DeepLabv3ResNet50 demonstrated superior performance, followed by FCNResNet50, with training times of 104 ± 22 minutes per fold.",
            "As outlined in Table 3, UNet exhibited a higher Dice loss function during training compared to UNet++. This may be attributed to UNet’s simpler architecture, which could enable more effective generalization during validation. Conversely, UNet++ introduces added complexity through its nested and dense skip connections, which may contribute to slower convergence, as shown in Table 4, or difficulties in optimizing all parameters effectively. This increased complexity may also render the model more susceptible to overfitting, as indicated by the higher variance in validation loss. The comparison between FCN with ResNet50 and ResNet101 underscores the impact of deeper networks. ResNet101, being a deeper model than ResNet50, generally allows for the learning of more complex features. However, the slightly higher training Dice loss in ResNet101 suggests that, while it has the potential to learn more detailed representations, the benefits may diminish, particularly if the dataset is insufficiently large to fully exploit the deeper network’s capacity. Similarly, DeepLabv3 with ResNet50 and ResNet101 shows relatively close performance. The architecture of DeepLabv3, which incorporates atrous convolutions and multi-scale context aggregation, is intended to enhance feature extraction for semantic segmentation. The minor variation in Dice loss suggests that, although ResNet101 offers more layers and potentially improved feature extraction, the advantages are not significantly superior to those of ResNet50. This may indicate that the additional layers in ResNet101 are not fully utilized, or that the model’s complexity poses challenges in training without overfitting. DenseNet demonstrates the highest Dice loss among the models. Although DenseNet’s architecture employs a dense connectivity pattern that encourages feature reuse and facilitates gradient flow during backpropagation, it lacks skip connections between the feature extractor and the expansion part of the network. Consequently, the poorest results can be attributed to this absence of skip connections."
        ]
    }
}