{
    "id_table_1": {
        "caption": "GSM8K Data set Evaluation",
        "table": [
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.1.1.1.1\">\n         Agent\n        </th>\n        \n",
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T1.1.1.1.2\">\n         Solve Rate\n        </th>\n       \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T1.1.2.1.1\">\n         Single GPT3.5-turbo\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T1.1.2.1.2\">\n         50%\n        </td>\n       \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.3.2.1\">\n         Multi-Agent GPT3.5-turbo\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_left\" id=\"S3.T1.1.3.2.2\">\n         55%\n        </td>\n       \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T1.1.4.3.1\">\n         Multi-Agent GPT3.5-turbo\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.4.3.1.1\">\n          (Our approach)\n         </span>\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T1.1.4.3.2\">\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.4.3.2.1\">\n          65%\n         </span>\n        </td>\n       \n"
            ]
        ],
        "footnotes": [],
        "references": [
            "The outcomes from both experiments can be found in Table                     1                   and Table                     2                   . In the initial experiment (example can be found here                     3.1.1                   ) using the GSM8K data set, the single-agent GPT-3 achieves approximately 50% accuracy, and the multi-agent GPT-3 performs slightly better at 55%. However, our multi-agent approach significantly enhances accuracy, surpassing other large language models (LLMs) such as Google’s PALM 540B parameter model, which we haven’t directly tested but are referencing from their paper. This improvement is notable in terms of accuracy, and it’s noteworthy that we haven’t retrained the model to achieve this enhancement. Assigning personas to the agents enables the LLM model to concentrate on specific aspects of the problem, and the use of chain-of-thought prompts equips it with efficient means to solve sub-problems."
        ]
    },
    "id_table_2": {
        "caption": "SVAMP Data set Evaluation",
        "table": [
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.1.1.1.1\">\n         Agent\n        </th>\n        \n",
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.1.1.1.2\">\n         Solve Rate\n        </th>\n       \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.2.1.1\">\n         Single GPT3.5-turbo\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T2.1.2.1.2\">\n         70%\n        </td>\n       \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.3.2.1\">\n         Multi-Agent GPT3.5-turbo\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_left\" id=\"S3.T2.1.3.2.2\">\n         73%\n        </td>\n       \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T2.1.4.3.1\">\n         Multi-Agent GPT3.5-turbo\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.4.3.1.1\">\n          (Our approach)\n         </span>\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T2.1.4.3.2\">\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.4.3.2.1\">\n          77%\n         </span>\n        </td>\n       \n"
            ]
        ],
        "footnotes": [],
        "references": [
            "The outcomes from both experiments can be found in Table                     1                   and Table                     2                   . In the initial experiment (example can be found here                     3.1.1                   ) using the GSM8K data set, the single-agent GPT-3 achieves approximately 50% accuracy, and the multi-agent GPT-3 performs slightly better at 55%. However, our multi-agent approach significantly enhances accuracy, surpassing other large language models (LLMs) such as Google’s PALM 540B parameter model, which we haven’t directly tested but are referencing from their paper. This improvement is notable in terms of accuracy, and it’s noteworthy that we haven’t retrained the model to achieve this enhancement. Assigning personas to the agents enables the LLM model to concentrate on specific aspects of the problem, and the use of chain-of-thought prompts equips it with efficient means to solve sub-problems."
        ]
    },
    "id_table_3": {
        "caption": "CSQA Data set Evaluation",
        "table": [
            [
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.1\">\n         Agent\n        </th>\n        \n",
                "<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.2\">\n         Solve Rate\n        </th>\n       \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.1.2.1.1\">\n         Single GPT3.5-turbo\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.1.2.1.2\">\n         77%\n        </td>\n       \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.3.2.1\">\n         Multi-Agent GPT3.5-turbo\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.3.2.2\">\n         78%\n        </td>\n       \n"
            ],
            [
                "<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T3.1.4.3.1\">\n         Multi-Agent GPT3.5-turbo\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.4.3.1.1\">\n          (Our approach)\n         </span>\n        </td>\n        \n",
                "<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T3.1.4.3.2\">\n         <span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.4.3.2.1\">\n          83%\n         </span>\n        </td>\n       \n"
            ]
        ],
        "footnotes": [],
        "references": [
            "The results of the third experiment are detailed in Table                     3                   . The single-agent GPT-3 achieves an impressive 77% accuracy, while the multi-agent GPT-3 performs slightly better at 78%. However, our multi-agent approach substantially improves accuracy, surpassing the other two and reaching approximately 83% accuracy. Notably, this accuracy is attained through Few-Shot training, indicating there is room for further enhancement. Few-shot training involves providing the LLM with a few examples of a specific problem type, enabling it to learn the correct answer without retraining the entire model for novel problems. Examples can be found here                     3.2.1                   and here                     3.2.2                   ."
        ]
    }
}