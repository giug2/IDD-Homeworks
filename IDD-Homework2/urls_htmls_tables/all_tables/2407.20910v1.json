{
    "S2.T1": {
        "caption": "Table 1: Summary of datasets used.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S2.T1.2\">\n<tr class=\"ltx_tr\" id=\"S2.T1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.1.1.1\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.1.2.1\">Platform</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.1.3.1\">Topic</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.1.4.1\">#Claims</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.1.5.1\">#Refute</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.2.1.6.1\">#Support</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.2.2.1\">GWSD&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib38\" title=\"\">38</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.2.2\">News</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.2.3\">Climate</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.2.4\">N/A</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.2.5\">400</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.2.6\">777</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.2.3.1\">Climate Skepticism</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.3.2\">Reddit</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.3.3\">Climate</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.3.4\">3</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.3.5\">1,277</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.3.6\">1,650</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.2.4.1\">COVID-FACT&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib66\" title=\"\">66</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.4.2\">Reddit</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.4.3\">COVID-19</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.4.4\">4,086</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.4.5\">2,790</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.4.6\">1,296</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.2.5.1\">COVID-CQ&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib46\" title=\"\">46</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.5.2\">Twitter</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.5.3\">COVID-19</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.5.4\">1</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.5.5\">3,488</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.5.6\">3,515</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.2.6.1\">Stanceosaurus&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib85\" title=\"\">85</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.6.2\">Twitter</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.6.3\">Fact-Checking</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.6.4\">190</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.6.5\">1,442</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.6.6\">3,025</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.2.7.1\">Election Denial&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib54\" title=\"\">54</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.7.2\">Twitter</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.7.3\">Election</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.7.4\">3</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.7.5\">128</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T1.2.7.6\">454</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.2.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T1.2.8.1\">PERSPECTRUM&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib14\" title=\"\">14</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T1.2.8.2\">Debates</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T1.2.8.3\">Argument Mining</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T1.2.8.4\">907</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T1.2.8.5\">2,468</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T1.2.8.6\">2,627</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We curate and collect multiple datasets throughout our work that i)\u00a0come from multiple social media platforms (Reddit, Twitter), ii)\u00a0cover different topics (e.g, Climate Change, COVID-19), and iii)\u00a0contain different levels of granularity (i.e, fine-grained or coarse-grained claims).\nA summary of the datasets used in our work is presented in Table\u00a01.",
            "Summary. A summary of all the datasets curated and collected is listed in Table\u00a01.\nWe can observe that the datasets used by our work span across different use cases of misinformation such as climate denial, public health emergencies, civic processes such as elections, and general purpose fact-checking.\nThis way, we aim to comprehensively evaluate our method on a variety of misleading claims occurring across two different social media platforms."
        ]
    },
    "S2.T2": {
        "caption": "Table 2: Summary of climate skeptic claims annotated with stance labels.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S2.T2.2\">\n<tr class=\"ltx_tr\" id=\"S2.T2.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T2.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.2.1.1.1\">Claim</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T2.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.2.1.2.1\">#Refute</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T2.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T2.2.1.3.1\">#Support</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T2.2.2.1\">Cosmic Rays cause GW</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T2.2.2.2\">577</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T2.2.2.3\">439</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.2.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T2.2.3.1\">UHI effect exaggerate GW trends</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T2.2.3.2\">390</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T2.2.3.3\">495</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T2.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T2.2.4.1\">Antarctica is gaining ice</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T2.2.4.2\">683</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T2.2.4.3\">343</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Climate Skepticism.\nThe majority of stance detection datasets are topic-based or target-based in nature, with a very limited set of datasets on claim-based stance detection occurring on social media text.\nThis existing gap motivates us to prepare a comprehensive claim-based stance detection dataset.\nWe curate a dataset of climate change denial discussions, containing Reddit posts that support or refute three different claims related to different arguments used in climate change discussions.\nWe query the Pushshift Reddit dataset\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib7\" title=\"\">7</a>]</cite> with curated keywords related to the claims, retrieving posts from Reddit that are discussing narratives related to three of the most popular climate denier claims: i)&#160;\n[7] with curated keywords related to the claims, retrieving posts from Reddit that are discussing narratives related to three of the most popular climate denier claims: i)\u00a0Cosmic rays are causing global warming (GW), ii)\u00a0Antarctica is gaining ice, and iii)\u00a0Urban Heat island (UHI) effect exaggerate global warming trends.\nThese claims are fine-grained and objective in nature, unlike high-level \u201ctopics\u201d in the GWSD dataset such as \u201cGlobal warming is a hoax,\u201d or \u201cClimate change is not happening.\u201d\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib38\" title=\"\">38</a>]</cite>\nFor the goal of scalable and tractable soft moderation, these claims are very representative of misleading claims propagating on social media that can be easily refuted from scientific consensus, or authoritative sources (e.g. Skeptical Science).\nWe then set out to annotate 1,000 Reddit posts for each claim by developing a codebook dedicated to climate skepticism.\nOur codebook was informed by the crowdsourced resource Skeptical Science, which provides pointers for understanding different narratives used by climate skeptics to deny a claim as well as examples of scientific support for confirmed claims.\nWe do not include posts that are inquiring about the claim in question, are neutral towards it, or are topically irrelevant.\nTwo researchers performed multiple rounds of annotation and reached a near-perfect agreement of \n[44, 38]\nFor the goal of scalable and tractable soft moderation, these claims are very representative of misleading claims propagating on social media that can be easily refuted from scientific consensus, or authoritative sources (e.g. Skeptical Science).\nWe then set out to annotate 1,000 Reddit posts for each claim by developing a codebook dedicated to climate skepticism.\nOur codebook was informed by the crowdsourced resource Skeptical Science, which provides pointers for understanding different narratives used by climate skeptics to deny a claim as well as examples of scientific support for confirmed claims.\nWe do not include posts that are inquiring about the claim in question, are neutral towards it, or are topically irrelevant.\nTwo researchers performed multiple rounds of annotation and reached a near-perfect agreement of <math alttext=\"\\kappa\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p3.1.m1.1\">\n  <semantics id=\"S2.p3.1.m1.1a\">\n    <mi id=\"S2.p3.1.m1.1.1\" xref=\"S2.p3.1.m1.1.1.cmml\">&#954;</mi>\n    <annotation-xml encoding=\"MathML-Content\" id=\"S2.p3.1.m1.1b\">\n      <ci id=\"S2.p3.1.m1.1.1.cmml\" xref=\"S2.p3.1.m1.1.1\">&#120581;</ci>\n    </annotation-xml>\n    <annotation encoding=\"application/x-tex\" id=\"S2.p3.1.m1.1c\">\\kappa</annotation>\n    <annotation encoding=\"application/x-llamapun\" id=\"S2.p3.1.m1.1d\">italic_&#954;</annotation>\n  </semantics>\n</math> = 0.865&#160;\n<semantics id=\"S2.p3.1.m1.1a\">\n  <mi id=\"S2.p3.1.m1.1.1\" xref=\"S2.p3.1.m1.1.1.cmml\">&#954;</mi>\n  <annotation-xml encoding=\"MathML-Content\" id=\"S2.p3.1.m1.1b\">\n    <ci id=\"S2.p3.1.m1.1.1.cmml\" xref=\"S2.p3.1.m1.1.1\">&#120581;</ci>\n  </annotation-xml>\n  <annotation encoding=\"application/x-tex\" id=\"S2.p3.1.m1.1c\">\\kappa</annotation>\n  <annotation encoding=\"application/x-llamapun\" id=\"S2.p3.1.m1.1d\">italic_&#954;</annotation>\n</semantics>\n<mi id=\"S2.p3.1.m1.1.1\" xref=\"S2.p3.1.m1.1.1.cmml\">&#954;</mi>\n\u03ba<annotation-xml encoding=\"MathML-Content\" id=\"S2.p3.1.m1.1b\">\n  <ci id=\"S2.p3.1.m1.1.1.cmml\" xref=\"S2.p3.1.m1.1.1\">&#120581;</ci>\n</annotation-xml>\n<ci id=\"S2.p3.1.m1.1.1.cmml\" xref=\"S2.p3.1.m1.1.1\">&#120581;</ci>\n\ud835\udf05<annotation encoding=\"application/x-tex\" id=\"S2.p3.1.m1.1c\">\\kappa</annotation>\n\\kappa<annotation encoding=\"application/x-llamapun\" id=\"S2.p3.1.m1.1d\">italic_&#954;</annotation>\nitalic_\u03ba = 0.865\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib41\" title=\"\">41</a>]</cite>) Cohen&#8217;s Kappa (i.e., strong agreement).\nThis dataset also has value in evaluating the transferability of stance detection approaches as it contains multiple targets (claims), and different types of label distribution within the claims.\nA summary of the climate denial claims and the number of annotated Reddit posts for each claim is provided in Table&#160;\n[41]) Cohen\u2019s Kappa (i.e., strong agreement).\nThis dataset also has value in evaluating the transferability of stance detection approaches as it contains multiple targets (claims), and different types of label distribution within the claims.\nA summary of the climate denial claims and the number of annotated Reddit posts for each claim is provided in Table\u00a02."
        ]
    },
    "S2.T3": {
        "caption": "Table 3: Summary of election denial claims from \u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib54\" title=\"\">54</a>]</cite> annotated with stance labels\n[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib54\" title=\"\">54</a>]\n54] annotated with stance labels",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T3.2.1\">\n<tr class=\"ltx_tr\" id=\"S2.T3.2.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T3.2.1.1.1.1\">Claim</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T3.2.1.1.2.1\">#Refute</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T3.2.1.1.3.1\">#Support</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.2.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.2.1\">Wisconsin Voter Turnout above 90%</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.2.2\">132</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.2.3\">32</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.2.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.3.1\">Illegal suitcase of ballots in Georgia</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.3.2\">161</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.3.3\">55</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T3.2.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.4.1\">Dead Voters voted in Michigan</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.4.2\">161</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S2.T3.2.1.4.3\">41</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Election denial\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib54\" title=\"\">54</a>]</cite>.\n[54].\nThis dataset contains 499 election denial claims and 101,353 tweets discussing the claims retrieved by the corresponding soft-moderation system Lambretta.\nWe select the three most popular election denial claims by frequency present in the dataset and annotate a sample of 200 random tweets discussing the three claims for the stance of the tweets concerning the claim in question.\nWe adapt the codebook and annotation process used for annotating climate denial-related claims.\nA near-perfect agreement of <math alttext=\"\\kappa\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p7.1.m1.1\">\n  <semantics id=\"S2.p7.1.m1.1a\">\n    <mi id=\"S2.p7.1.m1.1.1\" xref=\"S2.p7.1.m1.1.1.cmml\">&#954;</mi>\n    <annotation-xml encoding=\"MathML-Content\" id=\"S2.p7.1.m1.1b\">\n      <ci id=\"S2.p7.1.m1.1.1.cmml\" xref=\"S2.p7.1.m1.1.1\">&#120581;</ci>\n    </annotation-xml>\n    <annotation encoding=\"application/x-tex\" id=\"S2.p7.1.m1.1c\">\\kappa</annotation>\n    <annotation encoding=\"application/x-llamapun\" id=\"S2.p7.1.m1.1d\">italic_&#954;</annotation>\n  </semantics>\n</math> = 0.866&#160;\n<semantics id=\"S2.p7.1.m1.1a\">\n  <mi id=\"S2.p7.1.m1.1.1\" xref=\"S2.p7.1.m1.1.1.cmml\">&#954;</mi>\n  <annotation-xml encoding=\"MathML-Content\" id=\"S2.p7.1.m1.1b\">\n    <ci id=\"S2.p7.1.m1.1.1.cmml\" xref=\"S2.p7.1.m1.1.1\">&#120581;</ci>\n  </annotation-xml>\n  <annotation encoding=\"application/x-tex\" id=\"S2.p7.1.m1.1c\">\\kappa</annotation>\n  <annotation encoding=\"application/x-llamapun\" id=\"S2.p7.1.m1.1d\">italic_&#954;</annotation>\n</semantics>\n<mi id=\"S2.p7.1.m1.1.1\" xref=\"S2.p7.1.m1.1.1.cmml\">&#954;</mi>\n\u03ba<annotation-xml encoding=\"MathML-Content\" id=\"S2.p7.1.m1.1b\">\n  <ci id=\"S2.p7.1.m1.1.1.cmml\" xref=\"S2.p7.1.m1.1.1\">&#120581;</ci>\n</annotation-xml>\n<ci id=\"S2.p7.1.m1.1.1.cmml\" xref=\"S2.p7.1.m1.1.1\">&#120581;</ci>\n\ud835\udf05<annotation encoding=\"application/x-tex\" id=\"S2.p7.1.m1.1c\">\\kappa</annotation>\n\\kappa<annotation encoding=\"application/x-llamapun\" id=\"S2.p7.1.m1.1d\">italic_&#954;</annotation>\nitalic_\u03ba = 0.866\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib41\" title=\"\">41</a>]</cite> was reached among the annotators.\nA summary of the claims, and the number of supporting, and refuting tweets for each claim is presented in Table&#160;\n[41] was reached among the annotators.\nA summary of the claims, and the number of supporting, and refuting tweets for each claim is presented in Table\u00a03.",
            "At this point, we have experimentally validated that a fine-tuned FLAN model on the CTD task has better performance than existing supervised baselines and LLMs bootstrapped for the task, making it the state-of-the-art approach in claim-based stance detection.\nOur motivation for designing CTD, however, is to enable soft moderation approaches to get rid of contextual false positives, allowing platforms to deploy more effective warnings that are only applied to content that is supporting a certain false claim.\nThe state-of-the-art soft moderation tool Lambretta\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib54\" title=\"\">54</a>]</cite> is unable to discern this contextual information, and while it performs well in discarding candidate posts that are irrelevant to a given claim, it still flags a large fraction of posts that refute false claims as candidates for moderation: looking at the results reported by Lambretta on three false claims related to the 2020 US Presidential Election (see Table&#160;\n[54] is unable to discern this contextual information, and while it performs well in discarding candidate posts that are irrelevant to a given claim, it still flags a large fraction of posts that refute false claims as candidates for moderation: looking at the results reported by Lambretta on three false claims related to the 2020 US Presidential Election (see Table\u00a03), we find that 20% of the candidates flagged by the system are contextual false positives.",
            "Setup.\nWe use the annotated dataset of election denial tweets discussed in Table\u00a03 for this purpose.\nThese tweets were flagged by Lambretta as part of the evaluation in the original paper\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib54\" title=\"\">54</a>]</cite>.\nWe can observe that the class of stance in the tweets is heavily skewed towards spreading the misinformation (\n[54].\nWe can observe that the class of stance in the tweets is heavily skewed towards spreading the misinformation (Refuting the fact-checks), and contains a smaller proportion of tweets that are debunking the misinformation (Supporting the fact-checks).\nAs discussed, Lambretta has no contextual understanding of its candidates for soft moderation, and when evaluating for contextual false positives, we find that the system reports a 20% False Detection Rate on average, with an F1 score on the three claims that ranges between 0.88 and 0.89 depending on the claim (see Table\u00a09).\nNote that the False Negative Rate for the Lambretta baseline is 0 since the system does not perform any contextual filtering on the moderation candidates, and all retrieved tweets are considered matches for moderation."
        ]
    },
    "S3.T4": {
        "caption": "Table 4: Performance of BERT model on GWSD claims evaluated on Climate Skepticism dataset.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.T4.2\">\n<tr class=\"ltx_tr\" id=\"S3.T4.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T4.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.2.1.1.1\">Claim</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T4.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T4.2.1.2.1\">F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T4.2.2.1\">Antarctica is gaining ice</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T4.2.2.2\">0.61</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T4.2.3.1\">UHI exaggerate GW trends</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T4.2.3.2\">0.44</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T4.2.4.1\">Cosmic rays cause GW</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T4.2.4.2\">0.41</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Takeaways. The fine-tuning procedure on the GWSD dataset performs well when cross-evaluated on coarser claims (F1 score of 0.766 on 5-fold cross-validation).\nHowever, the model performance drops drastically when evaluated on the fine-grained climate claims from the Climate Skepticism dataset as seen in Table\u00a04.\nThis experiment shows that supervised models trained on coarse-level claims fail to evaluate the stance on fine-grained ones, despite having high domain and topic overlap with the training data.\nThis motivates the need to design stance detection methods that are highly granular and specific in nature."
        ]
    },
    "S3.T5": {
        "caption": "Table 5: Stance detection performance across claims. Each line shows the F1 score for the model trained on one claim and tested on the three claims in the Climate Skepticism dataset.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T5.2.1\">\n<tr class=\"ltx_tr\" id=\"S3.T5.2.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.1.1.1.1\">Training Claim</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.1.1.2.1\">F1 #1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.1.1.3.1\">F1 #2</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.1.1.4.1\">F1 #3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.2.1\">#1 Antarctica is gaining ice</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.1.2.2.1\">0.828</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.2.3\">0.429</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.2.4\">0.551</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.3.1\">#2 UHI exaggerate GW trends</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.3.2\">0.470</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.1.3.3.1\">0.7315</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.3.4\">0.578</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.4.1\">#3 Cosmic rays cause GW</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.4.2\">0.4183</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.4.3\">0.589</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T5.2.1.4.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.1.4.4.1\">0.817</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "To investigate if existing stance detection approaches can generalize between claims, we again use the Climate Skepticism dataset, as it contains three fine-grained claims.\nIt is to note that all three corpora for the individual claims come from the same social media platform (Reddit), thus we can expect the corpus distribution of the evaluation setting to be similar to the training setting.\nAs in the previous step, we train a DistilBERT model for each claim and evaluate the model on detecting the stance of posts on the other two claims that it was not trained on.\nThe results are provided in Table\u00a05."
        ]
    },
    "S4.T6": {
        "caption": "Table 6: Summary of F1 Scores for Different Methods",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T6.2\">\n<tr class=\"ltx_tr\" id=\"S4.T6.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T6.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.1.1.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T6.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.1.2.1\">Mean F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T6.2.2.1\">BERT Fine Tuning</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T6.2.2.2\">0.786</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T6.2.3.1\">Climate Fever NLI</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T6.2.3.2\">0.626</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T6.2.4.1\">LLM w/o Contrastive Markers</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T6.2.4.2\">0.795</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T6.2.5.1\">LLM w/o Consensus</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S4.T6.2.5.2\">0.771</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.2.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S4.T6.2.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.6.1.1\">Bootstrapped CTD</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T6.2.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T6.2.6.2.1\">0.836</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Results. A summary of the bootstrapping results with the mean F1 scores for the three Climate Skepticism claims is presented in Table\u00a06.\nWe find that our bootstrapped method (which is unsupervised) performs better than supervised BERT-based fine-tuning baselines.\nAdditionally, we find that our approach provides better performance over using the LLMs in their default state: without consensus grounding (LLM without consensus), and without contrastive markers (LLM without contrastive markers).\nThe results also suggest that the triplet setup of CTD performs better than the conventional setup of entailment for stance detection.\nAdditionally, we observe that having the contrastive markers by themselves without the consensus statement (LLM without consensus) is not nearly as effective for detecting stance.\nOverall, these results validate that the task of CTD can outperform existing methods for supervised stance detection.\nMoreover, the utility of our approach is validated in being fully unsupervised and requiring minimal setup needed for a claim (i.e. a consensus statement, and a pair of supporting and refuting in-context examples)."
        ]
    },
    "S5.T7": {
        "caption": "Table 7: Results of comprehensive evaluation.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S5.T7.2\">\n<tr class=\"ltx_tr\" id=\"S5.T7.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T7.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.2.1.1.1\">Claim / Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T7.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.2.1.2.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T7.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.2.1.3.1\">F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T7.2.2.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S5.T7.2.2.1.1\">Climate Skepticism (Reddit)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T7.2.2.2\">Task-BERT</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T7.2.2.3\">0.786</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.3.1\">MT-DNN</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.3.2\">0.645</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.4.1\">POLITICS</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.4.2\">0.734</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.5.1\">Bootstrapped CTD</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.5.2\">0.836</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.2.6.1.1\">Fine-tuned CTD</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.2.6.2.1\">0.871</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T7.2.7.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S5.T7.2.7.1.1\">COVID-CQ (Twitter)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T7.2.7.2\">Task-BERT</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T7.2.7.3\">0.900</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.8.1\">MT-DNN</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.8.2\">0.586</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.9.1\">POLITICS</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.9.2\">0.831</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.10.1\">Bootstrapped CTD</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.10.2\">0.810</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.11.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.2.11.1.1\">Fine-tuned CTD</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.11.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.2.11.2.1\">0.904</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T7.2.12.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S5.T7.2.12.1.1\">Stanceosaurus (Twitter)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T7.2.12.2\">Task-BERT</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T7.2.12.3\">0.731</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.13.1\">MT-DNN</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.13.2\">0.656</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.14.1\">POLITICS</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.14.2\">0.670</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.15\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.15.1\">Bootstrapped CTD</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T7.2.15.2\">0.773</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.2.16\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S5.T7.2.16.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.2.16.1.1\">Fine-tuned CTD</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" id=\"S5.T7.2.16.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.2.16.2.1\">0.848</span></td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Then, using the PEFT configuration of LoRA, we fine-tune the FLAN-T5 model on the augmented fine-tuning dataset.\nTo make the task more manageable, we randomly sample 4 contrastive examples per claim to fine-tune the model, resulting in a dataset size of 36,000 triplets from 905 claims.\nWe divide the fine-tuning dataset into 85-15 training and validation splits and fine-tune the FLAN-T5 model for 5 epochs until the validation loss stops decreasing further.\nFinally, we test this fine-tuned FLAN model on all three of our evaluation datasets (one coming from Reddit and two from Twitter).\nThe results of this experiment are shown in Table\u00a07.\nAs it can be seen, the fine-tuned CTD model performs well, reporting F1-scores between 0.84 and 0.90 on the different datasets.",
            "Results.\nThe summary of evaluation results of the fine-tuned FLAN model and other methods is presented in Table\u00a07.\nWe can observe that the fine-tuned FLAN model for CTD performs consistently better than all other baselines on all evaluation datasets, outperforming not only Task-BERT and other baselines but also the results from the bootstrapped CTD.\nFirst, this confirms our hypothesis that the zero-shot learning capabilities of LLMs can be further bolstered by behaviorally fine-tuning a LLM on the CTD task.\nSecondly, fine-tuned CTD has better performance than other stance detection approaches such as MT-DNN and POLITICS while being fine-tuned on the same dataset.\nThis proves that the task formulation of Contrastive Textual Deviation leveraged by the fine-tuned CTD model meaningfully outperforms existing systems for stance detection.\nAdditionally, it is interesting to note that the FLAN-T5 model, which was fine-tuned on normalized argumentative structures that are domain and platform-independent (as discussed in Section\u00a05.1), consistently outperforms the Task-BERT models that were specifically fine-tuned on claim specific posts from social media text.\nThis again affirms our hypothesis that a granular, topic-independent, and platform-independent stance detection model can be created by reframing the problem as a task of Contrastive Textual Deviation, which captures the semantics of stance detection much better on a foundation level.\nIn summary, these results show that the FLAN-T5 model fine-tuned on the CTD task is a reliable, robust, and scalable stance detection method for the soft moderation of social media text."
        ]
    },
    "S5.T8": {
        "caption": "Table 8: Performance of different FLAN-T5 models on Contrastive Textual Deviation.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T8.2\">\n<tr class=\"ltx_tr\" id=\"S5.T8.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T8.2.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T8.2.1.1.1\">Model</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T8.2.1.2.1\"># params</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T8.2.1.3.1\">Runtime (s)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T8.2.1.4.1\">Mean F1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T8.2.2.1\">FLAN-T5-Small</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.2.2\">60M</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.2.3\">0.008</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.2.4\">0.492</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.2.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T8.2.3.1\">FLAN-T5-Base</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.3.2\">250M</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.3.3\">0.012</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.3.4\">0.555</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.2.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T8.2.4.1\">FLAN-T5-Large</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.4.2\">780M</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.4.3\">0.018</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.4.4\">0.589</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.2.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T8.2.5.1\">FLAN-T5-XL</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.5.2\">3B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.5.3\">0.043</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T8.2.5.4\">0.811</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.2.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T8.2.6.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T8.2.6.1.1\">FLAN-T5-XXL</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T8.2.6.2\">11B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T8.2.6.3\">0.078</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T8.2.6.4\">0.874</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Finally, we study how the runtime and performance of CTD varies based on the different models available in the FLAN-T5 family.\nFollowing the same methodology discussed in Section\u00a05.1, we fine-tune four smaller models of CTD: i)\u00a0FLAN-T5-Small, ii)\u00a0FLAN-T5-Base, iii)\u00a0FLAN-T5-Large, and iv)\u00a0FLAN-T5-XL.\nThis helps us better understand the scaling properties of the CTD task.\nMoreover, researchers and practitioners can use this to guide them in appropriate model selection based on their resource constraints and runtime requirements.\nTable\u00a08 shows that the performance of CTD increases linearly as the model size increases along with the tradeoff on runtime.\nOn the other hand, CTD fine-tuned on FLAN-T5-XL can be a viable option for practitioners as the performance dropoff from the best model (i.e. FLAN-T5-XXL) is relatively minor compared to the substantial reduction in model size (11B to 3B)."
        ]
    },
    "S5.T9": {
        "caption": "Table 9: Evaluation of the end-to-end component.",
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S5.T9.2.1\">\n<tr class=\"ltx_tr\" id=\"S5.T9.2.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.1.1.1\">Claim</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.1.2.1\">Method</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.1.3.1\">F1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.1.4.1\">FDR</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.1.5.1\">FNR</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T9.2.1.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.2.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T9.2.1.2.1.1\">GA suitcase of ballots</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.2.2\">Lambretta</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.2.3\">0.877</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.2.4\">0.219</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.2.5.1\">0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T9.2.1.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.3.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.3.1.1\">Lambretta + CTD</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.3.2.1\">0.987</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.3.3.1\">0.015</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.3.4\">0.010</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T9.2.1.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.4.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T9.2.1.4.1.1\">Dead Voters voted in MI</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.4.2\">Lambretta</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.4.3\">0.887</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.4.4\">0.203</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.4.5.1\">0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T9.2.1.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.5.1.1\">Lambretta + CTD</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.5.2.1\">0.9632</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.5.3.1\">0.048</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.5.4\">0.024</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T9.2.1.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.6.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T9.2.1.6.1.1\">WI Voter Turnout above 90%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.6.2\">Lambretta</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.6.3\">0.891</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.6.4\">0.195</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.6.5.1\">0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T9.2.1.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.7.1.1\">Lambretta + CTD</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.7.2.1\">0.988</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T9.2.1.7.3.1\">0</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" id=\"S5.T9.2.1.7.4\">0.022</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Setup.\nWe use the annotated dataset of election denial tweets discussed in Table\u00a03 for this purpose.\nThese tweets were flagged by Lambretta as part of the evaluation in the original paper\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2407.20910v1#bib.bib54\" title=\"\">54</a>]</cite>.\nWe can observe that the class of stance in the tweets is heavily skewed towards spreading the misinformation (\n[54].\nWe can observe that the class of stance in the tweets is heavily skewed towards spreading the misinformation (Refuting the fact-checks), and contains a smaller proportion of tweets that are debunking the misinformation (Supporting the fact-checks).\nAs discussed, Lambretta has no contextual understanding of its candidates for soft moderation, and when evaluating for contextual false positives, we find that the system reports a 20% False Detection Rate on average, with an F1 score on the three claims that ranges between 0.88 and 0.89 depending on the claim (see Table\u00a09).\nNote that the False Negative Rate for the Lambretta baseline is 0 since the system does not perform any contextual filtering on the moderation candidates, and all retrieved tweets are considered matches for moderation.",
            "Results.\nThe summary of the evaluation is presented in Table\u00a09.\nAs it can be seen, integrating CTD with Lambretta largely reduces the rate of contextual false positives, bringing down the average false detection rate by an order of magnitude from 20% to 2.1%.\nFor the \u201cWisconsin voter turnout above 90%,\u201d the false detection rate after applying our approach is actually zero.\nAt the same time, the false negative rate remains small, being 1.8% on average.\nThis translates in F1 scores between 0.98 and 0.96, showing an improvement of about 10% over the baseline, showing that CTD can be effectively used to improve soft moderation systems for social media."
        ]
    }
}