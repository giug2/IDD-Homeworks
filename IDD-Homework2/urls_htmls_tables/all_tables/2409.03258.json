{
    "id_table_1": {
        "caption": "Table 1:  Analysis on Macro- and Micro-level Tasks with Different Baseline Methods and Models.",
        "table": "S5.T1.1.1",
        "footnotes": [],
        "references": [
            "A  key observation  is that enhancing LLM performance in graph-related applications depends critically on LLMs ability to comprehend graph structures through natural language descriptions.  Existing studies  Shang & Huang ( 2024 ); Li et al. ( 2023 )  primarily utilizes two direct methods to transform graphs into text inputs for LLMs: the  structural format transforming , such as adjacency matrices (termed as  AM ) or lists (termed as  AL ) and the  sequential format transforming , such as edge-by-edge descriptions (termed as  Raw Seq ).  However, extensive empirical studies  Yuan et al. ( 2024 )  have shown that LLMs face significant challenges in understanding and reasoning about graph structures using current graph transformation methods, especially as graph size increases, leading to a comprehension collapse.  As shown in Figure 1 (a), several common LLMs perform poorly on graph structure understanding tasks (see benchmarks in Section  5.1 ), and their comprehension declines sharply as the graph size increases, ultimately leading to complete failure.",
            "Based on Definition  1 , the LLMs ability to understand  T T \\mathcal{T} caligraphic_T  can be quantified as shown in Definition  2 .",
            "Following Definition  3 , we build the GraphSQA benchmark (see Section  5.1 ) to comprehensively and fairly evaluate LLMs performance in graph structure understanding.",
            "After calculating the PageRank scores, we sort the nodes in descending order. Starting from the node with the highest score, we iteratively construct subgraphs centered on each node, including directly connected neighbors with lower degrees, provided the connecting edges havent been used in other subgraphs.  This ensures that each edge is only included in one subgraph, which guarantees that the total length of the merged subgraph descriptions equals the original graph description sequence. This is because, as per Definition 1, we describe the graph edge by edge. The descriptions for these subgraphs  G 1 , G 2 , ... , G k subscript G 1 subscript G 2 ... subscript G k G_{1},G_{2},\\dots,G_{k} italic_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , italic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT  are denoted as  t 1 , t 2 , ... , t k subscript t 1 subscript t 2 ... subscript t k t_{1},t_{2},\\dots,t_{k} italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ... , italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT .  Then, each subgraph description  t i subscript t i t_{i} italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is formed by combining the descriptions of all edges within the subgraph  G i subscript G i G_{i} italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , according to the graph description defined previously in Definition  1 . The importance  I  ( t i ) I subscript t i \\mathcal{I}(t_{i}) caligraphic_I ( italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )  of each subgraph description  t i subscript t i t_{i} italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is defined as the PageRank score of its central node  v c i subscript v subscript c i v_{c_{i}} italic_v start_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT :  I  ( t i ) = PR  ( v c i ) I subscript t i PR subscript v subscript c i \\mathcal{I}(t_{i})=\\text{PR}(v_{c_{i}}) caligraphic_I ( italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = PR ( italic_v start_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) .",
            "We conduct experiments with GraphInsight on two level graph understanding tasks: (i) macro understanding, (ii) micro understanding. Section  5.1  summarizes the experimental setup. Section  5.2  demonstrates the advantages of GraphInsight in enhancing LLMs understanding of graphs. Ablation study and hyperparameter analysis are on Sections  5.3  and  5.4 . Each reported value is the average of three runs.",
            "GraphInsight outperforms all other methods across all large models for macro-tasks, as shown in Table  1 . Specifically, GraphInsight can achieve up to a 4.61  \\times   increase in score compared to AM on the Vicuna-7B model. Structural methods show the smallest improvement for macro-level tasks. The other two types of methods, i.e., prompting and structural methods, result in only minimal improvements in the understanding of LLMs for macro-level tasks. For example, on Llama-3-8B, they can achieve at most a minimal improvement of 5.7%, from 0.4379 to 0.4404. However, GraphInsight can provide a substantial increase of 23.82%, from 0.4379 to 0.5422. Also, as shown in Figures  4 (a)-(b), across macro-level tasks with varying  | V | V |V| | italic_V | , GraphInsight consistently outperforms other methods. As  | V | V |V| | italic_V |  increases, the understanding capability tends to decrease, but GraphInsight shows the smallest decline.",
            "For the micro-level tasks, GraphInsight still outperforms the others, as shown in Table  1 . Notably, GraphInsight can achieve up to an 14.02  \\times   increase in score compared to AL on Vicuna-7B. Similar to macro-level tasks, baseline methods offer minimal improvement in the large models understanding. For example, on Qwen2-7B, they can achieve at most a minimal improvement of 3.4%, from 0.5637 to 0.5828. However, GraphInsight can provide a substantial increase of 48.78%, from 0.5637 to 0.8387. In Figures  4 (c)-(d), as  | V | V |V| | italic_V |  increases, GraphInsight causes the least decline in the models understanding. For example, on Mistral-7B, when  | V | V |V| | italic_V |  increases from 135 to 195, the score decreases only slightly from 0.68 to 0.67. In contrast, the best baselines score drops more significantly, from 0.54 to 0.29. We also conduct experiments on composite tasks, e.g., common neighbor finding (CN) and  k k k italic_k -order neighbor finding ( k k k italic_k -ON) shown in Figure  5 . GraphInsight can provide an improvement of 12.75  \\times   and 3.25  \\times   on Vicuna, respectively.",
            "This metric effectively penalizes larger deviations from the ground truth while allowing for partial credit when the prediction is reasonably close. As shown in Equation  11 , it offers a graded evaluation that more accurately reflects the precision of the numerical predictions.",
            "As expressed in Equation  12 , this similarity measure yields a score ranging from 0 to 1, where 1 indicates a perfect match between the predicted and ground truth sets, and 0 indicates no overlap. By considering both false positives and false negatives, the Jaccard similarity provides a balanced and comprehensive evaluation for set-type answers, effectively capturing both precision and recall in the predictions."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Ablation Study.",
        "table": "S5.T2.1.1",
        "footnotes": [],
        "references": [
            "There are two primary methods for converting graphs into description sequences for LLMs:  1)  structural format transforming (e.g., adjacency matrices/lists) and  2)  sequential format transforming (e.g., edge-by-edge descriptions). Since empirical studies (see Section  5.2 ) show that sequential format is more conducive to LLMs understanding and can seamlessly integrate additional semantic information (e.g., node and edge attributes, labels, etc.), our framework focuses on optimizing graph description sequences under this format. Therefore, for a given graph  G G G italic_G , we define the standard graph description sequences  T T \\mathcal{T} caligraphic_T  as follows:",
            "Based on Definition  1 , the LLMs ability to understand  T T \\mathcal{T} caligraphic_T  can be quantified as shown in Definition  2 .",
            "Here,    ( p )  p \\Psi(p) roman_ ( italic_p )  denotes the positional bias curve, which represents the distribution of an LLMs inherent comprehension at position  p p p italic_p .  As mentioned in Figure  2 ,    ( p )  p \\Psi(p) roman_ ( italic_p )  typically displays stronger comprehension at the head and tail of a sequence, with weaker comprehension in the middle, forming a U-shape curve.  In this paper, we follow above assumption and deine the positions corresponding to the head   % percent  \\alpha\\% italic_ %  and tail   % percent  \\beta\\% italic_ %  of the sequence as strong memory regio ns, and the rest as weak memory regions.",
            "Finally, the subgraph descriptions are reordered based on their importance and organized within the strong memory regions of the LLM, as defined in Definition  2 . Specifically, the head   % percent  \\alpha\\% italic_ %  and the tail   % percent  \\beta\\% italic_ %  of the graph description sequence are designated as the strong memory regions. Consequently, the most important subgraph descriptions are prioritized and placed in these regions, while the remaining descriptions, sorted by importance, occupy the middle, considered the weak memory region. The final graph description sequence  T ^ ^ T \\mathcal{\\hat{T}} over^ start_ARG caligraphic_T end_ARG  is:",
            "We conduct experiments with GraphInsight on two level graph understanding tasks: (i) macro understanding, (ii) micro understanding. Section  5.1  summarizes the experimental setup. Section  5.2  demonstrates the advantages of GraphInsight in enhancing LLMs understanding of graphs. Ablation study and hyperparameter analysis are on Sections  5.3  and  5.4 . Each reported value is the average of three runs.",
            "We conduct the ablation study on graph description organization and GraphRAG to verify the effectiveness of them. As shown in Table  2 , graph description organization is the optimization primarily for macro-level tasks as well as for micro-level tasks.  For example, on Llama-3-8B-262K, reorganization can achieve an 11.4% increase for macro-level tasks and an 8.9% increase for micro-level tasks.  On the other hand, GraphRAG focuses on micro-level tasks and can provide further notably improvements for micro-level tasks on top of the gains achieved by reorganization. For example, GraphRAG brings a 173.7% improvement on Vicuna-7B.",
            "As expressed in Equation  12 , this similarity measure yields a score ranging from 0 to 1, where 1 indicates a perfect match between the predicted and ground truth sets, and 0 indicates no overlap. By considering both false positives and false negatives, the Jaccard similarity provides a balanced and comprehensive evaluation for set-type answers, effectively capturing both precision and recall in the predictions."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Final hyperparameters used for each model/algorithm in the experiments.",
        "table": "A3.T3.5.5",
        "footnotes": [],
        "references": [
            "Next, we introduce two levels of graph understafnding tasks, as shown in Definition  3 .",
            "Following Definition  3 , we build the GraphSQA benchmark (see Section  5.1 ) to comprehensively and fairly evaluate LLMs performance in graph structure understanding.",
            "In this section, we present the  GraphInsight  framework, as shown in Figure  3 , which consists of two key techniques that enhance LLMs graph comprehension.",
            "We conduct experiments with GraphInsight on two level graph understanding tasks: (i) macro understanding, (ii) micro understanding. Section  5.1  summarizes the experimental setup. Section  5.2  demonstrates the advantages of GraphInsight in enhancing LLMs understanding of graphs. Ablation study and hyperparameter analysis are on Sections  5.3  and  5.4 . Each reported value is the average of three runs.",
            "In this section, we list the final hyperparameters used for each model/algorithm in the experiments conducted in this paper, as in Table  3 ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Notations used throughout this paper.",
        "table": "A4.T4.39.39",
        "footnotes": [],
        "references": [
            "We conduct experiments with GraphInsight on two level graph understanding tasks: (i) macro understanding, (ii) micro understanding. Section  5.1  summarizes the experimental setup. Section  5.2  demonstrates the advantages of GraphInsight in enhancing LLMs understanding of graphs. Ablation study and hyperparameter analysis are on Sections  5.3  and  5.4 . Each reported value is the average of three runs.",
            "GraphInsight outperforms all other methods across all large models for macro-tasks, as shown in Table  1 . Specifically, GraphInsight can achieve up to a 4.61  \\times   increase in score compared to AM on the Vicuna-7B model. Structural methods show the smallest improvement for macro-level tasks. The other two types of methods, i.e., prompting and structural methods, result in only minimal improvements in the understanding of LLMs for macro-level tasks. For example, on Llama-3-8B, they can achieve at most a minimal improvement of 5.7%, from 0.4379 to 0.4404. However, GraphInsight can provide a substantial increase of 23.82%, from 0.4379 to 0.5422. Also, as shown in Figures  4 (a)-(b), across macro-level tasks with varying  | V | V |V| | italic_V | , GraphInsight consistently outperforms other methods. As  | V | V |V| | italic_V |  increases, the understanding capability tends to decrease, but GraphInsight shows the smallest decline.",
            "For the micro-level tasks, GraphInsight still outperforms the others, as shown in Table  1 . Notably, GraphInsight can achieve up to an 14.02  \\times   increase in score compared to AL on Vicuna-7B. Similar to macro-level tasks, baseline methods offer minimal improvement in the large models understanding. For example, on Qwen2-7B, they can achieve at most a minimal improvement of 3.4%, from 0.5637 to 0.5828. However, GraphInsight can provide a substantial increase of 48.78%, from 0.5637 to 0.8387. In Figures  4 (c)-(d), as  | V | V |V| | italic_V |  increases, GraphInsight causes the least decline in the models understanding. For example, on Mistral-7B, when  | V | V |V| | italic_V |  increases from 135 to 195, the score decreases only slightly from 0.68 to 0.67. In contrast, the best baselines score drops more significantly, from 0.54 to 0.29. We also conduct experiments on composite tasks, e.g., common neighbor finding (CN) and  k k k italic_k -order neighbor finding ( k k k italic_k -ON) shown in Figure  5 . GraphInsight can provide an improvement of 12.75  \\times   and 3.25  \\times   on Vicuna, respectively.",
            "This section summarizes all notations used throughout this paper, as in Table  4 ."
        ]
    },
    "global_footnotes": [
        "Advancements in pre-training techniques and corpus optimization may alter the exact shape of this curve. Nevertheless, the variation in LLM comprehension across different sequence positions is likely to persist. Our framework is not restricted to a U-shaped curve; once the precise curve shape of a particular LLM is empirically estimated, our framework can be easily adjusted and adapted.",
        "PR can be replaced with others describe the importance of graph structures. Designing graph structure importance remains an open problem",
        ", and is orthogonal to our work."
    ]
}