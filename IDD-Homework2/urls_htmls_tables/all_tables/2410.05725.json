{
    "id_table_1": {
        "caption": "Table 1:  The parameter numbers and model sizes for Llama2-7B with & without LoRA rank of  16 16 16 16 .",
        "table": "S3.T1.3",
        "footnotes": [],
        "references": [
            "Even when considered relatively \"small\", the full size of the base model such as Llama2-7B, still occupies a significant amount of storage. The resulting inconvenience for transmitting the full model weights of  W D  P subscript W D P \\mathbb{W}_{DP} blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT  is plain to see. In contrast, LoRA adaptation significantly reduces the transmission burden by allowing us to send only the LoRA adapter  A D  P subscript A D P \\mathbb{A}_{DP} blackboard_A start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT , resulting in a far more manageable model size. Detailed comparison of model sizes is shown in Table  1 .",
            "Our baselines comprise one None-Private approach, one private approach with DP-SGD  Abadi et al. ( 2016 ) , and six private approaches using synthetic data generation, i.e. ICL  Dong et al. ( 2022 ) , Self-Instruct  Wang et al. ( 2022 ) , Self-Instruct-ICL, DP-Gene  Kurakin et al. ( 2024 ) , DP-Instruct  Yu et al. ( 2024 )  and DP-Instruct-ICL. The detailed comparison of baselines is shown in Table  14  in Appendix  F.3 .",
            "Following  Zhang et al. ( 2023 ) , we conduct free-form evaluation by employing GPT-3.5-turbo  Zheng et al. ( 2023 )  to serve as a judge. For each instruction in the test dataset, the judge pairwise compares two responses resulting from the target model and THE reference model, respectively. We employ text-davinci-003, GPT-3.5-turbo, GPT-4 and Claude-2 as reference models. To avoid positional bias, we evaluate each sample twice with exchanged positions of different responses generated by the test and reference models. We follow  Li et al. ( 2023b )  to score the models by calculating the win rate. Additional experiments on medical benchmarks are attached in Appendix  C.1 .",
            "From Table  4  and Table  10 , we can conclude that: (1) Considering both benchmark and free-form results,  KnowledgeSG  consistently and significantly surpasses all other baselines in the medical domain. Particularly in the free-from evaluation, our method outperforms all other synthetic text generation baselines to a large margin, even doubling the performance of the None-private approach using original private data. (2) DP-based generation methods achieve much higher win rate scores than that of Self-instruction-based methods. This is expected because DP-based methods require additionally differentially private fine-tuning of the base model on private data. (3) The free-form results of  KnowledgeSG  surpassing AlpaCare (underlined in Table  4 ) highlight the immense potential of synthetic generation approaches which acquire knowledge distillation from a professional model, inspiring future research to further explore this area.",
            "Fine-tuning models to satisfies DP can only address the risk of memorization. There is no protection during the data collection stage where the user instructions are exposed to human annotators for response generation  Yu et al. ( 2024 ) . Moreover, using DP-SGD to prevent memorization by adding noise into the training process is destined to sacrifice performance. As proved in our experiments in Table  11 , employing DP-SGD alone leads to considerable performance drop.",
            "For domain-specific settings such as the medical domain, the judgements are mainly based on whether the tested instructions are related to particular medical knowledge. We first prompt AlpaCare using the template written in Figure  10 , then extract judgements from the model outputs. In experiments, we also try GPT-3.5-turbo as the domain classifier of instructions and receive acceptable results.",
            "From Table  10 , we can conclude that: (1) Compared to free-form evaluation in Section  4 , the results on medical benchmarks are more random. Along with the limit of performance ceiling, the gap between different methods are narrowed especially on MedQA and MedMCQA. (2) Our method still performs the best on average.",
            "Compared to the benchmark results in Table  10 , the gap between different baselines is much more pronounced and noticeable in the free-form evaluation in Table  4 , aligning more closely with expectations. We attribute the reasons as: (1) For MedQA and MedMCQA, the dataset we use is HealthCareMagic, whose purpose is to provide patients with consultant. This may not correspond with the nature of benchmarks to choose the right answer to a medicine-related question. (2) Benchmark results involve more randomness, thus improving the performance of inferior competitors to some extent.",
            "We follow the details for DP-finetuning in Appendix  F.1  and evaluate its performance on the financial domain, same as Section  4.3 .",
            "From the results in Table  11 , we can conclude that relying on DP-SGD only results in a considerable decline of performance, necessitating our approach of synthetic data generation with knowledge distillation from server.",
            "As shown in Table  12 ,  KnowledgeSG  outperforms ICL and Non-Private methods. The results confirm the effectiveness of  KnowledgeSG  in the math and code domain, further proving its generalizability. However, in the code domain, the performance gap between different methods is less pronounced compared to other domains. We attribute this to the suboptimal coding performance of pre-trained Llama2-7B, which may lack the capacity to generalize effectively on coding tasks. This finding aligns with related studies, where experiments on HumanEval are primarily conducted using the Llama2-13B model or larger variants  Luo et al. ( 2023 ); Xu et al. ( 2023 ) . The reason we prefer financial and medical domain than code and math is that math solving and code writing tasks are not directly related to privacy because there usually is no PIIs in these datasets.",
            "We choose GPT-4  OpenAI ( 2023 )  to be the datum model as we assume it is an all-around player that behaves well both on general tasks and domain-specific tasks. And the  Gap Ratio  is calculated by the ratio of target model results and GPT-4 results on the same evaluation benchmark. For example, from Table  13 , Llama2-7Bs  Gap Ratio  is  0.8722 0.8722 0.8722 0.8722  on Chatbot Arena and  0.7007 0.7007 0.7007 0.7007  on general benchmarks on average.",
            "No matter what the absolute value is in different measurements of model performance, we can apparently see that the gap between Llama2 and GPT will be greatly widened if changed from general to a specific domain. As in Table  13 , we draw a datum line of  0.5 0.5 0.5 0.5 , smaller than which indicates a tendency of worse synthetic generation.",
            "To give a detailed comparison between different baselines in our experiments, we elaborate on three aspects in Table  14 , ranging from the model used for generating instructions, whether the baseline first generates instructions then responses and whether the baseline requires few-shot examples to generate response if it is twp-step. DP-Instruct-ICL and Self-Instruct-ICL are different from DP-Instruct and Self-Instruct in that they require few-shot examples from original dataset to produce better responses during the second stage of generation while the others do not. Theoretically, DP-Instruct performs better than Self-Instruct and DP-Gene performs better than ICL because of additional DP-finetuning of base model."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Reconstruction rate comparison between different baselines on the medical and financial domains.  Inc  represents the increase of reconstruction rate between certain baseline and random guessing. Higher reconstruction rate indicates more memorization of the private data. Results in both domains demonstrate that synthetic data methods, including  KnowledgeSG , achieve significantly better privacy protection than non-private methods.",
        "table": "S4.T2.18",
        "footnotes": [],
        "references": [
            "If not otherwise mentioned, our base model is pre-trained Llama2-7B  Touvron et al. ( 2023b ) . We choose FinGPT  Yang ( 2023 )  and AlpaCare  Zhang et al. ( 2023 )  as our professional models for financial and medical domains respectively. The dataset sample is kept to  500 500 500 500  for any comparison except the ablation study in Section  4.6 . We use the name substitution technique in Appendix  B.2  to pre-process datasets, preventing inaccurate evaluation on privacy.",
            "From Table  2 , we can see that: (1) Using synthetic data instead of original data successfully reduces the PII reconstruction rate by a tremendous margin, demonstrating superior privacy protection over Non-Private method. (2) Differentially private training can preserve data privacy to a great content, but is still not on par with synthetic data approaches. (3) The privacy protection capabilities of different baselines exploiting synthetic data are closely aligned, with  KnowledgeSG  ranking first and ICL lagging behind, which validates the effectiveness of our method. This is reasonable in that ICL-related methods require few-shot examples from the original dataset to generate responses, thus introducing greater privacy risks.",
            "Table  3  demonstrates the results of our method and six other baselines using synthetic data generation on financial benchmarks. From the table, we can conclude that: (1)  KnowledgeSG  outperforms all other baselines on average, even better than using original private data, proving the effectiveness of knowledge distillation from professional model through our framework, not to mention our privacy-preserving nature. (2) For the FiQA-SA dataset, a large portion of the evaluation sample labels are  Neutral . Following the evaluation benchmarks  Yang ( 2023 ) , we treat responses with no predictions (Positive/Negative/Neutral) as  Neutral . This situation rarely happens except for pre-trained models that struggle with instruction following. Most of LLaMA2-7Bs responses are classified as  Neutral , thus explaining its unexpectedly strong performance on FiQA-SA. (3) Ignoring FiQA-SA, some synthetic generation baselines still perform even worse than the pre-trained Llama2 on FPB and TFNS. This phenomenon shows evidence for the quality issue we found for domain-specific data after generation. The  Gap Ratio , as introduced in Appendix  E.2  is  0.4682 0.4682 0.4682 0.4682  for FPB and  0.3663 0.3663 0.3663 0.3663  for TFNS, both below the heuristically drawn datum line of  0.5 0.5 0.5 0.5 .",
            "In order to discard the possibility that the pre-trained model has already seen those individual names (e.g.  John, Trump ) in our training datasets  D P  r  i subscript D P r i \\mathbb{D}_{Pri} blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT , we ask GPT-4  OpenAI ( 2023 )  to generate hundreds of unique names (e.g.  Anastasija, Melangell ) to substitute the original names. This technique addresses the potential privacy risk discussed in Appendix  A  and pave the groundwork for accurate experiments in Section  4.2 .",
            "To evaluate the name substitution technique, we follow the experimental setups in Section  4.2 , and compare reconstruction rates of different baselines before and after name substitution. The results in Table  9  reveal the effectiveness of our approach. Before name substitution, there is no distinguished gap between the different models. After name substitution, as expected, the pre-trained Llama2 exhibits no memorization, while the Non-private approach shows high memorization because of fine-tuning over private data. And the memorization issue is addressed through synthetic text generation.",
            "As shown in Table  12 ,  KnowledgeSG  outperforms ICL and Non-Private methods. The results confirm the effectiveness of  KnowledgeSG  in the math and code domain, further proving its generalizability. However, in the code domain, the performance gap between different methods is less pronounced compared to other domains. We attribute this to the suboptimal coding performance of pre-trained Llama2-7B, which may lack the capacity to generalize effectively on coding tasks. This finding aligns with related studies, where experiments on HumanEval are primarily conducted using the Llama2-13B model or larger variants  Luo et al. ( 2023 ); Xu et al. ( 2023 ) . The reason we prefer financial and medical domain than code and math is that math solving and code writing tasks are not directly related to privacy because there usually is no PIIs in these datasets."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Comparison with baselines on the financial benchmarks, where the sentiment analysis dataset from FinGPT  Yang et al. ( 2023 )  is used. Four evaluation datasets are considered, including FPB, FIQA-SA, TFNS, and NWGI. We also show results of GPT-3.5/4, Llama2-7B and FinGPT v3.3 for reference. We leverage Llama2-7B as the base model and FinGPT v3.3 as the professional model. The results demonstrate that  KnowledgeSG  outperforms all other baselines and is on par with the performance of GPT3.5/4.",
        "table": "S4.T3.1",
        "footnotes": [
            ""
        ],
        "references": [
            "We start by sampling a small amount of data from public datasets, e.g. Alpaca  Taori et al. ( 2023 ) , as the seed dataset  D S  e  e  d subscript D S e e d \\mathbb{D}_{Seed} blackboard_D start_POSTSUBSCRIPT italic_S italic_e italic_e italic_d end_POSTSUBSCRIPT , which is agreed and shared by the client and server at the beginning. Then we fine-tune the original base model  W L  o  c subscript W L o c \\mathbb{W}_{Loc} blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT  on  D S  e  e  d subscript D S e e d \\mathbb{D}_{Seed} blackboard_D start_POSTSUBSCRIPT italic_S italic_e italic_e italic_d end_POSTSUBSCRIPT  to create a full adaption of model weights and replace original  W L  o  c subscript W L o c \\mathbb{W}_{Loc} blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT  with the new model  W L  o  c  subscript superscript W  L o c \\mathbb{W}^{{}^{\\prime}}_{Loc} blackboard_W start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT  end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT . The local learning process described in Section  3.3  is based on  W L  o  c  subscript superscript W  L o c \\mathbb{W}^{{}^{\\prime}}_{Loc} blackboard_W start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT  end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT  afterwards. In this way, we make sure that, even if an adversarial eavesdropper intercepts the LoRA adapter  A D  P subscript A D P \\mathbb{A}_{DP} blackboard_A start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT , he cannot recover our entire model with the old version of base model  W L  o  c subscript W L o c \\mathbb{W}_{Loc} blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT  instead of  W L  o  c  subscript superscript W  L o c \\mathbb{W}^{{}^{\\prime}}_{Loc} blackboard_W start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT  end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT .",
            "Our baselines comprise one None-Private approach, one private approach with DP-SGD  Abadi et al. ( 2016 ) , and six private approaches using synthetic data generation, i.e. ICL  Dong et al. ( 2022 ) , Self-Instruct  Wang et al. ( 2022 ) , Self-Instruct-ICL, DP-Gene  Kurakin et al. ( 2024 ) , DP-Instruct  Yu et al. ( 2024 )  and DP-Instruct-ICL. The detailed comparison of baselines is shown in Table  14  in Appendix  F.3 .",
            "Table  3  demonstrates the results of our method and six other baselines using synthetic data generation on financial benchmarks. From the table, we can conclude that: (1)  KnowledgeSG  outperforms all other baselines on average, even better than using original private data, proving the effectiveness of knowledge distillation from professional model through our framework, not to mention our privacy-preserving nature. (2) For the FiQA-SA dataset, a large portion of the evaluation sample labels are  Neutral . Following the evaluation benchmarks  Yang ( 2023 ) , we treat responses with no predictions (Positive/Negative/Neutral) as  Neutral . This situation rarely happens except for pre-trained models that struggle with instruction following. Most of LLaMA2-7Bs responses are classified as  Neutral , thus explaining its unexpectedly strong performance on FiQA-SA. (3) Ignoring FiQA-SA, some synthetic generation baselines still perform even worse than the pre-trained Llama2 on FPB and TFNS. This phenomenon shows evidence for the quality issue we found for domain-specific data after generation. The  Gap Ratio , as introduced in Appendix  E.2  is  0.4682 0.4682 0.4682 0.4682  for FPB and  0.3663 0.3663 0.3663 0.3663  for TFNS, both below the heuristically drawn datum line of  0.5 0.5 0.5 0.5 .",
            "Instruction following difficulty (IFD) introduced by  Li et al. ( 2023a ) , evaluates how much help the instruction provides for the generation of corresponding response. It compares the change of losses in model responses with and without the instructional context, and outputs a ratio as the final score. A lower IFD score indicates better quality of the evaluated sample. Thus we apply IFD score to measure the utility and quality of the generated instruction tuning datasets. The average IFD scores of dataset samples before filtering are presented in Table  3 , exhibiting the disparity in the generation capabilities across various baselines. In practice, we deploy IFD score as the data filtering measure  Li et al. ( 2024b ); Zhang et al. ( 2024 )  in our framework. However, in consideration of fair comparison with other baselines, we exclude it from the experiments in Sections  4.3  and  4.4 .",
            "From Table  5  and Fig  3 , We can conclude that: (1) Although the absolute values of MAUVE and FID are influenced by the specific settings used in its calculation, e.g. scalar scaling constants, the relative rankings of different synthetic datasets remain consistent. Still,  KnowledgeSG  achieves the best similarity measured by the MAUVE score. For the FID score, our method is only second to DP-Instruct-ICL, an improved version we adopt from  Yu et al. ( 2024 ) . (2) The leading performance of  KnowledgeSG  indicates better quality of synthetic data compared to other baselines. This is consistent with the performance results in Section  4.4  (3) For instruction following difficulty, the results conform to those of embedding distribution similarity, further proving the effectiveness of our proposed method.",
            "As mentioned in Section  3 , filtration with model means that we prompt the professional model  W P  r  o subscript W P r o \\mathbb{W}_{Pro} blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT  with raw instructions for judgments. Then we filter out subpar instructions based on judgements.",
            "We follow the details for DP-finetuning in Appendix  F.1  and evaluate its performance on the financial domain, same as Section  4.3 .",
            "We choose GPT-4  OpenAI ( 2023 )  to be the datum model as we assume it is an all-around player that behaves well both on general tasks and domain-specific tasks. And the  Gap Ratio  is calculated by the ratio of target model results and GPT-4 results on the same evaluation benchmark. For example, from Table  13 , Llama2-7Bs  Gap Ratio  is  0.8722 0.8722 0.8722 0.8722  on Chatbot Arena and  0.7007 0.7007 0.7007 0.7007  on general benchmarks on average.",
            "No matter what the absolute value is in different measurements of model performance, we can apparently see that the gap between Llama2 and GPT will be greatly widened if changed from general to a specific domain. As in Table  13 , we draw a datum line of  0.5 0.5 0.5 0.5 , smaller than which indicates a tendency of worse synthetic generation."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Performance results and comparative analysis of free-form instruction evaluation in the medical domain.  KnowledgeSG  outperforms all other baselines and has a relative improvement of  120.39 % percent 120.39 120.39\\% 120.39 %  than Non-Private method. Numbers with underlines represent performance surpassing the professional model AlpaCare  Zhang et al. ( 2023 ) .",
        "table": "S4.T4.3",
        "footnotes": [
            ""
        ],
        "references": [
            "Finally, we use the generated instructions and responses sorted by the IFD score  Li et al. ( 2023a )  to normally (non-DP) fine-tune  W D  P subscript W D P \\mathbb{W}_{DP} blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT  and obtain the desired model  W T  a  r  g  e  t subscript W T a r g e t \\mathbb{W}_{Target} blackboard_W start_POSTSUBSCRIPT italic_T italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT . Further details and results regarding the IFD score are presented in Section  4.5 . At this stage, DP-finetuning is not needed, as we assume the refined synthetic data contains no sensitive information.",
            "If not otherwise mentioned, our base model is pre-trained Llama2-7B  Touvron et al. ( 2023b ) . We choose FinGPT  Yang ( 2023 )  and AlpaCare  Zhang et al. ( 2023 )  as our professional models for financial and medical domains respectively. The dataset sample is kept to  500 500 500 500  for any comparison except the ablation study in Section  4.6 . We use the name substitution technique in Appendix  B.2  to pre-process datasets, preventing inaccurate evaluation on privacy.",
            "Our baselines comprise one None-Private approach, one private approach with DP-SGD  Abadi et al. ( 2016 ) , and six private approaches using synthetic data generation, i.e. ICL  Dong et al. ( 2022 ) , Self-Instruct  Wang et al. ( 2022 ) , Self-Instruct-ICL, DP-Gene  Kurakin et al. ( 2024 ) , DP-Instruct  Yu et al. ( 2024 )  and DP-Instruct-ICL. The detailed comparison of baselines is shown in Table  14  in Appendix  F.3 .",
            "We utilize the HealthCareMagic-100k dataset 5 5 5 https://huggingface.co/datasets/lavita/ChatDoctor-HealthCareMagic-100k   Li et al. ( 2023c )  as our training dataset, since it contains many individual names (e.g. see Fig  4 ). This dataset consists of real conversations between patients and doctors collected from the HealthCareMagic website.",
            "From Table  4  and Table  10 , we can conclude that: (1) Considering both benchmark and free-form results,  KnowledgeSG  consistently and significantly surpasses all other baselines in the medical domain. Particularly in the free-from evaluation, our method outperforms all other synthetic text generation baselines to a large margin, even doubling the performance of the None-private approach using original private data. (2) DP-based generation methods achieve much higher win rate scores than that of Self-instruction-based methods. This is expected because DP-based methods require additionally differentially private fine-tuning of the base model on private data. (3) The free-form results of  KnowledgeSG  surpassing AlpaCare (underlined in Table  4 ) highlight the immense potential of synthetic generation approaches which acquire knowledge distillation from a professional model, inspiring future research to further explore this area.",
            "Note that the experiments in Section  4.5  are based on the same datasets we generated in Section  4.4 . For paraphrase-MiniLM-L6-v2, its FID score is about 10 times the absolute value of other embedding models. Therefore for an unbiased comparison, we scale its score to match the magnitude of others.",
            "Instruction following difficulty (IFD) introduced by  Li et al. ( 2023a ) , evaluates how much help the instruction provides for the generation of corresponding response. It compares the change of losses in model responses with and without the instructional context, and outputs a ratio as the final score. A lower IFD score indicates better quality of the evaluated sample. Thus we apply IFD score to measure the utility and quality of the generated instruction tuning datasets. The average IFD scores of dataset samples before filtering are presented in Table  3 , exhibiting the disparity in the generation capabilities across various baselines. In practice, we deploy IFD score as the data filtering measure  Li et al. ( 2024b ); Zhang et al. ( 2024 )  in our framework. However, in consideration of fair comparison with other baselines, we exclude it from the experiments in Sections  4.3  and  4.4 .",
            "From Table  5  and Fig  3 , We can conclude that: (1) Although the absolute values of MAUVE and FID are influenced by the specific settings used in its calculation, e.g. scalar scaling constants, the relative rankings of different synthetic datasets remain consistent. Still,  KnowledgeSG  achieves the best similarity measured by the MAUVE score. For the FID score, our method is only second to DP-Instruct-ICL, an improved version we adopt from  Yu et al. ( 2024 ) . (2) The leading performance of  KnowledgeSG  indicates better quality of synthetic data compared to other baselines. This is consistent with the performance results in Section  4.4  (3) For instruction following difficulty, the results conform to those of embedding distribution similarity, further proving the effectiveness of our proposed method.",
            "We perform an ablation study on dataset size to investigate its impact on the models final performance through synthetic data generation. The training and evaluation setups are the same as Section  4.4 . For a fair comparison, we make sure that each data sample is iterated  5 5 5 5  times by training the models for corresponding rounds wile keeping other parameters fixed (e.g., the 500-sample dataset is trained for  50 50 50 50  rounds, and the 1000-sample dataset for  100 100 100 100  rounds).",
            "To further validate the effectiveness of  KnowledgeSG  and ensure that no private data has been accessed by either the base model or the professional model, we conducted additional experiments using the ai-medical-chatbot dataset 8 8 8 https://huggingface.co/datasets/ruslanmv/ai-medical-chatbot , which was collected and released six months later than Llama2-7B and AlpaCare. We adhere to the experimental setups described in Section  4.4  and also employ Llama2-7B as the base model.",
            "In order to discard the possibility that the pre-trained model has already seen those individual names (e.g.  John, Trump ) in our training datasets  D P  r  i subscript D P r i \\mathbb{D}_{Pri} blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT , we ask GPT-4  OpenAI ( 2023 )  to generate hundreds of unique names (e.g.  Anastasija, Melangell ) to substitute the original names. This technique addresses the potential privacy risk discussed in Appendix  A  and pave the groundwork for accurate experiments in Section  4.2 .",
            "To evaluate the name substitution technique, we follow the experimental setups in Section  4.2 , and compare reconstruction rates of different baselines before and after name substitution. The results in Table  9  reveal the effectiveness of our approach. Before name substitution, there is no distinguished gap between the different models. After name substitution, as expected, the pre-trained Llama2 exhibits no memorization, while the Non-private approach shows high memorization because of fine-tuning over private data. And the memorization issue is addressed through synthetic text generation.",
            "We evaluate the same models as Section  4.4  on  3 3 3 3  medical question answering benchmarks including MedQA  Jin et al. ( 2021 ) , PubMedQA  Jin et al. ( 2019 ) , and MedMCQA  Pal et al. ( 2022 ) . We follow the code base of LMflow 9 9 9 https://github.com/OptimalScale/LMFlow   Diao et al. ( 2023 )  and use the prompt shown in Figure  6  to inference answers.",
            "From Table  10 , we can conclude that: (1) Compared to free-form evaluation in Section  4 , the results on medical benchmarks are more random. Along with the limit of performance ceiling, the gap between different methods are narrowed especially on MedQA and MedMCQA. (2) Our method still performs the best on average.",
            "Compared to the benchmark results in Table  10 , the gap between different baselines is much more pronounced and noticeable in the free-form evaluation in Table  4 , aligning more closely with expectations. We attribute the reasons as: (1) For MedQA and MedMCQA, the dataset we use is HealthCareMagic, whose purpose is to provide patients with consultant. This may not correspond with the nature of benchmarks to choose the right answer to a medicine-related question. (2) Benchmark results involve more randomness, thus improving the performance of inferior competitors to some extent.",
            "We follow the details for DP-finetuning in Appendix  F.1  and evaluate its performance on the financial domain, same as Section  4.3 .",
            "We show examples of PII from HealthCareMagic dataset in Fig  4 . Since our current focus is not on any specific category of leaked PII, we only evaluate Individual Name in Section  4  for convenience.",
            "To give a detailed comparison between different baselines in our experiments, we elaborate on three aspects in Table  14 , ranging from the model used for generating instructions, whether the baseline first generates instructions then responses and whether the baseline requires few-shot examples to generate response if it is twp-step. DP-Instruct-ICL and Self-Instruct-ICL are different from DP-Instruct and Self-Instruct in that they require few-shot examples from original dataset to produce better responses during the second stage of generation while the others do not. Theoretically, DP-Instruct performs better than Self-Instruct and DP-Gene performs better than ICL because of additional DP-finetuning of base model."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Embedding distribution distance between the synthetic and original data measured by the MAUVE and FID score. Better similarity indicates better quality of the synthetic data. The results on average reaffirm that  KnowledgeSG  has best data quality compared to other baselines.",
        "table": "S4.T5.8",
        "footnotes": [],
        "references": [
            "Finally, we use the generated instructions and responses sorted by the IFD score  Li et al. ( 2023a )  to normally (non-DP) fine-tune  W D  P subscript W D P \\mathbb{W}_{DP} blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT  and obtain the desired model  W T  a  r  g  e  t subscript W T a r g e t \\mathbb{W}_{Target} blackboard_W start_POSTSUBSCRIPT italic_T italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT . Further details and results regarding the IFD score are presented in Section  4.5 . At this stage, DP-finetuning is not needed, as we assume the refined synthetic data contains no sensitive information.",
            "Note that the experiments in Section  4.5  are based on the same datasets we generated in Section  4.4 . For paraphrase-MiniLM-L6-v2, its FID score is about 10 times the absolute value of other embedding models. Therefore for an unbiased comparison, we scale its score to match the magnitude of others.",
            "From Table  5  and Fig  3 , We can conclude that: (1) Although the absolute values of MAUVE and FID are influenced by the specific settings used in its calculation, e.g. scalar scaling constants, the relative rankings of different synthetic datasets remain consistent. Still,  KnowledgeSG  achieves the best similarity measured by the MAUVE score. For the FID score, our method is only second to DP-Instruct-ICL, an improved version we adopt from  Yu et al. ( 2024 ) . (2) The leading performance of  KnowledgeSG  indicates better quality of synthetic data compared to other baselines. This is consistent with the performance results in Section  4.4  (3) For instruction following difficulty, the results conform to those of embedding distribution similarity, further proving the effectiveness of our proposed method.",
            "Deploying an LLM to generate new synthetic data from the original private data is just like asking a student to read an examination question and try to create a new copy of it. Naturally, the quality of the rewritten question is highly dependent on how the student understands the original question, and how he may generalize. As illustrated in Fig  5 , a Ph.D. student will behave well on general questions, e.g. Alpaca 16 16 16 https://huggingface.co/datasets/tatsu-lab/alpaca   Taori et al. ( 2023 ) . But if you ask a kindergarten student to create a new calculus test based on several examples, e.g. Math 17 17 17 https://huggingface.co/datasets/lighteval/MATH   Hendrycks et al. ( 2021b ) , it is highly unlikely that he can fulfil this task."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Ablations on dataset size. With more data involved, the model performance improves as expected.",
        "table": "S4.T6.1",
        "footnotes": [],
        "references": [
            "If not otherwise mentioned, our base model is pre-trained Llama2-7B  Touvron et al. ( 2023b ) . We choose FinGPT  Yang ( 2023 )  and AlpaCare  Zhang et al. ( 2023 )  as our professional models for financial and medical domains respectively. The dataset sample is kept to  500 500 500 500  for any comparison except the ablation study in Section  4.6 . We use the name substitution technique in Appendix  B.2  to pre-process datasets, preventing inaccurate evaluation on privacy.",
            "For all methods shown in Table  6 , the results indicate that as the amount of involved data increases, the performance of the trained model improves correspondingly. However, the last row of  KnowledgeSG  suggests that the improvement from accumulating additional data may reach a potential threshold. We leave further exploration of this for future work.",
            "We evaluate the same models as Section  4.4  on  3 3 3 3  medical question answering benchmarks including MedQA  Jin et al. ( 2021 ) , PubMedQA  Jin et al. ( 2019 ) , and MedMCQA  Pal et al. ( 2022 ) . We follow the code base of LMflow 9 9 9 https://github.com/OptimalScale/LMFlow   Diao et al. ( 2023 )  and use the prompt shown in Figure  6  to inference answers."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Experiments of proposed transmitting unit. The  Relative Drop  in performance suggests that our model is safeguarded against the attacker during transmission.",
        "table": "S4.T7.1",
        "footnotes": [],
        "references": [
            "Results in Table  7  show that the performance of model stolen by the attacker drops significantly compared to  KnowledgeSG . This demonstrates that our model is not compromised, confirming the efficacy of proposed transmitting unit.",
            "We use VLLM  Kwon et al. ( 2023 )  for faster inferencing and set the max-model-len to as long as  2048 2048 2048 2048  to obtain more information. The inferencing experiments are mostly conducted on A100 40G. We set temperature to 0.7 to encourage diversity. We follow in-context learning  Dong et al. ( 2022 )  and self-instruct  Wang et al. ( 2022 )  to formulate our prompts. The prompt templates we employ are shown in Figure  7  and  8 . To make sure we have enough instructions for subsequent filtering, the generation times are set two times of the original dataset size. To ensure sufficient instructions for subsequent filtering, the generation count is set to twice the size of the original dataset. For instruction extraction and pre-processing, we extract the first instruction the model generates and filter those shorter than 2 tokens."
        ]
    },
    "id_table_8": {
        "caption": "Table 8:  Free-form evaluation results using medical-ai-chatbot as the private dataset.",
        "table": "A1.T8.1",
        "footnotes": [],
        "references": [
            "The results presented in Table  8 , reaffirm the effectiveness of  KnowledgeSG , regardless of whether the models had access to the private dataset. It also shows that  KnowledgeSG  can generalize well across different datasets. Additionally, they demonstrate that  KnowledgeSG  generalizes well across different datasets. Llama2 trained on the ai-medical-chatbot dataset yields lower scores compared to its training on HealthCareMagic, indicating that the latter dataset may have higher quality.",
            "We use VLLM  Kwon et al. ( 2023 )  for faster inferencing and set the max-model-len to as long as  2048 2048 2048 2048  to obtain more information. The inferencing experiments are mostly conducted on A100 40G. We set temperature to 0.7 to encourage diversity. We follow in-context learning  Dong et al. ( 2022 )  and self-instruct  Wang et al. ( 2022 )  to formulate our prompts. The prompt templates we employ are shown in Figure  7  and  8 . To make sure we have enough instructions for subsequent filtering, the generation times are set two times of the original dataset size. To ensure sufficient instructions for subsequent filtering, the generation count is set to twice the size of the original dataset. For instruction extraction and pre-processing, we extract the first instruction the model generates and filter those shorter than 2 tokens."
        ]
    },
    "id_table_9": {
        "caption": "Table 9:  Reconstruction rate comparison  Before  and  After  name substitution using Flair as the NER extraction tool. The expansion of the gap between Non-Private and Synthetic methods validates our name substitution approach.",
        "table": "A2.T9.1",
        "footnotes": [],
        "references": [
            "To evaluate the name substitution technique, we follow the experimental setups in Section  4.2 , and compare reconstruction rates of different baselines before and after name substitution. The results in Table  9  reveal the effectiveness of our approach. Before name substitution, there is no distinguished gap between the different models. After name substitution, as expected, the pre-trained Llama2 exhibits no memorization, while the Non-private approach shows high memorization because of fine-tuning over private data. And the memorization issue is addressed through synthetic text generation."
        ]
    },
    "id_table_10": {
        "caption": "Table 10:  Performance results on medical domain. Comparative analysis of free-form instruction evaluation.",
        "table": "A3.T10.1",
        "footnotes": [],
        "references": [
            "From Table  4  and Table  10 , we can conclude that: (1) Considering both benchmark and free-form results,  KnowledgeSG  consistently and significantly surpasses all other baselines in the medical domain. Particularly in the free-from evaluation, our method outperforms all other synthetic text generation baselines to a large margin, even doubling the performance of the None-private approach using original private data. (2) DP-based generation methods achieve much higher win rate scores than that of Self-instruction-based methods. This is expected because DP-based methods require additionally differentially private fine-tuning of the base model on private data. (3) The free-form results of  KnowledgeSG  surpassing AlpaCare (underlined in Table  4 ) highlight the immense potential of synthetic generation approaches which acquire knowledge distillation from a professional model, inspiring future research to further explore this area.",
            "For domain-specific settings such as the medical domain, the judgements are mainly based on whether the tested instructions are related to particular medical knowledge. We first prompt AlpaCare using the template written in Figure  10 , then extract judgements from the model outputs. In experiments, we also try GPT-3.5-turbo as the domain classifier of instructions and receive acceptable results.",
            "From Table  10 , we can conclude that: (1) Compared to free-form evaluation in Section  4 , the results on medical benchmarks are more random. Along with the limit of performance ceiling, the gap between different methods are narrowed especially on MedQA and MedMCQA. (2) Our method still performs the best on average.",
            "Compared to the benchmark results in Table  10 , the gap between different baselines is much more pronounced and noticeable in the free-form evaluation in Table  4 , aligning more closely with expectations. We attribute the reasons as: (1) For MedQA and MedMCQA, the dataset we use is HealthCareMagic, whose purpose is to provide patients with consultant. This may not correspond with the nature of benchmarks to choose the right answer to a medicine-related question. (2) Benchmark results involve more randomness, thus improving the performance of inferior competitors to some extent."
        ]
    },
    "id_table_11": {
        "caption": "Table 11:  Comparison of Non-Private approach with DP-SGD. The drop in performance validates the limitations of relying on DP-SGD only.",
        "table": "A3.T11.1",
        "footnotes": [],
        "references": [
            "Fine-tuning models to satisfies DP can only address the risk of memorization. There is no protection during the data collection stage where the user instructions are exposed to human annotators for response generation  Yu et al. ( 2024 ) . Moreover, using DP-SGD to prevent memorization by adding noise into the training process is destined to sacrifice performance. As proved in our experiments in Table  11 , employing DP-SGD alone leads to considerable performance drop.",
            "From the results in Table  11 , we can conclude that relying on DP-SGD only results in a considerable decline of performance, necessitating our approach of synthetic data generation with knowledge distillation from server."
        ]
    },
    "id_table_12": {
        "caption": "Table 12:  Performance results on mathematical and code domains. The relative improvement of KnowledgeSG over Non-Private and ICL demonstrates the generalizability of  KnowledgeSG . We show accuracy and Pass@10 for GSM8K and HumanEval respectively.   *: Given that privacy concerns are not the primary issue in the generation of synthetic data for mathematical and code domains, we adopt a simplified version which focuses on knowledge distillation for convenience. This approach excludes differential privacy fine-tuning, instruction filtration, and the transmitting unit.",
        "table": "A3.T12.1",
        "footnotes": [],
        "references": [
            "As shown in Table  12 ,  KnowledgeSG  outperforms ICL and Non-Private methods. The results confirm the effectiveness of  KnowledgeSG  in the math and code domain, further proving its generalizability. However, in the code domain, the performance gap between different methods is less pronounced compared to other domains. We attribute this to the suboptimal coding performance of pre-trained Llama2-7B, which may lack the capacity to generalize effectively on coding tasks. This finding aligns with related studies, where experiments on HumanEval are primarily conducted using the Llama2-13B model or larger variants  Luo et al. ( 2023 ); Xu et al. ( 2023 ) . The reason we prefer financial and medical domain than code and math is that math solving and code writing tasks are not directly related to privacy because there usually is no PIIs in these datasets."
        ]
    },
    "id_table_13": {
        "caption": "Table 13:  Comparison between {Llama2-7B, Llam2-7B-Chat} and {GPT-4, ChatGPT } on general benchmarks including Chatbot Arena Leaderboard, MT-Bench, MMLU  Chiang et al. ( 2024 ); Hendrycks et al. ( 2021a ); Zheng et al. ( 2023 )  and domain-specific benchmarks including FPB, PubMedQA Malo et al. ( 2014 ); Jin et al. ( 2019 ) . Results with tagger* is collected from  Zhang et al. ( 2023 ) . Results with    and    indicate whether the  Gap Ratio  exceeds the datum line of  0.5 0.5 0.5 0.5  or not.",
        "table": "A5.T13.6",
        "footnotes": [
            "",
            "",
            "",
            "",
            "",
            ""
        ],
        "references": [
            "We choose GPT-4  OpenAI ( 2023 )  to be the datum model as we assume it is an all-around player that behaves well both on general tasks and domain-specific tasks. And the  Gap Ratio  is calculated by the ratio of target model results and GPT-4 results on the same evaluation benchmark. For example, from Table  13 , Llama2-7Bs  Gap Ratio  is  0.8722 0.8722 0.8722 0.8722  on Chatbot Arena and  0.7007 0.7007 0.7007 0.7007  on general benchmarks on average.",
            "No matter what the absolute value is in different measurements of model performance, we can apparently see that the gap between Llama2 and GPT will be greatly widened if changed from general to a specific domain. As in Table  13 , we draw a datum line of  0.5 0.5 0.5 0.5 , smaller than which indicates a tendency of worse synthetic generation."
        ]
    },
    "id_table_14": {
        "caption": "Table 14:  Elaboration of baselines.  Model  means the generative model used for generating synthetic instructions.  Twp-Step  means whether the baseline first generates instructions then responses or generates both instructions and responses meanwhile.  ICL  means whether the baseline requires few-shot examples from original dataset to generate response at the second stage.",
        "table": "A6.T14.1",
        "footnotes": [],
        "references": [
            "Our baselines comprise one None-Private approach, one private approach with DP-SGD  Abadi et al. ( 2016 ) , and six private approaches using synthetic data generation, i.e. ICL  Dong et al. ( 2022 ) , Self-Instruct  Wang et al. ( 2022 ) , Self-Instruct-ICL, DP-Gene  Kurakin et al. ( 2024 ) , DP-Instruct  Yu et al. ( 2024 )  and DP-Instruct-ICL. The detailed comparison of baselines is shown in Table  14  in Appendix  F.3 .",
            "To give a detailed comparison between different baselines in our experiments, we elaborate on three aspects in Table  14 , ranging from the model used for generating instructions, whether the baseline first generates instructions then responses and whether the baseline requires few-shot examples to generate response if it is twp-step. DP-Instruct-ICL and Self-Instruct-ICL are different from DP-Instruct and Self-Instruct in that they require few-shot examples from original dataset to produce better responses during the second stage of generation while the others do not. Theoretically, DP-Instruct performs better than Self-Instruct and DP-Gene performs better than ICL because of additional DP-finetuning of base model."
        ]
    }
}