{
    "id_table_1": {
        "caption": "Table 1.  Configuration choices related to UserKNN made by LensKit for Python and Cornac.",
        "table": "S3.T1.1",
        "footnotes": [],
        "references": [
            "Figures  1a  to  1e  show the correlation between item average rating and item popularity within the five synthetic datasets. There is a noticeable effect of the data characteristics discussed in this study, given that the synthetic datasets were constructed with them in mind. Specifically, scenario 1 shows no relation between average rating and popularity, as the ratings were drawn uniformly at random. Scenarios 2 and 3 showcase a very positive and a very negative correlation, respectively. For scenario 4, we see a positive correlation, which is higher for users with large profiles, and for scenario 5 a negative correlation, even lower for users with large profiles.",
            "It is worth noting that LensKit and Cornac differ when it comes to these choices as seen in Table  1 . Two of the parameters tested are not configurable in Cornac, while the third is not configurable in either frameworks.",
            "In this section, we describe the experiments that we run in order to determine the effect of data characteristics and algorithm configuration on the propagation of popularity bias. The Jupyter notebooks that contain the experiments 3 3 3 https://github.com/SavvinaDaniil/DiagnosingBiasRecSys/  have been made open source. For every synthetic data scenario, we perform a recommendation process given every version of UserKNN. Specifically, we test the following versions given the configurations discussed in section  3.2.1 :",
            "For scenario  1  where ratings are uniformly at random generated, there is no notable popularity bias propagation observed when minimum neighbours are set to 1, while there is bias when minimum neighbours is set to 2. Increasing minimum neighbours results in higher popularity bias for all datasets and metrics."
        ]
    },
    "id_table_2": {
        "caption": "Table 2.  Popularity bias and performance of different UserKNN configurations given different data scenarios. OverCommon set to True corresponds to the Cornac implementation, and set to False to the LensKit implementation. For the popularity bias metrics, we embolden the highest value among configurations. For ARP and PL, we use the asterisk (*) to signify which values are significantly lower than the highest one according to a MannWhitney  U U U italic_U  test with  p < 0.005 p 0.005 p<0.005 italic_p < 0.005 .",
        "table": "S5.T2.9",
        "footnotes": [],
        "references": [
            "In this section, we describe the experiments that we run in order to determine the effect of data characteristics and algorithm configuration on the propagation of popularity bias. The Jupyter notebooks that contain the experiments 3 3 3 https://github.com/SavvinaDaniil/DiagnosingBiasRecSys/  have been made open source. For every synthetic data scenario, we perform a recommendation process given every version of UserKNN. Specifically, we test the following versions given the configurations discussed in section  3.2.1 :",
            "In this section, we provide insights into how UserKNN configurations impact popularity bias and performance for the different datasets by presenting the results across the set of metrics listed in section  4  in table  2 .",
            "Performance varies across the data scenarios. RMSE specifically is lower for scenarios  2  and  3  compared to the other three. In these two scenarios, users tend to agree between them on whether they like popular items or not, which facilitates the rating prediction task. NDCG@10 is the highest for scenario  2 , where popular items are highly rated by the users. In this case, the rating prediction and ranking tasks are linked, since the highest ranked (i.e., popular items) are also highly rated.",
            "When considering only common items to calculate similarity, users with smaller profiles have a larger influence. This is relevant in scenario  4  where users with large profiles like popular items. Table  2  shows that even though scenario  4  still leads to popularity bias, considering only common items reduces it across all metrics. Therefore, this implementation choice can have a big impact on whether popularity bias is propagated and to what extent."
        ]
    }
}