{
    "S3.T1": {
        "caption": "Table 1. Question type definition for the GQA dataset.",
        "table": "<table id=\"S3.T1.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S3.T1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_p\" style=\"width:37.3pt;\"><span id=\"S3.T1.1.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Type </span><math id=\"S3.T1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"t\" display=\"inline\"><semantics id=\"S3.T1.1.1.1.1.1.m1.1a\"><mi mathsize=\"80%\" id=\"S3.T1.1.1.1.1.1.m1.1.1\" xref=\"S3.T1.1.1.1.1.1.m1.1.1.cmml\">t</mi><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.1.1.1.1.1.m1.1b\"><ci id=\"S3.T1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T1.1.1.1.1.1.m1.1.1\">ğ‘¡</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.1.1.1.1.1.m1.1c\">t</annotation></semantics></math></span>\n</span>\n</th>\n<th id=\"S3.T1.2.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S3.T1.2.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.2.2.1.1\" class=\"ltx_p\" style=\"width:368.6pt;\"><span id=\"S3.T1.2.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Definition </span><math id=\"S3.T1.2.2.2.1.1.m1.1\" class=\"ltx_Math\" alttext=\"d_{t}\" display=\"inline\"><semantics id=\"S3.T1.2.2.2.1.1.m1.1a\"><msub id=\"S3.T1.2.2.2.1.1.m1.1.1\" xref=\"S3.T1.2.2.2.1.1.m1.1.1.cmml\"><mi mathsize=\"80%\" id=\"S3.T1.2.2.2.1.1.m1.1.1.2\" xref=\"S3.T1.2.2.2.1.1.m1.1.1.2.cmml\">d</mi><mi mathsize=\"80%\" id=\"S3.T1.2.2.2.1.1.m1.1.1.3\" xref=\"S3.T1.2.2.2.1.1.m1.1.1.3.cmml\">t</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.2.2.2.1.1.m1.1b\"><apply id=\"S3.T1.2.2.2.1.1.m1.1.1.cmml\" xref=\"S3.T1.2.2.2.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.T1.2.2.2.1.1.m1.1.1.1.cmml\" xref=\"S3.T1.2.2.2.1.1.m1.1.1\">subscript</csymbol><ci id=\"S3.T1.2.2.2.1.1.m1.1.1.2.cmml\" xref=\"S3.T1.2.2.2.1.1.m1.1.1.2\">ğ‘‘</ci><ci id=\"S3.T1.2.2.2.1.1.m1.1.1.3.cmml\" xref=\"S3.T1.2.2.2.1.1.m1.1.1.3\">ğ‘¡</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.2.2.2.1.1.m1.1c\">d_{t}</annotation></semantics></math></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.2.3.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.3.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span id=\"S3.T1.2.3.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.3.1.1.1.1\" class=\"ltx_p\" style=\"width:37.3pt;\"><span id=\"S3.T1.2.3.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">obj</span></span>\n</span>\n</td>\n<td id=\"S3.T1.2.3.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" style=\"background-color:#ECECEC;\">\n<span id=\"S3.T1.2.3.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.3.1.2.1.1\" class=\"ltx_p\" style=\"width:368.6pt;\"><span id=\"S3.T1.2.3.1.2.1.1.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;background-color:#ECECEC;\">question asking existence of object.</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.4.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.4.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.4.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.4.2.1.1.1\" class=\"ltx_p\" style=\"width:37.3pt;\"><span id=\"S3.T1.2.4.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">cat</span></span>\n</span>\n</td>\n<td id=\"S3.T1.2.4.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"background-color:#ECECEC;\">\n<span id=\"S3.T1.2.4.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.4.2.2.1.1\" class=\"ltx_p\" style=\"width:368.6pt;\"><span id=\"S3.T1.2.4.2.2.1.1.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;background-color:#ECECEC;\">question related to object identification within some category.</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.5.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.5.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.5.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.5.3.1.1.1\" class=\"ltx_p\" style=\"width:37.3pt;\"><span id=\"S3.T1.2.5.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">attr</span></span>\n</span>\n</td>\n<td id=\"S3.T1.2.5.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"background-color:#ECECEC;\">\n<span id=\"S3.T1.2.5.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.5.3.2.1.1\" class=\"ltx_p\" style=\"width:368.6pt;\"><span id=\"S3.T1.2.5.3.2.1.1.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;background-color:#ECECEC;\">question asking about the attributes or position of an object. (e.g. \"What is the color of bar?\", \"On which of image is the foo?\")</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.6.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.6.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S3.T1.2.6.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.6.4.1.1.1\" class=\"ltx_p\" style=\"width:37.3pt;\"><span id=\"S3.T1.2.6.4.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">rel</span></span>\n</span>\n</td>\n<td id=\"S3.T1.2.6.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"background-color:#ECECEC;\">\n<span id=\"S3.T1.2.6.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.6.4.2.1.1\" class=\"ltx_p\" style=\"width:368.6pt;\"><span id=\"S3.T1.2.6.4.2.1.1.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;background-color:#ECECEC;\">question derived from an affirmative sentence and asking about its subject or object (e.g. \"What is the foo next to the baz wearing?\", \"Is the qux holding a quux?\").</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S3.T1.2.7.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.2.7.5.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S3.T1.2.7.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.7.5.1.1.1\" class=\"ltx_p\" style=\"width:37.3pt;\"><span id=\"S3.T1.2.7.5.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">global</span></span>\n</span>\n</td>\n<td id=\"S3.T1.2.7.5.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\" style=\"background-color:#ECECEC;\">\n<span id=\"S3.T1.2.7.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.2.7.5.2.1.1\" class=\"ltx_p\" style=\"width:368.6pt;\"><span id=\"S3.T1.2.7.5.2.1.1.1\" class=\"ltx_text ltx_font_typewriter\" style=\"font-size:80%;background-color:#ECECEC;\">question asking about the entire situation of the scene, such as weather or facility (e.g. \"Is it foo?\").</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "where ppresubscriptğ‘prep_{\\text{\\scriptsize pre}} is the original preprompt,\nrcodesubscriptğ‘Ÿcoder_{\\text{\\scriptsize code}} is the instruction to write code snippets, rspsubscriptğ‘Ÿspr_{\\text{\\scriptsize sp}} is an additional instruction to write code specialized for a specific question type with a placeholder to insert the definition of question type dtsubscriptğ‘‘ğ‘¡d_{t}, and tâˆˆYğ‘¡ğ‘Œt\\in Y is a question type.\nFigureÂ 3b and 3c show the definitions of rcodesubscriptğ‘Ÿcoder_{\\text{\\scriptsize code}} and rspsubscriptğ‘Ÿspr_{\\text{\\scriptsize sp}}, respectively.\nHere, we assumed that a pre-defined set of question types Yğ‘ŒY is given.\nFor example, with the GQA datasetÂ (Hudson and Manning, 2019), five question types shown in TableÂ 1 are provided with their definitions."
        ]
    },
    "S4.T2": {
        "caption": "Table 2. Comparison with other methods. AdaCoder is compared with ViperGPTÂ (SurÃ­s etÂ al., 2023), LLMLinguaÂ (Jiang etÂ al., 2023), and Simple compression that omits QA classification prompts.",
        "table": "<table id=\"S4.T2.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.3.4.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T2.3.4.1.1.1\" class=\"ltx_text\">Method</span></th>\n<th id=\"S4.T2.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T2.3.4.1.2.1\" class=\"ltx_text\">LLM</span></th>\n<th id=\"S4.T2.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"3\">Accuracy (%)</th>\n<th id=\"S4.T2.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"3\">Input prompt</th>\n<th id=\"S4.T2.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Output</th>\n</tr>\n<tr id=\"S4.T2.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.3.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">GQA</th>\n<th id=\"S4.T2.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">VQAv2</th>\n<th id=\"S4.T2.3.3.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">NLVR2</th>\n<th id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Token length <math id=\"S4.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.m1.1.1.cmml\">â†“</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.m1.1b\"><ci id=\"S4.T2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1\">â†“</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S4.T2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Characters <math id=\"S4.T2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.2.2.2.m1.1.1\" xref=\"S4.T2.2.2.2.m1.1.1.cmml\">â†“</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.m1.1b\"><ci id=\"S4.T2.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1\">â†“</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S4.T2.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">Reduction <math id=\"S4.T2.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.3.3.3.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.3.3.3.m1.1.1\" xref=\"S4.T2.3.3.3.m1.1.1.cmml\">â†‘</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.3.3.m1.1b\"><ci id=\"S4.T2.3.3.3.m1.1.1.cmml\" xref=\"S4.T2.3.3.3.m1.1.1\">â†‘</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.3.3.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"S4.T2.3.3.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Token length</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.3.5.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.5.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">ViperGPT baseline</td>\n<td id=\"S4.T2.3.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">gpt-3.5-turbo</td>\n<td id=\"S4.T2.3.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">41.3</td>\n<td id=\"S4.T2.3.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">42.7</td>\n<td id=\"S4.T2.3.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">59.2</td>\n<td id=\"S4.T2.3.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">3,434</td>\n<td id=\"S4.T2.3.5.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">15,950</td>\n<td id=\"S4.T2.3.5.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S4.T2.3.5.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">78</td>\n</tr>\n<tr id=\"S4.T2.3.6.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.6.2.1\" class=\"ltx_td ltx_align_left ltx_border_r\">LLMLingua</td>\n<td id=\"S4.T2.3.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">gpt-3.5-turbo</td>\n<td id=\"S4.T2.3.6.2.3\" class=\"ltx_td ltx_align_center\">39.1</td>\n<td id=\"S4.T2.3.6.2.4\" class=\"ltx_td ltx_align_center\">45.2</td>\n<td id=\"S4.T2.3.6.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">47.3</td>\n<td id=\"S4.T2.3.6.2.6\" class=\"ltx_td ltx_align_center\">2,536</td>\n<td id=\"S4.T2.3.6.2.7\" class=\"ltx_td ltx_align_center\">11,507</td>\n<td id=\"S4.T2.3.6.2.8\" class=\"ltx_td ltx_align_center ltx_border_r\">26.2%</td>\n<td id=\"S4.T2.3.6.2.9\" class=\"ltx_td ltx_align_center\">71</td>\n</tr>\n<tr id=\"S4.T2.3.7.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.7.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Simple compression</td>\n<td id=\"S4.T2.3.7.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">gpt-3.5-turbo</td>\n<td id=\"S4.T2.3.7.3.3\" class=\"ltx_td ltx_align_center\">28.9</td>\n<td id=\"S4.T2.3.7.3.4\" class=\"ltx_td ltx_align_center\">42.6</td>\n<td id=\"S4.T2.3.7.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">50.3</td>\n<td id=\"S4.T2.3.7.3.6\" class=\"ltx_td ltx_align_center\">810</td>\n<td id=\"S4.T2.3.7.3.7\" class=\"ltx_td ltx_align_center\">3,553</td>\n<td id=\"S4.T2.3.7.3.8\" class=\"ltx_td ltx_align_center ltx_border_r\">76.4%</td>\n<td id=\"S4.T2.3.7.3.9\" class=\"ltx_td ltx_align_center\">80</td>\n</tr>\n<tr id=\"S4.T2.3.8.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.8.4.1\" class=\"ltx_td ltx_align_left ltx_border_r\">AdaCoder (Ours)</td>\n<td id=\"S4.T2.3.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">gpt-3.5-turbo</td>\n<td id=\"S4.T2.3.8.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.8.4.3.1\" class=\"ltx_text ltx_font_bold\">43.6</span></td>\n<td id=\"S4.T2.3.8.4.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.8.4.4.1\" class=\"ltx_text ltx_font_bold\">46.2</span></td>\n<td id=\"S4.T2.3.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.3.8.4.5.1\" class=\"ltx_text ltx_font_bold\">60.8</span></td>\n<td id=\"S4.T2.3.8.4.6\" class=\"ltx_td ltx_align_center\">993</td>\n<td id=\"S4.T2.3.8.4.7\" class=\"ltx_td ltx_align_center\">4,343</td>\n<td id=\"S4.T2.3.8.4.8\" class=\"ltx_td ltx_align_center ltx_border_r\">71.1%</td>\n<td id=\"S4.T2.3.8.4.9\" class=\"ltx_td ltx_align_center\">77</td>\n</tr>\n<tr id=\"S4.T2.3.9.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.9.5.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">ViperGPT baseline</td>\n<td id=\"S4.T2.3.9.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">claude-3-haiku</td>\n<td id=\"S4.T2.3.9.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">40.4</td>\n<td id=\"S4.T2.3.9.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">42.6</td>\n<td id=\"S4.T2.3.9.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.3.9.5.5.1\" class=\"ltx_text ltx_font_bold\">60.1</span></td>\n<td id=\"S4.T2.3.9.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\">3,777</td>\n<td id=\"S4.T2.3.9.5.7\" class=\"ltx_td ltx_align_center ltx_border_t\">15,950</td>\n<td id=\"S4.T2.3.9.5.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S4.T2.3.9.5.9\" class=\"ltx_td ltx_align_center ltx_border_t\">300</td>\n</tr>\n<tr id=\"S4.T2.3.10.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.10.6.1\" class=\"ltx_td ltx_align_left ltx_border_r\">LLMLingua</td>\n<td id=\"S4.T2.3.10.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">claude-3-haiku</td>\n<td id=\"S4.T2.3.10.6.3\" class=\"ltx_td ltx_align_center\">37.0</td>\n<td id=\"S4.T2.3.10.6.4\" class=\"ltx_td ltx_align_center\">43.1</td>\n<td id=\"S4.T2.3.10.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\">59.5</td>\n<td id=\"S4.T2.3.10.6.6\" class=\"ltx_td ltx_align_center\">2,766</td>\n<td id=\"S4.T2.3.10.6.7\" class=\"ltx_td ltx_align_center\">11,507</td>\n<td id=\"S4.T2.3.10.6.8\" class=\"ltx_td ltx_align_center ltx_border_r\">26.8%</td>\n<td id=\"S4.T2.3.10.6.9\" class=\"ltx_td ltx_align_center\">306</td>\n</tr>\n<tr id=\"S4.T2.3.11.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.11.7.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Simple compression</td>\n<td id=\"S4.T2.3.11.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">claude-3-haiku</td>\n<td id=\"S4.T2.3.11.7.3\" class=\"ltx_td ltx_align_center\">14.5</td>\n<td id=\"S4.T2.3.11.7.4\" class=\"ltx_td ltx_align_center\">23.6</td>\n<td id=\"S4.T2.3.11.7.5\" class=\"ltx_td ltx_align_center ltx_border_r\">54,3</td>\n<td id=\"S4.T2.3.11.7.6\" class=\"ltx_td ltx_align_center\">1,181</td>\n<td id=\"S4.T2.3.11.7.7\" class=\"ltx_td ltx_align_center\">4,535</td>\n<td id=\"S4.T2.3.11.7.8\" class=\"ltx_td ltx_align_center ltx_border_r\">68.7%</td>\n<td id=\"S4.T2.3.11.7.9\" class=\"ltx_td ltx_align_center\">245</td>\n</tr>\n<tr id=\"S4.T2.3.12.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.12.8.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">AdaCoder (Ours)</td>\n<td id=\"S4.T2.3.12.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">claude-3-haiku</td>\n<td id=\"S4.T2.3.12.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.3.12.8.3.1\" class=\"ltx_text ltx_font_bold\">41.6</span></td>\n<td id=\"S4.T2.3.12.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.3.12.8.4.1\" class=\"ltx_text ltx_font_bold\">44.7</span></td>\n<td id=\"S4.T2.3.12.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.3.12.8.5.1\" class=\"ltx_text ltx_font_bold\">60.1</span></td>\n<td id=\"S4.T2.3.12.8.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">1,170</td>\n<td id=\"S4.T2.3.12.8.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">4,503</td>\n<td id=\"S4.T2.3.12.8.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">69.0%</td>\n<td id=\"S4.T2.3.12.8.9\" class=\"ltx_td ltx_align_center ltx_border_bb\">234</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "QA accuracy.\nTableÂ 2 shows QA accuracy in comparison to the ViperGPT baseline. We see that AdaCoder reduces the input token length by 71.1%, while improving QA accuracy on all of the three datasets. This shows the effectiveness and efficiency of the proposed prompt compression method.",
            "With LLMLingua, we observed that it cannot maintain the structure of code snippets in the preprompt after compression at a reduction rate of 71.1% (the same rate as ours), resulting in a QA accuracy of 0%. Therefore, the results in TableÂ 2 are given at a lower reduction rate â‰ƒsimilar-to-or-equals\\simeq 25% by adjusting the compression ratio parameter accordingly.\nWith this setting, LLMs can generate executable code with a probability of 98%; however, the QA accuracy is degraded by 2.2 points on GQA.\nThis shows that prompt compression for VPMs is challenging.\nIt is also worth noting that while our method is effective, it relies on QA classification and is not inherently a robust compression approach across all problems."
        ]
    },
    "S4.T3": {
        "caption": "Table 3. Analysis on effect of question type classification.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">Method</th>\n<th id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">Token length</th>\n<th id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">Accuracy (%)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">w/ Predicted question types</th>\n<td id=\"S4.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">993</td>\n<td id=\"S4.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">43.6</td>\n</tr>\n<tr id=\"S4.T3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">w/ Oracle question types</th>\n<td id=\"S4.T3.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">851</td>\n<td id=\"S4.T3.1.3.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">44.5</td>\n</tr>\n<tr id=\"S4.T3.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">w/ Random question types</th>\n<td id=\"S4.T3.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">851</td>\n<td id=\"S4.T3.1.4.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">37.6</td>\n</tr>\n<tr id=\"S4.T3.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">w/o Q. type based compression</th>\n<td id=\"S4.T3.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">810</td>\n<td id=\"S4.T3.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.2pt;padding-right:3.2pt;\">28.9</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "To investigate how these classification errors affect the final QA accuracy, TableÂ 3 compares AdaCoder using 1) predicted question types, 2) ground-truth question types, 3) random question types, and 4) without using question type based compression.\nWe observe three key findings.\nFirst, the best performance is achieved by using ground truth question types. This highlights the importance of classifying question types to improve overall accuracy.\nSecond, the performance drop due to classification errors is less than 1.0 points.\nThis suggests that AdaCoder effectively classified the critical question types necessary for code generation, even though the accuracy for question classification is not very high.\nThird, the method using random question types, which compresses prompts for each question type and randomly choose one of them in inference, is better than the method without question type based compression.\nThis is because the instruction prompt rspsubscriptğ‘Ÿspr_{\\text{\\scriptsize sp}} in Eq.Â (7) for specializing code snippets to each question type makes it more likely to provide code snippets that are related to each other, thereby increasing the probability of completing the program. When this instruction is omitted and compression is performed regardless of the question type, code snippets that are effective for any question type tend to be retained after compression.\nHowever, this approach results in the loss of some specific snippets that are necessary to complete the program, thereby reducing QA accuracy. These results suggest that the instruction rspsubscriptğ‘Ÿspr_{\\text{\\scriptsize sp}} is important for compressing code snippets."
        ]
    },
    "S4.T4": {
        "caption": "Table 4. Token length and number of characters for each component of input prompt. Reduction rate is measured by token length.",
        "table": "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-left:1.5pt;padding-right:1.5pt;\" rowspan=\"2\"><span id=\"S4.T4.1.1.1.1.1\" class=\"ltx_text\">Component</span></td>\n<td id=\"S4.T4.1.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:1.5pt;padding-right:1.5pt;\" colspan=\"2\">ViperGPT</td>\n<td id=\"S4.T4.1.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt\" style=\"padding-left:1.5pt;padding-right:1.5pt;\" colspan=\"3\">AdaCoder</td>\n</tr>\n<tr id=\"S4.T4.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.2.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">Tokens</td>\n<td id=\"S4.T4.1.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">Characters</td>\n<td id=\"S4.T4.1.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">Tokens</td>\n<td id=\"S4.T4.1.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">Characters</td>\n<td id=\"S4.T4.1.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">Reduction</td>\n</tr>\n<tr id=\"S4.T4.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">API defs</td>\n<td id=\"S4.T4.1.3.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">1,971</td>\n<td id=\"S4.T4.1.3.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">9,299</td>\n<td id=\"S4.T4.1.3.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">541</td>\n<td id=\"S4.T4.1.3.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">2,360</td>\n<td id=\"S4.T4.1.3.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">72.6%</td>\n</tr>\n<tr id=\"S4.T4.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.4.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">Code snippets</td>\n<td id=\"S4.T4.1.4.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">1,386</td>\n<td id=\"S4.T4.1.4.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">6,263</td>\n<td id=\"S4.T4.1.4.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">234</td>\n<td id=\"S4.T4.1.4.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">971</td>\n<td id=\"S4.T4.1.4.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">83.1%</td>\n</tr>\n<tr id=\"S4.T4.1.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.5.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">Instruction</td>\n<td id=\"S4.T4.1.5.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">77</td>\n<td id=\"S4.T4.1.5.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">388</td>\n<td id=\"S4.T4.1.5.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">77</td>\n<td id=\"S4.T4.1.5.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">388</td>\n<td id=\"S4.T4.1.5.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">-</td>\n</tr>\n<tr id=\"S4.T4.1.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.6.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">Classification</td>\n<td id=\"S4.T4.1.6.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">0</td>\n<td id=\"S4.T4.1.6.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">0</td>\n<td id=\"S4.T4.1.6.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">141</td>\n<td id=\"S4.T4.1.6.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">618</td>\n<td id=\"S4.T4.1.6.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">-</td>\n</tr>\n<tr id=\"S4.T4.1.7.7\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.7.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">Total</td>\n<td id=\"S4.T4.1.7.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">3,434</td>\n<td id=\"S4.T4.1.7.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">15,950</td>\n<td id=\"S4.T4.1.7.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">993</td>\n<td id=\"S4.T4.1.7.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">4,337</td>\n<td id=\"S4.T4.1.7.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:1.5pt;padding-right:1.5pt;\">71.7%</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Compressed prompts.\nTableÂ 4 summarizes the token length and compression performance for each component of the input preprompt.\nWe see that both API definitions and code snippets are significantly compressed.\nA comparison of the original and compressed API definitions is shown in FigureÂ 6.\nWe see that descriptions of methods unnecessary for coding, such as those for the initialization method, are omitted, and the remaining sections are condensed into shorter sentences. This is an effective compression achieved by the language understanding and summarization capabilities of black-box LLMs."
        ]
    },
    "S4.T5": {
        "caption": "Table 5. Ablation study w.r.t prompt compression (GQA, gpt-3.5-turbo).",
        "table": "<table id=\"S4.T5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">Method</th>\n<td id=\"S4.T5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">Tokens</td>\n<td id=\"S4.T5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">Acc.</td>\n</tr>\n<tr id=\"S4.T5.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">AdaCoder</th>\n<td id=\"S4.T5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">993</td>\n<td id=\"S4.T5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\"><span id=\"S4.T5.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">43.6</span></td>\n</tr>\n<tr id=\"S4.T5.1.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">w/o compressing API defs.</th>\n<td id=\"S4.T5.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">2,422</td>\n<td id=\"S4.T5.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">40.6</td>\n</tr>\n<tr id=\"S4.T5.1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">w/o compressing code snips.</th>\n<td id=\"S4.T5.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">2,145</td>\n<td id=\"S4.T5.1.4.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">41.1</td>\n</tr>\n<tr id=\"S4.T5.1.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">w/o QA classification</th>\n<td id=\"S4.T5.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">810</td>\n<td id=\"S4.T5.1.5.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">28.9</td>\n</tr>\n<tr id=\"S4.T5.1.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">w/o any compression</th>\n<td id=\"S4.T5.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">3,434</td>\n<td id=\"S4.T5.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">41.3</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Ablation study.\nTableÂ 5 presents the results of an ablation study. We see that both compression of API definitions and code snippets contribute to each other for both reducing the input token length and improving QA accuracy.\nTableÂ 6 summarizes the QA accuracy obtained by using a single compressed prompt. We see that even with one prompt of either â€œattrâ€ or â€œrelâ€, our method achieves comparable or slightly better performance than the ViperGPT baseline (41.3%). However, using one prompt of either â€œobjâ€ or â€œglobalâ€, the QA accuracy is significantly degraded. These results demonstrate that our adaptation approach is essential for improving QA accuracy while compressing input prompts.\nThe detailed QA accuracy by question type is analyzed in TableÂ 7.\nWe see that the four compressed prompt specialized for â€œobjâ€, â€œcatâ€, â€œattrâ€, and â€œrelâ€ performed the best for corresponding questions.\nFor the â€œglobalâ€ questions, the prompt for â€œattrâ€ was the best.\nThis is because â€œglobalâ€ questions are highly varied and not easily categorized.\nDefining fine-grained QA types would be interesting as a next step in future research."
        ]
    },
    "S4.T6": {
        "caption": "Table 6. Ablation study using a single specialized prompt (GQA, gpt-3.5-turbo).",
        "table": "<table id=\"S4.T6.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T6.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T6.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">Method</th>\n<th id=\"S4.T6.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">Tokens</th>\n<th id=\"S4.T6.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">Acc.</th>\n</tr>\n<tr id=\"S4.T6.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T6.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">AdaCoder</th>\n<th id=\"S4.T6.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">993</th>\n<th id=\"S4.T6.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\"><span id=\"S4.T6.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">43.6</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T6.1.3.1\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">w/ fixed prompt of obj</td>\n<td id=\"S4.T6.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">967</td>\n<td id=\"S4.T6.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">30.9</td>\n</tr>\n<tr id=\"S4.T6.1.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">w/ fixed prompt of cat</td>\n<td id=\"S4.T6.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">1,015</td>\n<td id=\"S4.T6.1.4.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">39.0</td>\n</tr>\n<tr id=\"S4.T6.1.5.3\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">w/ fixed prompt of attr</td>\n<td id=\"S4.T6.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">1,008</td>\n<td id=\"S4.T6.1.5.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">41.7</td>\n</tr>\n<tr id=\"S4.T6.1.6.4\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">w/ fixed prompt of rel</td>\n<td id=\"S4.T6.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">993</td>\n<td id=\"S4.T6.1.6.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">42.3</td>\n</tr>\n<tr id=\"S4.T6.1.7.5\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">w/ fixed prompt of global</td>\n<td id=\"S4.T6.1.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">977</td>\n<td id=\"S4.T6.1.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:9.0pt;padding-right:9.0pt;\">35.3</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Ablation study.\nTableÂ 5 presents the results of an ablation study. We see that both compression of API definitions and code snippets contribute to each other for both reducing the input token length and improving QA accuracy.\nTableÂ 6 summarizes the QA accuracy obtained by using a single compressed prompt. We see that even with one prompt of either â€œattrâ€ or â€œrelâ€, our method achieves comparable or slightly better performance than the ViperGPT baseline (41.3%). However, using one prompt of either â€œobjâ€ or â€œglobalâ€, the QA accuracy is significantly degraded. These results demonstrate that our adaptation approach is essential for improving QA accuracy while compressing input prompts.\nThe detailed QA accuracy by question type is analyzed in TableÂ 7.\nWe see that the four compressed prompt specialized for â€œobjâ€, â€œcatâ€, â€œattrâ€, and â€œrelâ€ performed the best for corresponding questions.\nFor the â€œglobalâ€ questions, the prompt for â€œattrâ€ was the best.\nThis is because â€œglobalâ€ questions are highly varied and not easily categorized.\nDefining fine-grained QA types would be interesting as a next step in future research."
        ]
    },
    "S4.T7": {
        "caption": "Table 7. Cross question type evaluation (GQA, gpt-3.5-turbo).",
        "table": "<table id=\"S4.T7.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T7.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T7.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">QA type</th>\n<th id=\"S4.T7.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">obj</th>\n<th id=\"S4.T7.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">cat</th>\n<th id=\"S4.T7.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">attr</th>\n<th id=\"S4.T7.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">rel</th>\n<th id=\"S4.T7.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">global</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T7.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T7.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">obj</th>\n<td id=\"S4.T7.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\"><span id=\"S4.T7.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">77.0</span></td>\n<td id=\"S4.T7.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">17.5</td>\n<td id=\"S4.T7.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">31.1</td>\n<td id=\"S4.T7.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">21.8</td>\n<td id=\"S4.T7.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">16.9</td>\n</tr>\n<tr id=\"S4.T7.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T7.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">cat</th>\n<td id=\"S4.T7.1.3.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">74.5</td>\n<td id=\"S4.T7.1.3.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\"><span id=\"S4.T7.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\">45.3</span></td>\n<td id=\"S4.T7.1.3.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">39.9</td>\n<td id=\"S4.T7.1.3.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">28.5</td>\n<td id=\"S4.T7.1.3.2.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">35.4</td>\n</tr>\n<tr id=\"S4.T7.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T7.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">attr</th>\n<td id=\"S4.T7.1.4.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">68.9</td>\n<td id=\"S4.T7.1.4.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">30.7</td>\n<td id=\"S4.T7.1.4.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\"><span id=\"S4.T7.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">52.4</span></td>\n<td id=\"S4.T7.1.4.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">28.9</td>\n<td id=\"S4.T7.1.4.3.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\"><span id=\"S4.T7.1.4.3.6.1\" class=\"ltx_text ltx_font_bold\">36.9</span></td>\n</tr>\n<tr id=\"S4.T7.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T7.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">rel</th>\n<td id=\"S4.T7.1.5.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">70.2</td>\n<td id=\"S4.T7.1.5.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">35.8</td>\n<td id=\"S4.T7.1.5.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">50.9</td>\n<td id=\"S4.T7.1.5.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\"><span id=\"S4.T7.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\">30.3</span></td>\n<td id=\"S4.T7.1.5.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">33.9</td>\n</tr>\n<tr id=\"S4.T7.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T7.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">global</th>\n<td id=\"S4.T7.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">71.1</td>\n<td id=\"S4.T7.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">31.4</td>\n<td id=\"S4.T7.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">38.0</td>\n<td id=\"S4.T7.1.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">24.8</td>\n<td id=\"S4.T7.1.6.5.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.0pt;padding-right:8.0pt;\">32.3</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Ablation study.\nTableÂ 5 presents the results of an ablation study. We see that both compression of API definitions and code snippets contribute to each other for both reducing the input token length and improving QA accuracy.\nTableÂ 6 summarizes the QA accuracy obtained by using a single compressed prompt. We see that even with one prompt of either â€œattrâ€ or â€œrelâ€, our method achieves comparable or slightly better performance than the ViperGPT baseline (41.3%). However, using one prompt of either â€œobjâ€ or â€œglobalâ€, the QA accuracy is significantly degraded. These results demonstrate that our adaptation approach is essential for improving QA accuracy while compressing input prompts.\nThe detailed QA accuracy by question type is analyzed in TableÂ 7.\nWe see that the four compressed prompt specialized for â€œobjâ€, â€œcatâ€, â€œattrâ€, and â€œrelâ€ performed the best for corresponding questions.\nFor the â€œglobalâ€ questions, the prompt for â€œattrâ€ was the best.\nThis is because â€œglobalâ€ questions are highly varied and not easily categorized.\nDefining fine-grained QA types would be interesting as a next step in future research."
        ]
    },
    "S4.T8": {
        "caption": "Table 8. Error analysis (individual error rates as percentages).",
        "table": "<table id=\"S4.T8.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T8.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">Error type</td>\n<td id=\"S4.T8.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">ViperGPT</td>\n<td id=\"S4.T8.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">AdaCoder</td>\n</tr>\n<tr id=\"S4.T8.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Correct but with unnecessary details</td>\n<td id=\"S4.T8.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.5</td>\n<td id=\"S4.T8.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.5</td>\n</tr>\n<tr id=\"S4.T8.1.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Correct except for articles</td>\n<td id=\"S4.T8.1.3.3.2\" class=\"ltx_td ltx_align_center\">1.1</td>\n<td id=\"S4.T8.1.3.3.3\" class=\"ltx_td ltx_align_center\">1.5</td>\n</tr>\n<tr id=\"S4.T8.1.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Correct by paraphrasing</td>\n<td id=\"S4.T8.1.4.4.2\" class=\"ltx_td ltx_align_center\">1.4</td>\n<td id=\"S4.T8.1.4.4.3\" class=\"ltx_td ltx_align_center\">1.6</td>\n</tr>\n<tr id=\"S4.T8.1.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Coding error</td>\n<td id=\"S4.T8.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">8.3</td>\n<td id=\"S4.T8.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">7.8</td>\n</tr>\n<tr id=\"S4.T8.1.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Cannot answer to simple query</td>\n<td id=\"S4.T8.1.6.6.2\" class=\"ltx_td ltx_align_center\">6.1</td>\n<td id=\"S4.T8.1.6.6.3\" class=\"ltx_td ltx_align_center\">6.1</td>\n</tr>\n<tr id=\"S4.T8.1.7.7\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_r\">No object detected</td>\n<td id=\"S4.T8.1.7.7.2\" class=\"ltx_td ltx_align_center\">0.7</td>\n<td id=\"S4.T8.1.7.7.3\" class=\"ltx_td ltx_align_center\">1.6</td>\n</tr>\n<tr id=\"S4.T8.1.8.8\" class=\"ltx_tr\">\n<td id=\"S4.T8.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">Wrong answer</td>\n<td id=\"S4.T8.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">40.6</td>\n<td id=\"S4.T8.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">37.3</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Error analysis.\nTableÂ 8 shows an error analysis, where we manually counted the occurrence of four types of errors.\nâ€œCoding errorâ€ indicates that the generated program is not executable or returns nothing.\nâ€œCannot answer to simple queryâ€ indicates that the program is correct but the simple_query method returned a response such as â€œI cannot answerâ€.\nâ€œNo object detectedâ€ indicates that no object is detected by the find method.\nâ€œWrong answerâ€ indicates that the returned answer was wrong.\nWe have two observations. First, the predominant type of error was wrong answers, and AdaCoder reduced their frequency.\nSecond, despite AdaCoderâ€™s improvement in coding quality, there is still a 7.8% incidence of coding errors. This suggests that there is still room for improvement in instructing LLMs about API usage."
        ]
    },
    "S4.T9": {
        "caption": "Table 9. Evaluation on various multimodal tasks. Token and Red. indicate token length and reduction rate, respectively.",
        "table": "<table id=\"S4.T9.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T9.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.2.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"></td>\n<td id=\"S4.T9.1.2.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\" rowspan=\"2\"><span id=\"S4.T9.1.2.1.2.1\" class=\"ltx_text\">Task</span></td>\n<td id=\"S4.T9.1.2.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\" rowspan=\"2\"><span id=\"S4.T9.1.2.1.3.1\" class=\"ltx_text\">Dataset</span></td>\n<td id=\"S4.T9.1.2.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\" colspan=\"2\">Baseline</td>\n<td id=\"S4.T9.1.2.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt\" style=\"padding-left:1.0pt;padding-right:1.0pt;\" colspan=\"3\">AdaCoder</td>\n</tr>\n<tr id=\"S4.T9.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"></td>\n<td id=\"S4.T9.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Acc.</td>\n<td id=\"S4.T9.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Token</td>\n<td id=\"S4.T9.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Acc.</td>\n<td id=\"S4.T9.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Token</td>\n<td id=\"S4.T9.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Red.<math id=\"S4.T9.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T9.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T9.1.1.1.m1.1.1\" xref=\"S4.T9.1.1.1.m1.1.1.cmml\">â†‘</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.1.1.1.m1.1b\"><ci id=\"S4.T9.1.1.1.m1.1.1.cmml\" xref=\"S4.T9.1.1.1.m1.1.1\">â†‘</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.1.1.1.m1.1c\">\\uparrow</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S4.T9.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.3.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\" rowspan=\"3\"><span id=\"S4.T9.1.3.2.1.1\" class=\"ltx_text\">\n<span id=\"S4.T9.1.3.2.1.1.1\" class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:7.9pt;height:41.7pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:41.7pt;transform:translate(-16.91pt,-16.03pt) rotate(-90deg) ;\">\n<span id=\"S4.T9.1.3.2.1.1.1.1\" class=\"ltx_p\"><span id=\"S4.T9.1.3.2.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">ViperGPT</span></span>\n</span></span></span></td>\n<td id=\"S4.T9.1.3.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Visual grounding</td>\n<td id=\"S4.T9.1.3.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">RefCOCO <cite class=\"ltx_cite ltx_citemacro_citep\">(Yu etÂ al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib46\" title=\"\" class=\"ltx_ref\">2016</a>)</cite>\n</td>\n<td id=\"S4.T9.1.3.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">39.5</td>\n<td id=\"S4.T9.1.3.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">3,434</td>\n<td id=\"S4.T9.1.3.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S4.T9.1.3.2.6.1\" class=\"ltx_text ltx_font_bold\">49.0</span></td>\n<td id=\"S4.T9.1.3.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">853</td>\n<td id=\"S4.T9.1.3.2.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">75.2%</td>\n</tr>\n<tr id=\"S4.T9.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.4.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Counting</td>\n<td id=\"S4.T9.1.4.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">BLINKÂ <cite class=\"ltx_cite ltx_citemacro_citep\">(Fu etÂ al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">2024</a>)</cite>\n</td>\n<td id=\"S4.T9.1.4.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">38.3</td>\n<td id=\"S4.T9.1.4.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">3,434</td>\n<td id=\"S4.T9.1.4.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S4.T9.1.4.3.5.1\" class=\"ltx_text ltx_font_bold\">39.2</span></td>\n<td id=\"S4.T9.1.4.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">935</td>\n<td id=\"S4.T9.1.4.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">72.8%</td>\n</tr>\n<tr id=\"S4.T9.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.5.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Relative depth</td>\n<td id=\"S4.T9.1.5.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">BLINKÂ <cite class=\"ltx_cite ltx_citemacro_citep\">(Fu etÂ al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">2024</a>)</cite>\n</td>\n<td id=\"S4.T9.1.5.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S4.T9.1.5.4.3.1\" class=\"ltx_text ltx_font_bold\">59.7</span></td>\n<td id=\"S4.T9.1.5.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">3,434</td>\n<td id=\"S4.T9.1.5.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S4.T9.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\">59.7</span></td>\n<td id=\"S4.T9.1.5.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">847</td>\n<td id=\"S4.T9.1.5.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">75.3%</td>\n</tr>\n<tr id=\"S4.T9.1.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.6.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\" rowspan=\"4\"><span id=\"S4.T9.1.6.5.1.1\" class=\"ltx_text\">\n<span id=\"S4.T9.1.6.5.1.1.1\" class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:7.9pt;height:31.5pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:31.5pt;transform:translate(-11.78pt,-10.9pt) rotate(-90deg) ;\">\n<span id=\"S4.T9.1.6.5.1.1.1.1\" class=\"ltx_p\"><span id=\"S4.T9.1.6.5.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">VisProg</span></span>\n</span></span></span></td>\n<td id=\"S4.T9.1.6.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Visual QA</td>\n<td id=\"S4.T9.1.6.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">GQAÂ <cite class=\"ltx_cite ltx_citemacro_citep\">(Hudson and Manning, <a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">2019</a>)</cite>\n</td>\n<td id=\"S4.T9.1.6.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">47.5</td>\n<td id=\"S4.T9.1.6.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">1,836</td>\n<td id=\"S4.T9.1.6.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S4.T9.1.6.5.6.1\" class=\"ltx_text ltx_font_bold\">49.0</span></td>\n<td id=\"S4.T9.1.6.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">657</td>\n<td id=\"S4.T9.1.6.5.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">64.2%</td>\n</tr>\n<tr id=\"S4.T9.1.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.7.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Visual reasoning</td>\n<td id=\"S4.T9.1.7.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">NLVR2Â <cite class=\"ltx_cite ltx_citemacro_citep\">(Suhr etÂ al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">2019</a>)</cite>\n</td>\n<td id=\"S4.T9.1.7.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">62.0</td>\n<td id=\"S4.T9.1.7.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">1,495</td>\n<td id=\"S4.T9.1.7.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S4.T9.1.7.6.5.1\" class=\"ltx_text ltx_font_bold\">62.5</span></td>\n<td id=\"S4.T9.1.7.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">338</td>\n<td id=\"S4.T9.1.7.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">77.4%</td>\n</tr>\n<tr id=\"S4.T9.1.8.7\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.8.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Image editing</td>\n<td id=\"S4.T9.1.8.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">MagicBrushÂ <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang etÂ al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib49\" title=\"\" class=\"ltx_ref\">2023</a>)</cite>\n</td>\n<td id=\"S4.T9.1.8.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">68.3</td>\n<td id=\"S4.T9.1.8.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">879</td>\n<td id=\"S4.T9.1.8.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S4.T9.1.8.7.5.1\" class=\"ltx_text ltx_font_bold\">70.0</span></td>\n<td id=\"S4.T9.1.8.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">219</td>\n<td id=\"S4.T9.1.8.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">75.1%</td>\n</tr>\n<tr id=\"S4.T9.1.9.8\" class=\"ltx_tr\">\n<td id=\"S4.T9.1.9.8.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">Object tagging</td>\n<td id=\"S4.T9.1.9.8.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">RefCOCO <cite class=\"ltx_cite ltx_citemacro_citep\">(Yu etÂ al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib46\" title=\"\" class=\"ltx_ref\">2016</a>)</cite>\n</td>\n<td id=\"S4.T9.1.9.8.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S4.T9.1.9.8.3.1\" class=\"ltx_text ltx_font_bold\">43.3</span></td>\n<td id=\"S4.T9.1.9.8.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">1,836</td>\n<td id=\"S4.T9.1.9.8.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S4.T9.1.9.8.5.1\" class=\"ltx_text ltx_font_bold\">43.3</span></td>\n<td id=\"S4.T9.1.9.8.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">216</td>\n<td id=\"S4.T9.1.9.8.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">88.2%</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Evaluation on various tasks.\nFinally, we evaluated the generalizability of our method across various multimodal tasks, including visual grounding (VG), counting (CT), relative depth estimation (RDE), visual reasoning (VR), image editing (IE), and object tagging (OT).\nAs shown in TableÂ 9, our method is consistently effective for all of these tasks."
        ]
    }
}