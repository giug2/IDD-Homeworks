{
    "S3.T1": {
        "caption": "Table 1: Word Error Rate(WER) for different model variations using Voice Search Domain. The N-Best WER indicates the best WER in the top N=10 beams.",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Test WER</span></th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S3.T1.1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T1.1.1.1.3.1.1\" class=\"ltx_p\"><span id=\"S3.T1.1.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Test WER</span> +</span>\n<span id=\"S3.T1.1.1.1.3.1.2\" class=\"ltx_p\"><span id=\"S3.T1.1.1.1.3.1.2.1\" class=\"ltx_text ltx_font_bold\">LM Rescoring</span></span>\n</span>\n</th>\n<th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">N-Best WER</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">LAS-Gen</td>\n<td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">25.31</td>\n<td id=\"S3.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">22.18</td>\n<td id=\"S3.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">13.71</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">LAS-Dense</td>\n<td id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">16.25</td>\n<td id=\"S3.T1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">15.55</td>\n<td id=\"S3.T1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">7.6</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">LAS-Decoder</td>\n<td id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">13.65</td>\n<td id=\"S3.T1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T1.1.4.3.3.1\" class=\"ltx_text ltx_font_bold\">13.36</span></td>\n<td id=\"S3.T1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">5.82</td>\n</tr>\n<tr id=\"S3.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\">CTC-Gen</td>\n<td id=\"S3.T1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">31.84</td>\n<td id=\"S3.T1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">25.58</td>\n<td id=\"S3.T1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">13.83</td>\n</tr>\n<tr id=\"S3.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">CTC-Dense</td>\n<td id=\"S3.T1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">20.32</td>\n<td id=\"S3.T1.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">17.66</td>\n<td id=\"S3.T1.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">8.24</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "In this work, we evaluate dense only fine-tuning baseline for CTC and attention-based models. The domain adaptation approach is presented on two datasets from voice search and address domain. The word error rates(WER) is used to compare the different approaches. The WER is word-level Levenshtein distance between ground truth text and output text. The results for voice search domain and address domain are shown in Table 1 and Table 2 respectively. The models are first trained on the generic multi-domain dataset and represented as CTC-Gen and LAS-Gen. These pre-trained models are then fine-tuned single speaker synthetic dataset. We show that dense only fine-tuning provides considerable improvement in accuracy while at the same time avoiding over-fitting on single speaker data. The dense-finetuned models are referred to as CTC-Dense and LAS-Dense. We also evaluate decoder-only fine-tuning for LAS models termed as LAS-Decoder. We report WER with and without external language model rescoring. A kenLM based language model is trained using text transcripts for both the domains individually. The N-Best WER is computed by picking the best beam from the top N=10 beam elements."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Word Error Rate(WER) for different model variations using Address Domain. The N-Best WER indicates the best WER in the top N=10 beams.",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Test WER</span></th>\n<th id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">\n<span id=\"S3.T2.1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T2.1.1.1.3.1.1\" class=\"ltx_p\"><span id=\"S3.T2.1.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Test WER</span> +</span>\n<span id=\"S3.T2.1.1.1.3.1.2\" class=\"ltx_p\"><span id=\"S3.T2.1.1.1.3.1.2.1\" class=\"ltx_text ltx_font_bold\">LM Rescoring</span></span>\n</span>\n</th>\n<th id=\"S3.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">N-Best WER</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">LAS-Gen</td>\n<td id=\"S3.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">39.42</td>\n<td id=\"S3.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">31.62</td>\n<td id=\"S3.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">25.35</td>\n</tr>\n<tr id=\"S3.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">LAS-Dense</td>\n<td id=\"S3.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">22.57</td>\n<td id=\"S3.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">16.38</td>\n<td id=\"S3.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">11.01</td>\n</tr>\n<tr id=\"S3.T2.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">LAS-Decoder</td>\n<td id=\"S3.T2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">18.96</td>\n<td id=\"S3.T2.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.4.3.3.1\" class=\"ltx_text ltx_font_bold\">12.54</span></td>\n<td id=\"S3.T2.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">8.17</td>\n</tr>\n<tr id=\"S3.T2.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\">CTC-Gen</td>\n<td id=\"S3.T2.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">31.08</td>\n<td id=\"S3.T2.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">22.81</td>\n<td id=\"S3.T2.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">19.74</td>\n</tr>\n<tr id=\"S3.T2.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">CTC-Dense</td>\n<td id=\"S3.T2.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">22.43</td>\n<td id=\"S3.T2.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">15.42</td>\n<td id=\"S3.T2.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">12.15</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "In this work, we evaluate dense only fine-tuning baseline for CTC and attention-based models. The domain adaptation approach is presented on two datasets from voice search and address domain. The word error rates(WER) is used to compare the different approaches. The WER is word-level Levenshtein distance between ground truth text and output text. The results for voice search domain and address domain are shown in Table 1 and Table 2 respectively. The models are first trained on the generic multi-domain dataset and represented as CTC-Gen and LAS-Gen. These pre-trained models are then fine-tuned single speaker synthetic dataset. We show that dense only fine-tuning provides considerable improvement in accuracy while at the same time avoiding over-fitting on single speaker data. The dense-finetuned models are referred to as CTC-Dense and LAS-Dense. We also evaluate decoder-only fine-tuning for LAS models termed as LAS-Decoder. We report WER with and without external language model rescoring. A kenLM based language model is trained using text transcripts for both the domains individually. The N-Best WER is computed by picking the best beam from the top N=10 beam elements."
        ]
    }
}