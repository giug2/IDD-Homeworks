{
    "S6.T1.1": {
        "caption": [],
        "table": "<table id=\"S6.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.1.1.1\" class=\"ltx_td ltx_border_t\"></td>\n<th id=\"S6.T1.1.1.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\">Unweighted</th>\n<th id=\"S6.T1.1.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\">Weighted</th>\n<th id=\"S6.T1.1.1.1.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\">Nested Lasso</th>\n<th id=\"S6.T1.1.1.1.5\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\">Non-adaptive</th>\n<th id=\"S6.T1.1.1.1.6\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\">CSCS</th>\n</tr>\n<tr id=\"S6.T1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.2.2.1\" class=\"ltx_td ltx_align_right ltx_border_t\">LDA</td>\n<td id=\"S6.T1.1.2.2.2\" class=\"ltx_td ltx_align_right ltx_border_t\">0.271</td>\n<td id=\"S6.T1.1.2.2.3\" class=\"ltx_td ltx_align_right ltx_border_t\">0.246</td>\n<td id=\"S6.T1.1.2.2.4\" class=\"ltx_td ltx_align_right ltx_border_t\">0.250</td>\n<td id=\"S6.T1.1.2.2.5\" class=\"ltx_td ltx_align_right ltx_border_t\">0.268</td>\n<td id=\"S6.T1.1.2.2.6\" class=\"ltx_td ltx_align_right ltx_border_t\">0.245</td>\n</tr>\n<tr id=\"S6.T1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.3.3.1\" class=\"ltx_td ltx_align_right ltx_border_b\">QDA</td>\n<td id=\"S6.T1.1.3.3.2\" class=\"ltx_td ltx_align_right ltx_border_b\">0.232</td>\n<td id=\"S6.T1.1.3.3.3\" class=\"ltx_td ltx_align_right ltx_border_b\">0.256</td>\n<td id=\"S6.T1.1.3.3.4\" class=\"ltx_td ltx_align_right ltx_border_b\">0.221</td>\n<td id=\"S6.T1.1.3.3.5\" class=\"ltx_td ltx_align_right ltx_border_b\">0.246</td>\n<td id=\"S6.T1.1.3.3.6\" class=\"ltx_td ltx_align_right ltx_border_b\">0.267</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "To demonstrate the use of our estimator in the high-dimensional setting, we randomly split the data into two parts,\nwith 10%percent1010\\% of the data assigned to the training set and the remaining 90%percent9090\\% of the data assigned to the test set.\nOn the training set,\nwe use 5-fold cross-validation to select the tuning parameter minimizing misclassification error on the validation data.\nThe estimates L^^ğ¿\\hat{L} and L^(k)superscript^ğ¿ğ‘˜\\hat{L}^{(k)} are then\nplugged into\n(26) and (27)\nalong with\nÎ¼^(k)=âˆ‘iâˆˆclassâ€‹kxi/n(k)superscript^ğœ‡ğ‘˜subscriptğ‘–classğ‘˜subscriptğ‘¥ğ‘–superscriptğ‘›ğ‘˜\\hat{\\mu}^{(k)}=\\sum_{i\\in{\\mathrm{class}\\,k}}x_{i}/n^{(k)} and Ï€^(k)=n(k)/ntrainsuperscript^ğœ‹ğ‘˜superscriptğ‘›ğ‘˜subscriptğ‘›train\\hat{\\pi}^{(k)}=n^{(k)}/n_{\\mathrm{train}}\nto calculate the misclassification error in the test set.\nFor comparison, we also include non-adaptive banding, the nested lasso, and CSCS.\nWe compute the classification error (summarized in\nTableÂ 1), averaged over 10 random train-test splits."
        ]
    }
}