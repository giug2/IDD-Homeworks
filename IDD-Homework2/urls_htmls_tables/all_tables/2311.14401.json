{
    "PAPER'S NUMBER OF TABLES": 3,
    "S4.T1": {
        "caption": "Table 1. CNN model.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Layer (type)</span></th>\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Output Shape</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Flatten</th>\n<td id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">784</td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Dense</th>\n<td id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">128</td>\n</tr>\n<tr id=\"S4.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Dropout</th>\n<td id=\"S4.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">128</td>\n</tr>\n<tr id=\"S4.T1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\">Dense</th>\n<td id=\"S4.T1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">10</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Any Federated Learning solution requires clients with their own data to train their models, and a central server that coordinates communications and which is responsible for weighting the models of the clients and distributing the global model. For our experiment, it is necessary to set up some edge devices to act as clients. Providing them with data so that they can train their respective models. Consequently, a dataset will also have to be obtained in order to distribute its data among all the clients.",
                "The choice of the dataset and model to be used had to take into account the processing and dynamic memory capacity of the raspberrys. The model could not be too complex so that the raspberrys would not be able to train it. Besides, the dataset would have to be extensive so that it could be divided among several clients. That choice was to take the MNIST dataset ",
                "(LeCun and Cortes, ",
                "2010",
                ")",
                ". This is a dataset made up of handwritten numbers by different people. The training set consists of 60,000 samples while the test set has 10,000 samples. The images are made up of 28x28 pixels, they look as shown in ",
                "Figure 3",
                ". This dataset is well known and is common for people who are learning Machine Learning techniques.",
                "Raspberry boards were chosen to simulate the devices that would act as clients. Five boards were used for the experiment, three of them Raspberry Pi 3 Model B whereas the other two were Raspberry Pi 2 Model B. All of them have 1 Gb of RAM, this plus CPU capacity supposed a limiting factor. Their description is as follows:",
                "Raspberry Pi 3 Model B ",
                "(Rapsberry Pi 3, ",
                "2022",
                ")",
                ": CPU (Broadcom BCM2387 64bit ARMv7 Quad Core 1.2GHz); RAM (1GB LPDDR2; Wifi (Yes)",
                "Raspberry Pi 2 Model B ",
                "(Rapsberry Pi 2, ",
                "2022",
                ")",
                ": CPU (Broadcom BCM2836 900MHz quad-core ARM Cortex-A7); RAM (1GB LPDDR2); Wifi (No)",
                "An AWS instance, as mentioned above, simulates the central server, with the following technical characteristics: Model t2micro; vCPU 1; Mem 8 GiB.",
                "The model used to be trained with this dataset is a simple convolutional neural network, which are known for performing well in image classification tasks. Keras ",
                "(Chollet, ",
                "2015",
                ")",
                ", a deep learning library, running on top of TensorFlow. is used to create the model. The model looks as shown in ",
                "Table 1",
                ", it consists of an input layer, two hidden layers and an output layer. The input layer flattens the input data, then a regular dense layer that uses ",
                "ReLU",
                " as activation function and a dropout layer which helps prevent overfitting, finally the output layer is another regular dense layer which uses ",
                "Softmax",
                " as activation function. ",
                "ReLU",
                " activation function is a linear function that will output the input directly if it is positive, or zero otherwise. ",
                "Softmax",
                " activation function converts a vector of numbers into a vector of probabilities.",
                "The list of weights is passed as a bytearray in the message payload via MQTT communication. In the receiver, the model is reconstructed with the keras ",
                "(Chollet, ",
                "2015",
                ")",
                " method ",
                "loadmodel()",
                ". On each raspberry pi board, 4 clients were simulated using multiprocessing, where each process is a client. Making a total of 20 clients participating in Federated Learning. This was the maximum number of participants in the different tests."
            ]
        ]
    },
    "S5.T2": {
        "caption": "Table 2. Distribution of MNIST samples",
        "table": "<table id=\"S5.T2.1\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Dataset</th>\n<th id=\"S5.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">label 0</th>\n<th id=\"S5.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">label 1</th>\n<th id=\"S5.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">label 2</th>\n<th id=\"S5.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">label 3</th>\n<th id=\"S5.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">label 4</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt\">Train</th>\n<td id=\"S5.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">5,923</td>\n<td id=\"S5.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">6,742</td>\n<td id=\"S5.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">5,958</td>\n<td id=\"S5.T2.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">6,131</td>\n<td id=\"S5.T2.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">5,842</td>\n</tr>\n<tr id=\"S5.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">Test</th>\n<td id=\"S5.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">980</td>\n<td id=\"S5.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1,135</td>\n<td id=\"S5.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1,032</td>\n<td id=\"S5.T2.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1,010</td>\n<td id=\"S5.T2.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">982</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "As mentioned in the previous section, we use the MNIST one dataset. It follows a quite uniform distribution of samples, which can be seen in the ",
                "Table 2",
                ". In its totality it has 60,000 samples for training and 10,000 for testing. The choice was that each client would have 300 training samples, as a lower number would not give as well-representative results, and a larger number would start to give problems to the Raspberry devices. On the other hand, the 10,000 test samples are always used, which is necessary so that the results of the different tests can be compared.",
                "The objective of the model trained is to predict which number is the one in the image that is introduced. There are different metrics to measure performance. In order to asses the performance, we use the regular measures: (1) ",
                "Accuracy",
                ", which is the number of correct predictions divided by the number of total predictions, this metric works best when the number of samples of each label is the same. MNIST is close to having this equality; (2)",
                "Confusion matrix",
                ", a matrix showing the number of False positives, False negatives, True positives and True negatives; (3) ",
                "F1 score",
                ", which is the harmonic mean between precision and recall, and seeks a compromise between this two; (4) ",
                "MAE",
                " and ",
                "MSE",
                ", which aim to give an average of the distance between predicted and actual values, this is not useful for this classification problem, since similar numbers are for example 1 and 7, but their distance would not express anything; and (5) ",
                "Loss",
                ", which is not a metric, but is used by the neural network when training, being the distance between real and predicted values. Being what the neural network seeks to minimise during training.",
                "The decision made was to use accuracy and loss. Accuracy is one of the most universal metrics and allows to easily know the performance. Loss, on the other hand, relates well to precision, as combined they allow us to know what is happening. For example, if both increase, it could be due to overfitting, i.e. it will adjust to learning the particular cases we teach it and will be unable to recognise new data. However, if the accuracy increases while the loss decreases, it is assumable that the neural network is learning correctly.",
                "The second important point to consider is how to evaluate the performance of Federated Learning. The results were compared with those obtained in a traditional architecture, where data is centralised. Therefore, the performance of Federated Learning would be compared with the results that a client would obtain with only its own data, in case data restrictions prevented them from being shared, and on the other hand, with the results that a centralised server would obtain with the data of all the clients.",
                "Plotly ",
                "(Plotly, ",
                "2022",
                ")",
                ", a tool for data analysis and visualisation, was used for the creation of all the graphs. The results obtained for the tests with centralised data can be seen in ",
                "Figure 4",
                ". The maximum efficiency achieved by a single client is ",
                "78.23%",
                ", which is not a high number, but it is reasonable since it does not have enough samples to achieve a higher effectiveness. Furthermore, from epoch 15 on-wards the loss starts to increase, which may be due to overfitting as the model has few samples.",
                "In contrast, the results with data from 20, 10 and 15 clients are much better. These have respectively 3000, 4500 and 6000 samples for training, and achieve efficiencies of ",
                "92.87%",
                ", ",
                "94.26%",
                " and ",
                "95.23%",
                ". In these cases, the loss starts to increase around epoch 20-25, training from then on does not improve the model.",
                "In the case of the Federated Learning tests, 10, 15 and 20 clients were also used. In turn, for each of these cases, 1,3,5 epochs were used, i.e. the number of times the model will be trained on the entire dataset. This is to test how it would influence the fact that more training would be done on all models in each round of communication. The results can be found in ",
                "Figure 5",
                ".",
                "It can be noticed how effectiveness improves as the number of clients and the amount of training in each round of communication increases. Since effectiveness improves with the number of epochs, a compromise should be found with the effort that each client makes to train his model. A full breakdown of the results can be found in ",
                "Table 3",
                "The highest number achieved with Federated Learning is ",
                "90.55%",
                ", which is a respectable result, although it is a little far from the ",
                "95.23%",
                " that would be obtained with centralised data. However, although it sometimes happens, the objective of Federated Learning is not to improve the results of traditional centralised models, but to serve in cases where it is not possible to use them. Actually, even the worst result of the scenarios tested with Federated Learning, with 10 clients and 1 epoch, and ",
                "84.55%",
                " accuracy, is quite better than the ",
                "78.23%",
                " achieved by an single client."
            ]
        ]
    },
    "S5.T3": {
        "caption": "Table 3. Accuracy Comparation",
        "table": "<table id=\"S5.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"></th>\n<th id=\"S5.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">10 Clients</th>\n<th id=\"S5.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">15 Clients</th>\n<th id=\"S5.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">20 Clients</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">1 Epoch F.L.</td>\n<td id=\"S5.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">84.63%</td>\n<td id=\"S5.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">88.03%</td>\n<td id=\"S5.T3.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">88.42%</td>\n</tr>\n<tr id=\"S5.T3.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">3 Epoch F.L.</td>\n<td id=\"S5.T3.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">88.03%</td>\n<td id=\"S5.T3.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">88.68%</td>\n<td id=\"S5.T3.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.13%</td>\n</tr>\n<tr id=\"S5.T3.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">5 Epoch F.L.</td>\n<td id=\"S5.T3.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">88.73%</td>\n<td id=\"S5.T3.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.2%</td>\n<td id=\"S5.T3.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.55%</td>\n</tr>\n<tr id=\"S5.T3.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Centralized data</td>\n<td id=\"S5.T3.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">92.87%</td>\n<td id=\"S5.T3.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">94.26%</td>\n<td id=\"S5.T3.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">95.23%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "As mentioned in the previous section, we use the MNIST one dataset. It follows a quite uniform distribution of samples, which can be seen in the ",
                "Table 2",
                ". In its totality it has 60,000 samples for training and 10,000 for testing. The choice was that each client would have 300 training samples, as a lower number would not give as well-representative results, and a larger number would start to give problems to the Raspberry devices. On the other hand, the 10,000 test samples are always used, which is necessary so that the results of the different tests can be compared.",
                "The objective of the model trained is to predict which number is the one in the image that is introduced. There are different metrics to measure performance. In order to asses the performance, we use the regular measures: (1) ",
                "Accuracy",
                ", which is the number of correct predictions divided by the number of total predictions, this metric works best when the number of samples of each label is the same. MNIST is close to having this equality; (2)",
                "Confusion matrix",
                ", a matrix showing the number of False positives, False negatives, True positives and True negatives; (3) ",
                "F1 score",
                ", which is the harmonic mean between precision and recall, and seeks a compromise between this two; (4) ",
                "MAE",
                " and ",
                "MSE",
                ", which aim to give an average of the distance between predicted and actual values, this is not useful for this classification problem, since similar numbers are for example 1 and 7, but their distance would not express anything; and (5) ",
                "Loss",
                ", which is not a metric, but is used by the neural network when training, being the distance between real and predicted values. Being what the neural network seeks to minimise during training.",
                "The decision made was to use accuracy and loss. Accuracy is one of the most universal metrics and allows to easily know the performance. Loss, on the other hand, relates well to precision, as combined they allow us to know what is happening. For example, if both increase, it could be due to overfitting, i.e. it will adjust to learning the particular cases we teach it and will be unable to recognise new data. However, if the accuracy increases while the loss decreases, it is assumable that the neural network is learning correctly.",
                "The second important point to consider is how to evaluate the performance of Federated Learning. The results were compared with those obtained in a traditional architecture, where data is centralised. Therefore, the performance of Federated Learning would be compared with the results that a client would obtain with only its own data, in case data restrictions prevented them from being shared, and on the other hand, with the results that a centralised server would obtain with the data of all the clients.",
                "Plotly ",
                "(Plotly, ",
                "2022",
                ")",
                ", a tool for data analysis and visualisation, was used for the creation of all the graphs. The results obtained for the tests with centralised data can be seen in ",
                "Figure 4",
                ". The maximum efficiency achieved by a single client is ",
                "78.23%",
                ", which is not a high number, but it is reasonable since it does not have enough samples to achieve a higher effectiveness. Furthermore, from epoch 15 on-wards the loss starts to increase, which may be due to overfitting as the model has few samples.",
                "In contrast, the results with data from 20, 10 and 15 clients are much better. These have respectively 3000, 4500 and 6000 samples for training, and achieve efficiencies of ",
                "92.87%",
                ", ",
                "94.26%",
                " and ",
                "95.23%",
                ". In these cases, the loss starts to increase around epoch 20-25, training from then on does not improve the model.",
                "In the case of the Federated Learning tests, 10, 15 and 20 clients were also used. In turn, for each of these cases, 1,3,5 epochs were used, i.e. the number of times the model will be trained on the entire dataset. This is to test how it would influence the fact that more training would be done on all models in each round of communication. The results can be found in ",
                "Figure 5",
                ".",
                "It can be noticed how effectiveness improves as the number of clients and the amount of training in each round of communication increases. Since effectiveness improves with the number of epochs, a compromise should be found with the effort that each client makes to train his model. A full breakdown of the results can be found in ",
                "Table 3",
                "The highest number achieved with Federated Learning is ",
                "90.55%",
                ", which is a respectable result, although it is a little far from the ",
                "95.23%",
                " that would be obtained with centralised data. However, although it sometimes happens, the objective of Federated Learning is not to improve the results of traditional centralised models, but to serve in cases where it is not possible to use them. Actually, even the worst result of the scenarios tested with Federated Learning, with 10 clients and 1 epoch, and ",
                "84.55%",
                " accuracy, is quite better than the ",
                "78.23%",
                " achieved by an single client."
            ]
        ]
    }
}