{
    "id_table_1": {
        "caption": "Table 1:  Training data statistics.",
        "table": "A4.tab1.1",
        "footnotes": [],
        "references": [
            "This paper presents comprehensive analyses on long-context LLMs in RAG systems.  Contrary to the suggestions of previous work  (Xu et al.,  2023 ; Li et al.,  2024 ) , our research reveals that increasing the number of retrieved passages does not consistently improve performance with long-context LLMs (Section  3.1 ).  Instead, we observe that the generative modeling performance initially increases and then declines  simply providing more retrieved passages does not guarantee better outcomes.  Using stronger retrievers is also not a mitigation mechanism  indeed the performance degradation can even be more severe with them.  For deeper understanding of the phenomenon, we conduct further investigations, which reveal that increasing the number of retrieved passages can introduce irrelevant information (noise) that can mislead the LLM generation (Section  3.2 ).  We also examine the impact of hard negatives of different retrievers on the LLMs, and show that there are scenarios where the hard negatives from stronger retrievers might confuse the LLM generation even more than those from weaker retrievers (Section  3.3 ).",
            "Observations.   Figure  1  presents the following key observations:  1) Strong Retriever (e5): Across all LLMs, increasing the number of retrieved passages initially improves performance, but then leads to a sharp decline or plateau.  2) Weak Retriever (BM25): Performance generally exhibits a continuous increase or a slight decrease as the number of retrieved passages increases.  While these observations may appear counter-intuitive - given that one might expect monotonic improvements due to higher recall ( i.e. , a greater chance of retrieving relevant information) - the inclusion of additional documents can reduce precision, with irrelevant or misleading passages detracting LLMs from overall performance.  Comparison of different retrievers and the results on other datasets are shown in Appendix  A  and  B.1 .",
            "While the fine-tuning approach described in Section  5.1  implicitly enhances the LLMs robustness to hard negatives, it does not explicitly train the model to differentiate between relevant and irrelevant passages within the retrieved context.  To address this, we investigate the effectiveness of incorporating an intermediate reasoning step into the fine-tuning process.",
            "We utilize the same training data mixture as in Section  5.1  and augment it with reasoning labels generated by Gemini-1.5-Pro for each question-passage pair. These labels provide explicit guidance on identifying relevant passages. Further details of the experimental setup and the generation of reasoning labels can be found in Appendix  H .",
            "Observations.   Figure  9  presents the following key observations similar to that in Section  3.1 :  1) Strong Retriever (e5): Across all LLMs, increasing the number of retrieved passages initially enhances performance, but subsequently results in either a sharp decline or a plateau.  2) Weak Retriever (BM25): Performance generally shows a continuous improvement or a slighter decrease as the number of retrieved passages increases.  While these observations may appear counter-intuitive - given that one might expect monotonic improvements due to higher recall ( i.e. , a greater chance of retrieving relevant information) - the inclusion of additional documents can reduce precision, with irrelevant or misleading passages detracting LLMs from overall performance.",
            "Observations.  Figure  10  shows the following observations similar to that in Section  3.3 :  (1) Sensitivity to hard negatives: Across all LLMs, increasing the number of hard negative passages generally results in a decline in RAG answer accuracy.  (2) Retriever strength and hard negative difficulty: The strength of the retriever is directly correlated with the difficulty of the retrieved hard negatives. LLMs struggle more with hard negatives generated by stronger retrievers ( e.g. , e5) compared to those produced by weaker retrievers ( e.g. , BM25) or through random sampling.  (3) Distinguishing random and hard negatives: While all the LLMs demonstrates robustness to random negatives, it remains susceptible to the influence of hard negatives.",
            "We select a series of fine-tuning data designed to enhance the models robustness to hard negatives in the retrieval context and improve its contextual awareness in generating predictions.  The training data are from four sources with different answer types: Natural Question (short-form), Wizard of Wikipedia (long-form), FEVER (true/false), and MMLU (close-set).  The statistics of the training data mix can be found in Table  1 .",
            "Hyperparameters.  The hyperparameter setting is the same to that in Appendix  G.1 .",
            "Evaluation RAG instruction templates.  The RAG instruction templates for different testing datasets can be found in Table  10 .",
            "In Figure  5 , we illustrate the performance of implicit RAG finetuning on eight datasets with three different base models due to the space limitation. The whole results with Gemma-2-9B models can be found in Figure  11 .",
            "In Figure  6 , we show the power of RAG finetuning with intermediate reasoning on five datasets because of the space limitation. The whole results on all the nine datasets with Gemma-2-9B models can be found in Figure  12 .  Note that due to the computational complexity of inference with reasoning augmentation, results are shown for 1000 randomly-sampled queries for each dataset.",
            "In addition to the comprehensive data-augmented RAG fine-tuning results with three different base LLMs reported in Section  5 , we also would like to show the results specifically with the Mistral-Nemo-12B models in Figure  13 .",
            "In addition to the comprehensive data-augmented RAG fine-tuning results with three different base LLMs reported in Section  5 , we also would like to show the results specifically with the Gemini-1.0-Pro models in Figure  14 .  Due to the Gemini-1.0-Pro API call credit limitation, we random sample 1000 queries for each dataset.",
            "To investigate the influence of the size of the training data on the effectiveness of RAG-specific tuning, we fine-tune the Gemma-2-9B-Base model using varying amounts (5k to 200k samples) of mixed training data from NQ, WoW, Fever, and MMLU.  Table  11  presents the evaluation results on the NQ dataset, demonstrating a clear positive correlation between the scale of training data and the performance of the resulting LLM in RAG.  Increasing the amount of training data consistently leads to improved accuracy, highlighting the benefits of leveraging larger datasets for fine-tuning LLMs in RAG applications.",
            "Table  12  presents the results, demonstrating that incorporating RAG-specific data into the SFT process can significantly improve the LLMs performance on RAG tasks while maintaining its performance on general language tasks.  This finding suggests that combining task-specific and general-purpose data during fine-tuning can be a viable strategy for enhancing LLMs in specialized applications without compromising their overall capabilities."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Testing data statistics.",
        "table": "A4.tab2.1",
        "footnotes": [],
        "references": [
            "This paper presents comprehensive analyses on long-context LLMs in RAG systems.  Contrary to the suggestions of previous work  (Xu et al.,  2023 ; Li et al.,  2024 ) , our research reveals that increasing the number of retrieved passages does not consistently improve performance with long-context LLMs (Section  3.1 ).  Instead, we observe that the generative modeling performance initially increases and then declines  simply providing more retrieved passages does not guarantee better outcomes.  Using stronger retrievers is also not a mitigation mechanism  indeed the performance degradation can even be more severe with them.  For deeper understanding of the phenomenon, we conduct further investigations, which reveal that increasing the number of retrieved passages can introduce irrelevant information (noise) that can mislead the LLM generation (Section  3.2 ).  We also examine the impact of hard negatives of different retrievers on the LLMs, and show that there are scenarios where the hard negatives from stronger retrievers might confuse the LLM generation even more than those from weaker retrievers (Section  3.3 ).",
            "Experimental setting.   We analyze the relationship between RAG performance and retrieval quality, specifically recall and precision, using the Gemma-2-9B-Chat LLM with both e5 and BM25 retrievers (Figure  2 ).  Recall@k measures the presence of relevant passages within the top-k retrieved passages, while precision@k quantifies the proportion of relevant passages among them.",
            "Observations.   (1) Sensitivity to hard negatives: Across all LLMs, increasing the number of hard negative passages generally leads to a decline in RAG answer accuracy.  (2) Retriever strength and hard negative difficulty: The strength of the retriever directly correlates with the difficulty of the retrieved hard negatives. LLMs struggle more with hard negatives from stronger retrievers ( e.g. , e5) compared to those from weaker retrievers ( e.g. , BM25) or random sampling.  (3) Distinguishing random and hard negatives: While Gemini-1.5-Pro demonstrates robustness to random negatives, it remains susceptible to the influence of hard negatives.  More results on other datasets and qualitative studies can be found in Appendix  B.2  and  D .",
            "To comprehensively evaluate our methods, we select testing datasets across different tasks including: (1) Question-answering: TriviaQA, PopQA, WebQuestions; (2) Multi-hop tasks: HotpotQA, 2WikiMultiHopQA, Bamboogle; (3) Long-form tasks: ASQA; (4) Slot filling: T-REx, Zero-shot RE.  The statistics of all the datasets can be found in Table  2 .",
            "In Figure  6 , we show the power of RAG finetuning with intermediate reasoning on five datasets because of the space limitation. The whole results on all the nine datasets with Gemma-2-9B models can be found in Figure  12 .  Note that due to the computational complexity of inference with reasoning augmentation, results are shown for 1000 randomly-sampled queries for each dataset.",
            "Table  12  presents the results, demonstrating that incorporating RAG-specific data into the SFT process can significantly improve the LLMs performance on RAG tasks while maintaining its performance on general language tasks.  This finding suggests that combining task-specific and general-purpose data during fine-tuning can be a viable strategy for enhancing LLMs in specialized applications without compromising their overall capabilities."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Implicit RAG finetuning hyperparameters.",
        "table": "A4.tab3.1",
        "footnotes": [],
        "references": [
            "This paper presents comprehensive analyses on long-context LLMs in RAG systems.  Contrary to the suggestions of previous work  (Xu et al.,  2023 ; Li et al.,  2024 ) , our research reveals that increasing the number of retrieved passages does not consistently improve performance with long-context LLMs (Section  3.1 ).  Instead, we observe that the generative modeling performance initially increases and then declines  simply providing more retrieved passages does not guarantee better outcomes.  Using stronger retrievers is also not a mitigation mechanism  indeed the performance degradation can even be more severe with them.  For deeper understanding of the phenomenon, we conduct further investigations, which reveal that increasing the number of retrieved passages can introduce irrelevant information (noise) that can mislead the LLM generation (Section  3.2 ).  We also examine the impact of hard negatives of different retrievers on the LLMs, and show that there are scenarios where the hard negatives from stronger retrievers might confuse the LLM generation even more than those from weaker retrievers (Section  3.3 ).",
            "Experimental setting.   This study investigates the effect of hard negative passages on long-context LLM performance in a controlled setting.  We tasked three LLMs (Gemma2-7B-Chat, Mistral-Nemo-12B-Instruct, and Gemini-1.5-Pro) with answering queries based on a context comprising a single golden passage and a varying number of hard negative passages retrieved using different methods (e5, Contriever, BM25, and random sampling).  This synthetic experiment, detailed in Figure  3 , isolates the impact of hard negatives by holding the golden passage constant and intentionally excluding scenarios with multiple golden passages, which are common in real-world RAG systems.  See Appendix  C  for a complete illustration of the experimental setup.",
            "Building upon the analyses in Section  3  on the detrimental impact of hard negatives on long-context LLMs in RAG, we focus on the training-free solution,  retrieval reordering .  This method leverages the inherent \"lost-in-the-middle\" phenomenon observed in LLMs to mitigate the negative effects of hard negatives.  As highlighted by  Liu et al. ( 2024 ) , LLMs exhibit a tendency to prioritize information presented at the beginning and end of an input sequence, while paying less attention to the middle.",
            "In addition to the analysis presented on the NQ dataset in Section  3 , we conduct further studies on the PopQA dataset to underscore the generality of our findings.",
            "Observations.   Figure  9  presents the following key observations similar to that in Section  3.1 :  1) Strong Retriever (e5): Across all LLMs, increasing the number of retrieved passages initially enhances performance, but subsequently results in either a sharp decline or a plateau.  2) Weak Retriever (BM25): Performance generally shows a continuous improvement or a slighter decrease as the number of retrieved passages increases.  While these observations may appear counter-intuitive - given that one might expect monotonic improvements due to higher recall ( i.e. , a greater chance of retrieving relevant information) - the inclusion of additional documents can reduce precision, with irrelevant or misleading passages detracting LLMs from overall performance.",
            "Observations.  Figure  10  shows the following observations similar to that in Section  3.3 :  (1) Sensitivity to hard negatives: Across all LLMs, increasing the number of hard negative passages generally results in a decline in RAG answer accuracy.  (2) Retriever strength and hard negative difficulty: The strength of the retriever is directly correlated with the difficulty of the retrieved hard negatives. LLMs struggle more with hard negatives generated by stronger retrievers ( e.g. , e5) compared to those produced by weaker retrievers ( e.g. , BM25) or through random sampling.  (3) Distinguishing random and hard negatives: While all the LLMs demonstrates robustness to random negatives, it remains susceptible to the influence of hard negatives.",
            "Hyperparameters.   We use the top-40 retrieved text chunks for a given example to generate the fine-tuning samples and use e5 as the retriever for the main results.  We fine-tune both Gemma-2-9B-Base and Mistral-Nemo-12B-Base using 8 H100 GPUs.  For both models, we use the chat template corresponding to Gemma-2-9B-Chat and Mistral-Nemo-12B-Instruct respectively when tuning the models.  We use the axolotl 1 1 1 https://github.com/axolotl-ai-cloud/axolotl  codebase for their tuning.  For Gemini-1.0-Pro tuning, we use the Google Cloud Tuning API 2 2 2 https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/tuning  with the default settings.  The hyperparameters can be found in Table  3 .",
            "In addition to the comprehensive data-augmented RAG fine-tuning results with three different base LLMs reported in Section  5 , we also would like to show the results specifically with the Mistral-Nemo-12B models in Figure  13 ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Training instruction templates for implicit RAG tuning.",
        "table": "A6.T1.1",
        "footnotes": [],
        "references": [
            "Retrieval reordering significantly improves RAG performance, particularly with larger numbers of retrieved passages.   To assess the effectiveness of retrieval reordering, we conduct experiments with two retrievers (e5 and BM25), two long-context LLMs (Gemma-2-9B-Chat and Mistral-Nemo-12B-Instruct), and two datasets (NQ and PopQA).  As illustrated in Figure  4 , retrieval reordering yields negligible improvements with smaller retrieval sets, but significantly and consistently outperforms the original ordering when the number of retrieved passages is large.  This behavior is attributed to the interplay of two factors that become increasingly significant with larger retrieval sets: (1) the amplified \"lost-in-the-middle\" phenomenon, where LLMs prioritize information at the beginning and end of the input sequence, and (2) the increased prevalence of hard negatives, which can hinder accurate answer generation.  By strategically placing passages, retrieval reordering mitigates these issues, highlighting the potential of  position engineering  as a complementary technique to prompt engineering for optimizing long-context LLMs in RAG.",
            "While the  retrieval reordering  strategy presented in Section  4  mitigates the detrimental impact of hard negatives, it does not inherently enhance the LLMs ability to handle such irrelevant information within the context.  To address this, we conduct a systematic investigation into RAG-specific tuning as a means of improving long-context LLMs for RAG applications.",
            "Training RAG instruction templates.  The RAG instruction templates for different training datasets can be found in Table  4 .",
            "In addition to the comprehensive data-augmented RAG fine-tuning results with three different base LLMs reported in Section  5 , we also would like to show the results specifically with the Gemini-1.0-Pro models in Figure  14 .  Due to the Gemini-1.0-Pro API call credit limitation, we random sample 1000 queries for each dataset."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Training answer templates for implicit RAG tuning.",
        "table": "A6.T2.1",
        "footnotes": [],
        "references": [
            "Figure  5  shows the three key observations:  (1) Consistent improvement over baselines: RAG FT consistently outperforms the chat model w. RAG and the Direct FT model across all evaluated datasets.  (2) Robustness to hard negatives: the curve of RAG FT is generally flatter than that of the chat model, which demonstrates that our finetuned LLM is more robust to the hard negatives as the number of retrieved passages increases.  (3) Superiority over direct fine-tuning: In most cases, RAG FT demonstrates superior performance compared to Direct FT. This indicates that RAG FT not only enables the LLM to \"memorize\" knowledge during training but also equips it with the ability to effectively \"extract\" relevant information from retrieved context during inference.  These findings highlight the effectiveness of RAG-specific tuning in enhancing the generalization capabilities of LLMs for knowledge-intensive tasks.  Separate results on those three LLMs are shown in Appendix  J ,  K  and  L .  Qualitative studies can be found in Appendix  I .",
            "While the fine-tuning approach described in Section  5.1  implicitly enhances the LLMs robustness to hard negatives, it does not explicitly train the model to differentiate between relevant and irrelevant passages within the retrieved context.  To address this, we investigate the effectiveness of incorporating an intermediate reasoning step into the fine-tuning process.",
            "We utilize the same training data mixture as in Section  5.1  and augment it with reasoning labels generated by Gemini-1.5-Pro for each question-passage pair. These labels provide explicit guidance on identifying relevant passages. Further details of the experimental setup and the generation of reasoning labels can be found in Appendix  H .",
            "Training RAG answer templates.  The RAG answer templates for different training datasets can be found in Table  5 .",
            "In Figure  5 , we illustrate the performance of implicit RAG finetuning on eight datasets with three different base models due to the space limitation. The whole results with Gemma-2-9B models can be found in Figure  11 .",
            "In addition to the comprehensive data-augmented RAG fine-tuning results with three different base LLMs reported in Section  5 , we also would like to show the results specifically with the Mistral-Nemo-12B models in Figure  13 .",
            "In addition to the comprehensive data-augmented RAG fine-tuning results with three different base LLMs reported in Section  5 , we also would like to show the results specifically with the Gemini-1.0-Pro models in Figure  14 .  Due to the Gemini-1.0-Pro API call credit limitation, we random sample 1000 queries for each dataset.",
            "Having established the effectiveness of RAG-specific fine-tuning for improving LLM performance in RAG tasks, we now investigate whether combining RAG-specific data with general SFT data can further enhance performance while preserving the LLMs general capabilities ( e.g. , reasoning and long-form generation), as a way to assess the potential of the proposed tuning methods to be useful for construction of foundation models.  We train the Gemma-2-9B model using two different strategies:  (1) SFT data only: The LLM is trained solely on general SFT data (Ultrachat 200k).  (2) SFT data + RAG-specific data: The LLM is trained on a combination of Ultrachat 200k and 50k RAG-specific data (the same data used in Figure  5 ).  We evaluate the resulting models on MT-Bench to assess their general language capabilities and on NQ and TriviaQA to measure their RAG performance."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Testing instruction templates for implicit RAG tuning.",
        "table": "A7.T3.1",
        "footnotes": [],
        "references": [
            "Figure  6  demonstrates the effectiveness of this approach. The LLM fine-tuned with explicit intermediate reasoning consistently outperforms training with implicit RAG data. This improvement can be attributed to two key factors:  (1) Explicit relevance training: Providing intermediate reasoning labels during training explicitly teaches the LLM to differentiate between relevant and irrelevant passages, enhancing its ability to discern crucial information from noise.  (2) Structured reasoning for enhanced understanding: Generating a reasoning paragraph before answering introduces a structured approach to processing the retrieved context. This step, akin to chain-of-thought reasoning  (Wei et al.,  2022 ) , helps decouple the complex information and facilitates a more focused analysis, ultimately leading to improved performance.  These highlight the value of incorporating explicit reasoning mechanisms in RAG tuning to enhance the LLMs ability to effectively utilize retrieved context.  More results on Gemma-2-9B models, Mistral-Nemo-12B models and Gemini-1.0-Pro models are shown in Appendix  J ,  K  and  L .  Qualitative studies can be found in Appendix  I .",
            "Evaluation RAG instruction templates.  The RAG instruction templates for different testing datasets can be found in Table  6 .",
            "In Figure  6 , we show the power of RAG finetuning with intermediate reasoning on five datasets because of the space limitation. The whole results on all the nine datasets with Gemma-2-9B models can be found in Figure  12 .  Note that due to the computational complexity of inference with reasoning augmentation, results are shown for 1000 randomly-sampled queries for each dataset."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Training instruction templates for RAG tuning with intermediate reasoning.",
        "table": "A7.T4.1",
        "footnotes": [],
        "references": [
            "Figure  7 (a) demonstrates that a mixed distribution of training data leads to superior generalization performance on unseen RAG tasks compared to training on a single data source.  This highlights the importance of data diversity in enhancing the adaptability of LLMs to new RAG scenarios.",
            "Figure  7 (b) presents the results, revealing two key findings:  (1) Superiority of mixed retriever training: Fine-tuning with the data corresponding to a mix of retrievers consistently yields the best performance across both seen and unseen retrievers during inference. This suggests that training on a diverse set of retrieved passages enhances the LLMs ability to adapt to different retrieval strategies and knowledge sources.  (2) Retriever similarity and generalization: The generalization ability of an LLM fine-tuned with a specific retriever is influenced by the similarity between the training retriever and the inference retriever. For instance, an LLM trained with BM25 generalizes better to Contriever, while an LLM trained with e5 generalizes better to BGE. This observation suggests that \"hard negatives\" exhibit different characteristics depending on the employed retriever, and training with a specific retriever implicitly equips the LLM to better handle similar types of hard negatives. See Appendix  A  for a detailed analysis of retriever similarity.",
            "Figure  7 (c) presents the results on NQ, demonstrating that fine-tuning with the maximum number of retrieved passages (100% max) consistently yields the best performance across various retrieval sizes during inference.  This suggests that training with the full context capacity enhances the LLMs ability to effectively handle varying amounts of retrieved information, leading to improved generalization and robustness.  More analyses of RAG-specific tuning can be found in in Appendix  M  and  N .",
            "Training RAG instruction templates.  The RAG instruction templates with intermediate reasoning for different training datasets can be found in Table  7 ."
        ]
    },
    "id_table_8": {
        "caption": "Table 8:  Training answer templates for RAG tuning with intermediate reasoning.",
        "table": "A7.T5.1",
        "footnotes": [],
        "references": [
            "We analyze the performance and similarity of four retrievers (BM25, contriever, e5 and bge) on the NQ dataset shown in Figure  8 .  Each data point corresponds to a retrieval (recall, precision) pair for a specific number of retrieved passages.  The overall retrieval performances on NQ are observed as e5 > bge > contriever > bm25, with contriever having a similar performance with BM25 and bge having a similar performance with e5 (as their curves are closer).",
            "Training RAG Answer templates.  The RAG answer templates for different training datasets can be found in Table  8 ."
        ]
    },
    "id_table_9": {
        "caption": "Table 9:  Prompts to guide Gemini-1.5-pro for intermediate reasoning generation.",
        "table": "A7.T6.1",
        "footnotes": [],
        "references": [
            "Observations.   Figure  9  presents the following key observations similar to that in Section  3.1 :  1) Strong Retriever (e5): Across all LLMs, increasing the number of retrieved passages initially enhances performance, but subsequently results in either a sharp decline or a plateau.  2) Weak Retriever (BM25): Performance generally shows a continuous improvement or a slighter decrease as the number of retrieved passages increases.  While these observations may appear counter-intuitive - given that one might expect monotonic improvements due to higher recall ( i.e. , a greater chance of retrieving relevant information) - the inclusion of additional documents can reduce precision, with irrelevant or misleading passages detracting LLMs from overall performance.",
            "Instructions to generate intermediate reasoning from Gemini-1.5-pro.  The prompt that guides Gemini-1.5-pro for intermediate reasoning generation can be found in Table  9 ."
        ]
    },
    "id_table_10": {
        "caption": "Table 10:  Testing instruction templates for RAG tuning with intermediate reasoning.",
        "table": "A8.T7.1.1",
        "footnotes": [],
        "references": [
            "Observations.  Figure  10  shows the following observations similar to that in Section  3.3 :  (1) Sensitivity to hard negatives: Across all LLMs, increasing the number of hard negative passages generally results in a decline in RAG answer accuracy.  (2) Retriever strength and hard negative difficulty: The strength of the retriever is directly correlated with the difficulty of the retrieved hard negatives. LLMs struggle more with hard negatives generated by stronger retrievers ( e.g. , e5) compared to those produced by weaker retrievers ( e.g. , BM25) or through random sampling.  (3) Distinguishing random and hard negatives: While all the LLMs demonstrates robustness to random negatives, it remains susceptible to the influence of hard negatives.",
            "Evaluation RAG instruction templates.  The RAG instruction templates for different testing datasets can be found in Table  10 ."
        ]
    },
    "id_table_11": {
        "caption": "Table 11:  Impact of RAG-specific training data scale on LLM performance in RAG.",
        "table": "A8.T8.1",
        "footnotes": [],
        "references": [
            "In Figure  5 , we illustrate the performance of implicit RAG finetuning on eight datasets with three different base models due to the space limitation. The whole results with Gemma-2-9B models can be found in Figure  11 .",
            "To investigate the influence of the size of the training data on the effectiveness of RAG-specific tuning, we fine-tune the Gemma-2-9B-Base model using varying amounts (5k to 200k samples) of mixed training data from NQ, WoW, Fever, and MMLU.  Table  11  presents the evaluation results on the NQ dataset, demonstrating a clear positive correlation between the scale of training data and the performance of the resulting LLM in RAG.  Increasing the amount of training data consistently leads to improved accuracy, highlighting the benefits of leveraging larger datasets for fine-tuning LLMs in RAG applications."
        ]
    },
    "id_table_12": {
        "caption": "Table 12:  Combining RAG-specific data with general SFT data for enhanced LLM performance in RAG.",
        "table": "A8.T9.1.1",
        "footnotes": [],
        "references": [
            "In Figure  6 , we show the power of RAG finetuning with intermediate reasoning on five datasets because of the space limitation. The whole results on all the nine datasets with Gemma-2-9B models can be found in Figure  12 .  Note that due to the computational complexity of inference with reasoning augmentation, results are shown for 1000 randomly-sampled queries for each dataset.",
            "Table  12  presents the results, demonstrating that incorporating RAG-specific data into the SFT process can significantly improve the LLMs performance on RAG tasks while maintaining its performance on general language tasks.  This finding suggests that combining task-specific and general-purpose data during fine-tuning can be a viable strategy for enhancing LLMs in specialized applications without compromising their overall capabilities."
        ]
    },
    "id_table_13": {
        "caption": "",
        "table": "A8.T10.1.1",
        "footnotes": [],
        "references": [
            "In addition to the comprehensive data-augmented RAG fine-tuning results with three different base LLMs reported in Section  5 , we also would like to show the results specifically with the Mistral-Nemo-12B models in Figure  13 ."
        ]
    },
    "id_table_14": {
        "caption": "",
        "table": "A9.tab1.1",
        "footnotes": [],
        "references": [
            "In addition to the comprehensive data-augmented RAG fine-tuning results with three different base LLMs reported in Section  5 , we also would like to show the results specifically with the Gemini-1.0-Pro models in Figure  14 .  Due to the Gemini-1.0-Pro API call credit limitation, we random sample 1000 queries for each dataset."
        ]
    },
    "id_table_15": {
        "caption": "",
        "table": "A9.tab2.1",
        "footnotes": [],
        "references": []
    },
    "id_table_16": {
        "caption": "",
        "table": "A13.T11.1",
        "footnotes": [],
        "references": []
    },
    "id_table_17": {
        "caption": "",
        "table": "A14.T12.1",
        "footnotes": [],
        "references": []
    },
    "global_footnotes": []
}