{
    "PAPER'S NUMBER OF TABLES": 4,
    "S5.T1": {
        "caption": "TABLE I: Comparison of Performance between FedSlate and Baseline under Various Environmental Settings",
        "table": "<table id=\"S5.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Metric</span></td>\n<td id=\"S5.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"S5.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\"><span id=\"S5.T1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Environment</span></td>\n</tr>\n<tr id=\"S5.T1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N=10,n=3</td>\n<td id=\"S5.T1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N=100,n=10</td>\n<td id=\"S5.T1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N=500,n=10</td>\n</tr>\n<tr id=\"S5.T1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.1.3.3.1.1\" class=\"ltx_text\">ETROR</span></td>\n<td id=\"S5.T1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SlateQ</td>\n<td id=\"S5.T1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S5.T1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3400</td>\n<td id=\"S5.T1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2020</td>\n</tr>\n<tr id=\"S5.T1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate</td>\n<td id=\"S5.T1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S5.T1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.4.4.3.1\" class=\"ltx_text ltx_font_bold\">2340</span></td>\n<td id=\"S5.T1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.4.4.4.1\" class=\"ltx_text ltx_font_bold\">1700</span></td>\n</tr>\n<tr id=\"S5.T1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.1.5.5.1.1\" class=\"ltx_text\">Optimal Reward</span></td>\n<td id=\"S5.T1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SlateQ</td>\n<td id=\"S5.T1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S5.T1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.5.5.4.1\" class=\"ltx_text ltx_font_bold\">1115.072</span></td>\n<td id=\"S5.T1.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T1.1.5.5.5.1\" class=\"ltx_text ltx_font_bold\">1117.974</span></td>\n</tr>\n<tr id=\"S5.T1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate</td>\n<td id=\"S5.T1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S5.T1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1106.57</td>\n<td id=\"S5.T1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1107.092</td>\n</tr>\n<tr id=\"S5.T1.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Mean Reward</td>\n<td id=\"S5.T1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">Rand</td>\n<td id=\"S5.T1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">947.087</td>\n<td id=\"S5.T1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">942.75</td>\n<td id=\"S5.T1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">938.665</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Experimental Results: We conducted multiple iterations of FedSlate and a baseline method under various environmental settings. Specifically, for the parameter selection of N𝑁N and n𝑛n, we adhered to the standard configurations detailed in the RecSim technical documentation[18]. Our comparison focused on the performance metrics M1′superscriptsubscript𝑀1′M_{1}^{{}^{\\prime}} and M2′superscriptsubscript𝑀2′M_{2}^{{}^{\\prime}}. As depicted in Table I, M2′superscriptsubscript𝑀2′M_{2}^{{}^{\\prime}} is consistently less than or equal to M1′superscriptsubscript𝑀1′M_{1}^{{}^{\\prime}} across different settings, indicating that FedSlate can enhance the training velocity of agent α𝛼\\alpha. However, it may compromise the agent’s learning of an optimal local policy by potentially reducing the optimal reward. This is attributed to FedSlate’s design, which focuses on optimizing the aggregate long-term benefit for users across platforms rather than maximizing the immediate value for individual users on a single platform. Notably, we omitted the performance comparison between the SlateQ and FedSlate algorithms in the scenario with N=10,n=3formulae-sequence𝑁10𝑛3N=10,n=3, since neither algorithm converged in this setting, performing substantially worse than a random recommendation approach. This lack of convergence is likely due to overfitting within an overly simplistic environment. Despite this, We argue that FedSlate effectively aids feedback data owners—designated as agent α𝛼\\alpha in the experiment—by improving training efficiency and significantly reducing computational resource consumption. Moreover, the recommendation strategy learned through FedSlate demonstrates comparable performance to that developed using SlateQ. For a visual representation of the comparative experimental results under different settings, please refer to Fig. 5. In the context of random recommendation algorithms, it is noteworthy that we compare their average reward against the optimal reward achieved by FedSlate and SlateQ, while refraining from providing its ETROR. This approach is inherently justified, given that for random recommendation algorithms, there is no process of ‘learning an optimal recommendation strategy’. Instead, they persistently operate with suboptimal performance, making the utilization of average reward a more representative metric for evaluating the performance of random algorithms."
        ]
    },
    "S5.T2": {
        "caption": "TABLE II: Comparison of Performance between FedSlate and Random Recommendation Algorithm under Various Environmental Settings",
        "table": "<table id=\"S5.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.1.1.1.2\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\"><span id=\"S5.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Environment</span></td>\n</tr>\n<tr id=\"S5.T2.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S5.T2.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Metric</span></td>\n<td id=\"S5.T2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"S5.T2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">N=10,n=3</span></td>\n<td id=\"S5.T2.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">N=100,n=10</span></td>\n<td id=\"S5.T2.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">N=500,n=10</span></td>\n</tr>\n<tr id=\"S5.T2.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.3.3.1.1\" class=\"ltx_text\" style=\"color:#374151;\">Optimal Reward</span></td>\n<td id=\"S5.T2.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate</td>\n<td id=\"S5.T2.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.3.3.3.1\" class=\"ltx_text\" style=\"color:#374151;\"><span id=\"S5.T2.1.3.3.3.1.1\" class=\"ltx_text ltx_font_bold\" style=\"color:#374151;\">1115.281</span></span></td>\n<td id=\"S5.T2.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.3.3.4.1\" class=\"ltx_text ltx_font_bold\">1102.269</span></td>\n<td id=\"S5.T2.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.3.3.5.1\" class=\"ltx_text ltx_font_bold\">1129.96</span></td>\n</tr>\n<tr id=\"S5.T2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Mean Reward</td>\n<td id=\"S5.T2.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">Rand</td>\n<td id=\"S5.T2.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.4.4.3.1\" class=\"ltx_text\" style=\"color:#374151;\">948.294</span></td>\n<td id=\"S5.T2.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">944.982</td>\n<td id=\"S5.T2.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">939.979</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Furthermore, a pivotal aspect of our study is assessing if FedSlate can empower platforms lacking user feedback to augment their recommendation systems by leveraging feedback from other platforms. The performance of agent β𝛽\\beta, which employs FedSlate, is contrasted with that of random recommendations. As illustrated in Table II, agent β𝛽\\beta consistently outperforms random recommendations in various settings, as indicated by RM3′≥Rr​n​dsubscript𝑅superscriptsubscript𝑀3′subscript𝑅𝑟𝑛𝑑R_{M_{3}^{{}^{\\prime}}}\\geq R_{rnd}. Please note that our comparative analysis was strictly limited to evaluating the performance of FedSlate-Beta against the random recommendation algorithm. This limitation was necessitated by a fundamental constraint of the original SlateQ framework, which is its incapacity to develop an effective recommendation policy without reward feedback. This finding demonstrates that FedSlate enables entities (represented by agent β𝛽\\beta) without feedback data to benefit from user feedback. Such data-deprived entities are likely to have a heightened interest in FedSlate, as it offers a means to exploit insights from feedback data previously inaccessible to them. The comparative results are visually represented in Fig. 6. Notably, in scenarios with N=10,n=3formulae-sequence𝑁10𝑛3N=10,n=3, agent β𝛽\\beta demonstrates a reliable learning of the recommendation strategy. This robustness can be attributed to the indirect training process where the target Q-values from agent α𝛼\\alpha differ from agent β𝛽\\beta’s objective Q-values, adding a layer of complexity to the training."
        ]
    },
    "S5.T3": {
        "caption": "TABLE III: Comparison of Performance between Ablated FedSlate Algorithm and Original Algorithm",
        "table": "<table id=\"S5.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Metric</span></td>\n<td id=\"S5.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"S5.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Environment</span></td>\n</tr>\n<tr id=\"S5.T3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">N=100,n=10</span></td>\n</tr>\n<tr id=\"S5.T3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S5.T3.1.3.3.1.1\" class=\"ltx_text\">ETROR</span></td>\n<td id=\"S5.T3.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate-Alpha</td>\n<td id=\"S5.T3.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.3.3.3.1\" class=\"ltx_text ltx_font_bold\">2340</span></td>\n</tr>\n<tr id=\"S5.T3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate(abl)-Alpha</td>\n<td id=\"S5.T3.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n</tr>\n<tr id=\"S5.T3.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate-Beta</td>\n<td id=\"S5.T3.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.5.5.2.1\" class=\"ltx_text ltx_font_bold\">2800</span></td>\n</tr>\n<tr id=\"S5.T3.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate(abl)-Beta</td>\n<td id=\"S5.T3.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n</tr>\n<tr id=\"S5.T3.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S5.T3.1.7.7.1.1\" class=\"ltx_text\">Optimal Reward</span></td>\n<td id=\"S5.T3.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate-Alpha</td>\n<td id=\"S5.T3.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.7.7.3.1\" class=\"ltx_text ltx_font_bold\">1115.072</span></td>\n</tr>\n<tr id=\"S5.T3.1.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.8.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate(abl)-Alpha</td>\n<td id=\"S5.T3.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1005.524</td>\n</tr>\n<tr id=\"S5.T3.1.9.9\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.9.9.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate-Beta</td>\n<td id=\"S5.T3.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.9.9.2.1\" class=\"ltx_text ltx_font_bold\">1102.269</span></td>\n</tr>\n<tr id=\"S5.T3.1.10.10\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">FedSlate(abl)-Beta</td>\n<td id=\"S5.T3.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">956.612</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In the evaluation experiment of FedSlate, both the local and global networks are fully connected networks with five hidden layers. We employ the Mish function [46] as the activation function Nonetheless, the hidden layers vary in size, with the local network possessing a larger size and the global network a smaller size. In the ablation experiment, we maintain the structure of the local network unchanged and simplify the global network as much as possible. We reduce the global network to a single hidden layer network and remove the activation function, transforming it into a simple Linear Model. Through this setup, we force FedSlate to directly utilize Q-values generated by the local network for recommendations. The experimental results, as depicted in Table III, do not provide the ETROR data for the ablated algorithm. Throughout the entire training process, the rewards for the ablation group diverge completely, and its performance does not exhibit significant improvement compared to random recommendation algorithms. The detailed experimental results can be referred to in Fig.7. The ablation experiment demonstrates the effectiveness of our FedSlate framework in terms of vertical FL."
        ]
    },
    "S5.T4": {
        "caption": "TABLE IV: Comparison of Performance between Extended FedSlate Algorithm and Original Algorithm",
        "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T4.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Environment(N=100,n=10)</span></td>\n</tr>\n<tr id=\"S5.T4.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S5.T4.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Metric</span></td>\n<td id=\"S5.T4.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T4.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"S5.T4.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">dense</span></td>\n<td id=\"S5.T4.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">sparse</span></td>\n</tr>\n<tr id=\"S5.T4.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.3.3.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T4.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate-Alpha</td>\n<td id=\"S5.T4.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2340</td>\n<td id=\"S5.T4.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3540</td>\n</tr>\n<tr id=\"S5.T4.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.4.4.1\" class=\"ltx_td ltx_border_l ltx_border_r\"></td>\n<td id=\"S5.T4.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate(exp)-Alpha</td>\n<td id=\"S5.T4.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S5.T4.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.4.4.4.1\" class=\"ltx_text ltx_font_bold\">2280</span></td>\n</tr>\n<tr id=\"S5.T4.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.5.5.1\" class=\"ltx_td ltx_border_l ltx_border_r\"></td>\n<td id=\"S5.T4.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate-Beta</td>\n<td id=\"S5.T4.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2800</td>\n<td id=\"S5.T4.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2940</td>\n</tr>\n<tr id=\"S5.T4.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\"><span id=\"S5.T4.1.6.6.1.1\" class=\"ltx_text\">ETROR</span></td>\n<td id=\"S5.T4.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate(exp)-Beta</td>\n<td id=\"S5.T4.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S5.T4.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.6.6.4.1\" class=\"ltx_text ltx_font_bold\">780</span></td>\n</tr>\n<tr id=\"S5.T4.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.7.7.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T4.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate-Alpha</td>\n<td id=\"S5.T4.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1115.072</td>\n<td id=\"S5.T4.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1081.422</td>\n</tr>\n<tr id=\"S5.T4.1.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.8.8.1\" class=\"ltx_td ltx_border_l ltx_border_r\"></td>\n<td id=\"S5.T4.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate(exp)-Alpha</td>\n<td id=\"S5.T4.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S5.T4.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.8.8.4.1\" class=\"ltx_text ltx_font_bold\">1091.515</span></td>\n</tr>\n<tr id=\"S5.T4.1.9.9\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.9.9.1\" class=\"ltx_td ltx_border_l ltx_border_r\"></td>\n<td id=\"S5.T4.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedSlate-Beta</td>\n<td id=\"S5.T4.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1102.269</td>\n<td id=\"S5.T4.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1042.926</td>\n</tr>\n<tr id=\"S5.T4.1.10.10\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r\"><span id=\"S5.T4.1.10.10.1.1\" class=\"ltx_text\" style=\"color:#374151;\">Optimal Reward</span></td>\n<td id=\"S5.T4.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">FedSlate(exp)-Beta</td>\n<td id=\"S5.T4.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S5.T4.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.10.10.4.1\" class=\"ltx_text ltx_font_bold\">1108.855</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The constructed scenario requires the collaborative efforts of multiple agents to enhance the collective lifetime value of individual users across different platforms. However, in the implementation process, we used the rewards from Platform A to reflect the overall lifetime value. If the team rewards are too sparse, it may adversely affect the performance of FedSlate. To investigate the impact of this factor, we simulated the scenario of sparse team rewards by setting different random seeds for the sub-environments within the main environment, and conducted experiments under the settings of N=100,n=10formulae-sequence𝑁100𝑛10N=100,n=10. Additionally, we included the extended version of FedSlate for comparative analysis. The experimental results are presented in Table IV. We observed that when the team rewards in the environment are sparse, the learning process for agents in FedSlate to acquire recommendation policies takes longer, and the resulting policies are less effective. The extended algorithm of FedSlate outperforms the original version in terms of ETROR and Optimal Reward, and we observed that this improvement is more pronounced for agent β𝛽\\beta.The visual results of the comparative experiments are shown in Fig. 8. It should be noted that the extended algorithm of FedSlate is merely a supplementary approach for the original algorithm under specific circumstances. It requires agent β𝛽\\beta to have access to reward information, which contradicts the fundamental principles of FedSlate based on vertical FL."
        ]
    }
}