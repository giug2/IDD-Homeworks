{
    "id_table_1": {
        "caption": "TABLE I:  Generated Python scripts with ChatVis (left), and GPT-4 (right) for streamline tracing.",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": [
            "In this section we describe our methodology to generate an accurate ParaView Python script from user input written in natural language. We propose an LLM-based method as outlined in Figure  1 . Initially, the user describes their visualization needs in natural language, and an LLM processes this input to generate a more effective prompt. This prompt, combined with multiple example code snippets, is used by the LLM to create a Python script. We then execute this script using ParaViews PvPython API. If no errors are detected, the script produces a 2D screenshot. If errors occur during script execution, the error messages are fed back to the LLM for corrections, creating a feedback loop that continuously refines the script. This iterative process allows for ongoing improvements based on the error messages until an error-free script is achieved. Upon successful execution, this refinement process generates an error-free Python script and a screenshot of the visualization for evaluation."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Performance comparison of various LLMs based on two criterias: (i) whether the model can generate scripts without syntax errors, and (ii) whether the scripts can successfully produce screenshots (SS).",
        "table": "S4.T2.1",
        "footnotes": [],
        "references": [
            "Figure  2  displays the generated images for the isosurfacing task. Figure  2(a)  is generated through manual use of the ParaView GUI and represents our ground truth, while Figure  2(b)  is generated by ChatVis, and Figure  2(c)  is generated by GPT-4. We observe that both ChatVis and GPT-4 can correctly perform the requested operations. This is the only example where GPT-4 produces a correct image as this is a relatively simple task. GPT-4 created a gray background, which is different from the default ParaView script. Meanwhile, the ChatVis background matched the ground truth because ChatVis learned to specify the background color to be white. The camera position was also not specified by the user, leading to slightly different default zoom levels. Later experiments specify camera parameters."
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "S4.T2.1.4.3.1.1",
        "footnotes": [],
        "references": [
            "Figure  3  compares the ground truth screenshot with the one generated by ChatVis. ChatVis executed all operations correctly and produced a screenshot identical to the ground truth. On the other hand, the code generated by GPT-4 encountered syntax errors because the script attempted to access non-existent attributes. Specifically, it attempted to access the  UseSeparateColorMap  attribute of the  Contour  class by calling  ColorBy(contour, None)  and to set the  ViewUp  attribute on the  RenderView  class using the code  view.ViewUp = [0.0, 1.0, 0.0] ."
        ]
    }
}