{
    "A2.T1": {
        "caption": "Table 1: CCM’s hyperparameters for sparse-reward environments",
        "table": "<table id=\"A2.T1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T1.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Environment</th>\n<th id=\"A2.T1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Meta-train tasks</th>\n<th id=\"A2.T1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Meta-test tasks</th>\n<th id=\"A2.T1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Number of exploration episodes</th>\n<th id=\"A2.T1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><math id=\"A2.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\" display=\"inline\"><semantics id=\"A2.T1.1.1.1.m1.1a\"><mi id=\"A2.T1.1.1.1.m1.1.1\" xref=\"A2.T1.1.1.1.m1.1.1.cmml\">α</mi><annotation-xml encoding=\"MathML-Content\" id=\"A2.T1.1.1.1.m1.1b\"><ci id=\"A2.T1.1.1.1.m1.1.1.cmml\" xref=\"A2.T1.1.1.1.m1.1.1\">𝛼</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T1.1.1.1.m1.1c\">\\alpha</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"A2.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">cheetah-sparse</td>\n<td id=\"A2.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">60</td>\n<td id=\"A2.T1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">10</td>\n<td id=\"A2.T1.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">2</td>\n<td id=\"A2.T1.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">1</td>\n</tr>\n<tr id=\"A2.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"A2.T1.1.3.2.1\" class=\"ltx_td ltx_align_left\">walker-sparse</td>\n<td id=\"A2.T1.1.3.2.2\" class=\"ltx_td ltx_align_left\">60</td>\n<td id=\"A2.T1.1.3.2.3\" class=\"ltx_td ltx_align_left\">10</td>\n<td id=\"A2.T1.1.3.2.4\" class=\"ltx_td ltx_align_left\">2</td>\n<td id=\"A2.T1.1.3.2.5\" class=\"ltx_td ltx_align_left\">2</td>\n</tr>\n<tr id=\"A2.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"A2.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_b\">hard-point-robot</td>\n<td id=\"A2.T1.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_b\">40</td>\n<td id=\"A2.T1.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_b\">10</td>\n<td id=\"A2.T1.1.4.3.4\" class=\"ltx_td ltx_align_left ltx_border_b\">4</td>\n<td id=\"A2.T1.1.4.3.5\" class=\"ltx_td ltx_align_left ltx_border_b\">2</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "We model the context encoder as the product of independent Gaussian factors, in which the mean and variance are parameterized by MLPs with 333 hidden layers of (300,300,300)300300300(300,300,300) units that produce a 7-dimensional vector. When comparing context encoder training strategy, we use deterministic version of the context encoder network. In other cases, we select β𝛽\\beta in KL divergence term from {0.01,0.1,1}0.010.11\\{0.01,0.1,1\\}. For contrastive context encoder, the scale of RV or DP loss is 111 while the scale for contrastive loss is chosen between {1,5,10}1510\\{1,5,10\\}. For DP, the penalty parameter (Lee et al., 2020) is set to be 0.50.50.5. We use SAC for both exploration and execution agents and set learning rate as 3​e−43𝑒43e-4. Other hyperparameters are detailed on Table 1 and 2."
        ]
    },
    "A2.T2": {
        "caption": "Table 2: hyperparameters for continuous control benchmarks",
        "table": "<table id=\"A2.T2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\">Environment</th>\n<th id=\"A2.T2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Meta-train tasks</th>\n<th id=\"A2.T2.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Meta-test tasks</th>\n<th id=\"A2.T2.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Meta batch size</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"A2.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">humanoid-dir</th>\n<td id=\"A2.T2.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">100</td>\n<td id=\"A2.T2.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">30</td>\n<td id=\"A2.T2.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">20</td>\n</tr>\n<tr id=\"A2.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"A2.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">cheetah-mass</th>\n<td id=\"A2.T2.1.3.2.2\" class=\"ltx_td ltx_align_left\">30</td>\n<td id=\"A2.T2.1.3.2.3\" class=\"ltx_td ltx_align_left\">5</td>\n<td id=\"A2.T2.1.3.2.4\" class=\"ltx_td ltx_align_left\">16</td>\n</tr>\n<tr id=\"A2.T2.1.4.3\" class=\"ltx_tr\">\n<th id=\"A2.T2.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">cheetah-mass-OOD</th>\n<td id=\"A2.T2.1.4.3.2\" class=\"ltx_td ltx_align_left\">30</td>\n<td id=\"A2.T2.1.4.3.3\" class=\"ltx_td ltx_align_left\">5</td>\n<td id=\"A2.T2.1.4.3.4\" class=\"ltx_td ltx_align_left\">16</td>\n</tr>\n<tr id=\"A2.T2.1.5.4\" class=\"ltx_tr\">\n<th id=\"A2.T2.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">cheetah-vel-OOD</th>\n<td id=\"A2.T2.1.5.4.2\" class=\"ltx_td ltx_align_left\">50</td>\n<td id=\"A2.T2.1.5.4.3\" class=\"ltx_td ltx_align_left\">5</td>\n<td id=\"A2.T2.1.5.4.4\" class=\"ltx_td ltx_align_left\">24</td>\n</tr>\n<tr id=\"A2.T2.1.6.5\" class=\"ltx_tr\">\n<th id=\"A2.T2.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">ant-mass</th>\n<td id=\"A2.T2.1.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_b\">50</td>\n<td id=\"A2.T2.1.6.5.3\" class=\"ltx_td ltx_align_left ltx_border_b\">5</td>\n<td id=\"A2.T2.1.6.5.4\" class=\"ltx_td ltx_align_left ltx_border_b\">24</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "We model the context encoder as the product of independent Gaussian factors, in which the mean and variance are parameterized by MLPs with 333 hidden layers of (300,300,300)300300300(300,300,300) units that produce a 7-dimensional vector. When comparing context encoder training strategy, we use deterministic version of the context encoder network. In other cases, we select β𝛽\\beta in KL divergence term from {0.01,0.1,1}0.010.11\\{0.01,0.1,1\\}. For contrastive context encoder, the scale of RV or DP loss is 111 while the scale for contrastive loss is chosen between {1,5,10}1510\\{1,5,10\\}. For DP, the penalty parameter (Lee et al., 2020) is set to be 0.50.50.5. We use SAC for both exploration and execution agents and set learning rate as 3​e−43𝑒43e-4. Other hyperparameters are detailed on Table 1 and 2."
        ]
    }
}