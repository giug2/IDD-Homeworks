{
    "PAPER'S NUMBER OF TABLES": 3,
    "S6.T1": {
        "caption": "Table 1: Accuracies on target domains. ",
        "table": "<table id=\"S6.T1.7\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T1.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S6.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\lambda\" display=\"inline\"><semantics id=\"S6.T1.1.1.1.m1.1a\"><mi mathsize=\"90%\" id=\"S6.T1.1.1.1.m1.1.1\" xref=\"S6.T1.1.1.1.m1.1.1.cmml\">λ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.1.1.1.m1.1b\"><ci id=\"S6.T1.1.1.1.m1.1.1.cmml\" xref=\"S6.T1.1.1.1.m1.1.1\">𝜆</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.1.1.1.m1.1c\">\\lambda</annotation></semantics></math></th>\n<th id=\"S6.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.2.2.2.1\" class=\"ltx_text ltx_font_typewriter ltx_font_bold\" style=\"font-size:90%;\">mt<span id=\"S6.T1.2.2.2.1.2\" class=\"ltx_text ltx_font_serif\">, </span>sv<span id=\"S6.T1.2.2.2.1.1\" class=\"ltx_text ltx_font_serif\"> <math id=\"S6.T1.2.2.2.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S6.T1.2.2.2.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S6.T1.2.2.2.1.1.m1.1.1\" xref=\"S6.T1.2.2.2.1.1.m1.1.1.cmml\">→</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.2.2.2.1.1.m1.1b\"><ci id=\"S6.T1.2.2.2.1.1.m1.1.1.cmml\" xref=\"S6.T1.2.2.2.1.1.m1.1.1\">→</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.2.2.2.1.1.m1.1c\">\\rightarrow</annotation></semantics></math> </span>up</span></th>\n<th id=\"S6.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.3.3.3.1\" class=\"ltx_text ltx_font_typewriter ltx_font_bold\" style=\"font-size:90%;\">mt<span id=\"S6.T1.3.3.3.1.2\" class=\"ltx_text ltx_font_serif\">, </span>up<span id=\"S6.T1.3.3.3.1.1\" class=\"ltx_text ltx_font_serif\"> <math id=\"S6.T1.3.3.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S6.T1.3.3.3.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S6.T1.3.3.3.1.1.m1.1.1\" xref=\"S6.T1.3.3.3.1.1.m1.1.1.cmml\">→</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.3.3.3.1.1.m1.1b\"><ci id=\"S6.T1.3.3.3.1.1.m1.1.1.cmml\" xref=\"S6.T1.3.3.3.1.1.m1.1.1\">→</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.3.3.3.1.1.m1.1c\">\\rightarrow</annotation></semantics></math> </span>sv</span></th>\n<th id=\"S6.T1.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.4.4.4.1\" class=\"ltx_text ltx_font_typewriter ltx_font_bold\" style=\"font-size:90%;\">up<span id=\"S6.T1.4.4.4.1.2\" class=\"ltx_text ltx_font_serif\">, </span>sv<span id=\"S6.T1.4.4.4.1.1\" class=\"ltx_text ltx_font_serif\"> <math id=\"S6.T1.4.4.4.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S6.T1.4.4.4.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S6.T1.4.4.4.1.1.m1.1.1\" xref=\"S6.T1.4.4.4.1.1.m1.1.1.cmml\">→</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.4.4.4.1.1.m1.1b\"><ci id=\"S6.T1.4.4.4.1.1.m1.1.1.cmml\" xref=\"S6.T1.4.4.4.1.1.m1.1.1\">→</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.4.4.4.1.1.m1.1c\">\\rightarrow</annotation></semantics></math> </span>mt</span></th>\n<th id=\"S6.T1.4.4.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Avg</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T1.5.5\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S6.T1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"n_{i}/n\" display=\"inline\"><semantics id=\"S6.T1.5.5.1.m1.1a\"><mrow id=\"S6.T1.5.5.1.m1.1.1\" xref=\"S6.T1.5.5.1.m1.1.1.cmml\"><msub id=\"S6.T1.5.5.1.m1.1.1.2\" xref=\"S6.T1.5.5.1.m1.1.1.2.cmml\"><mi mathsize=\"90%\" id=\"S6.T1.5.5.1.m1.1.1.2.2\" xref=\"S6.T1.5.5.1.m1.1.1.2.2.cmml\">n</mi><mi mathsize=\"90%\" id=\"S6.T1.5.5.1.m1.1.1.2.3\" xref=\"S6.T1.5.5.1.m1.1.1.2.3.cmml\">i</mi></msub><mo maxsize=\"90%\" minsize=\"90%\" stretchy=\"true\" symmetric=\"true\" id=\"S6.T1.5.5.1.m1.1.1.1\" xref=\"S6.T1.5.5.1.m1.1.1.1.cmml\">/</mo><mi mathsize=\"90%\" id=\"S6.T1.5.5.1.m1.1.1.3\" xref=\"S6.T1.5.5.1.m1.1.1.3.cmml\">n</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.5.5.1.m1.1b\"><apply id=\"S6.T1.5.5.1.m1.1.1.cmml\" xref=\"S6.T1.5.5.1.m1.1.1\"><divide id=\"S6.T1.5.5.1.m1.1.1.1.cmml\" xref=\"S6.T1.5.5.1.m1.1.1.1\"></divide><apply id=\"S6.T1.5.5.1.m1.1.1.2.cmml\" xref=\"S6.T1.5.5.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S6.T1.5.5.1.m1.1.1.2.1.cmml\" xref=\"S6.T1.5.5.1.m1.1.1.2\">subscript</csymbol><ci id=\"S6.T1.5.5.1.m1.1.1.2.2.cmml\" xref=\"S6.T1.5.5.1.m1.1.1.2.2\">𝑛</ci><ci id=\"S6.T1.5.5.1.m1.1.1.2.3.cmml\" xref=\"S6.T1.5.5.1.m1.1.1.2.3\">𝑖</ci></apply><ci id=\"S6.T1.5.5.1.m1.1.1.3.cmml\" xref=\"S6.T1.5.5.1.m1.1.1.3\">𝑛</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.5.5.1.m1.1c\">n_{i}/n</annotation></semantics></math></th>\n<td id=\"S6.T1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">59.0</span></td>\n<td id=\"S6.T1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">14.1</span></td>\n<td id=\"S6.T1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.5.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.1</span></td>\n<td id=\"S6.T1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.5.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">29.7</span></td>\n</tr>\n<tr id=\"S6.T1.6.6\" class=\"ltx_tr\">\n<th id=\"S6.T1.6.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S6.T1.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"1/m\" display=\"inline\"><semantics id=\"S6.T1.6.6.1.m1.1a\"><mrow id=\"S6.T1.6.6.1.m1.1.1\" xref=\"S6.T1.6.6.1.m1.1.1.cmml\"><mn mathsize=\"90%\" id=\"S6.T1.6.6.1.m1.1.1.2\" xref=\"S6.T1.6.6.1.m1.1.1.2.cmml\">1</mn><mo maxsize=\"90%\" minsize=\"90%\" stretchy=\"true\" symmetric=\"true\" id=\"S6.T1.6.6.1.m1.1.1.1\" xref=\"S6.T1.6.6.1.m1.1.1.1.cmml\">/</mo><mi mathsize=\"90%\" id=\"S6.T1.6.6.1.m1.1.1.3\" xref=\"S6.T1.6.6.1.m1.1.1.3.cmml\">m</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.6.6.1.m1.1b\"><apply id=\"S6.T1.6.6.1.m1.1.1.cmml\" xref=\"S6.T1.6.6.1.m1.1.1\"><divide id=\"S6.T1.6.6.1.m1.1.1.1.cmml\" xref=\"S6.T1.6.6.1.m1.1.1.1\"></divide><cn type=\"integer\" id=\"S6.T1.6.6.1.m1.1.1.2.cmml\" xref=\"S6.T1.6.6.1.m1.1.1.2\">1</cn><ci id=\"S6.T1.6.6.1.m1.1.1.3.cmml\" xref=\"S6.T1.6.6.1.m1.1.1.3\">𝑚</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.6.6.1.m1.1c\">1/m</annotation></semantics></math></th>\n<td id=\"S6.T1.6.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.6.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">58.7</span></td>\n<td id=\"S6.T1.6.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">14.9</span></td>\n<td id=\"S6.T1.6.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.6.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">52.1</span></td>\n<td id=\"S6.T1.6.6.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.6.6.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">41.6</span></td>\n</tr>\n<tr id=\"S6.T1.7.8.1\" class=\"ltx_tr\">\n<th id=\"S6.T1.7.8.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.8.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">AFL</span></th>\n<td id=\"S6.T1.7.8.1.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.8.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">60.1</span></td>\n<td id=\"S6.T1.7.8.1.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.8.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.0</span></td>\n<td id=\"S6.T1.7.8.1.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.8.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">52.4</span></td>\n<td id=\"S6.T1.7.8.1.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.8.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">42.5</span></td>\n</tr>\n<tr id=\"S6.T1.7.9.2\" class=\"ltx_tr\">\n<th id=\"S6.T1.7.9.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.9.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">DRFA</span></th>\n<td id=\"S6.T1.7.9.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.9.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">61.6</span></td>\n<td id=\"S6.T1.7.9.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.9.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.1</span></td>\n<td id=\"S6.T1.7.9.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.9.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">53.0</span></td>\n<td id=\"S6.T1.7.9.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.9.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">43.2</span></td>\n</tr>\n<tr id=\"S6.T1.7.7\" class=\"ltx_tr\">\n<th id=\"S6.T1.7.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.7.1.1\" class=\"ltx_text ltx_markedasmath ltx_font_sansserif\" style=\"font-size:90%;\">WAFL</span></th>\n<td id=\"S6.T1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.7.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">65.6</span></td>\n<td id=\"S6.T1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.7.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">16.6</span></td>\n<td id=\"S6.T1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.7.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">58.1</span></td>\n<td id=\"S6.T1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S6.T1.7.7.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">46.7</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We aim to show four key results through numerical experiments. First, we show the relationship between the hyperparameter ",
                "γ",
                "𝛾",
                "\\gamma",
                " and the traditional worst-case perturbation ",
                "ρ",
                "𝜌",
                "\\rho",
                " used in distributionally robust learning . Second, we investigate the effect of ",
                "γ",
                "𝛾",
                "\\gamma",
                " on ",
                "WAFL",
                "’s performance in two data settings . Third, we provide an extensive comparison of ",
                "WAFL",
                " with other robust baselines and with FedAvg in scenarios with varying degrees of attack in an FL network . Finally,  we perform several experiments in multi-source domain adaptation to illustrate the findings in ",
                "Sec.",
                " ",
                "5",
                ".",
                "Experimental settings.",
                " We design two non-i.i.d. FL settings. First, we use the MNIST dataset ",
                "[",
                "41",
                "]",
                " to distribute to ",
                "100",
                "100",
                "100",
                " clients and employ a multinomial logistic regression model in a convex setting. We then use CIFAR-10 ",
                "[",
                "42",
                "]",
                " to distribute to ",
                "20",
                "20",
                "20",
                " clients and employ a CNN model in ",
                "McMahan et al. [",
                "2",
                "]",
                " in a non-convex setting. In the following experiments, we randomly sample ",
                "|",
                "S",
                "t",
                "|",
                "=",
                "10",
                "subscript",
                "𝑆",
                "𝑡",
                "10",
                "|S_{t}|=10",
                " clients to participate in training at each communication round. When the stochastic gradient is calculated, we use a batch size of ",
                "|",
                "𝒟",
                "i",
                "|",
                "=",
                "64",
                "subscript",
                "𝒟",
                "𝑖",
                "64",
                "|{\\mathcal{D}}_{i}|=64",
                ". For a fair comparison, we use the same number of global and local optimization rounds for each algorithm (",
                "T",
                "=",
                "200",
                ",",
                "K",
                "=",
                "2",
                "formulae-sequence",
                "𝑇",
                "200",
                "𝐾",
                "2",
                "T=200,K=2",
                "). More detail can be found in ",
                "Sec.",
                " ",
                "G.1",
                ".",
                "Effect of ",
                "γ",
                "𝛾",
                "\\gamma",
                " on the worst-case risk perturbations.",
                " Define the (squared) average worst-case perturbation as ",
                "ρ",
                "^",
                "2",
                "=",
                "𝐄",
                "Z",
                "∼",
                "P",
                "^",
                "λ",
                "​",
                "[",
                "d",
                "2",
                "​",
                "(",
                "Z",
                "^",
                ",",
                "Z",
                ")",
                "]",
                "superscript",
                "^",
                "𝜌",
                "2",
                "subscript",
                "𝐄",
                "similar-to",
                "𝑍",
                "subscript",
                "^",
                "𝑃",
                "𝜆",
                "delimited-[]",
                "superscript",
                "𝑑",
                "2",
                "^",
                "𝑍",
                "𝑍",
                "\\widehat{\\rho}^{2}=\\mathbf{E}_{Z\\sim\\widehat{P}_{\\lambda}}\\bigl{[}d^{2}(\\widehat{Z},Z)\\bigr{]}",
                ", where ",
                "Z",
                "^",
                "^",
                "𝑍",
                "\\widehat{Z}",
                " is the adversarial example of ",
                "Z",
                "𝑍",
                "Z",
                " as a solution to ",
                "ϕ",
                "γ",
                "​",
                "(",
                "Z",
                ",",
                "⋅",
                ")",
                "subscript",
                "italic-ϕ",
                "𝛾",
                "𝑍",
                "⋅",
                "\\phi_{\\gamma}(Z,\\cdot)",
                ". ",
                "Fig.",
                " ",
                "2",
                " depicts the relationship between ",
                "ρ",
                "^",
                "^",
                "𝜌",
                "\\widehat{\\rho}",
                " and the predetermined ",
                "γ",
                "𝛾",
                "\\gamma",
                " in the two data settings, and shows that smaller ",
                "γ",
                "𝛾",
                "\\gamma",
                " corresponds to larger ",
                "ρ",
                "^",
                "^",
                "𝜌",
                "\\widehat{\\rho}",
                ". This allows us to indirectly control the amount of worst-case perturbation through the change of the hyperparameter ",
                "γ",
                "𝛾",
                "\\gamma",
                " in the opposite direction. In other words, ",
                "γ",
                "𝛾",
                "\\gamma",
                " is a hyperparameter that needs fine-tuning in order to obtain the best performance, and setting a sufficiently large ",
                "γ",
                "𝛾",
                "\\gamma",
                " provides a ",
                "moderate",
                " level of robustness (smaller ",
                "ρ",
                "𝜌",
                "\\rho",
                " by duality) while ensuring ",
                "ϕ",
                "γ",
                "subscript",
                "italic-ϕ",
                "𝛾",
                "\\phi_{\\gamma}",
                " can be solved ",
                "fast",
                " using gradient methods (",
                "Sec.",
                " ",
                "3.3",
                ").",
                "Effect of ",
                "γ",
                "𝛾",
                "\\gamma",
                " on the generalizability and robustness of ",
                "WAFL",
                ".",
                "\nConsider ",
                "P",
                "^",
                "λ",
                "subscript",
                "^",
                "𝑃",
                "𝜆",
                "\\widehat{P}_{\\lambda}",
                " and ",
                "Q",
                "^",
                "^",
                "𝑄",
                "\\widehat{Q}",
                " as the empirical distributions of training and test samples, respectively. By controlling the hyperparameter ",
                "γ",
                "𝛾",
                "\\gamma",
                ", we aim to train a global model robust to any test distribution ",
                "Q",
                "^",
                "^",
                "𝑄",
                "\\widehat{Q}",
                ". To do so, we design two scenarios. In the ",
                "clean data",
                " scenario, the global model is trained with different values of ",
                "γ",
                "𝛾",
                "\\gamma",
                " and evaluated on clients’ hold-out test data. In the ",
                "distribution shift",
                " scenario, the training process is the same, but the hold-out test data go through distribution shifts. To obtain these shifts,  we employ the common PGD attack ",
                "[",
                "34",
                "]",
                " under the ",
                "l",
                "∞",
                "subscript",
                "𝑙",
                "l_{\\infty}",
                "-norm to generate an ",
                "ϵ",
                "italic-ϵ",
                "\\epsilon",
                "-level perturbation of clients’ test data. We fix the number of gradient steps to generate adversarial examples, and use ",
                "t",
                "a",
                "​",
                "v",
                "​",
                "d",
                "=",
                "40",
                ",",
                "ϵ",
                "=",
                "0.3",
                ",",
                "α",
                "=",
                "0.01",
                "formulae-sequence",
                "subscript",
                "𝑡",
                "𝑎",
                "𝑣",
                "𝑑",
                "40",
                "formulae-sequence",
                "italic-ϵ",
                "0.3",
                "𝛼",
                "0.01",
                "t_{avd}=40,\\epsilon=0.3,\\alpha=0.01",
                " for MNIST, and ",
                "t",
                "a",
                "​",
                "v",
                "​",
                "d",
                "=",
                "10",
                ",",
                "ϵ",
                "=",
                "8",
                "/",
                "255",
                ",",
                "α",
                "=",
                "2",
                "/",
                "255",
                "formulae-sequence",
                "subscript",
                "𝑡",
                "𝑎",
                "𝑣",
                "𝑑",
                "10",
                "formulae-sequence",
                "italic-ϵ",
                "8",
                "255",
                "𝛼",
                "2",
                "255",
                "t_{avd}=10,\\epsilon=8/255,\\alpha=2/255",
                " for CIFAR-10. We note that this setting is similar to that involving adversarial poisoning attacks, whose main purpose is to increase the Wasserstein distance between ",
                "P",
                "^",
                "λ",
                "subscript",
                "^",
                "𝑃",
                "𝜆",
                "\\widehat{P}_{\\lambda}",
                " and ",
                "Q",
                "^",
                "^",
                "𝑄",
                "\\widehat{Q}",
                ", thereby helping to verify the robustness of ",
                "WAFL",
                ".",
                "Fig.",
                " ",
                "3",
                " shows the performance of ",
                "WAFL",
                " and FedAvg in the two scenarios. Under ",
                "clean data",
                ", the distance between ",
                "P",
                "^",
                "γ",
                "subscript",
                "^",
                "𝑃",
                "𝛾",
                "\\widehat{P}_{\\gamma}",
                " and ",
                "Q",
                "^",
                "^",
                "𝑄",
                "\\widehat{Q}",
                " is relatively small, therefore requiring a lower amount of robustness (large ",
                "γ",
                "𝛾",
                "\\gamma",
                "). By carefully fine-tuning ",
                "γ",
                "𝛾",
                "\\gamma",
                " in the ranges ",
                "[",
                "0.5",
                ",",
                "1",
                "]",
                "0.5",
                "1",
                "[0.5,1]",
                " for MNIST and ",
                "[",
                "10",
                ",",
                "20",
                "]",
                "10",
                "20",
                "[10,20]",
                " for CIFAR-10, ",
                "WAFL",
                " enjoys the same or even better performance as FedAvg. The benefit of ",
                "γ",
                "𝛾",
                "\\gamma",
                " emerges most clearly under ",
                "distribution shift",
                ". In this scenario, ",
                "P",
                "^",
                "γ",
                "subscript",
                "^",
                "𝑃",
                "𝛾",
                "\\widehat{P}_{\\gamma}",
                " and ",
                "Q",
                "^",
                "^",
                "𝑄",
                "\\widehat{Q}",
                " grow further apart, requiring a larger ambiguity set ",
                "ℬ",
                "​",
                "(",
                "P",
                "^",
                "λ",
                ",",
                "ρ",
                "^",
                ")",
                "ℬ",
                "subscript",
                "^",
                "𝑃",
                "𝜆",
                "^",
                "𝜌",
                "{\\mathcal{B}}(\\widehat{P}_{\\lambda},\\widehat{\\rho})",
                " (or, equivalently, a smaller ",
                "γ",
                "𝛾",
                "\\gamma",
                ") to ensure robustness. Meanwhile, too small ",
                "γ",
                "𝛾",
                "\\gamma",
                " may violate the assumption that ",
                "γ",
                ">",
                "L",
                "z",
                "​",
                "z",
                "𝛾",
                "subscript",
                "𝐿",
                "𝑧",
                "𝑧",
                "\\gamma>L_{zz}",
                " and can hurt ",
                "WAFL",
                "’s performance as ",
                "ρ",
                "^",
                "^",
                "𝜌",
                "\\widehat{\\rho}",
                " becomes too large, as demonstrated in ",
                "Sec.",
                " ",
                "4",
                ". In later experiments, we choose ",
                "γ",
                "=",
                "0.5",
                "𝛾",
                "0.5",
                "\\gamma=0.5",
                " for MNIST and ",
                "γ",
                "=",
                "10",
                "𝛾",
                "10",
                "\\gamma=10",
                " for CIFAR-10.",
                "Comparison with other robust methods.",
                "\nWe compare ",
                "WAFL",
                " with FedAvg and four robust baselines in FL: FedPGM, FedFGSM, distributionally robust FedAvg ",
                "[",
                "14",
                ", DRFA]",
                " and agnostic FL ",
                "[",
                "11",
                ", AFL]",
                ". FedPGM and FedFGSM are FedAvg with adversarial training using the PGD method ",
                "[",
                "34",
                "]",
                " and the FGSM method ",
                "[",
                "31",
                "]",
                " on local clients, respectively. In each local update of FedPGD and FedFGSM, all clients solve ",
                "δ",
                "∗",
                "=",
                "arg",
                "​",
                "max",
                "∥",
                "δ",
                "∥",
                "∞",
                "≤",
                "ϵ",
                "⁡",
                "{",
                "ℓ",
                "​",
                "(",
                "h",
                "θ",
                "​",
                "(",
                "z",
                "+",
                "δ",
                ")",
                ",",
                "y",
                ")",
                "}",
                "superscript",
                "𝛿",
                "subscript",
                "arg",
                "max",
                "subscript",
                "delimited-∥∥",
                "𝛿",
                "italic-ϵ",
                "ℓ",
                "subscript",
                "ℎ",
                "𝜃",
                "𝑧",
                "𝛿",
                "𝑦",
                "\\delta^{*}=\\operatorname*{arg\\,max}\\nolimits_{\\lVert\\delta\\rVert_{\\infty}\\leq\\epsilon}\\big{\\{}\\ell(h_{\\theta}(z+\\delta),y)\\big{\\}}",
                " using projection onto an ",
                "l",
                "∞",
                "subscript",
                "𝑙",
                "l_{\\infty}",
                "-norm to find the worst-case perturbation ",
                "δ",
                "𝛿",
                "\\delta",
                ". While FedPGD uses ",
                "t",
                "a",
                "​",
                "v",
                "​",
                "d",
                "subscript",
                "𝑡",
                "𝑎",
                "𝑣",
                "𝑑",
                "t_{avd}",
                " gradient steps to find ",
                "δ",
                "∗",
                "superscript",
                "𝛿",
                "\\delta^{*}",
                ", FedFGSM uses only one gradient step. We use the same value of ",
                "t",
                "a",
                "​",
                "v",
                "​",
                "d",
                "subscript",
                "𝑡",
                "𝑎",
                "𝑣",
                "𝑑",
                "t_{avd}",
                " when training using ",
                "WAFL",
                " and FedPGM. On the other hand, DRFA and AFL both aim to achieve robustness by changing the clients’ weights ",
                "λ",
                "i",
                "subscript",
                "𝜆",
                "𝑖",
                "\\lambda_{i}",
                " based on local gradients and losses. AFL is considered a special case of DRFA by performing only one local gradient update.",
                "To compare ",
                "WAFL",
                " with these baselines, we consider a scenario in which a subset of clients suffers from distribution shifts (we call them ",
                "attacked clients",
                "). We generate the shifts using the same values of ",
                "ϵ",
                "italic-ϵ",
                "\\epsilon",
                " and ",
                "α",
                "𝛼",
                "\\alpha",
                " . We additionally train ",
                "WAFL",
                " with the value of ",
                "γ",
                "𝛾",
                "\\gamma",
                " generating the same level of perturbation ",
                "ϵ",
                "italic-ϵ",
                "\\epsilon",
                " in FedPGM and FedFGSM. The randomly-chosen attacked clients are between 20% and 80% of all clients. The global accuracy and loss for each dataset are presented in ",
                "Fig.",
                " ",
                "4",
                ". As expected, with all algorithms, the global accuracy decreases monotonically with the percentage of attacked clients. While FedAvg, by definition a non-robust method, unsurprisingly suffers the largest performance drop, ",
                "WAFL",
                " ourperforms all baselines, retaining over 50% accuracy on MNIST and nearly 45% on CIFAR-10 even when 80% of clients experience distribution shifts. We  observe that the performance of FedPGD and FedFGSM is much better than DRFA and AFL, and is the closest to ",
                "WAFL",
                ". This suggests that adjusting the clients’ weights ",
                "λ",
                "i",
                "subscript",
                "𝜆",
                "𝑖",
                "\\lambda_{i}",
                " may not notably help with achieving robustness.",
                "Furthermore, we provide a comparison between the performance of WAFL with different ",
                "p",
                "𝑝",
                "p",
                " values and other baselines in ",
                "Sec.",
                " ",
                "G.3",
                " to show that the duality result in ",
                "Equation",
                " ",
                "5",
                " suffices with any ",
                "ℓ",
                "p",
                "subscript",
                "ℓ",
                "𝑝",
                "\\ell_{p}",
                " norm.",
                "Domain adaptation.",
                "\n",
                "Sec.",
                " ",
                "5",
                " describes ",
                "WAFL",
                "’s capability in multi-source domain adaptation by solving a linear program in ",
                "λ",
                "𝜆",
                "\\lambda",
                ". We empirically demonstrate that capability using three digit recognition datasets including MNIST (",
                "mt",
                ") ",
                "[",
                "41",
                "]",
                ", USPS (",
                "up",
                ") ",
                "[",
                "43",
                "]",
                " and SVHN (",
                "sv",
                ") ",
                "[",
                "44",
                "]",
                " . We convert all images to have the size of ",
                "28",
                "×",
                "28",
                "×",
                "3",
                "28",
                "28",
                "3",
                "28\\times 28\\times 3",
                ". More information about these datasets  can be found  in ",
                "Sec.",
                " ",
                "G.1",
                ". We then train a global multinomial logistic regression model on two source domain datasets, and evaluate it using the remaining dataset as the target domain. To solve the linear program in ",
                "Equation",
                " ",
                "8",
                ", we estimate the Wasserstein distance by leveraging the computational methods introduced in ",
                "[",
                "40",
                ", ",
                "45",
                "]",
                ", and solve the linear program using SciPy",
                "2",
                "2",
                "2",
                "https://docs.scipy.org/doc/scipy/reference/optimize.html",
                ". For comparison, we use FedAvg in two scenarios: ",
                "λ",
                "i",
                "=",
                "n",
                "i",
                "/",
                "n",
                "subscript",
                "𝜆",
                "𝑖",
                "subscript",
                "𝑛",
                "𝑖",
                "𝑛",
                "\\lambda_{i}=n_{i}/n",
                " and ",
                "λ",
                "i",
                "=",
                "1",
                "/",
                "m",
                "subscript",
                "𝜆",
                "𝑖",
                "1",
                "𝑚",
                "\\lambda_{i}=1/m",
                ". We also employ AFL and DRFA, both of which can vary the ",
                "λ",
                "i",
                "subscript",
                "𝜆",
                "𝑖",
                "\\lambda_{i}",
                " to achieve robustness. All algorithms are fine-tuned to obtain their best performance on the target datasets.",
                "The accuracies on the target domains are presented in ",
                "Table",
                " ",
                "1",
                ". In all three scenarios, ",
                "WAFL",
                " outperforms all other methods, especially in the settings ",
                "mt",
                ", ",
                "sv",
                " ",
                "→",
                "→",
                "\\rightarrow",
                " ",
                "up",
                " and ",
                "sv",
                ", ",
                "up",
                " ",
                "→",
                "→",
                "\\rightarrow",
                " ",
                "mt",
                ", where ",
                "WAFL",
                "’s accuracy exceeds the second-best accuracy (achieved by DRFA) by five percentage points. We note that the ",
                "sv",
                " dataset is the most different from the other two, measured by the Wasserstein distance, which is why generalization to ",
                "sv",
                "’s domain is the most difficult."
            ]
        ]
    },
    "A7.T2": {
        "caption": "Table 2:  Statistics of all datasets using in the WAFL’s robustness experiments.",
        "table": "<table id=\"A7.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A7.T2.1.1\" class=\"ltx_tr\">\n<th id=\"A7.T2.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" rowspan=\"2\"><span id=\"A7.T2.1.1.2.1\" class=\"ltx_text\">Dataset</span></th>\n<th id=\"A7.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" rowspan=\"2\"><span id=\"A7.T2.1.1.1.1\" class=\"ltx_text\"><math id=\"A7.T2.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"m\" display=\"inline\"><semantics id=\"A7.T2.1.1.1.1.m1.1a\"><mi id=\"A7.T2.1.1.1.1.m1.1.1\" xref=\"A7.T2.1.1.1.1.m1.1.1.cmml\">m</mi><annotation-xml encoding=\"MathML-Content\" id=\"A7.T2.1.1.1.1.m1.1b\"><ci id=\"A7.T2.1.1.1.1.m1.1.1.cmml\" xref=\"A7.T2.1.1.1.1.m1.1.1\">𝑚</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T2.1.1.1.1.m1.1c\">m</annotation></semantics></math></span></th>\n<th id=\"A7.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" rowspan=\"2\"><span id=\"A7.T2.1.1.3.1\" class=\"ltx_text\">\n<span id=\"A7.T2.1.1.3.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"A7.T2.1.1.3.1.1.1\" class=\"ltx_tr\">\n<span id=\"A7.T2.1.1.3.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Total</span></span>\n<span id=\"A7.T2.1.1.3.1.1.2\" class=\"ltx_tr\">\n<span id=\"A7.T2.1.1.3.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">samples</span></span>\n</span></span></th>\n<th id=\"A7.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" rowspan=\"2\"><span id=\"A7.T2.1.1.4.1\" class=\"ltx_text\">\n<span id=\"A7.T2.1.1.4.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"A7.T2.1.1.4.1.1.1\" class=\"ltx_tr\">\n<span id=\"A7.T2.1.1.4.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Num labels</span></span>\n<span id=\"A7.T2.1.1.4.1.1.2\" class=\"ltx_tr\">\n<span id=\"A7.T2.1.1.4.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">/ client</span></span>\n</span></span></th>\n<th id=\"A7.T2.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" colspan=\"2\">Samples / client</th>\n</tr>\n<tr id=\"A7.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"A7.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Mean</th>\n<th id=\"A7.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Std</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A7.T2.1.3.1\" class=\"ltx_tr\">\n<th id=\"A7.T2.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">CIFAR-10</th>\n<td id=\"A7.T2.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">20</td>\n<td id=\"A7.T2.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">43,098</td>\n<td id=\"A7.T2.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">3</td>\n<td id=\"A7.T2.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">2154</td>\n<td id=\"A7.T2.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">593.8</td>\n</tr>\n<tr id=\"A7.T2.1.4.2\" class=\"ltx_tr\">\n<th id=\"A7.T2.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">MNIST</th>\n<td id=\"A7.T2.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">100</td>\n<td id=\"A7.T2.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">70,000</td>\n<td id=\"A7.T2.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">2</td>\n<td id=\"A7.T2.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">700</td>\n<td id=\"A7.T2.1.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">313.4</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "For robustness-related experiments, we distribute all datasets to clients as follows:",
                "MNIST",
                ": A handwritten digit dataset ",
                "[",
                "41",
                "]",
                " including ",
                "70",
                ",",
                "000",
                "70",
                "000",
                "70,000",
                " instances belonged to 10 classes. We distribute dataset to ",
                "m",
                "=",
                "100",
                "𝑚",
                "100",
                "m=100",
                " clients and each client has a different local data size with only ",
                "2",
                "2",
                "2",
                " of the ",
                "10",
                "10",
                "10",
                " classes.",
                "CIFAR-10",
                ": An object recognition dataset ",
                "[",
                "42",
                "]",
                " including ",
                "60",
                ",",
                "000",
                "60",
                "000",
                "60,000",
                " colored images belonged to ",
                "10",
                "10",
                "10",
                " classes. We partition the dataset to ",
                "m",
                "=",
                "20",
                "𝑚",
                "20",
                "m=20",
                " clients and there are ",
                "3",
                "3",
                "3",
                " labels per client. Each client has a different local data size.\n",
                "We standardize and randomly split all datasets with ",
                "75",
                "%",
                "percent",
                "75",
                "75\\%",
                " and ",
                "25",
                "%",
                "percent",
                "25",
                "25\\%",
                " for training and testing, respectively. The statistics of all datasets are summarized in ",
                "Table",
                " ",
                "2",
                ".",
                "For domain adaptation experiments, we use a set of three digit recognition datasets including MNIST ",
                "[",
                "41",
                "]",
                ", USPS ",
                "[",
                "43",
                "]",
                ", and SVHN ",
                "[",
                "44",
                "]",
                ". In particular, we choose two datasets for training and one for testing. The statistics of all datasets are summarized in ",
                "Table",
                " ",
                "3",
                "."
            ]
        ]
    },
    "A7.T3": {
        "caption": "Table 3: Statistics of all datasets using in the domain adaptation experiments.",
        "table": "<table id=\"A7.T3.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A7.T3.4.1.1\" class=\"ltx_tr\">\n<th id=\"A7.T3.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" rowspan=\"2\"><span id=\"A7.T3.4.1.1.1.1\" class=\"ltx_text\">Dataset</span></th>\n<th id=\"A7.T3.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" rowspan=\"2\"><span id=\"A7.T3.4.1.1.2.1\" class=\"ltx_text\">Original Size</span></th>\n<th id=\"A7.T3.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" rowspan=\"2\"><span id=\"A7.T3.4.1.1.3.1\" class=\"ltx_text\">\n<span id=\"A7.T3.4.1.1.3.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"A7.T3.4.1.1.3.1.1.1\" class=\"ltx_tr\">\n<span id=\"A7.T3.4.1.1.3.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Total</span></span>\n<span id=\"A7.T3.4.1.1.3.1.1.2\" class=\"ltx_tr\">\n<span id=\"A7.T3.4.1.1.3.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">samples</span></span>\n</span></span></th>\n<th id=\"A7.T3.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" rowspan=\"2\"><span id=\"A7.T3.4.1.1.4.1\" class=\"ltx_text\">\n<span id=\"A7.T3.4.1.1.4.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"A7.T3.4.1.1.4.1.1.1\" class=\"ltx_tr\">\n<span id=\"A7.T3.4.1.1.4.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Num labels</span></span>\n<span id=\"A7.T3.4.1.1.4.1.1.2\" class=\"ltx_tr\">\n<span id=\"A7.T3.4.1.1.4.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">/ client</span></span>\n</span></span></th>\n<th id=\"A7.T3.4.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\" colspan=\"2\">Samples / client</th>\n</tr>\n<tr id=\"A7.T3.4.2.2\" class=\"ltx_tr\">\n<th id=\"A7.T3.4.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Training</th>\n<th id=\"A7.T3.4.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Testing</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A7.T3.4.3.1\" class=\"ltx_tr\">\n<td id=\"A7.T3.4.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">MNIST</td>\n<td id=\"A7.T3.4.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">28x28</td>\n<td id=\"A7.T3.4.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">70,000</td>\n<td id=\"A7.T3.4.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">10</td>\n<td id=\"A7.T3.4.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">60,000</td>\n<td id=\"A7.T3.4.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">10,000</td>\n</tr>\n<tr id=\"A7.T3.4.4.2\" class=\"ltx_tr\">\n<td id=\"A7.T3.4.4.2.1\" class=\"ltx_td ltx_align_left\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">USPS</td>\n<td id=\"A7.T3.4.4.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">16x16</td>\n<td id=\"A7.T3.4.4.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">9,298</td>\n<td id=\"A7.T3.4.4.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">10</td>\n<td id=\"A7.T3.4.4.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">7,291</td>\n<td id=\"A7.T3.4.4.2.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">2,007</td>\n</tr>\n<tr id=\"A7.T3.4.5.3\" class=\"ltx_tr\">\n<td id=\"A7.T3.4.5.3.1\" class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">SVHN</td>\n<td id=\"A7.T3.4.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">32x32</td>\n<td id=\"A7.T3.4.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">89,289</td>\n<td id=\"A7.T3.4.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">10</td>\n<td id=\"A7.T3.4.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">63,257</td>\n<td id=\"A7.T3.4.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">26,032</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "For robustness-related experiments, we distribute all datasets to clients as follows:",
                "MNIST",
                ": A handwritten digit dataset ",
                "[",
                "41",
                "]",
                " including ",
                "70",
                ",",
                "000",
                "70",
                "000",
                "70,000",
                " instances belonged to 10 classes. We distribute dataset to ",
                "m",
                "=",
                "100",
                "𝑚",
                "100",
                "m=100",
                " clients and each client has a different local data size with only ",
                "2",
                "2",
                "2",
                " of the ",
                "10",
                "10",
                "10",
                " classes.",
                "CIFAR-10",
                ": An object recognition dataset ",
                "[",
                "42",
                "]",
                " including ",
                "60",
                ",",
                "000",
                "60",
                "000",
                "60,000",
                " colored images belonged to ",
                "10",
                "10",
                "10",
                " classes. We partition the dataset to ",
                "m",
                "=",
                "20",
                "𝑚",
                "20",
                "m=20",
                " clients and there are ",
                "3",
                "3",
                "3",
                " labels per client. Each client has a different local data size.\n",
                "We standardize and randomly split all datasets with ",
                "75",
                "%",
                "percent",
                "75",
                "75\\%",
                " and ",
                "25",
                "%",
                "percent",
                "25",
                "25\\%",
                " for training and testing, respectively. The statistics of all datasets are summarized in ",
                "Table",
                " ",
                "2",
                ".",
                "For domain adaptation experiments, we use a set of three digit recognition datasets including MNIST ",
                "[",
                "41",
                "]",
                ", USPS ",
                "[",
                "43",
                "]",
                ", and SVHN ",
                "[",
                "44",
                "]",
                ". In particular, we choose two datasets for training and one for testing. The statistics of all datasets are summarized in ",
                "Table",
                " ",
                "3",
                "."
            ]
        ]
    }
}