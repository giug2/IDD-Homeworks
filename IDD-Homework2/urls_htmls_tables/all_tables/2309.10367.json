{
    "PAPER'S NUMBER OF TABLES": 5,
    "S5.T1": {
        "caption": "Table 1: The VGG16 model architecture details used in computer vision experiment.",
        "table": "<table id=\"S5.T1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Layer type</td>\n<td id=\"S5.T1.1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Output dimension</td>\n<td id=\"S5.T1.1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">Param #</td>\n<td id=\"S5.T1.1.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Layer type</td>\n<td id=\"S5.T1.1.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Output dimension</td>\n<td id=\"S5.T1.1.1.1.1.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">Param #</td>\n<td id=\"S5.T1.1.1.1.1.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Layer type</td>\n<td id=\"S5.T1.1.1.1.1.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Output dimension</td>\n<td id=\"S5.T1.1.1.1.1.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Param #</td>\n</tr>\n<tr id=\"S5.T1.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">conv2d</td>\n<td id=\"S5.T1.1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(32, 32, 64)</td>\n<td id=\"S5.T1.1.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">1792</td>\n<td id=\"S5.T1.1.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">activation_4</td>\n<td id=\"S5.T1.1.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(8, 8, 256)</td>\n<td id=\"S5.T1.1.1.2.2.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.2.2.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">activation_9</td>\n<td id=\"S5.T1.1.1.2.2.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(4, 4, 512)</td>\n<td id=\"S5.T1.1.1.2.2.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S5.T1.1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">batch_normalization</td>\n<td id=\"S5.T1.1.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(32, 32, 64)</td>\n<td id=\"S5.T1.1.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">256</td>\n<td id=\"S5.T1.1.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">conv2d_5</td>\n<td id=\"S5.T1.1.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(8, 8, 256)</td>\n<td id=\"S5.T1.1.1.3.3.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">590080</td>\n<td id=\"S5.T1.1.1.3.3.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">max_pooling2d_3</td>\n<td id=\"S5.T1.1.1.3.3.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(2, 2, 512)</td>\n<td id=\"S5.T1.1.1.3.3.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S5.T1.1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">activation</td>\n<td id=\"S5.T1.1.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(32, 32, 64)</td>\n<td id=\"S5.T1.1.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">batch_normalization_5</td>\n<td id=\"S5.T1.1.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(8, 8, 256)</td>\n<td id=\"S5.T1.1.1.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">1024</td>\n<td id=\"S5.T1.1.1.4.4.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">conv2d_10</td>\n<td id=\"S5.T1.1.1.4.4.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(2, 2, 512)</td>\n<td id=\"S5.T1.1.1.4.4.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">2359808</td>\n</tr>\n<tr id=\"S5.T1.1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">conv2d_1</td>\n<td id=\"S5.T1.1.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(32, 32, 64)</td>\n<td id=\"S5.T1.1.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">36928</td>\n<td id=\"S5.T1.1.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">activation_5</td>\n<td id=\"S5.T1.1.1.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(8, 8, 256)</td>\n<td id=\"S5.T1.1.1.5.5.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.5.5.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">batch_normalization_10</td>\n<td id=\"S5.T1.1.1.5.5.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(2, 2, 512)</td>\n<td id=\"S5.T1.1.1.5.5.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">2048</td>\n</tr>\n<tr id=\"S5.T1.1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">batch_normalization_1</td>\n<td id=\"S5.T1.1.1.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(32, 32, 64)</td>\n<td id=\"S5.T1.1.1.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">256</td>\n<td id=\"S5.T1.1.1.6.6.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">conv2d_6</td>\n<td id=\"S5.T1.1.1.6.6.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(8, 8, 256)</td>\n<td id=\"S5.T1.1.1.6.6.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">590080</td>\n<td id=\"S5.T1.1.1.6.6.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">activation_10</td>\n<td id=\"S5.T1.1.1.6.6.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(2, 2, 512)</td>\n<td id=\"S5.T1.1.1.6.6.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S5.T1.1.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">activation</td>\n<td id=\"S5.T1.1.1.7.7.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(32, 32, 64)</td>\n<td id=\"S5.T1.1.1.7.7.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.7.7.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">batch_normalization_6</td>\n<td id=\"S5.T1.1.1.7.7.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(8, 8, 256)</td>\n<td id=\"S5.T1.1.1.7.7.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">1024</td>\n<td id=\"S5.T1.1.1.7.7.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">conv2d_11</td>\n<td id=\"S5.T1.1.1.7.7.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(2, 2, 512)</td>\n<td id=\"S5.T1.1.1.7.7.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">2359808</td>\n</tr>\n<tr id=\"S5.T1.1.1.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">max_pooling2d</td>\n<td id=\"S5.T1.1.1.8.8.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(16, 16, 64)</td>\n<td id=\"S5.T1.1.1.8.8.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.8.8.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">activation_6</td>\n<td id=\"S5.T1.1.1.8.8.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(8, 8, 256)</td>\n<td id=\"S5.T1.1.1.8.8.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.8.8.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">batch_normalization_11</td>\n<td id=\"S5.T1.1.1.8.8.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(2, 2, 512)</td>\n<td id=\"S5.T1.1.1.8.8.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">2048</td>\n</tr>\n<tr id=\"S5.T1.1.1.9.9\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">conv2d_2</td>\n<td id=\"S5.T1.1.1.9.9.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(16, 16, 128)</td>\n<td id=\"S5.T1.1.1.9.9.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">73856</td>\n<td id=\"S5.T1.1.1.9.9.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">max_pooling2d_2</td>\n<td id=\"S5.T1.1.1.9.9.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(4, 4, 256)</td>\n<td id=\"S5.T1.1.1.9.9.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.9.9.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">activation_11</td>\n<td id=\"S5.T1.1.1.9.9.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(2, 2, 512)</td>\n<td id=\"S5.T1.1.1.9.9.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S5.T1.1.1.10.10\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">batch_normalization_2</td>\n<td id=\"S5.T1.1.1.10.10.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(16, 16, 128)</td>\n<td id=\"S5.T1.1.1.10.10.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">512</td>\n<td id=\"S5.T1.1.1.10.10.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">conv2d_7</td>\n<td id=\"S5.T1.1.1.10.10.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(4, 4, 512)</td>\n<td id=\"S5.T1.1.1.10.10.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">1180160</td>\n<td id=\"S5.T1.1.1.10.10.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">conv2d_12</td>\n<td id=\"S5.T1.1.1.10.10.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(2, 2, 512)</td>\n<td id=\"S5.T1.1.1.10.10.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">2359808</td>\n</tr>\n<tr id=\"S5.T1.1.1.11.11\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.11.11.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">activation_2</td>\n<td id=\"S5.T1.1.1.11.11.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(16, 16, 128)</td>\n<td id=\"S5.T1.1.1.11.11.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.11.11.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">batch_normalization_7</td>\n<td id=\"S5.T1.1.1.11.11.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(4, 4, 512)</td>\n<td id=\"S5.T1.1.1.11.11.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">2048</td>\n<td id=\"S5.T1.1.1.11.11.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">batch_normalization_12</td>\n<td id=\"S5.T1.1.1.11.11.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(2, 2, 512)</td>\n<td id=\"S5.T1.1.1.11.11.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">2048</td>\n</tr>\n<tr id=\"S5.T1.1.1.12.12\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.12.12.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">conv2d_3</td>\n<td id=\"S5.T1.1.1.12.12.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(16, 16, 128)</td>\n<td id=\"S5.T1.1.1.12.12.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">147584</td>\n<td id=\"S5.T1.1.1.12.12.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">activation_7</td>\n<td id=\"S5.T1.1.1.12.12.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(4, 4, 512)</td>\n<td id=\"S5.T1.1.1.12.12.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.12.12.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">activation_12</td>\n<td id=\"S5.T1.1.1.12.12.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(2, 2, 512)</td>\n<td id=\"S5.T1.1.1.12.12.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S5.T1.1.1.13.13\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.13.13.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">batch_normalization_3</td>\n<td id=\"S5.T1.1.1.13.13.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(16, 16, 128)</td>\n<td id=\"S5.T1.1.1.13.13.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">512</td>\n<td id=\"S5.T1.1.1.13.13.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">conv2d_8</td>\n<td id=\"S5.T1.1.1.13.13.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(4, 4, 512)</td>\n<td id=\"S5.T1.1.1.13.13.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">2359808</td>\n<td id=\"S5.T1.1.1.13.13.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">max_pooling2d_4</td>\n<td id=\"S5.T1.1.1.13.13.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(1, 1, 512)</td>\n<td id=\"S5.T1.1.1.13.13.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S5.T1.1.1.14.14\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.14.14.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">activation_3</td>\n<td id=\"S5.T1.1.1.14.14.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(16, 16, 128)</td>\n<td id=\"S5.T1.1.1.14.14.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.14.14.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">batch_normalization_8</td>\n<td id=\"S5.T1.1.1.14.14.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(4, 4, 512)</td>\n<td id=\"S5.T1.1.1.14.14.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">2048</td>\n<td id=\"S5.T1.1.1.14.14.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">average_pooling2d</td>\n<td id=\"S5.T1.1.1.14.14.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(1, 1, 512)</td>\n<td id=\"S5.T1.1.1.14.14.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S5.T1.1.1.15.15\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.15.15.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">max_pooling2d_1</td>\n<td id=\"S5.T1.1.1.15.15.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(8, 8, 128)</td>\n<td id=\"S5.T1.1.1.15.15.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.15.15.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">activation_8</td>\n<td id=\"S5.T1.1.1.15.15.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(4, 4, 512)</td>\n<td id=\"S5.T1.1.1.15.15.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">0</td>\n<td id=\"S5.T1.1.1.15.15.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">flatten</td>\n<td id=\"S5.T1.1.1.15.15.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(512)</td>\n<td id=\"S5.T1.1.1.15.15.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0</td>\n</tr>\n<tr id=\"S5.T1.1.1.16.16\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.16.16.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">conv2d_4</td>\n<td id=\"S5.T1.1.1.16.16.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(8, 8, 256)</td>\n<td id=\"S5.T1.1.1.16.16.3\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">295168</td>\n<td id=\"S5.T1.1.1.16.16.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">conv2d_9</td>\n<td id=\"S5.T1.1.1.16.16.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(4, 4, 512)</td>\n<td id=\"S5.T1.1.1.16.16.6\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">2359808</td>\n<td id=\"S5.T1.1.1.16.16.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">dense</td>\n<td id=\"S5.T1.1.1.16.16.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">(10)</td>\n<td id=\"S5.T1.1.1.16.16.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">5130</td>\n</tr>\n<tr id=\"S5.T1.1.1.17.17\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.17.17.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">batch_normalization_4</td>\n<td id=\"S5.T1.1.1.17.17.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">(8, 8, 256)</td>\n<td id=\"S5.T1.1.1.17.17.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_rr ltx_border_t\">1024</td>\n<td id=\"S5.T1.1.1.17.17.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">batch_normalization_9</td>\n<td id=\"S5.T1.1.1.17.17.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">(4, 4, 512)</td>\n<td id=\"S5.T1.1.1.17.17.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_rr ltx_border_t\">2048</td>\n<td id=\"S5.T1.1.1.17.17.7\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T1.1.1.17.17.8\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T1.1.1.17.17.9\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Experiment 1: This experiment focuses on a computer vision task that utilizes CIFAR-10 dataset222http://www.cs.toronto.edu/~kriz/cifar.html. The dataset consists of 60,0006000060,000 colour images with dimensions of 32√ó32323232\\times 32 pixels, grouped into 101010 classes, with 6,00060006,000 samples per each. The dataset is divided into two subsets: 50,0005000050,000 training images and 10,0001000010,000 test images. Also, we used the VGG16 model Krizhevsky et¬†al. (2009) in this experiment. Table 1 shows the model architecture, including layer types, output dimensions, and the number of trainable parameters per layer. The model has a total of 14,736,7141473671414,736,714 parameters and 141414 trainable layers, including the output layer. The generated model size is 53.5‚ÄãM‚ÄãB53.5ùëÄùêµ53.5MB. For more information, please refer to the client source code available on GitHub.333https://github.com/saadiabadi/cifar_updated.git."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Model specification for the sentiments analysis architecture.",
        "table": "<table id=\"S5.T2.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Layers</span></td>\n<td id=\"S5.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Parameters characteristic</span></td>\n</tr>\n<tr id=\"S5.T2.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Embedding layer</span></td>\n<td id=\"S5.T2.1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">max features= 20000, maxlen= 100, embedding size= 128</td>\n</tr>\n<tr id=\"S5.T2.1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.3.3.1.1\" class=\"ltx_text ltx_font_bold\">Convolutional layer</span></td>\n<td id=\"S5.T2.1.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">kernel size=5, filters= 64, pool size= 4</td>\n</tr>\n<tr id=\"S5.T2.1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.4.4.1.1\" class=\"ltx_text ltx_font_bold\">LSTM layer</span></td>\n<td id=\"S5.T2.1.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">lstm outputsize= 70</td>\n</tr>\n<tr id=\"S5.T2.1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.1.5.5.1.1\" class=\"ltx_text ltx_font_bold\">One output Dense layer</span></td>\n<td id=\"S5.T2.1.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">2 outputs (positive or negative review)</td>\n</tr>\n<tr id=\"S5.T2.1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T2.1.1.6.6.1.1\" class=\"ltx_text ltx_font_bold\">The generated model size = 10MB</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Experiment 2:\nThis experiment is centred around sentiment analysis tasks using the IMDB dataset v1.0444https://ai.stanford.edu/~amaas/data/sentiment/. The dataset consists of 50,0005000050,000 reviews, with a maximum of 303030 reviews per movie, equally divided between positive and negative reviews. In Maas et¬†al. (2011), the dataset has been used for sentiment analysis tasks, where a machine learning model predicts whether a given review is positive or negative based on the review text. We used a deep learning model to predict the review decision for this task. Table 2 shows the detailed architecture of the model, including the layer types, dimensions and parameters used to construct and generate the initial model. Further technical details can be found on the client source code GitHub555https://github.com/saadiabadi/IMDB_Example.git."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: The average transferred data size for different numbers of trained layers during a communication round with 10 participating clients",
        "table": "<table id=\"S5.T3.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_r\"></th>\n<th id=\"S5.T3.1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">4 Layers</span></th>\n<th id=\"S5.T3.1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">7 Layers</span></th>\n<th id=\"S5.T3.1.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">10 Layers</span></th>\n<th id=\"S5.T3.1.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">14 Layers</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">No. of training parameters</span></td>\n<td id=\"S5.T3.1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">34.88 M</td>\n<td id=\"S5.T3.1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">67.92 M</td>\n<td id=\"S5.T3.1.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">101.3 M</td>\n<td id=\"S5.T3.1.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">147.2 M</td>\n</tr>\n<tr id=\"S5.T3.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.3.2.1.1\" class=\"ltx_text ltx_font_bold\">Transferred data size</span></td>\n<td id=\"S5.T3.1.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">133.1 MB</td>\n<td id=\"S5.T3.1.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">259.1 MB</td>\n<td id=\"S5.T3.1.1.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">386.5 MB</td>\n<td id=\"S5.T3.1.1.3.2.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">561.6 MB</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table¬†3 presents the number of trainable parameters and transferred data size for different training settings over 100 training rounds with 10 clients, highlighting the linear correlation between the number of trainable layers and serialized data size.",
            "Additionally, we observed a significant time difference (see Figure¬†7) between training a model with 4 layers (268 minutes) and 14 layers (331 minutes), with a difference of 63 minutes. When considering factors such as model accuracy (refer to Figure¬†1), transferred updated gradients, number of trainable parameters (as shown in Table¬†3), and training time (see Figure¬†7), these effects will be discussed in more detail in the upcoming section."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: The local training cost in terms of time (seconds), CPU, and RAM per round may vary for different clients with different flavors deployed on the SNIC Science Cloud. Flavors: ssc.xsmall (1 VCPU, 1 GB RAM),ssc.small (1 VCPU, 2 GB RAM), ssc.small.highcpu (2 VCPU, 2 GB RAM), ssc.medium (2 VCPU, 4 GB RAM), ssc.medium.highcpu (4 VCPU, 4 GB RAM), ssc.large (4 VCPU, 8 GB RAM), ssc.xlarge (8 VCPU, 16 GB RAM)",
        "table": "<table id=\"S5.T4.5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"3\"><span id=\"S5.T4.5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Flavour</span></th>\n<td id=\"S5.T4.5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" colspan=\"4\"><span id=\"S5.T4.5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Training time (Sec.)</span></td>\n<td id=\"S5.T4.5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"8\"><span id=\"S5.T4.5.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Resources Consumption</span></td>\n</tr>\n<tr id=\"S5.T4.5.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.5.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.5.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">4 Layers</span></td>\n<td id=\"S5.T4.5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.5.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">7 Layers</span></td>\n<td id=\"S5.T4.5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.5.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">10 Layers</span></td>\n<td id=\"S5.T4.5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.5.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">14 Layers</span></td>\n<td id=\"S5.T4.5.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T4.5.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">4 Layers</span></td>\n<td id=\"S5.T4.5.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T4.5.1.2.2.6.1\" class=\"ltx_text ltx_font_bold\">7 Layers</span></td>\n<td id=\"S5.T4.5.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T4.5.1.2.2.7.1\" class=\"ltx_text ltx_font_bold\">10 Layers</span></td>\n<td id=\"S5.T4.5.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T4.5.1.2.2.8.1\" class=\"ltx_text ltx_font_bold\">14 Layers</span></td>\n</tr>\n<tr id=\"S5.T4.5.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.5.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CPU</td>\n<td id=\"S5.T4.5.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">RAM (MB)</td>\n<td id=\"S5.T4.5.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CPU</td>\n<td id=\"S5.T4.5.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">RAM (MB)</td>\n<td id=\"S5.T4.5.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CPU</td>\n<td id=\"S5.T4.5.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">RAM (MB)</td>\n<td id=\"S5.T4.5.1.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CPU</td>\n<td id=\"S5.T4.5.1.3.3.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">RAM (MB)</td>\n</tr>\n<tr id=\"S5.T4.5.1.4.4\" class=\"ltx_tr\" style=\"background-color:#CCE6BF;\">\n<th id=\"S5.T4.5.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.1.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">ssc.xsmall</span></th>\n<td id=\"S5.T4.5.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.2.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">1119.49</span></td>\n<td id=\"S5.T4.5.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n<td id=\"S5.T4.5.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.4.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n<td id=\"S5.T4.5.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\"><span id=\"S5.T4.5.1.4.4.5.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n<td id=\"S5.T4.5.1.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.6.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">99%</span></td>\n<td id=\"S5.T4.5.1.4.4.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.7.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">988 (95.70%)</span></td>\n<td id=\"S5.T4.5.1.4.4.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.8.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n<td id=\"S5.T4.5.1.4.4.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.9.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n<td id=\"S5.T4.5.1.4.4.10\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.10.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n<td id=\"S5.T4.5.1.4.4.11\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.11.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n<td id=\"S5.T4.5.1.4.4.12\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.12.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n<td id=\"S5.T4.5.1.4.4.13\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.4.4.13.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n</tr>\n<tr id=\"S5.T4.5.1.5.5\" class=\"ltx_tr\" style=\"background-color:#CCE6BF;\">\n<th id=\"S5.T4.5.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.1.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">ssc.small</span></th>\n<td id=\"S5.T4.5.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.2.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">894.0</span></td>\n<td id=\"S5.T4.5.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.3.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">954.0</span></td>\n<td id=\"S5.T4.5.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.4.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">1086.0</span></td>\n<td id=\"S5.T4.5.1.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\"><span id=\"S5.T4.5.1.5.5.5.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n<td id=\"S5.T4.5.1.5.5.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.6.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">99%</span></td>\n<td id=\"S5.T4.5.1.5.5.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.7.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">1312 (66.21%)</span></td>\n<td id=\"S5.T4.5.1.5.5.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.8.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">99%</span></td>\n<td id=\"S5.T4.5.1.5.5.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.9.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">1490 (72.75%)</span></td>\n<td id=\"S5.T4.5.1.5.5.10\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.10.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">99%</span></td>\n<td id=\"S5.T4.5.1.5.5.11\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.11.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">1758 (85.83%)</span></td>\n<td id=\"S5.T4.5.1.5.5.12\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.12.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n<td id=\"S5.T4.5.1.5.5.13\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S5.T4.5.1.5.5.13.1\" class=\"ltx_text\" style=\"background-color:#CCE6BF;\">-</span></td>\n</tr>\n<tr id=\"S5.T4.5.1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T4.5.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">ssc.small.highcpu</th>\n<td id=\"S5.T4.5.1.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">535.24</td>\n<td id=\"S5.T4.5.1.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">546.23</td>\n<td id=\"S5.T4.5.1.6.6.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">604.65</td>\n<td id=\"S5.T4.5.1.6.6.5\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">619.65</td>\n<td id=\"S5.T4.5.1.6.6.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">90%</td>\n<td id=\"S5.T4.5.1.6.6.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1284 (64.64%)</td>\n<td id=\"S5.T4.5.1.6.6.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">94%</td>\n<td id=\"S5.T4.5.1.6.6.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1373 (69.10%)</td>\n<td id=\"S5.T4.5.1.6.6.10\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">96%</td>\n<td id=\"S5.T4.5.1.6.6.11\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1438 (72.39%)</td>\n<td id=\"S5.T4.5.1.6.6.12\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">98%</td>\n<td id=\"S5.T4.5.1.6.6.13\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1525 (76.78%)</td>\n</tr>\n<tr id=\"S5.T4.5.1.7.7\" class=\"ltx_tr\">\n<th id=\"S5.T4.5.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">ssc.medium</th>\n<td id=\"S5.T4.5.1.7.7.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">467.16</td>\n<td id=\"S5.T4.5.1.7.7.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">533.75</td>\n<td id=\"S5.T4.5.1.7.7.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">555.92</td>\n<td id=\"S5.T4.5.1.7.7.5\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">582.22</td>\n<td id=\"S5.T4.5.1.7.7.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">80%</td>\n<td id=\"S5.T4.5.1.7.7.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1410 (35.85%)</td>\n<td id=\"S5.T4.5.1.7.7.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">87%</td>\n<td id=\"S5.T4.5.1.7.7.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1486 (37.77%)</td>\n<td id=\"S5.T4.5.1.7.7.10\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">90%</td>\n<td id=\"S5.T4.5.1.7.7.11\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1559 (39.64%)</td>\n<td id=\"S5.T4.5.1.7.7.12\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">93%</td>\n<td id=\"S5.T4.5.1.7.7.13\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1678 (42.63%)</td>\n</tr>\n<tr id=\"S5.T4.5.1.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T4.5.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">ssc.medium.highcpu</th>\n<td id=\"S5.T4.5.1.8.8.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">280.87</td>\n<td id=\"S5.T4.5.1.8.8.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">310.19</td>\n<td id=\"S5.T4.5.1.8.8.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">323.15</td>\n<td id=\"S5.T4.5.1.8.8.5\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">357.6</td>\n<td id=\"S5.T4.5.1.8.8.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">71%</td>\n<td id=\"S5.T4.5.1.8.8.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1519 (38.63%)</td>\n<td id=\"S5.T4.5.1.8.8.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">77%</td>\n<td id=\"S5.T4.5.1.8.8.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1660 (42.20%)</td>\n<td id=\"S5.T4.5.1.8.8.10\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">82%</td>\n<td id=\"S5.T4.5.1.8.8.11\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1662 (42.20%)</td>\n<td id=\"S5.T4.5.1.8.8.12\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">88%</td>\n<td id=\"S5.T4.5.1.8.8.13\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1698 (43.18%)</td>\n</tr>\n<tr id=\"S5.T4.5.1.9.9\" class=\"ltx_tr\">\n<th id=\"S5.T4.5.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">ssc.large</th>\n<td id=\"S5.T4.5.1.9.9.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">270.26</td>\n<td id=\"S5.T4.5.1.9.9.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">303.13</td>\n<td id=\"S5.T4.5.1.9.9.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">315.37</td>\n<td id=\"S5.T4.5.1.9.9.5\" class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\">342.66</td>\n<td id=\"S5.T4.5.1.9.9.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">68%</td>\n<td id=\"S5.T4.5.1.9.9.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1541 (19.38%)</td>\n<td id=\"S5.T4.5.1.9.9.8\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">76%</td>\n<td id=\"S5.T4.5.1.9.9.9\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1602 (20.13%)</td>\n<td id=\"S5.T4.5.1.9.9.10\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">79%</td>\n<td id=\"S5.T4.5.1.9.9.11\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1661 (20.86%)</td>\n<td id=\"S5.T4.5.1.9.9.12\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">86%</td>\n<td id=\"S5.T4.5.1.9.9.13\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">1723 (21.64%)</td>\n</tr>\n<tr id=\"S5.T4.5.1.10.10\" class=\"ltx_tr\">\n<th id=\"S5.T4.5.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">ssc.xlarge</th>\n<td id=\"S5.T4.5.1.10.10.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">160.24</td>\n<td id=\"S5.T4.5.1.10.10.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">180.08</td>\n<td id=\"S5.T4.5.1.10.10.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">187.04</td>\n<td id=\"S5.T4.5.1.10.10.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_rr ltx_border_t\">195.86</td>\n<td id=\"S5.T4.5.1.10.10.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">55%</td>\n<td id=\"S5.T4.5.1.10.10.7\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">1795 (11.22%)</td>\n<td id=\"S5.T4.5.1.10.10.8\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">60%</td>\n<td id=\"S5.T4.5.1.10.10.9\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">1934 (12.09%)</td>\n<td id=\"S5.T4.5.1.10.10.10\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">64%</td>\n<td id=\"S5.T4.5.1.10.10.11\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">1988 (12.42%)</td>\n<td id=\"S5.T4.5.1.10.10.12\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">78%</td>\n<td id=\"S5.T4.5.1.10.10.13\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">2059 (12.86%)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In this section we empirically study practical resource constraints by varying the computational resources available clients side by using different VM flavors in the SNIC Science Cloud. Table 4 reports the measured percentage of CPU and RAM utilization for local training when varying the number of trainable layers. We conducted experiments starting from the ssc.xsmall flavor, which simulates devices with restricted resources, and gradually scaled up the client resources to the ssc.xlarge flavor. As shown in Table 4, using the ssc.xsmall flavor allowed us to train only 4 layers of the VGG16 model, utilizing both CPU and RAM fully, and requiring 1119.49 seconds. Due to resource limitations, the client cannot train additional layers using the available resources. However, by scaling up to the ssc.small flavor, we were able to train up to 10 layers without any issues. Training the entire model required the essential resource of the ssc.small.highcpu flavor (2 VCPUs, 2 RAM). When training 4 layers, 90% of the CPU and 64.64% of the RAM were allocated, with a training time of 535.24 seconds compared to the ssc.xsmall flavor. Training half of the model resulted in a 4% increase in CPU and RAM utilization, slowing down the training process by approximately 11 seconds. Comparing the local training process for 14 and 4 layers, we observed a significant resource utilization gap (CPU: 8%, RAM: 12.14%) and an increase in training time by 84.41 seconds, highlighting the need for more computational power to perform the task."
        ]
    },
    "S5.T5": {
        "caption": "Table 5: The local training cost in terms of time (Seconds), CPU and RAM per round using Jetson Nano 2GB client (Quad-core ARM CPU, 2GB RAM)",
        "table": "<table id=\"S5.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"8\"><span id=\"S5.T5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Training time (Sec.)</span></td>\n</tr>\n<tr id=\"S5.T5.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T5.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">4 Layers</span></td>\n<td id=\"S5.T5.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T5.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">7 Layers</span></td>\n<td id=\"S5.T5.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T5.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">10 Layers</span></td>\n<td id=\"S5.T5.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T5.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">14 Layers</span></td>\n</tr>\n<tr id=\"S5.T5.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">191.4</td>\n<td id=\"S5.T5.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">235.6</td>\n<td id=\"S5.T5.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">257.8</td>\n<td id=\"S5.T5.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"background-color:#BFBFFF;\" colspan=\"2\"><span id=\"S5.T5.1.3.3.4.1\" class=\"ltx_text\" style=\"background-color:#BFBFFF;\">-</span></td>\n</tr>\n<tr id=\"S5.T5.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"8\"><span id=\"S5.T5.1.4.4.1.1\" class=\"ltx_text ltx_font_bold\">Resources Consumption</span></td>\n</tr>\n<tr id=\"S5.T5.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.5.5.1.1\" class=\"ltx_text ltx_font_bold\">CPU</span></td>\n<td id=\"S5.T5.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.5.5.2.1\" class=\"ltx_text ltx_font_bold\">RAM (MB)</span></td>\n<td id=\"S5.T5.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.5.5.3.1\" class=\"ltx_text ltx_font_bold\">CPU</span></td>\n<td id=\"S5.T5.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.5.5.4.1\" class=\"ltx_text ltx_font_bold\">RAM (MB)</span></td>\n<td id=\"S5.T5.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.5.5.5.1\" class=\"ltx_text ltx_font_bold\">CPU</span></td>\n<td id=\"S5.T5.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.5.5.6.1\" class=\"ltx_text ltx_font_bold\">RAM (MB)</span></td>\n<td id=\"S5.T5.1.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.5.5.7.1\" class=\"ltx_text ltx_font_bold\">CPU</span></td>\n<td id=\"S5.T5.1.5.5.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T5.1.5.5.8.1\" class=\"ltx_text ltx_font_bold\">RAM (MB)</span></td>\n</tr>\n<tr id=\"S5.T5.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">46.55%</td>\n<td id=\"S5.T5.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1747 (88.61%)</td>\n<td id=\"S5.T5.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">48.23%</td>\n<td id=\"S5.T5.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1821 (92.38%)</td>\n<td id=\"S5.T5.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">50.63%</td>\n<td id=\"S5.T5.1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1881 (95.68%)</td>\n<td id=\"S5.T5.1.6.6.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"background-color:#BFBFFF;\"><span id=\"S5.T5.1.6.6.7.1\" class=\"ltx_text\" style=\"background-color:#BFBFFF;\">-</span></td>\n<td id=\"S5.T5.1.6.6.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"background-color:#BFBFFF;\"><span id=\"S5.T5.1.6.6.8.1\" class=\"ltx_text\" style=\"background-color:#BFBFFF;\">-</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 5 reports the training time and resource consumption per training round for different trainable layers on the Jetson Nano. It can be observed that training 4 layers requires 191.4 seconds per round and demands 46.55% and 88.61% of the CPU and RAM, respectively. These resource demands are still manageable for the device. However, as we increase the number of trained layers, these values increase accordingly. Comparing the training time for 4 and 10 layers, we noticed a difference of approximately 66 seconds, which can be significant in critical scenarios. Furthermore, training 10 layers resulted in a 4% and 7% increase in both CPU and RAM consumption, respectively."
        ]
    }
}